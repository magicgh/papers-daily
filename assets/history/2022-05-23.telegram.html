<b><u>#ComputerVision</u></b> 
• <a href="http://arxiv.org/abs/2205.10351v1">Enriching StyleGAN with Illumination Physics</a> <a href="http://arxiv.org/pdf/2205.10351v1">[PDF]</a>
• <a href="http://arxiv.org/abs/2205.10347v1">Diverse super-resolution with pretrained deep hiererarchical VAEs</a> <a href="http://arxiv.org/pdf/2205.10347v1">[PDF]</a>
• <a href="http://arxiv.org/abs/2205.10342v1">Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT)</a> <a href="http://arxiv.org/pdf/2205.10342v1">[PDF]</a>

<b><u>#NLP</u></b> 
• <a href="http://arxiv.org/abs/2205.10350v1">Lossless Acceleration for Seq2seq Generation with Aggressive Decoding</a> <a href="http://arxiv.org/pdf/2205.10350v1">[PDF]</a> <a href="https://github.com/microsoft/unilm">[Code]</a>
• <a href="http://arxiv.org/abs/2205.10312v1">ClusterEA: Scalable Entity Alignment with Stochastic Training and Normalized Mini-batch Similarities</a> <a href="http://arxiv.org/pdf/2205.10312v1">[PDF]</a> <a href="https://github.com/joker-xii/clusterea">[Code]</a>
• <a href="http://arxiv.org/abs/2205.10282v1">Heterformer: A Transformer Architecture for Node Representation Learning on Heterogeneous Text-Rich Networks</a> <a href="http://arxiv.org/pdf/2205.10282v1">[PDF]</a>

<b><u>#ReinforcementLearning</u></b> 
• <a href="http://arxiv.org/abs/2205.10330v1">A Review of Safe Reinforcement Learning: Methods, Theory and Applications</a> <a href="http://arxiv.org/pdf/2205.10330v1">[PDF]</a> <a href="https://github.com/chauncygu/safe-reinforcement-learning-baselines">[Code]</a>
• <a href="http://arxiv.org/abs/2205.10218v1">Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions</a> <a href="http://arxiv.org/pdf/2205.10218v1">[PDF]</a>
• <a href="http://arxiv.org/abs/2205.10187v1">Adversarial Body Shape Search for Legged Robots</a> <a href="http://arxiv.org/pdf/2205.10187v1">[PDF]</a>

<b><u>#UnsupervisedLearning</u></b> 
<b>#ContinualLearning</b> 
• <a href="http://arxiv.org/abs/2205.09891v1">Interpolating Compressed Parameter Subspaces</a> <a href="http://arxiv.org/pdf/2205.09891v1">[PDF]</a>
• <a href="http://arxiv.org/abs/2205.09588v1">How catastrophic can catastrophic forgetting be in linear regression?</a> <a href="http://arxiv.org/pdf/2205.09588v1">[PDF]</a>
• <a href="http://arxiv.org/abs/2205.09357v1">Continual Pre-Training Mitigates Forgetting in Language and Vision</a> <a href="http://arxiv.org/pdf/2205.09357v1">[PDF]</a> <a href="https://github.com/andreacossu/continual-pretraining-nlp-vision">[Code]</a>
<b>#MetaLearning</b> 
• <a href="http://arxiv.org/abs/2205.09990v1">Set-based Meta-Interpolation for Few-Task Meta-Learning</a> <a href="http://arxiv.org/pdf/2205.09990v1">[PDF]</a>
• <a href="http://arxiv.org/abs/2205.09930v1">BayesPCN: A Continually Learnable Predictive Coding Associative Memory</a> <a href="http://arxiv.org/pdf/2205.09930v1">[PDF]</a>
• <a href="http://arxiv.org/abs/2205.08957v1">Meta-Learning Sparse Compression Networks</a> <a href="http://arxiv.org/pdf/2205.08957v1">[PDF]</a>
<b>#TransferLearning</b> 
• <a href="http://arxiv.org/abs/2205.10279v1">Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors</a> <a href="http://arxiv.org/pdf/2205.10279v1">[PDF]</a> <a href="https://github.com/hsouri/bayesiantransferlearning">[Code]</a>
• <a href="http://arxiv.org/abs/2205.09904v1">Deep transfer learning for image classification: a survey</a> <a href="http://arxiv.org/pdf/2205.09904v1">[PDF]</a>
• <a href="http://arxiv.org/abs/2205.09850v1">Human Gender Prediction Based on Deep Transfer Learning from Panoramic Radiograph Images</a> <a href="http://arxiv.org/pdf/2205.09850v1">[PDF]</a>

<b><u>#GraphNeuralNetwork</u></b> 
• <a href="http://arxiv.org/abs/2205.10282v1">Heterformer: A Transformer Architecture for Node Representation Learning on Heterogeneous Text-Rich Networks</a> <a href="http://arxiv.org/pdf/2205.10282v1">[PDF]</a>
• <a href="http://arxiv.org/abs/2205.10070v1">On the Prediction Instability of Graph Neural Networks</a> <a href="http://arxiv.org/pdf/2205.10070v1">[PDF]</a> <a href="https://github.com/mklabunde/on-the-prediction-instability-of-graph-neural-networks">[Code]</a>
• <a href="http://arxiv.org/abs/2205.09977v1">FairNorm: Fair and Fast Graph Neural Network Training</a> <a href="http://arxiv.org/pdf/2205.09977v1">[PDF]</a>

