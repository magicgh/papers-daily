{"Computer Vision": {"Computer Vision": {"2202.12884": {"publish_time": "2022-02-25", "title": "Learning to Identify Perceptual Bugs in 3D Video Games", "author": "Benedict Wilkins et.al.", "abstract": "Automated Bug Detection (ABD) in video games is composed of two distinct but complementary problems: automated game exploration and bug identification. Automated game exploration has received much recent attention, spurred on by developments in fields such as reinforcement learning. The complementary problem of identifying the bugs present in a player's experience has for the most part relied on the manual specification of rules. Although it is widely recognised that many bugs of interest cannot be identified with such methods, little progress has been made in this direction. In this work we show that it is possible to identify a range of perceptual bugs using learning-based methods by making use of only the rendered game screen as seen by the player. To support our work, we have developed World of Bugs (WOB) an open platform for testing ABD methods in 3D game environments.", "paper_url": "http://arxiv.org/abs/2202.12884v1", "pdf_url": "http://arxiv.org/pdf/2202.12884v1", "repo_url": null}, "2202.12860": {"publish_time": "2022-02-25", "title": "ARIA: Adversarially Robust Image Attribution for Content Provenance", "author": "Maksym Andriushchenko et.al.", "abstract": "Image attribution -- matching an image back to a trusted source -- is an emerging tool in the fight against online misinformation. Deep visual fingerprinting models have recently been explored for this purpose. However, they are not robust to tiny input perturbations known as adversarial examples. First we illustrate how to generate valid adversarial images that can easily cause incorrect image attribution. Then we describe an approach to prevent imperceptible adversarial attacks on deep visual fingerprinting models, via robust contrastive learning. The proposed training procedure leverages training on $\\ell_\\infty$-bounded adversarial examples, it is conceptually simple and incurs only a small computational overhead. The resulting models are substantially more robust, are accurate even on unperturbed images, and perform well even over a database with millions of images. In particular, we achieve 91.6% standard and 85.1% adversarial recall under $\\ell_\\infty$-bounded perturbations on manipulated images compared to 80.1% and 0.0% from prior work. We also show that robustness generalizes to other types of imperceptible perturbations unseen during training. Finally, we show how to train an adversarially robust image comparator model for detecting editorial changes in matched images.", "paper_url": "http://arxiv.org/abs/2202.12860v1", "pdf_url": "http://arxiv.org/pdf/2202.12860v1", "repo_url": null}, "2202.12838": {"publish_time": "2022-02-25", "title": "RELMOBNET: A Robust Two-Stage End-To-End Training Approach For MOBILENETV3 Based Relative Camera Pose Estimation", "author": "Praveen Kumar Rajendran et.al.", "abstract": "Relative camera pose estimation plays a pivotal role in dealing with 3D reconstruction and visual localization. To address this, we propose a Siamese network based on MobileNetV3-Large for an end-to-end relative camera pose regression independent of camera parameters. The proposed network uses pair of images taken at different locations in the same scene to estimate the 3D translation vector and rotation vector in unit quaternion. To increase the generality of the model, rather than training it for a single scene, data for four scenes are combined to train a single universal model to estimate the relative pose. Further for independency of hyperparameter weighing between translation and rotation loss is not used. Instead we use the novel two-stage training procedure to learn the balance implicitly with faster convergence. We compare the results obtained with the Cambridge Landmarks dataset, comprising of different scenes, with existing CNN-based regression methods as baselines, e.g., RPNet and RCPNet. The findings indicate that, when compared to RCPNet, proposed model improves the estimation of the translation vector by a percentage change of 16.11%, 28.88%, 52.27% on the Kings College, Old Hospital, St Marys Church scenes from Cambridge Landmarks dataset, respectively.", "paper_url": "http://arxiv.org/abs/2202.12838v1", "pdf_url": "http://arxiv.org/pdf/2202.12838v1", "repo_url": null}, "2202.12825": {"publish_time": "2022-02-25", "title": "NeuralFusion: Neural Volumetric Rendering under Human-object Interactions", "author": "Yuheng Jiang et.al.", "abstract": "4D reconstruction and rendering of human activities is critical for immersive VR/AR experience. Recent advances still fail to recover fine geometry and texture results with the level of detail present in the input images from sparse multi-view RGB cameras. In this paper, we propose NeuralHumanFVV, a real-time neural human performance capture and rendering system to generate both high-quality geometry and photo-realistic texture of human activities in arbitrary novel views. We propose a neural geometry generation scheme with a hierarchical sampling strategy for real-time implicit geometry inference, as well as a novel neural blending scheme to generate high resolution (e.g., 1k) and photo-realistic texture results in the novel views. Furthermore, we adopt neural normal blending to enhance geometry details and formulate our neural geometry and texture rendering into a multi-task learning framework. Extensive experiments demonstrate the effectiveness of our approach to achieve high-quality geometry and photo-realistic free view-point reconstruction for challenging human performances.", "paper_url": "http://arxiv.org/abs/2202.12825v1", "pdf_url": "http://arxiv.org/pdf/2202.12825v1", "repo_url": null}, "2202.12818": {"publish_time": "2022-02-25", "title": "Improving generalization with synthetic training data for deep learning based quality inspection", "author": "Antoine Cordier et.al.", "abstract": "Automating quality inspection with computer vision techniques is often a very data-demanding task. Specifically, supervised deep learning requires a large amount of annotated images for training. In practice, collecting and annotating such data is not only costly and laborious, but also inefficient, given the fact that only a few instances may be available for certain defect classes. If working with video frames can increase the number of these instances, it has a major disadvantage: the resulting images will be highly correlated with one another. As a consequence, models trained under such constraints are expected to be very sensitive to input distribution changes, which may be caused in practice by changes in the acquisition system (cameras, lights), in the parts or in the defects aspect. In this work, we demonstrate the use of randomly generated synthetic training images can help tackle domain instability issues, making the trained models more robust to contextual changes. We detail both our synthetic data generation pipeline and our deep learning methodology for answering these questions.", "paper_url": "http://arxiv.org/abs/2202.12818v1", "pdf_url": "http://arxiv.org/pdf/2202.12818v1", "repo_url": null}, "2202.14034": {"publish_time": "2022-02-28", "title": "Attribute Descent: Simulating Object-Centric Datasets on the Content Level and Beyond", "author": "Yue Yao et.al.", "abstract": "This article aims to use graphic engines to simulate a large number of training data that have free annotations and possibly strongly resemble to real-world data. Between synthetic and real, a two-level domain gap exists, involving content level and appearance level. While the latter is concerned with appearance style, the former problem arises from a different mechanism, i.e., content mismatch in attributes such as camera viewpoint, object placement and lighting conditions. In contrast to the widely-studied appearance-level gap, the content-level discrepancy has not been broadly studied. To address the content-level misalignment, we propose an attribute descent approach that automatically optimizes engine attributes to enable synthetic data to approximate real-world data. We verify our method on object-centric tasks, wherein an object takes up a major portion of an image. In these tasks, the search space is relatively small, and the optimization of each attribute yields sufficiently obvious supervision signals. We collect a new synthetic asset VehicleX, and reformat and reuse existing the synthetic assets ObjectX and PersonX. Extensive experiments on image classification and object re-identification confirm that adapted synthetic data can be effectively used in three scenarios: training with synthetic data only, training data augmentation and numerically understanding dataset content.", "paper_url": "http://arxiv.org/abs/2202.14034v1", "pdf_url": "http://arxiv.org/pdf/2202.14034v1", "repo_url": null}, "2202.14030": {"publish_time": "2022-02-28", "title": "Learning Semantic Segmentation from Multiple Datasets with Label Shifts", "author": "Dongwan Kim et.al.", "abstract": "With increasing applications of semantic segmentation, numerous datasets have been proposed in the past few years. Yet labeling remains expensive, thus, it is desirable to jointly train models across aggregations of datasets to enhance data volume and diversity. However, label spaces differ across datasets and may even be in conflict with one another. This paper proposes UniSeg, an effective approach to automatically train models across multiple datasets with differing label spaces, without any manual relabeling efforts. Specifically, we propose two losses that account for conflicting and co-occurring labels to achieve better generalization performance in unseen domains. First, a gradient conflict in training due to mismatched label spaces is identified and a class-independent binary cross-entropy loss is proposed to alleviate such label conflicts. Second, a loss function that considers class-relationships across datasets is proposed for a better multi-dataset training scheme. Extensive quantitative and qualitative analyses on road-scene datasets show that UniSeg improves over multi-dataset baselines, especially on unseen datasets, e.g., achieving more than 8% gain in IoU on KITTI averaged over all the settings.", "paper_url": "http://arxiv.org/abs/2202.14030v1", "pdf_url": "http://arxiv.org/pdf/2202.14030v1", "repo_url": null}, "2202.14026": {"publish_time": "2022-02-28", "title": "Robust Training under Label Noise by Over-parameterization", "author": "Sheng Liu et.al.", "abstract": "Recently, over-parameterized deep networks, with increasingly more network parameters than training samples, have dominated the performances of modern machine learning. However, when the training data is corrupted, it has been well-known that over-parameterized networks tend to overfit and do not generalize. In this work, we propose a principled approach for robust training of over-parameterized deep networks in classification tasks where a proportion of training labels are corrupted. The main idea is yet very simple: label noise is sparse and incoherent with the network learned from clean data, so we model the noise and learn to separate it from the data. Specifically, we model the label noise via another sparse over-parameterization term, and exploit implicit algorithmic regularizations to recover and separate the underlying corruptions. Remarkably, when trained using such a simple method in practice, we demonstrate state-of-the-art test accuracy against label noise on a variety of real datasets. Furthermore, our experimental results are corroborated by theory on simplified linear models, showing that exact separation between sparse noise and low-rank data can be achieved under incoherent conditions. The work opens many interesting directions for improving over-parameterized models by using sparse over-parameterization and implicit regularization.", "paper_url": "http://arxiv.org/abs/2202.14026v1", "pdf_url": "http://arxiv.org/pdf/2202.14026v1", "repo_url": "https://github.com/shengliu66/sop"}, "2202.14020": {"publish_time": "2022-02-28", "title": "State-of-the-Art in the Architecture, Methods and Applications of StyleGAN", "author": "Amit H. Bermano et.al.", "abstract": "Generative Adversarial Networks (GANs) have established themselves as a prevalent approach to image synthesis. Of these, StyleGAN offers a fascinating case study, owing to its remarkable visual quality and an ability to support a large array of downstream tasks. This state-of-the-art report covers the StyleGAN architecture, and the ways it has been employed since its conception, while also analyzing its severe limitations. It aims to be of use for both newcomers, who wish to get a grasp of the field, and for more experienced readers that might benefit from seeing current research trends and existing tools laid out. Among StyleGAN's most interesting aspects is its learned latent space. Despite being learned with no supervision, it is surprisingly well-behaved and remarkably disentangled. Combined with StyleGAN's visual quality, these properties gave rise to unparalleled editing capabilities. However, the control offered by StyleGAN is inherently limited to the generator's learned distribution, and can only be applied to images generated by StyleGAN itself. Seeking to bring StyleGAN's latent control to real-world scenarios, the study of GAN inversion and latent space embedding has quickly gained in popularity. Meanwhile, this same study has helped shed light on the inner workings and limitations of StyleGAN. We map out StyleGAN's impressive story through these investigations, and discuss the details that have made StyleGAN the go-to generator. We further elaborate on the visual priors StyleGAN constructs, and discuss their use in downstream discriminative tasks. Looking forward, we point out StyleGAN's limitations and speculate on current trends and promising directions for future research, such as task and target specific fine-tuning.", "paper_url": "http://arxiv.org/abs/2202.14020v1", "pdf_url": "http://arxiv.org/pdf/2202.14020v1", "repo_url": null}, "2202.14019": {"publish_time": "2022-02-28", "title": "Domain Knowledge-Informed Self-Supervised Representations for Workout Form Assessment", "author": "Paritosh Parmar et.al.", "abstract": "Maintaining proper form while exercising is important for preventing injuries and maximizing muscle mass gains. While fitness apps are becoming popular, they lack the functionality to detect errors in workout form. Detecting such errors naturally requires estimating users' body pose. However, off-the-shelf pose estimators struggle to perform well on the videos recorded in gym scenarios due to factors such as camera angles, occlusion from gym equipment, illumination, and clothing. To aggravate the problem, the errors to be detected in the workouts are very subtle. To that end, we propose to learn exercise-specific representations from unlabeled samples such that a small dataset annotated by experts suffices for supervised error detection. In particular, our domain knowledge-informed self-supervised approaches exploit the harmonic motion of the exercise actions, and capitalize on the large variances in camera angles, clothes, and illumination to learn powerful representations. To facilitate our self-supervised pretraining, and supervised finetuning, we curated a new exercise dataset, Fitness-AQA, comprising of three exercises: BackSquat, BarbellRow, and OverheadPress. It has been annotated by expert trainers for multiple crucial and typically occurring exercise errors. Experimental results show that our self-supervised representations outperform off-the-shelf 2D- and 3D-pose estimators and several other baselines.", "paper_url": "http://arxiv.org/abs/2202.14019v1", "pdf_url": "http://arxiv.org/pdf/2202.14019v1", "repo_url": null}, "2203.00680": {"publish_time": "2022-03-01", "title": "CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding", "author": "Mohamed Afham et.al.", "abstract": "Manual annotation of large-scale point cloud dataset for varying tasks such as 3D object classification, segmentation and detection is often laborious owing to the irregular structure of point clouds. Self-supervised learning, which operates without any human labeling, is a promising approach to address this issue. We observe in the real world that humans are capable of mapping the visual concepts learnt from 2D images to understand the 3D world. Encouraged by this insight, we propose CrossPoint, a simple cross-modal contrastive learning approach to learn transferable 3D point cloud representations. It enables a 3D-2D correspondence of objects by maximizing agreement between point clouds and the corresponding rendered 2D image in the invariant space, while encouraging invariance to transformations in the point cloud modality. Our joint training objective combines the feature correspondences within and across modalities, thus ensembles a rich learning signal from both 3D point cloud and 2D image modalities in a self-supervised fashion. Experimental results show that our approach outperforms the previous unsupervised learning methods on a diverse range of downstream tasks including 3D object classification and segmentation. Further, the ablation studies validate the potency of our approach for a better point cloud understanding. Code and pretrained models are available at http://github.com/MohamedAfham/CrossPoint.", "paper_url": "http://arxiv.org/abs/2203.00680v1", "pdf_url": "http://arxiv.org/pdf/2203.00680v1", "repo_url": "https://github.com/mohamedafham/crosspoint"}, "2203.00672": {"publish_time": "2022-03-01", "title": "Generalizable Person Re-Identification via Self-Supervised Batch Norm Test-Time Adaption", "author": "Ke Han et.al.", "abstract": "In this paper, we investigate the generalization problem of person re-identification (re-id), whose major challenge is the distribution shift on an unseen domain. As an important tool of regularizing the distribution, batch normalization (BN) has been widely used in existing methods. However, they neglect that BN is severely biased to the training domain and inevitably suffers the performance drop if directly generalized without being updated. To tackle this issue, we propose Batch Norm Test-time Adaption (BNTA), a novel re-id framework that applies the self-supervised strategy to update BN parameters adaptively. Specifically, BNTA quickly explores the domain-aware information within unlabeled target data before inference, and accordingly modulates the feature distribution normalized by BN to adapt to the target domain. This is accomplished by two designed self-supervised auxiliary tasks, namely part positioning and part nearest neighbor matching, which help the model mine the domain-aware information with respect to the structure and identity of body parts, respectively. To demonstrate the effectiveness of our method, we conduct extensive experiments on three re-id datasets and confirm the superior performance to the state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2203.00672v1", "pdf_url": "http://arxiv.org/pdf/2203.00672v1", "repo_url": null}, "2203.00667": {"publish_time": "2022-03-01", "title": "Generative Adversarial Networks", "author": "Gilad Cohen et.al.", "abstract": "Generative Adversarial Networks (GANs) are very popular frameworks for generating high-quality data, and are immensely used in both the academia and industry in many domains. Arguably, their most substantial impact has been in the area of computer vision, where they achieve state-of-the-art image generation. This chapter gives an introduction to GANs, by discussing their principle mechanism and presenting some of their inherent problems during training and evaluation. We focus on these three issues: (1) mode collapse, (2) vanishing gradients, and (3) generation of low-quality images. We then list some architecture-variant and loss-variant GANs that remedy the above challenges. Lastly, we present two utilization examples of GANs for real-world applications: Data augmentation and face images generation.", "paper_url": "http://arxiv.org/abs/2203.00667v1", "pdf_url": "http://arxiv.org/pdf/2203.00667v1", "repo_url": null}, "2203.00645": {"publish_time": "2022-03-01", "title": "Variational Autoencoders Without the Variation", "author": "Gregory A. Daly et.al.", "abstract": "Variational autoencdoers (VAE) are a popular approach to generative modelling. However, exploiting the capabilities of VAEs in practice can be difficult. Recent work on regularised and entropic autoencoders have begun to explore the potential, for generative modelling, of removing the variational approach and returning to the classic deterministic autoencoder (DAE) with additional novel regularisation methods. In this paper we empirically explore the capability of DAEs for image generation without additional novel methods and the effect of the implicit regularisation and smoothness of large networks. We find that DAEs can be used successfully for image generation without additional loss terms, and that many of the useful properties of VAEs can arise implicitly from sufficiently large convolutional encoders and decoders when trained on CIFAR-10 and CelebA.", "paper_url": "http://arxiv.org/abs/2203.00645v1", "pdf_url": "http://arxiv.org/pdf/2203.00645v1", "repo_url": null}, "2203.00641": {"publish_time": "2022-03-01", "title": "Multi-Task Multi-Scale Learning For Outcome Prediction in 3D PET Images", "author": "Amine Amyar et.al.", "abstract": "Background and Objectives: Predicting patient response to treatment and survival in oncology is a prominent way towards precision medicine. To that end, radiomics was proposed as a field of study where images are used instead of invasive methods. The first step in radiomic analysis is the segmentation of the lesion. However, this task is time consuming and can be physician subjective. Automated tools based on supervised deep learning have made great progress to assist physicians. However, they are data hungry, and annotated data remains a major issue in the medical field where only a small subset of annotated images is available. Methods: In this work, we propose a multi-task learning framework to predict patient's survival and response. We show that the encoder can leverage multiple tasks to extract meaningful and powerful features that improve radiomics performance. We show also that subsidiary tasks serve as an inductive bias so that the model can better generalize. Results: Our model was tested and validated for treatment response and survival in lung and esophageal cancers, with an area under the ROC curve of 77% and 71% respectively, outperforming single task learning methods. Conclusions: We show that, by using a multi-task learning approach, we can boost the performance of radiomic analysis by extracting rich information of intratumoral and peritumoral regions.", "paper_url": "http://arxiv.org/abs/2203.00641v1", "pdf_url": "http://arxiv.org/pdf/2203.00641v1", "repo_url": null}, "2203.01318": {"publish_time": "2022-03-02", "title": "Protecting Celebrities with Identity Consistency Transformer", "author": "Xiaoyi Dong et.al.", "abstract": "In this work we propose Identity Consistency Transformer, a novel face forgery detection method that focuses on high-level semantics, specifically identity information, and detecting a suspect face by finding identity inconsistency in inner and outer face regions. The Identity Consistency Transformer incorporates a consistency loss for identity consistency determination. We show that Identity Consistency Transformer exhibits superior generalization ability not only across different datasets but also across various types of image degradation forms found in real-world applications including deepfake videos. The Identity Consistency Transformer can be easily enhanced with additional identity information when such information is available, and for this reason it is especially well-suited for detecting face forgeries involving celebrities.", "paper_url": "http://arxiv.org/abs/2203.01318v1", "pdf_url": "http://arxiv.org/pdf/2203.01318v1", "repo_url": null}, "2203.01311": {"publish_time": "2022-03-02", "title": "HighMMT: Towards Modality and Task Generalization for High-Modality Representation Learning", "author": "Paul Pu Liang et.al.", "abstract": "Learning multimodal representations involves discovering correspondences and integrating information from multiple heterogeneous sources of data. While recent research has begun to explore the design of more general-purpose multimodal models (contrary to prior focus on domain and modality-specific architectures), these methods are still largely focused on a small set of modalities in the language, vision, and audio space. In order to accelerate generalization towards diverse and understudied modalities, we investigate methods for high-modality (a large set of diverse modalities) and partially-observable (each task only defined on a small subset of modalities) scenarios. To tackle these challenges, we design a general multimodal model that enables multitask and transfer learning: multitask learning with shared parameters enables stable parameter counts (addressing scalability), and cross-modal transfer learning enables information sharing across modalities and tasks (addressing partial observability). Our resulting model generalizes across text, image, video, audio, time-series, sensors, tables, and set modalities from different research areas, improves the tradeoff between performance and efficiency, transfers to new modalities and tasks, and reveals surprising insights on the nature of information sharing in multitask models. We release our code and benchmarks which we hope will present a unified platform for subsequent theoretical and empirical analysis: https://github.com/pliang279/HighMMT.", "paper_url": "http://arxiv.org/abs/2203.01311v1", "pdf_url": "http://arxiv.org/pdf/2203.01311v1", "repo_url": null}, "2203.01305": {"publish_time": "2022-03-02", "title": "DN-DETR: Accelerate DETR Training by Introducing Query DeNoising", "author": "Feng Li et.al.", "abstract": "We present in this paper a novel denoising training method to speedup DETR (DEtection TRansformer) training and offer a deepened understanding of the slow convergence issue of DETR-like methods. We show that the slow convergence results from the instability of bipartite graph matching which causes inconsistent optimization goals in early training stages. To address this issue, except for the Hungarian loss, our method additionally feeds ground-truth bounding boxes with noises into Transformer decoder and trains the model to reconstruct the original boxes, which effectively reduces the bipartite graph matching difficulty and leads to a faster convergence. Our method is universal and can be easily plugged into any DETR-like methods by adding dozens of lines of code to achieve a remarkable improvement. As a result, our DN-DETR results in a remarkable improvement ($+1.9$AP) under the same setting and achieves the best result (AP $43.4$ and $48.6$ with $12$ and $50$ epochs of training respectively) among DETR-like methods with ResNet-$50$ backbone. Compared with the baseline under the same setting, DN-DETR achieves comparable performance with $50\\%$ training epochs. Code is available at \\url{https://github.com/FengLi-ust/DN-DETR}.", "paper_url": "http://arxiv.org/abs/2203.01305v1", "pdf_url": "http://arxiv.org/pdf/2203.01305v1", "repo_url": null}, "2203.01296": {"publish_time": "2022-03-02", "title": "Half Wavelet Attention on M-Net+ for Low-Light Image Enhancement", "author": "Chi-Mao Fan et.al.", "abstract": "Low-Light Image Enhancement is a computer vision task which intensifies the dark images to appropriate brightness. It can also be seen as an ill-posed problem in image restoration domain. With the success of deep neural networks, the convolutional neural networks surpass the traditional algorithm-based methods and become the mainstream in the computer vision area. To advance the performance of enhancement algorithms, we propose an image enhancement network (HWMNet) based on an improved hierarchical model: M-Net+. Specifically, we use a half wavelet attention block on M-Net+ to enrich the features from wavelet domain. Furthermore, our HWMNet has competitive performance results on two image enhancement datasets in terms of quantitative metrics and visual quality. The source code and pretrained model are available at https://github.com/FanChiMao/HWMNet.", "paper_url": "http://arxiv.org/abs/2203.01296v1", "pdf_url": "http://arxiv.org/pdf/2203.01296v1", "repo_url": "https://github.com/fanchimao/hwmnet"}, "2203.01289": {"publish_time": "2022-03-02", "title": "ADVISE: ADaptive Feature Relevance and VISual Explanations for Convolutional Neural Networks", "author": "Mohammad Mahdi Dehshibi et.al.", "abstract": "To equip Convolutional Neural Networks (CNNs) with explainability, it is essential to interpret how opaque models take specific decisions, understand what causes the errors, improve the architecture design, and identify unethical biases in the classifiers. This paper introduces ADVISE, a new explainability method that quantifies and leverages the relevance of each unit of the feature map to provide better visual explanations. To this end, we propose using adaptive bandwidth kernel density estimation to assign a relevance score to each unit of the feature map with respect to the predicted class. We also propose an evaluation protocol to quantitatively assess the visual explainability of CNN models. We extensively evaluate our idea in the image classification task using AlexNet, VGG16, ResNet50, and Xception pretrained on ImageNet. We compare ADVISE with the state-of-the-art visual explainable methods and show that the proposed method outperforms competing approaches in quantifying feature-relevance and visual explainability while maintaining competitive time complexity. Our experiments further show that ADVISE fulfils the sensitivity and implementation independence axioms while passing the sanity checks. The implementation is accessible for reproducibility purposes on https://github.com/dehshibi/ADVISE.", "paper_url": "http://arxiv.org/abs/2203.01289v1", "pdf_url": "http://arxiv.org/pdf/2203.01289v1", "repo_url": "https://github.com/dehshibi/advise"}}}, "NLP": {"NLP": {"2202.12875": {"publish_time": "2022-02-25", "title": "DataLab: A Platform for Data Analysis and Intervention", "author": "Yang Xiao et.al.", "abstract": "Despite data's crucial role in machine learning, most existing tools and research tend to focus on systems on top of existing data rather than how to interpret and manipulate data. In this paper, we propose DataLab, a unified data-oriented platform that not only allows users to interactively analyze the characteristics of data, but also provides a standardized interface for different data processing operations. Additionally, in view of the ongoing proliferation of datasets, \\toolname has features for dataset recommendation and global vision analysis that help researchers form a better view of the data ecosystem. So far, DataLab covers 1,715 datasets and 3,583 of its transformed version (e.g., hyponyms replacement), where 728 datasets support various analyses (e.g., with respect to gender bias) with the help of 140M samples annotated by 318 feature functions. DataLab is under active development and will be supported going forward. We have released a web platform, web API, Python SDK, PyPI published package and online documentation, which hopefully, can meet the diverse needs of researchers.", "paper_url": "http://arxiv.org/abs/2202.12875v1", "pdf_url": "http://arxiv.org/pdf/2202.12875v1", "repo_url": null}, "2202.12837": {"publish_time": "2022-02-25", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?", "author": "Sewon Min et.al.", "abstract": "Large language models (LMs) are able to in-context learn -- perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. In this paper, we show that ground truth demonstrations are in fact not required -- randomly replacing labels in the demonstrations barely hurts performance, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of end task performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.", "paper_url": "http://arxiv.org/abs/2202.12837v1", "pdf_url": "http://arxiv.org/pdf/2202.12837v1", "repo_url": null}, "2202.12832": {"publish_time": "2022-02-25", "title": "Morphology Without Borders: Clause-Level Morphological Annotation", "author": "Omer Goldman et.al.", "abstract": "Morphological tasks use large multi-lingual datasets that organize words into inflection tables, which then serve as training and evaluation data for various tasks. However, a closer inspection of these data reveals profound cross-linguistic inconsistencies, that arise from the lack of a clear linguistic and operational definition of what is a word, and that severely impair the universality of the derived tasks. To overcome this deficiency, we propose to view morphology as a clause-level phenomenon, rather than word-level. It is anchored in a fixed yet inclusive set of features homogeneous across languages, that encapsulates all functions realized in a saturated clause. We deliver MightyMorph, a novel dataset for clause-level morphology covering 4 typologically-different languages: English, German, Turkish and Hebrew. We use this dataset to derive 3 clause-level morphological tasks: inflection, reinflection and analysis. Our experiments show that the clause-level tasks are substantially harder than the respective word-level tasks, while having comparable complexity across languages. Furthermore, redefining morphology to the clause-level provides a neat interface with contextualized language models (LMs) and can be used to probe LMs capacity to encode complex morphology. Taken together, this work opens up new horizons in the study of computational morphology, leaving ample space for studying neural morphological modeling cross-linguistically.", "paper_url": "http://arxiv.org/abs/2202.12832v1", "pdf_url": "http://arxiv.org/pdf/2202.12832v1", "repo_url": null}, "2202.12814": {"publish_time": "2022-02-25", "title": "The Reality of Multi-Lingual Machine Translation", "author": "Tom Kocmi et.al.", "abstract": "Our book \"The Reality of Multi-Lingual Machine Translation\" discusses the benefits and perils of using more than two languages in machine translation systems. While focused on the particular task of sequence-to-sequence processing and multi-task learning, the book targets somewhat beyond the area of natural language processing. Machine translation is for us a prime example of deep learning applications where human skills and learning capabilities are taken as a benchmark that many try to match and surpass. We document that some of the gains observed in multi-lingual translation may result from simpler effects than the assumed cross-lingual transfer of knowledge.   In the first, rather general part, the book will lead you through the motivation for multi-linguality, the versatility of deep neural networks especially in sequence-to-sequence tasks to complications of this learning. We conclude the general part with warnings against too optimistic and unjustified explanations of the gains that neural networks demonstrate.   In the second part, we fully delve into multi-lingual models, with a particularly careful examination of transfer learning as one of the more straightforward approaches utilizing additional languages. The recent multi-lingual techniques, including massive models, are surveyed and practical aspects of deploying systems for many languages are discussed. The conclusion highlights the open problem of machine understanding and reminds of two ethical aspects of building large-scale models: the inclusivity of research and its ecological trace.", "paper_url": "http://arxiv.org/abs/2202.12814v1", "pdf_url": "http://arxiv.org/pdf/2202.12814v1", "repo_url": null}, "2202.12801": {"publish_time": "2022-02-25", "title": "On the data requirements of probing", "author": "Zining Zhu et.al.", "abstract": "As large and powerful neural language models are developed, researchers have been increasingly interested in developing diagnostic tools to probe them. There are many papers with conclusions of the form \"observation X is found in model Y\", using their own datasets with varying sizes. Larger probing datasets bring more reliability, but are also expensive to collect. There is yet to be a quantitative method for estimating reasonable probing dataset sizes. We tackle this omission in the context of comparing two probing configurations: after we have collected a small dataset from a pilot study, how many additional data samples are sufficient to distinguish two different configurations? We present a novel method to estimate the required number of data samples in such experiments and, across several case studies, we verify that our estimations have sufficient statistical power. Our framework helps to systematically construct probing datasets to diagnose neural NLP models.", "paper_url": "http://arxiv.org/abs/2202.12801v1", "pdf_url": "http://arxiv.org/pdf/2202.12801v1", "repo_url": null}, "2202.14035": {"publish_time": "2022-02-28", "title": "ParaNames: A Massively Multilingual Entity Name Corpus", "author": "Jonne S\u00e4lev\u00e4 et.al.", "abstract": "This preprint describes work in progress on ParaNames, a multilingual parallel name resource consisting of names for approximately 14 million entities. The included names span over 400 languages, and almost all entities are mapped to standardized entity types (PER/LOC/ORG). Using Wikidata as a source, we create the largest resource of this type to-date. We describe our approach to filtering and standardizing the data to provide the best quality possible. ParaNames is useful for multilingual language processing, both in defining tasks for name translation/transliteration and as supplementary data for tasks such as named entity recognition and linking. Our resource is released on GitHub (https://github.com/bltlab/paranames) under a Creative Commons license (CC BY 4.0).", "paper_url": "http://arxiv.org/abs/2202.14035v1", "pdf_url": "http://arxiv.org/pdf/2202.14035v1", "repo_url": null}, "2202.13972": {"publish_time": "2022-02-28", "title": "The impact of lexical and grammatical processing on generating code from natural language", "author": "Nathana\u00ebl Beau et.al.", "abstract": "Considering the seq2seq architecture of TranX for natural language to code translation, we identify four key components of importance: grammatical constraints, lexical preprocessing, input representations, and copy mechanisms. To study the impact of these components, we use a state-of-the-art architecture that relies on BERT encoder and a grammar-based decoder for which a formalization is provided. The paper highlights the importance of the lexical substitution component in the current natural language to code systems.", "paper_url": "http://arxiv.org/abs/2202.13972v1", "pdf_url": "http://arxiv.org/pdf/2202.13972v1", "repo_url": null}, "2202.13914": {"publish_time": "2022-02-28", "title": "Combining Modular Skills in Multitask Learning", "author": "Edoardo M. Ponti et.al.", "abstract": "A modular design encourages neural models to disentangle and recombine different facets of knowledge to generalise more systematically to new tasks. In this work, we assume that each task is associated with a subset of latent discrete skills from a (potentially small) inventory. In turn, skills correspond to parameter-efficient (sparse / low-rank) model parameterisations. By jointly learning these and a task-skill allocation matrix, the network for each task is instantiated as the average of the parameters of active skills. To favour non-trivial soft partitions of skills across tasks, we experiment with a series of inductive biases, such as an Indian Buffet Process prior and a two-speed learning rate. We evaluate our latent-skill model on two main settings: 1) multitask reinforcement learning for grounded instruction following on 8 levels of the BabyAI platform; and 2) few-shot adaptation of pre-trained text-to-text generative models on CrossFit, a benchmark comprising 160 NLP tasks. We find that the modular design of a network significantly increases sample efficiency in reinforcement learning and few-shot generalisation in supervised learning, compared to baselines with fully shared, task-specific, or conditionally generated parameters where knowledge is entangled across tasks. In addition, we show how discrete skills help interpretability, as they yield an explicit hierarchy of tasks.", "paper_url": "http://arxiv.org/abs/2202.13914v1", "pdf_url": "http://arxiv.org/pdf/2202.13914v1", "repo_url": null}, "2202.13887": {"publish_time": "2022-02-28", "title": "Probing the Robustness of Trained Metrics for Conversational Dialogue Systems", "author": "Jan Deriu et.al.", "abstract": "This paper introduces an adversarial method to stress-test trained metrics to evaluate conversational dialogue systems. The method leverages Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics. We apply our method to test recently proposed trained metrics. We find that they all are susceptible to giving high scores to responses generated by relatively simple and obviously flawed strategies that our method converges on. For instance, simply copying parts of the conversation context to form a response yields competitive scores or even outperforms responses written by humans.", "paper_url": "http://arxiv.org/abs/2202.13887v1", "pdf_url": "http://arxiv.org/pdf/2202.13887v1", "repo_url": null}, "2202.13876": {"publish_time": "2022-02-28", "title": "PMC-Patients: A Large-scale Dataset of Patient Notes and Relations Extracted from Case Reports in PubMed Central", "author": "Zhengyun Zhao et.al.", "abstract": "We present PMC-Patients, a dataset consisting of 167k patient notes with 3.1M relevant article annotations and 293k similar patient annotations. The patient notes are extracted by identifying certain sections from case reports in PubMed Central, and those with at least CC BY-NC-SA license are re-distributed. Patient-article relevance and patient-patient similarity are defined by citation relationships in PubMed. We also perform four tasks with PMC-Patients to demonstrate its utility, including Patient Note Recognition (PNR), Patient-Patient Similarity (PPS), Patient-Patient Retrieval (PPR), and Patient-Article Retrieval (PAR). In summary, PMC-Patients provides the largest-scale patient notes with high quality, diverse conditions, easy access, and rich annotations.", "paper_url": "http://arxiv.org/abs/2202.13876v1", "pdf_url": "http://arxiv.org/pdf/2202.13876v1", "repo_url": "https://github.com/zhao-zy15/pmc-patients"}, "2203.00674": {"publish_time": "2022-03-01", "title": "Advancing an Interdisciplinary Science of Conversation: Insights from a Large Multimodal Corpus of Human Speech", "author": "Andrew Reece et.al.", "abstract": "People spend a substantial portion of their lives engaged in conversation, and yet our scientific understanding of conversation is still in its infancy. In this report we advance an interdisciplinary science of conversation, with findings from a large, novel, multimodal corpus of 1,656 recorded conversations in spoken English. This 7+ million word, 850 hour corpus totals over 1TB of audio, video, and transcripts, with moment-to-moment measures of vocal, facial, and semantic expression, along with an extensive survey of speaker post conversation reflections. We leverage the considerable scope of the corpus to (1) extend key findings from the literature, such as the cooperativeness of human turn-taking; (2) define novel algorithmic procedures for the segmentation of speech into conversational turns; (3) apply machine learning insights across various textual, auditory, and visual features to analyze what makes conversations succeed or fail; and (4) explore how conversations are related to well-being across the lifespan. We also report (5) a comprehensive mixed-method report, based on quantitative analysis and qualitative review of each recording, that showcases how individuals from diverse backgrounds alter their communication patterns and find ways to connect. We conclude with a discussion of how this large-scale public dataset may offer new directions for future research, especially across disciplinary boundaries, as scholars from a variety of fields appear increasingly interested in the study of conversation.", "paper_url": "http://arxiv.org/abs/2203.00674v1", "pdf_url": "http://arxiv.org/pdf/2203.00674v1", "repo_url": null}, "2203.00648": {"publish_time": "2022-03-01", "title": "Measuring the Impact of Individual Domain Factors in Self-Supervised Pre-Training", "author": "Ramon Sanabria et.al.", "abstract": "Human speech data comprises a rich set of domain factors such as accent, syntactic and semantic variety, or acoustic environment. Previous work explores the effect of domain mismatch in automatic speech recognition between pre-training and fine-tuning as a whole but does not dissect the contribution of individual factors. In this paper, we present a controlled study to better understand the effect of such factors on the performance of pre-trained representations. To do so, we pre-train models either on modified natural speech or synthesized audio, with a single domain factor modified, and then measure performance on automatic speech recognition after fine tuning. Results show that phonetic domain factors play an important role during pre-training while grammatical and syntactic factors are far less important. To our knowledge, this is the first study to better understand the domain characteristics in self-supervised pre-training for speech.", "paper_url": "http://arxiv.org/abs/2203.00648v1", "pdf_url": "http://arxiv.org/pdf/2203.00648v1", "repo_url": null}, "2203.00633": {"publish_time": "2022-03-01", "title": "Transformer Grammars: Augmenting Transformer Language Models with Syntactic Inductive Biases at Scale", "author": "Laurent Sartran et.al.", "abstract": "Transformer language models that are trained on vast amounts of data have achieved remarkable success at various NLP benchmarks. Intriguingly, this success is achieved by models that lack an explicit modeling of hierarchical syntactic structures, which were hypothesized by decades of linguistic research to be necessary for good generalization. This naturally leaves a question: to what extent can we further improve the performance of Transformer language models, through an inductive bias that encourages the model to explain the data through the lens of recursive syntactic compositions? Although the benefits of modeling recursive syntax have been shown at the small data and model scales, it remains an open question whether -- and to what extent -- a similar design principle is still beneficial in the case of powerful Transformer language models that work well at scale. To answer these questions, we introduce Transformer Grammars -- a novel class of Transformer language models that combine: (i) the expressive power, scalability, and strong performance of Transformers, and (ii) recursive syntactic compositions, which here are implemented through a special attention mask. We find that Transformer Grammars outperform various strong baselines on multiple syntax-sensitive language modeling evaluation metrics, in addition to sentence-level language modeling perplexity. Nevertheless, we find that the recursive syntactic composition bottleneck harms perplexity on document-level modeling, providing evidence that a different kind of memory mechanism -- that works independently of syntactic structures -- plays an important role in the processing of long-form text.", "paper_url": "http://arxiv.org/abs/2203.00633v1", "pdf_url": "http://arxiv.org/pdf/2203.00633v1", "repo_url": null}, "2203.00613": {"publish_time": "2022-03-01", "title": "Towards a Common Speech Analysis Engine", "author": "Hagai Aronowitz et.al.", "abstract": "Recent innovations in self-supervised representation learning have led to remarkable advances in natural language processing. That said, in the speech processing domain, self-supervised representation learning-based systems are not yet considered state-of-the-art. We propose leveraging recent advances in self-supervised-based speech processing to create a common speech analysis engine. Such an engine should be able to handle multiple speech processing tasks, using a single architecture, to obtain state-of-the-art accuracy. The engine must also enable support for new tasks with small training datasets. Beyond that, a common engine should be capable of supporting distributed training with client in-house private data. We present the architecture for a common speech analysis engine based on the HuBERT self-supervised speech representation. Based on experiments, we report our results for language identification and emotion recognition on the standard evaluations NIST-LRE 07 and IEMOCAP. Our results surpass the state-of-the-art performance reported so far on these tasks. We also analyzed our engine on the emotion recognition task using reduced amounts of training data and show how to achieve improved results.", "paper_url": "http://arxiv.org/abs/2203.00613v1", "pdf_url": "http://arxiv.org/pdf/2203.00613v1", "repo_url": null}, "2203.00588": {"publish_time": "2022-03-01", "title": "Structural invariants and semantic fingerprints in the \"ego network\" of words", "author": "Kilian Ollivier et.al.", "abstract": "Well-established cognitive models coming from anthropology have shown that, due to the cognitive constraints that limit our \"bandwidth\" for social interactions, humans organize their social relations according to a regular structure. In this work, we postulate that similar regularities can be found in other cognitive processes, such as those involving language production. In order to investigate this claim, we analyse a dataset containing tweets of a heterogeneous group of Twitter users (regular users and professional writers). Leveraging a methodology similar to the one used to uncover the well-established social cognitive constraints, we find regularities at both the structural and semantic level. At the former, we find that a concentric layered structure (which we call ego network of words, in analogy to the ego network of social relationships) very well captures how individuals organise the words they use. The size of the layers in this structure regularly grows (approximately 2-3 times with respect to the previous one) when moving outwards, and the two penultimate external layers consistently account for approximately 60% and 30% of the used words, irrespective of the number of the total number of layers of the user. For the semantic analysis, each ring of each ego network is described by a semantic profile, which captures the topics associated with the words in the ring. We find that ring #1 has a special role in the model. It is semantically the most dissimilar and the most diverse among the rings. We also show that the topics that are important in the innermost ring also have the characteristic of being predominant in each of the other rings, as well as in the entire ego network. In this respect, ring #1 can be seen as the semantic fingerprint of the ego network of words.", "paper_url": "http://arxiv.org/abs/2203.00588v1", "pdf_url": "http://arxiv.org/pdf/2203.00588v1", "repo_url": null}, "2203.01311": {"publish_time": "2022-03-02", "title": "HighMMT: Towards Modality and Task Generalization for High-Modality Representation Learning", "author": "Paul Pu Liang et.al.", "abstract": "Learning multimodal representations involves discovering correspondences and integrating information from multiple heterogeneous sources of data. While recent research has begun to explore the design of more general-purpose multimodal models (contrary to prior focus on domain and modality-specific architectures), these methods are still largely focused on a small set of modalities in the language, vision, and audio space. In order to accelerate generalization towards diverse and understudied modalities, we investigate methods for high-modality (a large set of diverse modalities) and partially-observable (each task only defined on a small subset of modalities) scenarios. To tackle these challenges, we design a general multimodal model that enables multitask and transfer learning: multitask learning with shared parameters enables stable parameter counts (addressing scalability), and cross-modal transfer learning enables information sharing across modalities and tasks (addressing partial observability). Our resulting model generalizes across text, image, video, audio, time-series, sensors, tables, and set modalities from different research areas, improves the tradeoff between performance and efficiency, transfers to new modalities and tasks, and reveals surprising insights on the nature of information sharing in multitask models. We release our code and benchmarks which we hope will present a unified platform for subsequent theoretical and empirical analysis: https://github.com/pliang279/HighMMT.", "paper_url": "http://arxiv.org/abs/2203.01311v1", "pdf_url": "http://arxiv.org/pdf/2203.01311v1", "repo_url": null}, "2203.01294": {"publish_time": "2022-03-02", "title": "Providing Insights for Open-Response Surveys via End-to-End Context-Aware Clustering", "author": "Soheil Esmaeilzadeh et.al.", "abstract": "Teachers often conduct surveys in order to collect data from a predefined group of students to gain insights into topics of interest. When analyzing surveys with open-ended textual responses, it is extremely time-consuming, labor-intensive, and difficult to manually process all the responses into an insightful and comprehensive report. In the analysis step, traditionally, the teacher has to read each of the responses and decide on how to group them in order to extract insightful information. Even though it is possible to group the responses only using certain keywords, such an approach would be limited since it not only fails to account for embedded contexts but also cannot detect polysemous words or phrases and semantics that are not expressible in single words. In this work, we present a novel end-to-end context-aware framework that extracts, aggregates, and abbreviates embedded semantic patterns in open-response survey data. Our framework relies on a pre-trained natural language model in order to encode the textual data into semantic vectors. The encoded vectors then get clustered either into an optimally tuned number of groups or into a set of groups with pre-specified titles. In the former case, the clusters are then further analyzed to extract a representative set of keywords or summary sentences that serve as the labels of the clusters. In our framework, for the designated clusters, we finally provide context-aware wordclouds that demonstrate the semantically prominent keywords within each group. Honoring user privacy, we have successfully built the on-device implementation of our framework suitable for real-time analysis on mobile devices and have tested it on a synthetic dataset. Our framework reduces the costs at-scale by automating the process of extracting the most insightful information pieces from survey data.", "paper_url": "http://arxiv.org/abs/2203.01294v1", "pdf_url": "http://arxiv.org/pdf/2203.01294v1", "repo_url": null}, "2203.01282": {"publish_time": "2022-03-02", "title": "$\\texttt{py-irt}$: A Scalable Item Response Theory Library for Python", "author": "John P. Lalor et.al.", "abstract": "$\\texttt{py-irt}$ is a Python library for fitting Bayesian Item Response Theory (IRT) models. $\\texttt{py-irt}$ estimates latent traits of subjects and items, making it appropriate for use in IRT tasks as well as ideal-point models. $\\texttt{py-irt}$ is built on top of the Pyro and PyTorch frameworks and uses GPU-accelerated training to scale to large data sets. Code, documentation, and examples can be found at https://github.com/nd-ball/py-irt. $\\texttt{py-irt}$ can be installed from the GitHub page or the Python Package Index (PyPI).", "paper_url": "http://arxiv.org/abs/2203.01282v1", "pdf_url": "http://arxiv.org/pdf/2203.01282v1", "repo_url": "https://github.com/nd-ball/py-irt"}, "2203.01215": {"publish_time": "2022-03-02", "title": "Mukayese: Turkish NLP Strikes Back", "author": "Ali Safaya et.al.", "abstract": "Having sufficient resources for language X lifts it from the under-resourced languages class, but not necessarily from the under-researched class. In this paper, we address the problem of the absence of organized benchmarks in the Turkish language. We demonstrate that languages such as Turkish are left behind the state-of-the-art in NLP applications. As a solution, we present Mukayese, a set of NLP benchmarks for the Turkish language that contains several NLP tasks. We work on one or more datasets for each benchmark and present two or more baselines. Moreover, we present four new benchmarking datasets in Turkish for language modeling, sentence segmentation, and spell checking. All datasets and baselines are available under: https://github.com/alisafaya/mukayese", "paper_url": "http://arxiv.org/abs/2203.01215v1", "pdf_url": "http://arxiv.org/pdf/2203.01215v1", "repo_url": "https://github.com/alisafaya/mukayese"}, "2203.01111": {"publish_time": "2022-03-02", "title": "Large-Scale Hate Speech Detection with Cross-Domain Transfer", "author": "Cagri Toraman et.al.", "abstract": "The performance of hate speech detection models relies on the datasets on which the models are trained. Existing datasets are mostly prepared with a limited number of instances or hate domains that define hate topics. This hinders large-scale analysis and transfer learning with respect to hate domains. In this study, we construct large-scale tweet datasets for hate speech detection in English and a low-resource language, Turkish, consisting of human-labeled 100k tweets per each. Our datasets are designed to have equal number of tweets distributed over five domains. The experimental results supported by statistical tests show that Transformer-based language models outperform conventional bag-of-words and neural models by at least 5% in English and 10% in Turkish for large-scale hate speech detection. The performance is also scalable to different training sizes, such that 98% of performance in English, and 97% in Turkish, are recovered when 20% of training instances are used. We further examine the generalization ability of cross-domain transfer among hate domains. We show that 96% of the performance of a target domain in average is recovered by other domains for English, and 92% for Turkish. Gender and religion are more successful to generalize to other domains, while sports fail most.", "paper_url": "http://arxiv.org/abs/2203.01111v1", "pdf_url": "http://arxiv.org/pdf/2203.01111v1", "repo_url": "https://github.com/avaapm/hatespeech"}}}, "Reinforcement Learning": {"Reinforcement Learning": {"2202.12884": {"publish_time": "2022-02-25", "title": "Learning to Identify Perceptual Bugs in 3D Video Games", "author": "Benedict Wilkins et.al.", "abstract": "Automated Bug Detection (ABD) in video games is composed of two distinct but complementary problems: automated game exploration and bug identification. Automated game exploration has received much recent attention, spurred on by developments in fields such as reinforcement learning. The complementary problem of identifying the bugs present in a player's experience has for the most part relied on the manual specification of rules. Although it is widely recognised that many bugs of interest cannot be identified with such methods, little progress has been made in this direction. In this work we show that it is possible to identify a range of perceptual bugs using learning-based methods by making use of only the rendered game screen as seen by the player. To support our work, we have developed World of Bugs (WOB) an open platform for testing ABD methods in 3D game environments.", "paper_url": "http://arxiv.org/abs/2202.12884v1", "pdf_url": "http://arxiv.org/pdf/2202.12884v1", "repo_url": null}, "2202.12872": {"publish_time": "2022-02-25", "title": "AutoFR: Automated Filter Rule Generation for Adblocking", "author": "Hieu Le et.al.", "abstract": "Adblocking relies on filter lists, which are manually curated and maintained by a small community of filter list authors. This manual process is laborious and does not scale well to a large number of sites and over time. We introduce AutoFR, a reinforcement learning framework to fully automate the process of filter rule creation and evaluation. We design an algorithm based on multi-arm bandits to generate filter rules while controlling the trade-off between blocking ads and avoiding breakage. We test our implementation of AutoFR on thousands of sites in terms of efficiency and effectiveness. AutoFR is efficient: it takes only a few minutes to generate filter rules for a site. AutoFR is also effective: it generates filter rules that can block 86% of the ads, as compared to 87% by EasyList while achieving comparable visual breakage. The filter rules generated by AutoFR generalize well to new and unseen sites. We envision AutoFR to assist the adblocking community in automated filter rule generation at scale.", "paper_url": "http://arxiv.org/abs/2202.12872v1", "pdf_url": "http://arxiv.org/pdf/2202.12872v1", "repo_url": null}, "2202.12866": {"publish_time": "2022-02-25", "title": "Learning to Schedule Heuristics for the Simultaneous Stochastic Optimization of Mining Complexes", "author": "Yassine Yaakoubi et.al.", "abstract": "The simultaneous stochastic optimization of mining complexes (SSOMC) is a large-scale stochastic combinatorial optimization problem that simultaneously manages the extraction of materials from multiple mines and their processing using interconnected facilities to generate a set of final products, while taking into account material supply (geological) uncertainty to manage the associated risk. Although simulated annealing has been shown to outperform comparing methods for solving the SSOMC, early performance might dominate recent performance in that a combination of the heuristics' performance is used to determine which perturbations to apply. This work proposes a data-driven framework for heuristic scheduling in a fully self-managed hyper-heuristic to solve the SSOMC. The proposed learn-to-perturb (L2P) hyper-heuristic is a multi-neighborhood simulated annealing algorithm. The L2P selects the heuristic (perturbation) to be applied in a self-adaptive manner using reinforcement learning to efficiently explore which local search is best suited for a particular search point. Several state-of-the-art agents have been incorporated into L2P to better adapt the search and guide it towards better solutions. By learning from data describing the performance of the heuristics, a problem-specific ordering of heuristics that collectively finds better solutions faster is obtained. L2P is tested on several real-world mining complexes, with an emphasis on efficiency, robustness, and generalization capacity. Results show a reduction in the number of iterations by 30-50% and in the computational time by 30-45%.", "paper_url": "http://arxiv.org/abs/2202.12866v1", "pdf_url": "http://arxiv.org/pdf/2202.12866v1", "repo_url": null}, "2202.12861": {"publish_time": "2022-02-25", "title": "Hierarchical Control for Multi-Agent Autonomous Racing", "author": "Rishabh Saumil Thakkar et.al.", "abstract": "We develop a hierarchical controller for multi-agent autonomous racing. A high-level planner approximates the race as a discrete game with simplified dynamics that encodes the complex safety and fairness rules seen in real-life racing and calculates a series of target waypoints. The low-level controller takes the resulting waypoints as a reference trajectory and computes high-resolution control inputs by solving a simplified formulation of a multi-agent racing game. We consider two approaches for the low-level planner to construct two hierarchical controllers. One approach uses multi-agent reinforcement learning (MARL), and the other solves a linear-quadratic Nash game (LQNG) to produce control inputs. We test the controllers against three baselines: an end-to-end MARL controller, a MARL controller tracking a fixed racing line, and an LQNG controller tracking a fixed racing line. Quantitative results show that the proposed hierarchical methods outperform their respective baseline methods in terms of head-to-head race wins and abiding by the rules. The hierarchical controller using MARL for low-level control consistently outperformed all other methods by winning over 88\\% of head-to-head races and more consistently adhered to the complex racing rules. Qualitatively, we observe the proposed controllers mimicking actions performed by expert human drivers such as shielding/blocking, overtaking, and long-term planning for delayed advantages. We show that hierarchical planning for game-theoretic reasoning produces competitive behavior even when challenged with complex rules and constraints.", "paper_url": "http://arxiv.org/abs/2202.12861v1", "pdf_url": "http://arxiv.org/pdf/2202.12861v1", "repo_url": "https://github.com/ribsthakkar/HierarchicalKarting"}, "2202.12847": {"publish_time": "2022-02-25", "title": "Building a 3-Player Mahjong AI using Deep Reinforcement Learning", "author": "Xiangyu Zhao et.al.", "abstract": "Mahjong is a popular multi-player imperfect-information game developed in China in the late 19th-century, with some very challenging features for AI research. Sanma, being a 3-player variant of the Japanese Riichi Mahjong, possesses unique characteristics including fewer tiles and, consequently, a more aggressive playing style. It is thus challenging and of great research interest in its own right, but has not yet been explored. In this paper, we present Meowjong, an AI for Sanma using deep reinforcement learning. We define an informative and compact 2-dimensional data structure for encoding the observable information in a Sanma game. We pre-train 5 convolutional neural networks (CNNs) for Sanma's 5 actions -- discard, Pon, Kan, Kita and Riichi, and enhance the major action's model, namely the discard model, via self-play reinforcement learning using the Monte Carlo policy gradient method. Meowjong's models achieve test accuracies comparable with AIs for 4-player Mahjong through supervised learning, and gain a significant further enhancement from reinforcement learning. Being the first ever AI in Sanma, we claim that Meowjong stands as a state-of-the-art in this game.", "paper_url": "http://arxiv.org/abs/2202.12847v1", "pdf_url": "http://arxiv.org/pdf/2202.12847v1", "repo_url": null}, "2202.13914": {"publish_time": "2022-02-28", "title": "Combining Modular Skills in Multitask Learning", "author": "Edoardo M. Ponti et.al.", "abstract": "A modular design encourages neural models to disentangle and recombine different facets of knowledge to generalise more systematically to new tasks. In this work, we assume that each task is associated with a subset of latent discrete skills from a (potentially small) inventory. In turn, skills correspond to parameter-efficient (sparse / low-rank) model parameterisations. By jointly learning these and a task-skill allocation matrix, the network for each task is instantiated as the average of the parameters of active skills. To favour non-trivial soft partitions of skills across tasks, we experiment with a series of inductive biases, such as an Indian Buffet Process prior and a two-speed learning rate. We evaluate our latent-skill model on two main settings: 1) multitask reinforcement learning for grounded instruction following on 8 levels of the BabyAI platform; and 2) few-shot adaptation of pre-trained text-to-text generative models on CrossFit, a benchmark comprising 160 NLP tasks. We find that the modular design of a network significantly increases sample efficiency in reinforcement learning and few-shot generalisation in supervised learning, compared to baselines with fully shared, task-specific, or conditionally generated parameters where knowledge is entangled across tasks. In addition, we show how discrete skills help interpretability, as they yield an explicit hierarchy of tasks.", "paper_url": "http://arxiv.org/abs/2202.13914v1", "pdf_url": "http://arxiv.org/pdf/2202.13914v1", "repo_url": null}, "2202.13890": {"publish_time": "2022-02-28", "title": "Pessimistic Q-Learning for Offline Reinforcement Learning: Towards Optimal Sample Complexity", "author": "Laixi Shi et.al.", "abstract": "Offline or batch reinforcement learning seeks to learn a near-optimal policy using history data without active exploration of the environment. To counter the insufficient coverage and sample scarcity of many offline datasets, the principle of pessimism has been recently introduced to mitigate high bias of the estimated values. While pessimistic variants of model-based algorithms (e.g., value iteration with lower confidence bounds) have been theoretically investigated, their model-free counterparts -- which do not require explicit model estimation -- have not been adequately studied, especially in terms of sample efficiency. To address this inadequacy, we study a pessimistic variant of Q-learning in the context of finite-horizon Markov decision processes, and characterize its sample complexity under the single-policy concentrability assumption which does not require the full coverage of the state-action space. In addition, a variance-reduced pessimistic Q-learning algorithm is proposed to achieve near-optimal sample complexity. Altogether, this work highlights the efficiency of model-free algorithms in offline RL when used in conjunction with pessimism and variance reduction.", "paper_url": "http://arxiv.org/abs/2202.13890v1", "pdf_url": "http://arxiv.org/pdf/2202.13890v1", "repo_url": null}, "2202.13887": {"publish_time": "2022-02-28", "title": "Probing the Robustness of Trained Metrics for Conversational Dialogue Systems", "author": "Jan Deriu et.al.", "abstract": "This paper introduces an adversarial method to stress-test trained metrics to evaluate conversational dialogue systems. The method leverages Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics. We apply our method to test recently proposed trained metrics. We find that they all are susceptible to giving high scores to responses generated by relatively simple and obviously flawed strategies that our method converges on. For instance, simply copying parts of the conversation context to form a response yields competitive scores or even outperforms responses written by humans.", "paper_url": "http://arxiv.org/abs/2202.13887v1", "pdf_url": "http://arxiv.org/pdf/2202.13887v1", "repo_url": null}, "2202.13863": {"publish_time": "2022-02-28", "title": "Provably Efficient Convergence of Primal-Dual Actor-Critic with Nonlinear Function Approximation", "author": "Jing Dong et.al.", "abstract": "We study the convergence of the actor-critic algorithm with nonlinear function approximation under a nonconvex-nonconcave primal-dual formulation. Stochastic gradient descent ascent is applied with an adaptive proximal term for robust learning rates. We show the first efficient convergence result with primal-dual actor-critic with a convergence rate of $\\mathcal{O}\\left(\\sqrt{\\frac{\\ln \\left(N d G^2 \\right)}{N}}\\right)$ under Markovian sampling, where $G$ is the element-wise maximum of the gradient, $N$ is the number of iterations, and $d$ is the dimension of the gradient. Our result is presented with only the Polyak-\\L{}ojasiewicz condition for the dual variables, which is easy to verify and applicable to a wide range of reinforcement learning (RL) scenarios. The algorithm and analysis are general enough to be applied to other RL settings, like multi-agent RL. Empirical results on OpenAI Gym continuous control tasks corroborate our theoretical findings.", "paper_url": "http://arxiv.org/abs/2202.13863v1", "pdf_url": "http://arxiv.org/pdf/2202.13863v1", "repo_url": null}, "2202.13706": {"publish_time": "2022-02-28", "title": "Monkey Business: Reinforcement learning meets neighborhood search for Virtual Network Embedding", "author": "Maxime Elkael et.al.", "abstract": "In this article, we consider the Virtual Network Embedding (VNE) problem for 5G networks slicing. This problem requires to allocate multiple Virtual Networks (VN) on a substrate virtualized physical network while maximizing among others, resource utilization, maximum number of placed VNs and network operator's benefit. We solve the online version of the problem where slices arrive over time. Inspired by the Nested Rollout Policy Adaptation (NRPA) algorithm, a variant of the well known Monte Carlo Tree Search (MCTS) that learns how to perform good simulations over time, we propose a new algorithm that we call Neighborhood Enhanced Policy Adaptation (NEPA). The key feature of our algorithm is to observe NRPA cannot exploit knowledge acquired in one branch of the state tree for another one which starts differently. NEPA learns by combining NRPA with Neighbordhood Search in a frugal manner which improves only promising solutions while keeping the running time low. We call this technique a monkey business because it comes down to jumping from one interesting branch to the other, similar to how monkeys jump from tree to tree instead of going down everytime. NEPA achieves better results in terms of acceptance ratio and revenue-to-cost ratio compared to other state-of-the-art algorithms, both on real and synthetic topologies.", "paper_url": "http://arxiv.org/abs/2202.13706v1", "pdf_url": "http://arxiv.org/pdf/2202.13706v1", "repo_url": null}, "2203.00669": {"publish_time": "2022-03-01", "title": "AI Planning Annotation for Sample Efficient Reinforcement Learning", "author": "Junkyu Lee et.al.", "abstract": "AI planning and Reinforcement Learning (RL) both solve sequential decision-making problems under the different formulations. AI Planning requires operator models, but then allows efficient plan generation. RL requires no operator model, instead learns a policy to guide an agent to high reward states. Planning can be brittle in the face of noise whereas RL is more tolerant. However, RL requires a large number of training examples to learn the policy. In this work, we aim to bring AI planning and RL closer by showing that a suitably defined planning model can be used to improve the efficiency of RL. Specifically, we show that the options in the hierarchical RL can be derived from a planning task and integrate planning and RL algorithms for training option policy functions. Our experiments demonstrate an improved sample efficiency on a variety of RL environments over the previous state-of-the-art.", "paper_url": "http://arxiv.org/abs/2203.00669v1", "pdf_url": "http://arxiv.org/pdf/2203.00669v1", "repo_url": null}, "2203.00636": {"publish_time": "2022-03-01", "title": "Distributional Reinforcement Learning for Scheduling of (Bio)chemical Production Processes", "author": "Max Mowbray et.al.", "abstract": "Reinforcement Learning (RL) has recently received significant attention from the process systems engineering and control communities. Recent works have investigated the application of RL to identify optimal scheduling decision in the presence of uncertainty. In this work, we present a RL methodology to address precedence and disjunctive constraints as commonly imposed on production scheduling problems. This work naturally enables the optimization of risk-sensitive formulations such as the conditional value-at-risk (CVaR), which are essential in realistic scheduling processes. The proposed strategy is investigated thoroughly in a single-stage, parallel batch production environment, and benchmarked against mixed integer linear programming (MILP) strategies. We show that the policy identified by our approach is able to account for plant uncertainties in online decision-making, with expected performance comparable to existing MILP methods. Additionally, the framework gains the benefits of optimizing for risk-sensitive measures, and identifies decisions orders of magnitude faster than the most efficient optimization approaches. This promises to mitigate practical issues and ease in handling realizations of process uncertainty in the paradigm of online production scheduling.", "paper_url": "http://arxiv.org/abs/2203.00636v1", "pdf_url": "http://arxiv.org/pdf/2203.00636v1", "repo_url": null}, "2203.00543": {"publish_time": "2022-03-01", "title": "On the Generalization of Representations in Reinforcement Learning", "author": "Charline Le Lan et.al.", "abstract": "In reinforcement learning, state representations are used to tractably deal with large problem spaces. State representations serve both to approximate the value function with few parameters, but also to generalize to newly encountered states. Their features may be learned implicitly (as part of a neural network) or explicitly (for example, the successor representation of \\citet{dayan1993improving}). While the approximation properties of representations are reasonably well-understood, a precise characterization of how and when these representations generalize is lacking. In this work, we address this gap and provide an informative bound on the generalization error arising from a specific state representation. This bound is based on the notion of effective dimension which measures the degree to which knowing the value at one state informs the value at other states. Our bound applies to any state representation and quantifies the natural tension between representations that generalize well and those that approximate well. We complement our theoretical results with an empirical survey of classic representation learning methods from the literature and results on the Arcade Learning Environment, and find that the generalization behaviour of learned representations is well-explained by their effective dimension.", "paper_url": "http://arxiv.org/abs/2203.00543v1", "pdf_url": "http://arxiv.org/pdf/2203.00543v1", "repo_url": null}, "2203.00494": {"publish_time": "2022-03-01", "title": "DreamingV2: Reinforcement Learning with Discrete World Models without Reconstruction", "author": "Masashi Okada et.al.", "abstract": "The present paper proposes a novel reinforcement learning method with world models, DreamingV2, a collaborative extension of DreamerV2 and Dreaming. DreamerV2 is a cutting-edge model-based reinforcement learning from pixels that uses discrete world models to represent latent states with categorical variables. Dreaming is also a form of reinforcement learning from pixels that attempts to avoid the autoencoding process in general world model training by involving a reconstruction-free contrastive learning objective. The proposed DreamingV2 is a novel approach of adopting both the discrete representation of DreamingV2 and the reconstruction-free objective of Dreaming. Compared to DreamerV2 and other recent model-based methods without reconstruction, DreamingV2 achieves the best scores on five simulated challenging 3D robot arm tasks. We believe that DreamingV2 will be a reliable solution for robot learning since its discrete representation is suitable to describe discontinuous environments, and the reconstruction-free fashion well manages complex vision observations.", "paper_url": "http://arxiv.org/abs/2203.00494v1", "pdf_url": "http://arxiv.org/pdf/2203.00494v1", "repo_url": null}, "2203.00397": {"publish_time": "2022-03-01", "title": "A Theory of Abstraction in Reinforcement Learning", "author": "David Abel et.al.", "abstract": "Reinforcement learning defines the problem facing agents that learn to make good decisions through action and observation alone. To be effective problem solvers, such agents must efficiently explore vast worlds, assign credit from delayed feedback, and generalize to new experiences, all while making use of limited data, computational resources, and perceptual bandwidth. Abstraction is essential to all of these endeavors. Through abstraction, agents can form concise models of their environment that support the many practices required of a rational, adaptive decision maker. In this dissertation, I present a theory of abstraction in reinforcement learning. I first offer three desiderata for functions that carry out the process of abstraction: they should 1) preserve representation of near-optimal behavior, 2) be learned and constructed efficiently, and 3) lower planning or learning time. I then present a suite of new algorithms and analysis that clarify how agents can learn to abstract according to these desiderata. Collectively, these results provide a partial path toward the discovery and use of abstraction that minimizes the complexity of effective reinforcement learning.", "paper_url": "http://arxiv.org/abs/2203.00397v1", "pdf_url": "http://arxiv.org/pdf/2203.00397v1", "repo_url": null}, "2203.01302": {"publish_time": "2022-03-02", "title": "Evolving Curricula with Regret-Based Environment Design", "author": "Jack Parker-Holder et.al.", "abstract": "It remains a significant challenge to train generally capable agents with reinforcement learning (RL). A promising avenue for improving the robustness of RL agents is through the use of curricula. One such class of methods frames environment design as a game between a student and a teacher, using regret-based objectives to produce environment instantiations (or levels) at the frontier of the student agent's capabilities. These methods benefit from their generality, with theoretical guarantees at equilibrium, yet they often struggle to find effective levels in challenging design spaces. By contrast, evolutionary approaches seek to incrementally alter environment complexity, resulting in potentially open-ended learning, but often rely on domain-specific heuristics and vast amounts of computational resources. In this paper we propose to harness the power of evolution in a principled, regret-based curriculum. Our approach, which we call Adversarially Compounding Complexity by Editing Levels (ACCEL), seeks to constantly produce levels at the frontier of an agent's capabilities, resulting in curricula that start simple but become increasingly complex. ACCEL maintains the theoretical benefits of prior regret-based methods, while providing significant empirical gains in a diverse set of environments. An interactive version of the paper is available at accelagent.github.io.", "paper_url": "http://arxiv.org/abs/2203.01302v1", "pdf_url": "http://arxiv.org/pdf/2203.01302v1", "repo_url": null}, "2203.01298": {"publish_time": "2022-03-02", "title": "Pareto Frontier Approximation Network (PA-Net) to Solve Bi-objective TSP", "author": "Ishaan Mehta et.al.", "abstract": "Travelling salesperson problem (TSP) is a classic resource allocation problem used to find an optimal order of doing a set of tasks while minimizing (or maximizing) an associated objective function. It is widely used in robotics for applications such as planning, scheduling etc. In this work, we solve TSP for two objectives using reinforcement learning. Often in multi objective optimization problems, the associated objective functions can be conflicting in nature. In such cases, the optimality is defined in terms of Pareto optimality. A set of these Pareto Optimal solutions in the objective space form a Pareto front (or frontier). Each solution has its own trade off. } In this work, we present PA-Net, a network that generates good approximations of the Pareto front for the bi-objective travelling salesperson problem (BTSP). Firstly, BTSP is converted into a constrained optimization problem. We then train our network to solve this constrained problem using the Lagrangian relaxation and policy gradient. With PA-Net we are able to generate good quality Pareto fronts with fast inference times. Finally, we present the application of PA-Net to find optimal visiting order in a robotic navigation task/coverage planning.", "paper_url": "http://arxiv.org/abs/2203.01298v1", "pdf_url": "http://arxiv.org/pdf/2203.01298v1", "repo_url": null}, "2203.01292": {"publish_time": "2022-03-02", "title": "Andes_gym: A Versatile Environment for Deep Reinforcement Learning in Power Systems", "author": "Hantao Cui et.al.", "abstract": "This paper presents Andes_gym, a versatile and high-performance reinforcement learning environment for power system studies. The environment leverages the modeling and simulation capability of ANDES and the reinforcement learning (RL) environment OpenAI Gym to enable the prototyping and demonstration of RL algorithms for power systems. The architecture of the proposed software tool is elaborated to provide the observation and action interfaces for RL algorithms. An example is shown to rapidly prototype a load-frequency control algorithm based on RL trained by available algorithms. The proposed environment is highly generalized by supporting all the power system dynamic models available in ANDES and numerous RL algorithms available for OpenAI Gym.", "paper_url": "http://arxiv.org/abs/2203.01292v1", "pdf_url": "http://arxiv.org/pdf/2203.01292v1", "repo_url": null}, "2203.01190": {"publish_time": "2022-03-02", "title": "Model-free Neural Lyapunov Control for Safe Robot Navigation", "author": "Zikang Xiong et.al.", "abstract": "Model-free Deep Reinforcement Learning (DRL) controllers have demonstrated promising results on various challenging non-linear control tasks. While a model-free DRL algorithm can solve unknown dynamics and high-dimensional problems, it lacks safety assurance. Although safety constraints can be encoded as part of a reward function, there still exists a large gap between an RL controller trained with this modified reward and a safe controller. In contrast, instead of implicitly encoding safety constraints with rewards, we explicitly co-learn a Twin Neural Lyapunov Function (TNLF) with the control policy in the DRL training loop and use the learned TNLF to build a runtime monitor. Combined with the path generated from a planner, the monitor chooses appropriate waypoints that guide the learned controller to provide collision-free control trajectories. Our approach inherits the scalability advantages from DRL while enhancing safety guarantees. Our experimental evaluation demonstrates the effectiveness of our approach compared to DRL with augmented rewards and constrained DRL methods over a range of high-dimensional safety-sensitive navigation tasks.", "paper_url": "http://arxiv.org/abs/2203.01190v1", "pdf_url": "http://arxiv.org/pdf/2203.01190v1", "repo_url": null}, "2203.01148": {"publish_time": "2022-03-02", "title": "Reactive Stepping for Humanoid Robots using Reinforcement Learning: Application to Standing Push Recovery on the Exoskeleton Atalante", "author": "Alexis Duburcq et.al.", "abstract": "State-of-the-art reinforcement learning is now able to learn versatile locomotion, balancing and push-recovery capabilities for bipedal robots in simulation. Yet, the reality gap has mostly been overlooked and the simulated results hardly transfer to real hardware. Either it is unsuccessful in practice because the physics is over-simplified and hardware limitations are ignored, or regularity is not guaranteed and unexpected hazardous motions can occur. This paper presents a reinforcement learning framework capable of learning robust standing push recovery for bipedal robots with a smooth out-of-the-box transfer to reality, requiring only instantaneous proprioceptive observations. By combining original termination conditions and policy smoothness conditioning, we achieve stable learning, sim-to-real transfer and safety using a policy without memory nor observation history. Reward shaping is then used to give insights into how to keep balance. We demonstrate its performance in reality on the lower-limb medical exoskeleton Atalante.", "paper_url": "http://arxiv.org/abs/2203.01148v1", "pdf_url": "http://arxiv.org/pdf/2203.01148v1", "repo_url": null}}}, "Unsupervised Learning": {"Continual Learning": {"2202.11918": {"publish_time": "2022-02-24", "title": "Phase Continuity: Learning Derivatives of Phase Spectrum for Speech Enhancement", "author": "Doyeon Kim et.al.", "abstract": "Modern neural speech enhancement models usually include various forms of phase information in their training loss terms, either explicitly or implicitly. However, these loss terms are typically designed to reduce the distortion of phase spectrum values at specific frequencies, which ensures they do not significantly affect the quality of the enhanced speech. In this paper, we propose an effective phase reconstruction strategy for neural speech enhancement that can operate in noisy environments. Specifically, we introduce a phase continuity loss that considers relative phase variations across the time and frequency axes. By including this phase continuity loss in a state-of-the-art neural speech enhancement system trained with reconstruction loss and a number of magnitude spectral losses, we show that our proposed method further improves the quality of enhanced speech signals over the baseline, especially when training is done jointly with a magnitude spectrum loss.", "paper_url": "http://arxiv.org/abs/2202.11918v1", "pdf_url": "http://arxiv.org/pdf/2202.11918v1", "repo_url": null}, "2202.11295": {"publish_time": "2022-02-23", "title": "Continual learning-based probabilistic slow feature analysis for multimode dynamic process monitoring", "author": "Jingxin Zhang et.al.", "abstract": "In this paper, a novel multimode dynamic process monitoring approach is proposed by extending elastic weight consolidation (EWC) to probabilistic slow feature analysis (PSFA) in order to extract multimode slow features for online monitoring. EWC was originally introduced in the setting of machine learning of sequential multi-tasks with the aim of avoiding catastrophic forgetting issue, which equally poses as a major challenge in multimode dynamic process monitoring. When a new mode arrives, a set of data should be collected so that this mode can be identified by PSFA and prior knowledge. Then, a regularization term is introduced to prevent new data from significantly interfering with the learned knowledge, where the parameter importance measures are estimated. The proposed method is denoted as PSFA-EWC, which is updated continually and capable of achieving excellent performance for successive modes. Different from traditional multimode monitoring algorithms, PSFA-EWC furnishes backward and forward transfer ability. The significant features of previous modes are retained while consolidating new information, which may contribute to learning new relevant modes. Compared with several known methods, the effectiveness of the proposed method is demonstrated via a continuous stirred tank heater and a practical coal pulverizing system.", "paper_url": "http://arxiv.org/abs/2202.11295v1", "pdf_url": "http://arxiv.org/pdf/2202.11295v1", "repo_url": null}, "2202.10821": {"publish_time": "2022-02-22", "title": "Increasing Depth of Neural Networks for Life-long Learning", "author": "J\u0119drzej Kozal et.al.", "abstract": "Increasing neural network depth is a well-known method for improving neural network performance. Modern deep architectures contain multiple mechanisms that allow hundreds or even thousands of layers to train. This work is trying to answer if extending neural network depth may be beneficial in a life-long learning setting. In particular, we propose a novel method based on adding new layers on top of existing ones to enable the forward transfer of knowledge and adapting previously learned representations for new tasks. We utilize a method of determining the most similar tasks for selecting the best location in our network to add new nodes with trainable parameters. This approach allows for creating a tree-like model, where each node is a set of neural network parameters dedicated to a specific task. The proposed method is inspired by Progressive Neural Network (PNN) concept, therefore it is rehearsal-free and benefits from dynamic change of network structure. However, it requires fewer parameters per task than PNN. Experiments on Permuted MNIST and SplitCIFAR show that the proposed algorithm is on par with other continual learning methods. We also perform ablation studies to clarify the contributions of each system part.", "paper_url": "http://arxiv.org/abs/2202.10821v1", "pdf_url": "http://arxiv.org/pdf/2202.10821v1", "repo_url": null}, "2202.10788": {"publish_time": "2022-02-22", "title": "Explicit Regularization via Regularizer Mirror Descent", "author": "Navid Azizan et.al.", "abstract": "Despite perfectly interpolating the training data, deep neural networks (DNNs) can often generalize fairly well, in part due to the \"implicit regularization\" induced by the learning algorithm. Nonetheless, various forms of regularization, such as \"explicit regularization\" (via weight decay), are often used to avoid overfitting, especially when the data is corrupted. There are several challenges with explicit regularization, most notably unclear convergence properties. Inspired by convergence properties of stochastic mirror descent (SMD) algorithms, we propose a new method for training DNNs with regularization, called regularizer mirror descent (RMD). In highly overparameterized DNNs, SMD simultaneously interpolates the training data and minimizes a certain potential function of the weights. RMD starts with a standard cost which is the sum of the training loss and a convex regularizer of the weights. Reinterpreting this cost as the potential of an \"augmented\" overparameterized network and applying SMD yields RMD. As a result, RMD inherits the properties of SMD and provably converges to a point \"close\" to the minimizer of this cost. RMD is computationally comparable to stochastic gradient descent (SGD) and weight decay, and is parallelizable in the same manner. Our experimental results on training sets with various levels of corruption suggest that the generalization performance of RMD is remarkably robust and significantly better than both SGD and weight decay, which implicitly and explicitly regularize the $\\ell_2$ norm of the weights. RMD can also be used to regularize the weights to a desired weight vector, which is particularly relevant for continual learning.", "paper_url": "http://arxiv.org/abs/2202.10788v1", "pdf_url": "http://arxiv.org/pdf/2202.10788v1", "repo_url": null}, "2202.10688": {"publish_time": "2022-02-22", "title": "Graph Lifelong Learning: A Survey", "author": "Falih Gozi Febrinanto et.al.", "abstract": "Graph learning substantially contributes to solving artificial intelligence (AI) tasks in various graph-related domains such as social networks, biological networks, recommender systems, and computer vision. However, despite its unprecedented prevalence, addressing the dynamic evolution of graph data over time remains a challenge. In many real-world applications, graph data continuously evolves. Current graph learning methods that assume graph representation is complete before the training process begins are not applicable in this setting. This challenge in graph learning motivates the development of a continuous learning process called graph lifelong learning to accommodate the future and refine the previous knowledge in graph data. Unlike existing survey papers that focus on either lifelong learning or graph learning separately, this survey paper covers the motivations, potentials, state-of-the-art approaches (that are well categorized), and open issues of graph lifelong learning. We expect extensive research and development interest in this emerging field.", "paper_url": "http://arxiv.org/abs/2202.10688v1", "pdf_url": "http://arxiv.org/pdf/2202.10688v1", "repo_url": null}, "2202.13657": {"publish_time": "2022-02-28", "title": "Avalanche RL: a Continual Reinforcement Learning Library", "author": "Nicol\u00f2 Lucchesi et.al.", "abstract": "Continual Reinforcement Learning (CRL) is a challenging setting where an agent learns to interact with an environment that is constantly changing over time (the stream of experiences). In this paper, we describe Avalanche RL, a library for Continual Reinforcement Learning which allows to easily train agents on a continuous stream of tasks. Avalanche RL is based on PyTorch and supports any OpenAI Gym environment. Its design is based on Avalanche, one of the more popular continual learning libraries, which allow us to reuse a large number of continual learning strategies and improve the interaction between reinforcement learning and continual learning researchers. Additionally, we propose Continual Habitat-Lab, a novel benchmark and a high-level library which enables the usage of the photorealistic simulator Habitat-Sim for CRL research. Overall, Avalanche RL attempts to unify under a common framework continual reinforcement learning applications, which we hope will foster the growth of the field.", "paper_url": "http://arxiv.org/abs/2202.13657v1", "pdf_url": "http://arxiv.org/pdf/2202.13657v1", "repo_url": "https://github.com/nicklucche/continual-habitat-lab"}, "2202.13369": {"publish_time": "2022-02-27", "title": "Robust Continual Learning through a Comprehensively Progressive Bayesian Neural Network", "author": "Guo Yang et.al.", "abstract": "This work proposes a comprehensively progressive Bayesian neural network for robust continual learning of a sequence of tasks. A Bayesian neural network is progressively pruned and grown such that there are sufficient network resources to represent a sequence of tasks, while the network does not explode. It starts with the contention that similar tasks should have the same number of total network resources, to ensure fair representation of all tasks in a continual learning scenario. Thus, as the data for new task streams in, sufficient neurons are added to the network such that the total number of neurons in each layer of the network, including the shared representations with previous tasks and individual task related representation, are equal for all tasks. The weights that are redundant at the end of training each task are also pruned through re-initialization, in order to be efficiently utilized in the subsequent task. Thus, the network grows progressively, but ensures effective utilization of network resources. We refer to our proposed method as 'Robust Continual Learning through a Comprehensively Progressive Bayesian Neural Network (RCL-CPB)' and evaluate the proposed approach on the MNIST data set, under three different continual learning scenarios. Further to this, we evaluate the performance of RCL-CPB on a homogeneous sequence of tasks using split CIFAR100 (20 tasks of 5 classes each), and a heterogeneous sequence of tasks using MNIST, SVHN and CIFAR10 data sets. The demonstrations and the performance results show that the proposed strategies for progressive BNN enable robust continual learning.", "paper_url": "http://arxiv.org/abs/2202.13369v1", "pdf_url": "http://arxiv.org/pdf/2202.13369v1", "repo_url": null}, "2203.01012": {"publish_time": "2022-03-02", "title": "Continual Feature Selection: Spurious Features in Continual Learning", "author": "Timoth\u00e9e Lesort et.al.", "abstract": "Continual Learning (CL) is the research field addressing learning settings where the data distribution is not static. This paper studies spurious features' influence on continual learning algorithms. Indeed, we show that learning algorithms solve tasks by overfitting features that are not generalizable. To better understand these phenomena and their impact, we propose a domain incremental scenario that we study through various out-of-distribution generalizations and continual learning algorithms. The experiments of this paper show that continual learning algorithms face two related challenges: (1) the spurious features challenge: some features are well correlated with labels in train data but not in test data due to a covariate shift between train and test. (2) the local spurious features challenge: some features correlate well with labels within a task but not within the whole task sequence. The challenge is to learn general features that are neither spurious (in general) nor locally spurious. We prove that the latter is a major cause of performance decrease in continual learning along with catastrophic forgetting. Our results indicate that the best solution to overcome the feature selection problems varies depending on the correlation between spurious features (SFs) and labels. The vanilla replay approach seems to be a powerful approach to deal with SFs, which could explain its good performance in the continual learning literature. This paper presents a different way of understanding performance decrease in continual learning by describing the influence of spurious/local spurious features.", "paper_url": "http://arxiv.org/abs/2203.01012v1", "pdf_url": "http://arxiv.org/pdf/2203.01012v1", "repo_url": null}, "2203.00936": {"publish_time": "2022-03-02", "title": "Continual Learning of Multi-modal Dynamics with External Memory", "author": "Abdullah Akg\u00fcl et.al.", "abstract": "We study the problem of fitting a model to a dynamical environment when new modes of behavior emerge sequentially. The learning model is aware when a new mode appears, but it does not have access to the true modes of individual training sequences. We devise a novel continual learning method that maintains a descriptor of the mode of an encountered sequence in a neural episodic memory. We employ a Dirichlet Process prior on the attention weights of the memory to foster efficient storage of the mode descriptors. Our method performs continual learning by transferring knowledge across tasks by retrieving the descriptors of similar modes of past tasks to the mode of a current sequence and feeding this descriptor into its transition kernel as control input. We observe the continual learning performance of our method to compare favorably to the mainstream parameter transfer approach.", "paper_url": "http://arxiv.org/abs/2203.00936v1", "pdf_url": "http://arxiv.org/pdf/2203.00936v1", "repo_url": null}}, "Meta Learning": {"2202.12888": {"publish_time": "2022-02-25", "title": "Meta-Learning for Simple Regret Minimization", "author": "Mohammadjavad Azizi et.al.", "abstract": "We develop a meta-learning framework for simple regret minimization in bandits. In this framework, a learning agent interacts with a sequence of bandit tasks, which are sampled i.i.d.\\ from an unknown prior distribution, and learns its meta-parameters to perform better on future tasks. We propose the first Bayesian and frequentist algorithms for this meta-learning problem. The Bayesian algorithm has access to a prior distribution over the meta-parameters and its meta simple regret over $m$ bandit tasks with horizon $n$ is mere $\\tilde{O}(m / \\sqrt{n})$. This is while we show that the meta simple regret of the frequentist algorithm is $\\tilde{O}(\\sqrt{m} n + m/ \\sqrt{n})$, and thus, worse. However, the algorithm is more general, because it does not need a prior distribution over the meta-parameters, and is easier to implement for various distributions. We instantiate our algorithms for several classes of bandit problems. Our algorithms are general and we complement our theory by evaluating them empirically in several environments.", "paper_url": "http://arxiv.org/abs/2202.12888v1", "pdf_url": "http://arxiv.org/pdf/2202.12888v1", "repo_url": "https://github.com/Azizimj/Meta-SRM"}, "2202.12450": {"publish_time": "2022-02-25", "title": "MetaVA: Curriculum Meta-learning and Pre-fine-tuning of Deep Neural Networks for Detecting Ventricular Arrhythmias based on ECGs", "author": "Wenrui Zhang et.al.", "abstract": "Ventricular arrhythmias (VA) are the main causes of sudden cardiac death. Developing machine learning methods for detecting VA based on electrocardiograms (ECGs) can help save people's lives. However, developing such machine learning models for ECGs is challenging because of the following: 1) group-level diversity from different subjects and 2) individual-level diversity from different moments of a single subject. In this study, we aim to solve these problems in the pre-training and fine-tuning stages. For the pre-training stage, we propose a novel model agnostic meta-learning (MAML) with curriculum learning (CL) method to solve group-level diversity. MAML is expected to better transfer the knowledge from a large dataset and use only a few recordings to quickly adapt the model to a new person. CL is supposed to further improve MAML by meta-learning from easy to difficult tasks. For the fine-tuning stage, we propose improved pre-fine-tuning to solve individual-level diversity. We conduct experiments using a combination of three publicly available ECG datasets. The results show that our method outperforms the compared methods in terms of all evaluation metrics. Ablation studies show that MAML and CL could help perform more evenly, and pre-fine-tuning could better fit the model to training data.", "paper_url": "http://arxiv.org/abs/2202.12450v1", "pdf_url": "http://arxiv.org/pdf/2202.12450v1", "repo_url": null}, "2202.12396": {"publish_time": "2022-02-24", "title": "Finite-Sum Compositional Stochastic Optimization: Theory and Applications", "author": "Bokun Wang et.al.", "abstract": "This paper studies stochastic optimization for a sum of compositional functions, where the inner-level function of each summand is coupled with the corresponding summation index. We refer to this family of problems as finite-sum coupled compositional optimization (FCCO). It has broad applications in machine learning for optimizing non-convex or convex compositional measures/objectives such as average precision (AP), $p$-norm push, listwise ranking losses, neighborhood component analysis (NCA), deep survival analysis, deep latent variable models, softmax functions, and model agnostic meta-learning, which deserves finer analysis. Yet, existing algorithms and analysis are restricted in one or other aspects. The contribution of this paper is to provide a comprehensive analysis of a simple stochastic algorithm for both non-convex and convex objectives. The key results are {\\bf improved oracle complexities with the parallel speed-up} by the moving-average based stochastic estimator with mini-batching. Our theoretical analysis also exhibits new insights for improving the practical implementation by sampling the batches of equal size for the outer and inner levels. Numerical experiments on AP maximization and $p$-norm push optimization corroborate some aspects of the theory.", "paper_url": "http://arxiv.org/abs/2202.12396v1", "pdf_url": "http://arxiv.org/pdf/2202.12396v1", "repo_url": null}, "2202.12326": {"publish_time": "2022-02-24", "title": "Towards Better Meta-Initialization with Task Augmentation for Kindergarten-aged Speech Recognition", "author": "Yunzheng Zhu et.al.", "abstract": "Children's automatic speech recognition (ASR) is always difficult due to, in part, the data scarcity problem, especially for kindergarten-aged kids. When data are scarce, the model might overfit to the training data, and hence good starting points for training are essential. Recently, meta-learning was proposed to learn model initialization (MI) for ASR tasks of different languages. This method leads to good performance when the model is adapted to an unseen language. However, MI is vulnerable to overfitting on training tasks (learner overfitting). It is also unknown whether MI generalizes to other low-resource tasks. In this paper, we validate the effectiveness of MI in children's ASR and attempt to alleviate the problem of learner overfitting. To achieve model-agnostic meta-learning (MAML), we regard children's speech at each age as a different task. In terms of learner overfitting, we propose a task-level augmentation method by simulating new ages using frequency warping techniques. Detailed experiments are conducted to show the impact of task augmentation on each age for kindergarten-aged speech. As a result, our approach achieves a relative word error rate (WER) improvement of 51% over the baseline system with no augmentation or initialization.", "paper_url": "http://arxiv.org/abs/2202.12326v1", "pdf_url": "http://arxiv.org/pdf/2202.12326v1", "repo_url": null}, "2202.11490": {"publish_time": "2022-02-23", "title": "Towards Tailored Models on Private AIoT Devices: Federated Direct Neural Architecture Search", "author": "Chunhui Zhang et.al.", "abstract": "Neural networks often encounter various stringent resource constraints while deploying on edge devices. To tackle these problems with less human efforts, automated machine learning becomes popular in finding various neural architectures that fit diverse Artificial Intelligence of Things (AIoT) scenarios. Recently, to prevent the leakage of private information while enable automated machine intelligence, there is an emerging trend to integrate federated learning and neural architecture search (NAS). Although promising as it may seem, the coupling of difficulties from both tenets makes the algorithm development quite challenging. In particular, how to efficiently search the optimal neural architecture directly from massive non-independent and identically distributed (non-IID) data among AIoT devices in a federated manner is a hard nut to crack. In this paper, to tackle this challenge, by leveraging the advances in ProxylessNAS, we propose a Federated Direct Neural Architecture Search (FDNAS) framework that allows for hardware-friendly NAS from non- IID data across devices. To further adapt to both various data distributions and different types of devices with heterogeneous embedded hardware platforms, inspired by meta-learning, a Cluster Federated Direct Neural Architecture Search (CFDNAS) framework is proposed to achieve device-aware NAS, in the sense that each device can learn a tailored deep learning model for its particular data distribution and hardware constraint. Extensive experiments on non-IID datasets have shown the state-of-the-art accuracy-efficiency trade-offs achieved by the proposed solution in the presence of both data and device heterogeneity.", "paper_url": "http://arxiv.org/abs/2202.11490v1", "pdf_url": "http://arxiv.org/pdf/2202.11490v1", "repo_url": null}, "2202.13611": {"publish_time": "2022-02-28", "title": "Prepare for Trouble and Make it Double. Supervised and Unsupervised Stacking for AnomalyBased Intrusion Detection", "author": "Tommaso Zoppi et.al.", "abstract": "In the last decades, researchers, practitioners and companies struggled in devising mechanisms to detect malicious activities originating security threats. Amongst the many solutions, network intrusion detection emerged as one of the most popular to analyze network traffic and detect ongoing intrusions based on rules or by means of Machine Learners (MLs), which process such traffic and learn a model to suspect intrusions. Supervised MLs are very effective in detecting known threats, but struggle in identifying zero-day attacks (unknown during learning phase), which instead can be detected through unsupervised MLs. Unfortunately, there are no definitive answers on the combined use of both approaches for network intrusion detection. In this paper we first expand the problem of zero-day attacks and motivate the need to combine supervised and unsupervised algorithms. We propose the adoption of meta-learning, in the form of a two-layer Stacker, to create a mixed approach that detects both known and unknown threats. Then we implement and empirically evaluate our Stacker through an experimental campaign that allows i) debating on meta-features crafted through unsupervised base-level learners, ii) electing the most promising supervised meta-level classifiers, and iii) benchmarking classification scores of the Stacker with respect to supervised and unsupervised classifiers. Last, we compare our solution with existing works from the recent literature. Overall, our Stacker reduces misclassifications with respect to (un)supervised ML algorithms in all the 7 public datasets we considered, and outperforms existing studies in 6 out of those 7 datasets. In particular, it turns out to be more effective in detecting zero-day attacks than supervised algorithms, limiting their main weakness but still maintaining adequate capabilities in detecting known attacks.", "paper_url": "http://arxiv.org/abs/2202.13611v1", "pdf_url": "http://arxiv.org/pdf/2202.13611v1", "repo_url": null}, "2202.13474": {"publish_time": "2022-02-27", "title": "Interpretable Concept-based Prototypical Networks for Few-Shot Learning", "author": "Mohammad Reza Zarei et.al.", "abstract": "Few-shot learning aims at recognizing new instances from classes with limited samples. This challenging task is usually alleviated by performing meta-learning on similar tasks. However, the resulting models are black-boxes. There has been growing concerns about deploying black-box machine learning models and FSL is not an exception in this regard. In this paper, we propose a method for FSL based on a set of human-interpretable concepts. It constructs a set of metric spaces associated with the concepts and classifies samples of novel classes by aggregating concept-specific decisions. The proposed method does not require concept annotations for query samples. This interpretable method achieved results on a par with six previously state-of-the-art black-box FSL methods on the CUB fine-grained bird classification dataset.", "paper_url": "http://arxiv.org/abs/2202.13474v1", "pdf_url": "http://arxiv.org/pdf/2202.13474v1", "repo_url": null}, "2202.13227": {"publish_time": "2022-02-26", "title": "Towards Scalable and Robust Structured Bandits: A Meta-Learning Framework", "author": "Runzhe Wan et.al.", "abstract": "Online learning in large-scale structured bandits is known to be challenging due to the curse of dimensionality. In this paper, we propose a unified meta-learning framework for a general class of structured bandit problems where the parameter space can be factorized to item-level. The novel bandit algorithm is general to be applied to many popular problems,scalable to the huge parameter and action spaces, and robust to the specification of the generalization model. At the core of this framework is a Bayesian hierarchical model that allows information sharing among items via their features, upon which we design a meta Thompson sampling algorithm. Three representative examples are discussed thoroughly. Both theoretical analysis and numerical results support the usefulness of the proposed method.", "paper_url": "http://arxiv.org/abs/2202.13227v1", "pdf_url": "http://arxiv.org/pdf/2202.13227v1", "repo_url": null}, "2202.13117": {"publish_time": "2022-02-26", "title": "An Unsupervised Cross-Modal Hashing Method Robust to Noisy Training Image-Text Correspondences in Remote Sensing", "author": "Georgii Mikriukov et.al.", "abstract": "The development of accurate and scalable cross-modal image-text retrieval methods, where queries from one modality (e.g., text) can be matched to archive entries from another (e.g., remote sensing image) has attracted great attention in remote sensing (RS). Most of the existing methods assume that a reliable multi-modal training set with accurately matched text-image pairs is existing. However, this assumption may not always hold since the multi-modal training sets may include noisy pairs (i.e., textual descriptions/captions associated to training images can be noisy), distorting the learning process of the retrieval methods. To address this problem, we propose a novel unsupervised cross-modal hashing method robust to the noisy image-text correspondences (CHNR). CHNR consists of three modules: 1) feature extraction module, which extracts feature representations of image-text pairs; 2) noise detection module, which detects potential noisy correspondences; and 3) hashing module that generates cross-modal binary hash codes. The proposed CHNR includes two training phases: i) meta-learning phase that uses a small portion of clean (i.e., reliable) data to train the noise detection module in an adversarial fashion; and ii) the main training phase for which the trained noise detection module is used to identify noisy correspondences while the hashing module is trained on the noisy multi-modal training set. Experimental results show that the proposed CHNR outperforms state-of-the-art methods. Our code is publicly available at https://git.tu-berlin.de/rsim/chnr", "paper_url": "http://arxiv.org/abs/2202.13117v1", "pdf_url": "http://arxiv.org/pdf/2202.13117v1", "repo_url": "https://git.tu-berlin.de/rsim/chnr"}, "2202.13001": {"publish_time": "2022-02-25", "title": "Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms", "author": "MohammadJavad Azizi et.al.", "abstract": "We study a sequential decision problem where the learner faces a sequence of $K$-armed stochastic bandit tasks. The tasks may be designed by an adversary, but the adversary is constrained to choose the optimal arm of each task in a smaller (but unknown) subset of $M$ arms. The task boundaries might be known (the bandit meta-learning setting), or unknown (the non-stationary bandit setting), and the number of tasks $N$ as well as the total number of rounds $T$ are known ($N$ could be unknown in the meta-learning setting). We design an algorithm based on a reduction to bandit submodular maximization, and show that its regret in both settings is smaller than the simple baseline of $\\tilde{O}(\\sqrt{KNT})$ that can be obtained by using standard algorithms designed for non-stationary bandit problems. For the bandit meta-learning problem with fixed task length $\\tau$, we show that the regret of the algorithm is bounded as $\\tilde{O}(N\\sqrt{M \\tau}+N^{2/3})$. Under additional assumptions on the identifiability of the optimal arms in each task, we show a bandit meta-learning algorithm with an improved $\\tilde{O}(N\\sqrt{M \\tau}+N^{1/2})$ regret.", "paper_url": "http://arxiv.org/abs/2202.13001v1", "pdf_url": "http://arxiv.org/pdf/2202.13001v1", "repo_url": "https://github.com/duongnhatthang/meta-bandit"}, "2203.00089": {"publish_time": "2022-02-28", "title": "Amortized Proximal Optimization", "author": "Juhan Bae et.al.", "abstract": "We propose a framework for online meta-optimization of parameters that govern optimization, called Amortized Proximal Optimization (APO). We first interpret various existing neural network optimizers as approximate stochastic proximal point methods which trade off the current-batch loss with proximity terms in both function space and weight space. The idea behind APO is to amortize the minimization of the proximal point objective by meta-learning the parameters of an update rule. We show how APO can be used to adapt a learning rate or a structured preconditioning matrix. Under appropriate assumptions, APO can recover existing optimizers such as natural gradient descent and KFAC. It enjoys low computational overhead and avoids expensive and numerically sensitive operations required by some second-order optimizers, such as matrix inverses. We empirically test APO for online adaptation of learning rates and structured preconditioning matrices for regression, image reconstruction, image classification, and natural language translation tasks. Empirically, the learning rate schedules found by APO generally outperform optimal fixed learning rates and are competitive with manually tuned decay schedules. Using APO to adapt a structured preconditioning matrix generally results in optimization performance competitive with second-order methods. Moreover, the absence of matrix inversion provides numerical stability, making it effective for low precision training.", "paper_url": "http://arxiv.org/abs/2203.00089v1", "pdf_url": "http://arxiv.org/pdf/2203.00089v1", "repo_url": null}, "2203.01123": {"publish_time": "2022-03-01", "title": "A Constrained Optimization Approach to Bilevel Optimization with Multiple Inner Minima", "author": "Daouda Sow et.al.", "abstract": "Bilevel optimization has found extensive applications in modern machine learning problems such as hyperparameter optimization, neural architecture search, meta-learning, etc. While bilevel problems with a unique inner minimal point (e.g., where the inner function is strongly convex) are well understood, bilevel problems with multiple inner minimal points remains to be a challenging and open problem. Existing algorithms designed for such a problem were applicable to restricted situations and do not come with the full guarantee of convergence. In this paper, we propose a new approach, which convert the bilevel problem to an equivalent constrained optimization, and then the primal-dual algorithm can be used to solve the problem. Such an approach enjoys a few advantages including (a) addresses the multiple inner minima challenge; (b) features fully first-order efficiency without involving second-order Hessian and Jacobian computations, as opposed to most existing gradient-based bilevel algorithms; (c) admits the convergence guarantee via constrained nonconvex optimization. Our experiments further demonstrate the desired performance of the proposed approach.", "paper_url": "http://arxiv.org/abs/2203.01123v1", "pdf_url": "http://arxiv.org/pdf/2203.01123v1", "repo_url": null}}, "Transfer Learning": {"2202.12814": {"publish_time": "2022-02-25", "title": "The Reality of Multi-Lingual Machine Translation", "author": "Tom Kocmi et.al.", "abstract": "Our book \"The Reality of Multi-Lingual Machine Translation\" discusses the benefits and perils of using more than two languages in machine translation systems. While focused on the particular task of sequence-to-sequence processing and multi-task learning, the book targets somewhat beyond the area of natural language processing. Machine translation is for us a prime example of deep learning applications where human skills and learning capabilities are taken as a benchmark that many try to match and surpass. We document that some of the gains observed in multi-lingual translation may result from simpler effects than the assumed cross-lingual transfer of knowledge.   In the first, rather general part, the book will lead you through the motivation for multi-linguality, the versatility of deep neural networks especially in sequence-to-sequence tasks to complications of this learning. We conclude the general part with warnings against too optimistic and unjustified explanations of the gains that neural networks demonstrate.   In the second part, we fully delve into multi-lingual models, with a particularly careful examination of transfer learning as one of the more straightforward approaches utilizing additional languages. The recent multi-lingual techniques, including massive models, are surveyed and practical aspects of deploying systems for many languages are discussed. The conclusion highlights the open problem of machine understanding and reminds of two ethical aspects of building large-scale models: the inclusivity of research and its ecological trace.", "paper_url": "http://arxiv.org/abs/2202.12814v1", "pdf_url": "http://arxiv.org/pdf/2202.12814v1", "repo_url": null}, "2202.12576": {"publish_time": "2022-02-25", "title": "A Survey of Multilingual Models for Automatic Speech Recognition", "author": "Hemant Yadav et.al.", "abstract": "Although Automatic Speech Recognition (ASR) systems have achieved human-like performance for a few languages, the majority of the world's languages do not have usable systems due to the lack of large speech datasets to train these models. Cross-lingual transfer is an attractive solution to this problem, because low-resource languages can potentially benefit from higher-resource languages either through transfer learning, or being jointly trained in the same multilingual model. The problem of cross-lingual transfer has been well studied in ASR, however, recent advances in Self Supervised Learning are opening up avenues for unlabeled speech data to be used in multilingual ASR models, which can pave the way for improved performance on low-resource languages. In this paper, we survey the state of the art in multilingual ASR models that are built with cross-lingual transfer in mind. We present best practices for building multilingual models from research across diverse languages and techniques, discuss open questions and provide recommendations for future work.", "paper_url": "http://arxiv.org/abs/2202.12576v1", "pdf_url": "http://arxiv.org/pdf/2202.12576v1", "repo_url": null}, "2202.12505": {"publish_time": "2022-02-25", "title": "A Deep Learning Approach for Network-wide Dynamic Traffic Prediction during Hurricane Evacuation", "author": "Rezaur Rahman et.al.", "abstract": "Proactive evacuation traffic management largely depends on real-time monitoring and prediction of traffic flow at a high spatiotemporal resolution. However, evacuation traffic prediction is challenging due to the uncertainties caused by sudden changes in projected hurricane paths and consequently household evacuation behavior. Moreover, modeling spatiotemporal traffic flow patterns requires extensive data over a longer time period, whereas evacuations typically last for 2 to 5 days. In this paper, we present a novel data-driven approach for predicting evacuation traffic at a network scale. We develop a dynamic graph convolution LSTM (DGCN-LSTM) model to learn the network dynamics of hurricane evacuation. We first train the model for non-evacuation period traffic data showing that the model outperforms existing deep learning models for predicting non-evacuation period traffic with an RMSE value of 226.84. However, when we apply the model for evacuation period, the RMSE value increased to 1440.99. We overcome this issue by adopting a transfer learning approach with additional features related to evacuation traffic demand such as distance from the evacuation zone, time to landfall, and other zonal level features to control the transfer of information (network dynamics) from non-evacuation periods to evacuation periods. The final transfer learned DGCN-LSTM model performs well to predict evacuation traffic flow (RMSE=399.69). The implemented model can be applied to predict evacuation traffic over a longer forecasting horizon (6 hour). It will assist transportation agencies to activate appropriate traffic management strategies to reduce delays for evacuating traffic.", "paper_url": "http://arxiv.org/abs/2202.12505v1", "pdf_url": "http://arxiv.org/pdf/2202.12505v1", "repo_url": null}, "2202.12174": {"publish_time": "2022-02-24", "title": "Collaborative Training of Heterogeneous Reinforcement Learning Agents in Environments with Sparse Rewards: What and When to Share?", "author": "Alain Andres et.al.", "abstract": "In the early stages of human life, babies develop their skills by exploring different scenarios motivated by their inherent satisfaction rather than by extrinsic rewards from the environment. This behavior, referred to as intrinsic motivation, has emerged as one solution to address the exploration challenge derived from reinforcement learning environments with sparse rewards. Diverse exploration approaches have been proposed to accelerate the learning process over single- and multi-agent problems with homogeneous agents. However, scarce studies have elaborated on collaborative learning frameworks between heterogeneous agents deployed into the same environment, but interacting with different instances of the latter without any prior knowledge. Beyond the heterogeneity, each agent's characteristics grant access only to a subset of the full state space, which may hide different exploration strategies and optimal solutions. In this work we combine ideas from intrinsic motivation and transfer learning. Specifically, we focus on sharing parameters in actor-critic model architectures and on combining information obtained through intrinsic motivation with the aim of having a more efficient exploration and faster learning. We test our strategies through experiments performed over a modified ViZDooM's My Way Home scenario, which is more challenging than its original version and allows evaluating the heterogeneity between agents. Our results reveal different ways in which a collaborative framework with little additional computational cost can outperform an independent learning process without knowledge sharing. Additionally, we depict the need for modulating correctly the importance between the extrinsic and intrinsic rewards to avoid undesired agent behaviors.", "paper_url": "http://arxiv.org/abs/2202.12174v1", "pdf_url": "http://arxiv.org/pdf/2202.12174v1", "repo_url": null}, "2202.11685": {"publish_time": "2022-02-23", "title": "A Class of Geometric Structures in Transfer Learning: Minimax Bounds and Optimality", "author": "Xuhui Zhang et.al.", "abstract": "We study the problem of transfer learning, observing that previous efforts to understand its information-theoretic limits do not fully exploit the geometric structure of the source and target domains. In contrast, our study first illustrates the benefits of incorporating a natural geometric structure within a linear regression model, which corresponds to the generalized eigenvalue problem formed by the Gram matrices of both domains. We next establish a finite-sample minimax lower bound, propose a refined model interpolation estimator that enjoys a matching upper bound, and then extend our framework to multiple source domains and generalized linear models. Surprisingly, as long as information is available on the distance between the source and target parameters, negative-transfer does not occur. Simulation studies show that our proposed interpolation estimator outperforms state-of-the-art transfer learning methods in both moderate- and high-dimensional settings.", "paper_url": "http://arxiv.org/abs/2202.11685v1", "pdf_url": "http://arxiv.org/pdf/2202.11685v1", "repo_url": null}, "2202.13626": {"publish_time": "2022-02-28", "title": "Improving Response Time of Home IoT Services in Federated Learning", "author": "Dongjun Hwang et.al.", "abstract": "For intelligent home IoT services with sensors and machine learning, we need to upload IoT data to the cloud server which cannot share private data for training. A recent machine learning approach, called federated learning, keeps user data on the device in the distributed computing environment. Though federated learning is useful for protecting privacy, it experiences poor performance in terms of the end-to-end response time in home IoT services, because IoT devices are usually controlled by remote servers in the cloud. In addition, it is difficult to achieve the high accuracy of federated learning models due to insufficient data problems and model inversion attacks. In this paper, we propose a local IoT control method for a federated learning home service that recognizes the user behavior in the home network quickly and accurately. We present a federated learning client with transfer learning and differential privacy to solve data scarcity and data model inversion attack problems. From experiments, we show that the local control of home IoT devices for user authentication and control message transmission by the federated learning clients improves the response time to less than 1 second. Moreover, we demonstrate that federated learning with transfer learning achieves 97% of accuracy under 9,000 samples, which is only 2% of the difference from centralized learning.", "paper_url": "http://arxiv.org/abs/2202.13626v1", "pdf_url": "http://arxiv.org/pdf/2202.13626v1", "repo_url": "https://github.com/hwangdongjun/federated_learning_using_websockets"}, "2202.13403": {"publish_time": "2022-02-27", "title": "A Multimodal German Dataset for Automatic Lip Reading Systems and Transfer Learning", "author": "Gerald Schwiebert et.al.", "abstract": "Large datasets as required for deep learning of lip reading do not exist in many languages. In this paper we present the dataset GLips (German Lips) consisting of 250,000 publicly available videos of the faces of speakers of the Hessian Parliament, which was processed for word-level lip reading using an automatic pipeline. The format is similar to that of the English language LRW (Lip Reading in the Wild) dataset, with each video encoding one word of interest in a context of 1.16 seconds duration, which yields compatibility for studying transfer learning between both datasets. By training a deep neural network, we investigate whether lip reading has language-independent features, so that datasets of different languages can be used to improve lip reading models. We demonstrate learning from scratch and show that transfer learning from LRW to GLips and vice versa improves learning speed and performance, in particular for the validation set.", "paper_url": "http://arxiv.org/abs/2202.13403v1", "pdf_url": "http://arxiv.org/pdf/2202.13403v1", "repo_url": null}, "2202.13174": {"publish_time": "2022-02-26", "title": "BioADAPT-MRC: Adversarial Learning-based Domain Adaptation Improves Biomedical Machine Reading Comprehension Task", "author": "Maria Mahbub et.al.", "abstract": "Motivation: Biomedical machine reading comprehension (biomedical-MRC) aims to comprehend complex biomedical narratives and assist healthcare professionals in retrieving information from them. The high performance of modern neural network-based MRC systems depends on high-quality, large-scale, human-annotated training datasets. In the biomedical domain, a crucial challenge in creating such datasets is the requirement for domain knowledge, inducing the scarcity of labeled data and the need for transfer learning from the labeled general-purpose (source) domain to the biomedical (target) domain. However, there is a discrepancy in marginal distributions between the general-purpose and biomedical domains due to the variances in topics. Therefore, direct-transferring of learned representations from a model trained on a general-purpose domain to the biomedical domain can hurt the model's performance.   Results: We present an adversarial learning-based domain adaptation framework for the biomedical machine reading comprehension task (BioADAPT-MRC), a neural network-based method to address the discrepancies in the marginal distributions between the general and biomedical domain datasets. BioADAPT-MRC relaxes the need for generating pseudo labels for training a well-performing biomedical-MRC model. We extensively evaluate the performance of BioADAPT-MRC by comparing it with the best existing methods on three widely used benchmark biomedical-MRC datasets -- BioASQ-7b, BioASQ-8b, and BioASQ-9b. Our results suggest that without using any synthetic or human-annotated data from the biomedical domain, BioADAPT-MRC can achieve state-of-the-art performance on these datasets.   Availability: BioADAPT-MRC is freely available as an open-source project at\\\\https://github.com/mmahbub/BioADAPT-MRC", "paper_url": "http://arxiv.org/abs/2202.13174v1", "pdf_url": "http://arxiv.org/pdf/2202.13174v1", "repo_url": null}, "2203.00585": {"publish_time": "2022-03-01", "title": "Self-Supervised Vision Transformers Learn Visual Concepts in Histopathology", "author": "Richard J. Chen et.al.", "abstract": "Tissue phenotyping is a fundamental task in learning objective characterizations of histopathologic biomarkers within the tumor-immune microenvironment in cancer pathology. However, whole-slide imaging (WSI) is a complex computer vision in which: 1) WSIs have enormous image resolutions with precludes large-scale pixel-level efforts in data curation, and 2) diversity of morphological phenotypes results in inter- and intra-observer variability in tissue labeling. To address these limitations, current efforts have proposed using pretrained image encoders (transfer learning from ImageNet, self-supervised pretraining) in extracting morphological features from pathology, but have not been extensively validated. In this work, we conduct a search for good representations in pathology by training a variety of self-supervised models with validation on a variety of weakly-supervised and patch-level tasks. Our key finding is in discovering that Vision Transformers using DINO-based knowledge distillation are able to learn data-efficient and interpretable features in histology images wherein the different attention heads learn distinct morphological phenotypes. We make evaluation code and pretrained weights publicly-available at: https://github.com/Richarizardd/Self-Supervised-ViT-Path.", "paper_url": "http://arxiv.org/abs/2203.00585v1", "pdf_url": "http://arxiv.org/pdf/2203.00585v1", "repo_url": "https://github.com/richarizardd/self-supervised-vit-path"}, "2203.00355": {"publish_time": "2022-03-01", "title": "Tempera: Spatial Transformer Feature Pyramid Network for Cardiac MRI Segmentation", "author": "Christoforos Galazis et.al.", "abstract": "Assessing the structure and function of the right ventricle (RV) is important in the diagnosis of several cardiac pathologies. However, it remains more challenging to segment the RV than the left ventricle (LV). In this paper, we focus on segmenting the RV in both short (SA) and long-axis (LA) cardiac MR images simultaneously. For this task, we propose a new multi-input/output architecture, hybrid 2D/3D geometric spatial TransformEr Multi-Pass fEature pyRAmid (Tempera). Our feature pyramid extends current designs by allowing not only a multi-scale feature output but multi-scale SA and LA input images as well. Tempera transfers learned features between SA and LA images via layer weight sharing and incorporates a geometric target transformer to map the predicted SA segmentation to LA space. Our model achieves an average Dice score of 0.836 and 0.798 for the SA and LA, respectively, and 26.31 mm and 31.19 mm Hausdorff distances. This opens up the potential for the incorporation of RV segmentation models into clinical workflows.", "paper_url": "http://arxiv.org/abs/2203.00355v1", "pdf_url": "http://arxiv.org/pdf/2203.00355v1", "repo_url": "https://github.com/cgalaz01/mnms2_challenge"}, "2203.00251": {"publish_time": "2022-03-01", "title": "FIRL: Fast Imitation and Policy Reuse Learning", "author": "Yiwen Chen et.al.", "abstract": "Intelligent robotics policies have been widely researched for challenging applications such as opening doors, washing dishes, and table organization. We refer to a \"Policy Pool\", containing skills that be easily accessed and reused. There are researches to leverage the pool, such as policy reuse, modular learning, assembly learning, transfer learning, hierarchical reinforcement learning (HRL), etc. However, most methods generally do not perform well in learning efficiency and require large datasets for training. This work focuses on enabling fast learning based on the policy pool. It should learn fast enough in one-shot or few-shot by avoiding learning from scratch. We also allow it to interact and learn from humans, but the training period should be within minutes. We propose FIRL, Fast (one-shot) Imitation, and Policy Reuse Learning. Instead of learning a new skill from scratch, it performs the one-shot imitation learning on the higher layer under a 2-layer hierarchical mechanism. Our method reduces a complex task learning to a simple regression problem that it could solve in a few offline iterations. The agent could have a good command of a new task given a one-shot demonstration. We demonstrate this method on the OpenDoors mini-grid environment, and the code is available on http://www.github.com/yiwc/firl.", "paper_url": "http://arxiv.org/abs/2203.00251v1", "pdf_url": "http://arxiv.org/pdf/2203.00251v1", "repo_url": "https://github.com/yiwc/firl"}, "2203.01311": {"publish_time": "2022-03-02", "title": "HighMMT: Towards Modality and Task Generalization for High-Modality Representation Learning", "author": "Paul Pu Liang et.al.", "abstract": "Learning multimodal representations involves discovering correspondences and integrating information from multiple heterogeneous sources of data. While recent research has begun to explore the design of more general-purpose multimodal models (contrary to prior focus on domain and modality-specific architectures), these methods are still largely focused on a small set of modalities in the language, vision, and audio space. In order to accelerate generalization towards diverse and understudied modalities, we investigate methods for high-modality (a large set of diverse modalities) and partially-observable (each task only defined on a small subset of modalities) scenarios. To tackle these challenges, we design a general multimodal model that enables multitask and transfer learning: multitask learning with shared parameters enables stable parameter counts (addressing scalability), and cross-modal transfer learning enables information sharing across modalities and tasks (addressing partial observability). Our resulting model generalizes across text, image, video, audio, time-series, sensors, tables, and set modalities from different research areas, improves the tradeoff between performance and efficiency, transfers to new modalities and tasks, and reveals surprising insights on the nature of information sharing in multitask models. We release our code and benchmarks which we hope will present a unified platform for subsequent theoretical and empirical analysis: https://github.com/pliang279/HighMMT.", "paper_url": "http://arxiv.org/abs/2203.01311v1", "pdf_url": "http://arxiv.org/pdf/2203.01311v1", "repo_url": null}, "2203.01265": {"publish_time": "2022-03-02", "title": "Self-supervised Transformer for Deepfake Detection", "author": "Hanqing Zhao et.al.", "abstract": "The fast evolution and widespread of deepfake techniques in real-world scenarios require stronger generalization abilities of face forgery detectors. Some works capture the features that are unrelated to method-specific artifacts, such as clues of blending boundary, accumulated up-sampling, to strengthen the generalization ability. However, the effectiveness of these methods can be easily corrupted by post-processing operations such as compression. Inspired by transfer learning, neural networks pre-trained on other large-scale face-related tasks may provide useful features for deepfake detection. For example, lip movement has been proved to be a kind of robust and good-transferring highlevel semantic feature, which can be learned from the lipreading task. However, the existing method pre-trains the lip feature extraction model in a supervised manner, which requires plenty of human resources in data annotation and increases the difficulty of obtaining training data. In this paper, we propose a self-supervised transformer based audio-visual contrastive learning method. The proposed method learns mouth motion representations by encouraging the paired video and audio representations to be close while unpaired ones to be diverse. After pre-training with our method, the model will then be partially fine-tuned for deepfake detection task. Extensive experiments show that our self-supervised method performs comparably or even better than the supervised pre-training counterpart.", "paper_url": "http://arxiv.org/abs/2203.01265v1", "pdf_url": "http://arxiv.org/pdf/2203.01265v1", "repo_url": null}, "2203.01187": {"publish_time": "2022-03-02", "title": "Visual Feature Encoding for GNNs on Road Networks", "author": "Oliver Stromann et.al.", "abstract": "In this work, we present a novel approach to learning an encoding of visual features into graph neural networks with the application on road network data. We propose an architecture that combines state-of-the-art vision backbone networks with graph neural networks. More specifically, we perform a road type classification task on an Open Street Map road network through encoding of satellite imagery using various ResNet architectures. Our architecture further enables fine-tuning and a transfer-learning approach is evaluated by pretraining on the NWPU-RESISC45 image classification dataset for remote sensing and comparing them to purely ImageNet-pretrained ResNet models as visual feature encoders. The results show not only that the visual feature encoders are superior to low-level visual features, but also that the fine-tuning of the visual feature encoder to a general remote sensing dataset such as NWPU-RESISC45 can further improve the performance of a GNN on a machine learning task like road type classification.", "paper_url": "http://arxiv.org/abs/2203.01187v1", "pdf_url": "http://arxiv.org/pdf/2203.01187v1", "repo_url": null}, "2203.01111": {"publish_time": "2022-03-02", "title": "Large-Scale Hate Speech Detection with Cross-Domain Transfer", "author": "Cagri Toraman et.al.", "abstract": "The performance of hate speech detection models relies on the datasets on which the models are trained. Existing datasets are mostly prepared with a limited number of instances or hate domains that define hate topics. This hinders large-scale analysis and transfer learning with respect to hate domains. In this study, we construct large-scale tweet datasets for hate speech detection in English and a low-resource language, Turkish, consisting of human-labeled 100k tweets per each. Our datasets are designed to have equal number of tweets distributed over five domains. The experimental results supported by statistical tests show that Transformer-based language models outperform conventional bag-of-words and neural models by at least 5% in English and 10% in Turkish for large-scale hate speech detection. The performance is also scalable to different training sizes, such that 98% of performance in English, and 97% in Turkish, are recovered when 20% of training instances are used. We further examine the generalization ability of cross-domain transfer among hate domains. We show that 96% of the performance of a target domain in average is recovered by other domains for English, and 92% for Turkish. Gender and religion are more successful to generalize to other domains, while sports fail most.", "paper_url": "http://arxiv.org/abs/2203.01111v1", "pdf_url": "http://arxiv.org/pdf/2203.01111v1", "repo_url": "https://github.com/avaapm/hatespeech"}, "2203.00853": {"publish_time": "2022-03-02", "title": "Transfer Learning of High-Fidelity Opacity Spectra in Autoencoders and Surrogate Models", "author": "Michael D. Vander Wal et.al.", "abstract": "Simulations of high energy density physics are expensive, largely in part for the need to produce non-local thermodynamic equilibrium opacities. High-fidelity spectra may reveal new physics in the simulations not seen with low-fidelity spectra, but the cost of these simulations also scale with the level of fidelity of the opacities being used. Neural networks are capable of reproducing these spectra, but neural networks need data to to train them which limits the level of fidelity of the training data. This paper demonstrates that it is possible to reproduce high-fidelity spectra with median errors in the realm of 3\\% to 4\\% using as few as 50 samples of high-fidelity Krypton data by performing transfer learning on a neural network trained on many times more low-fidelity data.", "paper_url": "http://arxiv.org/abs/2203.00853v1", "pdf_url": "http://arxiv.org/pdf/2203.00853v1", "repo_url": null}}}, "Graph Neural Network": {"Graph Neural Network": {"2202.12619": {"publish_time": "2022-02-25", "title": "Fluid Simulation System Based on Graph Neural Network", "author": "Qiang Liu et.al.", "abstract": "Traditional computational fluid dynamics calculates the physical information of the flow field by solving partial differential equations, which takes a long time to calculate and consumes a lot of computational resources. We build a fluid simulation simulator based on the graph neural network architecture. The simulator has fast computing speed and low consumption of computing resources. We regard the computational domain as a structural graph, and the computational nodes in the structural graph determine neighbor nodes through adaptive sampling. Building deep learning architectures with attention graph neural networks. The fluid simulation simulator is trained according to the simulation results of the flow field around the cylinder with different Reynolds numbers. The trained fluid simulation simulator not only has a very high accuracy for the prediction of the flow field in the training set, but also can extrapolate the flow field outside the training set. Compared to traditional CFD solvers, the fluid simulation simulator achieves a speedup of 2-3 orders of magnitude. The fluid simulation simulator provides new ideas for the rapid optimization and design of fluid mechanics models and the real-time control of intelligent fluid mechanisms.", "paper_url": "http://arxiv.org/abs/2202.12619v1", "pdf_url": "http://arxiv.org/pdf/2202.12619v1", "repo_url": null}, "2202.12586": {"publish_time": "2022-02-25", "title": "Spatio-Temporal Latent Graph Structure Learning for Traffic Forecasting", "author": "Jiabin Tang et.al.", "abstract": "Accurate traffic forecasting, the foundation of intelligent transportation systems (ITS), has never been more significant than nowadays due to the prosperity of the smart cities and urban computing. Recently, Graph Neural Network truly outperforms the traditional methods. Nevertheless, the most conventional GNN based model works well while given a pre-defined graph structure. And the existing methods of defining the graph structures focus purely on spatial dependencies and ignored the temporal correlation. Besides, the semantics of the static pre-defined graph adjacency applied during the whole training progress is always incomplete, thus overlooking the latent topologies that may fine-tune the model. To tackle these challenges, we proposed a new traffic forecasting framework--Spatio-Temporal Latent Graph Structure Learning networks (ST-LGSL). More specifically, the model employed a graph generator based on Multilayer perceptron and K-Nearest Neighbor, which learns the latent graph topological information from the entire data considering both spatial and temporal dynamics. Furthermore, with the initialization of MLP-kNN based on ground-truth adjacency matrix and similarity metric in kNN, ST-LGSL aggregates the topologies focusing on geography and node similarity. Additionally, the generated graphs act as the input of spatio-temporal prediction module combined with the Diffusion Graph Convolutions and Gated Temporal Convolutions Networks. Experimental results on two benchmarking datasets in real world demonstrate that ST-LGSL outperforms various types of state-of-art baselines.", "paper_url": "http://arxiv.org/abs/2202.12586v1", "pdf_url": "http://arxiv.org/pdf/2202.12586v1", "repo_url": null}, "2202.12508": {"publish_time": "2022-02-25", "title": "Addressing Over-Smoothing in Graph Neural Networks via Deep Supervision", "author": "Pantelis Elinas et.al.", "abstract": "Learning useful node and graph representations with graph neural networks (GNNs) is a challenging task. It is known that deep GNNs suffer from over-smoothing where, as the number of layers increases, node representations become nearly indistinguishable and model performance on the downstream task degrades significantly. To address this problem, we propose deeply-supervised GNNs (DSGNNs), i.e., GNNs enhanced with deep supervision where representations learned at all layers are used for training. We show empirically that DSGNNs are resilient to over-smoothing and can outperform competitive benchmarks on node and graph property prediction problems.", "paper_url": "http://arxiv.org/abs/2202.12508v1", "pdf_url": "http://arxiv.org/pdf/2202.12508v1", "repo_url": null}, "2202.12481": {"publish_time": "2022-02-25", "title": "Multi-View Graph Representation for Programming Language Processing: An Investigation into Algorithm Detection", "author": "Ting Long et.al.", "abstract": "Program representation, which aims at converting program source code into vectors with automatically extracted features, is a fundamental problem in programming language processing (PLP). Recent work tries to represent programs with neural networks based on source code structures. However, such methods often focus on the syntax and consider only one single perspective of programs, limiting the representation power of models. This paper proposes a multi-view graph (MVG) program representation method. MVG pays more attention to code semantics and simultaneously includes both data flow and control flow as multiple views. These views are then combined and processed by a graph neural network (GNN) to obtain a comprehensive program representation that covers various aspects. We thoroughly evaluate our proposed MVG approach in the context of algorithm detection, an important and challenging subfield of PLP. Specifically, we use a public dataset POJ-104 and also construct a new challenging dataset ALG-109 to test our method. In experiments, MVG outperforms previous methods significantly, demonstrating our model's strong capability of representing source code.", "paper_url": "http://arxiv.org/abs/2202.12481v1", "pdf_url": "http://arxiv.org/pdf/2202.12481v1", "repo_url": null}, "2202.12478": {"publish_time": "2022-02-25", "title": "GAME-ON: Graph Attention Network based Multimodal Fusion for Fake News Detection", "author": "Mudit Dhawan et.al.", "abstract": "Social media in present times has a significant and growing influence. Fake news being spread on these platforms have a disruptive and damaging impact on our lives. Furthermore, as multimedia content improves the visibility of posts more than text data, it has been observed that often multimedia is being used for creating fake content. A plethora of previous multimodal-based work has tried to address the problem of modeling heterogeneous modalities in identifying fake content. However, these works have the following limitations: (1) inefficient encoding of inter-modal relations by utilizing a simple concatenation operator on the modalities at a later stage in a model, which might result in information loss; (2) training very deep neural networks with a disproportionate number of parameters on small but complex real-life multimodal datasets result in higher chances of overfitting. To address these limitations, we propose GAME-ON, a Graph Neural Network based end-to-end trainable framework that allows granular interactions within and across different modalities to learn more robust data representations for multimodal fake news detection. We use two publicly available fake news datasets, Twitter and Weibo, for evaluations. Our model outperforms on Twitter by an average of 11% and keeps competitive performance on Weibo, within a 2.6% margin, while using 65% fewer parameters than the best comparable state-of-the-art baseline.", "paper_url": "http://arxiv.org/abs/2202.12478v1", "pdf_url": "http://arxiv.org/pdf/2202.12478v1", "repo_url": null}, "2202.13956": {"publish_time": "2022-02-28", "title": "RouteNet-Erlang: A Graph Neural Network for Network Performance Evaluation", "author": "Miquel Ferriol-Galm\u00e9s et.al.", "abstract": "Network modeling is a fundamental tool in network research, design, and operation. Arguably the most popular method for modeling is Queuing Theory (QT). Its main limitation is that it imposes strong assumptions on the packet arrival process, which typically do not hold in real networks. In the field of Deep Learning, Graph Neural Networks (GNN) have emerged as a new technique to build data-driven models that can learn complex and non-linear behavior. In this paper, we present \\emph{RouteNet-Erlang}, a pioneering GNN architecture designed to model computer networks. RouteNet-Erlang supports complex traffic models, multi-queue scheduling policies, routing policies and can provide accurate estimates in networks not seen in the training phase. We benchmark RouteNet-Erlang against a state-of-the-art QT model, and our results show that it outperforms QT in all the network scenarios.", "paper_url": "http://arxiv.org/abs/2202.13956v1", "pdf_url": "http://arxiv.org/pdf/2202.13956v1", "repo_url": null}, "2202.13947": {"publish_time": "2022-02-28", "title": "Data-Augmentation for Graph Neural Network Learning of the Relaxed Energies of Unrelaxed Structures", "author": "Jason B. Gibson et.al.", "abstract": "Computational materials discovery has continually grown in utility over the past decade due to advances in computing power and crystal structure prediction algorithms (CSPA). However, the computational cost of the \\textit{ab initio} calculations required by CSPA limits its utility to small unit cells, reducing the compositional and structural space the algorithms can explore. Past studies have bypassed many unneeded \\textit{ab initio} calculations by utilizing machine learning methods to predict formation energy and determine the stability of a material. Specifically, graph neural networks display high fidelity in predicting formation energy. Traditionally graph neural networks are trained on large data sets of relaxed structures. Unfortunately, the geometries of unrelaxed candidate structures produced by CSPA often deviate from the relaxed state, which leads to poor predictions hindering the model's ability to filter energetically unfavorable prior to \\textit{ab initio} evaluation. This work shows that the prediction error on relaxed structures reduces as training progresses, while the prediction error on unrelaxed structures increases, suggesting an inverse correlation between relaxed and unrelaxed structure prediction accuracy. To remedy this behavior, we propose a simple, physically motivated, computationally cheap perturbation technique that augments training data to improve predictions on unrelaxed structures dramatically. On our test set consisting of 623 Nb-Sr-H hydride structures, we found that training a crystal graph convolutional neural networks, utilizing our augmentation method, reduced the MAE of formation energy prediction by 66\\% compared to training with only relaxed structures. We then show how this error reduction can accelerates CSPA by improving the model's ability to filter out energetically unfavorable structures accurately.", "paper_url": "http://arxiv.org/abs/2202.13947v1", "pdf_url": "http://arxiv.org/pdf/2202.13947v1", "repo_url": null}, "2202.13852": {"publish_time": "2022-02-28", "title": "Hyperbolic Graph Neural Networks: A Review of Methods and Applications", "author": "Menglin Yang et.al.", "abstract": "Graph neural networks generalize conventional neural networks to graph-structured data and have received widespread attention due to their impressive representation ability. In spite of the remarkable achievements, the performance of Euclidean models in graph-related learning is still bounded and limited by the representation ability of Euclidean geometry, especially for datasets with highly non-Euclidean latent anatomy. Recently, hyperbolic space has gained increasing popularity in processing graph data with tree-like structure and power-law distribution, owing to its exponential growth property. In this survey, we comprehensively revisit the technical details of the current hyperbolic graph neural networks, unifying them into a general framework and summarizing the variants of each component. More importantly, we present various HGNN-related applications. Last, we also identify several challenges, which potentially serve as guidelines for further flourishing the achievements of graph learning in hyperbolic spaces.", "paper_url": "http://arxiv.org/abs/2202.13852v1", "pdf_url": "http://arxiv.org/pdf/2202.13852v1", "repo_url": "https://github.com/marlin-codes/HGNNs"}, "2202.13800": {"publish_time": "2022-02-28", "title": "Differential equation and probability inspired graph neural networks for latent variable learning", "author": "Zhuangwei Shi et.al.", "abstract": "Probabilistic theory and differential equation are powerful tools for the interpretability and guidance of the design of machine learning models, especially for illuminating the mathematical motivation of learning latent variable from observation. State estimation and subspace learning are two classical problems in latent variable learning. State estimation solves optimal value for latent variable (i.e. state) from noised observation. Subspace learning maps high-dimensional features on low-dimensional subspace to capture efficient representation. Graphs are widely applied for modeling latent variable learning problems, and graph neural networks implement deep learning architectures on graphs. Inspired by probabilistic theory and differential equations, this paper proposes graph neural networks to solve state estimation and subspace learning problems. This paper conducts theoretical studies, and adopts empirical studies on several tasks, including text classification, protein classification, stock prediction and state estimation for robotics. Experiments illustrate that the proposed graph neural networks are superior to the current methods. Source code of this paper is available at https://github.com/zshicode/Latent-variable-GNN.", "paper_url": "http://arxiv.org/abs/2202.13800v1", "pdf_url": "http://arxiv.org/pdf/2202.13800v1", "repo_url": "https://github.com/zshicode/latent-variable-gnn"}, "2202.13686": {"publish_time": "2022-02-28", "title": "Points-of-Interest Relationship Inference with Spatial-enriched Graph Neural Networks", "author": "Yile Chen et.al.", "abstract": "As a fundamental component in location-based services, inferring the relationship between points-of-interests (POIs) is very critical for service providers to offer good user experience to business owners and customers. Most of the existing methods for relationship inference are not targeted at POI, thus failing to capture unique spatial characteristics that have huge effects on POI relationships. In this work we propose PRIM to tackle POI relationship inference for multiple relation types. PRIM features four novel components, including a weighted relational graph neural network, category taxonomy integration, a self-attentive spatial context extractor, and a distance-specific scoring function. Extensive experiments on two real-world datasets show that PRIM achieves the best results compared to state-of-the-art baselines and it is robust against data sparsity and is applicable to unseen cases in practice.", "paper_url": "http://arxiv.org/abs/2202.13686v1", "pdf_url": "http://arxiv.org/pdf/2202.13686v1", "repo_url": null}, "2203.00638": {"publish_time": "2022-03-01", "title": "PaSca: a Graph Neural Architecture Search System under the Scalable Paradigm", "author": "Wentao Zhang et.al.", "abstract": "Graph neural networks (GNNs) have achieved state-of-the-art performance in various graph-based tasks. However, as mainstream GNNs are designed based on the neural message passing mechanism, they do not scale well to data size and message passing steps. Although there has been an emerging interest in the design of scalable GNNs, current researches focus on specific GNN design, rather than the general design space, limiting the discovery of potential scalable GNN models. This paper proposes PasCa, a new paradigm and system that offers a principled approach to systemically construct and explore the design space for scalable GNNs, rather than studying individual designs. Through deconstructing the message passing mechanism, PasCa presents a novel Scalable Graph Neural Architecture Paradigm (SGAP), together with a general architecture design space consisting of 150k different designs. Following the paradigm, we implement an auto-search engine that can automatically search well-performing and scalable GNN architectures to balance the trade-off between multiple criteria (e.g., accuracy and efficiency) via multi-objective optimization. Empirical studies on ten benchmark datasets demonstrate that the representative instances (i.e., PasCa-V1, V2, and V3) discovered by our system achieve consistent performance among competitive baselines. Concretely, PasCa-V3 outperforms the state-of-the-art GNN method JK-Net by 0.4\\% in terms of predictive accuracy on our large industry dataset while achieving up to $28.3\\times$ training speedups.", "paper_url": "http://arxiv.org/abs/2203.00638v1", "pdf_url": "http://arxiv.org/pdf/2203.00638v1", "repo_url": null}, "2203.00611": {"publish_time": "2022-03-01", "title": "Learning Intermediate Representations using Graph Neural Networks for NUMA and Prefetchers Optimization", "author": "Ali TehraniJamsaz et.al.", "abstract": "There is a large space of NUMA and hardware prefetcher configurations that can significantly impact the performance of an application. Previous studies have demonstrated how a model can automatically select configurations based on the dynamic properties of the code to achieve speedups. This paper demonstrates how the static Intermediate Representation (IR) of the code can guide NUMA/prefetcher optimizations without the prohibitive cost of performance profiling. We propose a method to create a comprehensive dataset that includes a diverse set of intermediate representations along with optimum configurations. We then apply a graph neural network model in order to validate this dataset. We show that our static intermediate representation based model achieves 80% of the performance gains provided by expensive dynamic performance profiling based strategies. We further develop a hybrid model that uses both static and dynamic information. Our hybrid model achieves the same gains as the dynamic models but at a reduced cost by only profiling 30% of the programs.", "paper_url": "http://arxiv.org/abs/2203.00611v1", "pdf_url": "http://arxiv.org/pdf/2203.00611v1", "repo_url": null}, "2203.00387": {"publish_time": "2022-03-01", "title": "Motion-aware Dynamic Graph Neural Network for Video Compressive Sensing", "author": "Ruiying Lu et.al.", "abstract": "Video snapshot compressive imaging (SCI) utilizes a 2D detector to capture sequential video frames and compresses them into a single measurement. Various reconstruction methods have been developed to recover the high-speed video frames from the snapshot measurement. However, most existing reconstruction methods are incapable of capturing long-range spatial and temporal dependencies, which are critical for video processing. In this paper, we propose a flexible and robust approach based on graph neural network (GNN) to efficiently model non-local interactions between pixels in space as well as time regardless of the distance. Specifically, we develop a motion-aware dynamic GNN for better video representation, i.e., represent each pixel as the aggregation of relative nodes under the guidance of frame-by-frame motions, which consists of motion-aware dynamic sampling, cross-scale node sampling and graph aggregation. Extensive results on both simulation and real data demonstrate both the effectiveness and efficiency of the proposed approach, and the visualization clearly illustrates the intrinsic dynamic sampling operations of our proposed model for boosting the video SCI reconstruction results. The code and models will be released to the public.", "paper_url": "http://arxiv.org/abs/2203.00387v1", "pdf_url": "http://arxiv.org/pdf/2203.00387v1", "repo_url": null}, "2203.00330": {"publish_time": "2022-03-01", "title": "Machine Learning for Particle Flow Reconstruction at CMS", "author": "Joosep Pata et.al.", "abstract": "We provide details on the implementation of a machine-learning based particle flow algorithm for CMS. The standard particle flow algorithm reconstructs stable particles based on calorimeter clusters and tracks to provide a global event reconstruction that exploits the combined information of multiple detector subsystems, leading to strong improvements for quantities such as jets and missing transverse energy. We have studied a possible evolution of particle flow towards heterogeneous computing platforms such as GPUs using a graph neural network. The machine-learned PF model reconstructs particle candidates based on the full list of tracks and calorimeter clusters in the event. For validation, we determine the physics performance directly in the CMS software framework when the proposed algorithm is interfaced with the offline reconstruction of jets and missing transverse energy. We also report the computational performance of the algorithm, which scales approximately linearly in runtime and memory usage with the input size.", "paper_url": "http://arxiv.org/abs/2203.00330v1", "pdf_url": "http://arxiv.org/pdf/2203.00330v1", "repo_url": null}, "2203.00199": {"publish_time": "2022-03-01", "title": "Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks", "author": "Haorui Wang et.al.", "abstract": "Graph neural networks (GNN) have shown great advantages in many graph-based learning tasks but often fail to predict accurately for a task-based on sets of nodes such as link/motif prediction and so on. Many works have recently proposed to address this problem by using random node features or node distance features. However, they suffer from either slow convergence, inaccurate prediction, or high complexity. In this work, we revisit GNNs that allow using positional features of nodes given by positional encoding (PE) techniques such as Laplacian Eigenmap, Deepwalk, etc. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable. Here, we study these issues in a principled way and propose a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. PEG uses separate channels to update the original node features and positional features. PEG imposes permutation equivariance w.r.t. the original node features and rotation equivariance w.r.t. the positional features simultaneously. Extensive link prediction experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability.", "paper_url": "http://arxiv.org/abs/2203.00199v1", "pdf_url": "http://arxiv.org/pdf/2203.00199v1", "repo_url": "https://github.com/graph-com/peg"}, "2203.01189": {"publish_time": "2022-03-02", "title": "GNN-based end-to-end reconstruction in the CMS Phase 2 High-Granularity Calorimeter", "author": "Saptaparna Bhattacharya et.al.", "abstract": "We present the current stage of research progress towards a one-pass, completely Machine Learning (ML) based imaging calorimeter reconstruction. The model used is based on Graph Neural Networks (GNNs) and directly analyzes the hits in each HGCAL endcap. The ML algorithm is trained to predict clusters of hits originating from the same incident particle by labeling the hits with the same cluster index. We impose simple criteria to assess whether the hits associated as a cluster by the prediction are matched to those hits resulting from any particular individual incident particles. The algorithm is studied by simulating two tau leptons in each of the two HGCAL endcaps, where each tau may decay according to its measured standard model branching probabilities. The simulation includes the material interaction of the tau decay products which may create additional particles incident upon the calorimeter. Using this varied multiparticle environment we can investigate the application of this reconstruction technique and begin to characterize energy containment and performance.", "paper_url": "http://arxiv.org/abs/2203.01189v1", "pdf_url": "http://arxiv.org/pdf/2203.01189v1", "repo_url": null}, "2203.01187": {"publish_time": "2022-03-02", "title": "Visual Feature Encoding for GNNs on Road Networks", "author": "Oliver Stromann et.al.", "abstract": "In this work, we present a novel approach to learning an encoding of visual features into graph neural networks with the application on road network data. We propose an architecture that combines state-of-the-art vision backbone networks with graph neural networks. More specifically, we perform a road type classification task on an Open Street Map road network through encoding of satellite imagery using various ResNet architectures. Our architecture further enables fine-tuning and a transfer-learning approach is evaluated by pretraining on the NWPU-RESISC45 image classification dataset for remote sensing and comparing them to purely ImageNet-pretrained ResNet models as visual feature encoders. The results show not only that the visual feature encoders are superior to low-level visual features, but also that the fine-tuning of the visual feature encoder to a general remote sensing dataset such as NWPU-RESISC45 can further improve the performance of a GNN on a machine learning task like road type classification.", "paper_url": "http://arxiv.org/abs/2203.01187v1", "pdf_url": "http://arxiv.org/pdf/2203.01187v1", "repo_url": null}, "2203.01112": {"publish_time": "2022-03-02", "title": "Hyperparameter optimization of data-driven AI models on HPC systems", "author": "Eric Wulff et.al.", "abstract": "In the European Center of Excellence in Exascale computing \"Research on AI- and Simulation-Based Engineering at Exascale\" (CoE RAISE), researchers develop novel, scalable AI technologies towards Exascale. This work exercises High Performance Computing resources to perform large-scale hyperparameter optimization using distributed training on multiple compute nodes. This is part of RAISE's work on data-driven use cases which leverages AI- and HPC cross-methods developed within the project. In response to the demand for parallelizable and resource efficient hyperparameter optimization methods, advanced hyperparameter search algorithms are benchmarked and compared. The evaluated algorithms, including Random Search, Hyperband and ASHA, are tested and compared in terms of both accuracy and accuracy per compute resources spent. As an example use case, a graph neural network model known as MLPF, developed for the task of Machine-Learned Particle-Flow reconstruction in High Energy Physics, acts as the base model for optimization. Results show that hyperparameter optimization significantly increased the performance of MLPF and that this would not have been possible without access to large-scale High Performance Computing resources. It is also shown that, in the case of MLPF, the ASHA algorithm in combination with Bayesian optimization gives the largest performance increase per compute resources spent out of the investigated algorithms.", "paper_url": "http://arxiv.org/abs/2203.01112v1", "pdf_url": "http://arxiv.org/pdf/2203.01112v1", "repo_url": null}, "2203.01093": {"publish_time": "2022-03-02", "title": "Information Gain Propagation: a new way to Graph Active Learning with Soft Labels", "author": "Wentao Zhang et.al.", "abstract": "Graph Neural Networks (GNNs) have achieved great success in various tasks, but their performance highly relies on a large number of labeled nodes, which typically requires considerable human effort. GNN-based Active Learning (AL) methods are proposed to improve the labeling efficiency by selecting the most valuable nodes to label. Existing methods assume an oracle can correctly categorize all the selected nodes and thus just focus on the node selection. However, such an exact labeling task is costly, especially when the categorization is out of the domain of individual expert (oracle). The paper goes further, presenting a soft-label approach to AL on GNNs. Our key innovations are: i) relaxed queries where a domain expert (oracle) only judges the correctness of the predicted labels (a binary question) rather than identifying the exact class (a multi-class question), and ii) new criteria of maximizing information gain propagation for active learner with relaxed queries and soft labels. Empirical studies on public datasets demonstrate that our method significantly outperforms the state-of-the-art GNN-based AL methods in terms of both accuracy and labeling cost.", "paper_url": "http://arxiv.org/abs/2203.01093v1", "pdf_url": "http://arxiv.org/pdf/2203.01093v1", "repo_url": "https://github.com/zwt233/igp"}, "2203.00949": {"publish_time": "2022-03-02", "title": "GAP: Differentially Private Graph Neural Networks with Aggregation Perturbation", "author": "Sina Sajadmanesh et.al.", "abstract": "Graph Neural Networks (GNNs) are powerful models designed for graph data that learn node representation by recursively aggregating information from each node's local neighborhood. However, despite their state-of-the-art performance in predictive graph-based applications, recent studies have shown that GNNs can raise significant privacy concerns when graph data contain sensitive information. As a result, in this paper, we study the problem of learning GNNs with Differential Privacy (DP). We propose GAP, a novel differentially private GNN that safeguards the privacy of nodes and edges using aggregation perturbation, i.e., adding calibrated stochastic noise to the output of the GNN's aggregation function, which statistically obfuscates the presence of a single edge (edge-level privacy) or a single node and all its adjacent edges (node-level privacy). To circumvent the accumulation of privacy cost at every forward pass of the model, we tailor the GNN architecture to the specifics of private learning. In particular, we first precompute private aggregations by recursively applying neighborhood aggregation and perturbing the output of each aggregation step. Then, we privately train a deep neural network on the resulting perturbed aggregations for any node-wise classification task. A major advantage of GAP over previous approaches is that we guarantee edge-level and node-level DP not only for training, but also at inference time with no additional costs beyond the training's privacy budget. We theoretically analyze the formal privacy guarantees of GAP using R\\'enyi DP. Empirical experiments conducted over three real-world graph datasets demonstrate that GAP achieves a favorable privacy-accuracy trade-off and significantly outperforms existing approaches.", "paper_url": "http://arxiv.org/abs/2203.00949v1", "pdf_url": "http://arxiv.org/pdf/2203.00949v1", "repo_url": null}}}}