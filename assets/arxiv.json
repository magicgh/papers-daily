{"Computer Vision": {"Computer Vision": {"2202.12884": {"publish_time": "2022-02-25", "title": "Learning to Identify Perceptual Bugs in 3D Video Games", "author": "Benedict Wilkins et.al.", "abstract": "Automated Bug Detection (ABD) in video games is composed of two distinct but complementary problems: automated game exploration and bug identification. Automated game exploration has received much recent attention, spurred on by developments in fields such as reinforcement learning. The complementary problem of identifying the bugs present in a player's experience has for the most part relied on the manual specification of rules. Although it is widely recognised that many bugs of interest cannot be identified with such methods, little progress has been made in this direction. In this work we show that it is possible to identify a range of perceptual bugs using learning-based methods by making use of only the rendered game screen as seen by the player. To support our work, we have developed World of Bugs (WOB) an open platform for testing ABD methods in 3D game environments.", "paper_url": "http://arxiv.org/abs/2202.12884v1", "pdf_url": "http://arxiv.org/pdf/2202.12884v1", "repo_url": null}, "2202.12860": {"publish_time": "2022-02-25", "title": "ARIA: Adversarially Robust Image Attribution for Content Provenance", "author": "Maksym Andriushchenko et.al.", "abstract": "Image attribution -- matching an image back to a trusted source -- is an emerging tool in the fight against online misinformation. Deep visual fingerprinting models have recently been explored for this purpose. However, they are not robust to tiny input perturbations known as adversarial examples. First we illustrate how to generate valid adversarial images that can easily cause incorrect image attribution. Then we describe an approach to prevent imperceptible adversarial attacks on deep visual fingerprinting models, via robust contrastive learning. The proposed training procedure leverages training on $\\ell_\\infty$-bounded adversarial examples, it is conceptually simple and incurs only a small computational overhead. The resulting models are substantially more robust, are accurate even on unperturbed images, and perform well even over a database with millions of images. In particular, we achieve 91.6% standard and 85.1% adversarial recall under $\\ell_\\infty$-bounded perturbations on manipulated images compared to 80.1% and 0.0% from prior work. We also show that robustness generalizes to other types of imperceptible perturbations unseen during training. Finally, we show how to train an adversarially robust image comparator model for detecting editorial changes in matched images.", "paper_url": "http://arxiv.org/abs/2202.12860v1", "pdf_url": "http://arxiv.org/pdf/2202.12860v1", "repo_url": null}, "2202.12838": {"publish_time": "2022-02-25", "title": "RELMOBNET: A Robust Two-Stage End-To-End Training Approach For MOBILENETV3 Based Relative Camera Pose Estimation", "author": "Praveen Kumar Rajendran et.al.", "abstract": "Relative camera pose estimation plays a pivotal role in dealing with 3D reconstruction and visual localization. To address this, we propose a Siamese network based on MobileNetV3-Large for an end-to-end relative camera pose regression independent of camera parameters. The proposed network uses pair of images taken at different locations in the same scene to estimate the 3D translation vector and rotation vector in unit quaternion. To increase the generality of the model, rather than training it for a single scene, data for four scenes are combined to train a single universal model to estimate the relative pose. Further for independency of hyperparameter weighing between translation and rotation loss is not used. Instead we use the novel two-stage training procedure to learn the balance implicitly with faster convergence. We compare the results obtained with the Cambridge Landmarks dataset, comprising of different scenes, with existing CNN-based regression methods as baselines, e.g., RPNet and RCPNet. The findings indicate that, when compared to RCPNet, proposed model improves the estimation of the translation vector by a percentage change of 16.11%, 28.88%, 52.27% on the Kings College, Old Hospital, St Marys Church scenes from Cambridge Landmarks dataset, respectively.", "paper_url": "http://arxiv.org/abs/2202.12838v1", "pdf_url": "http://arxiv.org/pdf/2202.12838v1", "repo_url": null}, "2202.12825": {"publish_time": "2022-02-25", "title": "NeuralFusion: Neural Volumetric Rendering under Human-object Interactions", "author": "Yuheng Jiang et.al.", "abstract": "4D reconstruction and rendering of human activities is critical for immersive VR/AR experience. Recent advances still fail to recover fine geometry and texture results with the level of detail present in the input images from sparse multi-view RGB cameras. In this paper, we propose NeuralHumanFVV, a real-time neural human performance capture and rendering system to generate both high-quality geometry and photo-realistic texture of human activities in arbitrary novel views. We propose a neural geometry generation scheme with a hierarchical sampling strategy for real-time implicit geometry inference, as well as a novel neural blending scheme to generate high resolution (e.g., 1k) and photo-realistic texture results in the novel views. Furthermore, we adopt neural normal blending to enhance geometry details and formulate our neural geometry and texture rendering into a multi-task learning framework. Extensive experiments demonstrate the effectiveness of our approach to achieve high-quality geometry and photo-realistic free view-point reconstruction for challenging human performances.", "paper_url": "http://arxiv.org/abs/2202.12825v1", "pdf_url": "http://arxiv.org/pdf/2202.12825v1", "repo_url": null}, "2202.12818": {"publish_time": "2022-02-25", "title": "Improving generalization with synthetic training data for deep learning based quality inspection", "author": "Antoine Cordier et.al.", "abstract": "Automating quality inspection with computer vision techniques is often a very data-demanding task. Specifically, supervised deep learning requires a large amount of annotated images for training. In practice, collecting and annotating such data is not only costly and laborious, but also inefficient, given the fact that only a few instances may be available for certain defect classes. If working with video frames can increase the number of these instances, it has a major disadvantage: the resulting images will be highly correlated with one another. As a consequence, models trained under such constraints are expected to be very sensitive to input distribution changes, which may be caused in practice by changes in the acquisition system (cameras, lights), in the parts or in the defects aspect. In this work, we demonstrate the use of randomly generated synthetic training images can help tackle domain instability issues, making the trained models more robust to contextual changes. We detail both our synthetic data generation pipeline and our deep learning methodology for answering these questions.", "paper_url": "http://arxiv.org/abs/2202.12818v1", "pdf_url": "http://arxiv.org/pdf/2202.12818v1", "repo_url": null}, "2202.14034": {"publish_time": "2022-02-28", "title": "Attribute Descent: Simulating Object-Centric Datasets on the Content Level and Beyond", "author": "Yue Yao et.al.", "abstract": "This article aims to use graphic engines to simulate a large number of training data that have free annotations and possibly strongly resemble to real-world data. Between synthetic and real, a two-level domain gap exists, involving content level and appearance level. While the latter is concerned with appearance style, the former problem arises from a different mechanism, i.e., content mismatch in attributes such as camera viewpoint, object placement and lighting conditions. In contrast to the widely-studied appearance-level gap, the content-level discrepancy has not been broadly studied. To address the content-level misalignment, we propose an attribute descent approach that automatically optimizes engine attributes to enable synthetic data to approximate real-world data. We verify our method on object-centric tasks, wherein an object takes up a major portion of an image. In these tasks, the search space is relatively small, and the optimization of each attribute yields sufficiently obvious supervision signals. We collect a new synthetic asset VehicleX, and reformat and reuse existing the synthetic assets ObjectX and PersonX. Extensive experiments on image classification and object re-identification confirm that adapted synthetic data can be effectively used in three scenarios: training with synthetic data only, training data augmentation and numerically understanding dataset content.", "paper_url": "http://arxiv.org/abs/2202.14034v1", "pdf_url": "http://arxiv.org/pdf/2202.14034v1", "repo_url": null}, "2202.14030": {"publish_time": "2022-02-28", "title": "Learning Semantic Segmentation from Multiple Datasets with Label Shifts", "author": "Dongwan Kim et.al.", "abstract": "With increasing applications of semantic segmentation, numerous datasets have been proposed in the past few years. Yet labeling remains expensive, thus, it is desirable to jointly train models across aggregations of datasets to enhance data volume and diversity. However, label spaces differ across datasets and may even be in conflict with one another. This paper proposes UniSeg, an effective approach to automatically train models across multiple datasets with differing label spaces, without any manual relabeling efforts. Specifically, we propose two losses that account for conflicting and co-occurring labels to achieve better generalization performance in unseen domains. First, a gradient conflict in training due to mismatched label spaces is identified and a class-independent binary cross-entropy loss is proposed to alleviate such label conflicts. Second, a loss function that considers class-relationships across datasets is proposed for a better multi-dataset training scheme. Extensive quantitative and qualitative analyses on road-scene datasets show that UniSeg improves over multi-dataset baselines, especially on unseen datasets, e.g., achieving more than 8% gain in IoU on KITTI averaged over all the settings.", "paper_url": "http://arxiv.org/abs/2202.14030v1", "pdf_url": "http://arxiv.org/pdf/2202.14030v1", "repo_url": null}, "2202.14026": {"publish_time": "2022-02-28", "title": "Robust Training under Label Noise by Over-parameterization", "author": "Sheng Liu et.al.", "abstract": "Recently, over-parameterized deep networks, with increasingly more network parameters than training samples, have dominated the performances of modern machine learning. However, when the training data is corrupted, it has been well-known that over-parameterized networks tend to overfit and do not generalize. In this work, we propose a principled approach for robust training of over-parameterized deep networks in classification tasks where a proportion of training labels are corrupted. The main idea is yet very simple: label noise is sparse and incoherent with the network learned from clean data, so we model the noise and learn to separate it from the data. Specifically, we model the label noise via another sparse over-parameterization term, and exploit implicit algorithmic regularizations to recover and separate the underlying corruptions. Remarkably, when trained using such a simple method in practice, we demonstrate state-of-the-art test accuracy against label noise on a variety of real datasets. Furthermore, our experimental results are corroborated by theory on simplified linear models, showing that exact separation between sparse noise and low-rank data can be achieved under incoherent conditions. The work opens many interesting directions for improving over-parameterized models by using sparse over-parameterization and implicit regularization.", "paper_url": "http://arxiv.org/abs/2202.14026v1", "pdf_url": "http://arxiv.org/pdf/2202.14026v1", "repo_url": "https://github.com/shengliu66/sop"}, "2202.14020": {"publish_time": "2022-02-28", "title": "State-of-the-Art in the Architecture, Methods and Applications of StyleGAN", "author": "Amit H. Bermano et.al.", "abstract": "Generative Adversarial Networks (GANs) have established themselves as a prevalent approach to image synthesis. Of these, StyleGAN offers a fascinating case study, owing to its remarkable visual quality and an ability to support a large array of downstream tasks. This state-of-the-art report covers the StyleGAN architecture, and the ways it has been employed since its conception, while also analyzing its severe limitations. It aims to be of use for both newcomers, who wish to get a grasp of the field, and for more experienced readers that might benefit from seeing current research trends and existing tools laid out. Among StyleGAN's most interesting aspects is its learned latent space. Despite being learned with no supervision, it is surprisingly well-behaved and remarkably disentangled. Combined with StyleGAN's visual quality, these properties gave rise to unparalleled editing capabilities. However, the control offered by StyleGAN is inherently limited to the generator's learned distribution, and can only be applied to images generated by StyleGAN itself. Seeking to bring StyleGAN's latent control to real-world scenarios, the study of GAN inversion and latent space embedding has quickly gained in popularity. Meanwhile, this same study has helped shed light on the inner workings and limitations of StyleGAN. We map out StyleGAN's impressive story through these investigations, and discuss the details that have made StyleGAN the go-to generator. We further elaborate on the visual priors StyleGAN constructs, and discuss their use in downstream discriminative tasks. Looking forward, we point out StyleGAN's limitations and speculate on current trends and promising directions for future research, such as task and target specific fine-tuning.", "paper_url": "http://arxiv.org/abs/2202.14020v1", "pdf_url": "http://arxiv.org/pdf/2202.14020v1", "repo_url": null}, "2202.14019": {"publish_time": "2022-02-28", "title": "Domain Knowledge-Informed Self-Supervised Representations for Workout Form Assessment", "author": "Paritosh Parmar et.al.", "abstract": "Maintaining proper form while exercising is important for preventing injuries and maximizing muscle mass gains. While fitness apps are becoming popular, they lack the functionality to detect errors in workout form. Detecting such errors naturally requires estimating users' body pose. However, off-the-shelf pose estimators struggle to perform well on the videos recorded in gym scenarios due to factors such as camera angles, occlusion from gym equipment, illumination, and clothing. To aggravate the problem, the errors to be detected in the workouts are very subtle. To that end, we propose to learn exercise-specific representations from unlabeled samples such that a small dataset annotated by experts suffices for supervised error detection. In particular, our domain knowledge-informed self-supervised approaches exploit the harmonic motion of the exercise actions, and capitalize on the large variances in camera angles, clothes, and illumination to learn powerful representations. To facilitate our self-supervised pretraining, and supervised finetuning, we curated a new exercise dataset, Fitness-AQA, comprising of three exercises: BackSquat, BarbellRow, and OverheadPress. It has been annotated by expert trainers for multiple crucial and typically occurring exercise errors. Experimental results show that our self-supervised representations outperform off-the-shelf 2D- and 3D-pose estimators and several other baselines.", "paper_url": "http://arxiv.org/abs/2202.14019v1", "pdf_url": "http://arxiv.org/pdf/2202.14019v1", "repo_url": null}, "2203.00680": {"publish_time": "2022-03-01", "title": "CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding", "author": "Mohamed Afham et.al.", "abstract": "Manual annotation of large-scale point cloud dataset for varying tasks such as 3D object classification, segmentation and detection is often laborious owing to the irregular structure of point clouds. Self-supervised learning, which operates without any human labeling, is a promising approach to address this issue. We observe in the real world that humans are capable of mapping the visual concepts learnt from 2D images to understand the 3D world. Encouraged by this insight, we propose CrossPoint, a simple cross-modal contrastive learning approach to learn transferable 3D point cloud representations. It enables a 3D-2D correspondence of objects by maximizing agreement between point clouds and the corresponding rendered 2D image in the invariant space, while encouraging invariance to transformations in the point cloud modality. Our joint training objective combines the feature correspondences within and across modalities, thus ensembles a rich learning signal from both 3D point cloud and 2D image modalities in a self-supervised fashion. Experimental results show that our approach outperforms the previous unsupervised learning methods on a diverse range of downstream tasks including 3D object classification and segmentation. Further, the ablation studies validate the potency of our approach for a better point cloud understanding. Code and pretrained models are available at http://github.com/MohamedAfham/CrossPoint.", "paper_url": "http://arxiv.org/abs/2203.00680v1", "pdf_url": "http://arxiv.org/pdf/2203.00680v1", "repo_url": "https://github.com/mohamedafham/crosspoint"}, "2203.00672": {"publish_time": "2022-03-01", "title": "Generalizable Person Re-Identification via Self-Supervised Batch Norm Test-Time Adaption", "author": "Ke Han et.al.", "abstract": "In this paper, we investigate the generalization problem of person re-identification (re-id), whose major challenge is the distribution shift on an unseen domain. As an important tool of regularizing the distribution, batch normalization (BN) has been widely used in existing methods. However, they neglect that BN is severely biased to the training domain and inevitably suffers the performance drop if directly generalized without being updated. To tackle this issue, we propose Batch Norm Test-time Adaption (BNTA), a novel re-id framework that applies the self-supervised strategy to update BN parameters adaptively. Specifically, BNTA quickly explores the domain-aware information within unlabeled target data before inference, and accordingly modulates the feature distribution normalized by BN to adapt to the target domain. This is accomplished by two designed self-supervised auxiliary tasks, namely part positioning and part nearest neighbor matching, which help the model mine the domain-aware information with respect to the structure and identity of body parts, respectively. To demonstrate the effectiveness of our method, we conduct extensive experiments on three re-id datasets and confirm the superior performance to the state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2203.00672v1", "pdf_url": "http://arxiv.org/pdf/2203.00672v1", "repo_url": null}, "2203.00667": {"publish_time": "2022-03-01", "title": "Generative Adversarial Networks", "author": "Gilad Cohen et.al.", "abstract": "Generative Adversarial Networks (GANs) are very popular frameworks for generating high-quality data, and are immensely used in both the academia and industry in many domains. Arguably, their most substantial impact has been in the area of computer vision, where they achieve state-of-the-art image generation. This chapter gives an introduction to GANs, by discussing their principle mechanism and presenting some of their inherent problems during training and evaluation. We focus on these three issues: (1) mode collapse, (2) vanishing gradients, and (3) generation of low-quality images. We then list some architecture-variant and loss-variant GANs that remedy the above challenges. Lastly, we present two utilization examples of GANs for real-world applications: Data augmentation and face images generation.", "paper_url": "http://arxiv.org/abs/2203.00667v1", "pdf_url": "http://arxiv.org/pdf/2203.00667v1", "repo_url": null}, "2203.00645": {"publish_time": "2022-03-01", "title": "Variational Autoencoders Without the Variation", "author": "Gregory A. Daly et.al.", "abstract": "Variational autoencdoers (VAE) are a popular approach to generative modelling. However, exploiting the capabilities of VAEs in practice can be difficult. Recent work on regularised and entropic autoencoders have begun to explore the potential, for generative modelling, of removing the variational approach and returning to the classic deterministic autoencoder (DAE) with additional novel regularisation methods. In this paper we empirically explore the capability of DAEs for image generation without additional novel methods and the effect of the implicit regularisation and smoothness of large networks. We find that DAEs can be used successfully for image generation without additional loss terms, and that many of the useful properties of VAEs can arise implicitly from sufficiently large convolutional encoders and decoders when trained on CIFAR-10 and CelebA.", "paper_url": "http://arxiv.org/abs/2203.00645v1", "pdf_url": "http://arxiv.org/pdf/2203.00645v1", "repo_url": null}, "2203.00641": {"publish_time": "2022-03-01", "title": "Multi-Task Multi-Scale Learning For Outcome Prediction in 3D PET Images", "author": "Amine Amyar et.al.", "abstract": "Background and Objectives: Predicting patient response to treatment and survival in oncology is a prominent way towards precision medicine. To that end, radiomics was proposed as a field of study where images are used instead of invasive methods. The first step in radiomic analysis is the segmentation of the lesion. However, this task is time consuming and can be physician subjective. Automated tools based on supervised deep learning have made great progress to assist physicians. However, they are data hungry, and annotated data remains a major issue in the medical field where only a small subset of annotated images is available. Methods: In this work, we propose a multi-task learning framework to predict patient's survival and response. We show that the encoder can leverage multiple tasks to extract meaningful and powerful features that improve radiomics performance. We show also that subsidiary tasks serve as an inductive bias so that the model can better generalize. Results: Our model was tested and validated for treatment response and survival in lung and esophageal cancers, with an area under the ROC curve of 77% and 71% respectively, outperforming single task learning methods. Conclusions: We show that, by using a multi-task learning approach, we can boost the performance of radiomic analysis by extracting rich information of intratumoral and peritumoral regions.", "paper_url": "http://arxiv.org/abs/2203.00641v1", "pdf_url": "http://arxiv.org/pdf/2203.00641v1", "repo_url": null}, "2203.01318": {"publish_time": "2022-03-02", "title": "Protecting Celebrities with Identity Consistency Transformer", "author": "Xiaoyi Dong et.al.", "abstract": "In this work we propose Identity Consistency Transformer, a novel face forgery detection method that focuses on high-level semantics, specifically identity information, and detecting a suspect face by finding identity inconsistency in inner and outer face regions. The Identity Consistency Transformer incorporates a consistency loss for identity consistency determination. We show that Identity Consistency Transformer exhibits superior generalization ability not only across different datasets but also across various types of image degradation forms found in real-world applications including deepfake videos. The Identity Consistency Transformer can be easily enhanced with additional identity information when such information is available, and for this reason it is especially well-suited for detecting face forgeries involving celebrities.", "paper_url": "http://arxiv.org/abs/2203.01318v1", "pdf_url": "http://arxiv.org/pdf/2203.01318v1", "repo_url": null}, "2203.01311": {"publish_time": "2022-03-02", "title": "HighMMT: Towards Modality and Task Generalization for High-Modality Representation Learning", "author": "Paul Pu Liang et.al.", "abstract": "Learning multimodal representations involves discovering correspondences and integrating information from multiple heterogeneous sources of data. While recent research has begun to explore the design of more general-purpose multimodal models (contrary to prior focus on domain and modality-specific architectures), these methods are still largely focused on a small set of modalities in the language, vision, and audio space. In order to accelerate generalization towards diverse and understudied modalities, we investigate methods for high-modality (a large set of diverse modalities) and partially-observable (each task only defined on a small subset of modalities) scenarios. To tackle these challenges, we design a general multimodal model that enables multitask and transfer learning: multitask learning with shared parameters enables stable parameter counts (addressing scalability), and cross-modal transfer learning enables information sharing across modalities and tasks (addressing partial observability). Our resulting model generalizes across text, image, video, audio, time-series, sensors, tables, and set modalities from different research areas, improves the tradeoff between performance and efficiency, transfers to new modalities and tasks, and reveals surprising insights on the nature of information sharing in multitask models. We release our code and benchmarks which we hope will present a unified platform for subsequent theoretical and empirical analysis: https://github.com/pliang279/HighMMT.", "paper_url": "http://arxiv.org/abs/2203.01311v1", "pdf_url": "http://arxiv.org/pdf/2203.01311v1", "repo_url": null}, "2203.01305": {"publish_time": "2022-03-02", "title": "DN-DETR: Accelerate DETR Training by Introducing Query DeNoising", "author": "Feng Li et.al.", "abstract": "We present in this paper a novel denoising training method to speedup DETR (DEtection TRansformer) training and offer a deepened understanding of the slow convergence issue of DETR-like methods. We show that the slow convergence results from the instability of bipartite graph matching which causes inconsistent optimization goals in early training stages. To address this issue, except for the Hungarian loss, our method additionally feeds ground-truth bounding boxes with noises into Transformer decoder and trains the model to reconstruct the original boxes, which effectively reduces the bipartite graph matching difficulty and leads to a faster convergence. Our method is universal and can be easily plugged into any DETR-like methods by adding dozens of lines of code to achieve a remarkable improvement. As a result, our DN-DETR results in a remarkable improvement ($+1.9$AP) under the same setting and achieves the best result (AP $43.4$ and $48.6$ with $12$ and $50$ epochs of training respectively) among DETR-like methods with ResNet-$50$ backbone. Compared with the baseline under the same setting, DN-DETR achieves comparable performance with $50\\%$ training epochs. Code is available at \\url{https://github.com/FengLi-ust/DN-DETR}.", "paper_url": "http://arxiv.org/abs/2203.01305v1", "pdf_url": "http://arxiv.org/pdf/2203.01305v1", "repo_url": null}, "2203.01296": {"publish_time": "2022-03-02", "title": "Half Wavelet Attention on M-Net+ for Low-Light Image Enhancement", "author": "Chi-Mao Fan et.al.", "abstract": "Low-Light Image Enhancement is a computer vision task which intensifies the dark images to appropriate brightness. It can also be seen as an ill-posed problem in image restoration domain. With the success of deep neural networks, the convolutional neural networks surpass the traditional algorithm-based methods and become the mainstream in the computer vision area. To advance the performance of enhancement algorithms, we propose an image enhancement network (HWMNet) based on an improved hierarchical model: M-Net+. Specifically, we use a half wavelet attention block on M-Net+ to enrich the features from wavelet domain. Furthermore, our HWMNet has competitive performance results on two image enhancement datasets in terms of quantitative metrics and visual quality. The source code and pretrained model are available at https://github.com/FanChiMao/HWMNet.", "paper_url": "http://arxiv.org/abs/2203.01296v1", "pdf_url": "http://arxiv.org/pdf/2203.01296v1", "repo_url": "https://github.com/fanchimao/hwmnet"}, "2203.01289": {"publish_time": "2022-03-02", "title": "ADVISE: ADaptive Feature Relevance and VISual Explanations for Convolutional Neural Networks", "author": "Mohammad Mahdi Dehshibi et.al.", "abstract": "To equip Convolutional Neural Networks (CNNs) with explainability, it is essential to interpret how opaque models take specific decisions, understand what causes the errors, improve the architecture design, and identify unethical biases in the classifiers. This paper introduces ADVISE, a new explainability method that quantifies and leverages the relevance of each unit of the feature map to provide better visual explanations. To this end, we propose using adaptive bandwidth kernel density estimation to assign a relevance score to each unit of the feature map with respect to the predicted class. We also propose an evaluation protocol to quantitatively assess the visual explainability of CNN models. We extensively evaluate our idea in the image classification task using AlexNet, VGG16, ResNet50, and Xception pretrained on ImageNet. We compare ADVISE with the state-of-the-art visual explainable methods and show that the proposed method outperforms competing approaches in quantifying feature-relevance and visual explainability while maintaining competitive time complexity. Our experiments further show that ADVISE fulfils the sensitivity and implementation independence axioms while passing the sanity checks. The implementation is accessible for reproducibility purposes on https://github.com/dehshibi/ADVISE.", "paper_url": "http://arxiv.org/abs/2203.01289v1", "pdf_url": "http://arxiv.org/pdf/2203.01289v1", "repo_url": "https://github.com/dehshibi/advise"}, "2203.01929": {"publish_time": "2022-03-03", "title": "CenterSnap: Single-Shot Multi-Object 3D Shape Reconstruction and Categorical 6D Pose and Size Estimation", "author": "Muhammad Zubair Irshad et.al.", "abstract": "This paper studies the complex task of simultaneous multi-object 3D reconstruction, 6D pose and size estimation from a single-view RGB-D observation. In contrast to instance-level pose estimation, we focus on a more challenging problem where CAD models are not available at inference time. Existing approaches mainly follow a complex multi-stage pipeline which first localizes and detects each object instance in the image and then regresses to either their 3D meshes or 6D poses. These approaches suffer from high-computational cost and low performance in complex multi-object scenarios, where occlusions can be present. Hence, we present a simple one-stage approach to predict both the 3D shape and estimate the 6D pose and size jointly in a bounding-box free manner. In particular, our method treats object instances as spatial centers where each center denotes the complete shape of an object along with its 6D pose and size. Through this per-pixel representation, our approach can reconstruct in real-time (40 FPS) multiple novel object instances and predict their 6D pose and sizes in a single-forward pass. Through extensive experiments, we demonstrate that our approach significantly outperforms all shape completion and categorical 6D pose and size estimation baselines on multi-object ShapeNet and NOCS datasets respectively with a 12.6% absolute improvement in mAP for 6D pose for novel real-world object instances.", "paper_url": "http://arxiv.org/abs/2203.01929v1", "pdf_url": "http://arxiv.org/pdf/2203.01929v1", "repo_url": null}, "2203.01925": {"publish_time": "2022-03-03", "title": "Label-Only Model Inversion Attacks via Boundary Repulsion", "author": "Mostafa Kahla et.al.", "abstract": "Recent studies show that the state-of-the-art deep neural networks are vulnerable to model inversion attacks, in which access to a model is abused to reconstruct private training data of any given target class. Existing attacks rely on having access to either the complete target model (whitebox) or the model's soft-labels (blackbox). However, no prior work has been done in the harder but more practical scenario, in which the attacker only has access to the model's predicted label, without a confidence measure. In this paper, we introduce an algorithm, Boundary-Repelling Model Inversion (BREP-MI), to invert private training data using only the target model's predicted labels. The key idea of our algorithm is to evaluate the model's predicted labels over a sphere and then estimate the direction to reach the target class's centroid. Using the example of face recognition, we show that the images reconstructed by BREP-MI successfully reproduce the semantics of the private training data for various datasets and target model architectures. We compare BREP-MI with the state-of-the-art whitebox and blackbox model inversion attacks and the results show that despite assuming less knowledge about the target model, BREP-MI outperforms the blackbox attack and achieves comparable results to the whitebox attack.", "paper_url": "http://arxiv.org/abs/2203.01925v1", "pdf_url": "http://arxiv.org/pdf/2203.01925v1", "repo_url": null}, "2203.01923": {"publish_time": "2022-03-03", "title": "Recovering 3D Human Mesh from Monocular Images: A Survey", "author": "Yating Tian et.al.", "abstract": "Estimating human pose and shape from monocular images is a long-standing problem in computer vision. Since the release of statistical body models, 3D human mesh recovery has been drawing broader attention. With the same goal of obtaining well-aligned and physically plausible mesh results, two paradigms have been developed to overcome challenges in the 2D-to-3D lifting process: i) an optimization-based paradigm, where different data terms and regularization terms are exploited as optimization objectives; and ii) a regression-based paradigm, where deep learning techniques are embraced to solve the problem in an end-to-end fashion. Meanwhile, continuous efforts are devoted to improving the quality of 3D mesh labels for a wide range of datasets. Though remarkable progress has been achieved in the past decade, the task is still challenging due to flexible body motions, diverse appearances, complex environments, and insufficient in-the-wild annotations. To the best of our knowledge, this is the first survey to focus on the task of monocular 3D human mesh recovery. We start with the introduction of body models, and then introduce recovery frameworks and training objectives by providing in-depth analyses of their strengths and weaknesses. We also summarize datasets, evaluation metrics, and benchmark results. Open issues and future directions are discussed in the end, hoping to motivate researchers and facilitate their research in this area. A regularly updated project page can be found at https://github.com/tinatiansjz/hmr-survey.", "paper_url": "http://arxiv.org/abs/2203.01923v1", "pdf_url": "http://arxiv.org/pdf/2203.01923v1", "repo_url": "https://github.com/tinatiansjz/hmr-survey"}, "2203.01922": {"publish_time": "2022-03-03", "title": "Vision-Language Intelligence: Tasks, Representation Learning, and Large Models", "author": "Feng Li et.al.", "abstract": "This paper presents a comprehensive survey of vision-language (VL) intelligence from the perspective of time. This survey is inspired by the remarkable progress in both computer vision and natural language processing, and recent trends shifting from single modality processing to multiple modality comprehension. We summarize the development in this field into three time periods, namely task-specific methods, vision-language pre-training (VLP) methods, and larger models empowered by large-scale weakly-labeled data. We first take some common VL tasks as examples to introduce the development of task-specific methods. Then we focus on VLP methods and comprehensively review key components of the model structures and training methods. After that, we show how recent work utilizes large-scale raw image-text data to learn language-aligned visual representations that generalize better on zero or few shot learning tasks. Finally, we discuss some potential future trends towards modality cooperation, unified representation, and knowledge incorporation. We believe that this review will be of help for researchers and practitioners of AI and ML, especially those interested in computer vision and natural language processing.", "paper_url": "http://arxiv.org/abs/2203.01922v1", "pdf_url": "http://arxiv.org/pdf/2203.01922v1", "repo_url": null}, "2203.01921": {"publish_time": "2022-03-03", "title": "NUQ: A Noise Metric for Diffusion MRI via Uncertainty Discrepancy Quantification", "author": "Shreyas Fadnavis et.al.", "abstract": "Diffusion MRI (dMRI) is the only non-invasive technique sensitive to tissue micro-architecture, which can, in turn, be used to reconstruct tissue microstructure and white matter pathways. The accuracy of such tasks is hampered by the low signal-to-noise ratio in dMRI. Today, the noise is characterized mainly by visual inspection of residual maps and estimated standard deviation. However, it is hard to estimate the impact of noise on downstream tasks based only on such qualitative assessments. To address this issue, we introduce a novel metric, Noise Uncertainty Quantification (NUQ), for quantitative image quality analysis in the absence of a ground truth reference image. NUQ uses a recent Bayesian formulation of dMRI models to estimate the uncertainty of microstructural measures. Specifically, NUQ uses the maximum mean discrepancy metric to compute a pooled quality score by comparing samples drawn from the posterior distribution of the microstructure measures. We show that NUQ allows a fine-grained analysis of noise, capturing details that are visually imperceptible. We perform qualitative and quantitative comparisons on real datasets, showing that NUQ generates consistent scores across different denoisers and acquisitions. Lastly, by using NUQ on a cohort of schizophrenics and controls, we quantify the substantial impact of denoising on group differences.", "paper_url": "http://arxiv.org/abs/2203.01921v1", "pdf_url": "http://arxiv.org/pdf/2203.01921v1", "repo_url": null}, "2203.02503": {"publish_time": "2022-03-04", "title": "HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening", "author": "Wele Gedara Chaminda Bandara et.al.", "abstract": "Pansharpening aims to fuse a registered high-resolution panchromatic image (PAN) with a low-resolution hyperspectral image (LR-HSI) to generate an enhanced HSI with high spectral and spatial resolution. Existing pansharpening approaches neglect using an attention mechanism to transfer HR texture features from PAN to LR-HSI features, resulting in spatial and spectral distortions. In this paper, we present a novel attention mechanism for pansharpening called HyperTransformer, in which features of LR-HSI and PAN are formulated as queries and keys in a transformer, respectively. HyperTransformer consists of three main modules, namely two separate feature extractors for PAN and HSI, a multi-head feature soft attention module, and a spatial-spectral feature fusion module. Such a network improves both spatial and spectral quality measures of the pansharpened HSI by learning cross-feature space dependencies and long-range details of PAN and LR-HSI. Furthermore, HyperTransformer can be utilized across multiple spatial scales at the backbone for obtaining improved performance. Extensive experiments conducted on three widely used datasets demonstrate that HyperTransformer achieves significant improvement over the state-of-the-art methods on both spatial and spectral quality measures. Implementation code and pre-trained weights can be accessed at https://github.com/wgcban/HyperTransformer.", "paper_url": "http://arxiv.org/abs/2203.02503v1", "pdf_url": "http://arxiv.org/pdf/2203.02503v1", "repo_url": "https://github.com/wgcban/HyperTransformer"}, "2203.02489": {"publish_time": "2022-03-04", "title": "Pedestrian Stop and Go Forecasting with Hybrid Feature Fusion", "author": "Dongxu Guo et.al.", "abstract": "Forecasting pedestrians' future motions is essential for autonomous driving systems to safely navigate in urban areas. However, existing prediction algorithms often overly rely on past observed trajectories and tend to fail around abrupt dynamic changes, such as when pedestrians suddenly start or stop walking. We suggest that predicting these highly non-linear transitions should form a core component to improve the robustness of motion prediction algorithms. In this paper, we introduce the new task of pedestrian stop and go forecasting. Considering the lack of suitable existing datasets for it, we release TRANS, a benchmark for explicitly studying the stop and go behaviors of pedestrians in urban traffic. We build it from several existing datasets annotated with pedestrians' walking motions, in order to have various scenarios and behaviors. We also propose a novel hybrid model that leverages pedestrian-specific and scene features from several modalities, both video sequences and high-level attributes, and gradually fuses them to integrate multiple levels of context. We evaluate our model and several baselines on TRANS, and set a new benchmark for the community to work on pedestrian stop and go forecasting.", "paper_url": "http://arxiv.org/abs/2203.02489v1", "pdf_url": "http://arxiv.org/pdf/2203.02489v1", "repo_url": null}, "2203.02488": {"publish_time": "2022-03-04", "title": "Behavioural Curves Analysis Using Near-Infrared-Iris Image Sequences", "author": "L. Causa et.al.", "abstract": "This paper proposes a new method to estimate behavioural curves from a stream of Near-Infra-Red (NIR) iris video frames. This method can be used in a Fitness For Duty system (FFD). The research focuses on determining the effect of external factors such as alcohol, drugs, and sleepiness on the Central Nervous System (CNS). The aim is to analyse how this behaviour is represented on iris and pupil movements and if it is possible to capture these changes with a standard NIR camera. The behaviour analysis showed essential differences in pupil and iris behaviour to classify the workers in \"Fit\" or \"Unfit\" conditions. The best results can distinguish subjects robustly under alcohol, drug consumption, and sleep conditions. The Multi-Layer-Perceptron and Gradient Boosted Machine reached the best results in all groups with an overall accuracy for Fit and Unfit classes of 74.0% and 75.5%, respectively. These results open a new application for iris capture devices.", "paper_url": "http://arxiv.org/abs/2203.02488v1", "pdf_url": "http://arxiv.org/pdf/2203.02488v1", "repo_url": null}, "2203.02486": {"publish_time": "2022-03-04", "title": "The Familiarity Hypothesis: Explaining the Behavior of Deep Open Set Methods", "author": "Thomas G. Dietterich et.al.", "abstract": "In many object recognition applications, the set of possible categories is an open set, and the deployed recognition system will encounter novel objects belonging to categories unseen during training. Detecting such \"novel category\" objects is usually formulated as an anomaly detection problem. Anomaly detection algorithms for feature-vector data identify anomalies as outliers, but outlier detection has not worked well in deep learning. Instead, methods based on the computed logits of visual object classifiers give state-of-the-art performance. This paper proposes the Familiarity Hypothesis that these methods succeed because they are detecting the absence of familiar learned features rather than the presence of novelty. The paper reviews evidence from the literature and presents additional evidence from our own experiments that provide strong support for this hypothesis. The paper concludes with a discussion of whether familiarity detection is an inevitable consequence of representation learning.", "paper_url": "http://arxiv.org/abs/2203.02486v1", "pdf_url": "http://arxiv.org/pdf/2203.02486v1", "repo_url": null}, "2203.02480": {"publish_time": "2022-03-04", "title": "Didn't see that coming: a survey on non-verbal social human behavior forecasting", "author": "German Barquero et.al.", "abstract": "Non-verbal social human behavior forecasting has increasingly attracted the interest of the research community in recent years. Its direct applications to human-robot interaction and socially-aware human motion generation make it a very attractive field. In this survey, we define the behavior forecasting problem for multiple interactive agents in a generic way that aims at unifying the fields of social signals prediction and human motion forecasting, traditionally separated. We hold that both problem formulations refer to the same conceptual problem, and identify many shared fundamental challenges: future stochasticity, context awareness, history exploitation, etc. We also propose a taxonomy that comprises methods published in the last 5 years in a very informative way and describes the current main concerns of the community with regard to this problem. In order to promote further research on this field, we also provide a summarised and friendly overview of audiovisual datasets featuring non-acted social interactions. Finally, we describe the most common metrics used in this task and their particular issues.", "paper_url": "http://arxiv.org/abs/2203.02480v1", "pdf_url": "http://arxiv.org/pdf/2203.02480v1", "repo_url": null}, "2203.03610": {"publish_time": "2022-03-07", "title": "ZippyPoint: Fast Interest Point Detection, Description, and Matching through Mixed Precision Discretization", "author": "Simon Maurer et.al.", "abstract": "The design of more complex and powerful neural network models has significantly advanced the state-of-the-art in local feature detection and description. These advances can be attributed to deeper networks, improved training methodologies through self-supervision, or the introduction of new building blocks, such as graph neural networks for feature matching. However, in the pursuit of increased performance, efficient architectures that generate lightweight descriptors have received surprisingly little attention. In this paper, we investigate the adaptations neural networks for detection and description require in order to enable their use in embedded platforms. To that end, we investigate and adapt network quantization techniques for use in real-time applications. In addition, we revisit common practices in descriptor quantization and propose the use of a binary descriptor normalization layer, enabling the generation of distinctive length-invariant binary descriptors. ZippyPoint, our efficient network, runs at 47.2 fps on the Apple M1 CPU. This is up to 5x faster than other learned detection and description models, making it the only real-time learned network. ZippyPoint consistently outperforms all other binary detection and descriptor methods in visual localization and homography estimation tasks. Code and trained models will be released upon publication.", "paper_url": "http://arxiv.org/abs/2203.03610v1", "pdf_url": "http://arxiv.org/pdf/2203.03610v1", "repo_url": null}, "2203.03609": {"publish_time": "2022-03-07", "title": "Human-Aware Object Placement for Visual Environment Reconstruction", "author": "Hongwei Yi et.al.", "abstract": "Humans are in constant contact with the world as they move through it and interact with it. This contact is a vital source of information for understanding 3D humans, 3D scenes, and the interactions between them. In fact, we demonstrate that these human-scene interactions (HSIs) can be leveraged to improve the 3D reconstruction of a scene from a monocular RGB video. Our key idea is that, as a person moves through a scene and interacts with it, we accumulate HSIs across multiple input images, and optimize the 3D scene to reconstruct a consistent, physically plausible and functional 3D scene layout. Our optimization-based approach exploits three types of HSI constraints: (1) humans that move in a scene are occluded or occlude objects, thus, defining the depth ordering of the objects, (2) humans move through free space and do not interpenetrate objects, (3) when humans and objects are in contact, the contact surfaces occupy the same place in space. Using these constraints in an optimization formulation across all observations, we significantly improve the 3D scene layout reconstruction. Furthermore, we show that our scene reconstruction can be used to refine the initial 3D human pose and shape (HPS) estimation. We evaluate the 3D scene layout reconstruction and HPS estimation qualitatively and quantitatively using the PROX and PiGraphs datasets. The code and data are available for research purposes at https://mover.is.tue.mpg.de/.", "paper_url": "http://arxiv.org/abs/2203.03609v1", "pdf_url": "http://arxiv.org/pdf/2203.03609v1", "repo_url": null}, "2203.03605": {"publish_time": "2022-03-07", "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection", "author": "Hao Zhang et.al.", "abstract": "We present DINO (\\textbf{D}ETR with \\textbf{I}mproved de\\textbf{N}oising anch\\textbf{O}r boxes), a state-of-the-art end-to-end object detector. % in this paper. DINO improves over previous DETR-like models in performance and efficiency by using a contrastive way for denoising training, a mixed query selection method for anchor initialization, and a look forward twice scheme for box prediction. DINO achieves $48.3$AP in $12$ epochs and $51.0$AP in $36$ epochs on COCO with a ResNet-50 backbone and multi-scale features, yielding a significant improvement of $\\textbf{+4.9}$\\textbf{AP} and $\\textbf{+2.4}$\\textbf{AP}, respectively, compared to DN-DETR, the previous best DETR-like model. DINO scales well in both model size and data size. Without bells and whistles, after pre-training on the Objects365 dataset with a SwinL backbone, DINO obtains the best results on both COCO \\texttt{val2017} ($\\textbf{63.2}$\\textbf{AP}) and \\texttt{test-dev} (\\textbf{$\\textbf{63.3}$AP}). Compared to other models on the leaderboard, DINO significantly reduces its model size and pre-training data size while achieving better results. Our code will be available at \\url{https://github.com/IDEACVR/DINO}.", "paper_url": "http://arxiv.org/abs/2203.03605v1", "pdf_url": "http://arxiv.org/pdf/2203.03605v1", "repo_url": null}, "2203.03598": {"publish_time": "2022-03-07", "title": "Audio-visual Generalised Zero-shot Learning with Cross-modal Attention and Language", "author": "Otniel-Bogdan Mercea et.al.", "abstract": "Learning to classify video data from classes not included in the training data, i.e. video-based zero-shot learning, is challenging. We conjecture that the natural alignment between the audio and visual modalities in video data provides a rich training signal for learning discriminative multi-modal representations. Focusing on the relatively underexplored task of audio-visual zero-shot learning, we propose to learn multi-modal representations from audio-visual data using cross-modal attention and exploit textual label embeddings for transferring knowledge from seen classes to unseen classes. Taking this one step further, in our generalised audio-visual zero-shot learning setting, we include all the training classes in the test-time search space which act as distractors and increase the difficulty while making the setting more realistic. Due to the lack of a unified benchmark in this domain, we introduce a (generalised) zero-shot learning benchmark on three audio-visual datasets of varying sizes and difficulty, VGGSound, UCF, and ActivityNet, ensuring that the unseen test classes do not appear in the dataset used for supervised training of the backbone deep models. Comparing multiple relevant and recent methods, we demonstrate that our proposed AVCA model achieves state-of-the-art performance on all three datasets. Code and data will be available at \\url{https://github.com/ExplainableML/AVCA-GZSL}.", "paper_url": "http://arxiv.org/abs/2203.03598v1", "pdf_url": "http://arxiv.org/pdf/2203.03598v1", "repo_url": "https://github.com/explainableml/avca-gzsl"}, "2203.03587": {"publish_time": "2022-03-07", "title": "On the pitfalls of entropy-based uncertainty for multi-class semi-supervised segmentation", "author": "Martin Van Waerebeke et.al.", "abstract": "Semi-supervised learning has emerged as an appealing strategy to train deep models with limited supervision. Most prior literature under this learning paradigm resorts to dual-based architectures, typically composed of a teacher-student duple. To drive the learning of the student, many of these models leverage the aleatoric uncertainty derived from the entropy of the predictions. While this has shown to work well in a binary scenario, we demonstrate in this work that this strategy leads to suboptimal results in a multi-class context, a more realistic and challenging setting. We argue, indeed, that these approaches underperform due to the erroneous uncertainty approximations in the presence of inter-class overlap. Furthermore, we propose an alternative solution to compute the uncertainty in a multi-class setting, based on divergence distances and which account for inter-class overlap. We evaluate the proposed solution on a challenging multi-class segmentation dataset and in two well-known uncertainty-based segmentation methods. The reported results demonstrate that by simply replacing the mechanism used to compute the uncertainty, our proposed solution brings substantial improvement on tested setups.", "paper_url": "http://arxiv.org/abs/2203.03587v1", "pdf_url": "http://arxiv.org/pdf/2203.03587v1", "repo_url": null}, "2203.04287": {"publish_time": "2022-03-08", "title": "A Simple Multi-Modality Transfer Learning Baseline for Sign Language Translation", "author": "Yutong Chen et.al.", "abstract": "This paper proposes a simple transfer learning baseline for sign language translation. Existing sign language datasets (e.g. PHOENIX-2014T, CSL-Daily) contain only about 10K-20K pairs of sign videos, gloss annotations and texts, which are an order of magnitude smaller than typical parallel data for training spoken language translation models. Data is thus a bottleneck for training effective sign language translation models. To mitigate this problem, we propose to progressively pretrain the model from general-domain datasets that include a large amount of external supervision to within-domain datasets. Concretely, we pretrain the sign-to-gloss visual network on the general domain of human actions and the within-domain of a sign-to-gloss dataset, and pretrain the gloss-to-text translation network on the general domain of a multilingual corpus and the within-domain of a gloss-to-text corpus. The joint model is fine-tuned with an additional module named the visual-language mapper that connects the two networks. This simple baseline surpasses the previous state-of-the-art results on two sign language translation benchmarks, demonstrating the effectiveness of transfer learning. With its simplicity and strong performance, this approach can serve as a solid baseline for future research.", "paper_url": "http://arxiv.org/abs/2203.04287v1", "pdf_url": "http://arxiv.org/pdf/2203.04287v1", "repo_url": null}, "2203.04279": {"publish_time": "2022-03-08", "title": "Probabilistic Warp Consistency for Weakly-Supervised Semantic Correspondences", "author": "Prune Truong et.al.", "abstract": "We propose Probabilistic Warp Consistency, a weakly-supervised learning objective for semantic matching. Our approach directly supervises the dense matching scores predicted by the network, encoded as a conditional probability distribution. We first construct an image triplet by applying a known warp to one of the images in a pair depicting different instances of the same object class. Our probabilistic learning objectives are then derived using the constraints arising from the resulting image triplet. We further account for occlusion and background clutter present in real image pairs by extending our probabilistic output space with a learnable unmatched state. To supervise it, we design an objective between image pairs depicting different object classes. We validate our method by applying it to four recent semantic matching architectures. Our weakly-supervised approach sets a new state-of-the-art on four challenging semantic matching benchmarks. Lastly, we demonstrate that our objective also brings substantial improvements in the strongly-supervised regime, when combined with keypoint annotations.", "paper_url": "http://arxiv.org/abs/2203.04279v1", "pdf_url": "http://arxiv.org/pdf/2203.04279v1", "repo_url": "https://github.com/PruneTruong/DenseMatching"}, "2203.04275": {"publish_time": "2022-03-08", "title": "Robust Multi-Task Learning and Online Refinement for Spacecraft Pose Estimation across Domain Gap", "author": "Tae Ha Park et.al.", "abstract": "This work presents Spacecraft Pose Network v2 (SPNv2), a Convolutional Neural Network (CNN) for pose estimation of noncooperative spacecraft across domain gap. SPNv2 is a multi-scale, multi-task CNN which consists of a shared multi-scale feature encoder and multiple prediction heads that perform different tasks on a shared feature output. These tasks are all related to detection and pose estimation of a target spacecraft from an image, such as prediction of pre-defined satellite keypoints, direct pose regression, and binary segmentation of the satellite foreground. It is shown that by jointly training on different yet related tasks with extensive data augmentations on synthetic images only, the shared encoder learns features that are common across image domains that have fundamentally different visual characteristics compared to synthetic images. This work also introduces Online Domain Refinement (ODR) which refines the parameters of the normalization layers of SPNv2 on the target domain images online at deployment. Specifically, ODR performs self-supervised entropy minimization of the predicted satellite foreground, thereby improving the CNN's performance on the target domain images without their pose labels and with minimal computational efforts. The GitHub repository for SPNv2 will be made available in the near future.", "paper_url": "http://arxiv.org/abs/2203.04275v1", "pdf_url": "http://arxiv.org/pdf/2203.04275v1", "repo_url": null}, "2203.04251": {"publish_time": "2022-03-08", "title": "End-to-End Semi-Supervised Learning for Video Action Detection", "author": "Akash Kumar et.al.", "abstract": "In this work, we focus on semi-supervised learning for video action detection which utilizes both labeled as well as unlabeled data. We propose a simple end-to-end consistency based approach which effectively utilizes the unlabeled data. Video action detection requires both, action class prediction as well as a spatio-temporal localization of actions. Therefore, we investigate two types of constraints, classification consistency, and spatio-temporal consistency. The presence of predominant background and static regions in a video makes it challenging to utilize spatio-temporal consistency for action detection. To address this, we propose two novel regularization constraints for spatio-temporal consistency; 1) temporal coherency, and 2) gradient smoothness. Both these aspects exploit the temporal continuity of action in videos and are found to be effective for utilizing unlabeled videos for action detection. We demonstrate the effectiveness of the proposed approach on two different action detection benchmark datasets, UCF101-24 and JHMDB-21. In addition, we also show the effectiveness of the proposed approach for video object segmentation on the Youtube-VOS dataset which demonstrates its generalization capability to other tasks. The proposed approach achieves competitive performance by using merely 20% of annotations on UCF101-24 when compared with recent fully supervised methods. On UCF101-24, it improves the score by +8.9% and +11% at 0.5 f-mAP and v-mAP respectively, compared to supervised approach.", "paper_url": "http://arxiv.org/abs/2203.04251v1", "pdf_url": "http://arxiv.org/pdf/2203.04251v1", "repo_url": null}, "2203.04232": {"publish_time": "2022-03-08", "title": "A Lightweight and Detector-free 3D Single Object Tracker on Point Clouds", "author": "Yan Xia et.al.", "abstract": "Recent works on 3D single object tracking treat the tracking as a target-specific 3D detection task, where an off-the-shelf 3D detector is commonly employed for tracking. However, it is non-trivial to perform accurate target-specific detection since the point cloud of objects in raw LiDAR scans is usually sparse and incomplete. In this paper, we address this issue by explicitly leveraging temporal motion cues and propose DMT, a Detector-free Motion prediction based 3D Tracking network that totally removes the usage of complicated 3D detectors, which is lighter, faster, and more accurate than previous trackers. Specifically, the motion prediction module is firstly introduced to estimate a potential target center of the current frame in a point-cloud free way. Then, an explicit voting module is proposed to directly regress the 3D box from the estimated target center. Extensive experiments on KITTI and NuScenes datasets demonstrate that our DMT, without applying any complicated 3D detectors, can still achieve better performance (~10% improvement on the NuScenes dataset) and faster tracking speed (i.e., 72 FPS) than state-of-the-art approaches. Our codes will be released publicly.", "paper_url": "http://arxiv.org/abs/2203.04232v1", "pdf_url": "http://arxiv.org/pdf/2203.04232v1", "repo_url": null}, "2203.04946": {"publish_time": "2022-03-09", "title": "On the surprising tradeoff between ImageNet accuracy and perceptual similarity", "author": "Manoj Kumar et.al.", "abstract": "Perceptual distances between images, as measured in the space of pre-trained deep features, have outperformed prior low-level, pixel-based metrics on assessing image similarity. While the capabilities of older and less accurate models such as AlexNet and VGG to capture perceptual similarity are well known, modern and more accurate models are less studied. First, we observe a surprising inverse correlation between ImageNet accuracy and Perceptual Scores of modern networks such as ResNets, EfficientNets, and Vision Transformers: that is better classifiers achieve worse Perceptual Scores. Then, we perform a large-scale study and examine the ImageNet accuracy/Perceptual Score relationship on varying the depth, width, number of training steps, weight decay, label smoothing, and dropout. Higher accuracy improves Perceptual Score up to a certain point, but we uncover a Pareto frontier between accuracies and Perceptual Score in the mid-to-high accuracy regime. We explore this relationship further using distortion invariance, spatial frequency sensitivity, and alternative perceptual functions. Interestingly we discover shallow ResNets, trained for less than 5 epochs only on ImageNet, whose emergent Perceptual Score matches the prior best networks trained directly on supervised human perceptual judgements.", "paper_url": "http://arxiv.org/abs/2203.04946v1", "pdf_url": "http://arxiv.org/pdf/2203.04946v1", "repo_url": null}, "2203.04930": {"publish_time": "2022-03-09", "title": "Triangular Character Animation Sampling with Motion, Emotion, and Relation", "author": "Yizhou Zhao et.al.", "abstract": "Dramatic progress has been made in animating individual characters. However, we still lack automatic control over activities between characters, especially those involving interactions. In this paper, we present a novel energy-based framework to sample and synthesize animations by associating the characters' body motions, facial expressions, and social relations. We propose a Spatial-Temporal And-Or graph (ST-AOG), a stochastic grammar model, to encode the contextual relationship between motion, emotion, and relation, forming a triangle in a conditional random field. We train our model from a labeled dataset of two-character interactions. Experiments demonstrate that our method can recognize the social relation between two characters and sample new scenes of vivid motion and emotion using Markov Chain Monte Carlo (MCMC) given the social relation. Thus, our method can provide animators with an automatic way to generate 3D character animations, help synthesize interactions between Non-Player Characters (NPCs), and enhance machine emotion intelligence (EQ) in virtual reality (VR).", "paper_url": "http://arxiv.org/abs/2203.04930v1", "pdf_url": "http://arxiv.org/pdf/2203.04930v1", "repo_url": null}, "2203.04913": {"publish_time": "2022-03-09", "title": "Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep Classifiers", "author": "Dominik Zietlow et.al.", "abstract": "Algorithmic fairness is frequently motivated in terms of a trade-off in which overall performance is decreased so as to improve performance on disadvantaged groups where the algorithm would otherwise be less accurate. Contrary to this, we find that applying existing fairness approaches to computer vision improve fairness by degrading the performance of classifiers across all groups (with increased degradation on the best performing groups).   Extending the bias-variance decomposition for classification to fairness, we theoretically explain why the majority of fairness classifiers designed for low capacity models should not be used in settings involving high-capacity models, a scenario common to computer vision. We corroborate this analysis with extensive experimental support that shows that many of the fairness heuristics used in computer vision also degrade performance on the most disadvantaged groups. Building on these insights, we propose an adaptive augmentation strategy that, uniquely, of all methods tested, improves performance for the disadvantaged groups.", "paper_url": "http://arxiv.org/abs/2203.04913v1", "pdf_url": "http://arxiv.org/pdf/2203.04913v1", "repo_url": null}, "2203.04908": {"publish_time": "2022-03-09", "title": "Rethinking data-driven point spread function modeling with a differentiable optical model", "author": "Tobias Liaudat et.al.", "abstract": "In astronomy, upcoming space telescopes with wide-field optical instruments have a spatially varying point spread function (PSF). Certain scientific goals require a high-fidelity estimation of the PSF at target positions where no direct measurement of the PSF is provided. Even though observations of the PSF are available at some positions of the field of view (FOV), they are undersampled, noisy, and integrated in wavelength in the instrument's passband. PSF modeling requires building a model from these observations that can infer a super-resolved PSF at any wavelength and any position in the FOV. Current data-driven PSF models can tackle spatial variations and super-resolution, but are not capable of capturing chromatic variations. Our model, coined WaveDiff, proposes a paradigm shift in the data-driven modeling of the point spread function field of telescopes. By adding a differentiable optical forward model into the modeling framework, we change the data-driven modeling space from the pixels to the wavefront. The proposed model relies on efficient automatic differentiation technology as well as modern stochastic first-order optimization techniques recently developed by the thriving machine-learning community. Our framework paves the way to building powerful models that are physically motivated and do not require special calibration data. This paper demonstrates the WaveDiff model on a simplified setting of a space telescope. The proposed framework represents a performance breakthrough with respect to existing data-driven approaches. The pixel reconstruction errors decrease 6-fold at observation resolution and 44-fold for a 3x super-resolution. The ellipticity errors are reduced by a factor of at least 20 and the size error by a factor of more than 250. By only using noisy broad-band in-focus observations, we successfully capture the PSF chromatic variations due to diffraction.", "paper_url": "http://arxiv.org/abs/2203.04908v1", "pdf_url": "http://arxiv.org/pdf/2203.04908v1", "repo_url": null}, "2203.04907": {"publish_time": "2022-03-09", "title": "Pose Guided Multi-person Image Generation From Text", "author": "Soon Yau Cheong et.al.", "abstract": "Transformers have recently been shown to generate high quality images from texts. However, existing methods struggle to create high fidelity full-body images, especially multiple people. A person's pose has a high degree of freedom that is difficult to describe using words only; this creates errors in the generated image, such as incorrect body proportions and pose. We propose a pose-guided text-to-image model, using pose as an additional input constraint. Using the proposed Keypoint Pose Encoding (KPE) to encode human pose into low dimensional representation, our model can generate novel multi-person images accurately representing the pose and text descriptions provided, with minimal errors. We demonstrate that KPE is invariant to changes in the target image domain and image resolution; we show results on the Deepfashion dataset and create a new multi-person Deepfashion dataset to demonstrate the multi-capabilities of our approach.", "paper_url": "http://arxiv.org/abs/2203.04907v1", "pdf_url": "http://arxiv.org/pdf/2203.04907v1", "repo_url": null}, "2203.05557": {"publish_time": "2022-03-10", "title": "Conditional Prompt Learning for Vision-Language Models", "author": "Kaiyang Zhou et.al.", "abstract": "With the rise of powerful pre-trained vision-language models like CLIP, it becomes essential to investigate ways to adapt these models to downstream datasets. A recently proposed method named Context Optimization (CoOp) introduces the concept of prompt learning -- a recent trend in NLP -- to the vision domain for adapting pre-trained vision-language models. Specifically, CoOp turns context words in a prompt into a set of learnable vectors and, with only a few labeled images for learning, can achieve huge improvements over intensively-tuned manual prompts. In our study we identify a critical problem of CoOp: the learned context is not generalizable to wider unseen classes within the same dataset, suggesting that CoOp overfits base classes observed during training. To address the problem, we propose Conditional Context Optimization (CoCoOp), which extends CoOp by further learning a lightweight neural network to generate for each image an input-conditional token (vector). Compared to CoOp's static prompts, our dynamic prompts adapt to each instance and are thus less sensitive to class shift. Extensive experiments show that CoCoOp generalizes much better than CoOp to unseen classes, even showing promising transferability beyond a single dataset; and yields stronger domain generalization performance as well. Code is available at https://github.com/KaiyangZhou/CoOp.", "paper_url": "http://arxiv.org/abs/2203.05557v1", "pdf_url": "http://arxiv.org/pdf/2203.05557v1", "repo_url": "https://github.com/kaiyangzhou/coop"}, "2203.05553": {"publish_time": "2022-03-10", "title": "Transfer of Representations to Video Label Propagation: Implementation Factors Matter", "author": "Daniel McKee et.al.", "abstract": "This work studies feature representations for dense label propagation in video, with a focus on recently proposed methods that learn video correspondence using self-supervised signals such as colorization or temporal cycle consistency. In the literature, these methods have been evaluated with an array of inconsistent settings, making it difficult to discern trends or compare performance fairly. Starting with a unified formulation of the label propagation algorithm that encompasses most existing variations, we systematically study the impact of important implementation factors in feature extraction and label propagation. Along the way, we report the accuracies of properly tuned supervised and unsupervised still image baselines, which are higher than those found in previous works. We also demonstrate that augmenting video-based correspondence cues with still-image-based ones can further improve performance. We then attempt a fair comparison of recent video-based methods on the DAVIS benchmark, showing convergence of best methods to performance levels near our strong ImageNet baseline, despite the usage of a variety of specialized video-based losses and training particulars. Additional comparisons on JHMDB and VIP datasets confirm the similar performance of current methods. We hope that this study will help to improve evaluation practices and better inform future research directions in temporal correspondence.", "paper_url": "http://arxiv.org/abs/2203.05553v1", "pdf_url": "http://arxiv.org/pdf/2203.05553v1", "repo_url": null}, "2203.05550": {"publish_time": "2022-03-10", "title": "An Empirical Investigation of 3D Anomaly Detection and Segmentation", "author": "Eliahu Horwitz et.al.", "abstract": "Anomaly detection and segmentation in images has made tremendous progress in recent years while 3D information has often been ignored. The objective of this paper is to further understand the benefit and role of 3D as opposed to color in image anomaly detection. Our study begins by presenting a surprising finding: standard color-only anomaly segmentation methods, when applied to 3D datasets, significantly outperform all current methods. On the other hand, we observe that color-only methods are insufficient for images containing geometric anomalies where shape cannot be unambiguously inferred from 2D. This suggests that better 3D methods are needed. We investigate different representations for 3D anomaly detection and discover that handcrafted orientation-invariant representations are unreasonably effective on this task. We uncover a simple 3D-only method that outperforms all recent approaches while not using deep learning, external pretraining datasets, or color information. As the 3D-only method cannot detect color and texture anomalies, we combine it with 2D color features, granting us the best current results by a large margin (Pixel-wise ROCAUC: 99.2%, PRO: 95.9% on MVTec 3D-AD). We conclude by discussing future challenges for 3D anomaly detection and segmentation.", "paper_url": "http://arxiv.org/abs/2203.05550v1", "pdf_url": "http://arxiv.org/pdf/2203.05550v1", "repo_url": null}, "2203.05534": {"publish_time": "2022-03-10", "title": "AGCN: Augmented Graph Convolutional Network for Lifelong Multi-label Image Recognition", "author": "Kaile Du et.al.", "abstract": "The Lifelong Multi-Label (LML) image recognition builds an online class-incremental classifier in a sequential multi-label image recognition data stream. The key challenges of LML image recognition are the construction of label relationships on Partial Labels of training data and the Catastrophic Forgetting on old classes, resulting in poor generalization. To solve the problems, the study proposes an Augmented Graph Convolutional Network (AGCN) model that can construct the label relationships across the sequential recognition tasks and sustain the catastrophic forgetting. First, we build an Augmented Correlation Matrix (ACM) across all seen classes, where the intra-task relationships derive from the hard label statistics while the inter-task relationships leverage both hard and soft labels from data and a constructed expert network. Then, based on the ACM, the proposed AGCN captures label dependencies with dynamic augmented structure and yields effective class representations. Last, to suppress the forgetting of label dependencies across old tasks, we propose a relationship-preserving loss as a constraint to the construction of label relationships. The proposed method is evaluated using two multi-label image benchmarks and the experimental results show that the proposed method is effective for LML image recognition and can build convincing correlation across tasks even if the labels of previous tasks are missing. Our code is available at https://github.com/Kaile-Du/AGCN.", "paper_url": "http://arxiv.org/abs/2203.05534v1", "pdf_url": "http://arxiv.org/pdf/2203.05534v1", "repo_url": null}, "2203.05508": {"publish_time": "2022-03-10", "title": "Towards Less Constrained Macro-Neural Architecture Search", "author": "Vasco Lopes et.al.", "abstract": "Networks found with Neural Architecture Search (NAS) achieve state-of-the-art performance in a variety of tasks, out-performing human-designed networks. However, most NAS methods heavily rely on human-defined assumptions that constrain the search: architecture's outer-skeletons, number of layers, parameter heuristics and search spaces. Additionally, common search spaces consist of repeatable modules (cells) instead of fully exploring the architecture's search space by designing entire architectures (macro-search). Imposing such constraints requires deep human expertise and restricts the search to pre-defined settings. In this paper, we propose LCMNAS, a method that pushes NAS to less constrained search spaces by performing macro-search without relying on pre-defined heuristics or bounded search spaces. LCMNAS introduces three components for the NAS pipeline: i) a method that leverages information about well-known architectures to autonomously generate complex search spaces based on Weighted Directed Graphs with hidden properties, ii) a evolutionary search strategy that generates complete architectures from scratch, and iii) a mixed-performance estimation approach that combines information about architectures at initialization stage and lower fidelity estimates to infer their trainability and capacity to model complex functions. We present experiments showing that LCMNAS generates state-of-the-art architectures from scratch with minimal GPU computation. We study the importance of different NAS components on a macro-search setting. Code for reproducibility is public at \\url{https://github.com/VascoLopes/LCMNAS}.", "paper_url": "http://arxiv.org/abs/2203.05508v1", "pdf_url": "http://arxiv.org/pdf/2203.05508v1", "repo_url": "https://github.com/vascolopes/lcmnas"}, "2203.06173": {"publish_time": "2022-03-11", "title": "Masked Visual Pre-training for Motor Control", "author": "Tete Xiao et.al.", "abstract": "This paper shows that self-supervised visual pre-training from real-world images is effective for learning motor control tasks from pixels. We first train the visual representations by masked modeling of natural images. We then freeze the visual encoder and train neural network controllers on top with reinforcement learning. We do not perform any task-specific fine-tuning of the encoder; the same visual representations are used for all motor control tasks. To the best of our knowledge, this is the first self-supervised model to exploit real-world images at scale for motor control. To accelerate progress in learning from pixels, we contribute a benchmark suite of hand-designed tasks varying in movements, scenes, and robots. Without relying on labels, state-estimation, or expert demonstrations, we consistently outperform supervised encoders by up to 80% absolute success rate, sometimes even matching the oracle state performance. We also find that in-the-wild images, e.g., from YouTube or Egocentric videos, lead to better visual representations for various manipulation tasks than ImageNet images.", "paper_url": "http://arxiv.org/abs/2203.06173v1", "pdf_url": "http://arxiv.org/pdf/2203.06173v1", "repo_url": null}, "2203.06172": {"publish_time": "2022-03-11", "title": "Deep AutoAugment", "author": "Yu Zheng et.al.", "abstract": "While recent automated data augmentation methods lead to state-of-the-art results, their design spaces and the derived data augmentation strategies still incorporate strong human priors. In this work, instead of fixing a set of hand-picked default augmentations alongside the searched data augmentations, we propose a fully automated approach for data augmentation search named Deep AutoAugment (DeepAA). DeepAA progressively builds a multi-layer data augmentation pipeline from scratch by stacking augmentation layers one at a time until reaching convergence. For each augmentation layer, the policy is optimized to maximize the cosine similarity between the gradients of the original and augmented data along the direction with low variance. Our experiments show that even without default augmentations, we can learn an augmentation policy that achieves strong performance with that of previous works. Extensive ablation studies show that the regularized gradient matching is an effective search method for data augmentation policies. Our code is available at: https://github.com/MSU-MLSys-Lab/DeepAA .", "paper_url": "http://arxiv.org/abs/2203.06172v1", "pdf_url": "http://arxiv.org/pdf/2203.06172v1", "repo_url": "https://github.com/msu-mlsys-lab/deepaa"}, "2203.06145": {"publish_time": "2022-03-11", "title": "Neuromorphic Data Augmentation for Training Spiking Neural Networks", "author": "Yuhang Li et.al.", "abstract": "Developing neuromorphic intelligence on event-based datasets with spiking neural networks (SNNs) has recently attracted much research attention. However, the limited size of event-based datasets makes SNNs prone to overfitting and unstable convergence. This issue remains unexplored by previous academic works. In an effort to minimize this generalization gap, we propose neuromorphic data augmentation (NDA), a family of geometric augmentations specifically designed for event-based datasets with the goal of significantly stabilizing the SNN training and reducing the generalization gap between training and test performance. The proposed method is simple and compatible with existing SNN training pipelines. Using the proposed augmentation, for the first time, we demonstrate the feasibility of unsupervised contrastive learning for SNNs. We conduct comprehensive experiments on prevailing neuromorphic vision benchmarks and show that NDA yields substantial improvements over previous state-of-the-art results. For example, NDA-based SNN achieves accuracy gain on CIFAR10-DVS and N-Caltech 101 by 10.1% and 13.7%, respectively.", "paper_url": "http://arxiv.org/abs/2203.06145v1", "pdf_url": "http://arxiv.org/pdf/2203.06145v1", "repo_url": null}, "2203.06127": {"publish_time": "2022-03-11", "title": "Spatial Consistency Loss for Training Multi-Label Classifiers from Single-Label Annotations", "author": "Thomas Verelst et.al.", "abstract": "As natural images usually contain multiple objects, multi-label image classification is more applicable \"in the wild\" than single-label classification. However, exhaustively annotating images with every object of interest is costly and time-consuming. We aim to train multi-label classifiers from single-label annotations only. We show that adding a consistency loss, ensuring that the predictions of the network are consistent over consecutive training epochs, is a simple yet effective method to train multi-label classifiers in a weakly supervised setting. We further extend this approach spatially, by ensuring consistency of the spatial feature maps produced over consecutive training epochs, maintaining per-class running-average heatmaps for each training image. We show that this spatial consistency loss further improves the multi-label mAP of the classifiers. In addition, we show that this method overcomes shortcomings of the \"crop\" data-augmentation by recovering correct supervision signal even when most of the single ground truth object is cropped out of the input image by the data augmentation. We demonstrate gains of the consistency and spatial consistency losses over the binary cross-entropy baseline, and over competing methods, on MS-COCO and Pascal VOC. We also demonstrate improved multi-label classification mAP on ImageNet-1K using the ReaL multi-label validation set.", "paper_url": "http://arxiv.org/abs/2203.06127v1", "pdf_url": "http://arxiv.org/pdf/2203.06127v1", "repo_url": null}, "2203.06113": {"publish_time": "2022-03-11", "title": "Detection of multiple retinal diseases in ultra-widefield fundus images using deep learning: data-driven identification of relevant regions", "author": "Justin Engelmann et.al.", "abstract": "Ultra-widefield (UWF) imaging is a promising modality that captures a larger retinal field of view compared to traditional fundus photography. Previous studies showed that deep learning (DL) models are effective for detecting retinal disease in UWF images, but primarily considered individual diseases under less-than-realistic conditions (excluding images with other diseases, artefacts, comorbidities, or borderline cases; and balancing healthy and diseased images) and did not systematically investigate which regions of the UWF images are relevant for disease detection. We first improve on the state of the field by proposing a DL model that can recognise multiple retinal diseases under more realistic conditions. We then use global explainability methods to identify which regions of the UWF images the model generally attends to. Our model performs very well, separating between healthy and diseased retinas with an area under the curve (AUC) of 0.9206 on an internal test set, and an AUC of 0.9841 on a challenging, external test set. When diagnosing specific diseases, the model attends to regions where we would expect those diseases to occur. We further identify the posterior pole as the most important region in a purely data-driven fashion. Surprisingly, 10% of the image around the posterior pole is sufficient for achieving comparable performance to having the full images available.", "paper_url": "http://arxiv.org/abs/2203.06113v1", "pdf_url": "http://arxiv.org/pdf/2203.06113v1", "repo_url": null}, "2203.07363": {"publish_time": "2022-03-14", "title": "Implicit Motion Handling for Video Camouflaged Object Detection", "author": "Xuelian Cheng et.al.", "abstract": "We propose a new video camouflaged object detection (VCOD) framework that can exploit both short-term dynamics and long-term temporal consistency to detect camouflaged objects from video frames. An essential property of camouflaged objects is that they usually exhibit patterns similar to the background and thus make them hard to identify from still images. Therefore, effectively handling temporal dynamics in videos becomes the key for the VCOD task as the camouflaged objects will be noticeable when they move. However, current VCOD methods often leverage homography or optical flows to represent motions, where the detection error may accumulate from both the motion estimation error and the segmentation error. On the other hand, our method unifies motion estimation and object segmentation within a single optimization framework. Specifically, we build a dense correlation volume to implicitly capture motions between neighbouring frames and utilize the final segmentation supervision to optimize the implicit motion estimation and segmentation jointly. Furthermore, to enforce temporal consistency within a video sequence, we jointly utilize a spatio-temporal transformer to refine the short-term predictions. Extensive experiments on VCOD benchmarks demonstrate the architectural effectiveness of our approach. We also provide a large-scale VCOD dataset named MoCA-Mask with pixel-level handcrafted ground-truth masks and construct a comprehensive VCOD benchmark with previous methods to facilitate research in this direction. Dataset Link: https://xueliancheng.github.io/SLT-Net-project.", "paper_url": "http://arxiv.org/abs/2203.07363v1", "pdf_url": "http://arxiv.org/pdf/2203.07363v1", "repo_url": null}, "2203.07345": {"publish_time": "2022-03-14", "title": "Federated Cycling (FedCy): Semi-supervised Federated Learning of Surgical Phases", "author": "Hasan Kassem et.al.", "abstract": "Recent advancements in deep learning methods bring computer-assistance a step closer to fulfilling promises of safer surgical procedures. However, the generalizability of such methods is often dependent on training on diverse datasets from multiple medical institutions, which is a restrictive requirement considering the sensitive nature of medical data. Recently proposed collaborative learning methods such as Federated Learning (FL) allow for training on remote datasets without the need to explicitly share data. Even so, data annotation still represents a bottleneck, particularly in medicine and surgery where clinical expertise is often required. With these constraints in mind, we propose FedCy, a federated semi-supervised learning (FSSL) method that combines FL and self-supervised learning to exploit a decentralized dataset of both labeled and unlabeled videos, thereby improving performance on the task of surgical phase recognition. By leveraging temporal patterns in the labeled data, FedCy helps guide unsupervised training on unlabeled data towards learning task-specific features for phase recognition. We demonstrate significant performance gains over state-of-the-art FSSL methods on the task of automatic recognition of surgical phases using a newly collected multi-institutional dataset of laparoscopic cholecystectomy videos. Furthermore, we demonstrate that our approach also learns more generalizable features when tested on data from an unseen domain.", "paper_url": "http://arxiv.org/abs/2203.07345v1", "pdf_url": "http://arxiv.org/pdf/2203.07345v1", "repo_url": null}, "2203.07341": {"publish_time": "2022-03-14", "title": "Defending From Physically-Realizable Adversarial Attacks Through Internal Over-Activation Analysis", "author": "Giulio Rossolini et.al.", "abstract": "This work presents Z-Mask, a robust and effective strategy to improve the adversarial robustness of convolutional networks against physically-realizable adversarial attacks. The presented defense relies on specific Z-score analysis performed on the internal network features to detect and mask the pixels corresponding to adversarial objects in the input image. To this end, spatially contiguous activations are examined in shallow and deep layers to suggest potential adversarial regions. Such proposals are then aggregated through a multi-thresholding mechanism. The effectiveness of Z-Mask is evaluated with an extensive set of experiments carried out on models for both semantic segmentation and object detection. The evaluation is performed with both digital patches added to the input images and printed patches positioned in the real world. The obtained results confirm that Z-Mask outperforms the state-of-the-art methods in terms of both detection accuracy and overall performance of the networks under attack. Additional experiments showed that Z-Mask is also robust against possible defense-aware attacks.", "paper_url": "http://arxiv.org/abs/2203.07341v1", "pdf_url": "http://arxiv.org/pdf/2203.07341v1", "repo_url": null}, "2203.07319": {"publish_time": "2022-03-14", "title": "GCFSR: a Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors", "author": "Jingwen He et.al.", "abstract": "Face image super resolution (face hallucination) usually relies on facial priors to restore realistic details and preserve identity information. Recent advances can achieve impressive results with the help of GAN prior. They either design complicated modules to modify the fixed GAN prior or adopt complex training strategies to finetune the generator. In this work, we propose a generative and controllable face SR framework, called GCFSR, which can reconstruct images with faithful identity information without any additional priors. Generally, GCFSR has an encoder-generator architecture. Two modules called style modulation and feature modulation are designed for the multi-factor SR task. The style modulation aims to generate realistic face details and the feature modulation dynamically fuses the multi-level encoded features and the generated ones conditioned on the upscaling factor. The simple and elegant architecture can be trained from scratch in an end-to-end manner. For small upscaling factors (<=8), GCFSR can produce surprisingly good results with only adversarial loss. After adding L1 and perceptual losses, GCFSR can outperform state-of-the-art methods for large upscaling factors (16, 32, 64). During the test phase, we can modulate the generative strength via feature modulation by changing the conditional upscaling factor continuously to achieve various generative effects.", "paper_url": "http://arxiv.org/abs/2203.07319v1", "pdf_url": "http://arxiv.org/pdf/2203.07319v1", "repo_url": null}, "2203.07308": {"publish_time": "2022-03-14", "title": "Accelerating Plug-and-Play Image Reconstruction via Multi-Stage Sketched Gradients", "author": "Junqi Tang et.al.", "abstract": "In this work we propose a new paradigm for designing fast plug-and-play (PnP) algorithms using dimensionality reduction techniques. Unlike existing approaches which utilize stochastic gradient iterations for acceleration, we propose novel multi-stage sketched gradient iterations which first perform downsampling dimensionality reduction in the image space, and then efficiently approximate the true gradient using the sketched gradient in the low-dimensional space. This sketched gradient scheme can also be naturally combined with PnP-SGD methods for further improvement on computational complexity. As a generic acceleration scheme, it can be applied to accelerate any existing PnP/RED algorithm. Our numerical experiments on X-ray fan-beam CT demonstrate the remarkable effectiveness of our scheme, that a computational free-lunch can be obtained using this dimensionality reduction in the image space.", "paper_url": "http://arxiv.org/abs/2203.07308v1", "pdf_url": "http://arxiv.org/pdf/2203.07308v1", "repo_url": null}, "2203.08141": {"publish_time": "2022-03-15", "title": "Object Manipulation via Visual Target Localization", "author": "Kiana Ehsani et.al.", "abstract": "Object manipulation is a critical skill required for Embodied AI agents interacting with the world around them. Training agents to manipulate objects, poses many challenges. These include occlusion of the target object by the agent's arm, noisy object detection and localization, and the target frequently going out of view as the agent moves around in the scene. We propose Manipulation via Visual Object Location Estimation (m-VOLE), an approach that explores the environment in search for target objects, computes their 3D coordinates once they are located, and then continues to estimate their 3D locations even when the objects are not visible, thus robustly aiding the task of manipulating these objects throughout the episode. Our evaluations show a massive 3x improvement in success rate over a model that has access to the same sensory suite but is trained without the object location estimator, and our analysis shows that our agent is robust to noise in depth perception and agent localization. Importantly, our proposed approach relaxes several assumptions about idealized localization and perception that are commonly employed by recent works in embodied AI -- an important step towards training agents for object manipulation in the real world.", "paper_url": "http://arxiv.org/abs/2203.08141v1", "pdf_url": "http://arxiv.org/pdf/2203.08141v1", "repo_url": null}, "2203.08140": {"publish_time": "2022-03-15", "title": "Learning Spatio-Temporal Downsampling for Effective Video Upscaling", "author": "Xiaoyu Xiang et.al.", "abstract": "Downsampling is one of the most basic image processing operations. Improper spatio-temporal downsampling applied on videos can cause aliasing issues such as moir\\'e patterns in space and the wagon-wheel effect in time. Consequently, the inverse task of upscaling a low-resolution, low frame-rate video in space and time becomes a challenging ill-posed problem due to information loss and aliasing artifacts. In this paper, we aim to solve the space-time aliasing problem by learning a spatio-temporal downsampler. Towards this goal, we propose a neural network framework that jointly learns spatio-temporal downsampling and upsampling. It enables the downsampler to retain the key patterns of the original video and maximizes the reconstruction performance of the upsampler. To make the downsamping results compatible with popular image and video storage formats, the downsampling results are encoded to uint8 with a differentiable quantization layer. To fully utilize the space-time correspondences, we propose two novel modules for explicit temporal propagation and space-time feature rearrangement. Experimental results show that our proposed method significantly boosts the space-time reconstruction quality by preserving spatial textures and motion patterns in both downsampling and upscaling. Moreover, our framework enables a variety of applications, including arbitrary video resampling, blurry frame reconstruction, and efficient video storage.", "paper_url": "http://arxiv.org/abs/2203.08140v1", "pdf_url": "http://arxiv.org/pdf/2203.08140v1", "repo_url": null}, "2203.08138": {"publish_time": "2022-03-15", "title": "CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D Molecular Volumes from Real Cryo-EM Images", "author": "Axel Levy et.al.", "abstract": "Cryo-electron microscopy (cryo-EM) has become a tool of fundamental importance in structural biology, helping us understand the basic building blocks of life. The algorithmic challenge of cryo-EM is to jointly estimate the unknown 3D poses and the 3D electron scattering potential of a biomolecule from millions of extremely noisy 2D images. Existing reconstruction algorithms, however, cannot easily keep pace with the rapidly growing size of cryo-EM datasets due to their high computational and memory cost. We introduce cryoAI, an ab initio reconstruction algorithm for homogeneous conformations that uses direct gradient-based optimization of particle poses and the electron scattering potential from single-particle cryo-EM data. CryoAI combines a learned encoder that predicts the poses of each particle image with a physics-based decoder to aggregate each particle image into an implicit representation of the scattering potential volume. This volume is stored in the Fourier domain for computational efficiency and leverages a modern coordinate network architecture for memory efficiency. Combined with a symmetrized loss function, this framework achieves results of a quality on par with state-of-the-art cryo-EM solvers for both simulated and experimental data, one order of magnitude faster for large datasets and with significantly lower memory requirements than existing methods.", "paper_url": "http://arxiv.org/abs/2203.08138v1", "pdf_url": "http://arxiv.org/pdf/2203.08138v1", "repo_url": null}, "2203.08133": {"publish_time": "2022-03-15", "title": "Animatable Neural Implicit Surfaces for Creating Avatars from Videos", "author": "Sida Peng et.al.", "abstract": "This paper aims to reconstruct an animatable human model from a video of very sparse camera views. Some recent works represent human geometry and appearance with neural radiance fields and utilize parametric human models to produce deformation fields for animation, which enables them to recover detailed 3D human models from videos. However, their reconstruction results tend to be noisy due to the lack of surface constraints on radiance fields. Moreover, as they generate the human appearance in 3D space, their rendering quality heavily depends on the accuracy of deformation fields. To solve these problems, we propose Animatable Neural Implicit Surface (AniSDF), which models the human geometry with a signed distance field and defers the appearance generation to the 2D image space with a 2D neural renderer. The signed distance field naturally regularizes the learned geometry, enabling the high-quality reconstruction of human bodies, which can be further used to improve the rendering speed. Moreover, the 2D neural renderer can be learned to compensate for geometric errors, making the rendering more robust to inaccurate deformations. Experiments on several datasets show that the proposed approach outperforms recent human reconstruction and synthesis methods by a large margin.", "paper_url": "http://arxiv.org/abs/2203.08133v1", "pdf_url": "http://arxiv.org/pdf/2203.08133v1", "repo_url": null}, "2203.08130": {"publish_time": "2022-03-15", "title": "One Network Doesn't Rule Them All: Moving Beyond Handcrafted Architectures in Self-Supervised Learning", "author": "Sharath Girish et.al.", "abstract": "The current literature on self-supervised learning (SSL) focuses on developing learning objectives to train neural networks more effectively on unlabeled data. The typical development process involves taking well-established architectures, e.g., ResNet demonstrated on ImageNet, and using them to evaluate newly developed objectives on downstream scenarios. While convenient, this does not take into account the role of architectures which has been shown to be crucial in the supervised learning literature. In this work, we establish extensive empirical evidence showing that a network architecture plays a significant role in SSL. We conduct a large-scale study with over 100 variants of ResNet and MobileNet architectures and evaluate them across 11 downstream scenarios in the SSL setting. We show that there is no one network that performs consistently well across the scenarios. Based on this, we propose to learn not only network weights but also architecture topologies in the SSL regime. We show that \"self-supervised architectures\" outperform popular handcrafted architectures (ResNet18 and MobileNetV2) while performing competitively with the larger and computationally heavy ResNet50 on major image classification benchmarks (ImageNet-1K, iNat2021, and more). Our results suggest that it is time to consider moving beyond handcrafted architectures in SSL and start thinking about incorporating architecture search into self-supervised learning objectives.", "paper_url": "http://arxiv.org/abs/2203.08130v1", "pdf_url": "http://arxiv.org/pdf/2203.08130v1", "repo_url": null}, "2203.08796": {"publish_time": "2022-03-16", "title": "A Continual Learning Framework for Adaptive Defect Classification and Inspection", "author": "Wenbo Sun et.al.", "abstract": "Machine-vision-based defect classification techniques have been widely adopted for automatic quality inspection in manufacturing processes. This article describes a general framework for classifying defects from high volume data batches with efficient inspection of unlabelled samples. The concept is to construct a detector to identify new defect types, send them to the inspection station for labelling, and dynamically update the classifier in an efficient manner that reduces both storage and computational needs imposed by data samples of previously observed batches. Both a simulation study on image classification and a case study on surface defect detection via 3D point clouds are performed to demonstrate the effectiveness of the proposed method.", "paper_url": "http://arxiv.org/abs/2203.08796v1", "pdf_url": "http://arxiv.org/pdf/2203.08796v1", "repo_url": null}, "2203.08795": {"publish_time": "2022-03-16", "title": "Zero Pixel Directional Boundary by Vector Transform", "author": "Edoardo Mello Rella et.al.", "abstract": "Boundaries are among the primary visual cues used by human and computer vision systems. One of the key problems in boundary detection is the label representation, which typically leads to class imbalance and, as a consequence, to thick boundaries that require non-differential post-processing steps to be thinned. In this paper, we re-interpret boundaries as 1-D surfaces and formulate a one-to-one vector transform function that allows for training of boundary prediction completely avoiding the class imbalance issue. Specifically, we define the boundary representation at any point as the unit vector pointing to the closest boundary surface. Our problem formulation leads to the estimation of direction as well as richer contextual information of the boundary, and, if desired, the availability of zero-pixel thin boundaries also at training time. Our method uses no hyper-parameter in the training loss and a fixed stable hyper-parameter at inference. We provide theoretical justification/discussions of the vector transform representation. We evaluate the proposed loss method using a standard architecture and show the excellent performance over other losses and representations on several datasets.", "paper_url": "http://arxiv.org/abs/2203.08795v1", "pdf_url": "http://arxiv.org/pdf/2203.08795v1", "repo_url": null}, "2203.08792": {"publish_time": "2022-03-16", "title": "PosePipe: Open-Source Human Pose Estimation Pipeline for Clinical Research", "author": "R. James Cotton et.al.", "abstract": "There has been significant progress in machine learning algorithms for human pose estimation that may provide immense value in rehabilitation and movement sciences. However, there remain several challenges to routine use of these tools for clinical practice and translational research, including: 1) high technical barrier to entry, 2) rapidly evolving space of algorithms, 3) challenging algorithmic interdependencies, and 4) complex data management requirements between these components. To mitigate these barriers, we developed a human pose estimation pipeline that facilitates running state-of-the-art algorithms on data acquired in clinical context. Our system allows for running different implementations of several classes of algorithms and handles their interdependencies easily. These algorithm classes include subject identification and tracking, 2D keypoint detection, 3D joint location estimation, and estimating the pose of body models. The system uses a database to manage videos, intermediate analyses, and data for computations at each stage. It also provides tools for data visualization, including generating video overlays that also obscure faces to enhance privacy. Our goal in this work is not to train new algorithms, but to advance the use of cutting-edge human pose estimation algorithms for clinical and translation research. We show that this tool facilitates analyzing large numbers of videos of human movement ranging from gait laboratories analyses, to clinic and therapy visits, to people in the community. We also highlight limitations of these algorithms when applied to clinical populations in a rehabilitation setting.", "paper_url": "http://arxiv.org/abs/2203.08792v1", "pdf_url": "http://arxiv.org/pdf/2203.08792v1", "repo_url": "https://github.com/peabody124/posepipeline"}, "2203.08777": {"publish_time": "2022-03-16", "title": "Object discovery and representation networks", "author": "Olivier J. H\u00e9naff et.al.", "abstract": "The promise of self-supervised learning (SSL) is to leverage large amounts of unlabeled data to solve complex tasks. While there has been excellent progress with simple, image-level learning, recent methods have shown the advantage of including knowledge of image structure. However, by introducing hand-crafted image segmentations to define regions of interest, or specialized augmentation strategies, these methods sacrifice the simplicity and generality that makes SSL so powerful. Instead, we propose a self-supervised learning paradigm that discovers the structure encoded in these priors by itself. Our method, Odin, couples object discovery and representation networks to discover meaningful image segmentations without any supervision. The resulting learning paradigm is simpler, less brittle, and more general, and achieves state-of-the-art transfer learning results for object detection and instance segmentation on COCO, and semantic segmentation on PASCAL and Cityscapes, while strongly surpassing supervised pre-training for video segmentation on DAVIS.", "paper_url": "http://arxiv.org/abs/2203.08777v1", "pdf_url": "http://arxiv.org/pdf/2203.08777v1", "repo_url": null}, "2203.08765": {"publish_time": "2022-03-16", "title": "Efficient conditioned face animation using frontally-viewed embedding", "author": "Maxime Oquab et.al.", "abstract": "As the quality of few shot facial animation from landmarks increases, new applications become possible, such as ultra low bandwidth video chat compression with a high degree of realism. However, there are some important challenges to tackle in order to improve the experience in real world conditions. In particular, the current approaches fail to represent profile views without distortions, while running in a low compute regime. We focus on this key problem by introducing a multi-frames embedding dubbed Frontalizer to improve profile views rendering. In addition to this core improvement, we explore the learning of a latent code conditioning generations along with landmarks to better convey facial expressions. Our dense models achieves 22% of improvement in perceptual quality and 73% reduction of landmark error over the first order model baseline on a subset of DFDC videos containing head movements. Declined with mobile architectures, our models outperform the previous state-of-the-art (improving perceptual quality by more than 16% and reducing landmark error by more than 47% on two datasets) while running on real time on iPhone 8 with very low bandwidth requirements.", "paper_url": "http://arxiv.org/abs/2203.08765v1", "pdf_url": "http://arxiv.org/pdf/2203.08765v1", "repo_url": null}, "2203.09517": {"publish_time": "2022-03-17", "title": "TensoRF: Tensorial Radiance Fields", "author": "Anpei Chen et.al.", "abstract": "We present TensoRF, a novel approach to model and reconstruct radiance fields. Unlike NeRF that purely uses MLPs, we model the radiance field of a scene as a 4D tensor, which represents a 3D voxel grid with per-voxel multi-channel features. Our central idea is to factorize the 4D scene tensor into multiple compact low-rank tensor components. We demonstrate that applying traditional CP decomposition -- that factorizes tensors into rank-one components with compact vectors -- in our framework leads to improvements over vanilla NeRF. To further boost performance, we introduce a novel vector-matrix (VM) decomposition that relaxes the low-rank constraints for two modes of a tensor and factorizes tensors into compact vector and matrix factors. Beyond superior rendering quality, our models with CP and VM decompositions lead to a significantly lower memory footprint in comparison to previous and concurrent works that directly optimize per-voxel features. Experimentally, we demonstrate that TensoRF with CP decomposition achieves fast reconstruction (<30 min) with better rendering quality and even a smaller model size (<4 MB) compared to NeRF. Moreover, TensoRF with VM decomposition further boosts rendering quality and outperforms previous state-of-the-art methods, while reducing the reconstruction time (<10 min) and retaining a compact model size (<75 MB).", "paper_url": "http://arxiv.org/abs/2203.09517v1", "pdf_url": "http://arxiv.org/pdf/2203.09517v1", "repo_url": null}, "2203.09516": {"publish_time": "2022-03-17", "title": "AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation", "author": "Paritosh Mittal et.al.", "abstract": "Powerful priors allow us to perform inference with insufficient information. In this paper, we propose an autoregressive prior for 3D shapes to solve multimodal 3D tasks such as shape completion, reconstruction, and generation. We model the distribution over 3D shapes as a non-sequential autoregressive distribution over a discretized, low-dimensional, symbolic grid-like latent representation of 3D shapes. This enables us to represent distributions over 3D shapes conditioned on information from an arbitrary set of spatially anchored query locations and thus perform shape completion in such arbitrary settings (e.g., generating a complete chair given only a view of the back leg). We also show that the learned autoregressive prior can be leveraged for conditional tasks such as single-view reconstruction and language-based generation. This is achieved by learning task-specific naive conditionals which can be approximated by light-weight models trained on minimal paired data. We validate the effectiveness of the proposed method using both quantitative and qualitative evaluation and show that the proposed method outperforms the specialized state-of-the-art methods trained for individual tasks. The project page with code and video visualizations can be found at https://yccyenchicheng.github.io/AutoSDF/.", "paper_url": "http://arxiv.org/abs/2203.09516v1", "pdf_url": "http://arxiv.org/pdf/2203.09516v1", "repo_url": null}, "2203.09513": {"publish_time": "2022-03-17", "title": "On Multi-Domain Long-Tailed Recognition, Generalization and Beyond", "author": "Yuzhe Yang et.al.", "abstract": "Real-world data often exhibit imbalanced label distributions. Existing studies on data imbalance focus on single-domain settings, i.e., samples are from the same data distribution. However, natural data can originate from distinct domains, where a minority class in one domain could have abundant instances from other domains. We formalize the task of Multi-Domain Long-Tailed Recognition (MDLT), which learns from multi-domain imbalanced data, addresses label imbalance, domain shift, and divergent label distributions across domains, and generalizes to all domain-class pairs. We first develop the domain-class transferability graph, and show that such transferability governs the success of learning in MDLT. We then propose BoDA, a theoretically grounded learning strategy that tracks the upper bound of transferability statistics, and ensures balanced alignment and calibration across imbalanced domain-class distributions. We curate five MDLT benchmarks based on widely-used multi-domain datasets, and compare BoDA to twenty algorithms that span different learning strategies. Extensive and rigorous experiments verify the superior performance of BoDA. Further, as a byproduct, BoDA establishes new state-of-the-art on Domain Generalization benchmarks, improving generalization to unseen domains. Code and data are available at https://github.com/YyzHarry/multi-domain-imbalance.", "paper_url": "http://arxiv.org/abs/2203.09513v1", "pdf_url": "http://arxiv.org/pdf/2203.09513v1", "repo_url": "https://github.com/yyzharry/multi-domain-imbalance"}, "2203.09510": {"publish_time": "2022-03-17", "title": "DetMatch: Two Teachers are Better Than One for Joint 2D and 3D Semi-Supervised Object Detection", "author": "Jinhyung Park et.al.", "abstract": "While numerous 3D detection works leverage the complementary relationship between RGB images and point clouds, developments in the broader framework of semi-supervised object recognition remain uninfluenced by multi-modal fusion. Current methods develop independent pipelines for 2D and 3D semi-supervised learning despite the availability of paired image and point cloud frames. Observing that the distinct characteristics of each sensor cause them to be biased towards detecting different objects, we propose DetMatch, a flexible framework for joint semi-supervised learning on 2D and 3D modalities. By identifying objects detected in both sensors, our pipeline generates a cleaner, more robust set of pseudo-labels that both demonstrates stronger performance and stymies single-modality error propagation. Further, we leverage the richer semantics of RGB images to rectify incorrect 3D class predictions and improve localization of 3D boxes. Evaluating on the challenging KITTI and Waymo datasets, we improve upon strong semi-supervised learning methods and observe higher quality pseudo-labels. Code will be released at https://github.com/Divadi/DetMatch", "paper_url": "http://arxiv.org/abs/2203.09510v1", "pdf_url": "http://arxiv.org/pdf/2203.09510v1", "repo_url": "https://github.com/divadi/detmatch"}, "2203.09507": {"publish_time": "2022-03-17", "title": "Towards Data-Efficient Detection Transformers", "author": "Wen Wang et.al.", "abstract": "Detection Transformers have achieved competitive performance on the sample-rich COCO dataset. However, we show most of them suffer from significant performance drops on small-size datasets, like Cityscapes. In other words, the detection transformers are generally data-hungry. To tackle this problem, we empirically analyze the factors that affect data efficiency, through a step-by-step transition from a data-efficient RCNN variant to the representative DETR. The empirical results suggest that sparse feature sampling from local image areas holds the key. Based on this observation, we alleviate the data-hungry issue of existing detection transformers by simply alternating how key and value sequences are constructed in the cross-attention layer, with minimum modifications to the original models. Besides, we introduce a simple yet effective label augmentation method to provide richer supervision and improve data efficiency. Experiments show that our method can be readily applied to different detection transformers and improve their performance on both small-size and sample-rich datasets. Code will be made publicly available at \\url{https://github.com/encounter1997/DE-DETRs}.", "paper_url": "http://arxiv.org/abs/2203.09507v1", "pdf_url": "http://arxiv.org/pdf/2203.09507v1", "repo_url": null}, "2203.10078": {"publish_time": "2022-03-18", "title": "Bayesian Inversion for Nonlinear Imaging Models using Deep Generative Priors", "author": "Pakshal Bohra et.al.", "abstract": "Most modern imaging systems involve a computational reconstruction pipeline to infer the image of interest from acquired measurements. The Bayesian reconstruction framework relies on the characterization of the posterior distribution, which depends on a model of the imaging system and prior knowledge on the image, for solving such inverse problems. Here, the choice of the prior distribution is critical for obtaining high-quality estimates. In this work, we use deep generative models to represent the prior distribution. We develop a posterior sampling scheme for the class of nonlinear inverse problems where the forward model has a neural-network-like structure. This class includes most existing imaging modalities. We introduce the notion of augmented generative models in order to suitably handle quantitative image recovery. We illustrate the advantages of our framework by applying it to two nonlinear imaging modalities-phase retrieval and optical diffraction tomography.", "paper_url": "http://arxiv.org/abs/2203.10078v1", "pdf_url": "http://arxiv.org/pdf/2203.10078v1", "repo_url": null}, "2203.10073": {"publish_time": "2022-03-18", "title": "Lunar Rover Localization Using Craters as Landmarks", "author": "Larry Matthies et.al.", "abstract": "Onboard localization capabilities for planetary rovers to date have used relative navigation, by integrating combinations of wheel odometry, visual odometry, and inertial measurements during each drive to track position relative to the start of each drive. At the end of each drive, a ground-in-the-loop (GITL) interaction is used to get a position update from human operators in a more global reference frame, by matching images or local maps from onboard the rover to orbital reconnaissance images or maps of a large region around the rover's current position. Autonomous rover drives are limited in distance so that accumulated relative navigation error does not risk the possibility of the rover driving into hazards known from orbital images. However, several rover mission concepts have recently been studied that require much longer drives between GITL cycles, particularly for the Moon. These concepts require greater autonomy to minimize GITL cycles to enable such large range; onboard global localization is a key element of such autonomy. Multiple techniques have been studied in the past for onboard rover global localization, but a satisfactory solution has not yet emerged. For the Moon, the ubiquitous craters offer a new possibility, which involves mapping craters from orbit, then recognizing crater landmarks with cameras and-or a lidar onboard the rover. This approach is applicable everywhere on the Moon, does not require high resolution stereo imaging from orbit as some other approaches do, and has potential to enable position knowledge with order of 5 to 10 m accuracy at all times. This paper describes our technical approach to crater-based lunar rover localization and presents initial results on crater detection using 3D point cloud data from onboard lidar or stereo cameras, as well as using shading cues in monocular onboard imagery.", "paper_url": "http://arxiv.org/abs/2203.10073v1", "pdf_url": "http://arxiv.org/pdf/2203.10073v1", "repo_url": null}, "2203.10062": {"publish_time": "2022-03-18", "title": "Imaging-based histological features are predictive of MET alterations in Non-Small Cell Lung Cancer", "author": "Rohan P. Joshi et.al.", "abstract": "MET is a proto-oncogene whose somatic activation in non-small cell lung cancer leads to increased cell growth and tumor progression. The two major classes of MET alterations are gene amplification and exon 14 deletion, both of which are therapeutic targets and detectable using existing molecular assays. However, existing tests are limited by their consumption of valuable tissue, cost and complexity that prevent widespread use. MET alterations could have an effect on cell morphology, and quantifying these associations could open new avenues for research and development of morphology-based screening tools. Using H&E-stained whole slide images (WSIs), we investigated the association of distinct cell-morphological features with MET amplifications and MET exon 14 deletions. We found that cell shape, color, grayscale intensity and texture-based features from both tumor infiltrating lymphocytes and tumor cells distinguished MET wild-type from MET amplified or MET exon 14 deletion cases. The association of individual cell features with MET alterations suggested a predictive model could distinguish MET wild-type from MET amplification or MET exon 14 deletion. We therefore developed an L1-penalized logistic regression model, achieving a mean Area Under the Receiver Operating Characteristic Curve (ROC-AUC) of 0.77 +/- 0.05sd in cross-validation and 0.77 on an independent holdout test set. A sparse set of 43 features differentiated these classes, which included features similar to what was found in the univariate analysis as well as the percent of tumor cells in the tissue. Our study demonstrates that MET alterations result in a detectable morphological signal in tumor cells and lymphocytes. These results suggest that development of low-cost predictive models based on H&E-stained WSIs may improve screening for MET altered tumors.", "paper_url": "http://arxiv.org/abs/2203.10062v1", "pdf_url": "http://arxiv.org/pdf/2203.10062v1", "repo_url": null}, "2203.10039": {"publish_time": "2022-03-18", "title": "Multi-input segmentation of damaged brain in acute ischemic stroke patients using slow fusion with skip connection", "author": "Luca Tomasetti et.al.", "abstract": "Time is a fundamental factor during stroke treatments. A fast, automatic approach that segments the ischemic regions helps treatment decisions. In clinical use today, a set of color-coded parametric maps generated from computed tomography perfusion (CTP) images are investigated manually to decide a treatment plan. We propose an automatic method based on a neural network using a set of parametric maps to segment the two ischemic regions (core and penumbra) in patients affected by acute ischemic stroke. Our model is based on a convolution-deconvolution bottleneck structure with multi-input and slow fusion. A loss function based on the focal Tversky index addresses the data imbalance issue. The proposed architecture demonstrates effective performance and results comparable to the ground truth annotated by neuroradiologists. A Dice coefficient of 0.81 for penumbra and 0.52 for core over the large vessel occlusion test set is achieved. The full implementation is available at: https://git.io/JtFGb.", "paper_url": "http://arxiv.org/abs/2203.10039v1", "pdf_url": "http://arxiv.org/pdf/2203.10039v1", "repo_url": null}, "2203.10035": {"publish_time": "2022-03-18", "title": "SHREC 2021: Classification in cryo-electron tomograms", "author": "Ilja Gubins et.al.", "abstract": "Cryo-electron tomography (cryo-ET) is an imaging technique that allows three-dimensional visualization of macro-molecular assemblies under near-native conditions. Cryo-ET comes with a number of challenges, mainly low signal-to-noise and inability to obtain images from all angles. Computational methods are key to analyze cryo-electron tomograms.   To promote innovation in computational methods, we generate a novel simulated dataset to benchmark different methods of localization and classification of biological macromolecules in tomograms. Our publicly available dataset contains ten tomographic reconstructions of simulated cell-like volumes. Each volume contains twelve different types of complexes, varying in size, function and structure.   In this paper, we have evaluated seven different methods of finding and classifying proteins. Seven research groups present results obtained with learning-based methods and trained on the simulated dataset, as well as a baseline template matching (TM), a traditional method widely used in cryo-ET research. We show that learning-based approaches can achieve notably better localization and classification performance than TM. We also experimentally confirm that there is a negative relationship between particle size and performance for all methods.", "paper_url": "http://arxiv.org/abs/2203.10035v1", "pdf_url": "http://arxiv.org/pdf/2203.10035v1", "repo_url": null}, "2203.11194": {"publish_time": "2022-03-21", "title": "Generating Fast and Slow: Scene Decomposition via Reconstruction", "author": "Mihir Prabhudesai et.al.", "abstract": "We consider the problem of segmenting scenes into constituent entities, i.e. underlying objects and their parts. Current supervised visual detectors though impressive within their training distribution, often fail to segment out-of-distribution scenes into their constituent entities. Recent slot-centric generative models break such dependence on supervision, by attempting to segment scenes into entities unsupervised, by reconstructing pixels. However, they have been restricted thus far to toy scenes as they suffer from a reconstruction-segmentation trade-off: as the entity bottleneck gets wider, reconstruction improves but then the segmentation collapses. We propose GFS-Nets (Generating Fast and Slow Networks) that alleviate this issue with two ingredients: i) curriculum training in the form of primitives, often missing from current generative models and, ii) test-time adaptation per scene through gradient descent on the reconstruction objective, what we call slow inference, missing from current feed-forward detectors. We show the proposed curriculum suffices to break the reconstruction-segmentation trade-off, and slow inference greatly improves segmentation in out-of-distribution scenes. We evaluate GFS-Nets in 3D and 2D scene segmentation benchmarks of PartNet, CLEVR, Room Diverse++, and show large ( 50%) performance improvements against SOTA supervised feed-forward detectors and unsupervised object discovery methods", "paper_url": "http://arxiv.org/abs/2203.11194v1", "pdf_url": "http://arxiv.org/pdf/2203.11194v1", "repo_url": null}, "2203.11192": {"publish_time": "2022-03-21", "title": "Transforming Model Prediction for Tracking", "author": "Christoph Mayer et.al.", "abstract": "Optimization based tracking methods have been widely successful by integrating a target model prediction module, providing effective global reasoning by minimizing an objective function. While this inductive bias integrates valuable domain knowledge, it limits the expressivity of the tracking network. In this work, we therefore propose a tracker architecture employing a Transformer-based model prediction module. Transformers capture global relations with little inductive bias, allowing it to learn the prediction of more powerful target models. We further extend the model predictor to estimate a second set of weights that are applied for accurate bounding box regression. The resulting tracker relies on training and on test frame information in order to predict all weights transductively. We train the proposed tracker end-to-end and validate its performance by conducting comprehensive experiments on multiple tracking datasets. Our tracker sets a new state of the art on three benchmarks, achieving an AUC of 68.5% on the challenging LaSOT dataset.", "paper_url": "http://arxiv.org/abs/2203.11192v1", "pdf_url": "http://arxiv.org/pdf/2203.11192v1", "repo_url": null}, "2203.11191": {"publish_time": "2022-03-21", "title": "Robust Visual Tracking by Segmentation", "author": "Matthieu Paul et.al.", "abstract": "Estimating the target extent poses a fundamental challenge in visual object tracking. Typically, trackers are box-centric and fully rely on a bounding box to define the target in the scene. In practice, objects often have complex shapes and are not aligned with the image axis. In these cases, bounding boxes do not provide an accurate description of the target and often contain a majority of background pixels. We propose a segmentation-centric tracking pipeline that not only produces a highly accurate segmentation mask, but also works internally with segmentation masks instead of bounding boxes. Thus, our tracker is able to better learn a target representation that clearly differentiates the target in the scene from background content. In order to achieve the necessary robustness for the challenging tracking scenario, we propose a separate instance localization component that is used to condition the segmentation decoder when producing the output mask. We infer a bounding box from the segmentation mask and validate our tracker on challenging tracking datasets and achieve the new state of the art on LaSOT with a success AUC score of 69.7%. Since fully evaluating the predicted masks on tracking datasets is not possible due to the missing mask annotations, we further validate our segmentation quality on two popular video object segmentation datasets.", "paper_url": "http://arxiv.org/abs/2203.11191v1", "pdf_url": "http://arxiv.org/pdf/2203.11191v1", "repo_url": null}, "2203.11183": {"publish_time": "2022-03-21", "title": "Masked Discrimination for Self-Supervised Learning on Point Clouds", "author": "Haotian Liu et.al.", "abstract": "Masked autoencoding has achieved great success for self-supervised learning in the image and language domains. However, mask based pretraining has yet to show benefits for point cloud understanding, likely due to standard backbones like PointNet being unable to properly handle the training versus testing distribution mismatch introduced by masking during training. In this paper, we bridge this gap by proposing a discriminative mask pretraining Transformer framework, MaskPoint}, for point clouds. Our key idea is to represent the point cloud as discrete occupancy values (1 if part of the point cloud; 0 if not), and perform simple binary classification between masked object points and sampled noise points as the proxy task. In this way, our approach is robust to the point sampling variance in point clouds, and facilitates learning rich representations. We evaluate our pretrained models across several downstream tasks, including 3D shape classification, segmentation, and real-word object detection, and demonstrate state-of-the-art results while achieving a significant pretraining speedup (e.g., 4.1x on ScanNet) compared to the prior state-of-the-art Transformer baseline. Code will be publicly available at https://github.com/haotian-liu/MaskPoint.", "paper_url": "http://arxiv.org/abs/2203.11183v1", "pdf_url": "http://arxiv.org/pdf/2203.11183v1", "repo_url": null}, "2203.11174": {"publish_time": "2022-03-21", "title": "DiffPoseNet: Direct Differentiable Camera Pose Estimation", "author": "Chethan M. Parameshwara et.al.", "abstract": "Current deep neural network approaches for camera pose estimation rely on scene structure for 3D motion estimation, but this decreases the robustness and thereby makes cross-dataset generalization difficult. In contrast, classical approaches to structure from motion estimate 3D motion utilizing optical flow and then compute depth. Their accuracy, however, depends strongly on the quality of the optical flow. To avoid this issue, direct methods have been proposed, which separate 3D motion from depth estimation but compute 3D motion using only image gradients in the form of normal flow. In this paper, we introduce a network NFlowNet, for normal flow estimation which is used to enforce robust and direct constraints. In particular, normal flow is used to estimate relative camera pose based on the cheirality (depth positivity) constraint. We achieve this by formulating the optimization problem as a differentiable cheirality layer, which allows for end-to-end learning of camera pose. We perform extensive qualitative and quantitative evaluation of the proposed DiffPoseNet's sensitivity to noise and its generalization across datasets. We compare our approach to existing state-of-the-art methods on KITTI, TartanAir, and TUM-RGBD datasets.", "paper_url": "http://arxiv.org/abs/2203.11174v1", "pdf_url": "http://arxiv.org/pdf/2203.11174v1", "repo_url": null}, "2203.11938": {"publish_time": "2022-03-22", "title": "\u03c6-SfT: Shape-from-Template with a Physics-Based Deformation Model", "author": "Navami Kairanda et.al.", "abstract": "Shape-from-Template (SfT) methods estimate 3D surface deformations from a single monocular RGB camera while assuming a 3D state known in advance (a template). This is an important yet challenging problem due to the under-constrained nature of the monocular setting. Existing SfT techniques predominantly use geometric and simplified deformation models, which often limits their reconstruction abilities. In contrast to previous works, this paper proposes a new SfT approach explaining 2D observations through physical simulations accounting for forces and material properties. Our differentiable physics simulator regularises the surface evolution and optimises the material elastic properties such as bending coefficients, stretching stiffness and density. We use a differentiable renderer to minimise the dense reprojection error between the estimated 3D states and the input images and recover the deformation parameters using an adaptive gradient-based optimisation. For the evaluation, we record with an RGB-D camera challenging real surfaces exposed to physical forces with various material properties and textures. Our approach significantly reduces the 3D reconstruction error compared to multiple competing methods. For the source code and data, see https://4dqv.mpi-inf.mpg.de/phi-SfT/.", "paper_url": "http://arxiv.org/abs/2203.11938v1", "pdf_url": "http://arxiv.org/pdf/2203.11938v1", "repo_url": null}, "2203.11937": {"publish_time": "2022-03-22", "title": "4D-OR: Semantic Scene Graphs for OR Domain Modeling", "author": "Ege \u00d6zsoy et.al.", "abstract": "Surgical procedures are conducted in highly complex operating rooms (OR), comprising different actors, devices, and interactions. To date, only medically trained human experts are capable of understanding all the links and interactions in such a demanding environment. This paper aims to bring the community one step closer to automated, holistic and semantic understanding and modeling of OR domain. Towards this goal, for the first time, we propose using semantic scene graphs (SSG) to describe and summarize the surgical scene. The nodes of the scene graphs represent different actors and objects in the room, such as medical staff, patients, and medical equipment, whereas edges are the relationships between them. To validate the possibilities of the proposed representation, we create the first publicly available 4D surgical SSG dataset, 4D-OR, containing ten simulated total knee replacement surgeries recorded with six RGB-D sensors in a realistic OR simulation center. 4D-OR includes 6734 frames and is richly annotated with SSGs, human and object poses, and clinical roles. We propose an end-to-end neural network-based SSG generation pipeline, with a rate of success of 0.75 macro F1, indeed being able to infer semantic reasoning in the OR. We further demonstrate the representation power of our scene graphs by using it for the problem of clinical role prediction, where we achieve 0.85 macro F1. The code and dataset will be made available upon acceptance.", "paper_url": "http://arxiv.org/abs/2203.11937v1", "pdf_url": "http://arxiv.org/pdf/2203.11937v1", "repo_url": null}, "2203.11933": {"publish_time": "2022-03-22", "title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning", "author": "Hugo Berg et.al.", "abstract": "Vision-language models can encode societal biases and stereotypes, but there are challenges to measuring and mitigating these harms. Prior proposed bias measurements lack robustness and feature degradation occurs when mitigating bias without access to pretraining data. We address both of these challenges in this paper: First, we evaluate different bias measures and propose the use of retrieval metrics to image-text representations via a bias measuring framework. Second, we investigate debiasing methods and show that optimizing for adversarial loss via learnable token embeddings minimizes various bias measures without substantially degrading feature representations.", "paper_url": "http://arxiv.org/abs/2203.11933v1", "pdf_url": "http://arxiv.org/pdf/2203.11933v1", "repo_url": "https://github.com/oxai/debias-vision-lang"}, "2203.11934": {"publish_time": "2022-03-22", "title": "Learning from All Vehicles", "author": "Dian Chen et.al.", "abstract": "In this paper, we present a system to train driving policies from experiences collected not just from the ego-vehicle, but all vehicles that it observes. This system uses the behaviors of other agents to create more diverse driving scenarios without collecting additional data. The main difficulty in learning from other vehicles is that there is no sensor information. We use a set of supervisory tasks to learn an intermediate representation that is invariant to the viewpoint of the controlling vehicle. This not only provides a richer signal at training time but also allows more complex reasoning during inference. Learning how all vehicles drive helps predict their behavior at test time and can avoid collisions. We evaluate this system in closed-loop driving simulations. Our system outperforms all prior methods on the public CARLA Leaderboard by a wide margin, improving driving score by 25 and route completion rate by 24 points. Our method won the 2021 CARLA Autonomous Driving challenge. Demo videos are available at https://dotchen.github.io/LAV/.", "paper_url": "http://arxiv.org/abs/2203.11934v1", "pdf_url": "http://arxiv.org/pdf/2203.11934v1", "repo_url": "https://github.com/dotchen/LAV"}, "2203.11932": {"publish_time": "2022-03-22", "title": "Dataset Distillation by Matching Training Trajectories", "author": "George Cazenavette et.al.", "abstract": "Dataset distillation is the task of synthesizing a small dataset such that a model trained on the synthetic set will match the test accuracy of the model trained on the full dataset. In this paper, we propose a new formulation that optimizes our distilled data to guide networks to a similar state as those trained on real data across many training steps. Given a network, we train it for several iterations on our distilled data and optimize the distilled data with respect to the distance between the synthetically trained parameters and the parameters trained on real data. To efficiently obtain the initial and target network parameters for large-scale datasets, we pre-compute and store training trajectories of expert networks trained on the real dataset. Our method handily outperforms existing methods and also allows us to distill higher-resolution visual data.", "paper_url": "http://arxiv.org/abs/2203.11932v1", "pdf_url": "http://arxiv.org/pdf/2203.11932v1", "repo_url": "https://github.com/georgecazenavette/mtt-distillation"}, "2203.12614": {"publish_time": "2022-03-23", "title": "Unsupervised Salient Object Detection with Spectral Cluster Voting", "author": "Gyungin Shin et.al.", "abstract": "In this paper, we tackle the challenging task of unsupervised salient object detection (SOD) by leveraging spectral clustering on self-supervised features. We make the following contributions: (i) We revisit spectral clustering and demonstrate its potential to group the pixels of salient objects; (ii) Given mask proposals from multiple applications of spectral clustering on image features computed from various self-supervised models, e.g., MoCov2, SwAV, DINO, we propose a simple but effective winner-takes-all voting mechanism for selecting the salient masks, leveraging object priors based on framing and distinctiveness; (iii) Using the selected object segmentation as pseudo groundtruth masks, we train a salient object detector, dubbed SelfMask, which outperforms prior approaches on three unsupervised SOD benchmarks. Code is publicly available at https://github.com/NoelShin/selfmask.", "paper_url": "http://arxiv.org/abs/2203.12614v1", "pdf_url": "http://arxiv.org/pdf/2203.12614v1", "repo_url": "https://github.com/noelshin/selfmask"}, "2203.12613": {"publish_time": "2022-03-23", "title": "A Hybrid Mesh-neural Representation for 3D Transparent Object Reconstruction", "author": "Jiamin Xu et.al.", "abstract": "We propose a novel method to reconstruct the 3D shapes of transparent objects using hand-held captured images under natural light conditions. It combines the advantage of explicit mesh and multi-layer perceptron (MLP) network, a hybrid representation, to simplify the capture setting used in recent contributions. After obtaining an initial shape through the multi-view silhouettes, we introduce surface-based local MLPs to encode the vertex displacement field (VDF) for the reconstruction of surface details. The design of local MLPs allows to represent the VDF in a piece-wise manner using two layer MLP networks, which is beneficial to the optimization algorithm. Defining local MLPs on the surface instead of the volume also reduces the searching space. Such a hybrid representation enables us to relax the ray-pixel correspondences that represent the light path constraint to our designed ray-cell correspondences, which significantly simplifies the implementation of single-image based environment matting algorithm. We evaluate our representation and reconstruction algorithm on several transparent objects with ground truth models. Our experiments show that our method can produce high-quality reconstruction results superior to state-of-the-art methods using a simplified data acquisition setup.", "paper_url": "http://arxiv.org/abs/2203.12613v1", "pdf_url": "http://arxiv.org/pdf/2203.12613v1", "repo_url": null}, "2203.12612": {"publish_time": "2022-03-23", "title": "StructToken : Rethinking Semantic Segmentation with Structural Prior", "author": "Fangjian Lin et.al.", "abstract": "In this paper, we present structure token (StructToken), a new paradigm for semantic segmentation. From a perspective on semantic segmentation as per-pixel classification, the previous deep learning-based methods learn the per-pixel representation first through an encoder and a decoder head and then classify each pixel representation to a specific category to obtain the semantic masks. Differently, we propose a structure-aware algorithm that takes structural information as prior to predict semantic masks directly without per-pixel classification. Specifically, given an input image, the learnable structure token interacts with the image representations to reason the final semantic masks. Three interaction approaches are explored and the results not only outperform the state-of-the-art methods but also contain more structural information. Experiments are conducted on three widely used datasets including ADE20k, Cityscapes, and COCO-Stuff 10K. We hope that structure token could serve as an alternative for semantic segmentation and inspire future research.", "paper_url": "http://arxiv.org/abs/2203.12612v1", "pdf_url": "http://arxiv.org/pdf/2203.12612v1", "repo_url": null}, "2203.12609": {"publish_time": "2022-03-23", "title": "Improving the Fairness of Chest X-ray Classifiers", "author": "Haoran Zhang et.al.", "abstract": "Deep learning models have reached or surpassed human-level performance in the field of medical imaging, especially in disease diagnosis using chest x-rays. However, prior work has found that such classifiers can exhibit biases in the form of gaps in predictive performance across protected groups. In this paper, we question whether striving to achieve zero disparities in predictive performance (i.e. group fairness) is the appropriate fairness definition in the clinical setting, over minimax fairness, which focuses on maximizing the performance of the worst-case group. We benchmark the performance of nine methods in improving classifier fairness across these two definitions. We find, consistent with prior work on non-clinical data, that methods which strive to achieve better worst-group performance do not outperform simple data balancing. We also find that methods which achieve group fairness do so by worsening performance for all groups. In light of these results, we discuss the utility of fairness definitions in the clinical setting, advocating for an investigation of the bias-inducing mechanisms in the underlying data generating process whenever possible.", "paper_url": "http://arxiv.org/abs/2203.12609v1", "pdf_url": "http://arxiv.org/pdf/2203.12609v1", "repo_url": "https://github.com/mlforhealth/cxr_fairness"}, "2203.12602": {"publish_time": "2022-03-23", "title": "VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training", "author": "Zhan Tong et.al.", "abstract": "Pre-training video transformers on extra large-scale datasets is generally required to achieve premier performance on relatively small datasets. In this paper, we show that video masked autoencoders (VideoMAE) are data-efficient learners for self-supervised video pre-training (SSVP). We are inspired by the recent ImageMAE and propose customized video tube masking and reconstruction. These simple designs turn out to be effective for overcoming information leakage caused by the temporal correlation during video reconstruction. We obtain three important findings on SSVP: (1) An extremely high proportion of masking ratio (i.e., 90% to 95%) still yields favorable performance of VideoMAE. The temporally redundant video content enables higher masking ratio than that of images. (2) VideoMAE achieves impressive results on very small datasets (i.e., around 3k-4k videos) without using any extra data. This is partially ascribed to the challenging task of video reconstruction to enforce high-level structure learning. (3) VideoMAE shows that data quality is more important than data quantity for SSVP. Domain shift between pre-training and target datasets are important issues in SSVP. Notably, our VideoMAE with the vanilla ViT backbone can achieve 83.9% on Kinects-400, 75.3% on Something-Something V2, 90.8% on UCF101, and 61.1% on HMDB51 without using any extra data. Code will be released at https://github.com/MCG-NJU/VideoMAE.", "paper_url": "http://arxiv.org/abs/2203.12602v1", "pdf_url": "http://arxiv.org/pdf/2203.12602v1", "repo_url": null}, "2203.13254": {"publish_time": "2022-03-24", "title": "EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation", "author": "Hansheng Chen et.al.", "abstract": "Locating 3D objects from a single RGB image via Perspective-n-Points (PnP) is a long-standing problem in computer vision. Driven by end-to-end deep learning, recent studies suggest interpreting PnP as a differentiable layer, so that 2D-3D point correspondences can be partly learned by backpropagating the gradient w.r.t. object pose. Yet, learning the entire set of unrestricted 2D-3D points from scratch fails to converge with existing approaches, since the deterministic pose is inherently non-differentiable. In this paper, we propose the EPro-PnP, a probabilistic PnP layer for general end-to-end pose estimation, which outputs a distribution of pose on the SE(3) manifold, essentially bringing categorical Softmax to the continuous domain. The 2D-3D coordinates and corresponding weights are treated as intermediate variables learned by minimizing the KL divergence between the predicted and target pose distribution. The underlying principle unifies the existing approaches and resembles the attention mechanism. EPro-PnP significantly outperforms competitive baselines, closing the gap between PnP-based method and the task-specific leaders on the LineMOD 6DoF pose estimation and nuScenes 3D object detection benchmarks.", "paper_url": "http://arxiv.org/abs/2203.13254v1", "pdf_url": "http://arxiv.org/pdf/2203.13254v1", "repo_url": "https://github.com/tjiiv-cprg/epro-pnp"}, "2203.13253": {"publish_time": "2022-03-24", "title": "Video Instance Segmentation via Multi-scale Spatio-temporal Split Attention Transformer", "author": "Omkar Thawakar et.al.", "abstract": "State-of-the-art transformer-based video instance segmentation (VIS) approaches typically utilize either single-scale spatio-temporal features or per-frame multi-scale features during the attention computations. We argue that such an attention computation ignores the multi-scale spatio-temporal feature relationships that are crucial to tackle target appearance deformations in videos. To address this issue, we propose a transformer-based VIS framework, named MS-STS VIS, that comprises a novel multi-scale spatio-temporal split (MS-STS) attention module in the encoder. The proposed MS-STS module effectively captures spatio-temporal feature relationships at multiple scales across frames in a video. We further introduce an attention block in the decoder to enhance the temporal consistency of the detected instances in different frames of a video. Moreover, an auxiliary discriminator is introduced during training to ensure better foreground-background separability within the multi-scale spatio-temporal feature space. We conduct extensive experiments on two benchmarks: Youtube-VIS (2019 and 2021). Our MS-STS VIS achieves state-of-the-art performance on both benchmarks. When using the ResNet50 backbone, our MS-STS achieves a mask AP of 50.1 %, outperforming the best reported results in literature by 2.7 % and by 4.8 % at higher overlap threshold of AP_75, while being comparable in model size and speed on Youtube-VIS 2019 val. set. When using the Swin Transformer backbone, MS-STS VIS achieves mask AP of 61.0 % on Youtube-VIS 2019 val. set. Our code and models are available at https://github.com/OmkarThawakar/MSSTS-VIS.", "paper_url": "http://arxiv.org/abs/2203.13253v1", "pdf_url": "http://arxiv.org/pdf/2203.13253v1", "repo_url": "https://github.com/OmkarThawakar/MSSTS-VIS"}, "2203.13251": {"publish_time": "2022-03-24", "title": "Dexterous Imitation Made Easy: A Learning-Based Framework for Efficient Dexterous Manipulation", "author": "Sridhar Pandian Arunachalam et.al.", "abstract": "Optimizing behaviors for dexterous manipulation has been a longstanding challenge in robotics, with a variety of methods from model-based control to model-free reinforcement learning having been previously explored in literature. Perhaps one of the most powerful techniques to learn complex manipulation strategies is imitation learning. However, collecting and learning from demonstrations in dexterous manipulation is quite challenging. The complex, high-dimensional action-space involved with multi-finger control often leads to poor sample efficiency of learning-based methods. In this work, we propose 'Dexterous Imitation Made Easy' (DIME) a new imitation learning framework for dexterous manipulation. DIME only requires a single RGB camera to observe a human operator and teleoperate our robotic hand. Once demonstrations are collected, DIME employs standard imitation learning methods to train dexterous manipulation policies. On both simulation and real robot benchmarks we demonstrate that DIME can be used to solve complex, in-hand manipulation tasks such as 'flipping', 'spinning', and 'rotating' objects with the Allegro hand. Our framework along with pre-collected demonstrations is publicly available at https://nyu-robot-learning.github.io/dime.", "paper_url": "http://arxiv.org/abs/2203.13251v1", "pdf_url": "http://arxiv.org/pdf/2203.13251v1", "repo_url": null}, "2203.13250": {"publish_time": "2022-03-24", "title": "Global Tracking Transformers", "author": "Xingyi Zhou et.al.", "abstract": "We present a novel transformer-based architecture for global multi-object tracking. Our network takes a short sequence of frames as input and produces global trajectories for all objects. The core component is a global tracking transformer that operates on objects from all frames in the sequence. The transformer encodes object features from all frames, and uses trajectory queries to group them into trajectories. The trajectory queries are object features from a single frame and naturally produce unique trajectories. Our global tracking transformer does not require intermediate pairwise grouping or combinatorial association, and can be jointly trained with an object detector. It achieves competitive performance on the popular MOT17 benchmark, with 75.3 MOTA and 59.1 HOTA. More importantly, our framework seamlessly integrates into state-of-the-art large-vocabulary detectors to track any objects. Experiments on the challenging TAO dataset show that our framework consistently improves upon baselines that are based on pairwise association, outperforming published works by a significant 7.7 tracking mAP. Code is available at https://github.com/xingyizhou/GTR.", "paper_url": "http://arxiv.org/abs/2203.13250v1", "pdf_url": "http://arxiv.org/pdf/2203.13250v1", "repo_url": "https://github.com/xingyizhou/GTR"}, "2203.13249": {"publish_time": "2022-03-24", "title": "BigDetection: A Large-scale Benchmark for Improved Object Detector Pre-training", "author": "Likun Cai et.al.", "abstract": "Multiple datasets and open challenges for object detection have been introduced in recent years. To build more general and powerful object detection systems, in this paper, we construct a new large-scale benchmark termed BigDetection. Our goal is to simply leverage the training data from existing datasets (LVIS, OpenImages and Object365) with carefully designed principles, and curate a larger dataset for improved detector pre-training. Specifically, we generate a new taxonomy which unifies the heterogeneous label spaces from different sources. Our BigDetection dataset has 600 object categories and contains over 3.4M training images with 36M bounding boxes. It is much larger in multiple dimensions than previous benchmarks, which offers both opportunities and challenges. Extensive experiments demonstrate its validity as a new benchmark for evaluating different object detection methods, and its effectiveness as a pre-training dataset.", "paper_url": "http://arxiv.org/abs/2203.13249v1", "pdf_url": "http://arxiv.org/pdf/2203.13249v1", "repo_url": "https://github.com/amazon-research/bigdetection"}, "2203.13817": {"publish_time": "2022-03-25", "title": "AutoAvatar: Autoregressive Neural Fields for Dynamic Avatar Modeling", "author": "Ziqian Bai et.al.", "abstract": "Neural fields such as implicit surfaces have recently enabled avatar modeling from raw scans without explicit temporal correspondences. In this work, we exploit autoregressive modeling to further extend this notion to capture dynamic effects, such as soft-tissue deformations. Although autoregressive models are naturally capable of handling dynamics, it is non-trivial to apply them to implicit representations, as explicit state decoding is infeasible due to prohibitive memory requirements. In this work, for the first time, we enable autoregressive modeling of implicit avatars. To reduce the memory bottleneck and efficiently model dynamic implicit surfaces, we introduce the notion of articulated observer points, which relate implicit states to the explicit surface of a parametric human body model. We demonstrate that encoding implicit surfaces as a set of height fields defined on articulated observer points leads to significantly better generalization compared to a latent representation. The experiments show that our approach outperforms the state of the art, achieving plausible dynamic deformations even for unseen motions. https://zqbai-jeremy.github.io/autoavatar", "paper_url": "http://arxiv.org/abs/2203.13817v1", "pdf_url": "http://arxiv.org/pdf/2203.13817v1", "repo_url": null}, "2203.13815": {"publish_time": "2022-03-25", "title": "Versatile Multi-Modal Pre-Training for Human-Centric Perception", "author": "Fangzhou Hong et.al.", "abstract": "Human-centric perception plays a vital role in vision and graphics. But their data annotations are prohibitively expensive. Therefore, it is desirable to have a versatile pre-train model that serves as a foundation for data-efficient downstream tasks transfer. To this end, we propose the Human-Centric Multi-Modal Contrastive Learning framework HCMoCo that leverages the multi-modal nature of human data (e.g. RGB, depth, 2D keypoints) for effective representation learning. The objective comes with two main challenges: dense pre-train for multi-modality data, efficient usage of sparse human priors. To tackle the challenges, we design the novel Dense Intra-sample Contrastive Learning and Sparse Structure-aware Contrastive Learning targets by hierarchically learning a modal-invariant latent space featured with continuous and ordinal feature distribution and structure-aware semantic consistency. HCMoCo provides pre-train for different modalities by combining heterogeneous datasets, which allows efficient usage of existing task-specific human data. Extensive experiments on four downstream tasks of different modalities demonstrate the effectiveness of HCMoCo, especially under data-efficient settings (7.16% and 12% improvement on DensePose Estimation and Human Parsing). Moreover, we demonstrate the versatility of HCMoCo by exploring cross-modality supervision and missing-modality inference, validating its strong ability in cross-modal association and reasoning.", "paper_url": "http://arxiv.org/abs/2203.13815v1", "pdf_url": "http://arxiv.org/pdf/2203.13815v1", "repo_url": null}, "2203.13812": {"publish_time": "2022-03-25", "title": "Spatially Multi-conditional Image Generation", "author": "Ritika Chakraborty et.al.", "abstract": "In most scenarios, conditional image generation can be thought of as an inversion of the image understanding process. Since generic image understanding involves the solving of multiple tasks, it is natural to aim at the generation of images via multi-conditioning. However, multi-conditional image generation is a very challenging problem due to the heterogeneity and the sparsity of the (in practice) available conditioning labels. In this work, we propose a novel neural architecture to address the problem of heterogeneity and sparsity of the spatially multi-conditional labels. Our choice of spatial conditioning, such as by semantics and depth, is driven by the promise it holds for better control of the image generation process. The proposed method uses a transformer-like architecture operating pixel-wise, which receives the available labels as input tokens to merge them in a learned homogeneous space of labels. The merged labels are then used for image generation via conditional generative adversarial training. In this process, the sparsity of the labels is handled by simply dropping the input tokens corresponding to the missing labels at the desired locations, thanks to the proposed pixel-wise operating architecture. Our experiments on three benchmark datasets demonstrate the clear superiority of our method over the state-of-the-art and the compared baselines.", "paper_url": "http://arxiv.org/abs/2203.13812v1", "pdf_url": "http://arxiv.org/pdf/2203.13812v1", "repo_url": null}, "2203.13802": {"publish_time": "2022-03-25", "title": "Playing Lottery Tickets in Style Transfer Models", "author": "Meihao Kong et.al.", "abstract": "Style transfer has achieved great success and attracted a wide range of attention from both academic and industrial communities due to its flexible application scenarios. However, the dependence on pretty large VGG based autoencoder leads to existing style transfer models have a high parameter complexities which limits the application for resource-constrained devices. Unfortunately, the compression of style transfer model has less been explored. In parallel, study on the lottery ticket hypothesis (LTH) has shown great potential in finding extremely sparse matching subnetworks which can achieve on par or even better performance than original full networks when trained in isolation. In this work, we perform the first empirical study to verify whether such trainable networks also exist in style transfer models. From a wide range of style transfer methods, we choose two of the most popular style transfer models as the main testbeds, i.e., AdaIN and SANet, representing approaches of global and local transformation based style transfer respectively. Through extensive experiments and comprehensive analysis, we draw the following main conclusions. (1) Compared with fixing VGG encoder, style transfer models can benefit more from training the whole network together. (2) Using iterative magnitude pruning, we find the most sparse matching subnetworks at 89.2% in AdaIN and 73.7% in SANet, which suggests that style transfer models can play lottery tickets too. (3) Feature transformation module should also be pruned to get a sparser model without affecting the existence and quality of matching subnetworks. (4) Besides AdaIN and SANet, other models such as LST, MANet, AdaAttN and MCCNet can also play lottert tickets, which shows that LTH can be generalized to various style transfer models.", "paper_url": "http://arxiv.org/abs/2203.13802v1", "pdf_url": "http://arxiv.org/pdf/2203.13802v1", "repo_url": null}, "2203.13800": {"publish_time": "2022-03-25", "title": "Continuous Dynamic-NeRF: Spline-NeRF", "author": "Julian Knodt et.al.", "abstract": "The problem of reconstructing continuous functions over time is important for problems such as reconstructing moving scenes, and interpolating between time steps. Previous approaches that use deep-learning rely on regularization to ensure that reconstructions are approximately continuous, which works well on short sequences. As sequence length grows, though, it becomes more difficult to regularize, and it becomes less feasible to learn only through regularization. We propose a new architecture for function reconstruction based on classical Bezier splines, which ensures $C^0$ and $C^1$-continuity, where $C^0$ continuity is that $\\forall c:\\lim\\limits_{x\\to c} f(x)   = f(c)$, or more intuitively that there are no breaks at any point in the function. In order to demonstrate our architecture, we reconstruct dynamic scenes using Neural Radiance Fields, but hope it is clear that our approach is general and can be applied to a variety of problems. We recover a Bezier spline $B(\\beta, t\\in[0,1])$, parametrized by the control points $\\beta$. Using Bezier splines ensures reconstructions have $C^0$ and $C^1$ continuity, allowing for guaranteed interpolation over time. We reconstruct $\\beta$ with a multi-layer perceptron (MLP), blending machine learning with classical animation techniques. All code is available at https://github.com/JulianKnodt/nerf_atlas, and datasets are from prior work.", "paper_url": "http://arxiv.org/abs/2203.13800v1", "pdf_url": "http://arxiv.org/pdf/2203.13800v1", "repo_url": "https://github.com/JulianKnodt/nerf_atlas"}, "2203.14957": {"publish_time": "2022-03-28", "title": "Frame-wise Action Representations for Long Videos via Sequence Contrastive Learning", "author": "Minghao Chen et.al.", "abstract": "Prior works on action representation learning mainly focus on designing various architectures to extract the global representations for short video clips. In contrast, many practical applications such as video alignment have strong demand for learning dense representations for long videos. In this paper, we introduce a novel contrastive action representation learning (CARL) framework to learn frame-wise action representations, especially for long videos, in a self-supervised manner. Concretely, we introduce a simple yet efficient video encoder that considers spatio-temporal context to extract frame-wise representations. Inspired by the recent progress of self-supervised learning, we present a novel sequence contrastive loss (SCL) applied on two correlated views obtained through a series of spatio-temporal data augmentations. SCL optimizes the embedding space by minimizing the KL-divergence between the sequence similarity of two augmented views and a prior Gaussian distribution of timestamp distance. Experiments on FineGym, PennAction and Pouring datasets show that our method outperforms previous state-of-the-art by a large margin for downstream fine-grained action classification. Surprisingly, although without training on paired videos, our approach also shows outstanding performance on video alignment and fine-grained frame retrieval tasks. Code and models are available at https://github.com/minghchen/CARL_code.", "paper_url": "http://arxiv.org/abs/2203.14957v1", "pdf_url": "http://arxiv.org/pdf/2203.14957v1", "repo_url": "https://github.com/minghchen/carl_code"}, "2203.14956": {"publish_time": "2022-03-28", "title": "LiDAR Distillation: Bridging the Beam-Induced Domain Gap for 3D Object Detection", "author": "Yi Wei et.al.", "abstract": "In this paper, we propose the LiDAR Distillation to bridge the domain gap induced by different LiDAR beams for 3D object detection. In many real-world applications, the LiDAR points used by mass-produced robots and vehicles usually have fewer beams than that in large-scale public datasets. Moreover, as the LiDARs are upgraded to other product models with different beam amount, it becomes challenging to utilize the labeled data captured by previous versions' high-resolution sensors. Despite the recent progress on domain adaptive 3D detection, most methods struggle to eliminate the beam-induced domain gap. We find that it is essential to align the point cloud density of the source domain with that of the target domain during the training process. Inspired by this discovery, we propose a progressive framework to mitigate the beam-induced domain shift. In each iteration, we first generate low-beam pseudo LiDAR by downsampling the high-beam point clouds. Then the teacher-student framework is employed to distill rich information from the data with more beams. Extensive experiments on Waymo, nuScenes and KITTI datasets with three different LiDAR-based detectors demonstrate the effectiveness of our LiDAR Distillation. Notably, our approach does not increase any additional computation cost for inference.", "paper_url": "http://arxiv.org/abs/2203.14956v1", "pdf_url": "http://arxiv.org/pdf/2203.14956v1", "repo_url": "https://github.com/weiyithu/lidar-distillation"}, "2203.14954": {"publish_time": "2022-03-28", "title": "GIRAFFE HD: A High-Resolution 3D-aware Generative Model", "author": "Yang Xue et.al.", "abstract": "3D-aware generative models have shown that the introduction of 3D information can lead to more controllable image generation. In particular, the current state-of-the-art model GIRAFFE can control each object's rotation, translation, scale, and scene camera pose without corresponding supervision. However, GIRAFFE only operates well when the image resolution is low. We propose GIRAFFE HD, a high-resolution 3D-aware generative model that inherits all of GIRAFFE's controllable features while generating high-quality, high-resolution images ($512^2$ resolution and above). The key idea is to leverage a style-based neural renderer, and to independently generate the foreground and background to force their disentanglement while imposing consistency constraints to stitch them together to composite a coherent final image. We demonstrate state-of-the-art 3D controllable high-resolution image generation on multiple natural image datasets.", "paper_url": "http://arxiv.org/abs/2203.14954v1", "pdf_url": "http://arxiv.org/pdf/2203.14954v1", "repo_url": null}, "2203.14952": {"publish_time": "2022-03-28", "title": "Energy-based Latent Aligner for Incremental Learning", "author": "K J Joseph et.al.", "abstract": "Deep learning models tend to forget their earlier knowledge while incrementally learning new tasks. This behavior emerges because the parameter updates optimized for the new tasks may not align well with the updates suitable for older tasks. The resulting latent representation mismatch causes forgetting. In this work, we propose ELI: Energy-based Latent Aligner for Incremental Learning, which first learns an energy manifold for the latent representations such that previous task latents will have low energy and the current task latents have high energy values. This learned manifold is used to counter the representational shift that happens during incremental learning. The implicit regularization that is offered by our proposed methodology can be used as a plug-and-play module in existing incremental learning methodologies. We validate this through extensive evaluation on CIFAR-100, ImageNet subset, ImageNet 1k and Pascal VOC datasets. We observe consistent improvement when ELI is added to three prominent methodologies in class-incremental learning, across multiple incremental settings. Further, when added to the state-of-the-art incremental object detector, ELI provides over 5% improvement in detection accuracy, corroborating its effectiveness and complementary advantage to existing art.", "paper_url": "http://arxiv.org/abs/2203.14952v1", "pdf_url": "http://arxiv.org/pdf/2203.14952v1", "repo_url": "https://github.com/josephkj/eli"}, "2203.14949": {"publish_time": "2022-03-28", "title": "Controllable Dynamic Multi-Task Architectures", "author": "Dripta S. Raychaudhuri et.al.", "abstract": "Multi-task learning commonly encounters competition for resources among tasks, specifically when model capacity is limited. This challenge motivates models which allow control over the relative importance of tasks and total compute cost during inference time. In this work, we propose such a controllable multi-task network that dynamically adjusts its architecture and weights to match the desired task preference as well as the resource constraints. In contrast to the existing dynamic multi-task approaches that adjust only the weights within a fixed architecture, our approach affords the flexibility to dynamically control the total computational cost and match the user-preferred task importance better. We propose a disentangled training of two hypernetworks, by exploiting task affinity and a novel branching regularized loss, to take input preferences and accordingly predict tree-structured models with adapted weights. Experiments on three multi-task benchmarks, namely PASCAL-Context, NYU-v2, and CIFAR-100, show the efficacy of our approach. Project page is available at https://www.nec-labs.com/~mas/DYMU.", "paper_url": "http://arxiv.org/abs/2203.14949v1", "pdf_url": "http://arxiv.org/pdf/2203.14949v1", "repo_url": null}, "2203.15799": {"publish_time": "2022-03-29", "title": "StyleT2I: Toward Compositional and High-Fidelity Text-to-Image Synthesis", "author": "Zhiheng Li et.al.", "abstract": "Although progress has been made for text-to-image synthesis, previous methods fall short of generalizing to unseen or underrepresented attribute compositions in the input text. Lacking compositionality could have severe implications for robustness and fairness, e.g., inability to synthesize the face images of underrepresented demographic groups. In this paper, we introduce a new framework, StyleT2I, to improve the compositionality of text-to-image synthesis. Specifically, we propose a CLIP-guided Contrastive Loss to better distinguish different compositions among different sentences. To further improve the compositionality, we design a novel Semantic Matching Loss and a Spatial Constraint to identify attributes' latent directions for intended spatial region manipulations, leading to better disentangled latent representations of attributes. Based on the identified latent directions of attributes, we propose Compositional Attribute Adjustment to adjust the latent code, resulting in better compositionality of image synthesis. In addition, we leverage the $\\ell_2$-norm regularization of identified latent directions (norm penalty) to strike a nice balance between image-text alignment and image fidelity. In the experiments, we devise a new dataset split and an evaluation metric to evaluate the compositionality of text-to-image synthesis models. The results show that StyleT2I outperforms previous approaches in terms of the consistency between the input text and synthesized images and achieves higher fidelity.", "paper_url": "http://arxiv.org/abs/2203.15799v1", "pdf_url": "http://arxiv.org/pdf/2203.15799v1", "repo_url": "https://github.com/zhihengli-UR/StyleT2I"}, "2203.15798": {"publish_time": "2022-03-29", "title": "DRaCoN -- Differentiable Rasterization Conditioned Neural Radiance Fields for Articulated Avatars", "author": "Amit Raj et.al.", "abstract": "Acquisition and creation of digital human avatars is an important problem with applications to virtual telepresence, gaming, and human modeling. Most contemporary approaches for avatar generation can be viewed either as 3D-based methods, which use multi-view data to learn a 3D representation with appearance (such as a mesh, implicit surface, or volume), or 2D-based methods which learn photo-realistic renderings of avatars but lack accurate 3D representations. In this work, we present, DRaCoN, a framework for learning full-body volumetric avatars which exploits the advantages of both the 2D and 3D neural rendering techniques. It consists of a Differentiable Rasterization module, DiffRas, that synthesizes a low-resolution version of the target image along with additional latent features guided by a parametric body model. The output of DiffRas is then used as conditioning to our conditional neural 3D representation module (c-NeRF) which generates the final high-res image along with body geometry using volumetric rendering. While DiffRas helps in obtaining photo-realistic image quality, c-NeRF, which employs signed distance fields (SDF) for 3D representations, helps to obtain fine 3D geometric details. Experiments on the challenging ZJU-MoCap and Human3.6M datasets indicate that DRaCoN outperforms state-of-the-art methods both in terms of error metrics and visual quality.", "paper_url": "http://arxiv.org/abs/2203.15798v1", "pdf_url": "http://arxiv.org/pdf/2203.15798v1", "repo_url": null}, "2203.15794": {"publish_time": "2022-03-29", "title": "CHEX: CHannel EXploration for CNN Model Compression", "author": "Zejiang Hou et.al.", "abstract": "Channel pruning has been broadly recognized as an effective technique to reduce the computation and memory cost of deep convolutional neural networks. However, conventional pruning methods have limitations in that: they are restricted to pruning process only, and they require a fully pre-trained large model. Such limitations may lead to sub-optimal model quality as well as excessive memory and training cost. In this paper, we propose a novel Channel Exploration methodology, dubbed as CHEX, to rectify these problems. As opposed to pruning-only strategy, we propose to repeatedly prune and regrow the channels throughout the training process, which reduces the risk of pruning important channels prematurely. More exactly: From intra-layer's aspect, we tackle the channel pruning problem via a well known column subset selection (CSS) formulation. From inter-layer's aspect, our regrowing stages open a path for dynamically re-allocating the number of channels across all the layers under a global channel sparsity constraint. In addition, all the exploration process is done in a single training from scratch without the need of a pre-trained large model. Experimental results demonstrate that CHEX can effectively reduce the FLOPs of diverse CNN architectures on a variety of computer vision tasks, including image classification, object detection, instance segmentation, and 3D vision. For example, our compressed ResNet-50 model on ImageNet dataset achieves 76% top1 accuracy with only 25% FLOPs of the original ResNet-50 model, outperforming previous state-of-the-art channel pruning methods. The checkpoints and code are available at here .", "paper_url": "http://arxiv.org/abs/2203.15794v1", "pdf_url": "http://arxiv.org/pdf/2203.15794v1", "repo_url": null}, "2203.15793": {"publish_time": "2022-03-29", "title": "Instance Relation Graph Guided Source-Free Domain Adaptive Object Detection", "author": "Vibashan VS et.al.", "abstract": "Unsupervised Domain Adaptation (UDA) is an effective approach to tackle the issue of domain shift. Specifically, UDA methods try to align the source and target representations to improve the generalization on the target domain. Further, UDA methods work under the assumption that the source data is accessible during the adaptation process. However, in real-world scenarios, the labelled source data is often restricted due to privacy regulations, data transmission constraints, or proprietary data concerns. The Source-Free Domain Adaptation (SFDA) setting aims to alleviate these concerns by adapting a source-trained model for the target domain without requiring access to the source data. In this paper, we explore the SFDA setting for the task of adaptive object detection. To this end, we propose a novel training strategy for adapting a source-trained object detector to the target domain without source data. More precisely, we design a novel contrastive loss to enhance the target representations by exploiting the objects relations for a given target domain input. These object instance relations are modelled using an Instance Relation Graph (IRG) network, which are then used to guide the contrastive representation learning. In addition, we utilize a student-teacher based knowledge distillation strategy to avoid overfitting to the noisy pseudo-labels generated by the source-trained model. Extensive experiments on multiple object detection benchmark datasets show that the proposed approach is able to efficiently adapt source-trained object detectors to the target domain, outperforming previous state-of-the-art domain adaptive detection methods. Code is available at https://github.com/Vibashan/irg-sfda.", "paper_url": "http://arxiv.org/abs/2203.15793v1", "pdf_url": "http://arxiv.org/pdf/2203.15793v1", "repo_url": "https://github.com/vibashan/irg-sfda"}, "2203.15792": {"publish_time": "2022-03-29", "title": "Target and Task specific Source-Free Domain Adaptive Image Segmentation", "author": "Vibashan VS et.al.", "abstract": "Solving the domain shift problem during inference is essential in medical imaging as most deep-learning based solutions suffer from it. In practice, domain shifts are tackled by performing Unsupervised Domain Adaptation (UDA), where a model is adapted to an unlabeled target domain by leveraging the labelled source domain. In medical scenarios, the data comes with huge privacy concerns making it difficult to apply standard UDA techniques. Hence, a closer clinical setting is Source-Free UDA (SFUDA), where we have access to source trained model but not the source data during adaptation. Methods trying to solve SFUDA typically address the domain shift using pseudo-label based self-training techniques. However, due to domain shift, these pseudo-labels are usually of high entropy and denoising them still does not make them perfect labels to supervise the model. Therefore, adapting the source model with noisy pseudo labels reduces its segmentation capability while addressing the domain shift. To this end, we propose a two-stage approach for source-free domain adaptive image segmentation: 1) Target-specific adaptation followed by 2) Task-specific adaptation. In the first stage, we focus on generating target-specific pseudo labels while suppressing high entropy regions by proposing an Ensemble Entropy Minimization loss. We also introduce a selective voting strategy to enhance pseudo-label generation. In the second stage, we focus on adapting the network for task-specific representation by using a teacher-student self-training approach based on augmentation-guided consistency. We evaluate our proposed method on both 2D fundus datasets and 3D MRI volumes across 7 different domain shifts where we achieve better performance than recent UDA and SF-UDA methods for medical image segmentation. Code is available at https://github.com/Vibashan/tt-sfuda.", "paper_url": "http://arxiv.org/abs/2203.15792v1", "pdf_url": "http://arxiv.org/pdf/2203.15792v1", "repo_url": "https://github.com/vibashan/tt-sfuda"}, "2203.16533": {"publish_time": "2022-03-30", "title": "Large-Scale Pre-training for Person Re-identification with Noisy Labels", "author": "Dengpan Fu et.al.", "abstract": "This paper aims to address the problem of pre-training for person re-identification (Re-ID) with noisy labels. To setup the pre-training task, we apply a simple online multi-object tracking system on raw videos of an existing unlabeled Re-ID dataset \"LUPerson\" nd build the Noisy Labeled variant called \"LUPerson-NL\". Since theses ID labels automatically derived from tracklets inevitably contain noises, we develop a large-scale Pre-training framework utilizing Noisy Labels (PNL), which consists of three learning modules: supervised Re-ID learning, prototype-based contrastive learning, and label-guided contrastive learning. In principle, joint learning of these three modules not only clusters similar examples to one prototype, but also rectifies noisy labels based on the prototype assignment. We demonstrate that learning directly from raw videos is a promising alternative for pre-training, which utilizes spatial and temporal correlations as weak supervision. This simple pre-training task provides a scalable way to learn SOTA Re-ID representations from scratch on \"LUPerson-NL\" without bells and whistles. For example, by applying on the same supervised Re-ID method MGN, our pre-trained model improves the mAP over the unsupervised pre-training counterpart by 5.7%, 2.2%, 2.3% on CUHK03, DukeMTMC, and MSMT17 respectively. Under the small-scale or few-shot setting, the performance gain is even more significant, suggesting a better transferability of the learned representation. Code is available at https://github.com/DengpanFu/LUPerson-NL", "paper_url": "http://arxiv.org/abs/2203.16533v1", "pdf_url": "http://arxiv.org/pdf/2203.16533v1", "repo_url": "https://github.com/dengpanfu/luperson-nl"}, "2203.16531": {"publish_time": "2022-03-30", "title": "Understanding 3D Object Articulation in Internet Videos", "author": "Shengyi Qian et.al.", "abstract": "We propose to investigate detecting and characterizing the 3D planar articulation of objects from ordinary videos. While seemingly easy for humans, this problem poses many challenges for computers. We propose to approach this problem by combining a top-down detection system that finds planes that can be articulated along with an optimization approach that solves for a 3D plane that can explain a sequence of observed articulations. We show that this system can be trained on a combination of videos and 3D scan datasets. When tested on a dataset of challenging Internet videos and the Charades dataset, our approach obtains strong performance. Project site: https://jasonqsy.github.io/Articulation3D", "paper_url": "http://arxiv.org/abs/2203.16531v1", "pdf_url": "http://arxiv.org/pdf/2203.16531v1", "repo_url": null}, "2203.16530": {"publish_time": "2022-03-30", "title": "Learning Instance-Specific Adaptation for Cross-Domain Segmentation", "author": "Yuliang Zou et.al.", "abstract": "We propose a test-time adaptation method for cross-domain image segmentation. Our method is simple: Given a new unseen instance at test time, we adapt a pre-trained model by conducting instance-specific BatchNorm (statistics) calibration. Our approach has two core components. First, we replace the manually designed BatchNorm calibration rule with a learnable module. Second, we leverage strong data augmentation to simulate random domain shifts for learning the calibration rule. In contrast to existing domain adaptation methods, our method does not require accessing the target domain data at training time or conducting computationally expensive test-time model training/optimization. Equipping our method with models trained by standard recipes achieves significant improvement, comparing favorably with several state-of-the-art domain generalization and one-shot unsupervised domain adaptation approaches. Combining our method with the domain generalization methods further improves performance, reaching a new state of the art.", "paper_url": "http://arxiv.org/abs/2203.16530v1", "pdf_url": "http://arxiv.org/pdf/2203.16530v1", "repo_url": null}, "2203.16529": {"publish_time": "2022-03-30", "title": "CaDeX: Learning Canonical Deformation Coordinate Space for Dynamic Surface Representation via Neural Homeomorphism", "author": "Jiahui Lei et.al.", "abstract": "While neural representations for static 3D shapes are widely studied, representations for deformable surfaces are limited to be template-dependent or lack efficiency. We introduce Canonical Deformation Coordinate Space (CaDeX), a unified representation of both shape and nonrigid motion. Our key insight is the factorization of the deformation between frames by continuous bijective canonical maps (homeomorphisms) and their inverses that go through a learned canonical shape. Our novel deformation representation and its implementation are simple, efficient, and guarantee cycle consistency, topology preservation, and, if needed, volume conservation. Our modelling of the learned canonical shapes provides a flexible and stable space for shape prior learning. We demonstrate state-of-the-art performance in modelling a wide range of deformable geometries: human bodies, animal bodies, and articulated objects.", "paper_url": "http://arxiv.org/abs/2203.16529v1", "pdf_url": "http://arxiv.org/pdf/2203.16529v1", "repo_url": null}, "2203.16528": {"publish_time": "2022-03-30", "title": "L^3U-net: Low-Latency Lightweight U-net Based Image Segmentation Model for Parallel CNN Processors", "author": "Osman Erman Okman et.al.", "abstract": "In this research, we propose a tiny image segmentation model, L^3U-net, that works on low-resource edge devices in real-time. We introduce a data folding technique that reduces inference latency by leveraging the parallel convolutional layer processing capability of the CNN accelerators. We also deploy the proposed model to such a device, MAX78000, and the results show that L^3U-net achieves more than 90% accuracy over two different segmentation datasets with 10 fps.", "paper_url": "http://arxiv.org/abs/2203.16528v1", "pdf_url": "http://arxiv.org/pdf/2203.16528v1", "repo_url": null}, "2203.17276": {"publish_time": "2022-03-31", "title": "Bringing Old Films Back to Life", "author": "Ziyu Wan et.al.", "abstract": "We present a learning-based framework, recurrent transformer network (RTN), to restore heavily degraded old films. Instead of performing frame-wise restoration, our method is based on the hidden knowledge learned from adjacent frames that contain abundant information about the occlusion, which is beneficial to restore challenging artifacts of each frame while ensuring temporal coherency. Moreover, contrasting the representation of the current frame and the hidden knowledge makes it possible to infer the scratch position in an unsupervised manner, and such defect localization generalizes well to real-world degradations. To better resolve mixed degradation and compensate for the flow estimation error during frame alignment, we propose to leverage more expressive transformer blocks for spatial restoration. Experiments on both synthetic dataset and real-world old films demonstrate the significant superiority of the proposed RTN over existing solutions. In addition, the same framework can effectively propagate the color from keyframes to the whole video, ultimately yielding compelling restored films. The implementation and model will be released at https://github.com/raywzy/Bringing-Old-Films-Back-to-Life.", "paper_url": "http://arxiv.org/abs/2203.17276v1", "pdf_url": "http://arxiv.org/pdf/2203.17276v1", "repo_url": "https://github.com/raywzy/bringing-old-films-back-to-life"}, "2203.17275": {"publish_time": "2022-03-31", "title": "DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools", "author": "Xingyu Lin et.al.", "abstract": "We consider the problem of sequential robotic manipulation of deformable objects using tools. Previous works have shown that differentiable physics simulators provide gradients to the environment state and help trajectory optimization to converge orders of magnitude faster than model-free reinforcement learning algorithms for deformable object manipulation. However, such gradient-based trajectory optimization typically requires access to the full simulator states and can only solve short-horizon, single-skill tasks due to local optima. In this work, we propose a novel framework, named DiffSkill, that uses a differentiable physics simulator for skill abstraction to solve long-horizon deformable object manipulation tasks from sensory observations. In particular, we first obtain short-horizon skills using individual tools from a gradient-based optimizer, using the full state information in a differentiable simulator; we then learn a neural skill abstractor from the demonstration trajectories which takes RGBD images as input. Finally, we plan over the skills by finding the intermediate goals and then solve long-horizon tasks. We show the advantages of our method in a new set of sequential deformable object manipulation tasks compared to previous reinforcement learning algorithms and compared to the trajectory optimizer.", "paper_url": "http://arxiv.org/abs/2203.17275v1", "pdf_url": "http://arxiv.org/pdf/2203.17275v1", "repo_url": null}, "2203.17273": {"publish_time": "2022-03-31", "title": "FindIt: Generalized Localization with Natural Language Queries", "author": "Weicheng Kuo et.al.", "abstract": "We propose FindIt, a simple and versatile framework that unifies a variety of visual grounding and localization tasks including referring expression comprehension, text-based localization, and object detection. Key to our architecture is an efficient multi-scale fusion module that unifies the disparate localization requirements across the tasks. In addition, we discover that a standard object detector is surprisingly effective in unifying these tasks without a need for task-specific design, losses, or pre-computed detections. Our end-to-end trainable framework responds flexibly and accurately to a wide range of referring expression, localization or detection queries for zero, one, or multiple objects. Jointly trained on these tasks, FindIt outperforms the state of the art on both referring expression and text-based localization, and shows competitive performance on object detection. Finally, FindIt generalizes better to out-of-distribution data and novel categories compared to strong single-task baselines. All of these are accomplished by a single, unified and efficient model. The code will be released.", "paper_url": "http://arxiv.org/abs/2203.17273v1", "pdf_url": "http://arxiv.org/pdf/2203.17273v1", "repo_url": null}, "2203.17274": {"publish_time": "2022-03-31", "title": "Visual Prompting: Modifying Pixel Space to Adapt Pre-trained Models", "author": "Hyojin Bahng et.al.", "abstract": "Prompting has recently become a popular paradigm for adapting language models to downstream tasks. Rather than fine-tuning model parameters or adding task-specific heads, this approach steers a model to perform a new task simply by adding a text prompt to the model's inputs. In this paper, we explore the question: can we create prompts with pixels instead? In other words, can pre-trained vision models be adapted to a new task solely by adding pixels to their inputs? We introduce visual prompting, which learns a task-specific image perturbation such that a frozen pre-trained model prompted with this perturbation performs a new task. We discover that changing only a few pixels is enough to adapt models to new tasks and datasets, and performs on par with linear probing, the current de facto approach to lightweight adaptation. The surprising effectiveness of visual prompting provides a new perspective on how to adapt pre-trained models in vision, and opens up the possibility of adapting models solely through their inputs, which, unlike model parameters or outputs, are typically under an end-user's control. Code is available at http://hjbahng.github.io/visual_prompting .", "paper_url": "http://arxiv.org/abs/2203.17274v1", "pdf_url": "http://arxiv.org/pdf/2203.17274v1", "repo_url": null}, "2203.17272": {"publish_time": "2022-03-31", "title": "MyStyle: A Personalized Generative Prior", "author": "Yotam Nitzan et.al.", "abstract": "We introduce MyStyle, a personalized deep generative prior trained with a few shots of an individual. MyStyle allows to reconstruct, enhance and edit images of a specific person, such that the output is faithful to the person's key facial characteristics. Given a small reference set of portrait images of a person (~100), we tune the weights of a pretrained StyleGAN face generator to form a local, low-dimensional, personalized manifold in the latent space. We show that this manifold constitutes a personalized region that spans latent codes associated with diverse portrait images of the individual. Moreover, we demonstrate that we obtain a personalized generative prior, and propose a unified approach to apply it to various ill-posed image enhancement problems, such as inpainting and super-resolution, as well as semantic editing. Using the personalized generative prior we obtain outputs that exhibit high-fidelity to the input images and are also faithful to the key facial characteristics of the individual in the reference set. We demonstrate our method with fair-use images of numerous widely recognizable individuals for whom we have the prior knowledge for a qualitative evaluation of the expected outcome. We evaluate our approach against few-shots baselines and show that our personalized prior, quantitatively and qualitatively, outperforms state-of-the-art alternatives.", "paper_url": "http://arxiv.org/abs/2203.17272v1", "pdf_url": "http://arxiv.org/pdf/2203.17272v1", "repo_url": null}, "2204.00616": {"publish_time": "2022-04-01", "title": "Simplicial Embeddings in Self-Supervised Learning and Downstream Classification", "author": "Samuel Lavoie et.al.", "abstract": "We introduce Simplicial Embeddings (SEMs) as a way to constrain the encoded representations of a self-supervised model to $L$ simplices of $V$ dimensions each using a Softmax operation. This procedure imposes a structure on the representations that reduce their expressivity for training downstream classifiers, which helps them generalize better. Specifically, we show that the temperature $\\tau$ of the Softmax operation controls for the SEM representation's expressivity, allowing us to derive a tighter downstream classifier generalization bound than that for classifiers using unnormalized representations. We empirically demonstrate that SEMs considerably improve generalization on natural image datasets such as CIFAR-100 and ImageNet. Finally, we also present evidence of the emergence of semantically relevant features in SEMs, a pattern that is absent from baseline self-supervised models.", "paper_url": "http://arxiv.org/abs/2204.00616v1", "pdf_url": "http://arxiv.org/pdf/2204.00616v1", "repo_url": null}, "2204.00613": {"publish_time": "2022-04-01", "title": "On the Importance of Asymmetry for Siamese Representation Learning", "author": "Xiao Wang et.al.", "abstract": "Many recent self-supervised frameworks for visual representation learning are based on certain forms of Siamese networks. Such networks are conceptually symmetric with two parallel encoders, but often practically asymmetric as numerous mechanisms are devised to break the symmetry. In this work, we conduct a formal study on the importance of asymmetry by explicitly distinguishing the two encoders within the network -- one produces source encodings and the other targets. Our key insight is keeping a relatively lower variance in target than source generally benefits learning. This is empirically justified by our results from five case studies covering different variance-oriented designs, and is aligned with our preliminary theoretical analysis on the baseline. Moreover, we find the improvements from asymmetric designs generalize well to longer training schedules, multiple other frameworks and newer backbones. Finally, the combined effect of several asymmetric designs achieves a state-of-the-art accuracy on ImageNet linear probing and competitive results on downstream transfer. We hope our exploration will inspire more research in exploiting asymmetry for Siamese representation learning.", "paper_url": "http://arxiv.org/abs/2204.00613v1", "pdf_url": "http://arxiv.org/pdf/2204.00613v1", "repo_url": "https://github.com/facebookresearch/asym-siam"}, "2204.00604": {"publish_time": "2022-04-01", "title": "Quantized GAN for Complex Music Generation from Dance Videos", "author": "Ye Zhu et.al.", "abstract": "We present Dance2Music-GAN (D2M-GAN), a novel adversarial multi-modal framework that generates complex musical samples conditioned on dance videos. Our proposed framework takes dance video frames and human body motion as input, and learns to generate music samples that plausibly accompany the corresponding input. Unlike most existing conditional music generation works that generate specific types of mono-instrumental sounds using symbolic audio representations (e.g., MIDI), and that heavily rely on pre-defined musical synthesizers, in this work we generate dance music in complex styles (e.g., pop, breakdancing, etc.) by employing a Vector Quantized (VQ) audio representation, and leverage both its generality and the high abstraction capacity of its symbolic and continuous counterparts. By performing an extensive set of experiments on multiple datasets, and following a comprehensive evaluation protocol, we assess the generative quality of our approach against several alternatives. The quantitative results, which measure the music consistency, beats correspondence, and music diversity, clearly demonstrate the effectiveness of our proposed method. Last but not least, we curate a challenging dance-music dataset of in-the-wild TikTok videos, which we use to further demonstrate the efficacy of our approach in real-world applications - and which we hope to serve as a starting point for relevant future research.", "paper_url": "http://arxiv.org/abs/2204.00604v1", "pdf_url": "http://arxiv.org/pdf/2204.00604v1", "repo_url": "https://github.com/l-yezhu/d2m-gan"}, "2204.00598": {"publish_time": "2022-04-01", "title": "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language", "author": "Andy Zeng et.al.", "abstract": "Large foundation models can exhibit unique capabilities depending on the domain of data they are trained on. While these domains are generic, they may only barely overlap. For example, visual-language models (VLMs) are trained on Internet-scale image captions, but large language models (LMs) are further trained on Internet-scale text with no images (e.g. from spreadsheets, to SAT questions). As a result, these models store different forms of commonsense knowledge across different domains. In this work, we show that this model diversity is symbiotic, and can be leveraged to build AI systems with structured Socratic dialogue -- in which new multimodal tasks are formulated as a guided language-based exchange between different pre-existing foundation models, without additional finetuning. In the context of egocentric perception, we present a case study of Socratic Models (SMs) that can provide meaningful results for complex tasks such as generating free-form answers to contextual questions about egocentric video, by formulating video Q&A as short story Q&A, i.e. summarizing the video into a short story, then answering questions about it. Additionally, SMs can generate captions for Internet images, and are competitive with state-of-the-art on zero-shot video-to-text retrieval with 42.8 R@1 on MSR-VTT 1k-A. SMs demonstrate how to compose foundation models zero-shot to capture new multimodal functionalities, without domain-specific data collection. Prototypes are available at socraticmodels.github.io.", "paper_url": "http://arxiv.org/abs/2204.00598v1", "pdf_url": "http://arxiv.org/pdf/2204.00598v1", "repo_url": null}, "2204.00597": {"publish_time": "2022-04-01", "title": "Fast and Automatic Object Registration for Human-Robot Collaboration in Industrial Manufacturing", "author": "Manuela Gei\u00df et.al.", "abstract": "We present an end-to-end framework for fast retraining of object detection models in human-robot-collaboration. Our Faster R-CNN based setup covers the whole workflow of automatic image generation and labeling, model retraining on-site as well as inference on a FPGA edge device. The intervention of a human operator reduces to providing the new object together with its label and starting the training process. Moreover, we present a new loss, the intraspread-objectosphere loss, to tackle the problem of open world recognition. Though it fails to completely solve the problem, it significantly reduces the number of false positive detections of unknown objects.", "paper_url": "http://arxiv.org/abs/2204.00597v1", "pdf_url": "http://arxiv.org/pdf/2204.00597v1", "repo_url": null}, "2204.01697": {"publish_time": "2022-04-04", "title": "MaxViT: Multi-Axis Vision Transformer", "author": "Zhengzhong Tu et.al.", "abstract": "Transformers have recently gained significant attention in the computer vision community. However, the lack of scalability of self-attention mechanisms with respect to image size has limited their wide adoption in state-of-the-art vision backbones. In this paper we introduce an efficient and scalable attention model we call multi-axis attention, which consists of two aspects: blocked local and dilated global attention. These design choices allow global-local spatial interactions on arbitrary input resolutions with only linear complexity. We also present a new architectural element by effectively blending our proposed attention model with convolutions, and accordingly propose a simple hierarchical vision backbone, dubbed MaxViT, by simply repeating the basic building block over multiple stages. Notably, MaxViT is able to \"see\" globally throughout the entire network, even in earlier, high-resolution stages. We demonstrate the effectiveness of our model on a broad spectrum of vision tasks. On image classification, MaxViT achieves state-of-the-art performance under various settings: without extra data, MaxViT attains 86.5\\% ImageNet-1K top-1 accuracy; with ImageNet-21K pre-training, our model achieves 88.7\\% top-1 accuracy. For downstream tasks, MaxViT as a backbone delivers favorable performance on object detection as well as visual aesthetic assessment. We also show that our proposed model expresses strong generative modeling capability on ImageNet, demonstrating the superior potential of MaxViT blocks as a universal vision module. We will make the code and models publicly available.", "paper_url": "http://arxiv.org/abs/2204.01697v1", "pdf_url": "http://arxiv.org/pdf/2204.01697v1", "repo_url": null}, "2204.00628": {"publish_time": "2022-04-04", "title": "Learning Neural Acoustic Fields", "author": "Andrew Luo et.al.", "abstract": "Our environment is filled with rich and dynamic acoustic information. When we walk into a cathedral, the reverberations as much as appearance inform us of the sanctuary's wide open space. Similarly, as an object moves around us, we expect the sound emitted to also exhibit this movement. While recent advances in learned implicit functions have led to increasingly higher quality representations of the visual world, there have not been commensurate advances in learning spatial auditory representations. To address this gap, we introduce Neural Acoustic Fields (NAFs), an implicit representation that captures how sounds propagate in a physical scene. By modeling acoustic propagation in a scene as a linear time-invariant system, NAFs learn to continuously map all emitter and listener location pairs to a neural impulse response function that can then be applied to arbitrary sounds. We demonstrate that the continuous nature of NAFs enables us to render spatial acoustics for a listener at an arbitrary location, and can predict sound propagation at novel locations. We further show that the representation learned by NAFs can help improve visual learning with sparse views. Finally, we show that a representation informative of scene structure emerges during the learning of NAFs.", "paper_url": "http://arxiv.org/abs/2204.00628v1", "pdf_url": "http://arxiv.org/pdf/2204.00628v1", "repo_url": null}, "2204.01695": {"publish_time": "2022-04-04", "title": "LISA: Learning Implicit Shape and Appearance of Hands", "author": "Enric Corona et.al.", "abstract": "This paper proposes a do-it-all neural model of human hands, named LISA. The model can capture accurate hand shape and appearance, generalize to arbitrary hand subjects, provide dense surface correspondences, be reconstructed from images in the wild and easily animated. We train LISA by minimizing the shape and appearance losses on a large set of multi-view RGB image sequences annotated with coarse 3D poses of the hand skeleton. For a 3D point in the hand local coordinate, our model predicts the color and the signed distance with respect to each hand bone independently, and then combines the per-bone predictions using predicted skinning weights. The shape, color and pose representations are disentangled by design, allowing to estimate or animate only selected parameters. We experimentally demonstrate that LISA can accurately reconstruct a dynamic hand from monocular or multi-view sequences, achieving a noticeably higher quality of reconstructed hand shapes compared to baseline approaches. Project page: https://www.iri.upc.edu/people/ecorona/lisa/.", "paper_url": "http://arxiv.org/abs/2204.01695v1", "pdf_url": "http://arxiv.org/pdf/2204.01695v1", "repo_url": null}, "2204.01696": {"publish_time": "2022-04-04", "title": "Joint Hand Motion and Interaction Hotspots Prediction from Egocentric Videos", "author": "Shaowei Liu et.al.", "abstract": "We propose to forecast future hand-object interactions given an egocentric video. Instead of predicting action labels or pixels, we directly predict the hand motion trajectory and the future contact points on the next active object (i.e., interaction hotspots). This relatively low-dimensional representation provides a concrete description of future interactions. To tackle this task, we first provide an automatic way to collect trajectory and hotspots labels on large-scale data. We then use this data to train an Object-Centric Transformer (OCT) model for prediction. Our model performs hand and object interaction reasoning via the self-attention mechanism in Transformers. OCT also provides a probabilistic framework to sample the future trajectory and hotspots to handle uncertainty in prediction. We perform experiments on the Epic-Kitchens-55, Epic-Kitchens-100, and EGTEA Gaze+ datasets, and show that OCT significantly outperforms state-of-the-art approaches by a large margin. Project page is available at https://stevenlsw.github.io/hoi-forecast .", "paper_url": "http://arxiv.org/abs/2204.01696v1", "pdf_url": "http://arxiv.org/pdf/2204.01696v1", "repo_url": null}, "2204.01694": {"publish_time": "2022-04-04", "title": "\"This is my unicorn, Fluffy\": Personalizing frozen vision-language representations", "author": "Niv Cohen et.al.", "abstract": "Large Vision & Language models pretrained on web-scale data provide representations that are invaluable for numerous V&L problems. However, it is unclear how they can be used for reasoning about user-specific visual concepts in unstructured language. This problem arises in multiple domains, from personalized image retrieval to personalized interaction with smart devices. We introduce a new learning setup called Personalized Vision & Language (PerVL) with two new benchmark datasets for retrieving and segmenting user-specific \"personalized\" concepts \"in the wild\". In PerVL, one should learn personalized concepts (1) independently of the downstream task (2) allowing a pretrained model to reason about them with free language, and (3) does not require personalized negative examples. We propose an architecture for solving PerVL that operates by extending the input vocabulary of a pretrained model with new word embeddings for the new personalized concepts. The model can then reason about them by simply using them in a sentence. We demonstrate that our approach learns personalized visual concepts from a few examples and can effectively apply them in image retrieval and semantic segmentation using rich textual queries.", "paper_url": "http://arxiv.org/abs/2204.01694v1", "pdf_url": "http://arxiv.org/pdf/2204.01694v1", "repo_url": null}, "2204.02397": {"publish_time": "2022-04-05", "title": "SALISA: Saliency-based Input Sampling for Efficient Video Object Detection", "author": "Babak Ehteshami Bejnordi et.al.", "abstract": "High-resolution images are widely adopted for high-performance object detection in videos. However, processing high-resolution inputs comes with high computation costs, and naive down-sampling of the input to reduce the computation costs quickly degrades the detection performance. In this paper, we propose SALISA, a novel non-uniform SALiency-based Input SAmpling technique for video object detection that allows for heavy down-sampling of unimportant background regions while preserving the fine-grained details of a high-resolution image. The resulting image is spatially smaller, leading to reduced computational costs while enabling a performance comparable to a high-resolution input. To achieve this, we propose a differentiable resampling module based on a thin plate spline spatial transformer network (TPS-STN). This module is regularized by a novel loss to provide an explicit supervision signal to learn to \"magnify\" salient regions. We report state-of-the-art results in the low compute regime on the ImageNet-VID and UA-DETRAC video object detection datasets. We demonstrate that on both datasets, the mAP of an EfficientDet-D1 (EfficientDet-D2) gets on par with EfficientDet-D2 (EfficientDet-D3) at a much lower computational cost. We also show that SALISA significantly improves the detection of small objects. In particular, SALISA with an EfficientDet-D1 detector improves the detection of small objects by $77\\%$, and remarkably also outperforms EfficientDetD3 baseline.", "paper_url": "http://arxiv.org/abs/2204.02397v1", "pdf_url": "http://arxiv.org/pdf/2204.02397v1", "repo_url": null}, "2204.02394": {"publish_time": "2022-04-05", "title": "SE(3)-Equivariant Attention Networks for Shape Reconstruction in Function Space", "author": "Evangelos Chatzipantazis et.al.", "abstract": "We propose the first SE(3)-equivariant coordinate-based network for learning occupancy fields from point clouds. In contrast to previous shape reconstruction methods that align the input to a regular grid, we operate directly on the irregular, unoriented point cloud. We leverage attention mechanisms in order to preserve the set structure (permutation equivariance and variable length) of the input. At the same time, attention layers enable local shape modelling, a crucial property for scalability to large scenes. In contrast to architectures that create a global signature for the shape, we operate on local tokens. Given an unoriented, sparse, noisy point cloud as input, we produce equivariant features for each point. These serve as keys and values for the subsequent equivariant cross-attention blocks that parametrize the occupancy field. By querying an arbitrary point in space, we predict its occupancy score. We show that our method outperforms previous SO(3)-equivariant methods, as well as non-equivariant methods trained on SO(3)-augmented datasets. More importantly, local modelling together with SE(3)-equivariance create an ideal setting for SE(3) scene reconstruction. We show that by training only on single objects and without any pre-segmentation, we can reconstruct a novel scene with single-object performance.", "paper_url": "http://arxiv.org/abs/2204.02394v1", "pdf_url": "http://arxiv.org/pdf/2204.02394v1", "repo_url": null}, "2204.02393": {"publish_time": "2022-04-05", "title": "Action-Conditioned Contrastive Policy Pretraining", "author": "Qihang Zhang et.al.", "abstract": "Deep visuomotor policy learning achieves promising results in control tasks such as robotic manipulation and autonomous driving, where the action is generated from the visual input by the neural policy. However, it requires a huge number of online interactions with the training environment, which limits its real-world application. Compared to the popular unsupervised feature learning for visual recognition, feature pretraining for visuomotor control tasks is much less explored. In this work, we aim to pretrain policy representations for driving tasks using hours-long uncurated YouTube videos. A new contrastive policy pretraining method is developed to learn action-conditioned features from video frames with action pseudo labels. Experiments show that the resulting action-conditioned features bring substantial improvements to the downstream reinforcement learning and imitation learning tasks, outperforming the weights pretrained from previous unsupervised learning methods. Code and models will be made publicly available.", "paper_url": "http://arxiv.org/abs/2204.02393v1", "pdf_url": "http://arxiv.org/pdf/2204.02393v1", "repo_url": null}, "2204.02390": {"publish_time": "2022-04-05", "title": "Learning Pneumatic Non-Prehensile Manipulation with a Mobile Blower", "author": "Jimmy Wu et.al.", "abstract": "We investigate pneumatic non-prehensile manipulation (i.e., blowing) as a means of efficiently moving scattered objects into a target receptacle. Due to the chaotic nature of aerodynamic forces, a blowing controller must (i) continually adapt to unexpected changes from its actions, (ii) maintain fine-grained control, since the slightest misstep can result in large unintended consequences (e.g., scatter objects already in a pile), and (iii) infer long-range plans (e.g., move the robot to strategic blowing locations). We tackle these challenges in the context of deep reinforcement learning, introducing a multi-frequency version of the spatial action maps framework. This allows for efficient learning of vision-based policies that effectively combine high-level planning and low-level closed-loop control for dynamic mobile manipulation. Experiments show that our system learns efficient behaviors for the task, demonstrating in particular that blowing achieves better downstream performance than pushing, and that our policies improve performance over baselines. Moreover, we show that our system naturally encourages emergent specialization between the different subpolicies spanning low-level fine-grained control and high-level planning. On a real mobile robot equipped with a miniature air blower, we show that our simulation-trained policies transfer well to a real environment and can generalize to novel objects.", "paper_url": "http://arxiv.org/abs/2204.02390v1", "pdf_url": "http://arxiv.org/pdf/2204.02390v1", "repo_url": null}, "2204.02389": {"publish_time": "2022-04-05", "title": "ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer", "author": "Ruohan Gao et.al.", "abstract": "Objects play a crucial role in our everyday activities. Though multisensory object-centric learning has shown great potential lately, the modeling of objects in prior work is rather unrealistic. ObjectFolder 1.0 is a recent dataset that introduces 100 virtualized objects with visual, acoustic, and tactile sensory data. However, the dataset is small in scale and the multisensory data is of limited quality, hampering generalization to real-world scenarios. We present ObjectFolder 2.0, a large-scale, multisensory dataset of common household objects in the form of implicit neural representations that significantly enhances ObjectFolder 1.0 in three aspects. First, our dataset is 10 times larger in the amount of objects and orders of magnitude faster in rendering time. Second, we significantly improve the multisensory rendering quality for all three modalities. Third, we show that models learned from virtual objects in our dataset successfully transfer to their real-world counterparts in three challenging tasks: object scale estimation, contact localization, and shape reconstruction. ObjectFolder 2.0 offers a new path and testbed for multisensory learning in computer vision and robotics. The dataset is available at https://github.com/rhgao/ObjectFolder.", "paper_url": "http://arxiv.org/abs/2204.02389v1", "pdf_url": "http://arxiv.org/pdf/2204.02389v1", "repo_url": "https://github.com/rhgao/objectfolder"}, "2204.02968": {"publish_time": "2022-04-06", "title": "Temporal Alignment Networks for Long-term Video", "author": "Tengda Han et.al.", "abstract": "The objective of this paper is a temporal alignment network that ingests long term video sequences, and associated text sentences, in order to: (1) determine if a sentence is alignable with the video; and (2) if it is alignable, then determine its alignment. The challenge is to train such networks from large-scale datasets, such as HowTo100M, where the associated text sentences have significant noise, and are only weakly aligned when relevant. Apart from proposing the alignment network, we also make four contributions: (i) we describe a novel co-training method that enables to denoise and train on raw instructional videos without using manual annotation, despite the considerable noise; (ii) to benchmark the alignment performance, we manually curate a 10-hour subset of HowTo100M, totalling 80 videos, with sparse temporal descriptions. Our proposed model, trained on HowTo100M, outperforms strong baselines (CLIP, MIL-NCE) on this alignment dataset by a significant margin; (iii) we apply the trained model in the zero-shot settings to multiple downstream video understanding tasks and achieve state-of-the-art results, including text-video retrieval on YouCook2, and weakly supervised video action segmentation on Breakfast-Action; (iv) we use the automatically aligned HowTo100M annotations for end-to-end finetuning of the backbone model, and obtain improved performance on downstream action recognition tasks.", "paper_url": "http://arxiv.org/abs/2204.02968v1", "pdf_url": "http://arxiv.org/pdf/2204.02968v1", "repo_url": null}, "2204.02965": {"publish_time": "2022-04-06", "title": "LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification", "author": "Sharath Girish et.al.", "abstract": "We introduce LilNetX, an end-to-end trainable technique for neural networks that enables learning models with specified accuracy-rate-computation trade-off. Prior works approach these problems one at a time and often require post-processing or multistage training which become less practical and do not scale very well for large datasets or architectures. Our method constructs a joint training objective that penalizes the self-information of network parameters in a reparameterized latent space to encourage small model size while also introducing priors to increase structured sparsity in the parameter space to reduce computation. We achieve up to 50% smaller model size and 98% model sparsity on ResNet-20 while retaining the same accuracy on the CIFAR-10 dataset as well as 35% smaller model size and 42% structured sparsity on ResNet-50 trained on ImageNet, when compared to existing state-of-the-art model compression methods. Code is available at https://github.com/Sharath-girish/LilNetX.", "paper_url": "http://arxiv.org/abs/2204.02965v1", "pdf_url": "http://arxiv.org/pdf/2204.02965v1", "repo_url": "https://github.com/sharath-girish/lilnetx"}, "2204.02964": {"publish_time": "2022-04-06", "title": "Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection", "author": "Yuxin Fang et.al.", "abstract": "We present an approach to efficiently and effectively adapt a masked image modeling (MIM) pre-trained vanilla Vision Transformer (ViT) for object detection, which is based on our two novel observations: (i) A MIM pre-trained vanilla ViT can work surprisingly well in the challenging object-level recognition scenario even with random sampled partial observations, e.g., only 25% ~ 50% of the input sequence. (ii) In order to construct multi-scale representations for object detection, a random initialized compact convolutional stem supplants the pre-trained large kernel patchify stem, and its intermediate features can naturally serve as the higher resolution inputs of a feature pyramid without upsampling. While the pre-trained ViT is only regarded as the third-stage of our detector's backbone instead of the whole feature extractor, resulting in a ConvNet-ViT hybrid architecture. The proposed detector, named MIMDet, enables a MIM pre-trained vanilla ViT to outperform hierarchical Swin Transformer by 2.3 box AP and 2.5 mask AP on COCO, and achieve even better results compared with other adapted vanilla ViT using a more modest fine-tuning recipe while converging 2.8x faster. Code and pre-trained models are available at \\url{https://github.com/hustvl/MIMDet}.", "paper_url": "http://arxiv.org/abs/2204.02964v1", "pdf_url": "http://arxiv.org/pdf/2204.02964v1", "repo_url": "https://github.com/hustvl/mimdet"}, "2204.02961": {"publish_time": "2022-04-06", "title": "SMU-Net: Style matching U-Net for brain tumor segmentation with missing modalities", "author": "Reza Azad et.al.", "abstract": "Gliomas are one of the most prevalent types of primary brain tumours, accounting for more than 30\\% of all cases and they develop from the glial stem or progenitor cells. In theory, the majority of brain tumours could well be identified exclusively by the use of Magnetic Resonance Imaging (MRI). Each MRI modality delivers distinct information on the soft tissue of the human brain and integrating all of them would provide comprehensive data for the accurate segmentation of the glioma, which is crucial for the patient's prognosis, diagnosis, and determining the best follow-up treatment. Unfortunately, MRI is prone to artifacts for a variety of reasons, which might result in missing one or more MRI modalities. Various strategies have been proposed over the years to synthesize the missing modality or compensate for the influence it has on automated segmentation models. However, these methods usually fail to model the underlying missing information. In this paper, we propose a style matching U-Net (SMU-Net) for brain tumour segmentation on MRI images. Our co-training approach utilizes a content and style-matching mechanism to distill the informative features from the full-modality network into a missing modality network. To do so, we encode both full-modality and missing-modality data into a latent space, then we decompose the representation space into a style and content representation. Our style matching module adaptively recalibrates the representation space by learning a matching function to transfer the informative and textural features from a full-modality path into a missing-modality path. Moreover, by modelling the mutual information, our content module surpasses the less informative features and re-calibrates the representation space based on discriminative semantic features. The evaluation process on the BraTS 2018 dataset shows a significant results.", "paper_url": "http://arxiv.org/abs/2204.02961v1", "pdf_url": "http://arxiv.org/pdf/2204.02961v1", "repo_url": "https://github.com/rezazad68/smunet"}, "2204.02960": {"publish_time": "2022-04-06", "title": "Simple and Effective Synthesis of Indoor 3D Scenes", "author": "Jing Yu Koh et.al.", "abstract": "We study the problem of synthesizing immersive 3D indoor scenes from one or more images. Our aim is to generate high-resolution images and videos from novel viewpoints, including viewpoints that extrapolate far beyond the input images while maintaining 3D consistency. Existing approaches are highly complex, with many separately trained stages and components. We propose a simple alternative: an image-to-image GAN that maps directly from reprojections of incomplete point clouds to full high-resolution RGB-D images. On the Matterport3D and RealEstate10K datasets, our approach significantly outperforms prior work when evaluated by humans, as well as on FID scores. Further, we show that our model is useful for generative data augmentation. A vision-and-language navigation (VLN) agent trained with trajectories spatially-perturbed by our model improves success rate by up to 1.5% over a state of the art baseline on the R2R benchmark. Our code will be made available to facilitate generative data augmentation and applications to downstream robotics and embodied AI tasks.", "paper_url": "http://arxiv.org/abs/2204.02960v1", "pdf_url": "http://arxiv.org/pdf/2204.02960v1", "repo_url": null}, "2204.03649": {"publish_time": "2022-04-07", "title": "Unsupervised Prompt Learning for Vision-Language Models", "author": "Tony Huang et.al.", "abstract": "Contrastive vision-language models like CLIP have shown great progress in zero-shot transfer learning. This new paradigm uses large-scale image-text pairs for training and aligns images and texts in a common embedding space. In the inference stage, the proper text description, known as prompt, needs to be carefully designed for zero-shot transfer. To avoid laborious prompt engineering and simultaneously improve transfer performance, recent works such as CoOp, CLIP-Adapter and Tip-Adapter propose to adapt vision-language models for downstream image recognition tasks by either optimizing the continuous prompt representations or training an additional adapter network on top of the pre-trained vision-language models on a small set of labeled data. Though promising improvements are achieved, using labeled images from target datasets may violate the intention of zero-shot transfer of pre-trained vision-language models. In this paper, we propose an unsupervised prompt learning (UPL) framework, which does not require any annotations of the target dataset, to improve the zero-shot transfer of CLIP-like vision-language models. Experimentally, for zero-shot transfer, our UPL outperforms original CLIP with prompt engineering and on ImageNet as well as other 10 datasets. An enhanced version of UPL is even on par with the 8-shot CoOp and the 8-shot TIP-Adapter on most datasets while our method does not need any labeled images for training. Code and models are available at https://github.com/tonyhuang2022/UPL.", "paper_url": "http://arxiv.org/abs/2204.03649v1", "pdf_url": "http://arxiv.org/pdf/2204.03649v1", "repo_url": "https://github.com/tonyhuang2022/upl"}, "2204.03648": {"publish_time": "2022-04-07", "title": "SunStage: Portrait Reconstruction and Relighting using the Sun as a Light Stage", "author": "Yifan Wang et.al.", "abstract": "Outdoor portrait photographs are often marred by the harsh shadows cast under direct sunlight. To resolve this, one can use post-capture lighting manipulation techniques, but these methods either require complex hardware (e.g., a light stage) to capture each individual, or rely on image-based priors and thus fail to reconstruct many of the subtle facial details that vary from person to person. In this paper, we present SunStage, a system for accurate, individually-tailored, and lightweight reconstruction of facial geometry and reflectance that can be used for general portrait relighting with cast shadows. Our method only requires the user to capture a selfie video outdoors, rotating in place, and uses the varying angles between the sun and the face as constraints in the joint reconstruction of facial geometry, reflectance properties, and lighting parameters. Aside from relighting, we show that our reconstruction can be used for applications like reflectance editing and view synthesis. Results and interactive demos are available at https://grail.cs.washington.edu/projects/sunstage/.", "paper_url": "http://arxiv.org/abs/2204.03648v1", "pdf_url": "http://arxiv.org/pdf/2204.03648v1", "repo_url": null}, "2204.03647": {"publish_time": "2022-04-07", "title": "Adapting CLIP For Phrase Localization Without Further Training", "author": "Jiahao Li et.al.", "abstract": "Supervised or weakly supervised methods for phrase localization (textual grounding) either rely on human annotations or some other supervised models, e.g., object detectors. Obtaining these annotations is labor-intensive and may be difficult to scale in practice. We propose to leverage recent advances in contrastive language-vision models, CLIP, pre-trained on image and caption pairs collected from the internet. In its original form, CLIP only outputs an image-level embedding without any spatial resolution. We adapt CLIP to generate high-resolution spatial feature maps. Importantly, we can extract feature maps from both ViT and ResNet CLIP model while maintaining the semantic properties of an image embedding. This provides a natural framework for phrase localization. Our method for phrase localization requires no human annotations or additional training. Extensive experiments show that our method outperforms existing no-training methods in zero-shot phrase localization, and in some cases, it even outperforms supervised methods. Code is available at https://github.com/pals-ttic/adapting-CLIP .", "paper_url": "http://arxiv.org/abs/2204.03647v1", "pdf_url": "http://arxiv.org/pdf/2204.03647v1", "repo_url": "https://github.com/pals-ttic/adapting-clip"}, "2204.03645": {"publish_time": "2022-04-07", "title": "DaViT: Dual Attention Vision Transformers", "author": "Mingyu Ding et.al.", "abstract": "In this work, we introduce Dual Attention Vision Transformers (DaViT), a simple yet effective vision transformer architecture that is able to capture global context while maintaining computational efficiency. We propose approaching the problem from an orthogonal angle: exploiting self-attention mechanisms with both \"spatial tokens\" and \"channel tokens\". With spatial tokens, the spatial dimension defines the token scope, and the channel dimension defines the token feature dimension. With channel tokens, we have the inverse: the channel dimension defines the token scope, and the spatial dimension defines the token feature dimension. We further group tokens along the sequence direction for both spatial and channel tokens to maintain the linear complexity of the entire model. We show that these two self-attentions complement each other: (i) since each channel token contains an abstract representation of the entire image, the channel attention naturally captures global interactions and representations by taking all spatial positions into account when computing attention scores between channels; (ii) the spatial attention refines the local representations by performing fine-grained interactions across spatial locations, which in turn helps the global information modeling in channel attention. Extensive experiments show our DaViT achieves state-of-the-art performance on four different tasks with efficient computations. Without extra data, DaViT-Tiny, DaViT-Small, and DaViT-Base achieve 82.8%, 84.2%, and 84.6% top-1 accuracy on ImageNet-1K with 28.3M, 49.7M, and 87.9M parameters, respectively. When we further scale up DaViT with 1.5B weakly supervised image and text pairs, DaViT-Gaint reaches 90.4% top-1 accuracy on ImageNet-1K. Code is available at https://github.com/dingmyu/davit.", "paper_url": "http://arxiv.org/abs/2204.03645v1", "pdf_url": "http://arxiv.org/pdf/2204.03645v1", "repo_url": "https://github.com/dingmyu/davit"}, "2204.03646": {"publish_time": "2022-04-07", "title": "FineDiving: A Fine-grained Dataset for Procedure-aware Action Quality Assessment", "author": "Jinglin Xu et.al.", "abstract": "Most existing action quality assessment methods rely on the deep features of an entire video to predict the score, which is less reliable due to the non-transparent inference process and poor interpretability. We argue that understanding both high-level semantics and internal temporal structures of actions in competitive sports videos is the key to making predictions accurate and interpretable. Towards this goal, we construct a new fine-grained dataset, called FineDiving, developed on diverse diving events with detailed annotations on action procedures. We also propose a procedure-aware approach for action quality assessment, learned by a new Temporal Segmentation Attention module. Specifically, we propose to parse pairwise query and exemplar action instances into consecutive steps with diverse semantic and temporal correspondences. The procedure-aware cross-attention is proposed to learn embeddings between query and exemplar steps to discover their semantic, spatial, and temporal correspondences, and further serve for fine-grained contrastive regression to derive a reliable scoring mechanism. Extensive experiments demonstrate that our approach achieves substantial improvements over state-of-the-art methods with better interpretability. The dataset and code are available at \\url{https://github.com/xujinglin/FineDiving}.", "paper_url": "http://arxiv.org/abs/2204.03646v1", "pdf_url": "http://arxiv.org/pdf/2204.03646v1", "repo_url": "https://github.com/xujinglin/finediving"}, "2204.04210": {"publish_time": "2022-04-08", "title": "Dancing under the stars: video denoising in starlight", "author": "Kristina Monakhova et.al.", "abstract": "Imaging in low light is extremely challenging due to low photon counts. Using sensitive CMOS cameras, it is currently possible to take videos at night under moonlight (0.05-0.3 lux illumination). In this paper, we demonstrate photorealistic video under starlight (no moon present, $<$0.001 lux) for the first time. To enable this, we develop a GAN-tuned physics-based noise model to more accurately represent camera noise at the lowest light levels. Using this noise model, we train a video denoiser using a combination of simulated noisy video clips and real noisy still images. We capture a 5-10 fps video dataset with significant motion at approximately 0.6-0.7 millilux with no active illumination. Comparing against alternative methods, we achieve improved video quality at the lowest light levels, demonstrating photorealistic video denoising in starlight for the first time.", "paper_url": "http://arxiv.org/abs/2204.04210v1", "pdf_url": "http://arxiv.org/pdf/2204.04210v1", "repo_url": null}, "2204.04199": {"publish_time": "2022-04-08", "title": "Underwater Image Enhancement Using Pre-trained Transformer", "author": "Abderrahmene Boudiaf et.al.", "abstract": "The goal of this work is to apply a denoising image transformer to remove the distortion from underwater images and compare it with other similar approaches. Automatic restoration of underwater images plays an important role since it allows to increase the quality of the images, without the need for more expensive equipment. This is a critical example of the important role of the machine learning algorithms to support marine exploration and monitoring, reducing the need for human intervention like the manual processing of the images, thus saving time, effort, and cost. This paper is the first application of the image transformer-based approach called \"Pre-Trained Image Processing Transformer\" to underwater images. This approach is tested on the UFO-120 dataset, containing 1500 images with the corresponding clean images.", "paper_url": "http://arxiv.org/abs/2204.04199v1", "pdf_url": "http://arxiv.org/pdf/2204.04199v1", "repo_url": null}, "2204.04153": {"publish_time": "2022-04-08", "title": "Particle Videos Revisited: Tracking Through Occlusions Using Point Trajectories", "author": "Adam W. Harley et.al.", "abstract": "Tracking pixels in videos is typically studied as an optical flow estimation problem, where every pixel is described with a displacement vector that locates it in the next frame. Even though wider temporal context is freely available, prior efforts to take this into account have yielded only small gains over 2-frame methods. In this paper, we revisit Sand and Teller's \"particle video\" approach, and study pixel tracking as a long-range motion estimation problem, where every pixel is described with a trajectory that locates it in multiple future frames. We re-build this classic approach using components that drive the current state-of-the-art in flow and object tracking, such as dense cost maps, iterative optimization, and learned appearance updates. We train our models using long-range amodal point trajectories mined from existing optical flow datasets that we synthetically augment with occlusions. We test our approach in trajectory estimation benchmarks and in keypoint label propagation tasks, and compare favorably against state-of-the-art optical flow and feature tracking methods.", "paper_url": "http://arxiv.org/abs/2204.04153v1", "pdf_url": "http://arxiv.org/pdf/2204.04153v1", "repo_url": null}, "2204.04151": {"publish_time": "2022-04-08", "title": "A Video Anomaly Detection Framework based on Appearance-Motion Semantics Representation Consistency", "author": "Xiangyu Huang et.al.", "abstract": "Video anomaly detection refers to the identification of events that deviate from the expected behavior. Due to the lack of anomalous samples in training, video anomaly detection becomes a very challenging task. Existing methods almost follow a reconstruction or future frame prediction mode. However, these methods ignore the consistency between appearance and motion information of samples, which limits their anomaly detection performance. Anomalies only occur in the moving foreground of surveillance videos, so the semantics expressed by video frame sequences and optical flow without background information in anomaly detection should be highly consistent and significant for anomaly detection. Based on this idea, we propose Appearance-Motion Semantics Representation Consistency (AMSRC), a framework that uses normal data's appearance and motion semantic representation consistency to handle anomaly detection. Firstly, we design a two-stream encoder to encode the appearance and motion information representations of normal samples and introduce constraints to further enhance the consistency of the feature semantics between appearance and motion information of normal samples so that abnormal samples with low consistency appearance and motion feature representation can be identified. Moreover, the lower consistency of appearance and motion features of anomalous samples can be used to generate predicted frames with larger reconstruction error, which makes anomalies easier to spot. Experimental results demonstrate the effectiveness of the proposed method.", "paper_url": "http://arxiv.org/abs/2204.04151v1", "pdf_url": "http://arxiv.org/pdf/2204.04151v1", "repo_url": null}, "2204.04145": {"publish_time": "2022-04-08", "title": "Constrained Bundle Adjustment for Structure From Motion Using Uncalibrated Multi-Camera Systems", "author": "Debao Huang et.al.", "abstract": "Structure from motion using uncalibrated multi-camera systems is a challenging task. This paper proposes a bundle adjustment solution that implements a baseline constraint respecting that these cameras are static to each other. We assume these cameras are mounted on a mobile platform, uncalibrated, and coarsely synchronized. To this end, we propose the baseline constraint that is formulated for the scenario in which the cameras have overlapping views. The constraint is incorporated in the bundle adjustment solution to keep the relative motion of different cameras static. Experiments were conducted using video frames of two collocated GoPro cameras mounted on a vehicle with no system calibration. These two cameras were placed capturing overlapping contents. We performed our bundle adjustment using the proposed constraint and then produced 3D dense point clouds. Evaluations were performed by comparing these dense point clouds against LiDAR reference data. We showed that, as compared to traditional bundle adjustment, our proposed method achieved an improvement of 29.38%.", "paper_url": "http://arxiv.org/abs/2204.04145v1", "pdf_url": "http://arxiv.org/pdf/2204.04145v1", "repo_url": null}, "2204.05308": {"publish_time": "2022-04-11", "title": "On the Generalization of BasicVSR++ to Video Deblurring and Denoising", "author": "Kelvin C. K. Chan et.al.", "abstract": "The exploitation of long-term information has been a long-standing problem in video restoration. The recent BasicVSR and BasicVSR++ have shown remarkable performance in video super-resolution through long-term propagation and effective alignment. Their success has led to a question of whether they can be transferred to different video restoration tasks. In this work, we extend BasicVSR++ to a generic framework for video restoration tasks. In tasks where inputs and outputs possess identical spatial size, the input resolution is reduced by strided convolutions to maintain efficiency. With only minimal changes from BasicVSR++, the proposed framework achieves compelling performance with great efficiency in various video restoration tasks including video deblurring and denoising. Notably, BasicVSR++ achieves comparable performance to Transformer-based approaches with up to 79% of parameter reduction and 44x speedup. The promising results demonstrate the importance of propagation and alignment in video restoration tasks beyond just video super-resolution. Code and models are available at https://github.com/ckkelvinchan/BasicVSR_PlusPlus.", "paper_url": "http://arxiv.org/abs/2204.05308v1", "pdf_url": "http://arxiv.org/pdf/2204.05308v1", "repo_url": null}, "2204.05306": {"publish_time": "2022-04-11", "title": "Full-Spectrum Out-of-Distribution Detection", "author": "Jingkang Yang et.al.", "abstract": "Existing out-of-distribution (OOD) detection literature clearly defines semantic shift as a sign of OOD but does not have a consensus over covariate shift. Samples experiencing covariate shift but not semantic shift are either excluded from the test set or treated as OOD, which contradicts the primary goal in machine learning -- being able to generalize beyond the training distribution. In this paper, we take into account both shift types and introduce full-spectrum OOD (FS-OOD) detection, a more realistic problem setting that considers both detecting semantic shift and being tolerant to covariate shift; and designs three benchmarks. These new benchmarks have a more fine-grained categorization of distributions (i.e., training ID, covariate-shifted ID, near-OOD, and far-OOD) for the purpose of more comprehensively evaluating the pros and cons of algorithms. To address the FS-OOD detection problem, we propose SEM, a simple feature-based semantics score function. SEM is mainly composed of two probability measures: one is based on high-level features containing both semantic and non-semantic information, while the other is based on low-level feature statistics only capturing non-semantic image styles. With a simple combination, the non-semantic part is cancelled out, which leaves only semantic information in SEM that can better handle FS-OOD detection. Extensive experiments on the three new benchmarks show that SEM significantly outperforms current state-of-the-art methods. Our code and benchmarks are released in https://github.com/Jingkang50/OpenOOD.", "paper_url": "http://arxiv.org/abs/2204.05306v1", "pdf_url": "http://arxiv.org/pdf/2204.05306v1", "repo_url": "https://github.com/jingkang50/openood"}, "2204.05300": {"publish_time": "2022-04-11", "title": "Single-Photon Structured Light", "author": "Varun Sundar et.al.", "abstract": "We present a novel structured light technique that uses Single Photon Avalanche Diode (SPAD) arrays to enable 3D scanning at high-frame rates and low-light levels. This technique, called \"Single-Photon Structured Light\", works by sensing binary images that indicates the presence or absence of photon arrivals during each exposure; the SPAD array is used in conjunction with a high-speed binary projector, with both devices operated at speeds as high as 20~kHz. The binary images that we acquire are heavily influenced by photon noise and are easily corrupted by ambient sources of light. To address this, we develop novel temporal sequences using error correction codes that are designed to be robust to short-range effects like projector and camera defocus as well as resolution mismatch between the two devices. Our lab prototype is capable of 3D imaging in challenging scenarios involving objects with extremely low albedo or undergoing fast motion, as well as scenes under strong ambient illumination.", "paper_url": "http://arxiv.org/abs/2204.05300v1", "pdf_url": "http://arxiv.org/pdf/2204.05300v1", "repo_url": null}, "2204.05289": {"publish_time": "2022-04-11", "title": "Towards Online Domain Adaptive Object Detection", "author": "Vibashan VS et.al.", "abstract": "Existing object detection models assume both the training and test data are sampled from the same source domain. This assumption does not hold true when these detectors are deployed in real-world applications, where they encounter new visual domain. Unsupervised Domain Adaptation (UDA) methods are generally employed to mitigate the adverse effects caused by domain shift. Existing UDA methods operate in an offline manner where the model is first adapted towards the target domain and then deployed in real-world applications. However, this offline adaptation strategy is not suitable for real-world applications as the model frequently encounters new domain shifts. Hence, it becomes critical to develop a feasible UDA method that generalizes to these domain shifts encountered during deployment time in a continuous online manner. To this end, we propose a novel unified adaptation framework that adapts and improves generalization on the target domain in online settings. In particular, we introduce MemXformer - a cross-attention transformer-based memory module where items in the memory take advantage of domain shifts and record prototypical patterns of the target distribution. Further, MemXformer produces strong positive and negative pairs to guide a novel contrastive loss, which enhances target specific representation learning. Experiments on diverse detection benchmarks show that the proposed strategy can produce state-of-the-art performance in both online and offline settings. To the best of our knowledge, this is the first work to address online and offline adaptation settings for object detection. Code at https://github.com/Vibashan/online-od", "paper_url": "http://arxiv.org/abs/2204.05289v1", "pdf_url": "http://arxiv.org/pdf/2204.05289v1", "repo_url": "https://github.com/vibashan/online-od"}, "2204.05281": {"publish_time": "2022-04-11", "title": "Physically Disentangled Representations", "author": "Tzofi Klinghoffer et.al.", "abstract": "State-of-the-art methods in generative representation learning yield semantic disentanglement, but typically do not consider physical scene parameters, such as geometry, albedo, lighting, or camera. We posit that inverse rendering, a way to reverse the rendering process to recover scene parameters from an image, can also be used to learn physically disentangled representations of scenes without supervision. In this paper, we show the utility of inverse rendering in learning representations that yield improved accuracy on downstream clustering, linear classification, and segmentation tasks with the help of our novel Leave-One-Out, Cycle Contrastive loss (LOOCC), which improves disentanglement of scene parameters and robustness to out-of-distribution lighting and viewpoints. We perform a comparison of our method with other generative representation learning methods across a variety of downstream tasks, including face attribute classification, emotion recognition, identification, face segmentation, and car classification. Our physically disentangled representations yield higher accuracy than semantically disentangled alternatives across all tasks and by as much as 18%. We hope that this work will motivate future research in applying advances in inverse rendering and 3D understanding to representation learning.", "paper_url": "http://arxiv.org/abs/2204.05281v1", "pdf_url": "http://arxiv.org/pdf/2204.05281v1", "repo_url": null}, "2204.05994": {"publish_time": "2022-04-12", "title": "Malceiver: Perceiver with Hierarchical and Multi-modal Features for Android Malware Detection", "author": "Niall McLaughlin et.al.", "abstract": "We propose the Malceiver, a hierarchical Perceiver model for Android malware detection that makes use of multi-modal features. The primary inputs are the opcode sequence and the requested permissions of a given Android APK file. To reach a malware classification decision the model combines hierarchical features extracted from the opcode sequence together with the requested permissions. The model's architecture is based on the Perceiver/PerceiverIO which allows for very long opcode sequences to be processed efficiently. Our proposed model can be easily extended to use multi-modal features. We show experimentally that this model outperforms a conventional CNN architecture for opcode sequence based malware detection. We then show that using additional modalities improves performance. Our proposed architecture opens new avenues for the use of Transformer-style networks in malware research.", "paper_url": "http://arxiv.org/abs/2204.05994v1", "pdf_url": "http://arxiv.org/pdf/2204.05994v1", "repo_url": null}, "2204.05991": {"publish_time": "2022-04-12", "title": "ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension", "author": "Sanjay Subramanian et.al.", "abstract": "Training a referring expression comprehension (ReC) model for a new visual domain requires collecting referring expressions, and potentially corresponding bounding boxes, for images in the domain. While large-scale pre-trained models are useful for image classification across domains, it remains unclear if they can be applied in a zero-shot manner to more complex tasks like ReC. We present ReCLIP, a simple but strong zero-shot baseline that repurposes CLIP, a state-of-the-art large-scale model, for ReC. Motivated by the close connection between ReC and CLIP's contrastive pre-training objective, the first component of ReCLIP is a region-scoring method that isolates object proposals via cropping and blurring, and passes them to CLIP. However, through controlled experiments on a synthetic dataset, we find that CLIP is largely incapable of performing spatial reasoning off-the-shelf. Thus, the second component of ReCLIP is a spatial relation resolver that handles several types of spatial relations. We reduce the gap between zero-shot baselines from prior work and supervised models by as much as 29% on RefCOCOg, and on RefGTA (video game imagery), ReCLIP's relative improvement over supervised ReC models trained on real images is 8%.", "paper_url": "http://arxiv.org/abs/2204.05991v1", "pdf_url": "http://arxiv.org/pdf/2204.05991v1", "repo_url": "https://github.com/allenai/reclip"}, "2204.05986": {"publish_time": "2022-04-12", "title": "Machine Learning Security against Data Poisoning: Are We There Yet?", "author": "Antonio Emanuele Cin\u00e0 et.al.", "abstract": "The recent success of machine learning has been fueled by the increasing availability of computing power and large amounts of data in many different applications. However, the trustworthiness of the resulting models can be compromised when such data is maliciously manipulated to mislead the learning process. In this article, we first review poisoning attacks that compromise the training data used to learn machine-learning models, including attacks that aim to reduce the overall performance, manipulate the predictions on specific test samples, and even implant backdoors in the model. We then discuss how to mitigate these attacks before, during, and after model training. We conclude our article by formulating some relevant open challenges which are hindering the development of testing methods and benchmarks suitable for assessing and improving the trustworthiness of machine-learning models against data poisoning attacks.", "paper_url": "http://arxiv.org/abs/2204.05986v1", "pdf_url": "http://arxiv.org/pdf/2204.05986v1", "repo_url": null}, "2204.05976": {"publish_time": "2022-04-12", "title": "Video Captioning: a comparative review of where we are and which could be the route", "author": "Daniela Moctezuma et.al.", "abstract": "Video captioning is the process of describing the content of a sequence of images capturing its semantic relationships and meanings. Dealing with this task with a single image is arduous, not to mention how difficult it is for a video (or images sequence). The amount and relevance of the applications of video captioning are vast, mainly to deal with a significant amount of video recordings in video surveillance, or assisting people visually impaired, to mention a few. To analyze where the efforts of our community to solve the video captioning task are, as well as what route could be better to follow, this manuscript presents an extensive review of more than 105 papers for the period of 2016 to 2021. As a result, the most-used datasets and metrics are identified. Also, the main approaches used and the best ones. We compute a set of rankings based on several performance metrics to obtain, according to its performance, the best method with the best result on the video captioning task. Finally, some insights are concluded about which could be the next steps or opportunity areas to improve dealing with this complex task.", "paper_url": "http://arxiv.org/abs/2204.05976v1", "pdf_url": "http://arxiv.org/pdf/2204.05976v1", "repo_url": null}, "2204.05957": {"publish_time": "2022-04-12", "title": "Localization Distillation for Object Detection", "author": "Zhaohui Zheng et.al.", "abstract": "Previous knowledge distillation (KD) methods for object detection mostly focus on feature imitation instead of mimicking the classification logits due to its inefficiency in distilling the localization information. In this paper, we investigate whether logit mimicking always lags behind feature imitation. Towards this goal, we first present a novel localization distillation (LD) method which can efficiently transfer the localization knowledge from the teacher to the student. Second, we introduce the concept of valuable localization region that can aid to selectively distill the classification and localization knowledge for a certain region. Combining these two new components, for the first time, we show that logit mimicking can outperform feature imitation and the absence of localization distillation is a critical reason for why logit mimicking underperforms for years. The thorough studies exhibit the great potential of logit mimicking that can significantly alleviate the localization ambiguity, learn robust feature representation, and ease the training difficulty in the early stage. We also provide the theoretical connection between the proposed LD and the classification KD, that they share the equivalent optimization effect. Our distillation scheme is simple as well as effective and can be easily applied to both dense horizontal object detectors and rotated object detectors. Extensive experiments on the MS COCO, PASCAL VOC, and DOTA benchmarks demonstrate that our method can achieve considerable AP improvement without any sacrifice on the inference speed. Our source code and pretrained models are publicly available at https://github.com/HikariTJU/LD.", "paper_url": "http://arxiv.org/abs/2204.05957v1", "pdf_url": "http://arxiv.org/pdf/2204.05957v1", "repo_url": "https://github.com/HikariTJU/LD"}, "2204.06558": {"publish_time": "2022-04-13", "title": "Controllable Video Generation through Global and Local Motion Dynamics", "author": "Aram Davtyan et.al.", "abstract": "We present GLASS, a method for Global and Local Action-driven Sequence Synthesis. GLASS is a generative model that is trained on video sequences in an unsupervised manner and that can animate an input image at test time. The method learns to segment frames into foreground-background layers and to generate transitions of the foregrounds over time through a global and local action representation. Global actions are explicitly related to 2D shifts, while local actions are instead related to (both geometric and photometric) local deformations. GLASS uses a recurrent neural network to transition between frames and is trained through a reconstruction loss. We also introduce W-Sprites (Walking Sprites), a novel synthetic dataset with a predefined action space. We evaluate our method on both W-Sprites and real datasets, and find that GLASS is able to generate realistic video sequences from a single input image and to successfully learn a more advanced action space than in prior work.", "paper_url": "http://arxiv.org/abs/2204.06558v1", "pdf_url": "http://arxiv.org/pdf/2204.06558v1", "repo_url": null}, "2204.06552": {"publish_time": "2022-04-13", "title": "Neural Vector Fields for Surface Representation and Inference", "author": "Edoardo Mello Rella et.al.", "abstract": "Neural implicit fields have recently been shown to represent 3D shapes accurately, opening up various applications in 3D shape analysis. Up to now, such implicit fields for 3D representation are scalar, encoding the signed distance or binary volume occupancy and more recently the unsigned distance. However, the first two can only represent closed shapes, while the unsigned distance has difficulties in accurate and fast shape inference. In this paper, we propose a Neural Vector Field for shape representation in order to overcome the two aforementioned problems. Mapping each point in space to the direction towards the closest surface, we can represent any type of shape. Similarly the shape mesh can be reconstructed by applying the marching cubes algorithm, with proposed small changes, on top of the inferred vector field. We compare the method on ShapeNet where the proposed new neural implicit field shows superior accuracy in representing both closed and open shapes outperforming previous methods.", "paper_url": "http://arxiv.org/abs/2204.06552v1", "pdf_url": "http://arxiv.org/pdf/2204.06552v1", "repo_url": null}, "2204.06527": {"publish_time": "2022-04-13", "title": "A9-Dataset: Multi-Sensor Infrastructure-Based Dataset for Mobility Research", "author": "Christian Cre\u00df et.al.", "abstract": "Data-intensive machine learning based techniques increasingly play a prominent role in the development of future mobility solutions - from driver assistance and automation functions in vehicles, to real-time traffic management systems realized through dedicated infrastructure. The availability of high quality real-world data is often an important prerequisite for the development and reliable deployment of such systems in large scale. Towards this endeavour, we present the A9-Dataset based on roadside sensor infrastructure from the 3 km long Providentia++ test field near Munich in Germany. The dataset includes anonymized and precision-timestamped multi-modal sensor and object data in high resolution, covering a variety of traffic situations. As part of the first set of data, which we describe in this paper, we provide camera and LiDAR frames from two overhead gantry bridges on the A9 autobahn with the corresponding objects labeled with 3D bounding boxes. The first set includes in total more than 1000 sensor frames and 14000 traffic objects. The dataset is available for download at https://a9-dataset.com.", "paper_url": "http://arxiv.org/abs/2204.06527v1", "pdf_url": "http://arxiv.org/pdf/2204.06527v1", "repo_url": null}, "2204.06512": {"publish_time": "2022-04-13", "title": "Does depth estimation help object detection?", "author": "Bedrettin Cetinkaya et.al.", "abstract": "Ground-truth depth, when combined with color data, helps improve object detection accuracy over baseline models that only use color. However, estimated depth does not always yield improvements. Many factors affect the performance of object detection when estimated depth is used. In this paper, we comprehensively investigate these factors with detailed experiments, such as using ground-truth vs. estimated depth, effects of different state-of-the-art depth estimation networks, effects of using different indoor and outdoor RGB-D datasets as training data for depth estimation, and different architectural choices for integrating depth to the base object detector network. We propose an early concatenation strategy of depth, which yields higher mAP than previous works' while using significantly fewer parameters.", "paper_url": "http://arxiv.org/abs/2204.06512v1", "pdf_url": "http://arxiv.org/pdf/2204.06512v1", "repo_url": null}, "2204.06507": {"publish_time": "2022-04-13", "title": "Out-of-distribution Detection with Deep Nearest Neighbors", "author": "Yiyou Sun et.al.", "abstract": "Out-of-distribution (OOD) detection is a critical task for deploying machine learning models in the open world. Distance-based methods have demonstrated promise, where testing samples are detected as OOD if they are relatively far away from in-distribution (ID) data. However, prior methods impose a strong distributional assumption of the underlying feature space, which may not always hold. In this paper, we explore the efficacy of non-parametric nearest-neighbor distance for OOD detection, which has been largely overlooked in the literature. Unlike prior works, our method does not impose any distributional assumption, hence providing stronger flexibility and generality. We demonstrate the effectiveness of nearest-neighbor-based OOD detection on several benchmarks and establish superior performance. Under the same model trained on ImageNet-1k, our method substantially reduces the false positive rate (FPR@TPR95) by 24.77% compared to a strong baseline SSD+, which uses a parametric approach Mahalanobis distance in detection.", "paper_url": "http://arxiv.org/abs/2204.06507v1", "pdf_url": "http://arxiv.org/pdf/2204.06507v1", "repo_url": null}, "2204.07159": {"publish_time": "2022-04-14", "title": "A Level Set Theory for Neural Implicit Evolution under Explicit Flows", "author": "Ishit Mehta et.al.", "abstract": "Coordinate-based neural networks parameterizing implicit surfaces have emerged as efficient representations of geometry. They effectively act as parametric level sets with the zero-level set defining the surface of interest. We present a framework that allows applying deformation operations defined for triangle meshes onto such implicit surfaces. Several of these operations can be viewed as energy-minimization problems that induce an instantaneous flow field on the explicit surface. Our method uses the flow field to deform parametric implicit surfaces by extending the classical theory of level sets. We also derive a consolidated view for existing methods on differentiable surface extraction and rendering, by formalizing connections to the level-set theory. We show that these methods drift from the theory and that our approach exhibits improvements for applications like surface smoothing, mean-curvature flow, inverse rendering and user-defined editing on implicit geometry.", "paper_url": "http://arxiv.org/abs/2204.07159v1", "pdf_url": "http://arxiv.org/pdf/2204.07159v1", "repo_url": null}, "2204.07157": {"publish_time": "2022-04-14", "title": "Joint Forecasting of Panoptic Segmentations with Difference Attention", "author": "Colin Graber et.al.", "abstract": "Forecasting of a representation is important for safe and effective autonomy. For this, panoptic segmentations have been studied as a compelling representation in recent work. However, recent state-of-the-art on panoptic segmentation forecasting suffers from two issues: first, individual object instances are treated independently of each other; second, individual object instance forecasts are merged in a heuristic manner. To address both issues, we study a new panoptic segmentation forecasting model that jointly forecasts all object instances in a scene using a transformer model based on 'difference attention.' It further refines the predictions by taking depth estimates into account. We evaluate the proposed model on the Cityscapes and AIODrive datasets. We find difference attention to be particularly suitable for forecasting because the difference of quantities like locations enables a model to explicitly reason about velocities and acceleration. Because of this, we attain state-of-the-art on panoptic segmentation forecasting metrics.", "paper_url": "http://arxiv.org/abs/2204.07157v1", "pdf_url": "http://arxiv.org/pdf/2204.07157v1", "repo_url": null}, "2204.07156": {"publish_time": "2022-04-14", "title": "Any-resolution Training for High-resolution Image Synthesis", "author": "Lucy Chai et.al.", "abstract": "Generative models operate at fixed resolution, even though natural images come in a variety of sizes. As high-resolution details are downsampled away, and low-resolution images are discarded altogether, precious supervision is lost. We argue that every pixel matters and create datasets with variable-size images, collected at their native resolutions. Taking advantage of this data is challenging; high-resolution processing is costly, and current architectures can only process fixed-resolution data. We introduce continuous-scale training, a process that samples patches at random scales to train a new generator with variable output resolutions. First, conditioning the generator on a target scale allows us to generate higher resolutions images than previously possible, without adding layers to the model. Second, by conditioning on continuous coordinates, we can sample patches that still obey a consistent global layout, which also allows for scalable training at higher resolutions. Controlled FFHQ experiments show our method takes advantage of the multi-resolution training data better than discrete multi-scale approaches, achieving better FID scores and cleaner high-frequency details. We also train on other natural image domains including churches, mountains, and birds, and demonstrate arbitrary scale synthesis with both coherent global layouts and realistic local details, going beyond 2K resolution in our experiments. Our project page is available at: https://chail.github.io/anyres-gan/.", "paper_url": "http://arxiv.org/abs/2204.07156v1", "pdf_url": "http://arxiv.org/pdf/2204.07156v1", "repo_url": null}, "2204.07154": {"publish_time": "2022-04-14", "title": "MiniViT: Compressing Vision Transformers with Weight Multiplexing", "author": "Jinnian Zhang et.al.", "abstract": "Vision Transformer (ViT) models have recently drawn much attention in computer vision due to their high model capability. However, ViT models suffer from huge number of parameters, restricting their applicability on devices with limited memory. To alleviate this problem, we propose MiniViT, a new compression framework, which achieves parameter reduction in vision transformers while retaining the same performance. The central idea of MiniViT is to multiplex the weights of consecutive transformer blocks. More specifically, we make the weights shared across layers, while imposing a transformation on the weights to increase diversity. Weight distillation over self-attention is also applied to transfer knowledge from large-scale ViT models to weight-multiplexed compact models. Comprehensive experiments demonstrate the efficacy of MiniViT, showing that it can reduce the size of the pre-trained Swin-B transformer by 48\\%, while achieving an increase of 1.0\\% in Top-1 accuracy on ImageNet. Moreover, using a single-layer of parameters, MiniViT is able to compress DeiT-B by 9.7 times from 86M to 9M parameters, without seriously compromising the performance. Finally, we verify the transferability of MiniViT by reporting its performance on downstream benchmarks. Code and models are available at here.", "paper_url": "http://arxiv.org/abs/2204.07154v1", "pdf_url": "http://arxiv.org/pdf/2204.07154v1", "repo_url": "https://github.com/microsoft/cream"}, "2204.07153": {"publish_time": "2022-04-14", "title": "What's in your hands? 3D Reconstruction of Generic Objects in Hands", "author": "Yufei Ye et.al.", "abstract": "Our work aims to reconstruct hand-held objects given a single RGB image. In contrast to prior works that typically assume known 3D templates and reduce the problem to 3D pose estimation, our work reconstructs generic hand-held object without knowing their 3D templates. Our key insight is that hand articulation is highly predictive of the object shape, and we propose an approach that conditionally reconstructs the object based on the articulation and the visual input. Given an image depicting a hand-held object, we first use off-the-shelf systems to estimate the underlying hand pose and then infer the object shape in a normalized hand-centric coordinate frame. We parameterized the object by signed distance which are inferred by an implicit network which leverages the information from both visual feature and articulation-aware coordinates to process a query point. We perform experiments across three datasets and show that our method consistently outperforms baselines and is able to reconstruct a diverse set of objects. We analyze the benefits and robustness of explicit articulation conditioning and also show that this allows the hand pose estimation to further improve in test-time optimization.", "paper_url": "http://arxiv.org/abs/2204.07153v1", "pdf_url": "http://arxiv.org/pdf/2204.07153v1", "repo_url": null}, "2204.07548": {"publish_time": "2022-04-15", "title": "Learning Multi-View Aggregation In the Wild for Large-Scale 3D Semantic Segmentation", "author": "Damien Robert et.al.", "abstract": "Recent works on 3D semantic segmentation propose to exploit the synergy between images and point clouds by processing each modality with a dedicated network and projecting learned 2D features onto 3D points. Merging large-scale point clouds and images raises several challenges, such as constructing a mapping between points and pixels, and aggregating features between multiple views. Current methods require mesh reconstruction or specialized sensors to recover occlusions, and use heuristics to select and aggregate available images. In contrast, we propose an end-to-end trainable multi-view aggregation model leveraging the viewing conditions of 3D points to merge features from images taken at arbitrary positions. Our method can combine standard 2D and 3D networks and outperforms both 3D models operating on colorized point clouds and hybrid 2D/3D networks without requiring colorization, meshing, or true depth maps. We set a new state-of-the-art for large-scale indoor/outdoor semantic segmentation on S3DIS (74.7 mIoU 6-Fold) and on KITTI-360 (58.3 mIoU). Our full pipeline is accessible at https://github.com/drprojects/DeepViewAgg, and only requires raw 3D scans and a set of images and poses.", "paper_url": "http://arxiv.org/abs/2204.07548v1", "pdf_url": "http://arxiv.org/pdf/2204.07548v1", "repo_url": "https://github.com/drprojects/deepviewagg"}, "2204.07546": {"publish_time": "2022-04-15", "title": "Semi-supervised atmospheric component learning in low-light image problem", "author": "Masud An Nur Islam Fahim et.al.", "abstract": "Ambient lighting conditions play a crucial role in determining the perceptual quality of images from photographic devices. In general, inadequate transmission light and undesired atmospheric conditions jointly degrade the image quality. If we know the desired ambient factors associated with the given low-light image, we can recover the enhanced image easily \\cite{b1}. Typical deep networks perform enhancement mappings without investigating the light distribution and color formulation properties. This leads to a lack of image instance-adaptive performance in practice. On the other hand, physical model-driven schemes suffer from the need for inherent decompositions and multiple objective minimizations. Moreover, the above approaches are rarely data efficient or free of postprediction tuning. Influenced by the above issues, this study presents a semisupervised training method using no-reference image quality metrics for low-light image restoration. We incorporate the classical haze distribution model \\cite{b2} to explore the physical properties of the given image in order to learn the effect of atmospheric components and minimize a single objective for restoration. We validate the performance of our network for six widely used low-light datasets. The experiments show that the proposed study achieves state-of-the-art or comparable performance.", "paper_url": "http://arxiv.org/abs/2204.07546v1", "pdf_url": "http://arxiv.org/pdf/2204.07546v1", "repo_url": null}, "2204.07537": {"publish_time": "2022-04-15", "title": "Unconditional Image-Text Pair Generation with Multimodal Cross Quantizer", "author": "Hyungyung Lee et.al.", "abstract": "Though deep generative models have gained a lot of attention, most of the existing works are designed for the unimodal generation task. In this paper, we explore a new method for unconditional image-text pair generation. We propose MXQ-VAE, a vector quantization method for multimodal image-text representation. MXQ-VAE accepts a paired image and text as input, and learns a joint quantized representation space, so that the image-text pair can be converted to a sequence of unified indices. Then we can use autoregressive generative models to model the joint image-text representation, and even perform unconditional image-text pair generation. Extensive experimental results demonstrate that our approach effectively generates semantically consistent image-text pair and also enhances meaningful alignment between image and text.", "paper_url": "http://arxiv.org/abs/2204.07537v1", "pdf_url": "http://arxiv.org/pdf/2204.07537v1", "repo_url": null}, "2204.07513": {"publish_time": "2022-04-15", "title": "Synthesizing Informative Training Samples with GAN", "author": "Bo Zhao et.al.", "abstract": "Remarkable progress has been achieved in synthesizing photo-realistic images with generative adversarial neural networks (GANs). Recently, GANs are utilized as the training sample generator when obtaining or storing real training data is expensive even infeasible. However, traditional GANs generated images are not as informative as the real training samples when being used to train deep neural networks. In this paper, we propose a novel method to synthesize Informative Training samples with GAN (IT-GAN). Specifically, we freeze a pre-trained GAN model and learn the informative latent vectors that corresponds to informative training samples. The synthesized images are required to preserve information for training deep neural networks rather than visual reality or fidelity. Experiments verify that the deep neural networks can learn faster and achieve better performance when being trained with our IT-GAN generated images. We also show that our method is a promising solution to dataset condensation problem.", "paper_url": "http://arxiv.org/abs/2204.07513v1", "pdf_url": "http://arxiv.org/pdf/2204.07513v1", "repo_url": null}, "2204.07486": {"publish_time": "2022-04-15", "title": "Patch-wise Contrastive Style Learning for Instagram Filter Removal", "author": "Furkan K\u0131nl\u0131 et.al.", "abstract": "Image-level corruptions and perturbations degrade the performance of CNNs on different downstream vision tasks. Social media filters are one of the most common resources of various corruptions and perturbations for real-world visual analysis applications. The negative effects of these distractive factors can be alleviated by recovering the original images with their pure style for the inference of the downstream vision tasks. Assuming these filters substantially inject a piece of additional style information to the social media images, we can formulate the problem of recovering the original versions as a reverse style transfer problem. We introduce Contrastive Instagram Filter Removal Network (CIFR), which enhances this idea for Instagram filter removal by employing a novel multi-layer patch-wise contrastive style learning mechanism. Experiments show our proposed strategy produces better qualitative and quantitative results than the previous studies. Moreover, we present the results of our additional experiments for proposed architecture within different settings. Finally, we present the inference outputs and quantitative comparison of filtered and recovered images on localization and segmentation tasks to encourage the main motivation for this problem.", "paper_url": "http://arxiv.org/abs/2204.07486v1", "pdf_url": "http://arxiv.org/pdf/2204.07486v1", "repo_url": "https://github.com/birdortyedi/cifr-pytorch"}, "2204.08453": {"publish_time": "2022-04-18", "title": "Neural Space-filling Curves", "author": "Hanyu Wang et.al.", "abstract": "We present Neural Space-filling Curves (SFCs), a data-driven approach to infer a context-based scan order for a set of images. Linear ordering of pixels forms the basis for many applications such as video scrambling, compression, and auto-regressive models that are used in generative modeling for images. Existing algorithms resort to a fixed scanning algorithm such as Raster scan or Hilbert scan. Instead, our work learns a spatially coherent linear ordering of pixels from the dataset of images using a graph-based neural network. The resulting Neural SFC is optimized for an objective suitable for the downstream task when the image is traversed along with the scan line order. We show the advantage of using Neural SFCs in downstream applications such as image compression. Code and additional results will be made available at https://hywang66.github.io/publication/neuralsfc.", "paper_url": "http://arxiv.org/abs/2204.08453v1", "pdf_url": "http://arxiv.org/pdf/2204.08453v1", "repo_url": null}, "2204.08454": {"publish_time": "2022-04-18", "title": "Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images", "author": "Wele Gedara Chaminda Bandara et.al.", "abstract": "Remote-sensing (RS) Change Detection (CD) aims to detect \"changes of interest\" from co-registered bi-temporal images. The performance of existing deep supervised CD methods is attributed to the large amounts of annotated data used to train the networks. However, annotating large amounts of remote sensing images is labor-intensive and expensive, particularly with bi-temporal images, as it requires pixel-wise comparisons by a human expert. On the other hand, we often have access to unlimited unlabeled multi-temporal RS imagery thanks to ever-increasing earth observation programs. In this paper, we propose a simple yet effective way to leverage the information from unlabeled bi-temporal images to improve the performance of CD approaches. More specifically, we propose a semi-supervised CD model in which we formulate an unsupervised CD loss in addition to the supervised Cross-Entropy (CE) loss by constraining the output change probability map of a given unlabeled bi-temporal image pair to be consistent under the small random perturbations applied on the deep feature difference map that is obtained by subtracting their latent feature representations. Experiments conducted on two publicly available CD datasets show that the proposed semi-supervised CD method can reach closer to the performance of supervised CD even with access to as little as 10% of the annotated training data. Code available at https://github.com/wgcban/SemiCD.", "paper_url": "http://arxiv.org/abs/2204.08454v1", "pdf_url": "http://arxiv.org/pdf/2204.08454v1", "repo_url": "https://github.com/wgcban/SemiCD"}, "2204.08451": {"publish_time": "2022-04-18", "title": "Learning to Listen: Modeling Non-Deterministic Dyadic Facial Motion", "author": "Evonne Ng et.al.", "abstract": "We present a framework for modeling interactional communication in dyadic conversations: given multimodal inputs of a speaker, we autoregressively output multiple possibilities of corresponding listener motion. We combine the motion and speech audio of the speaker using a motion-audio cross attention transformer. Furthermore, we enable non-deterministic prediction by learning a discrete latent representation of realistic listener motion with a novel motion-encoding VQ-VAE. Our method organically captures the multimodal and non-deterministic nature of nonverbal dyadic interactions. Moreover, it produces realistic 3D listener facial motion synchronous with the speaker (see video). We demonstrate that our method outperforms baselines qualitatively and quantitatively via a rich suite of experiments. To facilitate this line of research, we introduce a novel and large in-the-wild dataset of dyadic conversations. Code, data, and videos available at https://evonneng.github.io/learning2listen/.", "paper_url": "http://arxiv.org/abs/2204.08451v1", "pdf_url": "http://arxiv.org/pdf/2204.08451v1", "repo_url": null}, "2204.08446": {"publish_time": "2022-04-18", "title": "VSA: Learning Varied-Size Window Attention in Vision Transformers", "author": "Qiming Zhang et.al.", "abstract": "Attention within windows has been widely explored in vision transformers to balance the performance, computation complexity, and memory footprint. However, current models adopt a hand-crafted fixed-size window design, which restricts their capacity of modeling long-term dependencies and adapting to objects of different sizes. To address this drawback, we propose \\textbf{V}aried-\\textbf{S}ize Window \\textbf{A}ttention (VSA) to learn adaptive window configurations from data. Specifically, based on the tokens within each default window, VSA employs a window regression module to predict the size and location of the target window, i.e., the attention area where the key and value tokens are sampled. By adopting VSA independently for each attention head, it can model long-term dependencies, capture rich context from diverse windows, and promote information exchange among overlapped windows. VSA is an easy-to-implement module that can replace the window attention in state-of-the-art representative models with minor modifications and negligible extra computational cost while improving their performance by a large margin, e.g., 1.1\\% for Swin-T on ImageNet classification. In addition, the performance gain increases when using larger images for training and test. Experimental results on more downstream tasks, including object detection, instance segmentation, and semantic segmentation, further demonstrate the superiority of VSA over the vanilla window attention in dealing with objects of different sizes. The code will be released https://github.com/ViTAE-Transformer/ViTAE-VSA.", "paper_url": "http://arxiv.org/abs/2204.08446v1", "pdf_url": "http://arxiv.org/pdf/2204.08446v1", "repo_url": null}, "2204.08442": {"publish_time": "2022-04-18", "title": "Deep Equilibrium Optical Flow Estimation", "author": "Shaojie Bai et.al.", "abstract": "Many recent state-of-the-art (SOTA) optical flow models use finite-step recurrent update operations to emulate traditional algorithms by encouraging iterative refinements toward a stable flow estimation. However, these RNNs impose large computation and memory overheads, and are not directly trained to model such stable estimation. They can converge poorly and thereby suffer from performance degradation. To combat these drawbacks, we propose deep equilibrium (DEQ) flow estimators, an approach that directly solves for the flow as the infinite-level fixed point of an implicit layer (using any black-box solver), and differentiates through this fixed point analytically (thus requiring $O(1)$ training memory). This implicit-depth approach is not predicated on any specific model, and thus can be applied to a wide range of SOTA flow estimation model designs. The use of these DEQ flow estimators allows us to compute the flow faster using, e.g., fixed-point reuse and inexact gradients, consumes $4\\sim6\\times$ times less training memory than the recurrent counterpart, and achieves better results with the same computation budget. In addition, we propose a novel, sparse fixed-point correction scheme to stabilize our DEQ flow estimators, which addresses a longstanding challenge for DEQ models in general. We test our approach in various realistic settings and show that it improves SOTA methods on Sintel and KITTI datasets with substantially better computational and memory efficiency.", "paper_url": "http://arxiv.org/abs/2204.08442v1", "pdf_url": "http://arxiv.org/pdf/2204.08442v1", "repo_url": "https://github.com/locuslab/deq-flow"}, "2204.09041": {"publish_time": "2022-04-19", "title": "Unsupervised detection of ash dieback disease (Hymenoscyphus fraxineus) using diffusion-based hyperspectral image clustering", "author": "Sam L. Polk et.al.", "abstract": "Ash dieback (Hymenoscyphus fraxineus) is an introduced fungal disease that is causing the widespread death of ash trees across Europe. Remote sensing hyperspectral images encode rich structure that has been exploited for the detection of dieback disease in ash trees using supervised machine learning techniques. However, to understand the state of forest health at landscape-scale, accurate unsupervised approaches are needed. This article investigates the use of the unsupervised Diffusion and VCA-Assisted Image Segmentation (D-VIS) clustering algorithm for the detection of ash dieback disease in a forest site near Cambridge, United Kingdom. The unsupervised clustering presented in this work has high overlap with the supervised classification of previous work on this scene (overall accuracy = 71%). Thus, unsupervised learning may be used for the remote detection of ash dieback disease without the need for expert labeling.", "paper_url": "http://arxiv.org/abs/2204.09041v1", "pdf_url": "http://arxiv.org/pdf/2204.09041v1", "repo_url": null}, "2204.09015": {"publish_time": "2022-04-19", "title": "Dual-Domain Image Synthesis using Segmentation-Guided GAN", "author": "Dena Bazazian et.al.", "abstract": "We introduce a segmentation-guided approach to synthesise images that integrate features from two distinct domains. Images synthesised by our dual-domain model belong to one domain within the semantic mask, and to another in the rest of the image - smoothly integrated. We build on the successes of few-shot StyleGAN and single-shot semantic segmentation to minimise the amount of training required in utilising two domains. The method combines a few-shot cross-domain StyleGAN with a latent optimiser to achieve images containing features of two distinct domains. We use a segmentation-guided perceptual loss, which compares both pixel-level and activations between domain-specific and dual-domain synthetic images. Results demonstrate qualitatively and quantitatively that our model is capable of synthesising dual-domain images on a variety of objects (faces, horses, cats, cars), domains (natural, caricature, sketches) and part-based masks (eyes, nose, mouth, hair, car bonnet). The code is publicly available at: https://github.com/denabazazian/Dual-Domain-Synthesis.", "paper_url": "http://arxiv.org/abs/2204.09015v1", "pdf_url": "http://arxiv.org/pdf/2204.09015v1", "repo_url": null}, "2204.08978": {"publish_time": "2022-04-19", "title": "Real-Time Face Recognition System", "author": "Adarsh Ghimire et.al.", "abstract": "Over the past few decades, interest in algorithms for face recognition has been growing rapidly and has even surpassed human-level performance. Despite their accomplishments, their practical integration with a real-time performance-hungry system is not feasible due to high computational costs. So in this paper, we explore the recent, fast, and accurate face recognition system that can be easily integrated with real-time devices, and tested the algorithms on robot hardware platforms to confirm their robustness and speed.", "paper_url": "http://arxiv.org/abs/2204.08978v1", "pdf_url": "http://arxiv.org/pdf/2204.08978v1", "repo_url": null}, "2204.08974": {"publish_time": "2022-04-19", "title": "A comparison of different atmospheric turbulence simulation methods for image restoration", "author": "Nithin Gopalakrishnan Nair et.al.", "abstract": "Atmospheric turbulence deteriorates the quality of images captured by long-range imaging systems by introducing blur and geometric distortions to the captured scene. This leads to a drastic drop in performance when computer vision algorithms like object/face recognition and detection are performed on these images. In recent years, various deep learning-based atmospheric turbulence mitigation methods have been proposed in the literature. These methods are often trained using synthetically generated images and tested on real-world images. Hence, the performance of these restoration methods depends on the type of simulation used for training the network. In this paper, we systematically evaluate the effectiveness of various turbulence simulation methods on image restoration. In particular, we evaluate the performance of two state-or-the-art restoration networks using six simulations method on a real-world LRFID dataset consisting of face images degraded by turbulence. This paper will provide guidance to the researchers and practitioners working in this field to choose the suitable data generation models for training deep models for turbulence mitigation. The implementation codes for the simulation methods, source codes for the networks, and the pre-trained models will be publicly made available.", "paper_url": "http://arxiv.org/abs/2204.08974v1", "pdf_url": "http://arxiv.org/pdf/2204.08974v1", "repo_url": null}, "2204.08972": {"publish_time": "2022-04-19", "title": "Shallow camera pipeline for night photography rendering", "author": "Simone Zini et.al.", "abstract": "We introduce a camera pipeline for rendering visually pleasing photographs in low light conditions, as part of the NTIRE2022 Night Photography Rendering challenge. Given the nature of the task, where the objective is verbally defined by an expert photographer instead of relying on explicit ground truth images, we design an handcrafted solution, characterized by a shallow structure and by a low parameter count. Our pipeline exploits a local light enhancer as a form of high dynamic range correction, followed by a global adjustment of the image histogram to prevent washed-out results. We proportionally apply image denoising to darker regions, where it is more easily perceived, without losing details on brighter regions. The solution reached the fifth place in the competition, with a preference vote count comparable to those of other entries, based on deep convolutional neural networks. Code is available at www.github.com/AvailableAfterAcceptance.", "paper_url": "http://arxiv.org/abs/2204.08972v1", "pdf_url": "http://arxiv.org/pdf/2204.08972v1", "repo_url": null}, "2204.09667": {"publish_time": "2022-04-20", "title": "Sim-2-Sim Transfer for Vision-and-Language Navigation in Continuous Environments", "author": "Jacob Krantz et.al.", "abstract": "Recent work in Vision-and-Language Navigation (VLN) has presented two environmental paradigms with differing realism -- the standard VLN setting built on topological environments where navigation is abstracted away, and the VLN-CE setting where agents must navigate continuous 3D environments using low-level actions. Despite sharing the high-level task and even the underlying instruction-path data, performance on VLN-CE lags behind VLN significantly. In this work, we explore this gap by transferring an agent from the abstract environment of VLN to the continuous environment of VLN-CE. We find that this sim-2-sim transfer is highly effective, improving over the prior state of the art in VLN-CE by +12% success rate. While this demonstrates the potential for this direction, the transfer does not fully retain the original performance of the agent in the abstract setting. We present a sequence of experiments to identify what differences result in performance degradation, providing clear directions for further improvement.", "paper_url": "http://arxiv.org/abs/2204.09667v1", "pdf_url": "http://arxiv.org/pdf/2204.09667v1", "repo_url": null}, "2204.09648": {"publish_time": "2022-04-20", "title": "One-Class Model for Fabric Defect Detection", "author": "Hao Zhou et.al.", "abstract": "An automated and accurate fabric defect inspection system is in high demand as a replacement for slow, inconsistent, error-prone, and expensive human operators in the textile industry. Previous efforts focused on certain types of fabrics or defects, which is not an ideal solution. In this paper, we propose a novel one-class model that is capable of detecting various defects on different fabric types. Our model takes advantage of a well-designed Gabor filter bank to analyze fabric texture. We then leverage an advanced deep learning algorithm, autoencoder, to learn general feature representations from the outputs of the Gabor filter bank. Lastly, we develop a nearest neighbor density estimator to locate potential defects and draw them on the fabric images. We demonstrate the effectiveness and robustness of the proposed model by testing it on various types of fabrics such as plain, patterned, and rotated fabrics. Our model also achieves a true positive rate (a.k.a recall) value of 0.895 with no false alarms on our dataset based upon the Standard Fabric Defect Glossary.", "paper_url": "http://arxiv.org/abs/2204.09648v1", "pdf_url": "http://arxiv.org/pdf/2204.09648v1", "repo_url": null}, "2204.09636": {"publish_time": "2022-04-20", "title": "Residual Mixture of Experts", "author": "Lemeng Wu et.al.", "abstract": "Mixture of Experts (MoE) is able to scale up vision transformers effectively. However, it requires prohibiting computation resources to train a large MoE transformer. In this paper, we propose Residual Mixture of Experts (RMoE), an efficient training pipeline for MoE vision transformers on downstream tasks, such as segmentation and detection. RMoE achieves comparable results with the upper-bound MoE training, while only introducing minor additional training cost than the lower-bound non-MoE training pipelines. The efficiency is supported by our key observation: the weights of an MoE transformer can be factored into an input-independent core and an input-dependent residual. Compared with the weight core, the weight residual can be efficiently trained with much less computation resource, e.g., finetuning on the downstream data. We show that, compared with the current MoE training pipeline, we get comparable results while saving over 30% training cost. When compared with state-of-the-art non- MoE transformers, such as Swin-T / CvT-13 / Swin-L, we get +1.1 / 0.9 / 1.0 mIoU gain on ADE20K segmentation and +1.4 / 1.6 / 0.6 AP gain on MS-COCO object detection task with less than 3% additional training cost.", "paper_url": "http://arxiv.org/abs/2204.09636v1", "pdf_url": "http://arxiv.org/pdf/2204.09636v1", "repo_url": null}, "2204.09616": {"publish_time": "2022-04-20", "title": "Assembly Planning from Observations under Physical Constraints", "author": "Thomas Chabal et.al.", "abstract": "This paper addresses the problem of copying an unknown assembly of primitives with known shape and appearance using information extracted from a single photograph by an off-the-shelf procedure for object detection and pose estimation. The proposed algorithm uses a simple combination of physical stability constraints, convex optimization and Monte Carlo tree search to plan assemblies as sequences of pick-and-place operations represented by STRIPS operators. It is efficient and, most importantly, robust to the errors in object detection and pose estimation unavoidable in any real robotic system. The proposed approach is demonstrated with thorough experiments on a UR5 manipulator.", "paper_url": "http://arxiv.org/abs/2204.09616v1", "pdf_url": "http://arxiv.org/pdf/2204.09616v1", "repo_url": null}, "2204.09575": {"publish_time": "2022-04-20", "title": "Fast and Robust Femur Segmentation from Computed Tomography Images for Patient-Specific Hip Fracture Risk Screening", "author": "Pall Asgeir Bjornsson et.al.", "abstract": "Osteoporosis is a common bone disease that increases the risk of bone fracture. Hip-fracture risk screening methods based on finite element analysis depend on segmented computed tomography (CT) images; however, current femur segmentation methods require manual delineations of large data sets. Here we propose a deep neural network for fully automated, accurate, and fast segmentation of the proximal femur from CT. Evaluation on a set of 1147 proximal femurs with ground truth segmentations demonstrates that our method is apt for hip-fracture risk screening, bringing us one step closer to a clinically viable option for screening at-risk patients for hip-fracture susceptibility.", "paper_url": "http://arxiv.org/abs/2204.09575v1", "pdf_url": "http://arxiv.org/pdf/2204.09575v1", "repo_url": null}, "2204.10320": {"publish_time": "2022-04-21", "title": "SelfD: Self-Learning Large-Scale Driving Policies From the Web", "author": "Jimuyang Zhang et.al.", "abstract": "Effectively utilizing the vast amounts of ego-centric navigation data that is freely available on the internet can advance generalized intelligent systems, i.e., to robustly scale across perspectives, platforms, environmental conditions, scenarios, and geographical locations. However, it is difficult to directly leverage such large amounts of unlabeled and highly diverse data for complex 3D reasoning and planning tasks. Consequently, researchers have primarily focused on its use for various auxiliary pixel- and image-level computer vision tasks that do not consider an ultimate navigational objective. In this work, we introduce SelfD, a framework for learning scalable driving by utilizing large amounts of online monocular images. Our key idea is to leverage iterative semi-supervised training when learning imitative agents from unlabeled data. To handle unconstrained viewpoints, scenes, and camera parameters, we train an image-based model that directly learns to plan in the Bird's Eye View (BEV) space. Next, we use unlabeled data to augment the decision-making knowledge and robustness of an initially trained model via self-training. In particular, we propose a pseudo-labeling step which enables making full use of highly diverse demonstration data through \"hypothetical\" planning-based data augmentation. We employ a large dataset of publicly available YouTube videos to train SelfD and comprehensively analyze its generalization benefits across challenging navigation scenarios. Without requiring any additional data collection or annotation efforts, SelfD demonstrates consistent improvements (by up to 24%) in driving performance evaluation on nuScenes, Argoverse, Waymo, and CARLA.", "paper_url": "http://arxiv.org/abs/2204.10320v1", "pdf_url": "http://arxiv.org/pdf/2204.10320v1", "repo_url": null}, "2204.10321": {"publish_time": "2022-04-21", "title": "Learning Future Object Prediction with a Spatiotemporal Detection Transformer", "author": "Adam Tonderski et.al.", "abstract": "We explore future object prediction -- a challenging problem where all objects visible in a future video frame are to be predicted. We propose to tackle this problem end-to-end by training a detection transformer to directly output future objects. In order to make accurate predictions about the future, it is necessary to capture the dynamics in the scene, both of other objects and of the ego-camera. We extend existing detection transformers in two ways to capture the scene dynamics. First, we experiment with three different mechanisms that enable the model to spatiotemporally process multiple frames. Second, we feed ego-motion information to the model via cross-attention. We show that both of these cues substantially improve future object prediction performance. Our final approach learns to capture the dynamics and make predictions on par with an oracle for 100 ms prediction horizons, and outperform baselines for longer prediction horizons.", "paper_url": "http://arxiv.org/abs/2204.10321v1", "pdf_url": "http://arxiv.org/pdf/2204.10321v1", "repo_url": null}, "2204.10319": {"publish_time": "2022-04-21", "title": "TorchSparse: Efficient Point Cloud Inference Engine", "author": "Haotian Tang et.al.", "abstract": "Deep learning on point clouds has received increased attention thanks to its wide applications in AR/VR and autonomous driving. These applications require low latency and high accuracy to provide real-time user experience and ensure user safety. Unlike conventional dense workloads, the sparse and irregular nature of point clouds poses severe challenges to running sparse CNNs efficiently on the general-purpose hardware. Furthermore, existing sparse acceleration techniques for 2D images do not translate to 3D point clouds. In this paper, we introduce TorchSparse, a high-performance point cloud inference engine that accelerates the sparse convolution computation on GPUs. TorchSparse directly optimizes the two bottlenecks of sparse convolution: irregular computation and data movement. It applies adaptive matrix multiplication grouping to trade computation for better regularity, achieving 1.4-1.5x speedup for matrix multiplication. It also optimizes the data movement by adopting vectorized, quantized and fused locality-aware memory access, reducing the memory movement cost by 2.7x. Evaluated on seven representative models across three benchmark datasets, TorchSparse achieves 1.6x and 1.5x measured end-to-end speedup over the state-of-the-art MinkowskiEngine and SpConv, respectively.", "paper_url": "http://arxiv.org/abs/2204.10319v1", "pdf_url": "http://arxiv.org/pdf/2204.10319v1", "repo_url": "https://github.com/mit-han-lab/torchsparse"}, "2204.10318": {"publish_time": "2022-04-21", "title": "Feature anomaly detection system (FADS) for intelligent manufacturing", "author": "Anthony Garland et.al.", "abstract": "Anomaly detection is important for industrial automation and part quality assurance, and while humans can easily detect anomalies in components given a few examples, designing a generic automated system that can perform at human or above human capabilities remains a challenge. In this work, we present a simple new anomaly detection algorithm called FADS (feature-based anomaly detection system) which leverages pretrained convolutional neural networks (CNN) to generate a statistical model of nominal inputs by observing the activation of the convolutional filters. During inference the system compares the convolutional filter activation of the new input to the statistical model and flags activations that are outside the expected range of values and therefore likely an anomaly. By using a pretrained network, FADS demonstrates excellent performance similar to or better than other machine learning approaches to anomaly detection while at the same time FADS requires no tuning of the CNN weights. We demonstrate FADS ability by detecting process parameter changes on a custom dataset of additively manufactured lattices. The FADS localization algorithm shows that textural differences that are visible on the surface can be used to detect process parameter changes. In addition, we test FADS on benchmark datasets, such as the MVTec Anomaly Detection dataset, and report good results.", "paper_url": "http://arxiv.org/abs/2204.10318v1", "pdf_url": "http://arxiv.org/pdf/2204.10318v1", "repo_url": null}, "2204.10314": {"publish_time": "2022-04-21", "title": "Adversarial Contrastive Learning by Permuting Cluster Assignments", "author": "Muntasir Wahed et.al.", "abstract": "Contrastive learning has gained popularity as an effective self-supervised representation learning technique. Several research directions improve traditional contrastive approaches, e.g., prototypical contrastive methods better capture the semantic similarity among instances and reduce the computational burden by considering cluster prototypes or cluster assignments, while adversarial instance-wise contrastive methods improve robustness against a variety of attacks. To the best of our knowledge, no prior work jointly considers robustness, cluster-wise semantic similarity and computational efficiency. In this work, we propose SwARo, an adversarial contrastive framework that incorporates cluster assignment permutations to generate representative adversarial samples. We evaluate SwARo on multiple benchmark datasets and against various white-box and black-box attacks, obtaining consistent improvements over state-of-the-art baselines.", "paper_url": "http://arxiv.org/abs/2204.10314v1", "pdf_url": "http://arxiv.org/pdf/2204.10314v1", "repo_url": null}, "2204.10850": {"publish_time": "2022-04-22", "title": "Control-NeRF: Editable Feature Volumes for Scene Rendering and Manipulation", "author": "Verica Lazova et.al.", "abstract": "We present a novel method for performing flexible, 3D-aware image content manipulation while enabling high-quality novel view synthesis. While NeRF-based approaches are effective for novel view synthesis, such models memorize the radiance for every point in a scene within a neural network. Since these models are scene-specific and lack a 3D scene representation, classical editing such as shape manipulation, or combining scenes is not possible. Hence, editing and combining NeRF-based scenes has not been demonstrated. With the aim of obtaining interpretable and controllable scene representations, our model couples learnt scene-specific feature volumes with a scene agnostic neural rendering network. With this hybrid representation, we decouple neural rendering from scene-specific geometry and appearance. We can generalize to novel scenes by optimizing only the scene-specific 3D feature representation, while keeping the parameters of the rendering network fixed. The rendering function learnt during the initial training stage can thus be easily applied to new scenes, making our approach more flexible. More importantly, since the feature volumes are independent of the rendering model, we can manipulate and combine scenes by editing their corresponding feature volumes. The edited volume can then be plugged into the rendering model to synthesize high-quality novel views. We demonstrate various scene manipulations, including mixing scenes, deforming objects and inserting objects into scenes, while still producing photo-realistic results.", "paper_url": "http://arxiv.org/abs/2204.10850v1", "pdf_url": "http://arxiv.org/pdf/2204.10850v1", "repo_url": null}, "2204.10846": {"publish_time": "2022-04-22", "title": "Self-Supervised Video Object Segmentation via Cutout Prediction and Tagging", "author": "Jyoti Kini et.al.", "abstract": "We propose a novel self-supervised Video Object Segmentation (VOS) approach that strives to achieve better object-background discriminability for accurate object segmentation. Distinct from previous self-supervised VOS methods, our approach is based on a discriminative learning loss formulation that takes into account both object and background information to ensure object-background discriminability, rather than using only object appearance. The discriminative learning loss comprises cutout-based reconstruction (cutout region represents part of a frame, whose pixels are replaced with some constant values) and tag prediction loss terms. The cutout-based reconstruction term utilizes a simple cutout scheme to learn the pixel-wise correspondence between the current and previous frames in order to reconstruct the original current frame with added cutout region in it. The introduced cutout patch guides the model to focus as much on the significant features of the object of interest as the less significant ones, thereby implicitly equipping the model to address occlusion-based scenarios. Next, the tag prediction term encourages object-background separability by grouping tags of all pixels in the cutout region that are similar, while separating them from the tags of the rest of the reconstructed frame pixels. Additionally, we introduce a zoom-in scheme that addresses the problem of small object segmentation by capturing fine structural information at multiple scales. Our proposed approach, termed CT-VOS, achieves state-of-the-art results on two challenging benchmarks: DAVIS-2017 and Youtube-VOS. A detailed ablation showcases the importance of the proposed loss formulation to effectively capture object-background discriminability and the impact of our zoom-in scheme to accurately segment small-sized objects.", "paper_url": "http://arxiv.org/abs/2204.10846v1", "pdf_url": "http://arxiv.org/pdf/2204.10846v1", "repo_url": null}, "2204.10810": {"publish_time": "2022-04-22", "title": "Learning to Scaffold: Optimizing Model Explanations for Teaching", "author": "Patrick Fernandes et.al.", "abstract": "Modern machine learning models are opaque, and as a result there is a burgeoning academic subfield on methods that explain these models' behavior. However, what is the precise goal of providing such explanations, and how can we demonstrate that explanations achieve this goal? Some research argues that explanations should help teach a student (either human or machine) to simulate the model being explained, and that the quality of explanations can be measured by the simulation accuracy of students on unexplained examples. In this work, leveraging meta-learning techniques, we extend this idea to improve the quality of the explanations themselves, specifically by optimizing explanations such that student models more effectively learn to simulate the original model. We train models on three natural language processing and computer vision tasks, and find that students trained with explanations extracted with our framework are able to simulate the teacher significantly more effectively than ones produced with previous methods. Through human annotations and a user study, we further find that these learned explanations more closely align with how humans would explain the required decisions in these tasks. Our code is available at https://github.com/coderpat/learning-scaffold", "paper_url": "http://arxiv.org/abs/2204.10810v1", "pdf_url": "http://arxiv.org/pdf/2204.10810v1", "repo_url": "https://github.com/coderpat/learning-scaffold"}, "2204.10803": {"publish_time": "2022-04-22", "title": "Pay \"Attention\" to Adverse Weather: Weather-aware Attention-based Object Detection", "author": "Saket S. Chaturvedi et.al.", "abstract": "Despite the recent advances of deep neural networks, object detection for adverse weather remains challenging due to the poor perception of some sensors in adverse weather. Instead of relying on one single sensor, multimodal fusion has been one promising approach to provide redundant detection information based on multiple sensors. However, most existing multimodal fusion approaches are ineffective in adjusting the focus of different sensors under varying detection environments in dynamic adverse weather conditions. Moreover, it is critical to simultaneously observe local and global information under complex weather conditions, which has been neglected in most early or late-stage multimodal fusion works. In view of these, this paper proposes a Global-Local Attention (GLA) framework to adaptively fuse the multi-modality sensing streams, i.e., camera, gated camera, and lidar data, at two fusion stages. Specifically, GLA integrates an early-stage fusion via a local attention network and a late-stage fusion via a global attention network to deal with both local and global information, which automatically allocates higher weights to the modality with better detection features at the late-stage fusion to cope with the specific weather condition adaptively. Experimental results demonstrate the superior performance of the proposed GLA compared with state-of-the-art fusion approaches under various adverse weather conditions, such as light fog, dense fog, and snow.", "paper_url": "http://arxiv.org/abs/2204.10803v1", "pdf_url": "http://arxiv.org/pdf/2204.10803v1", "repo_url": null}, "2204.10776": {"publish_time": "2022-04-22", "title": "Gen6D: Generalizable Model-Free 6-DoF Object Pose Estimation from RGB Images", "author": "Yuan Liu et.al.", "abstract": "In this paper, we present a generalizable model-free 6-DoF object pose estimator called Gen6D. Existing generalizable pose estimators either need high-quality object models or require additional depth maps or object masks in test time, which significantly limits their application scope. In contrast, our pose estimator only requires some posed images of the unseen object and is able to accurately predict the poses of the object in arbitrary environments. Gen6D consists of an object detector, a viewpoint selector and a pose refiner, all of which do not require the 3D object model and can generalize to unseen objects. Experiments show that Gen6D achieves state-of-the-art results on two model-free datasets: the MOPED dataset and a new GenMOP dataset collected by us. In addition, on the LINEMOD dataset, Gen6D achieves competitive results compared with instance-specific pose estimators. Project page: https://liuyuan-pal.github.io/Gen6D/.", "paper_url": "http://arxiv.org/abs/2204.10776v1", "pdf_url": "http://arxiv.org/pdf/2204.10776v1", "repo_url": null}, "2204.11830": {"publish_time": "2022-04-25", "title": "Proto2Proto: Can you recognize the car, the way I do?", "author": "Monish Keswani et.al.", "abstract": "Prototypical methods have recently gained a lot of attention due to their intrinsic interpretable nature, which is obtained through the prototypes. With growing use cases of model reuse and distillation, there is a need to also study transfer of interpretability from one model to another. We present Proto2Proto, a novel method to transfer interpretability of one prototypical part network to another via knowledge distillation. Our approach aims to add interpretability to the \"dark\" knowledge transferred from the teacher to the shallower student model. We propose two novel losses: \"Global Explanation\" loss and \"Patch-Prototype Correspondence\" loss to facilitate such a transfer. Global Explanation loss forces the student prototypes to be close to teacher prototypes, and Patch-Prototype Correspondence loss enforces the local representations of the student to be similar to that of the teacher. Further, we propose three novel metrics to evaluate the student's proximity to the teacher as measures of interpretability transfer in our settings. We qualitatively and quantitatively demonstrate the effectiveness of our method on CUB-200-2011 and Stanford Cars datasets. Our experiments show that the proposed method indeed achieves interpretability transfer from teacher to student while simultaneously exhibiting competitive performance.", "paper_url": "http://arxiv.org/abs/2204.11830v1", "pdf_url": "http://arxiv.org/pdf/2204.11830v1", "repo_url": null}, "2204.11824": {"publish_time": "2022-04-25", "title": "Retrieval-Augmented Diffusion Models", "author": "Andreas Blattmann et.al.", "abstract": "Generative image synthesis with diffusion models has recently achieved excellent visual quality in several tasks such as text-based or class-conditional image synthesis. Much of this success is due to a dramatic increase in the computational capacity invested in training these models. This work presents an alternative approach: inspired by its successful application in natural language processing, we propose to complement the diffusion model with a retrieval-based approach and to introduce an explicit memory in the form of an external database. During training, our diffusion model is trained with similar visual features retrieved via CLIP and from the neighborhood of each training instance. By leveraging CLIP's joint image-text embedding space, our model achieves highly competitive performance on tasks for which it has not been explicitly trained, such as class-conditional or text-image synthesis, and can be conditioned on both text and image embeddings. Moreover, we can apply our approach to unconditional generation, where it achieves state-of-the-art performance. Our approach incurs low computational and memory overheads and is easy to implement. We discuss its relationship to concurrent work and will publish code and pretrained models soon.", "paper_url": "http://arxiv.org/abs/2204.11824v1", "pdf_url": "http://arxiv.org/pdf/2204.11824v1", "repo_url": null}, "2204.11823": {"publish_time": "2022-04-25", "title": "StyleGAN-Human: A Data-Centric Odyssey of Human Generation", "author": "Jianglin Fu et.al.", "abstract": "Unconditional human image generation is an important task in vision and graphics, which enables various applications in the creative industry. Existing studies in this field mainly focus on \"network engineering\" such as designing new components and objective functions. This work takes a data-centric perspective and investigates multiple critical aspects in \"data engineering\", which we believe would complement the current practice. To facilitate a comprehensive study, we collect and annotate a large-scale human image dataset with over 230K samples capturing diverse poses and textures. Equipped with this large dataset, we rigorously investigate three essential factors in data engineering for StyleGAN-based human generation, namely data size, data distribution, and data alignment. Extensive experiments reveal several valuable observations w.r.t. these aspects: 1) Large-scale data, more than 40K images, are needed to train a high-fidelity unconditional human generation model with vanilla StyleGAN. 2) A balanced training set helps improve the generation quality with rare face poses compared to the long-tailed counterpart, whereas simply balancing the clothing texture distribution does not effectively bring an improvement. 3) Human GAN models with body centers for alignment outperform models trained using face centers or pelvis points as alignment anchors. In addition, a model zoo and human editing applications are demonstrated to facilitate future research in the community.", "paper_url": "http://arxiv.org/abs/2204.11823v1", "pdf_url": "http://arxiv.org/pdf/2204.11823v1", "repo_url": "https://github.com/stylegan-human/stylegan-human"}, "2204.11822": {"publish_time": "2022-04-25", "title": "Zero-Shot Logit Adjustment", "author": "Dubing Chen et.al.", "abstract": "Semantic-descriptor-based Generalized Zero-Shot Learning (GZSL) poses challenges in recognizing the novel classes in the test phase. The development of generative models enables current GZSL techniques to probe further into the semantic-visual link, culminating in a two-stage form that includes a generator and a classifier. However, existing generation-based methods focus on enhancing the generator's effect while neglecting the improvement of the classifier. In this paper, we first conduct an analysis of two properties of the generated pseudo unseen sample: bias and homogeneity. Then, we perform variational Bayesian inference to back-derive the evaluation metrics, which reflects the balance of the seen and unseen classes. As a consequence of our derivation, the aforementioned two properties are incorporated into the classifier training as seen-unseen priors via logit adjustment. The Zero-Shot Logit Adjustment further puts semantic-based classifiers into effect in generation-based GZSL. Our experiments demonstrate that the proposed technique achieves the state of the art when combined with the basic generator, and it can improve various generative zero-shot learning frameworks. Our codes are available on \\url{https://github.com/cdb342/IJCAI-2022-ZLA}.", "paper_url": "http://arxiv.org/abs/2204.11822v1", "pdf_url": "http://arxiv.org/pdf/2204.11822v1", "repo_url": "https://github.com/cdb342/ijcai-2022-zla"}, "2204.11820": {"publish_time": "2022-04-25", "title": "Real-Time Neural Character Rendering with Pose-Guided Multiplane Images", "author": "Hao Ouyang et.al.", "abstract": "We propose pose-guided multiplane image (MPI) synthesis which can render an animatable character in real scenes with photorealistic quality. We use a portable camera rig to capture the multi-view images along with the driving signal for the moving subject. Our method generalizes the image-to-image translation paradigm, which translates the human pose to a 3D scene representation -- MPIs that can be rendered in free viewpoints, using the multi-views captures as supervision. To fully cultivate the potential of MPI, we propose depth-adaptive MPI which can be learned using variable exposure images while being robust to inaccurate camera registration. Our method demonstrates advantageous novel-view synthesis quality over the state-of-the-art approaches for characters with challenging motions. Moreover, the proposed method is generalizable to novel combinations of training poses and can be explicitly controlled. Our method achieves such expressive and animatable character rendering all in real time, serving as a promising solution for practical applications.", "paper_url": "http://arxiv.org/abs/2204.11820v1", "pdf_url": "http://arxiv.org/pdf/2204.11820v1", "repo_url": null}, "2204.12490": {"publish_time": "2022-04-26", "title": "From One Hand to Multiple Hands: Imitation Learning for Dexterous Manipulation from Single-Camera Teleoperation", "author": "Yuzhe Qin et.al.", "abstract": "We propose to perform imitation learning for dexterous manipulation with multi-finger robot hand from human demonstrations, and transfer the policy to the real robot hand. We introduce a novel single-camera teleoperation system to collect the 3D demonstrations efficiently with only an iPad and a computer. One key contribution of our system is that we construct a customized robot hand for each user in the physical simulator, which is a manipulator resembling the same kinematics structure and shape of the operator's hand. This provides an intuitive interface and avoid unstable human-robot hand retargeting for data collection, leading to large-scale and high quality data. Once the data is collected, the customized robot hand trajectories can be converted to different specified robot hands (models that are manufactured) to generate training demonstrations. With imitation learning using our data, we show large improvement over baselines with multiple complex manipulation tasks. Importantly, we show our learned policy is significantly more robust when transferring to the real robot. More videos can be found in the https://yzqin.github.io/dex-teleop-imitation .", "paper_url": "http://arxiv.org/abs/2204.12490v1", "pdf_url": "http://arxiv.org/pdf/2204.12490v1", "repo_url": null}, "2204.12489": {"publish_time": "2022-04-26", "title": "Sound Localization by Self-Supervised Time Delay Estimation", "author": "Ziyang Chen et.al.", "abstract": "Sounds reach one microphone in a stereo pair sooner than the other, resulting in an interaural time delay that conveys their directions. Estimating a sound's time delay requires finding correspondences between the signals recorded by each microphone. We propose to learn these correspondences through self-supervision, drawing on recent techniques from visual tracking. We adapt the contrastive random walk of Jabri et al. to learn a cycle-consistent representation from unlabeled stereo sounds, resulting in a model that performs on par with supervised methods on \"in the wild\" internet recordings. We also propose a multimodal contrastive learning model that solves a visually-guided localization task: estimating the time delay for a particular person in a multi-speaker mixture, given a visual representation of their face. Project site: https://ificl.github.io/stereocrw/", "paper_url": "http://arxiv.org/abs/2204.12489v1", "pdf_url": "http://arxiv.org/pdf/2204.12489v1", "repo_url": null}, "2204.12484": {"publish_time": "2022-04-26", "title": "ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation", "author": "Yufei Xu et.al.", "abstract": "Recently, customized vision transformers have been adapted for human pose estimation and have achieved superior performance with elaborate structures. However, it is still unclear whether plain vision transformers can facilitate pose estimation. In this paper, we take the first step toward answering the question by employing a plain and non-hierarchical vision transformer together with simple deconvolution decoders termed ViTPose for human pose estimation. We demonstrate that a plain vision transformer with MAE pretraining can obtain superior performance after finetuning on human pose estimation datasets. ViTPose has good scalability with respect to model size and flexibility regarding input resolution and token number. Moreover, it can be easily pretrained using the unlabeled pose data without the need for large-scale upstream ImageNet data. Our biggest ViTPose model based on the ViTAE-G backbone with 1 billion parameters obtains the best 80.9 mAP on the MS COCO test-dev set, while the ensemble models further set a new state-of-the-art for human pose estimation, i.e., 81.1 mAP. The source code and models will be released at https://github.com/ViTAE-Transformer/ViTPose.", "paper_url": "http://arxiv.org/abs/2204.12484v1", "pdf_url": "http://arxiv.org/pdf/2204.12484v1", "repo_url": "https://github.com/vitae-transformer/vitpose"}, "2204.12471": {"publish_time": "2022-04-26", "title": "Coarse-to-fine Q-attention with Tree Expansion", "author": "Stephen James et.al.", "abstract": "Coarse-to-fine Q-attention enables sample-efficient robot manipulation by discretizing the translation space in a coarse-to-fine manner, where the resolution gradually increases at each layer in the hierarchy. Although effective, Q-attention suffers from \"coarse ambiguity\" - when voxelization is significantly coarse, it is not feasible to distinguish similar-looking objects without first inspecting at a finer resolution. To combat this, we propose to envision Q-attention as a tree that can be expanded and used to accumulate value estimates across the top-k voxels at each Q-attention depth. When our extension, Q-attention with Tree Expansion (QTE), replaces standard Q-attention in the Attention-driven Robot Manipulation (ARM) system, we are able to accomplish a larger set of tasks; especially on those that suffer from \"coarse ambiguity\". In addition to evaluating our approach across 12 RLBench tasks, we also show that the improved performance is visible in a real-world task involving small objects.", "paper_url": "http://arxiv.org/abs/2204.12471v1", "pdf_url": "http://arxiv.org/pdf/2204.12471v1", "repo_url": null}, "2204.12466": {"publish_time": "2022-04-26", "title": "Meta-free representation learning for few-shot learning via stochastic weight averaging", "author": "Kuilin Chen et.al.", "abstract": "Recent studies on few-shot classification using transfer learning pose challenges to the effectiveness and efficiency of episodic meta-learning algorithms. Transfer learning approaches are a natural alternative, but they are restricted to few-shot classification. Moreover, little attention has been on the development of probabilistic models with well-calibrated uncertainty from few-shot samples, except for some Bayesian episodic learning algorithms. To tackle the aforementioned issues, we propose a new transfer learning method to obtain accurate and reliable models for few-shot regression and classification. The resulting method does not require episodic meta-learning and is called meta-free representation learning (MFRL). MFRL first finds low-rank representation generalizing well on meta-test tasks. Given the learned representation, probabilistic linear models are fine-tuned with few-shot samples to obtain models with well-calibrated uncertainty. The proposed method not only achieves the highest accuracy on a wide range of few-shot learning benchmark datasets but also correctly quantifies the prediction uncertainty. In addition, weight averaging and temperature scaling are effective in improving the accuracy and reliability of few-shot learning in existing meta-learning algorithms with a wide range of learning paradigms and model architectures.", "paper_url": "http://arxiv.org/abs/2204.12466v1", "pdf_url": "http://arxiv.org/pdf/2204.12466v1", "repo_url": null}, "2204.13101": {"publish_time": "2022-04-27", "title": "Self-Supervised Learning of Object Parts for Semantic Segmentation", "author": "Adrian Ziegler et.al.", "abstract": "Progress in self-supervised learning has brought strong general image representation learning methods. Yet so far, it has mostly focused on image-level learning. In turn, tasks such as unsupervised image segmentation have not benefited from this trend as they require spatially-diverse representations. However, learning dense representations is challenging, as in the unsupervised context it is not clear how to guide the model to learn representations that correspond to various potential object categories. In this paper, we argue that self-supervised learning of object parts is a solution to this issue. Object parts are generalizable: they are a priori independent of an object definition, but can be grouped to form objects a posteriori. To this end, we leverage the recently proposed Vision Transformer's capability of attending to objects and combine it with a spatially dense clustering task for fine-tuning the spatial tokens. Our method surpasses the state-of-the-art on three semantic segmentation benchmarks by 17%-3%, showing that our representations are versatile under various object definitions. Finally, we extend this to fully unsupervised segmentation - which refrains completely from using label information even at test-time - and demonstrate that a simple method for automatically merging discovered object parts based on community detection yields substantial gains.", "paper_url": "http://arxiv.org/abs/2204.13101v1", "pdf_url": "http://arxiv.org/pdf/2204.13101v1", "repo_url": null}, "2204.13100": {"publish_time": "2022-04-27", "title": "Few-Shot Head Swapping in the Wild", "author": "Changyong Shu et.al.", "abstract": "The head swapping task aims at flawlessly placing a source head onto a target body, which is of great importance to various entertainment scenarios. While face swapping has drawn much attention, the task of head swapping has rarely been explored, particularly under the few-shot setting. It is inherently challenging due to its unique needs in head modeling and background blending. In this paper, we present the Head Swapper (HeSer), which achieves few-shot head swapping in the wild through two delicately designed modules. Firstly, a Head2Head Aligner is devised to holistically migrate pose and expression information from the target to the source head by examining multi-scale information. Secondly, to tackle the challenges of skin color variations and head-background mismatches in the swapping procedure, a Head2Scene Blender is introduced to simultaneously modify facial skin color and fill mismatched gaps in the background around the head. Particularly, seamless blending is achieved with the help of a Semantic-Guided Color Reference Creation procedure and a Blending UNet. Extensive experiments demonstrate that the proposed method produces superior head swapping results in a variety of scenes.", "paper_url": "http://arxiv.org/abs/2204.13100v1", "pdf_url": "http://arxiv.org/pdf/2204.13100v1", "repo_url": null}, "2204.13096": {"publish_time": "2022-04-27", "title": "3D Magic Mirror: Clothing Reconstruction from a Single Image via a Causal Perspective", "author": "Zhedong Zheng et.al.", "abstract": "This research aims to study a self-supervised 3D clothing reconstruction method, which recovers the geometry shape, and texture of human clothing from a single 2D image. Compared with existing methods, we observe that three primary challenges remain: (1) the conventional template-based methods are limited to modeling non-rigid clothing objects, e.g., handbags and dresses, which are common in fashion images; (2) 3D ground-truth meshes of clothing are usually inaccessible due to annotation difficulties and time costs. (3) It remains challenging to simultaneously optimize four reconstruction factors, i.e., camera viewpoint, shape, texture, and illumination. The inherent ambiguity compromises the model training, such as the dilemma between a large shape with a remote camera or a small shape with a close camera.   In an attempt to address the above limitations, we propose a causality-aware self-supervised learning method to adaptively reconstruct 3D non-rigid objects from 2D images without 3D annotations. In particular, to solve the inherent ambiguity among four implicit variables, i.e., camera position, shape, texture, and illumination, we study existing works and introduce an explainable structural causal map (SCM) to build our model. The proposed model structure follows the spirit of the causal map, which explicitly considers the prior template in the camera estimation and shape prediction. When optimization, the causality intervention tool, i.e., two expectation-maximization loops, is deeply embedded in our algorithm to (1) disentangle four encoders and (2) help the prior template update. Extensive experiments on two 2D fashion benchmarks, e.g., ATR, and Market-HQ, show that the proposed method could yield high-fidelity 3D reconstruction. Furthermore, we also verify the scalability of the proposed method on a fine-grained bird dataset, i.e., CUB.", "paper_url": "http://arxiv.org/abs/2204.13096v1", "pdf_url": "http://arxiv.org/pdf/2204.13096v1", "repo_url": null}, "2204.13091": {"publish_time": "2022-04-27", "title": "Attention Consistency on Visual Corruptions for Single-Source Domain Generalization", "author": "Ilke Cugu et.al.", "abstract": "Generalizing visual recognition models trained on a single distribution to unseen input distributions (i.e. domains) requires making them robust to superfluous correlations in the training set. In this work, we achieve this goal by altering the training images to simulate new domains and imposing consistent visual attention across the different views of the same sample. We discover that the first objective can be simply and effectively met through visual corruptions. Specifically, we alter the content of the training images using the nineteen corruptions of the ImageNet-C benchmark and three additional transformations based on Fourier transform. Since these corruptions preserve object locations, we propose an attention consistency loss to ensure that class activation maps across original and corrupted versions of the same training sample are aligned. We name our model Attention Consistency on Visual Corruptions (ACVC). We show that ACVC consistently achieves the state of the art on three single-source domain generalization benchmarks, PACS, COCO, and the large-scale DomainNet.", "paper_url": "http://arxiv.org/abs/2204.13091v1", "pdf_url": "http://arxiv.org/pdf/2204.13091v1", "repo_url": "https://github.com/explainableml/acvc"}, "2204.13062": {"publish_time": "2022-04-27", "title": "Collaborative Learning for Hand and Object Reconstruction with Attention-guided Graph Convolution", "author": "Tze Ho Elden Tse et.al.", "abstract": "Estimating the pose and shape of hands and objects under interaction finds numerous applications including augmented and virtual reality. Existing approaches for hand and object reconstruction require explicitly defined physical constraints and known objects, which limits its application domains. Our algorithm is agnostic to object models, and it learns the physical rules governing hand-object interaction. This requires automatically inferring the shapes and physical interaction of hands and (potentially unknown) objects. We seek to approach this challenging problem by proposing a collaborative learning strategy where two-branches of deep networks are learning from each other. Specifically, we transfer hand mesh information to the object branch and vice versa for the hand branch. The resulting optimisation (training) problem can be unstable, and we address this via two strategies: (i) attention-guided graph convolution which helps identify and focus on mutual occlusion and (ii) unsupervised associative loss which facilitates the transfer of information between the branches. Experiments using four widely-used benchmarks show that our framework achieves beyond state-of-the-art accuracy in 3D pose estimation, as well as recovers dense 3D hand and object shapes. Each technical component above contributes meaningfully in the ablation study.", "paper_url": "http://arxiv.org/abs/2204.13062v1", "pdf_url": "http://arxiv.org/pdf/2204.13062v1", "repo_url": null}, "2204.13696": {"publish_time": "2022-04-28", "title": "NeurMiPs: Neural Mixture of Planar Experts for View Synthesis", "author": "Zhi-Hao Lin et.al.", "abstract": "We present Neural Mixtures of Planar Experts (NeurMiPs), a novel planar-based scene representation for modeling geometry and appearance. NeurMiPs leverages a collection of local planar experts in 3D space as the scene representation. Each planar expert consists of the parameters of the local rectangular shape representing geometry and a neural radiance field modeling the color and opacity. We render novel views by calculating ray-plane intersections and composite output colors and densities at intersected points to the image. NeurMiPs blends the efficiency of explicit mesh rendering and flexibility of the neural radiance field. Experiments demonstrate superior performance and speed of our proposed method, compared to other 3D representations in novel view synthesis.", "paper_url": "http://arxiv.org/abs/2204.13696v1", "pdf_url": "http://arxiv.org/pdf/2204.13696v1", "repo_url": "https://github.com/zhihao-lin/neurmips"}, "2204.13686": {"publish_time": "2022-04-28", "title": "HuMMan: Multi-Modal 4D Human Dataset for Versatile Sensing and Modeling", "author": "Zhongang Cai et.al.", "abstract": "4D human sensing and modeling are fundamental tasks in vision and graphics with numerous applications. With the advances of new sensors and algorithms, there is an increasing demand for more versatile datasets. In this work, we contribute HuMMan, a large-scale multi-modal 4D human dataset with 1000 human subjects, 400k sequences and 60M frames. HuMMan has several appealing properties: 1) multi-modal data and annotations including color images, point clouds, keypoints, SMPL parameters, and textured meshes; 2) popular mobile device is included in the sensor suite; 3) a set of 500 actions, designed to cover fundamental movements; 4) multiple tasks such as action recognition, pose estimation, parametric human recovery, and textured mesh reconstruction are supported and evaluated. Extensive experiments on HuMMan voice the need for further study on challenges such as fine-grained action recognition, dynamic human mesh reconstruction, point cloud-based parametric human recovery, and cross-device domain gaps.", "paper_url": "http://arxiv.org/abs/2204.13686v1", "pdf_url": "http://arxiv.org/pdf/2204.13686v1", "repo_url": null}, "2204.13683": {"publish_time": "2022-04-28", "title": "KING: Generating Safety-Critical Driving Scenarios for Robust Imitation via Kinematics Gradients", "author": "Niklas Hanselmann et.al.", "abstract": "Simulators offer the possibility of safe, low-cost development of self-driving systems. However, current driving simulators exhibit na\\\"ive behavior models for background traffic. Hand-tuned scenarios are typically added during simulation to induce safety-critical situations. An alternative approach is to adversarially perturb the background traffic trajectories. In this paper, we study this approach to safety-critical driving scenario generation using the CARLA simulator. We use a kinematic bicycle model as a proxy to the simulator's true dynamics and observe that gradients through this proxy model are sufficient for optimizing the background traffic trajectories. Based on this finding, we propose KING, which generates safety-critical driving scenarios with a 20% higher success rate than black-box optimization. By solving the scenarios generated by KING using a privileged rule-based expert algorithm, we obtain training data for an imitation learning policy. After fine-tuning on this new data, we show that the policy becomes better at avoiding collisions. Importantly, our generated data leads to reduced collisions on both held-out scenarios generated via KING as well as traditional hand-crafted scenarios, demonstrating improved robustness.", "paper_url": "http://arxiv.org/abs/2204.13683v1", "pdf_url": "http://arxiv.org/pdf/2204.13683v1", "repo_url": null}, "2204.13678": {"publish_time": "2022-04-28", "title": "Unified Simulation, Perception, and Generation of Human Behavior", "author": "Ye Yuan et.al.", "abstract": "Understanding and modeling human behavior is fundamental to almost any computer vision and robotics applications that involve humans. In this thesis, we take a holistic approach to human behavior modeling and tackle its three essential aspects -- simulation, perception, and generation. Throughout the thesis, we show how the three aspects are deeply connected and how utilizing and improving one aspect can greatly benefit the other aspects. We also discuss the lessons learned and our vision for what is next for human behavior modeling.", "paper_url": "http://arxiv.org/abs/2204.13678v1", "pdf_url": "http://arxiv.org/pdf/2204.13678v1", "repo_url": null}, "2204.13662": {"publish_time": "2022-04-28", "title": "Articulated Objects in Free-form Hand Interaction", "author": "Zicong Fan et.al.", "abstract": "We use our hands to interact with and to manipulate objects. Articulated objects are especially interesting since they often require the full dexterity of human hands to manipulate them. To understand, model, and synthesize such interactions, automatic and robust methods that reconstruct hands and articulated objects in 3D from a color image are needed. Existing methods for estimating 3D hand and object pose from images focus on rigid objects. In part, because such methods rely on training data and no dataset of articulated object manipulation exists. Consequently, we introduce ARCTIC - the first dataset of free-form interactions of hands and articulated objects. ARCTIC has 1.2M images paired with accurate 3D meshes for both hands and for objects that move and deform over time. The dataset also provides hand-object contact information. To show the value of our dataset, we perform two novel tasks on ARCTIC: (1) 3D reconstruction of two hands and an articulated object in interaction; (2) an estimation of dense hand-object relative distances, which we call interaction field estimation. For the first task, we present ArcticNet, a baseline method for the task of jointly reconstructing two hands and an articulated object from an RGB image. For interaction field estimation, we predict the relative distances from each hand vertex to the object surface, and vice versa. We introduce InterField, the first method that estimates such distances from a single RGB image. We provide qualitative and quantitative experiments for both tasks, and provide detailed analysis on the data. Code and data will be available at https://arctic.is.tue.mpg.de.", "paper_url": "http://arxiv.org/abs/2204.13662v1", "pdf_url": "http://arxiv.org/pdf/2204.13662v1", "repo_url": null}, "2204.14249": {"publish_time": "2022-04-29", "title": "OSSGAN: Open-Set Semi-Supervised Image Generation", "author": "Kai Katsumata et.al.", "abstract": "We introduce a challenging training scheme of conditional GANs, called open-set semi-supervised image generation, where the training dataset consists of two parts: (i) labeled data and (ii) unlabeled data with samples belonging to one of the labeled data classes, namely, a closed-set, and samples not belonging to any of the labeled data classes, namely, an open-set. Unlike the existing semi-supervised image generation task, where unlabeled data only contain closed-set samples, our task is more general and lowers the data collection cost in practice by allowing open-set samples to appear. Thanks to entropy regularization, the classifier that is trained on labeled data is able to quantify sample-wise importance to the training of cGAN as confidence, allowing us to use all samples in unlabeled data. We design OSSGAN, which provides decision clues to the discriminator on the basis of whether an unlabeled image belongs to one or none of the classes of interest, smoothly integrating labeled and unlabeled data during training. The results of experiments on Tiny ImageNet and ImageNet show notable improvements over supervised BigGAN and semi-supervised methods. Our code is available at https://github.com/raven38/OSSGAN.", "paper_url": "http://arxiv.org/abs/2204.14249v1", "pdf_url": "http://arxiv.org/pdf/2204.14249v1", "repo_url": "https://github.com/raven38/ossgan"}, "2204.14244": {"publish_time": "2022-04-29", "title": "CLIP-Art: Contrastive Pre-training for Fine-Grained Art Classification", "author": "Marcos V. Conde et.al.", "abstract": "Existing computer vision research in artwork struggles with artwork's fine-grained attributes recognition and lack of curated annotated datasets due to their costly creation. To the best of our knowledge, we are one of the first methods to use CLIP (Contrastive Language-Image Pre-Training) to train a neural network on a variety of artwork images and text descriptions pairs. CLIP is able to learn directly from free-form art descriptions, or, if available, curated fine-grained labels. Model's zero-shot capability allows predicting accurate natural language description for a given image, without directly optimizing for the task. Our approach aims to solve 2 challenges: instance retrieval and fine-grained artwork attribute recognition. We use the iMet Dataset, which we consider the largest annotated artwork dataset. In this benchmark we achieved competitive results using only self-supervision.", "paper_url": "http://arxiv.org/abs/2204.14244v1", "pdf_url": "http://arxiv.org/pdf/2204.14244v1", "repo_url": "https://github.com/KeremTurgutlu/clip_art"}, "2204.14240": {"publish_time": "2022-04-29", "title": "EndoMapper dataset of complete calibrated endoscopy procedures", "author": "Pablo Azagra et.al.", "abstract": "Computer-assisted systems are becoming broadly used in medicine. In endoscopy, most research focuses on automatic detection of polyps or other pathologies, but localization and navigation of the endoscope is completely performed manually by physicians. To broaden this research and bring spatial Artificial Intelligence to endoscopies, data from complete procedures are needed. This data will be used to build a 3D mapping and localization systems that can perform special task like, for example, detect blind zones during exploration, provide automatic polyp measurements, guide doctors to a polyp found in a previous exploration and retrieve previous images of the same area aligning them for easy comparison. These systems will provide an improvement in the quality and precision of the procedures while lowering the burden on the physicians. This paper introduces the Endomapper dataset, the first collection of complete endoscopy sequences acquired during regular medical practice, including slow and careful screening explorations, making secondary use of medical data. Its original purpose is to facilitate the development and evaluation of VSLAM (Visual Simultaneous Localization and Mapping) methods in real endoscopy data. The first release of the dataset is composed of 59 sequences with more than 15 hours of video. It is also the first endoscopic dataset that includes both the computed geometric and photometric endoscope calibration with the original calibration videos. Meta-data and annotations associated to the dataset varies from anatomical landmark and description of the procedure labeling, tools segmentation masks, COLMAP 3D reconstructions, simulated sequences with groundtruth and meta-data related to special cases, such as sequences from the same patient. This information will improve the research in endoscopic VSLAM, as well as other research lines, and create new research lines.", "paper_url": "http://arxiv.org/abs/2204.14240v1", "pdf_url": "http://arxiv.org/pdf/2204.14240v1", "repo_url": null}, "2204.14228": {"publish_time": "2022-04-29", "title": "Hardware Trojan Detection Using Unsupervised Deep Learning on Quantum Diamond Microscope Magnetic Field Images", "author": "Maitreyi Ashok et.al.", "abstract": "This paper presents a method for hardware trojan detection in integrated circuits. Unsupervised deep learning is used to classify wide field-of-view (4x4 mm$^2$), high spatial resolution magnetic field images taken using a Quantum Diamond Microscope (QDM). QDM magnetic imaging is enhanced using quantum control techniques and improved diamond material to increase magnetic field sensitivity by a factor of 4 and measurement speed by a factor of 16 over previous demonstrations. These upgrades facilitate the first demonstration of QDM magnetic field measurement for hardware trojan detection. Unsupervised convolutional neural networks and clustering are used to infer trojan presence from unlabeled data sets of 600x600 pixel magnetic field images without human bias. This analysis is shown to be more accurate than principal component analysis for distinguishing between field programmable gate arrays configured with trojan free and trojan inserted logic. This framework is tested on a set of scalable trojans that we developed and measured with the QDM. Scalable and TrustHub trojans are detectable down to a minimum trojan trigger size of 0.5% of the total logic. The trojan detection framework can be used for golden-chip free detection, since knowledge of the chips' identities is only used to evaluate detection accuracy", "paper_url": "http://arxiv.org/abs/2204.14228v1", "pdf_url": "http://arxiv.org/pdf/2204.14228v1", "repo_url": null}, "2204.14199": {"publish_time": "2022-04-29", "title": "Preoperative brain tumor imaging: models and software for segmentation and standardized reporting", "author": "D. Bouget et.al.", "abstract": "For patients suffering from brain tumor, prognosis estimation and treatment decisions are made by a multidisciplinary team based on a set of preoperative MR scans. Currently, the lack of standardized and automatic methods for tumor detection and generation of clinical reports represents a major hurdle. In this study, we investigate glioblastomas, lower grade gliomas, meningiomas, and metastases, through four cohorts of up to 4000 patients. Tumor segmentation models were trained using the AGU-Net architecture with different preprocessing steps and protocols. Segmentation performances were assessed in-depth using a wide-range of voxel and patient-wise metrics covering volume, distance, and probabilistic aspects. Finally, two software solutions have been developed, enabling an easy use of the trained models and standardized generation of clinical reports: Raidionics and Raidionics-Slicer. Segmentation performances were quite homogeneous across the four different brain tumor types, with an average true positive Dice ranging between 80% and 90%, patient-wise recall between 88% and 98%, and patient-wise precision around 95%. With our Raidionics software, running on a desktop computer with CPU support, tumor segmentation can be performed in 16 to 54 seconds depending on the dimensions of the MRI volume. For the generation of a standardized clinical report, including the tumor segmentation and features computation, 5 to 15 minutes are necessary. All trained models have been made open-access together with the source code for both software solutions and validation metrics computation. In the future, an automatic classification of the brain tumor type would be necessary to replace manual user input. Finally, the inclusion of post-operative segmentation in both software solutions will be key for generating complete post-operative standardized clinical reports.", "paper_url": "http://arxiv.org/abs/2204.14199v1", "pdf_url": "http://arxiv.org/pdf/2204.14199v1", "repo_url": "https://github.com/dbouget/Raidionics"}, "2205.01089": {"publish_time": "2022-05-02", "title": "ComPhy: Compositional Physical Reasoning of Objects and Events from Videos", "author": "Zhenfang Chen et.al.", "abstract": "Objects' motions in nature are governed by complex interactions and their properties. While some properties, such as shape and material, can be identified via the object's visual appearances, others like mass and electric charge are not directly visible. The compositionality between the visible and hidden properties poses unique challenges for AI models to reason from the physical world, whereas humans can effortlessly infer them with limited observations. Existing studies on video reasoning mainly focus on visually observable elements such as object appearance, movement, and contact interaction. In this paper, we take an initial step to highlight the importance of inferring the hidden physical properties not directly observable from visual appearances, by introducing the Compositional Physical Reasoning (ComPhy) dataset. For a given set of objects, ComPhy includes few videos of them moving and interacting under different initial conditions. The model is evaluated based on its capability to unravel the compositional hidden properties, such as mass and charge, and use this knowledge to answer a set of questions posted on one of the videos. Evaluation results of several state-of-the-art video reasoning models on ComPhy show unsatisfactory performance as they fail to capture these hidden properties. We further propose an oracle neural-symbolic framework named Compositional Physics Learner (CPL), combining visual perception, physical property learning, dynamic prediction, and symbolic execution into a unified framework. CPL can effectively identify objects' physical properties from their interactions and predict their dynamics to answer questions.", "paper_url": "http://arxiv.org/abs/2205.01089v1", "pdf_url": "http://arxiv.org/pdf/2205.01089v1", "repo_url": null}, "2205.01087": {"publish_time": "2022-05-02", "title": "Incomplete Gamma Kernels: Generalizing Locally Optimal Projection Operators", "author": "Patrick Stotko et.al.", "abstract": "We present incomplete gamma kernels, a generalization of Locally Optimal Projection (LOP) operators. In particular, we reveal the relation of the classical localized $ L_1 $ estimator, used in the LOP operator for surface reconstruction from noisy point clouds, to the common Mean Shift framework via a novel kernel. Furthermore, we generalize this result to a whole family of kernels that are built upon the incomplete gamma function and each represents a localized $ L_p $ estimator. By deriving various properties of the kernel family concerning distributional, Mean Shift induced, and other aspects such as strict positive definiteness, we obtain a deeper understanding of the operator's projection behavior. From these theoretical insights, we illustrate several applications ranging from an improved Weighted LOP (WLOP) density weighting scheme and a more accurate Continuous LOP (CLOP) kernel approximation to the definition of a novel set of robust loss functions. These incomplete gamma losses include the Gaussian and LOP loss as special cases and can be applied for reconstruction tasks such as normal filtering. We demonstrate the effects of each application in a range of quantitative and qualitative experiments that highlight the benefits induced by our modifications.", "paper_url": "http://arxiv.org/abs/2205.01087v1", "pdf_url": "http://arxiv.org/pdf/2205.01087v1", "repo_url": null}, "2205.01006": {"publish_time": "2022-05-02", "title": "Open-Set Semi-Supervised Learning for 3D Point Cloud Understanding", "author": "Xian Shi et.al.", "abstract": "Semantic understanding of 3D point cloud relies on learning models with massively annotated data, which, in many cases, are expensive or difficult to collect. This has led to an emerging research interest in semi-supervised learning (SSL) for 3D point cloud. It is commonly assumed in SSL that the unlabeled data are drawn from the same distribution as that of the labeled ones; This assumption, however, rarely holds true in realistic environments. Blindly using out-of-distribution (OOD) unlabeled data could harm SSL performance. In this work, we propose to selectively utilize unlabeled data through sample weighting, so that only conducive unlabeled data would be prioritized. To estimate the weights, we adopt a bi-level optimization framework which iteratively optimizes a metaobjective on a held-out validation set and a task-objective on a training set. Faced with the instability of efficient bi-level optimizers, we further propose three regularization techniques to enhance the training stability. Extensive experiments on 3D point cloud classification and segmentation tasks verify the effectiveness of our proposed method. We also demonstrate the feasibility of a more efficient training strategy.", "paper_url": "http://arxiv.org/abs/2205.01006v1", "pdf_url": "http://arxiv.org/pdf/2205.01006v1", "repo_url": null}, "2205.00968": {"publish_time": "2022-05-02", "title": "Detection Recovery in Online Multi-Object Tracking with Sparse Graph Tracker", "author": "Jeongseok Hyun et.al.", "abstract": "Joint object detection and online multi-object tracking (JDT) methods have been proposed recently to achieve one-shot tracking. Yet, existing works overlook the importance of detection itself and often result in missed detections when confronted by occlusions or motion blurs. The missed detections affect not only detection performance but also tracking performance due to inconsistent tracklets. Hence, we propose a new JDT model that recovers the missed detections while associating the detection candidates of consecutive frames by learning object-level spatio-temporal consistency through edge features in a Graph Neural Network (GNN). Our proposed model Sparse Graph Tracker (SGT) converts video data into a graph, where the nodes are top-$K$ scored detection candidates, and the edges are relations between the nodes at different times, such as position difference and visual similarity. Two nodes are connected if they are close in either a Euclidean or feature space, generating a sparsely connected graph. Without motion prediction or Re-Identification (ReID), the association is performed by predicting an edge score representing the probability that two connected nodes refer to the same object. Under the online setting, our SGT achieves state-of-the-art (SOTA) on the MOT17/20 Detection and MOT16/20 benchmarks in terms of AP and MOTA, respectively. Especially, SGT surpasses the previous SOTA on the crowded dataset MOT20 where partial occlusion cases are dominant, showing the effectiveness of detection recovery against partial occlusion. Code will be released at https://github.com/HYUNJS/SGT.", "paper_url": "http://arxiv.org/abs/2205.00968v1", "pdf_url": "http://arxiv.org/pdf/2205.00968v1", "repo_url": null}, "2205.00967": {"publish_time": "2022-05-02", "title": "Monocular 3D Fingerprint Reconstruction and Unwarping", "author": "Zhe Cui et.al.", "abstract": "Compared with contact-based fingerprint acquisition techniques, contactless acquisition has the advantages of less skin distortion, larger fingerprint area, and hygienic acquisition. However, perspective distortion is a challenge in contactless fingerprint recognition, which changes ridge orientation, frequency, and minutiae location, and thus causes degraded recognition accuracy. We propose a learning based shape from texture algorithm to reconstruct a 3D finger shape from a single image and unwarp the raw image to suppress perspective distortion. Experimental results on contactless fingerprint databases show that the proposed method has high 3D reconstruction accuracy. Matching experiments on contactless-contact and contactless-contactless matching prove that the proposed method improves matching accuracy.", "paper_url": "http://arxiv.org/abs/2205.00967v1", "pdf_url": "http://arxiv.org/pdf/2205.00967v1", "repo_url": null}, "2205.01668": {"publish_time": "2022-05-03", "title": "End-to-End Visual Editing with a Generatively Pre-Trained Artist", "author": "Andrew Brown et.al.", "abstract": "We consider the targeted image editing problem: blending a region in a source image with a driver image that specifies the desired change. Differently from prior works, we solve this problem by learning a conditional probability distribution of the edits, end-to-end. Training such a model requires addressing a fundamental technical challenge: the lack of example edits for training. To this end, we propose a self-supervised approach that simulates edits by augmenting off-the-shelf images in a target domain. The benefits are remarkable: implemented as a state-of-the-art auto-regressive transformer, our approach is simple, sidesteps difficulties with previous methods based on GAN-like priors, obtains significantly better edits, and is efficient. Furthermore, we show that different blending effects can be learned by an intuitive control of the augmentation process, with no other changes required to the model architecture. We demonstrate the superiority of this approach across several datasets in extensive quantitative and qualitative experiments, including human studies, significantly outperforming prior work.", "paper_url": "http://arxiv.org/abs/2205.01668v1", "pdf_url": "http://arxiv.org/pdf/2205.01668v1", "repo_url": null}, "2205.01666": {"publish_time": "2022-05-03", "title": "DANBO: Disentangled Articulated Neural Body Representations via Graph Neural Networks", "author": "Shih-Yang Su et.al.", "abstract": "Deep learning greatly improved the realism of animatable human models by learning geometry and appearance from collections of 3D scans, template meshes, and multi-view imagery. High-resolution models enable photo-realistic avatars but at the cost of requiring studio settings not available to end users. Our goal is to create avatars directly from raw images without relying on expensive studio setups and surface tracking. While a few such approaches exist, those have limited generalization capabilities and are prone to learning spurious (chance) correlations between irrelevant body parts, resulting in implausible deformations and missing body parts on unseen poses. We introduce a three-stage method that induces two inductive biases to better disentangled pose-dependent deformation. First, we model correlations of body parts explicitly with a graph neural network. Second, to further reduce the effect of chance correlations, we introduce localized per-bone features that use a factorized volumetric representation and a new aggregation function. We demonstrate that our model produces realistic body shapes under challenging unseen poses and shows high-quality image synthesis. Our proposed representation strikes a better trade-off between model capacity, expressiveness, and robustness than competing methods. Project website: https://lemonatsu.github.io/danbo.", "paper_url": "http://arxiv.org/abs/2205.01666v1", "pdf_url": "http://arxiv.org/pdf/2205.01666v1", "repo_url": null}, "2205.01657": {"publish_time": "2022-05-03", "title": "Cross-modal Representation Learning for Zero-shot Action Recognition", "author": "Chung-Ching Lin et.al.", "abstract": "We present a cross-modal Transformer-based framework, which jointly encodes video data and text labels for zero-shot action recognition (ZSAR). Our model employs a conceptually new pipeline by which visual representations are learned in conjunction with visual-semantic associations in an end-to-end manner. The model design provides a natural mechanism for visual and semantic representations to be learned in a shared knowledge space, whereby it encourages the learned visual embedding to be discriminative and more semantically consistent. In zero-shot inference, we devise a simple semantic transfer scheme that embeds semantic relatedness information between seen and unseen classes to composite unseen visual prototypes. Accordingly, the discriminative features in the visual structure could be preserved and exploited to alleviate the typical zero-shot issues of information loss, semantic gap, and the hubness problem. Under a rigorous zero-shot setting of not pre-training on additional datasets, the experiment results show our model considerably improves upon the state of the arts in ZSAR, reaching encouraging top-1 accuracy on UCF101, HMDB51, and ActivityNet benchmark datasets. Code will be made available.", "paper_url": "http://arxiv.org/abs/2205.01657v1", "pdf_url": "http://arxiv.org/pdf/2205.01657v1", "repo_url": null}, "2205.01656": {"publish_time": "2022-05-03", "title": "GeoRefine: Self-Supervised Online Depth Refinement for Accurate Dense Mapping", "author": "Pan Ji et.al.", "abstract": "We present a robust and accurate depth refinement system, named GeoRefine, for geometrically-consistent dense mapping from monocular sequences. GeoRefine consists of three modules: a hybrid SLAM module using learning-based priors, an online depth refinement module leveraging self-supervision, and a global mapping module via TSDF fusion. The proposed system is online by design and achieves great robustness and accuracy via: (i) a robustified hybrid SLAM that incorporates learning-based optical flow and/or depth; (ii) self-supervised losses that leverage SLAM outputs and enforce long-term geometric consistency; (iii) careful system design that avoids degenerate cases in online depth refinement. We extensively evaluate GeoRefine on multiple public datasets and reach as low as $5\\%$ absolute relative depth errors.", "paper_url": "http://arxiv.org/abs/2205.01656v1", "pdf_url": "http://arxiv.org/pdf/2205.01656v1", "repo_url": null}, "2205.01652": {"publish_time": "2022-05-03", "title": "Episodic Memory Question Answering", "author": "Samyak Datta et.al.", "abstract": "Egocentric augmented reality devices such as wearable glasses passively capture visual data as a human wearer tours a home environment. We envision a scenario wherein the human communicates with an AI agent powering such a device by asking questions (e.g., where did you last see my keys?). In order to succeed at this task, the egocentric AI assistant must (1) construct semantically rich and efficient scene memories that encode spatio-temporal information about objects seen during the tour and (2) possess the ability to understand the question and ground its answer into the semantic memory representation. Towards that end, we introduce (1) a new task - Episodic Memory Question Answering (EMQA) wherein an egocentric AI assistant is provided with a video sequence (the tour) and a question as an input and is asked to localize its answer to the question within the tour, (2) a dataset of grounded questions designed to probe the agent's spatio-temporal understanding of the tour, and (3) a model for the task that encodes the scene as an allocentric, top-down semantic feature map and grounds the question into the map to localize the answer. We show that our choice of episodic scene memory outperforms naive, off-the-shelf solutions for the task as well as a host of very competitive baselines and is robust to noise in depth, pose as well as camera jitter. The project page can be found at: https://samyak-268.github.io/emqa .", "paper_url": "http://arxiv.org/abs/2205.01652v1", "pdf_url": "http://arxiv.org/pdf/2205.01652v1", "repo_url": null}, "2205.02222": {"publish_time": "2022-05-04", "title": "COOPERNAUT: End-to-End Driving with Cooperative Perception for Networked Vehicles", "author": "Jiaxun Cui et.al.", "abstract": "Optical sensors and learning algorithms for autonomous vehicles have dramatically advanced in the past few years. Nonetheless, the reliability of today's autonomous vehicles is hindered by the limited line-of-sight sensing capability and the brittleness of data-driven methods in handling extreme situations. With recent developments of telecommunication technologies, cooperative perception with vehicle-to-vehicle communications has become a promising paradigm to enhance autonomous driving in dangerous or emergency situations. We introduce COOPERNAUT, an end-to-end learning model that uses cross-vehicle perception for vision-based cooperative driving. Our model encodes LiDAR information into compact point-based representations that can be transmitted as messages between vehicles via realistic wireless channels. To evaluate our model, we develop AutoCastSim, a network-augmented driving simulation framework with example accident-prone scenarios. Our experiments on AutoCastSim suggest that our cooperative perception driving models lead to a 40% improvement in average success rate over egocentric driving models in these challenging driving situations and a 5 times smaller bandwidth requirement than prior work V2VNet. COOPERNAUT and AUTOCASTSIM are available at https://ut-austin-rpl.github.io/Coopernaut/.", "paper_url": "http://arxiv.org/abs/2205.02222v1", "pdf_url": "http://arxiv.org/pdf/2205.02222v1", "repo_url": null}, "2205.02169": {"publish_time": "2022-05-04", "title": "Compound virtual screening by learning-to-rank with gradient boosting decision tree and enrichment-based cumulative gain", "author": "Kairi Furui et.al.", "abstract": "Learning-to-rank, a machine learning technique widely used in information retrieval, has recently been applied to the problem of ligand-based virtual screening, to accelerate the early stages of new drug development. Ranking prediction models learn based on ordinal relationships, making them suitable for integrating assay data from various environments. Existing studies of rank prediction in compound screening have generally used a learning-to-rank method called RankSVM. However, they have not been compared with or validated against the gradient boosting decision tree (GBDT)-based learning-to-rank methods that have gained popularity recently. Furthermore, although the ranking metric called Normalized Discounted Cumulative Gain (NDCG) is widely used in information retrieval, it only determines whether the predictions are better than those of other models. In other words, NDCG is incapable of recognizing when a prediction model produces worse than random results. Nevertheless, NDCG is still used in the performance evaluation of compound screening using learning-to-rank. This study used the GBDT model with ranking loss functions, called lambdarank and lambdaloss, for ligand-based virtual screening; results were compared with existing RankSVM methods and GBDT models using regression. We also proposed a new ranking metric, Normalized Enrichment Discounted Cumulative Gain (NEDCG), which aims to properly evaluate the goodness of ranking predictions. Results showed that the GBDT model with learning-to-rank outperformed existing regression methods using GBDT and RankSVM on diverse datasets. Moreover, NEDCG showed that predictions by regression were comparable to random predictions in multi-assay, multi-family datasets, demonstrating its usefulness for a more direct assessment of compound screening performance.", "paper_url": "http://arxiv.org/abs/2205.02169v1", "pdf_url": "http://arxiv.org/pdf/2205.02169v1", "repo_url": null}, "2205.02162": {"publish_time": "2022-05-04", "title": "UnrealNAS: Can We Search Neural Architectures with Unreal Data?", "author": "Zhen Dong et.al.", "abstract": "Neural architecture search (NAS) has shown great success in the automatic design of deep neural networks (DNNs). However, the best way to use data to search network architectures is still unclear and under exploration. Previous work [19, 46] has analyzed the necessity of having ground-truth labels in NAS and inspired broad interest. In this work, we take a further step to question whether real data is necessary for NAS to be effective. The answer to this question is important for applications with limited amount of accessible data, and can help people improve NAS by leveraging the extra flexibility of data generation. To explore if NAS needs real data, we construct three types of unreal datasets using: 1) randomly labeled real images; 2) generated images and labels; and 3) generated Gaussian noise with random labels. These datasets facilitate to analyze the generalization and expressivity of the searched architectures. We study the performance of architectures searched on these constructed datasets using popular differentiable NAS methods. Extensive experiments on CIFAR, ImageNet and CheXpert [12] show that the searched architectures can achieve promising results compared with those derived from the conventional NAS pipeline with real labeled data, suggesting the feasibility of performing NAS with unreal data.", "paper_url": "http://arxiv.org/abs/2205.02162v1", "pdf_url": "http://arxiv.org/pdf/2205.02162v1", "repo_url": null}, "2205.02152": {"publish_time": "2022-05-04", "title": "Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models", "author": "Constantine Maganaris et.al.", "abstract": "Recent studies indicate that detecting radiographic patterns on CT scans can yield high sensitivity and specificity for COVID-19 localization. In this paper, we investigate the appropriateness of deep learning models transferability, for semantic segmentation of pneumonia-infected areas in CT images. Transfer learning allows for the fast initialization/ reutilization of detection models, given that large volumes of training are not available. Our work explores the efficacy of using pre-trained U-Net architectures, on a specific CT data set, for identifying Covid-19 side-effects over images from different datasets. Experimental results indicate improvement in the segmentation accuracy of identifying COVID-19 infected regions.", "paper_url": "http://arxiv.org/abs/2205.02152v1", "pdf_url": "http://arxiv.org/pdf/2205.02152v1", "repo_url": null}, "2205.02151": {"publish_time": "2022-05-04", "title": "Dual Cross-Attention Learning for Fine-Grained Visual Categorization and Object Re-Identification", "author": "Haowei Zhu et.al.", "abstract": "Recently, self-attention mechanisms have shown impressive performance in various NLP and CV tasks, which can help capture sequential characteristics and derive global information. In this work, we explore how to extend self-attention modules to better learn subtle feature embeddings for recognizing fine-grained objects, e.g., different bird species or person identities. To this end, we propose a dual cross-attention learning (DCAL) algorithm to coordinate with self-attention learning. First, we propose global-local cross-attention (GLCA) to enhance the interactions between global images and local high-response regions, which can help reinforce the spatial-wise discriminative clues for recognition. Second, we propose pair-wise cross-attention (PWCA) to establish the interactions between image pairs. PWCA can regularize the attention learning of an image by treating another image as distractor and will be removed during inference. We observe that DCAL can reduce misleading attentions and diffuse the attention response to discover more complementary parts for recognition. We conduct extensive evaluations on fine-grained visual categorization and object re-identification. Experiments demonstrate that DCAL performs on par with state-of-the-art methods and consistently improves multiple self-attention baselines, e.g., surpassing DeiT-Tiny and ViT-Base by 2.8% and 2.4% mAP on MSMT17, respectively.", "paper_url": "http://arxiv.org/abs/2205.02151v1", "pdf_url": "http://arxiv.org/pdf/2205.02151v1", "repo_url": null}, "2205.02836": {"publish_time": "2022-05-05", "title": "Neural 3D Scene Reconstruction with the Manhattan-world Assumption", "author": "Haoyu Guo et.al.", "abstract": "This paper addresses the challenge of reconstructing 3D indoor scenes from multi-view images. Many previous works have shown impressive reconstruction results on textured objects, but they still have difficulty in handling low-textured planar regions, which are common in indoor scenes. An approach to solving this issue is to incorporate planer constraints into the depth map estimation in multi-view stereo-based methods, but the per-view plane estimation and depth optimization lack both efficiency and multi-view consistency. In this work, we show that the planar constraints can be conveniently integrated into the recent implicit neural representation-based reconstruction methods. Specifically, we use an MLP network to represent the signed distance function as the scene geometry. Based on the Manhattan-world assumption, planar constraints are employed to regularize the geometry in floor and wall regions predicted by a 2D semantic segmentation network. To resolve the inaccurate segmentation, we encode the semantics of 3D points with another MLP and design a novel loss that jointly optimizes the scene geometry and semantics in 3D space. Experiments on ScanNet and 7-Scenes datasets show that the proposed method outperforms previous methods by a large margin on 3D reconstruction quality. The code is available at https://zju3dv.github.io/manhattan_sdf.", "paper_url": "http://arxiv.org/abs/2205.02836v1", "pdf_url": "http://arxiv.org/pdf/2205.02836v1", "repo_url": "https://github.com/zju3dv/manhattan_sdf"}, "2205.02837": {"publish_time": "2022-05-05", "title": "BlobGAN: Spatially Disentangled Scene Representations", "author": "Dave Epstein et.al.", "abstract": "We propose an unsupervised, mid-level representation for a generative model of scenes. The representation is mid-level in that it is neither per-pixel nor per-image; rather, scenes are modeled as a collection of spatial, depth-ordered \"blobs\" of features. Blobs are differentiably placed onto a feature grid that is decoded into an image by a generative adversarial network. Due to the spatial uniformity of blobs and the locality inherent to convolution, our network learns to associate different blobs with different entities in a scene and to arrange these blobs to capture scene layout. We demonstrate this emergent behavior by showing that, despite training without any supervision, our method enables applications such as easy manipulation of objects within a scene (e.g., moving, removing, and restyling furniture), creation of feasible scenes given constraints (e.g., plausible rooms with drawers at a particular location), and parsing of real-world images into constituent parts. On a challenging multi-category dataset of indoor scenes, BlobGAN outperforms StyleGAN2 in image quality as measured by FID. See our project page for video results and interactive demo: http://www.dave.ml/blobgan", "paper_url": "http://arxiv.org/abs/2205.02837v1", "pdf_url": "http://arxiv.org/pdf/2205.02837v1", "repo_url": null}, "2205.02835": {"publish_time": "2022-05-05", "title": "Contact Points Discovery for Soft-Body Manipulations with Differentiable Physics", "author": "Sizhe Li et.al.", "abstract": "Differentiable physics has recently been shown as a powerful tool for solving soft-body manipulation tasks. However, the differentiable physics solver often gets stuck when the initial contact points of the end effectors are sub-optimal or when performing multi-stage tasks that require contact point switching, which often leads to local minima. To address this challenge, we propose a contact point discovery approach (CPDeform) that guides the stand-alone differentiable physics solver to deform various soft-body plasticines. The key idea of our approach is to integrate optimal transport-based contact points discovery into the differentiable physics solver to overcome the local minima from initial contact points or contact switching. On single-stage tasks, our method can automatically find suitable initial contact points based on transport priorities. On complex multi-stage tasks, we can iteratively switch the contact points of end-effectors based on transport priorities. To evaluate the effectiveness of our method, we introduce PlasticineLab-M that extends the existing differentiable physics benchmark PlasticineLab to seven new challenging multi-stage soft-body manipulation tasks. Extensive experimental results suggest that: 1) on multi-stage tasks that are infeasible for the vanilla differentiable physics solver, our approach discovers contact points that efficiently guide the solver to completion; 2) on tasks where the vanilla solver performs sub-optimally or near-optimally, our contact point discovery method performs better than or on par with the manipulation performance obtained with handcrafted contact points.", "paper_url": "http://arxiv.org/abs/2205.02835v1", "pdf_url": "http://arxiv.org/pdf/2205.02835v1", "repo_url": null}, "2205.02834": {"publish_time": "2022-05-05", "title": "Fixing Malfunctional Objects With Learned Physical Simulation and Functional Prediction", "author": "Yining Hong et.al.", "abstract": "This paper studies the problem of fixing malfunctional 3D objects. While previous works focus on building passive perception models to learn the functionality from static 3D objects, we argue that functionality is reckoned with respect to the physical interactions between the object and the user. Given a malfunctional object, humans can perform mental simulations to reason about its functionality and figure out how to fix it. Inspired by this, we propose FixIt, a dataset that contains about 5k poorly-designed 3D physical objects paired with choices to fix them. To mimic humans' mental simulation process, we present FixNet, a novel framework that seamlessly incorporates perception and physical dynamics. Specifically, FixNet consists of a perception module to extract the structured representation from the 3D point cloud, a physical dynamics prediction module to simulate the results of interactions on 3D objects, and a functionality prediction module to evaluate the functionality and choose the correct fix. Experimental results show that our framework outperforms baseline models by a large margin, and can generalize well to objects with similar interaction types.", "paper_url": "http://arxiv.org/abs/2205.02834v1", "pdf_url": "http://arxiv.org/pdf/2205.02834v1", "repo_url": null}, "2205.02833": {"publish_time": "2022-05-05", "title": "Cross-view Transformers for real-time Map-view Semantic Segmentation", "author": "Brady Zhou et.al.", "abstract": "We present cross-view transformers, an efficient attention-based model for map-view semantic segmentation from multiple cameras. Our architecture implicitly learns a mapping from individual camera views into a canonical map-view representation using a camera-aware cross-view attention mechanism. Each camera uses positional embeddings that depend on its intrinsic and extrinsic calibration. These embeddings allow a transformer to learn the mapping across different views without ever explicitly modeling it geometrically. The architecture consists of a convolutional image encoder for each view and cross-view transformer layers to infer a map-view semantic segmentation. Our model is simple, easily parallelizable, and runs in real-time. The presented architecture performs at state-of-the-art on the nuScenes dataset, with 4x faster inference speeds. Code is available at https://github.com/bradyz/cross_view_transformers.", "paper_url": "http://arxiv.org/abs/2205.02833v1", "pdf_url": "http://arxiv.org/pdf/2205.02833v1", "repo_url": "https://github.com/bradyz/cross_view_transformers"}, "2205.03381": {"publish_time": "2022-05-06", "title": "MINI: Mining Implicit Novel Instances for Few-Shot Object Detection", "author": "Yuhang Cao et.al.", "abstract": "Learning from a few training samples is a desirable ability of an object detector, inspiring the explorations of Few-Shot Object Detection (FSOD). Most existing approaches employ a pretrain-transfer paradigm. The model is first pre-trained on base classes with abundant data and then transferred to novel classes with a few annotated samples. Despite the substantial progress, the FSOD performance is still far behind satisfactory. During pre-training, due to the co-occurrence between base and novel classes, the model is learned to treat the co-occurred novel classes as backgrounds. During transferring, given scarce samples of novel classes, the model suffers from learning discriminative features to distinguish novel instances from backgrounds and base classes. To overcome the obstacles, we propose a novel framework, Mining Implicit Novel Instances (MINI), to mine the implicit novel instances as auxiliary training samples, which widely exist in abundant base data but are not annotated. MINI comprises an offline mining mechanism and an online mining mechanism. The offline mining mechanism leverages a self-supervised discriminative model to collaboratively mine implicit novel instances with a trained FSOD network. Taking the mined novel instances as auxiliary training samples, the online mining mechanism takes a teacher-student framework to simultaneously update the FSOD network and the mined implicit novel instances on the fly. Extensive experiments on PASCAL VOC and MS-COCO datasets show MINI achieves new state-of-the-art performance on any shot and split. The significant performance improvements demonstrate the superiority of our method.", "paper_url": "http://arxiv.org/abs/2205.03381v1", "pdf_url": "http://arxiv.org/pdf/2205.03381v1", "repo_url": null}, "2205.03371": {"publish_time": "2022-05-06", "title": "All Grains, One Scheme (AGOS): Learning Multi-grain Instance Representation for Aerial Scene Classification", "author": "Qi Bi et.al.", "abstract": "Aerial scene classification remains challenging as: 1) the size of key objects in determining the scene scheme varies greatly; 2) many objects irrelevant to the scene scheme are often flooded in the image. Hence, how to effectively perceive the region of interests (RoIs) from a variety of sizes and build more discriminative representation from such complicated object distribution is vital to understand an aerial scene. In this paper, we propose a novel all grains, one scheme (AGOS) framework to tackle these challenges. To the best of our knowledge, it is the first work to extend the classic multiple instance learning into multi-grain formulation. Specially, it consists of a multi-grain perception module (MGP), a multi-branch multi-instance representation module (MBMIR) and a self-aligned semantic fusion (SSF) module. Firstly, our MGP preserves the differential dilated convolutional features from the backbone, which magnifies the discriminative information from multi-grains. Then, our MBMIR highlights the key instances in the multi-grain representation under the MIL formulation. Finally, our SSF allows our framework to learn the same scene scheme from multi-grain instance representations and fuses them, so that the entire framework is optimized as a whole. Notably, our AGOS is flexible and can be easily adapted to existing CNNs in a plug-and-play manner. Extensive experiments on UCM, AID and NWPU benchmarks demonstrate that our AGOS achieves a comparable performance against the state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2205.03371v1", "pdf_url": "http://arxiv.org/pdf/2205.03371v1", "repo_url": null}, "2205.03346": {"publish_time": "2022-05-06", "title": "Multitask AET with Orthogonal Tangent Regularity for Dark Object Detection", "author": "Ziteng Cui et.al.", "abstract": "Dark environment becomes a challenge for computer vision algorithms owing to insufficient photons and undesirable noise. To enhance object detection in a dark environment, we propose a novel multitask auto encoding transformation (MAET) model which is able to explore the intrinsic pattern behind illumination translation. In a self-supervision manner, the MAET learns the intrinsic visual structure by encoding and decoding the realistic illumination-degrading transformation considering the physical noise model and image signal processing (ISP).   Based on this representation, we achieve the object detection task by decoding the bounding box coordinates and classes. To avoid the over-entanglement of two tasks, our MAET disentangles the object and degrading features by imposing an orthogonal tangent regularity. This forms a parametric manifold along which multitask predictions can be geometrically formulated by maximizing the orthogonality between the tangents along the outputs of respective tasks. Our framework can be implemented based on the mainstream object detection architecture and directly trained end-to-end using normal target detection datasets, such as VOC and COCO. We have achieved the state-of-the-art performance using synthetic and real-world datasets. Code is available at https://github.com/cuiziteng/MAET.", "paper_url": "http://arxiv.org/abs/2205.03346v1", "pdf_url": "http://arxiv.org/pdf/2205.03346v1", "repo_url": "https://github.com/cuiziteng/maet"}, "2205.03340": {"publish_time": "2022-05-06", "title": "Prompt Distribution Learning", "author": "Yuning Lu et.al.", "abstract": "We present prompt distribution learning for effectively adapting a pre-trained vision-language model to address downstream recognition tasks. Our method not only learns low-bias prompts from a few samples but also captures the distribution of diverse prompts to handle the varying visual representations. In this way, we provide high-quality task-related content for facilitating recognition. This prompt distribution learning is realized by an efficient approach that learns the output embeddings of prompts instead of the input embeddings. Thus, we can employ a Gaussian distribution to model them effectively and derive a surrogate loss for efficient training. Extensive experiments on 12 datasets demonstrate that our method consistently and significantly outperforms existing methods. For example, with 1 sample per category, it relatively improves the average result by 9.1% compared to human-crafted prompts.", "paper_url": "http://arxiv.org/abs/2205.03340v1", "pdf_url": "http://arxiv.org/pdf/2205.03340v1", "repo_url": null}, "2205.03307": {"publish_time": "2022-05-06", "title": "Forget Less, Count Better: A Domain-Incremental Self-Distillation Learning Benchmark for Lifelong Crowd Counting", "author": "Jiaqi Gao et.al.", "abstract": "Crowd Counting has important applications in public safety and pandemic control. A robust and practical crowd counting system has to be capable of continuously learning with the new-coming domain data in real-world scenarios instead of fitting one domain only. Off-the-shelf methods have some drawbacks to handle multiple domains. 1) The models will achieve limited performance (even drop dramatically) among old domains after training images from new domains due to the discrepancies of intrinsic data distributions from various domains, which is called catastrophic forgetting. 2) The well-trained model in a specific domain achieves imperfect performance among other unseen domains because of the domain shift. 3) It leads to linearly-increased storage overhead either mixing all the data for training or simply training dozens of separate models for different domains when new ones are available. To overcome these issues, we investigate a new task of crowd counting under the incremental domains training setting, namely, Lifelong Crowd Counting. It aims at alleviating the catastrophic forgetting and improving the generalization ability using a single model updated by the incremental domains. To be more specific, we propose a self-distillation learning framework as a benchmark~(Forget Less, Count Better, FLCB) for lifelong crowd counting, which helps the model sustainably leverage previous meaningful knowledge for better crowd counting to mitigate the forgetting when the new data arrive. Meanwhile, a new quantitative metric, normalized backward transfer~(nBwT), is developed to evaluate the forgetting degree of the model in the lifelong learning process. Extensive experimental results demonstrate the superiority of our proposed benchmark in achieving a low catastrophic forgetting degree and strong generalization ability.", "paper_url": "http://arxiv.org/abs/2205.03307v1", "pdf_url": "http://arxiv.org/pdf/2205.03307v1", "repo_url": null}, "2205.04454": {"publish_time": "2022-05-09", "title": "OpenPodcar: an Open Source Vehicle for Self-Driving Car Research", "author": "Fanta Camara et.al.", "abstract": "OpenPodcar is a low-cost, open source hardware and software, autonomous vehicle research platform based on an off-the-shelf, hard-canopy, mobility scooter donor vehicle. Hardware and software build instructions are provided to convert the donor vehicle into a low-cost and fully autonomous platform. The open platform consists of (a) hardware components: CAD designs, bill of materials, and build instructions; (b) Arduino, ROS and Gazebo control and simulation software files which provide standard ROS interfaces and simulation of the vehicle; and (c) higher-level ROS software implementations and configurations of standard robot autonomous planning and control, including the move_base interface with Timed-Elastic-Band planner which enacts commands to drive the vehicle from a current to a desired pose around obstacles. The vehicle is large enough to transport a human passenger or similar load at speeds up to 15km/h, for example for use as a last-mile autonomous taxi service or to transport delivery containers similarly around a city center. It is small and safe enough to be parked in a standard research lab and be used for realistic human-vehicle interaction studies. System build cost from new components is around USD7,000 in total in 2022. OpenPodcar thus provides a good balance between real world utility, safety, cost and research convenience.", "paper_url": "http://arxiv.org/abs/2205.04454v1", "pdf_url": "http://arxiv.org/pdf/2205.04454v1", "repo_url": "https://github.com/openpodcar/openpodcar"}, "2205.04449": {"publish_time": "2022-05-09", "title": "Introspective Deep Metric Learning", "author": "Chengkun Wang et.al.", "abstract": "This paper proposes an introspective deep metric learning (IDML) framework for uncertainty-aware comparisons of images. Conventional deep metric learning methods produce confident semantic distances between images regardless of the uncertainty level. However, we argue that a good similarity model should consider the semantic discrepancies with caution to better deal with ambiguous images for more robust training. To achieve this, we propose to represent an image using not only a semantic embedding but also an accompanying uncertainty embedding, which describes the semantic characteristics and ambiguity of an image, respectively. We further propose an introspective similarity metric to make similarity judgments between images considering both their semantic differences and ambiguities. Our framework attains state-of-the-art performance on the widely used CUB-200-2011, Cars196, and Stanford Online Products datasets for image retrieval. We further evaluate our framework for image classification on the ImageNet-1K, CIFAR-10, and CIFAR-100 datasets, which shows that equipping existing data mixing methods with the proposed introspective metric consistently achieves better results (e.g., +0.44 for CutMix on ImageNet-1K). Code is available at: https://github.com/wangck20/IDML.", "paper_url": "http://arxiv.org/abs/2205.04449v1", "pdf_url": "http://arxiv.org/pdf/2205.04449v1", "repo_url": "https://github.com/wangck20/idml"}, "2205.04442": {"publish_time": "2022-05-09", "title": "MixAugment & Mixup: Augmentation Methods for Facial Expression Recognition", "author": "Andreas Psaroudakis et.al.", "abstract": "Automatic Facial Expression Recognition (FER) has attracted increasing attention in the last 20 years since facial expressions play a central role in human communication. Most FER methodologies utilize Deep Neural Networks (DNNs) that are powerful tools when it comes to data analysis. However, despite their power, these networks are prone to overfitting, as they often tend to memorize the training data. What is more, there are not currently a lot of in-the-wild (i.e. in unconstrained environment) large databases for FER. To alleviate this issue, a number of data augmentation techniques have been proposed. Data augmentation is a way to increase the diversity of available data by applying constrained transformations on the original data. One such technique, which has positively contributed to various classification tasks, is Mixup. According to this, a DNN is trained on convex combinations of pairs of examples and their corresponding labels. In this paper, we examine the effectiveness of Mixup for in-the-wild FER in which data have large variations in head poses, illumination conditions, backgrounds and contexts. We then propose a new data augmentation strategy which is based on Mixup, called MixAugment. According to this, the network is trained concurrently on a combination of virtual examples and real examples; all these examples contribute to the overall loss function. We conduct an extensive experimental study that proves the effectiveness of MixAugment over Mixup and various state-of-the-art methods. We further investigate the combination of dropout with Mixup and MixAugment, as well as the combination of other data augmentation techniques with MixAugment.", "paper_url": "http://arxiv.org/abs/2205.04442v1", "pdf_url": "http://arxiv.org/pdf/2205.04442v1", "repo_url": null}, "2205.04437": {"publish_time": "2022-05-09", "title": "Activating More Pixels in Image Super-Resolution Transformer", "author": "Xiangyu Chen et.al.", "abstract": "Transformer-based methods have shown impressive performance in low-level vision tasks, such as image super-resolution. However, we find that these networks can only utilize a limited spatial range of input information through attribution analysis. This implies that the potential of Transformer is still not fully exploited in existing networks. In order to activate more input pixels for reconstruction, we propose a novel Hybrid Attention Transformer (HAT). It combines channel attention and self-attention schemes, thus making use of their complementary advantages. Moreover, to better aggregate the cross-window information, we introduce an overlapping cross-attention module to enhance the interaction between neighboring window features. In the training stage, we additionally propose a same-task pre-training strategy to bring further improvement. Extensive experiments show the effectiveness of the proposed modules, and the overall method significantly outperforms the state-of-the-art methods by more than 1dB. Codes and models will be available at https://github.com/chxy95/HAT.", "paper_url": "http://arxiv.org/abs/2205.04437v1", "pdf_url": "http://arxiv.org/pdf/2205.04437v1", "repo_url": "https://github.com/chxy95/hat"}, "2205.04404": {"publish_time": "2022-05-09", "title": "TeamX@DravidianLangTech-ACL2022: A Comparative Analysis for Troll-Based Meme Classification", "author": "Rabindra Nath Nandi et.al.", "abstract": "The spread of fake news, propaganda, misinformation, disinformation, and harmful content online raised concerns among social media platforms, government agencies, policymakers, and society as a whole. This is because such harmful or abusive content leads to several consequences to people such as physical, emotional, relational, and financial. Among different harmful content \\textit{trolling-based} online content is one of them, where the idea is to post a message that is provocative, offensive, or menacing with an intent to mislead the audience. The content can be textual, visual, a combination of both, or a meme. In this study, we provide a comparative analysis of troll-based memes classification using the textual, visual, and multimodal content. We report several interesting findings in terms of code-mixed text, multimodal setting, and combining an additional dataset, which shows improvements over the majority baseline.", "paper_url": "http://arxiv.org/abs/2205.04404v1", "pdf_url": "http://arxiv.org/pdf/2205.04404v1", "repo_url": null}, "2205.05076": {"publish_time": "2022-05-10", "title": "Reduce Information Loss in Transformers for Pluralistic Image Inpainting", "author": "Qiankun Liu et.al.", "abstract": "Transformers have achieved great success in pluralistic image inpainting recently. However, we find existing transformer based solutions regard each pixel as a token, thus suffer from information loss issue from two aspects: 1) They downsample the input image into much lower resolutions for efficiency consideration, incurring information loss and extra misalignment for the boundaries of masked regions. 2) They quantize $256^3$ RGB pixels to a small number (such as 512) of quantized pixels. The indices of quantized pixels are used as tokens for the inputs and prediction targets of transformer. Although an extra CNN network is used to upsample and refine the low-resolution results, it is difficult to retrieve the lost information back.To keep input information as much as possible, we propose a new transformer based framework \"PUT\". Specifically, to avoid input downsampling while maintaining the computation efficiency, we design a patch-based auto-encoder P-VQVAE, where the encoder converts the masked image into non-overlapped patch tokens and the decoder recovers the masked regions from inpainted tokens while keeping the unmasked regions unchanged. To eliminate the information loss caused by quantization, an Un-Quantized Transformer (UQ-Transformer) is applied, which directly takes the features from P-VQVAE encoder as input without quantization and regards the quantized tokens only as prediction targets. Extensive experiments show that PUT greatly outperforms state-of-the-art methods on image fidelity, especially for large masked regions and complex large-scale datasets.", "paper_url": "http://arxiv.org/abs/2205.05076v1", "pdf_url": "http://arxiv.org/pdf/2205.05076v1", "repo_url": null}, "2205.05072": {"publish_time": "2022-05-10", "title": "Learning Visual Styles from Audio-Visual Associations", "author": "Tingle Li et.al.", "abstract": "From the patter of rain to the crunch of snow, the sounds we hear often convey the visual textures that appear within a scene. In this paper, we present a method for learning visual styles from unlabeled audio-visual data. Our model learns to manipulate the texture of a scene to match a sound, a problem we term audio-driven image stylization. Given a dataset of paired audio-visual data, we learn to modify input images such that, after manipulation, they are more likely to co-occur with a given input sound. In quantitative and qualitative evaluations, our sound-based model outperforms label-based approaches. We also show that audio can be an intuitive representation for manipulating images, as adjusting a sound's volume or mixing two sounds together results in predictable changes to visual style. Project webpage: https://tinglok.netlify.app/files/avstyle", "paper_url": "http://arxiv.org/abs/2205.05072v1", "pdf_url": "http://arxiv.org/pdf/2205.05072v1", "repo_url": null}, "2205.05069": {"publish_time": "2022-05-10", "title": "Accelerating the Training of Video Super-Resolution", "author": "Lijian Lin et.al.", "abstract": "Despite that convolution neural networks (CNN) have recently demonstrated high-quality reconstruction for video super-resolution (VSR), efficiently training competitive VSR models remains a challenging problem. It usually takes an order of magnitude more time than training their counterpart image models, leading to long research cycles. Existing VSR methods typically train models with fixed spatial and temporal sizes from beginning to end. The fixed sizes are usually set to large values for good performance, resulting to slow training. However, is such a rigid training strategy necessary for VSR? In this work, we show that it is possible to gradually train video models from small to large spatial/temporal sizes, i.e., in an easy-to-hard manner. In particular, the whole training is divided into several stages and the earlier stage has smaller training spatial shape. Inside each stage, the temporal size also varies from short to long while the spatial size remains unchanged. Training is accelerated by such a multigrid training strategy, as most of computation is performed on smaller spatial and shorter temporal shapes. For further acceleration with GPU parallelization, we also investigate the large minibatch training without the loss in accuracy. Extensive experiments demonstrate that our method is capable of largely speeding up training (up to $6.2\\times$ speedup in wall-clock training time) without performance drop for various VSR models. The code is available at https://github.com/TencentARC/Efficient-VSR-Training.", "paper_url": "http://arxiv.org/abs/2205.05069v1", "pdf_url": "http://arxiv.org/pdf/2205.05069v1", "repo_url": null}, "2205.05065": {"publish_time": "2022-05-10", "title": "Metric Learning based Interactive Modulation for Real-World Super-Resolution", "author": "Chong Mou et.al.", "abstract": "Interactive image restoration aims to restore images by adjusting several controlling coefficients, which determine the restoration strength. Existing methods are restricted in learning the controllable functions under the supervision of known degradation types and levels. They usually suffer from a severe performance drop when the real degradation is different from their assumptions. Such a limitation is due to the complexity of real-world degradations, which can not provide explicit supervision to the interactive modulation during training. However, how to realize the interactive modulation in real-world super-resolution has not yet been studied. In this work, we present a Metric Learning based Interactive Modulation for Real-World Super-Resolution (MM-RealSR). Specifically, we propose an unsupervised degradation estimation strategy to estimate the degradation level in real-world scenarios. Instead of using known degradation levels as explicit supervision to the interactive mechanism, we propose a metric learning strategy to map the unquantifiable degradation levels in real-world scenarios to a metric space, which is trained in an unsupervised manner. Moreover, we introduce an anchor point strategy in the metric learning process to normalize the distribution of metric space. Extensive experiments demonstrate that the proposed MM-RealSR achieves excellent modulation and restoration performance in real-world super-resolution. Codes are available at https://github.com/TencentARC/MM-RealSR.", "paper_url": "http://arxiv.org/abs/2205.05065v1", "pdf_url": "http://arxiv.org/pdf/2205.05065v1", "repo_url": null}, "2205.05019": {"publish_time": "2022-05-10", "title": "Learning to Answer Visual Questions from Web Videos", "author": "Antoine Yang et.al.", "abstract": "Recent methods for visual question answering rely on large-scale annotated datasets. Manual annotation of questions and answers for videos, however, is tedious, expensive and prevents scalability. In this work, we propose to avoid manual annotation and generate a large-scale training dataset for video question answering making use of automatic cross-modal supervision. We leverage a question generation transformer trained on text data and use it to generate question-answer pairs from transcribed video narrations. Given narrated videos, we then automatically generate the HowToVQA69M dataset with 69M video-question-answer triplets. To handle the open vocabulary of diverse answers in this dataset, we propose a training procedure based on a contrastive loss between a video-question multi-modal transformer and an answer transformer. We introduce the zero-shot VideoQA task and the VideoQA feature probe evaluation setting and show excellent results, in particular for rare answers. Furthermore, our method achieves competitive results on MSRVTT-QA, ActivityNet-QA, MSVD-QA and How2QA datasets. We also show that our VideoQA dataset generation approach generalizes to another source of web video and text data. We use our method to generate the \\webdataname{} dataset from the WebVid dataset, i.e., videos with alt-text annotations, and show its benefits for training VideoQA models. Finally, for a detailed evaluation we introduce \\smalldatasetname{}, a new VideoQA dataset with reduced language bias and high-quality manual annotations. Code, datasets and trained models are available at https://antoyang.github.io/just-ask.html", "paper_url": "http://arxiv.org/abs/2205.05019v1", "pdf_url": "http://arxiv.org/pdf/2205.05019v1", "repo_url": "https://github.com/antoyang/just-ask"}, "2205.05678": {"publish_time": "2022-05-11", "title": "RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation", "author": "Pingchuan Ma et.al.", "abstract": "This work considers identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible. Existing solutions require massive training data or lack generalizability to unknown rendering configurations. We propose a novel approach that marries domain randomization and differentiable rendering gradients to address this problem. Our core idea is to train a rendering-invariant state-prediction (RISP) network that transforms image differences into state differences independent of rendering configurations, e.g., lighting, shadows, or material reflectance. To train this predictor, we formulate a new loss on rendering variances using gradients from differentiable rendering. Moreover, we present an efficient, second-order method to compute the gradients of this loss, allowing it to be integrated seamlessly into modern deep learning frameworks. We evaluate our method in rigid-body and deformable-body simulation environments using four tasks: state estimation, system identification, imitation learning, and visuomotor control. We further demonstrate the efficacy of our approach on a real-world example: inferring the state and action sequences of a quadrotor from a video of its motion sequences. Compared with existing methods, our approach achieves significantly lower reconstruction errors and has better generalizability among unknown rendering configurations.", "paper_url": "http://arxiv.org/abs/2205.05678v1", "pdf_url": "http://arxiv.org/pdf/2205.05678v1", "repo_url": null}, "2205.05677": {"publish_time": "2022-05-11", "title": "HULC: 3D Human Motion Capture with Pose Manifold Sampling and Dense Contact Guidance", "author": "Soshi Shimada et.al.", "abstract": "Marker-less monocular 3D human motion capture (MoCap) with scene interactions is a challenging research topic relevant for extended reality, robotics and virtual avatar generation. Due to the inherent depth ambiguity of monocular settings, 3D motions captured with existing methods often contain severe artefacts such as incorrect body-scene inter-penetrations, jitter and body floating. To tackle these issues, we propose HULC, a new approach for 3D human MoCap which is aware of the scene geometry. HULC estimates 3D poses and dense body-environment surface contacts for improved 3D localisations, as well as the absolute scale of the subject. Furthermore, we introduce a 3D pose trajectory optimisation based on a novel pose manifold sampling that resolves erroneous body-environment inter-penetrations. Although the proposed method requires less structured inputs compared to existing scene-aware monocular MoCap algorithms, it produces more physically-plausible poses: HULC significantly and consistently outperforms the existing approaches in various experiments and on different metrics.", "paper_url": "http://arxiv.org/abs/2205.05677v1", "pdf_url": "http://arxiv.org/pdf/2205.05677v1", "repo_url": null}, "2205.05676": {"publish_time": "2022-05-11", "title": "Revisiting Random Channel Pruning for Neural Network Compression", "author": "Yawei Li et.al.", "abstract": "Channel (or 3D filter) pruning serves as an effective way to accelerate the inference of neural networks. There has been a flurry of algorithms that try to solve this practical problem, each being claimed effective in some ways. Yet, a benchmark to compare those algorithms directly is lacking, mainly due to the complexity of the algorithms and some custom settings such as the particular network configuration or training procedure. A fair benchmark is important for the further development of channel pruning.   Meanwhile, recent investigations reveal that the channel configurations discovered by pruning algorithms are at least as important as the pre-trained weights. This gives channel pruning a new role, namely searching the optimal channel configuration. In this paper, we try to determine the channel configuration of the pruned models by random search. The proposed approach provides a new way to compare different methods, namely how well they behave compared with random pruning. We show that this simple strategy works quite well compared with other channel pruning methods. We also show that under this setting, there are surprisingly no clear winners among different channel importance evaluation methods, which then may tilt the research efforts into advanced channel configuration searching methods.", "paper_url": "http://arxiv.org/abs/2205.05676v1", "pdf_url": "http://arxiv.org/pdf/2205.05676v1", "repo_url": null}, "2205.05675": {"publish_time": "2022-05-11", "title": "NTIRE 2022 Challenge on Efficient Super-Resolution: Methods and Results", "author": "Yawei Li et.al.", "abstract": "This paper reviews the NTIRE 2022 challenge on efficient single image super-resolution with focus on the proposed solutions and results. The task of the challenge was to super-resolve an input image with a magnification factor of $\\times$4 based on pairs of low and corresponding high resolution images. The aim was to design a network for single image super-resolution that achieved improvement of efficiency measured according to several metrics including runtime, parameters, FLOPs, activations, and memory consumption while at least maintaining the PSNR of 29.00dB on DIV2K validation set. IMDN is set as the baseline for efficiency measurement. The challenge had 3 tracks including the main track (runtime), sub-track one (model complexity), and sub-track two (overall performance). In the main track, the practical runtime performance of the submissions was evaluated. The rank of the teams were determined directly by the absolute value of the average runtime on the validation set and test set. In sub-track one, the number of parameters and FLOPs were considered. And the individual rankings of the two metrics were summed up to determine a final ranking in this track. In sub-track two, all of the five metrics mentioned in the description of the challenge including runtime, parameter count, FLOPs, activations, and memory consumption were considered. Similar to sub-track one, the rankings of five metrics were summed up to determine a final ranking. The challenge had 303 registered participants, and 43 teams made valid submissions. They gauge the state-of-the-art in efficient single image super-resolution.", "paper_url": "http://arxiv.org/abs/2205.05675v1", "pdf_url": "http://arxiv.org/pdf/2205.05675v1", "repo_url": null}, "2205.05671": {"publish_time": "2022-05-11", "title": "RepSR: Training Efficient VGG-style Super-Resolution Networks with Structural Re-Parameterization and Batch Normalization", "author": "Xintao Wang et.al.", "abstract": "This paper explores training efficient VGG-style super-resolution (SR) networks with the structural re-parameterization technique. The general pipeline of re-parameterization is to train networks with multi-branch topology first, and then merge them into standard 3x3 convolutions for efficient inference. In this work, we revisit those primary designs and investigate essential components for re-parameterizing SR networks. First of all, we find that batch normalization (BN) is important to bring training non-linearity and improve the final performance. However, BN is typically ignored in SR, as it usually degrades the performance and introduces unpleasant artifacts. We carefully analyze the cause of BN issue and then propose a straightforward yet effective solution. In particular, we first train SR networks with mini-batch statistics as usual, and then switch to using population statistics at the later training period. While we have successfully re-introduced BN into SR, we further design a new re-parameterizable block tailored for SR, namely RepSR. It consists of a clean residual path and two expand-and-squeeze convolution paths with the modified BN. Extensive experiments demonstrate that our simple RepSR is capable of achieving superior performance to previous SR re-parameterization methods among different model sizes. In addition, our RepSR can achieve a better trade-off between performance and actual running time (throughput) than previous SR methods. Codes will be available at https://github.com/TencentARC/RepSR.", "paper_url": "http://arxiv.org/abs/2205.05671v1", "pdf_url": "http://arxiv.org/pdf/2205.05671v1", "repo_url": null}, "2205.06267": {"publish_time": "2022-05-12", "title": "Topologically-Aware Deformation Fields for Single-View 3D Reconstruction", "author": "Shivam Duggal et.al.", "abstract": "We present a new framework for learning 3D object shapes and dense cross-object 3D correspondences from just an unaligned category-specific image collection. The 3D shapes are generated implicitly as deformations to a category-specific signed distance field and are learned in an unsupervised manner solely from unaligned image collections without any 3D supervision. Generally, image collections on the internet contain several intra-category geometric and topological variations, for example, different chairs can have different topologies, which makes the task of joint shape and correspondence estimation much more challenging. Because of this, prior works either focus on learning each 3D object shape individually without modeling cross-instance correspondences or perform joint shape and correspondence estimation on categories with minimal intra-category topological variations. We overcome these restrictions by learning a topologically-aware implicit deformation field that maps a 3D point in the object space to a higher dimensional point in the category-specific canonical space. At inference time, given a single image, we reconstruct the underlying 3D shape by first implicitly deforming each 3D point in the object space to the learned category-specific canonical space using the topologically-aware deformation field and then reconstructing the 3D shape as a canonical signed distance field. Both canonical shape and deformation field are learned end-to-end in an inverse-graphics fashion using a learned recurrent ray marcher (SRN) as a differentiable rendering module. Our approach, dubbed TARS, achieves state-of-the-art reconstruction fidelity on several datasets: ShapeNet, Pascal3D+, CUB, and Pix3D chairs. Result videos and code at https://shivamduggal4.github.io/tars-3D/", "paper_url": "http://arxiv.org/abs/2205.06267v1", "pdf_url": "http://arxiv.org/pdf/2205.06267v1", "repo_url": null}, "2205.06265": {"publish_time": "2022-05-12", "title": "ELODI: Ensemble Logit Difference Inhibition for Positive-Congruent Training", "author": "Yue Zhao et.al.", "abstract": "Negative flips are errors introduced in a classification system when a legacy model is replaced with a new one. Existing methods to reduce the negative flip rate (NFR) either do so at the expense of overall accuracy using model distillation, or use ensembles, which multiply inference cost prohibitively. We present a method to train a classification system that achieves paragon performance in both error rate and NFR, at the inference cost of a single model. Our method introduces a generalized distillation objective, Logit Difference Inhibition (LDI), that penalizes changes in the logits between the new and old model, without forcing them to coincide as in ordinary distillation. LDI affords the model flexibility to reduce error rate along with NFR. The method uses a homogeneous ensemble as the reference model for LDI, hence the name Ensemble LDI, or ELODI. The reference model can then be substituted with a single model at inference time. The method leverages the observation that negative flips are typically not close to the decision boundary, but often exhibit large deviations in the distance among their logits, which are reduced by ELODI.", "paper_url": "http://arxiv.org/abs/2205.06265v1", "pdf_url": "http://arxiv.org/pdf/2205.06265v1", "repo_url": null}, "2205.06255": {"publish_time": "2022-05-12", "title": "3D Moments from Near-Duplicate Photos", "author": "Qianqian Wang et.al.", "abstract": "We introduce 3D Moments, a new computational photography effect. As input we take a pair of near-duplicate photos, i.e., photos of moving subjects from similar viewpoints, common in people's photo collections. As output, we produce a video that smoothly interpolates the scene motion from the first photo to the second, while also producing camera motion with parallax that gives a heightened sense of 3D. To achieve this effect, we represent the scene as a pair of feature-based layered depth images augmented with scene flow. This representation enables motion interpolation along with independent control of the camera viewpoint. Our system produces photorealistic space-time videos with motion parallax and scene dynamics, while plausibly recovering regions occluded in the original views. We conduct extensive experiments demonstrating superior performance over baselines on public datasets and in-the-wild photos. Project page: https://3d-moments.github.io/", "paper_url": "http://arxiv.org/abs/2205.06255v1", "pdf_url": "http://arxiv.org/pdf/2205.06255v1", "repo_url": null}, "2205.06254": {"publish_time": "2022-05-12", "title": "Learned Vertex Descent: A New Direction for 3D Human Model Fitting", "author": "Enric Corona et.al.", "abstract": "We propose a novel optimization-based paradigm for 3D human model fitting on images and scans. In contrast to existing approaches that directly regress the parameters of a low-dimensional statistical body model (e.g. SMPL) from input images, we train an ensemble of per-vertex neural fields network. The network predicts, in a distributed manner, the vertex descent direction towards the ground truth, based on neural features extracted at the current vertex projection. At inference, we employ this network, dubbed LVD, within a gradient-descent optimization pipeline until its convergence, which typically occurs in a fraction of a second even when initializing all vertices into a single point. An exhaustive evaluation demonstrates that our approach is able to capture the underlying body of clothed people with very different body shapes, achieving a significant improvement compared to state-of-the-art. LVD is also applicable to 3D model fitting of humans and hands, for which we show a significant improvement to the SOTA with a much simpler and faster method.", "paper_url": "http://arxiv.org/abs/2205.06254v1", "pdf_url": "http://arxiv.org/pdf/2205.06254v1", "repo_url": null}, "2205.06253": {"publish_time": "2022-05-12", "title": "What's in a Caption? Dataset-Specific Linguistic Diversity and Its Effect on Visual Description Models and Metrics", "author": "David M. Chan et.al.", "abstract": "While there have been significant gains in the field of automated video description, the generalization performance of automated description models to novel domains remains a major barrier to using these systems in the real world. Most visual description methods are known to capture and exploit patterns in the training data leading to evaluation metric increases, but what are those patterns? In this work, we examine several popular visual description datasets, and capture, analyze, and understand the dataset-specific linguistic patterns that models exploit but do not generalize to new domains. At the token level, sample level, and dataset level, we find that caption diversity is a major driving factor behind the generation of generic and uninformative captions. We further show that state-of-the-art models even outperform held-out ground truth captions on modern metrics, and that this effect is an artifact of linguistic diversity in datasets. Understanding this linguistic diversity is key to building strong captioning models, we recommend several methods and approaches for maintaining diversity in the collection of new data, and dealing with the consequences of limited diversity when using current models and metrics.", "paper_url": "http://arxiv.org/abs/2205.06253v1", "pdf_url": "http://arxiv.org/pdf/2205.06253v1", "repo_url": "https://github.com/cannylab/vdtk"}, "2205.06803": {"publish_time": "2022-05-13", "title": "VQFR: Blind Face Restoration with Vector-Quantized Dictionary and Parallel Decoder", "author": "Yuchao Gu et.al.", "abstract": "Although generative facial prior and geometric prior have recently demonstrated high-quality results for blind face restoration, producing fine-grained facial details faithful to inputs remains a challenging problem. Motivated by the classical dictionary-based methods and the recent vector quantization (VQ) technique, we propose a VQ-based face restoration method -- VQFR. VQFR takes advantage of high-quality low-level feature banks extracted from high-quality faces and can thus help recover realistic facial details. However, the simple application of the VQ codebook cannot achieve good results with faithful details and identity preservation. Therefore, we further introduce two special network designs. 1). We first investigate the compression patch size in the VQ codebook and find that the VQ codebook designed with a proper compression patch size is crucial to balance the quality and fidelity. 2). To further fuse low-level features from inputs while not \"contaminating\" the realistic details generated from the VQ codebook, we proposed a parallel decoder consisting of a texture decoder and a main decoder. Those two decoders then interact with a texture warping module with deformable convolution. Equipped with the VQ codebook as a facial detail dictionary and the parallel decoder design, the proposed VQFR can largely enhance the restored quality of facial details while keeping the fidelity to previous methods. Codes will be available at https://github.com/TencentARC/VQFR.", "paper_url": "http://arxiv.org/abs/2205.06803v1", "pdf_url": "http://arxiv.org/pdf/2205.06803v1", "repo_url": null}, "2205.06784": {"publish_time": "2022-05-13", "title": "KG-SP: Knowledge Guided Simple Primitives for Open World Compositional Zero-Shot Learning", "author": "Shyamgopal Karthik et.al.", "abstract": "The goal of open-world compositional zero-shot learning (OW-CZSL) is to recognize compositions of state and objects in images, given only a subset of them during training and no prior on the unseen compositions. In this setting, models operate on a huge output space, containing all possible state-object compositions. While previous works tackle the problem by learning embeddings for the compositions jointly, here we revisit a simple CZSL baseline and predict the primitives, i.e. states and objects, independently. To ensure that the model develops primitive-specific features, we equip the state and object classifiers with separate, non-linear feature extractors. Moreover, we estimate the feasibility of each composition through external knowledge, using this prior to remove unfeasible compositions from the output space. Finally, we propose a new setting, i.e. CZSL under partial supervision (pCZSL), where either only objects or state labels are available during training, and we can use our prior to estimate the missing labels. Our model, Knowledge-Guided Simple Primitives (KG-SP), achieves state of the art in both OW-CZSL and pCZSL, surpassing most recent competitors even when coupled with semi-supervised learning techniques. Code available at: https://github.com/ExplainableML/KG-SP.", "paper_url": "http://arxiv.org/abs/2205.06784v1", "pdf_url": "http://arxiv.org/pdf/2205.06784v1", "repo_url": "https://github.com/explainableml/kg-sp"}, "2205.06779": {"publish_time": "2022-05-13", "title": "Scribble2D5: Weakly-Supervised Volumetric Image Segmentation via Scribble Annotations", "author": "Qiuhui Chen et.al.", "abstract": "Recently, weakly-supervised image segmentation using weak annotations like scribbles has gained great attention, since such annotations are much easier to obtain compared to time-consuming and label-intensive labeling at the pixel/voxel level. However, because scribbles lack structure information of region of interest (ROI), existing scribble-based methods suffer from poor boundary localization. Furthermore, most current methods are designed for 2D image segmentation, which do not fully leverage the volumetric information if directly applied to image slices. In this paper, we propose a scribble-based volumetric image segmentation, Scribble2D5, which tackles 3D anisotropic image segmentation and improves boundary prediction. To achieve this, we augment a 2.5D attention UNet with a proposed label propagation module to extend semantic information from scribbles and a combination of static and active boundary prediction to learn ROI's boundary and regularize its shape. Extensive experiments on three public datasets demonstrate Scribble2D5 significantly outperforms current scribble-based methods and approaches the performance of fully-supervised ones. Our code is available online.", "paper_url": "http://arxiv.org/abs/2205.06779v1", "pdf_url": "http://arxiv.org/pdf/2205.06779v1", "repo_url": null}, "2205.06754": {"publish_time": "2022-05-13", "title": "Slimmable Video Codec", "author": "Zhaocheng Liu et.al.", "abstract": "Neural video compression has emerged as a novel paradigm combining trainable multilayer neural networks and machine learning, achieving competitive rate-distortion (RD) performances, but still remaining impractical due to heavy neural architectures, with large memory and computational demands. In addition, models are usually optimized for a single RD tradeoff. Recent slimmable image codecs can dynamically adjust their model capacity to gracefully reduce the memory and computation requirements, without harming RD performance. In this paper we propose a slimmable video codec (SlimVC), by integrating a slimmable temporal entropy model in a slimmable autoencoder. Despite a significantly more complex architecture, we show that slimming remains a powerful mechanism to control rate, memory footprint, computational cost and latency, all being important requirements for practical video compression.", "paper_url": "http://arxiv.org/abs/2205.06754v1", "pdf_url": "http://arxiv.org/pdf/2205.06754v1", "repo_url": null}, "2205.06740": {"publish_time": "2022-05-13", "title": "An empirical study of CTC based models for OCR of Indian languages", "author": "Minesh Mathew et.al.", "abstract": "Recognition of text on word or line images, without the need for sub-word segmentation has become the mainstream of research and development of text recognition for Indian languages. Modelling unsegmented sequences using Connectionist Temporal Classification (CTC) is the most commonly used approach for segmentation-free OCR. In this work we present a comprehensive empirical study of various neural network models that uses CTC for transcribing step-wise predictions in the neural network output to a Unicode sequence. The study is conducted for 13 Indian languages, using an internal dataset that has around 1000 pages per language. We study the choice of line vs word as the recognition unit, and use of synthetic data to train the models. We compare our models with popular publicly available OCR tools for end-to-end document image recognition. Our end-to-end pipeline that employ our recognition models and existing text segmentation tools outperform these public OCR tools for 8 out of the 13 languages. We also introduce a new public dataset called Mozhi for word and line recognition in Indian language. The dataset contains more than 1.2 million annotated word images (120 thousand text lines) across 13 Indian languages. Our code, trained models and the Mozhi dataset will be made available at http://cvit.iiit.ac.in/research/projects/cvit-projects/", "paper_url": "http://arxiv.org/abs/2205.06740v1", "pdf_url": "http://arxiv.org/pdf/2205.06740v1", "repo_url": null}, "2205.07844": {"publish_time": "2022-05-16", "title": "Guess What Moves: Unsupervised Video and Image Segmentation by Anticipating Motion", "author": "Subhabrata Choudhury et.al.", "abstract": "Motion, measured via optical flow, provides a powerful cue to discover and learn objects in images and videos. However, compared to using appearance, it has some blind spots, such as the fact that objects become invisible if they do not move. In this work, we propose an approach that combines the strengths of motion-based and appearance-based segmentation. We propose to supervise an image segmentation network, tasking it with predicting regions that are likely to contain simple motion patterns, and thus likely to correspond to objects. We apply this network in two modes. In the unsupervised video segmentation mode, the network is trained on a collection of unlabelled videos, using the learning process itself as an algorithm to segment these videos. In the unsupervised image segmentation model, the network is learned using videos and applied to segment independent still images. With this, we obtain strong empirical results in unsupervised video and image segmentation, significantly outperforming the state of the art on benchmarks such as DAVIS, sometimes with a $5\\%$ IoU gap.", "paper_url": "http://arxiv.org/abs/2205.07844v1", "pdf_url": "http://arxiv.org/pdf/2205.07844v1", "repo_url": null}, "2205.07839": {"publish_time": "2022-05-16", "title": "Deep Spectral Methods: A Surprisingly Strong Baseline for Unsupervised Semantic Segmentation and Localization", "author": "Luke Melas-Kyriazi et.al.", "abstract": "Unsupervised localization and segmentation are long-standing computer vision challenges that involve decomposing an image into semantically-meaningful segments without any labeled data. These tasks are particularly interesting in an unsupervised setting due to the difficulty and cost of obtaining dense image annotations, but existing unsupervised approaches struggle with complex scenes containing multiple objects. Differently from existing methods, which are purely based on deep learning, we take inspiration from traditional spectral segmentation methods by reframing image decomposition as a graph partitioning problem. Specifically, we examine the eigenvectors of the Laplacian of a feature affinity matrix from self-supervised networks. We find that these eigenvectors already decompose an image into meaningful segments, and can be readily used to localize objects in a scene. Furthermore, by clustering the features associated with these segments across a dataset, we can obtain well-delineated, nameable regions, i.e. semantic segmentations. Experiments on complex datasets (Pascal VOC, MS-COCO) demonstrate that our simple spectral method outperforms the state-of-the-art in unsupervised localization and segmentation by a significant margin. Furthermore, our method can be readily used for a variety of complex image editing tasks, such as background removal and compositing.", "paper_url": "http://arxiv.org/abs/2205.07839v1", "pdf_url": "http://arxiv.org/pdf/2205.07839v1", "repo_url": null}, "2205.07763": {"publish_time": "2022-05-16", "title": "FvOR: Robust Joint Shape and Pose Optimization for Few-view Object Reconstruction", "author": "Zhenpei Yang et.al.", "abstract": "Reconstructing an accurate 3D object model from a few image observations remains a challenging problem in computer vision. State-of-the-art approaches typically assume accurate camera poses as input, which could be difficult to obtain in realistic settings. In this paper, we present FvOR, a learning-based object reconstruction method that predicts accurate 3D models given a few images with noisy input poses. The core of our approach is a fast and robust multi-view reconstruction algorithm to jointly refine 3D geometry and camera pose estimation using learnable neural network modules. We provide a thorough benchmark of state-of-the-art approaches for this problem on ShapeNet. Our approach achieves best-in-class results. It is also two orders of magnitude faster than the recent optimization-based approach IDR. Our code is released at \\url{https://github.com/zhenpeiyang/FvOR/}", "paper_url": "http://arxiv.org/abs/2205.07763v1", "pdf_url": "http://arxiv.org/pdf/2205.07763v1", "repo_url": null}, "2205.07752": {"publish_time": "2022-05-16", "title": "A Data Cube of Big Satellite Image Time-Series for Agriculture Monitoring", "author": "Thanassis Drivas et.al.", "abstract": "The modernization of the Common Agricultural Policy (CAP) requires the large scale and frequent monitoring of agricultural land. Towards this direction, the free and open satellite data (i.e., Sentinel missions) have been extensively used as the sources for the required high spatial and temporal resolution Earth observations. Nevertheless, monitoring the CAP at large scales constitutes a big data problem and puts a strain on CAP paying agencies that need to adapt fast in terms of infrastructure and know-how. Hence, there is a need for efficient and easy-to-use tools for the acquisition, storage, processing and exploitation of big satellite data. In this work, we present the Agriculture monitoring Data Cube (ADC), which is an automated, modular, end-to-end framework for discovering, pre-processing and indexing optical and Synthetic Aperture Radar (SAR) images into a multidimensional cube. We also offer a set of powerful tools on top of the ADC, including i) the generation of analysis-ready feature spaces of big satellite data to feed downstream machine learning tasks and ii) the support of Satellite Image Time-Series (SITS) analysis via services pertinent to the monitoring of the CAP (e.g., detecting trends and events, monitoring the growth status etc.). The knowledge extracted from the SITS analyses and the machine learning tasks returns to the data cube, building scalable country-specific knowledge bases that can efficiently answer complex and multi-faceted geospatial queries.", "paper_url": "http://arxiv.org/abs/2205.07752v1", "pdf_url": "http://arxiv.org/pdf/2205.07752v1", "repo_url": null}, "2205.07723": {"publish_time": "2022-05-16", "title": "Pest presence prediction using interpretable machine learning", "author": "Ornela Nanushi et.al.", "abstract": "Helicoverpa Armigera, or cotton bollworm, is a serious insect pest of cotton crops that threatens the yield and the quality of lint. The timely knowledge of the presence of the insects in the field is crucial for effective farm interventions. Meteo-climatic and vegetation conditions have been identified as key drivers of crop pest abundance. In this work, we applied an interpretable classifier, i.e., Explainable Boosting Machine, which uses earth observation vegetation indices, numerical weather predictions and insect trap catches to predict the onset of bollworm harmfulness in cotton fields in Greece. The glass-box nature of our approach provides significant insight on the main drivers of the model and the interactions among them. Model interpretability adds to the trustworthiness of our approach and therefore its potential for rapid uptake and context-based implementation in operational farm management scenarios. Our results are satisfactory and the importance of drivers, through our analysis on global and local explainability, is in accordance with the literature.", "paper_url": "http://arxiv.org/abs/2205.07723v1", "pdf_url": "http://arxiv.org/pdf/2205.07723v1", "repo_url": null}, "2205.08536": {"publish_time": "2022-05-17", "title": "Disentangling Visual Embeddings for Attributes and Objects", "author": "Nirat Saini et.al.", "abstract": "We study the problem of compositional zero-shot learning for object-attribute recognition. Prior works use visual features extracted with a backbone network, pre-trained for object classification and thus do not capture the subtly distinct features associated with attributes. To overcome this challenge, these studies employ supervision from the linguistic space, and use pre-trained word embeddings to better separate and compose attribute-object pairs for recognition. Analogous to linguistic embedding space, which already has unique and agnostic embeddings for object and attribute, we shift the focus back to the visual space and propose a novel architecture that can disentangle attribute and object features in the visual space. We use visual decomposed features to hallucinate embeddings that are representative for the seen and novel compositions to better regularize the learning of our model. Extensive experiments show that our method outperforms existing work with significant margin on three datasets: MIT-States, UT-Zappos, and a new benchmark created based on VAW. The code, models, and dataset splits are publicly available at https://github.com/nirat1606/OADis.", "paper_url": "http://arxiv.org/abs/2205.08536v1", "pdf_url": "http://arxiv.org/pdf/2205.08536v1", "repo_url": "https://github.com/nirat1606/oadis"}, "2205.08535": {"publish_time": "2022-05-17", "title": "AvatarCLIP: Zero-Shot Text-Driven Generation and Animation of 3D Avatars", "author": "Fangzhou Hong et.al.", "abstract": "3D avatar creation plays a crucial role in the digital age. However, the whole production process is prohibitively time-consuming and labor-intensive. To democratize this technology to a larger audience, we propose AvatarCLIP, a zero-shot text-driven framework for 3D avatar generation and animation. Unlike professional software that requires expert knowledge, AvatarCLIP empowers layman users to customize a 3D avatar with the desired shape and texture, and drive the avatar with the described motions using solely natural languages. Our key insight is to take advantage of the powerful vision-language model CLIP for supervising neural human generation, in terms of 3D geometry, texture and animation. Specifically, driven by natural language descriptions, we initialize 3D human geometry generation with a shape VAE network. Based on the generated 3D human shapes, a volume rendering model is utilized to further facilitate geometry sculpting and texture generation. Moreover, by leveraging the priors learned in the motion VAE, a CLIP-guided reference-based motion synthesis method is proposed for the animation of the generated 3D avatar. Extensive qualitative and quantitative experiments validate the effectiveness and generalizability of AvatarCLIP on a wide range of avatars. Remarkably, AvatarCLIP can generate unseen 3D avatars with novel animations, achieving superior zero-shot capability.", "paper_url": "http://arxiv.org/abs/2205.08535v1", "pdf_url": "http://arxiv.org/pdf/2205.08535v1", "repo_url": "https://github.com/hongfz16/avatarclip"}, "2205.08534": {"publish_time": "2022-05-17", "title": "Vision Transformer Adapter for Dense Predictions", "author": "Zhe Chen et.al.", "abstract": "This work investigates a simple yet powerful adapter for Vision Transformer (ViT). Unlike recent visual transformers that introduce vision-specific inductive biases into their architectures, ViT achieves inferior performance on dense prediction tasks due to lacking prior information of images. To solve this issue, we propose a Vision Transformer Adapter (ViT-Adapter), which can remedy the defects of ViT and achieve comparable performance to vision-specific models by introducing inductive biases via an additional architecture. Specifically, the backbone in our framework is a vanilla transformer that can be pre-trained with multi-modal data. When fine-tuning on downstream tasks, a modality-specific adapter is used to introduce the data and tasks' prior information into the model, making it suitable for these tasks. We verify the effectiveness of our ViT-Adapter on multiple downstream tasks, including object detection, instance segmentation, and semantic segmentation. Notably, when using HTC++, our ViT-Adapter-L yields 60.1 box AP and 52.1 mask AP on COCO test-dev, surpassing Swin-L by 1.4 box AP and 1.0 mask AP. For semantic segmentation, our ViT-Adapter-L establishes a new state-of-the-art of 60.5 mIoU on ADE20K val, 0.6 points higher than SwinV2-G. We hope that the proposed ViT-Adapter could serve as an alternative for vision-specific transformers and facilitate future research.", "paper_url": "http://arxiv.org/abs/2205.08534v1", "pdf_url": "http://arxiv.org/pdf/2205.08534v1", "repo_url": "https://github.com/czczup/vit-adapter"}, "2205.08525": {"publish_time": "2022-05-17", "title": "Self-supervised Neural Articulated Shape and Appearance Models", "author": "Fangyin Wei et.al.", "abstract": "Learning geometry, motion, and appearance priors of object classes is important for the solution of a large variety of computer vision problems. While the majority of approaches has focused on static objects, dynamic objects, especially with controllable articulation, are less explored. We propose a novel approach for learning a representation of the geometry, appearance, and motion of a class of articulated objects given only a set of color images as input. In a self-supervised manner, our novel representation learns shape, appearance, and articulation codes that enable independent control of these semantic dimensions. Our model is trained end-to-end without requiring any articulation annotations. Experiments show that our approach performs well for different joint types, such as revolute and prismatic joints, as well as different combinations of these joints. Compared to state of the art that uses direct 3D supervision and does not output appearance, we recover more faithful geometry and appearance from 2D observations only. In addition, our representation enables a large variety of applications, such as few-shot reconstruction, the generation of novel articulations, and novel view-synthesis.", "paper_url": "http://arxiv.org/abs/2205.08525v1", "pdf_url": "http://arxiv.org/pdf/2205.08525v1", "repo_url": null}, "2205.08518": {"publish_time": "2022-05-17", "title": "Do Neural Networks Compress Manifolds Optimally?", "author": "Sourbh Bhadane et.al.", "abstract": "Artificial Neural-Network-based (ANN-based) lossy compressors have recently obtained striking results on several sources. Their success may be ascribed to an ability to identify the structure of low-dimensional manifolds in high-dimensional ambient spaces. Indeed, prior work has shown that ANN-based compressors can achieve the optimal entropy-distortion curve for some such sources. In contrast, we determine the optimal entropy-distortion tradeoffs for two low-dimensional manifolds with circular structure and show that state-of-the-art ANN-based compressors fail to optimally compress the sources, especially at high rates.", "paper_url": "http://arxiv.org/abs/2205.08518v1", "pdf_url": "http://arxiv.org/pdf/2205.08518v1", "repo_url": null}, "2205.09113": {"publish_time": "2022-05-18", "title": "Masked Autoencoders As Spatiotemporal Learners", "author": "Christoph Feichtenhofer et.al.", "abstract": "This paper studies a conceptually simple extension of Masked Autoencoders (MAE) to spatiotemporal representation learning from videos. We randomly mask out spacetime patches in videos and learn an autoencoder to reconstruct them in pixels. Interestingly, we show that our MAE method can learn strong representations with almost no inductive bias on spacetime (only except for patch and positional embeddings), and spacetime-agnostic random masking performs the best. We observe that the optimal masking ratio is as high as 90% (vs. 75% on images), supporting the hypothesis that this ratio is related to information redundancy of the data. A high masking ratio leads to a large speedup, e.g., > 4x in wall-clock time or even more. We report competitive results on several challenging video datasets using vanilla Vision Transformers. We observe that MAE can outperform supervised pre-training by large margins. We further report encouraging results of training on real-world, uncurated Instagram data. Our study suggests that the general framework of masked autoencoding (BERT, MAE, etc.) can be a unified methodology for representation learning with minimal domain knowledge.", "paper_url": "http://arxiv.org/abs/2205.09113v1", "pdf_url": "http://arxiv.org/pdf/2205.09113v1", "repo_url": null}, "2205.09111": {"publish_time": "2022-05-18", "title": "BodyMap: Learning Full-Body Dense Correspondence Map", "author": "Anastasia Ianina et.al.", "abstract": "Dense correspondence between humans carries powerful semantic information that can be utilized to solve fundamental problems for full-body understanding such as in-the-wild surface matching, tracking and reconstruction. In this paper we present BodyMap, a new framework for obtaining high-definition full-body and continuous dense correspondence between in-the-wild images of clothed humans and the surface of a 3D template model. The correspondences cover fine details such as hands and hair, while capturing regions far from the body surface, such as loose clothing. Prior methods for estimating such dense surface correspondence i) cut a 3D body into parts which are unwrapped to a 2D UV space, producing discontinuities along part seams, or ii) use a single surface for representing the whole body, but none handled body details. Here, we introduce a novel network architecture with Vision Transformers that learn fine-level features on a continuous body surface. BodyMap outperforms prior work on various metrics and datasets, including DensePose-COCO by a large margin. Furthermore, we show various applications ranging from multi-layer dense cloth correspondence, neural rendering with novel-view synthesis and appearance swapping.", "paper_url": "http://arxiv.org/abs/2205.09111v1", "pdf_url": "http://arxiv.org/pdf/2205.09111v1", "repo_url": null}, "2205.09086": {"publish_time": "2022-05-18", "title": "Pluralistic Image Completion with Probabilistic Mixture-of-Experts", "author": "Xiaobo Xia et.al.", "abstract": "Pluralistic image completion focuses on generating both visually realistic and diverse results for image completion. Prior methods enjoy the empirical successes of this task. However, their used constraints for pluralistic image completion are argued to be not well interpretable and unsatisfactory from two aspects. First, the constraints for visual reality can be weakly correlated to the objective of image completion or even redundant. Second, the constraints for diversity are designed to be task-agnostic, which causes the constraints to not work well. In this paper, to address the issues, we propose an end-to-end probabilistic method. Specifically, we introduce a unified probabilistic graph model that represents the complex interactions in image completion. The entire procedure of image completion is then mathematically divided into several sub-procedures, which helps efficient enforcement of constraints. The sub-procedure directly related to pluralistic results is identified, where the interaction is established by a Gaussian mixture model (GMM). The inherent parameters of GMM are task-related, which are optimized adaptively during training, while the number of its primitives can control the diversity of results conveniently. We formally establish the effectiveness of our method and demonstrate it with comprehensive experiments.", "paper_url": "http://arxiv.org/abs/2205.09086v1", "pdf_url": "http://arxiv.org/pdf/2205.09086v1", "repo_url": null}, "2205.09068": {"publish_time": "2022-05-18", "title": "VRAG: Region Attention Graphs for Content-Based Video Retrieval", "author": "Kennard Ng et.al.", "abstract": "Content-based Video Retrieval (CBVR) is used on media-sharing platforms for applications such as video recommendation and filtering. To manage databases that scale to billions of videos, video-level approaches that use fixed-size embeddings are preferred due to their efficiency. In this paper, we introduce Video Region Attention Graph Networks (VRAG) that improves the state-of-the-art of video-level methods. We represent videos at a finer granularity via region-level features and encode video spatio-temporal dynamics through region-level relations. Our VRAG captures the relationships between regions based on their semantic content via self-attention and the permutation invariant aggregation of Graph Convolution. In addition, we show that the performance gap between video-level and frame-level methods can be reduced by segmenting videos into shots and using shot embeddings for video retrieval. We evaluate our VRAG over several video retrieval tasks and achieve a new state-of-the-art for video-level retrieval. Furthermore, our shot-level VRAG shows higher retrieval precision than other existing video-level methods, and closer performance to frame-level methods at faster evaluation speeds. Finally, our code will be made publicly available.", "paper_url": "http://arxiv.org/abs/2205.09068v1", "pdf_url": "http://arxiv.org/pdf/2205.09068v1", "repo_url": null}, "2205.09048": {"publish_time": "2022-05-18", "title": "Global Contrast Masked Autoencoders Are Powerful Pathological Representation Learners", "author": "Hao Quan et.al.", "abstract": "Based on digital whole slide scanning technique, artificial intelligence algorithms represented by deep learning have achieved remarkable results in the field of computational pathology. Compared with other medical images such as Computed Tomography (CT) or Magnetic Resonance Imaging (MRI), pathological images are more difficult to annotate, thus there is an extreme lack of data sets that can be used for supervised learning. In this study, a self-supervised learning (SSL) model, Global Contrast Masked Autoencoders (GCMAE), is proposed, which has the ability to represent both global and local domain-specific features of whole slide image (WSI), as well as excellent cross-data transfer ability. The Camelyon16 and NCTCRC datasets are used to evaluate the performance of our model. When dealing with transfer learning tasks with different data sets, the experimental results show that GCMAE has better linear classification accuracy than MAE, which can reach 81.10% and 89.22% respectively. Our method outperforms the previous state-of-the-art algorithm and even surpass supervised learning (improved by 3.86% on NCTCRC data sets). The source code of this paper is publicly available at https://github.com/StarUniversus/gcmae", "paper_url": "http://arxiv.org/abs/2205.09048v1", "pdf_url": "http://arxiv.org/pdf/2205.09048v1", "repo_url": "https://github.com/staruniversus/gcmae"}, "2205.09747": {"publish_time": "2022-05-19", "title": "HandoverSim: A Simulation Framework and Benchmark for Human-to-Robot Object Handovers", "author": "Yu-Wei Chao et.al.", "abstract": "We introduce a new simulation benchmark \"HandoverSim\" for human-to-robot object handovers. To simulate the giver's motion, we leverage a recent motion capture dataset of hand grasping of objects. We create training and evaluation environments for the receiver with standardized protocols and metrics. We analyze the performance of a set of baselines and show a correlation with a real-world evaluation. Code is open sourced at https://handover-sim.github.io.", "paper_url": "http://arxiv.org/abs/2205.09747v1", "pdf_url": "http://arxiv.org/pdf/2205.09747v1", "repo_url": null}, "2205.09743": {"publish_time": "2022-05-19", "title": "BEVerse: Unified Perception and Prediction in Birds-Eye-View for Vision-Centric Autonomous Driving", "author": "Yunpeng Zhang et.al.", "abstract": "In this paper, we present BEVerse, a unified framework for 3D perception and prediction based on multi-camera systems. Unlike existing studies focusing on the improvement of single-task approaches, BEVerse features in producing spatio-temporal Birds-Eye-View (BEV) representations from multi-camera videos and jointly reasoning about multiple tasks for vision-centric autonomous driving. Specifically, BEVerse first performs shared feature extraction and lifting to generate 4D BEV representations from multi-timestamp and multi-view images. After the ego-motion alignment, the spatio-temporal encoder is utilized for further feature extraction in BEV. Finally, multiple task decoders are attached for joint reasoning and prediction. Within the decoders, we propose the grid sampler to generate BEV features with different ranges and granularities for different tasks. Also, we design the method of iterative flow for memory-efficient future prediction. We show that the temporal information improves 3D object detection and semantic map construction, while the multi-task learning can implicitly benefit motion prediction. With extensive experiments on the nuScenes dataset, we show that the multi-task BEVerse outperforms existing single-task methods on 3D object detection, semantic map construction, and motion prediction. Compared with the sequential paradigm, BEVerse also favors in significantly improved efficiency. The code and trained models will be released at https://github.com/zhangyp15/BEVerse.", "paper_url": "http://arxiv.org/abs/2205.09743v1", "pdf_url": "http://arxiv.org/pdf/2205.09743v1", "repo_url": "https://github.com/zhangyp15/beverse"}, "2205.09739": {"publish_time": "2022-05-19", "title": "Diverse Weight Averaging for Out-of-Distribution Generalization", "author": "Alexandre Rame et.al.", "abstract": "Standard neural networks struggle to generalize under distribution shifts. For out-of-distribution generalization in computer vision, the best current approach averages the weights along a training run. In this paper, we propose Diverse Weight Averaging (DiWA) that makes a simple change to this strategy: DiWA averages the weights obtained from several independent training runs rather than from a single run. Perhaps surprisingly, averaging these weights performs well under soft constraints despite the network's nonlinearities. The main motivation behind DiWA is to increase the functional diversity across averaged models. Indeed, models obtained from different runs are more diverse than those collected along a single run thanks to differences in hyperparameters and training procedures. We motivate the need for diversity by a new bias-variance-covariance-locality decomposition of the expected error, exploiting similarities between DiWA and standard functional ensembling. Moreover, this decomposition highlights that DiWA succeeds when the variance term dominates, which we show happens when the marginal distribution changes at test time. Experimentally, DiWA consistently improves the state of the art on the competitive DomainBed benchmark without inference overhead.", "paper_url": "http://arxiv.org/abs/2205.09739v1", "pdf_url": "http://arxiv.org/pdf/2205.09739v1", "repo_url": "https://github.com/alexrame/diwa"}, "2205.09731": {"publish_time": "2022-05-19", "title": "Towards Unified Keyframe Propagation Models", "author": "Patrick Esser et.al.", "abstract": "Many video editing tasks such as rotoscoping or object removal require the propagation of context across frames. While transformers and other attention-based approaches that aggregate features globally have demonstrated great success at propagating object masks from keyframes to the whole video, they struggle to propagate high-frequency details such as textures faithfully. We hypothesize that this is due to an inherent bias of global attention towards low-frequency features. To overcome this limitation, we present a two-stream approach, where high-frequency features interact locally and low-frequency features interact globally. The global interaction stream remains robust in difficult situations such as large camera motions, where explicit alignment fails. The local interaction stream propagates high-frequency details through deformable feature aggregation and, informed by the global interaction stream, learns to detect and correct errors of the deformation field. We evaluate our two-stream approach for inpainting tasks, where experiments show that it improves both the propagation of features within a single frame as required for image inpainting, as well as their propagation from keyframes to target frames. Applied to video inpainting, our approach leads to 44% and 26% improvements in FID and LPIPS scores. Code at https://github.com/runwayml/guided-inpainting", "paper_url": "http://arxiv.org/abs/2205.09731v1", "pdf_url": "http://arxiv.org/pdf/2205.09731v1", "repo_url": "https://github.com/runwayml/guided-inpainting"}, "2205.09723": {"publish_time": "2022-05-19", "title": "Robust and Efficient Medical Imaging with Self-Supervision", "author": "Shekoofeh Azizi et.al.", "abstract": "Recent progress in Medical Artificial Intelligence (AI) has delivered systems that can reach clinical expert level performance. However, such systems tend to demonstrate sub-optimal \"out-of-distribution\" performance when evaluated in clinical settings different from the training environment. A common mitigation strategy is to develop separate systems for each clinical setting using site-specific data [1]. However, this quickly becomes impractical as medical data is time-consuming to acquire and expensive to annotate [2]. Thus, the problem of \"data-efficient generalization\" presents an ongoing difficulty for Medical AI development. Although progress in representation learning shows promise, their benefits have not been rigorously studied, specifically for out-of-distribution settings. To meet these challenges, we present REMEDIS, a unified representation learning strategy to improve robustness and data-efficiency of medical imaging AI. REMEDIS uses a generic combination of large-scale supervised transfer learning with self-supervised learning and requires little task-specific customization. We study a diverse range of medical imaging tasks and simulate three realistic application scenarios using retrospective data. REMEDIS exhibits significantly improved in-distribution performance with up to 11.5% relative improvement in diagnostic accuracy over a strong supervised baseline. More importantly, our strategy leads to strong data-efficient generalization of medical imaging AI, matching strong supervised baselines using between 1% to 33% of retraining data across tasks. These results suggest that REMEDIS can significantly accelerate the life-cycle of medical imaging AI development thereby presenting an important step forward for medical imaging AI to deliver broad impact.", "paper_url": "http://arxiv.org/abs/2205.09723v1", "pdf_url": "http://arxiv.org/pdf/2205.09723v1", "repo_url": "https://github.com/google-research/big_transfer"}, "2205.10351": {"publish_time": "2022-05-20", "title": "Enriching StyleGAN with Illumination Physics", "author": "Anand Bhattad et.al.", "abstract": "StyleGAN generates novel images of a scene from latent codes which are impressively disentangled. But StyleGAN generates images that are \"like\" its training set. This paper shows how to use simple physical properties of images to enrich StyleGAN's generation capacity. We use an intrinsic image method to decompose an image, then search the latent space of a pretrained StyleGAN to find novel directions that fix one component (say, albedo) and vary another (say, shading). Therefore, we can change the lighting of a complex scene without changing the scene layout, object colors, and shapes. Or we can change the colors of objects without changing shading intensity or their scene layout. Our experiments suggest the proposed method, StyLitGAN, can add and remove luminaires in the scene and generate images with realistic lighting effects -- cast shadows, soft shadows, inter-reflections, glossy effects -- requiring no labeled paired relighting data or any other geometric supervision. Qualitative evaluation confirms that our generated images are realistic and that we can change or fix components at will. Quantitative evaluation shows that pre-trained StyleGAN could not produce the images StyLitGAN produces; we can automatically generate realistic out-of-distribution images, and so can significantly enrich the range of images StyleGAN can produce.", "paper_url": "http://arxiv.org/abs/2205.10351v1", "pdf_url": "http://arxiv.org/pdf/2205.10351v1", "repo_url": null}, "2205.10347": {"publish_time": "2022-05-20", "title": "Diverse super-resolution with pretrained deep hiererarchical VAEs", "author": "Jean Prost et.al.", "abstract": "Image super-resolution is a one-to-many problem, but most deep-learning based methods only provide one single solution to this problem. In this work, we tackle the problem of diverse super-resolution by reusing VD-VAE, a state-of-the art variational autoencoder (VAE). We find that the hierarchical latent representation learned by VD-VAE naturally separates the image low-frequency information, encoded in the latent groups at the top of the hierarchy, from the image high-frequency details, determined by the latent groups at the bottom of the latent hierarchy. Starting from this observation, we design a super-resolution model exploiting the specific structure of VD-VAE latent space. Specifically, we train an encoder to encode low-resolution images in the subset of VD-VAE latent space encoding the low-frequency information, and we combine this encoder with VD-VAE generative model to sample diverse super-resolved version of a low-resolution input. We demonstrate the ability of our method to generate diverse solutions to the super-resolution problem on face super-resolution with upsampling factors x4, x8, and x16.", "paper_url": "http://arxiv.org/abs/2205.10347v1", "pdf_url": "http://arxiv.org/pdf/2205.10347v1", "repo_url": null}, "2205.10342": {"publish_time": "2022-05-20", "title": "Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT)", "author": "Jue Jiang et.al.", "abstract": "Vision transformers, with their ability to more efficiently model long-range context, have demonstrated impressive accuracy gains in several computer vision and medical image analysis tasks including segmentation. However, such methods need large labeled datasets for training, which is hard to obtain for medical image analysis. Self-supervised learning (SSL) has demonstrated success in medical image segmentation using convolutional networks. In this work, we developed a \\underline{s}elf-distillation learning with \\underline{m}asked \\underline{i}mage modeling method to perform SSL for vision \\underline{t}ransformers (SMIT) applied to 3D multi-organ segmentation from CT and MRI. Our contribution is a dense pixel-wise regression within masked patches called masked image prediction, which we combined with masked patch token distillation as pretext task to pre-train vision transformers. We show our approach is more accurate and requires fewer fine tuning datasets than other pretext tasks. Unlike prior medical image methods, which typically used image sets arising from disease sites and imaging modalities corresponding to the target tasks, we used 3,643 CT scans (602,708 images) arising from head and neck, lung, and kidney cancers as well as COVID-19 for pre-training and applied it to abdominal organs segmentation from MRI pancreatic cancer patients as well as publicly available 13 different abdominal organs segmentation from CT. Our method showed clear accuracy improvement (average DSC of 0.875 from MRI and 0.878 from CT) with reduced requirement for fine-tuning datasets over commonly used pretext tasks. Extensive comparisons against multiple current SSL methods were done. Code will be made available upon acceptance for publication.", "paper_url": "http://arxiv.org/abs/2205.10342v1", "pdf_url": "http://arxiv.org/pdf/2205.10342v1", "repo_url": null}, "2205.10338": {"publish_time": "2022-05-20", "title": "Efficient visual object representation using a biologically plausible spike-latency code and winner-take-all inhibition", "author": "Melani Sanchez-Garcia et.al.", "abstract": "Deep neural networks have surpassed human performance in key visual challenges such as object recognition, but require a large amount of energy, computation, and memory. In contrast, spiking neural networks (SNNs) have the potential to improve both the efficiency and biological plausibility of object recognition systems. Here we present a SNN model that uses spike-latency coding and winner-take-all inhibition (WTA-I) to efficiently represent visual stimuli from the Fashion MNIST dataset. Stimuli were preprocessed with center-surround receptive fields and then fed to a layer of spiking neurons whose synaptic weights were updated using spike-timing-dependent-plasticity (STDP). We investigate how the quality of the represented objects changes under different WTA-I schemes and demonstrate that a network of 150 spiking neurons can efficiently represent objects with as little as 40 spikes. Studying how core object recognition may be implemented using biologically plausible learning rules in SNNs may not only further our understanding of the brain, but also lead to novel and efficient artificial vision systems.", "paper_url": "http://arxiv.org/abs/2205.10338v1", "pdf_url": "http://arxiv.org/pdf/2205.10338v1", "repo_url": null}, "2205.10337": {"publish_time": "2022-05-20", "title": "UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes", "author": "Alexander Kolesnikov et.al.", "abstract": "We introduce UViM, a unified approach capable of modeling a wide range of computer vision tasks. In contrast to previous models, UViM has the same functional form for all tasks; it requires no task-specific modifications which require extensive human expertise. The approach involves two components: (I) a base model (feed-forward) which is trained to directly predict raw vision outputs, guided by a learned discrete code and (II) a language model (autoregressive) that is trained to generate the guiding code. These components complement each other: the language model is well-suited to modeling structured interdependent data, while the base model is efficient at dealing with high-dimensional outputs. We demonstrate the effectiveness of UViM on three diverse and challenging vision tasks: panoptic segmentation, depth prediction and image colorization, where we achieve competitive and near state-of-the-art results. Our experimental results suggest that UViM is a promising candidate for a unified modeling approach in computer vision.", "paper_url": "http://arxiv.org/abs/2205.10337v1", "pdf_url": "http://arxiv.org/pdf/2205.10337v1", "repo_url": null}, "2205.11508": {"publish_time": "2022-05-23", "title": "Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods", "author": "Randall Balestriero et.al.", "abstract": "Self-Supervised Learning (SSL) surmises that inputs and pairwise positive relationships are enough to learn meaningful representations. Although SSL has recently reached a milestone: outperforming supervised methods in many modalities... the theoretical foundations are limited, method-specific, and fail to provide principled design guidelines to practitioners. In this paper, we propose a unifying framework under the helm of spectral manifold learning to address those limitations. Through the course of this study, we will rigorously demonstrate that VICReg, SimCLR, BarlowTwins et al. correspond to eponymous spectral methods such as Laplacian Eigenmaps, Multidimensional Scaling et al. This unification will then allow us to obtain (i) the closed-form optimal representation for each method, (ii) the closed-form optimal network parameters in the linear regime for each method, (iii) the impact of the pairwise relations used during training on each of those quantities and on downstream task performances, and most importantly, (iv) the first theoretical bridge between contrastive and non-contrastive methods towards global and local spectral embedding methods respectively, hinting at the benefits and limitations of each. For example, (a) if the pairwise relation is aligned with the downstream task, any SSL method can be employed successfully and will recover the supervised method, but in the low data regime, SimCLR or VICReg with high invariance hyper-parameter should be preferred; (b) if the pairwise relation is misaligned with the downstream task, BarlowTwins or VICReg with small invariance hyper-parameter should be preferred.", "paper_url": "http://arxiv.org/abs/2205.11508v1", "pdf_url": "http://arxiv.org/pdf/2205.11508v1", "repo_url": null}, "2205.11506": {"publish_time": "2022-05-23", "title": "Orchestra: Unsupervised Federated Learning via Globally Consistent Clustering", "author": "Ekdeep Singh Lubana et.al.", "abstract": "Federated learning is generally used in tasks where labels are readily available (e.g., next word prediction). Relaxing this constraint requires design of unsupervised learning techniques that can support desirable properties for federated training: robustness to statistical/systems heterogeneity, scalability with number of participants, and communication efficiency. Prior work on this topic has focused on directly extending centralized self-supervised learning techniques, which are not designed to have the properties listed above. To address this situation, we propose Orchestra, a novel unsupervised federated learning technique that exploits the federation's hierarchy to orchestrate a distributed clustering task and enforce a globally consistent partitioning of clients' data into discriminable clusters. We show the algorithmic pipeline in Orchestra guarantees good generalization performance under a linear probe, allowing it to outperform alternative techniques in a broad range of conditions, including variation in heterogeneity, number of clients, participation ratio, and local epochs.", "paper_url": "http://arxiv.org/abs/2205.11506v1", "pdf_url": "http://arxiv.org/pdf/2205.11506v1", "repo_url": "https://github.com/akhilmathurs/orchestra"}, "2205.11501": {"publish_time": "2022-05-23", "title": "VQA-GNN: Reasoning with Multimodal Semantic Graph for Visual Question Answering", "author": "Yanan Wang et.al.", "abstract": "Visual understanding requires seamless integration between recognition and reasoning: beyond image-level recognition (e.g., detecting objects), systems must perform concept-level reasoning (e.g., inferring the context of objects and intents of people). However, existing methods only model the image-level features, and do not ground them and reason with background concepts such as knowledge graphs (KGs). In this work, we propose a novel visual question answering method, VQA-GNN, which unifies the image-level information and conceptual knowledge to perform joint reasoning of the scene. Specifically, given a question-image pair, we build a scene graph from the image, retrieve a relevant linguistic subgraph from ConceptNet and visual subgraph from VisualGenome, and unify these three graphs and the question into one joint graph, multimodal semantic graph. Our VQA-GNN then learns to aggregate messages and reason across different modalities captured by the multimodal semantic graph. In the evaluation on the VCR task, our method outperforms the previous scene graph-based Trans-VL models by over 4%, and VQA-GNN-Large, our model that fuses a Trans-VL further improves the state of the art by 2%, attaining the top of the VCR leaderboard at the time of submission. This result suggests the efficacy of our model in performing conceptual reasoning beyond image-level recognition for visual understanding. Finally, we demonstrate that our model is the first work to provide interpretability across visual and textual knowledge domains for the VQA task.", "paper_url": "http://arxiv.org/abs/2205.11501v1", "pdf_url": "http://arxiv.org/pdf/2205.11501v1", "repo_url": null}, "2205.11495": {"publish_time": "2022-05-23", "title": "Flexible Diffusion Modeling of Long Videos", "author": "William Harvey et.al.", "abstract": "We present a framework for video modeling based on denoising diffusion probabilistic models that produces long-duration video completions in a variety of realistic environments. We introduce a generative model that can at test-time sample any arbitrary subset of video frames conditioned on any other subset and present an architecture adapted for this purpose. Doing so allows us to efficiently compare and optimize a variety of schedules for the order in which frames in a long video are sampled and use selective sparse and long-range conditioning on previously sampled frames. We demonstrate improved video modeling over prior work on a number of datasets and sample temporally coherent videos over 25 minutes in length. We additionally release a new video modeling dataset and semantically meaningful metrics based on videos generated in the CARLA self-driving car simulator.", "paper_url": "http://arxiv.org/abs/2205.11495v1", "pdf_url": "http://arxiv.org/pdf/2205.11495v1", "repo_url": null}, "2205.11487": {"publish_time": "2022-05-23", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding", "author": "Chitwan Saharia et.al.", "abstract": "We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (e.g. T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+CLIP, Latent Diffusion Models, and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment. See https://imagen.research.google/ for an overview of the results.", "paper_url": "http://arxiv.org/abs/2205.11487v1", "pdf_url": "http://arxiv.org/pdf/2205.11487v1", "repo_url": null}, "2205.12257": {"publish_time": "2022-05-24", "title": "OnePose: One-Shot Object Pose Estimation without CAD Models", "author": "Jiaming Sun et.al.", "abstract": "We propose a new method named OnePose for object pose estimation. Unlike existing instance-level or category-level methods, OnePose does not rely on CAD models and can handle objects in arbitrary categories without instance- or category-specific network training. OnePose draws the idea from visual localization and only requires a simple RGB video scan of the object to build a sparse SfM model of the object. Then, this model is registered to new query images with a generic feature matching network. To mitigate the slow runtime of existing visual localization methods, we propose a new graph attention network that directly matches 2D interest points in the query image with the 3D points in the SfM model, resulting in efficient and robust pose estimation. Combined with a feature-based pose tracker, OnePose is able to stably detect and track 6D poses of everyday household objects in real-time. We also collected a large-scale dataset that consists of 450 sequences of 150 objects.", "paper_url": "http://arxiv.org/abs/2205.12257v1", "pdf_url": "http://arxiv.org/pdf/2205.12257v1", "repo_url": "https://github.com/zju3dv/OnePose"}, "2205.12256": {"publish_time": "2022-05-24", "title": "Differentiable Dynamics for Articulated 3d Human Motion Reconstruction", "author": "Erik G\u00e4rtner et.al.", "abstract": "We introduce DiffPhy, a differentiable physics-based model for articulated 3d human motion reconstruction from video. Applications of physics-based reasoning in human motion analysis have so far been limited, both by the complexity of constructing adequate physical models of articulated human motion, and by the formidable challenges of performing stable and efficient inference with physics in the loop. We jointly address such modeling and inference challenges by proposing an approach that combines a physically plausible body representation with anatomical joint limits, a differentiable physics simulator, and optimization techniques that ensure good performance and robustness to suboptimal local optima. In contrast to several recent methods, our approach readily supports full-body contact including interactions with objects in the scene. Most importantly, our model connects end-to-end with images, thus supporting direct gradient-based physics optimization by means of image-based loss functions. We validate the model by demonstrating that it can accurately reconstruct physically plausible 3d human motion from monocular video, both on public benchmarks with available 3d ground-truth, and on videos from the internet.", "paper_url": "http://arxiv.org/abs/2205.12256v1", "pdf_url": "http://arxiv.org/pdf/2205.12256v1", "repo_url": null}, "2205.12239": {"publish_time": "2022-05-24", "title": "Gacs-Korner Common Information Variational Autoencoder", "author": "Michael Kleinman et.al.", "abstract": "We propose a notion of common information that allows one to quantify and separate the information that is shared between two random variables from the information that is unique to each. Our notion of common information is a variational relaxation of the G\\'acs-K\\\"orner common information, which we recover as a special case, but is more amenable to optimization and can be approximated empirically using samples from the underlying distribution. We then provide a method to partition and quantify the common and unique information using a simple modification of a traditional variational auto-encoder. Empirically, we demonstrate that our formulation allows us to learn semantically meaningful common and unique factors of variation even on high-dimensional data such as images and videos. Moreover, on datasets where ground-truth latent factors are known, we show that we can accurately quantify the common information between the random variables. Additionally, we show that the auto-encoder that we learn recovers semantically meaningful disentangled factors of variation, even though we do not explicitly optimize for it.", "paper_url": "http://arxiv.org/abs/2205.12239v1", "pdf_url": "http://arxiv.org/pdf/2205.12239v1", "repo_url": null}, "2205.12231": {"publish_time": "2022-05-24", "title": "ASSET: Autoregressive Semantic Scene Editing with Transformers at High Resolutions", "author": "Difan Liu et.al.", "abstract": "We present ASSET, a neural architecture for automatically modifying an input high-resolution image according to a user's edits on its semantic segmentation map. Our architecture is based on a transformer with a novel attention mechanism. Our key idea is to sparsify the transformer's attention matrix at high resolutions, guided by dense attention extracted at lower image resolutions. While previous attention mechanisms are computationally too expensive for handling high-resolution images or are overly constrained within specific image regions hampering long-range interactions, our novel attention mechanism is both computationally efficient and effective. Our sparsified attention mechanism is able to capture long-range interactions and context, leading to synthesizing interesting phenomena in scenes, such as reflections of landscapes onto water or flora consistent with the rest of the landscape, that were not possible to generate reliably with previous convnets and transformer approaches. We present qualitative and quantitative results, along with user studies, demonstrating the effectiveness of our method.", "paper_url": "http://arxiv.org/abs/2205.12231v1", "pdf_url": "http://arxiv.org/pdf/2205.12231v1", "repo_url": "https://github.com/difanliu/asset"}, "2205.12224": {"publish_time": "2022-05-24", "title": "GLOBUS: GLObal Building heights for Urban Studies", "author": "Harsh G. Kamath et.al.", "abstract": "Urban weather and climate studies continue to be important as extreme events cause economic loss and impact public health. Weather models seek to represent urban areas but are oversimplified due to data availability, especially building information. This paper introduces a novel Level of Detail-1 (LoD-1) building dataset derived from a Deep Neural Network (DNN) called GLObal Building heights for Urban Studies (GLOBUS). GLOBUS uses open-source datasets as predictors: Advanced Land Observation Satellite (ALOS) Digital Surface Model (DSM) normalized using Shuttle Radar Topography Mission (SRTM) Digital Elevation Model (DEM), Landscan population density, and building footprints. The building information from GLOBUS can be ingested in Numerical Weather Prediction (NWP) and urban energy-water balance models to study localized phenomena such as the Urban Heat Island (UHI) effect. GLOBUS has been trained and validated using the United States Geological Survey (USGS) 3DEP Light Detection and Ranging (LiDAR) data. We used data from 5 US cities for training and the model was validated over 6 cities. Performance metrics are computed at a spatial resolution of 300-meter. The Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE) were 5.15 meters and 28.8 %, respectively. The standard deviation and histogram of building heights over a 300-meter grid are well represented using GLOBUS.", "paper_url": "http://arxiv.org/abs/2205.12224v1", "pdf_url": "http://arxiv.org/pdf/2205.12224v1", "repo_url": null}, "2205.12956": {"publish_time": "2022-05-25", "title": "Inception Transformer", "author": "Chenyang Si et.al.", "abstract": "Recent studies show that Transformer has strong capability of building long-range dependencies, yet is incompetent in capturing high frequencies that predominantly convey local information. To tackle this issue, we present a novel and general-purpose Inception Transformer, or iFormer for short, that effectively learns comprehensive features with both high- and low-frequency information in visual data. Specifically, we design an Inception mixer to explicitly graft the advantages of convolution and max-pooling for capturing the high-frequency information to Transformers. Different from recent hybrid frameworks, the Inception mixer brings greater efficiency through a channel splitting mechanism to adopt parallel convolution/max-pooling path and self-attention path as high- and low-frequency mixers, while having the flexibility to model discriminative information scattered within a wide frequency range. Considering that bottom layers play more roles in capturing high-frequency details while top layers more in modeling low-frequency global information, we further introduce a frequency ramp structure, i.e. gradually decreasing the dimensions fed to the high-frequency mixer and increasing those to the low-frequency mixer, which can effectively trade-off high- and low-frequency components across different layers. We benchmark the iFormer on a series of vision tasks, and showcase that it achieves impressive performance on image classification, COCO detection and ADE20K segmentation. For example, our iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than DeiT-S by 3.6%, and even slightly better than much bigger model Swin-B (83.3%) with only 1/4 parameters and 1/3 FLOPs. Code and models will be released at https://github.com/sail-sg/iFormer.", "paper_url": "http://arxiv.org/abs/2205.12956v1", "pdf_url": "http://arxiv.org/pdf/2205.12956v1", "repo_url": "https://github.com/sail-sg/iformer"}, "2205.12955": {"publish_time": "2022-05-25", "title": "Neural 3D Reconstruction in the Wild", "author": "Jiaming Sun et.al.", "abstract": "We are witnessing an explosion of neural implicit representations in computer vision and graphics. Their applicability has recently expanded beyond tasks such as shape generation and image-based rendering to the fundamental problem of image-based 3D reconstruction. However, existing methods typically assume constrained 3D environments with constant illumination captured by a small set of roughly uniformly distributed cameras. We introduce a new method that enables efficient and accurate surface reconstruction from Internet photo collections in the presence of varying illumination. To achieve this, we propose a hybrid voxel- and surface-guided sampling technique that allows for more efficient ray sampling around surfaces and leads to significant improvements in reconstruction quality. Further, we present a new benchmark and protocol for evaluating reconstruction performance on such in-the-wild scenes. We perform extensive experiments, demonstrating that our approach surpasses both classical and neural reconstruction methods on a wide variety of metrics.", "paper_url": "http://arxiv.org/abs/2205.12955v1", "pdf_url": "http://arxiv.org/pdf/2205.12955v1", "repo_url": null}, "2205.12952": {"publish_time": "2022-05-25", "title": "Pretraining is All You Need for Image-to-Image Translation", "author": "Tengfei Wang et.al.", "abstract": "We propose to use pretraining to boost general image-to-image translation. Prior image-to-image translation methods usually need dedicated architectural design and train individual translation models from scratch, struggling for high-quality generation of complex scenes, especially when paired training data are not abundant. In this paper, we regard each image-to-image translation problem as a downstream task and introduce a simple and generic framework that adapts a pretrained diffusion model to accommodate various kinds of image-to-image translation. We also propose adversarial training to enhance the texture synthesis in the diffusion model training, in conjunction with normalized guidance sampling to improve the generation quality. We present extensive empirical comparison across various tasks on challenging benchmarks such as ADE20K, COCO-Stuff, and DIODE, showing the proposed pretraining-based image-to-image translation (PITI) is capable of synthesizing images of unprecedented realism and faithfulness.", "paper_url": "http://arxiv.org/abs/2205.12952v1", "pdf_url": "http://arxiv.org/pdf/2205.12952v1", "repo_url": null}, "2205.12923": {"publish_time": "2022-05-25", "title": "Domain Adaptation for Object Detection using SE Adaptors and Center Loss", "author": "Sushruth Nagesh et.al.", "abstract": "Despite growing interest in object detection, very few works address the extremely practical problem of cross-domain robustness especially for automative applications. In order to prevent drops in performance due to domain shift, we introduce an unsupervised domain adaptation method built on the foundation of faster-RCNN with two domain adaptation components addressing the shift at the instance and image levels respectively and apply a consistency regularization between them. We also introduce a family of adaptation layers that leverage the squeeze excitation mechanism called SE Adaptors to improve domain attention and thus improves performance without any prior requirement of knowledge of the new target domain. Finally, we incorporate a center loss in the instance and image level representations to improve the intra-class variance. We report all results with Cityscapes as our source domain and Foggy Cityscapes as the target domain outperforming previous baselines.", "paper_url": "http://arxiv.org/abs/2205.12923v1", "pdf_url": "http://arxiv.org/pdf/2205.12923v1", "repo_url": null}, "2205.12920": {"publish_time": "2022-05-25", "title": "DH-GAN: A Physics-driven Untrained Generative Adversarial Network for 3D Microscopic Imaging using Digital Holography", "author": "Xiwen Chen et.al.", "abstract": "Digital holography is a 3D imaging technique by emitting a laser beam with a plane wavefront to an object and measuring the intensity of the diffracted waveform, called holograms. The object's 3D shape can be obtained by numerical analysis of the captured holograms and recovering the incurred phase. Recently, deep learning (DL) methods have been used for more accurate holographic processing. However, most supervised methods require large datasets to train the model, which is rarely available in most DH applications due to the scarcity of samples or privacy concerns. A few one-shot DL-based recovery methods exist with no reliance on large datasets of paired images. Still, most of these methods often neglect the underlying physics law that governs wave propagation. These methods offer a black-box operation, which is not explainable, generalizable, and transferrable to other samples and applications. In this work, we propose a new DL architecture based on generative adversarial networks that uses a discriminative network for realizing a semantic measure for reconstruction quality while using a generative network as a function approximator to model the inverse of hologram formation. We impose smoothness on the background part of the recovered image using a progressive masking module powered by simulated annealing to enhance the reconstruction quality. The proposed method is one of its kind that exhibits high transferability to similar samples, which facilitates its fast deployment in time-sensitive applications without the need for retraining the network. The results show a considerable improvement to competitor methods in reconstruction quality (about 5 dB PSNR gain) and robustness to noise (about 50% reduction in PSNR vs noise increase rate).", "paper_url": "http://arxiv.org/abs/2205.12920v1", "pdf_url": "http://arxiv.org/pdf/2205.12920v1", "repo_url": null}, "2205.13543": {"publish_time": "2022-05-26", "title": "Revealing the Dark Secrets of Masked Image Modeling", "author": "Zhenda Xie et.al.", "abstract": "Masked image modeling (MIM) as pre-training is shown to be effective for numerous vision downstream tasks, but how and where MIM works remain unclear. In this paper, we compare MIM with the long-dominant supervised pre-trained models from two perspectives, the visualizations and the experiments, to uncover their key representational differences. From the visualizations, we find that MIM brings locality inductive bias to all layers of the trained models, but supervised models tend to focus locally at lower layers but more globally at higher layers. That may be the reason why MIM helps Vision Transformers that have a very large receptive field to optimize. Using MIM, the model can maintain a large diversity on attention heads in all layers. But for supervised models, the diversity on attention heads almost disappears from the last three layers and less diversity harms the fine-tuning performance. From the experiments, we find that MIM models can perform significantly better on geometric and motion tasks with weak semantics or fine-grained classification tasks, than their supervised counterparts. Without bells and whistles, a standard MIM pre-trained SwinV2-L could achieve state-of-the-art performance on pose estimation (78.9 AP on COCO test-dev and 78.0 AP on CrowdPose), depth estimation (0.287 RMSE on NYUv2 and 1.966 RMSE on KITTI), and video object tracking (70.7 SUC on LaSOT). For the semantic understanding datasets where the categories are sufficiently covered by the supervised pre-training, MIM models can still achieve highly competitive transfer performance. With a deeper understanding of MIM, we hope that our work can inspire new and solid research in this direction.", "paper_url": "http://arxiv.org/abs/2205.13543v1", "pdf_url": "http://arxiv.org/pdf/2205.13543v1", "repo_url": null}, "2205.13542": {"publish_time": "2022-05-26", "title": "BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation", "author": "Zhijian Liu et.al.", "abstract": "Multi-sensor fusion is essential for an accurate and reliable autonomous driving system. Recent approaches are based on point-level fusion: augmenting the LiDAR point cloud with camera features. However, the camera-to-LiDAR projection throws away the semantic density of camera features, hindering the effectiveness of such methods, especially for semantic-oriented tasks (such as 3D scene segmentation). In this paper, we break this deeply-rooted convention with BEVFusion, an efficient and generic multi-task multi-sensor fusion framework. It unifies multi-modal features in the shared bird's-eye view (BEV) representation space, which nicely preserves both geometric and semantic information. To achieve this, we diagnose and lift key efficiency bottlenecks in the view transformation with optimized BEV pooling, reducing latency by more than 40x. BEVFusion is fundamentally task-agnostic and seamlessly supports different 3D perception tasks with almost no architectural changes. It establishes the new state of the art on nuScenes, achieving 1.3% higher mAP and NDS on 3D object detection and 13.6% higher mIoU on BEV map segmentation, with 1.9x lower computation cost.", "paper_url": "http://arxiv.org/abs/2205.13542v1", "pdf_url": "http://arxiv.org/pdf/2205.13542v1", "repo_url": null}, "2205.13535": {"publish_time": "2022-05-26", "title": "AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition", "author": "Shoufa Chen et.al.", "abstract": "Although the pre-trained Vision Transformers (ViTs) achieved great success in computer vision, adapting a ViT to various image and video tasks is challenging because of its heavy computation and storage burdens, where each model needs to be independently and comprehensively fine-tuned to different tasks, limiting its transferability in different domains. To address this challenge, we propose an effective adaptation approach for Transformer, namely AdaptFormer, which can adapt the pre-trained ViTs into many different image and video tasks efficiently. It possesses several benefits more appealing than prior arts. Firstly, AdaptFormer introduces lightweight modules that only add less than 2% extra parameters to a ViT, while it is able to increase the ViT's transferability without updating its original pre-trained parameters, significantly outperforming the existing 100% fully fine-tuned models on action recognition benchmarks. Secondly, it can be plug-and-play in different Transformers and scalable to many visual tasks. Thirdly, extensive experiments on five image and video datasets show that AdaptFormer largely improves ViTs in the target domains. For example, when updating just 1.5% extra parameters, it achieves about 10% and 19% relative improvement compared to the fully fine-tuned models on Something-Something~v2 and HMDB51, respectively. Project page: http://www.shoufachen.com/adaptformer-page.", "paper_url": "http://arxiv.org/abs/2205.13535v1", "pdf_url": "http://arxiv.org/pdf/2205.13535v1", "repo_url": null}, "2205.13524": {"publish_time": "2022-05-26", "title": "PREF: Phasorial Embedding Fields for Compact Neural Representations", "author": "Binbin Huang et.al.", "abstract": "We present a phasorial embedding field \\emph{PREF} as a compact representation to facilitate neural signal modeling and reconstruction tasks. Pure multi-layer perceptron (MLP) based neural techniques are biased towards low frequency signals and have relied on deep layers or Fourier encoding to avoid losing details. PREF instead employs a compact and physically explainable encoding field based on the phasor formulation of the Fourier embedding space. We conduct a comprehensive theoretical analysis to demonstrate the advantages of PREF over the latest spatial embedding techniques. We then develop a highly efficient frequency learning framework using an approximated inverse Fourier transform scheme for PREF along with a novel Parseval regularizer. Extensive experiments show our compact PREF-based neural signal processing technique is on par with the state-of-the-art in 2D image completion, 3D SDF surface regression, and 5D radiance field reconstruction.", "paper_url": "http://arxiv.org/abs/2205.13524v1", "pdf_url": "http://arxiv.org/pdf/2205.13524v1", "repo_url": null}, "2205.13515": {"publish_time": "2022-05-26", "title": "Green Hierarchical Vision Transformer for Masked Image Modeling", "author": "Lang Huang et.al.", "abstract": "We present an efficient approach for Masked Image Modeling (MIM) with hierarchical Vision Transformers (ViTs), e.g., Swin Transformer, allowing the hierarchical ViTs to discard masked patches and operate only on the visible ones. Our approach consists of two key components. First, for the window attention, we design a Group Window Attention scheme following the Divide-and-Conquer strategy. To mitigate the quadratic complexity of the self-attention w.r.t. the number of patches, group attention encourages a uniform partition that visible patches within each local window of arbitrary size can be grouped with equal size, where masked self-attention is then performed within each group. Second, we further improve the grouping strategy via the Dynamic Programming algorithm to minimize the overall computation cost of the attention on the grouped patches. As a result, MIM now can work on hierarchical ViTs in a green and efficient way. For example, we can train the hierarchical ViTs about 2.7$\\times$ faster and reduce the GPU memory usage by 70%, while still enjoying competitive performance on ImageNet classification and the superiority on downstream COCO object detection benchmarks. Code and pre-trained models have been made publicly available at https://github.com/LayneH/GreenMIM.", "paper_url": "http://arxiv.org/abs/2205.13515v1", "pdf_url": "http://arxiv.org/pdf/2205.13515v1", "repo_url": "https://github.com/layneh/greenmim"}, "2205.14141": {"publish_time": "2022-05-27", "title": "Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation", "author": "Yixuan Wei et.al.", "abstract": "Masked image modeling (MIM) learns representations with remarkably good fine-tuning performances, overshadowing previous prevalent pre-training approaches such as image classification, instance contrastive learning, and image-text alignment. In this paper, we show that the inferior fine-tuning performance of these pre-training approaches can be significantly improved by a simple post-processing in the form of feature distillation (FD). The feature distillation converts the old representations to new representations that have a few desirable properties just like those representations produced by MIM. These properties, which we aggregately refer to as optimization friendliness, are identified and analyzed by a set of attention- and optimization-related diagnosis tools. With these properties, the new representations show strong fine-tuning performance. Specifically, the contrastive self-supervised learning methods are made as competitive in fine-tuning as the state-of-the-art masked image modeling (MIM) algorithms. The CLIP models' fine-tuning performance is also significantly improved, with a CLIP ViT-L model reaching 89.0% top-1 accuracy on ImageNet-1K classification. More importantly, our work provides a way for the future research to focus more effort on the generality and scalability of the learnt representations without being pre-occupied with optimization friendliness since it can be enhanced rather easily. The code will be available at https://github.com/SwinTransformer/Feature-Distillation.", "paper_url": "http://arxiv.org/abs/2205.14141v1", "pdf_url": "http://arxiv.org/pdf/2205.14141v1", "repo_url": null}, "2205.14120": {"publish_time": "2022-05-27", "title": "Neural Basis Models for Interpretability", "author": "Filip Radenovic et.al.", "abstract": "Due to the widespread use of complex machine learning models in real-world applications, it is becoming critical to explain model predictions. However, these models are typically black-box deep neural networks, explained post-hoc via methods with known faithfulness limitations. Generalized Additive Models (GAMs) are an inherently interpretable class of models that address this limitation by learning a non-linear shape function for each feature separately, followed by a linear model on top. However, these models are typically difficult to train, require numerous parameters, and are difficult to scale.   We propose an entirely new subfamily of GAMs that utilizes basis decomposition of shape functions. A small number of basis functions are shared among all features, and are learned jointly for a given task, thus making our model scale much better to large-scale data with high-dimensional features, especially when features are sparse. We propose an architecture denoted as the Neural Basis Model (NBM) which uses a single neural network to learn these bases. On a variety of tabular and image datasets, we demonstrate that for interpretable machine learning, NBMs are the state-of-the-art in accuracy, model size, and, throughput and can easily model all higher-order feature interactions.", "paper_url": "http://arxiv.org/abs/2205.14120v1", "pdf_url": "http://arxiv.org/pdf/2205.14120v1", "repo_url": null}, "2205.14112": {"publish_time": "2022-05-27", "title": "Improving Road Segmentation in Challenging Domains Using Similar Place Priors", "author": "Connor Malone et.al.", "abstract": "Road segmentation in challenging domains, such as night, snow or rain, is a difficult task. Most current approaches boost performance using fine-tuning, domain adaptation, style transfer, or by referencing previously acquired imagery. These approaches share one or more of three significant limitations: a reliance on large amounts of annotated training data that can be costly to obtain, both anticipation of and training data from the type of environmental conditions expected at inference time, and/or imagery captured from a previous visit to the location. In this research, we remove these restrictions by improving road segmentation based on similar places. We use Visual Place Recognition (VPR) to find similar but geographically distinct places, and fuse segmentations for query images and these similar place priors using a Bayesian approach and novel segmentation quality metric. Ablation studies show the need to re-evaluate notions of VPR utility for this task. We demonstrate the system achieving state-of-the-art road segmentation performance across multiple challenging condition scenarios including night time and snow, without requiring any prior training or previous access to the same geographical locations. Furthermore, we show that this method is network agnostic, improves multiple baseline techniques and is competitive against methods specialised for road prediction.", "paper_url": "http://arxiv.org/abs/2205.14112v1", "pdf_url": "http://arxiv.org/pdf/2205.14112v1", "repo_url": null}, "2205.14108": {"publish_time": "2022-05-27", "title": "Scalable Interpretability via Polynomials", "author": "Abhimanyu Dubey et.al.", "abstract": "Generalized Additive Models (GAMs) have quickly become the leading choice for fully-interpretable machine learning. However, unlike uninterpretable methods such as DNNs, they lack expressive power and easy scalability, and are hence not a feasible alternative for real-world tasks. We present a new class of GAMs that use tensor rank decompositions of polynomials to learn powerful, $\\textit{fully-interpretable}$ models. Our approach, titled Scalable Polynomial Additive Models (SPAM) is effortlessly scalable and models $\\textit{all}$ higher-order feature interactions without a combinatorial parameter explosion. SPAM outperforms all current interpretable approaches, and matches DNN/XGBoost performance on a series of real-world benchmarks with up to hundreds of thousands of features. We demonstrate by human subject evaluations that SPAMs are demonstrably more interpretable in practice, and are hence an effortless replacement for DNNs for creating interpretable and high-performance systems suitable for large-scale machine learning.", "paper_url": "http://arxiv.org/abs/2205.14108v1", "pdf_url": "http://arxiv.org/pdf/2205.14108v1", "repo_url": null}, "2205.14100": {"publish_time": "2022-05-27", "title": "GIT: A Generative Image-to-text Transformer for Vision and Language", "author": "Jianfeng Wang et.al.", "abstract": "In this paper, we design and train a Generative Image-to-text Transformer, GIT, to unify vision-language tasks such as image/video captioning and question answering. While generative models provide a consistent network architecture between pre-training and fine-tuning, existing work typically contains complex structures (uni/multi-modal encoder/decoder) and depends on external modules such as object detectors/taggers and optical character recognition (OCR). In GIT, we simplify the architecture as one image encoder and one text decoder under a single language modeling task. We also scale up the pre-training data and the model size to boost the model performance. Without bells and whistles, our GIT establishes new state of the arts on 12 challenging benchmarks with a large margin. For instance, our model surpasses the human performance for the first time on TextCaps (138.2 vs. 125.5 in CIDEr). Furthermore, we present a new scheme of generation-based image classification and scene text recognition, achieving decent performance on standard benchmarks.", "paper_url": "http://arxiv.org/abs/2205.14100v1", "pdf_url": "http://arxiv.org/pdf/2205.14100v1", "repo_url": null}, "2205.15299": {"publish_time": "2022-05-30", "title": "Adapting Rapid Motor Adaptation for Bipedal Robots", "author": "Ashish Kumar et.al.", "abstract": "Recent advances in legged locomotion have enabled quadrupeds to walk on challenging terrains. However, bipedal robots are inherently more unstable and hence it's harder to design walking controllers for them. In this work, we leverage recent advances in rapid adaptation for locomotion control, and extend them to work on bipedal robots. Similar to existing works, we start with a base policy which produces actions while taking as input an estimated extrinsics vector from an adaptation module. This extrinsics vector contains information about the environment and enables the walking controller to rapidly adapt online. However, the extrinsics estimator could be imperfect, which might lead to poor performance of the base policy which expects a perfect estimator. In this paper, we propose A-RMA (Adapting RMA), which additionally adapts the base policy for the imperfect extrinsics estimator by finetuning it using model-free RL. We demonstrate that A-RMA outperforms a number of RL-based baseline controllers and model-based controllers in simulation, and show zero-shot deployment of a single A-RMA policy to enable a bipedal robot, Cassie, to walk in a variety of different scenarios in the real world beyond what it has seen during training. Videos and results at https://ashish-kmr.github.io/a-rma/", "paper_url": "http://arxiv.org/abs/2205.15299v1", "pdf_url": "http://arxiv.org/pdf/2205.15299v1", "repo_url": null}, "2205.15290": {"publish_time": "2022-05-30", "title": "Zero-Shot and Few-Shot Learning for Lung Cancer Multi-Label Classification using Vision Transformer", "author": "Fu-Ming Guo et.al.", "abstract": "Lung cancer is the cancer leading cause of cancer-related death worldwide. Lung adenocarcinoma (LUAD) and lung squamous cell carcinoma (LUSC) are the most common histologic subtypes of NSCLC. Histology is an essential tool for lung cancer diagnosis. Pathologists make classifications according to the dominant subtypes. Although morphology remains the standard for diagnosis, significant tool needs to be developed to elucidate the diagnosis. In our study, we utilize the pre-trained Vision Transformer (ViT) model to classify multiple label lung cancer on histologic slices (from dataset LC25000), in both Zero-Shot and Few-Shot manners. Then we compare the performance of Zero-Shot and Few-Shot ViT on accuracy, precision, recall, sensitivity and specificity. Our study show that the pre-trained ViT model has a good performance in Zero-Shot setting, a competitive accuracy ($99.87\\%$) in Few-Shot setting ({epoch = 1}) and an optimal result ($100.00\\%$) in Few-Shot seeting ({epoch = 5}).", "paper_url": "http://arxiv.org/abs/2205.15290v1", "pdf_url": "http://arxiv.org/pdf/2205.15290v1", "repo_url": null}, "2205.15288": {"publish_time": "2022-05-30", "title": "Self-Supervised Visual Representation Learning with Semantic Grouping", "author": "Xin Wen et.al.", "abstract": "In this paper, we tackle the problem of learning visual representations from unlabeled scene-centric data. Existing works have demonstrated the potential of utilizing the underlying complex structure within scene-centric data; still, they commonly rely on hand-crafted objectness priors or specialized pretext tasks to build a learning framework, which may harm generalizability. Instead, we propose contrastive learning from data-driven semantic slots, namely SlotCon, for joint semantic grouping and representation learning. The semantic grouping is performed by assigning pixels to a set of learnable prototypes, which can adapt to each sample by attentive pooling over the feature and form new slots. Based on the learned data-dependent slots, a contrastive objective is employed for representation learning, which enhances the discriminability of features, and conversely facilitates grouping semantically coherent pixels together. Compared with previous efforts, by simultaneously optimizing the two coupled objectives of semantic grouping and contrastive learning, our approach bypasses the disadvantages of hand-crafted priors and is able to learn object/group-level representations from scene-centric images. Experiments show our approach effectively decomposes complex scenes into semantic groups for feature learning and significantly benefits downstream tasks, including object detection, instance segmentation, and semantic segmentation. The code will be made publicly available.", "paper_url": "http://arxiv.org/abs/2205.15288v1", "pdf_url": "http://arxiv.org/pdf/2205.15288v1", "repo_url": null}, "2205.15285": {"publish_time": "2022-05-30", "title": "Fast Dynamic Radiance Fields with Time-Aware Neural Voxels", "author": "Jiemin Fang et.al.", "abstract": "Neural radiance fields (NeRF) have shown great success in modeling 3D scenes and synthesizing novel-view images. However, most previous NeRF methods take much time to optimize one single scene. Explicit data structures, e.g. voxel features, show great potential to accelerate the training process. However, voxel features face two big challenges to be applied to dynamic scenes, i.e. modeling temporal information and capturing different scales of point motions. We propose a radiance field framework by representing scenes with time-aware voxel features, named as TiNeuVox. A tiny coordinate deformation network is introduced to model coarse motion trajectories and temporal information is further enhanced in the radiance network. A multi-distance interpolation method is proposed and applied on voxel features to model both small and large motions. Our framework significantly accelerates the optimization of dynamic radiance fields while maintaining high rendering quality. Empirical evaluation is performed on both synthetic and real scenes. Our TiNeuVox completes training with only 8 minutes and 8-MB storage cost while showing similar or even better rendering performance than previous dynamic NeRF methods.", "paper_url": "http://arxiv.org/abs/2205.15285v1", "pdf_url": "http://arxiv.org/pdf/2205.15285v1", "repo_url": null}, "2205.15278": {"publish_time": "2022-05-30", "title": "EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model", "author": "Xinya Ji et.al.", "abstract": "Although significant progress has been made to audio-driven talking face generation, existing methods either neglect facial emotion or cannot be applied to arbitrary subjects. In this paper, we propose the Emotion-Aware Motion Model (EAMM) to generate one-shot emotional talking faces by involving an emotion source video. Specifically, we first propose an Audio2Facial-Dynamics module, which renders talking faces from audio-driven unsupervised zero- and first-order key-points motion. Then through exploring the motion model's properties, we further propose an Implicit Emotion Displacement Learner to represent emotion-related facial dynamics as linearly additive displacements to the previously acquired motion representations. Comprehensive experiments demonstrate that by incorporating the results from both modules, our method can generate satisfactory talking face results on arbitrary subjects with realistic emotion patterns.", "paper_url": "http://arxiv.org/abs/2205.15278v1", "pdf_url": "http://arxiv.org/pdf/2205.15278v1", "repo_url": null}, "2205.16007": {"publish_time": "2022-05-31", "title": "Improved Vector Quantized Diffusion Models", "author": "Zhicong Tang et.al.", "abstract": "Vector quantized diffusion (VQ-Diffusion) is a powerful generative model for text-to-image synthesis, but sometimes can still generate low-quality samples or weakly correlated images with text input. We find these issues are mainly due to the flawed sampling strategy. In this paper, we propose two important techniques to further improve the sample quality of VQ-Diffusion. 1) We explore classifier-free guidance sampling for discrete denoising diffusion model and propose a more general and effective implementation of classifier-free guidance. 2) We present a high-quality inference strategy to alleviate the joint distribution issue in VQ-Diffusion. Finally, we conduct experiments on various datasets to validate their effectiveness and show that the improved VQ-Diffusion suppresses the vanilla version by large margins. We achieve an 8.44 FID score on MSCOCO, surpassing VQ-Diffusion by 5.42 FID score. When trained on ImageNet, we dramatically improve the FID score from 11.89 to 4.83, demonstrating the superiority of our proposed techniques.", "paper_url": "http://arxiv.org/abs/2205.16007v1", "pdf_url": "http://arxiv.org/pdf/2205.16007v1", "repo_url": "https://github.com/microsoft/vq-diffusion"}, "2205.16004": {"publish_time": "2022-05-31", "title": "What Knowledge Gets Distilled in Knowledge Distillation?", "author": "Utkarsh Ojha et.al.", "abstract": "Knowledge distillation aims to transfer useful information from a teacher network to a student network, with the primary goal of improving the student's performance for the task at hand. Over the years, there has a been a deluge of novel techniques and use cases of knowledge distillation. Yet, despite the various improvements, there seems to be a glaring gap in the community's fundamental understanding of the process. Specifically, what is the knowledge that gets distilled in knowledge distillation? In other words, in what ways does the student become similar to the teacher? Does it start to localize objects in the same way? Does it get fooled by the same adversarial samples? Does its data invariance properties become similar? Our work presents a comprehensive study to try to answer these questions and more. Our results, using image classification as a case study and three state-of-the-art knowledge distillation techniques, show that knowledge distillation methods can indeed indirectly distill other kinds of properties beyond improving task performance. By exploring these questions, we hope for our work to provide a clearer picture of what happens during knowledge distillation.", "paper_url": "http://arxiv.org/abs/2205.16004v1", "pdf_url": "http://arxiv.org/pdf/2205.16004v1", "repo_url": null}, "2205.15999": {"publish_time": "2022-05-31", "title": "Cascade Luminance and Chrominance for Image Retouching: More Like Artist", "author": "Hailong Ma et.al.", "abstract": "Photo retouching aims to adjust the luminance, contrast, and saturation of the image to make it more human aesthetically desirable. However, artists' actions in photo retouching are difficult to quantitatively analyze. By investigating their retouching behaviors, we propose a two-stage network that brightens images first and then enriches them in the chrominance plane. Six pieces of useful information from image EXIF are picked as the network's condition input. Additionally, hue palette loss is added to make the image more vibrant. Based on the above three aspects, Luminance-Chrominance Cascading Net(LCCNet) makes the machine learning problem of mimicking artists in photo retouching more reasonable. Experiments show that our method is effective on the benchmark MIT-Adobe FiveK dataset, and achieves state-of-the-art performance for both quantitative and qualitative evaluation.", "paper_url": "http://arxiv.org/abs/2205.15999v1", "pdf_url": "http://arxiv.org/pdf/2205.15999v1", "repo_url": null}, "2205.15997": {"publish_time": "2022-05-31", "title": "TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving", "author": "Kashyap Chitta et.al.", "abstract": "How should we integrate representations from complementary sensors for autonomous driving? Geometry-based fusion has shown promise for perception (e.g. object detection, motion forecasting). However, in the context of end-to-end driving, we find that imitation learning based on existing sensor fusion methods underperforms in complex driving scenarios with a high density of dynamic agents. Therefore, we propose TransFuser, a mechanism to integrate image and LiDAR representations using self-attention. Our approach uses transformer modules at multiple resolutions to fuse perspective view and bird's eye view feature maps. We experimentally validate its efficacy on a challenging new benchmark with long routes and dense traffic, as well as the official leaderboard of the CARLA urban driving simulator. At the time of submission, TransFuser outperforms all prior work on the CARLA leaderboard in terms of driving score by a large margin. Compared to geometry-based fusion, TransFuser reduces the average collisions per kilometer by 48%.", "paper_url": "http://arxiv.org/abs/2205.15997v1", "pdf_url": "http://arxiv.org/pdf/2205.15997v1", "repo_url": "https://github.com/autonomousvision/transfuser"}, "2205.15996": {"publish_time": "2022-05-31", "title": "Text2Human: Text-Driven Controllable Human Image Generation", "author": "Yuming Jiang et.al.", "abstract": "Generating high-quality and diverse human images is an important yet challenging task in vision and graphics. However, existing generative models often fall short under the high diversity of clothing shapes and textures. Furthermore, the generation process is even desired to be intuitively controllable for layman users. In this work, we present a text-driven controllable framework, Text2Human, for a high-quality and diverse human generation. We synthesize full-body human images starting from a given human pose with two dedicated steps. 1) With some texts describing the shapes of clothes, the given human pose is first translated to a human parsing map. 2) The final human image is then generated by providing the system with more attributes about the textures of clothes. Specifically, to model the diversity of clothing textures, we build a hierarchical texture-aware codebook that stores multi-scale neural representations for each type of texture. The codebook at the coarse level includes the structural representations of textures, while the codebook at the fine level focuses on the details of textures. To make use of the learned hierarchical codebook to synthesize desired images, a diffusion-based transformer sampler with mixture of experts is firstly employed to sample indices from the coarsest level of the codebook, which then is used to predict the indices of the codebook at finer levels. The predicted indices at different levels are translated to human images by the decoder learned accompanied with hierarchical codebooks. The use of mixture-of-experts allows for the generated image conditioned on the fine-grained text input. The prediction for finer level indices refines the quality of clothing textures. Extensive quantitative and qualitative evaluations demonstrate that our proposed framework can generate more diverse and realistic human images compared to state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2205.15996v1", "pdf_url": "http://arxiv.org/pdf/2205.15996v1", "repo_url": "https://github.com/yumingj/deepfashion-multimodal"}, "2206.00665": {"publish_time": "2022-06-01", "title": "MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction", "author": "Zehao Yu et.al.", "abstract": "In recent years, neural implicit surface reconstruction methods have become popular for multi-view 3D reconstruction. In contrast to traditional multi-view stereo methods, these approaches tend to produce smoother and more complete reconstructions due to the inductive smoothness bias of neural networks. State-of-the-art neural implicit methods allow for high-quality reconstructions of simple scenes from many input views. Yet, their performance drops significantly for larger and more complex scenes and scenes captured from sparse viewpoints. This is caused primarily by the inherent ambiguity in the RGB reconstruction loss that does not provide enough constraints, in particular in less-observed and textureless areas. Motivated by recent advances in the area of monocular geometry prediction, we systematically explore the utility these cues provide for improving neural implicit surface reconstruction. We demonstrate that depth and normal cues, predicted by general-purpose monocular estimators, significantly improve reconstruction quality and optimization time. Further, we analyse and investigate multiple design choices for representing neural implicit surfaces, ranging from monolithic MLP models over single-grid to multi-resolution grid representations. We observe that geometric monocular priors improve performance both for small-scale single-object as well as large-scale multi-object scenes, independent of the choice of representation.", "paper_url": "http://arxiv.org/abs/2206.00665v1", "pdf_url": "http://arxiv.org/pdf/2206.00665v1", "repo_url": null}, "2206.00645": {"publish_time": "2022-06-01", "title": "Extreme Floorplan Reconstruction by Structure-Hallucinating Transformer Cascades", "author": "Sepidehsadat Hosseini et.al.", "abstract": "This paper presents an extreme floorplan reconstruction task, a new benchmark for the task, and a neural architecture as a solution. Given a partial floorplan reconstruction inferred or curated from panorama images, the task is to reconstruct a complete floorplan including invisible architectural structures. The proposed neural network 1) encodes an input partial floorplan into a set of latent vectors by convolutional neural networks and a Transformer; and 2) reconstructs an entire floorplan while hallucinating invisible rooms and doors by cascading Transformer decoders. Qualitative and quantitative evaluations demonstrate effectiveness of our approach over the benchmark of 701 houses, outperforming the state-of-the-art reconstruction techniques. We will share our code, models, and data.", "paper_url": "http://arxiv.org/abs/2206.00645v1", "pdf_url": "http://arxiv.org/pdf/2206.00645v1", "repo_url": null}, "2206.00630": {"publish_time": "2022-06-01", "title": "Unifying Voxel-based Representation with Transformer for 3D Object Detection", "author": "Yanwei Li et.al.", "abstract": "In this work, we present a unified framework for multi-modality 3D object detection, named UVTR. The proposed method aims to unify multi-modality representations in the voxel space for accurate and robust single- or cross-modality 3D detection. To this end, the modality-specific space is first designed to represent different inputs in the voxel feature space. Different from previous work, our approach preserves the voxel space without height compression to alleviate semantic ambiguity and enable spatial interactions. Benefit from the unified manner, cross-modality interaction is then proposed to make full use of inherent properties from different sensors, including knowledge transfer and modality fusion. In this way, geometry-aware expressions in point clouds and context-rich features in images are well utilized for better performance and robustness. The transformer decoder is applied to efficiently sample features from the unified space with learnable positions, which facilitates object-level interactions. In general, UVTR presents an early attempt to represent different modalities in a unified framework. It surpasses previous work in single- and multi-modality entries and achieves leading performance in the nuScenes test set with 69.7%, 55.1%, and 71.1% NDS for LiDAR, camera, and multi-modality inputs, respectively. Code is made available at https://github.com/dvlab-research/UVTR.", "paper_url": "http://arxiv.org/abs/2206.00630v1", "pdf_url": "http://arxiv.org/pdf/2206.00630v1", "repo_url": "https://github.com/dvlab-research/uvtr"}, "2206.00629": {"publish_time": "2022-06-01", "title": "CLIP4IDC: CLIP for Image Difference Captioning", "author": "Zixin Guo et.al.", "abstract": "Image Difference Captioning (IDC) aims at generating sentences to describe the differences between two similar-looking images. The conventional approaches learn captioning models on the offline-extracted visual features and the learning can not be propagated back to the fixed feature extractors pre-trained on image classification datasets. Accordingly, potential improvements can be made by fine-tuning the visual features for: 1) narrowing the gap when generalizing the visual extractor trained on image classification to IDC, and 2) relating the extracted visual features to the descriptions of the corresponding changes. We thus propose CLIP4IDC to transfer a CLIP model for the IDC task to attain these improvements. Different from directly fine-tuning CLIP to generate sentences, a task-specific domain adaptation is used to improve the extracted features. Specifically, the target is to train CLIP on raw pixels to relate the image pairs to the described changes. Afterwards, a vanilla Transformer is trained for IDC on the features extracted by the vision encoder of CLIP. Experiments on three IDC benchmark datasets, CLEVR-Change, Spot-the-Diff and Image-Editing-Request, demonstrate the effectiveness of CLIP4IDC. Our code and models will be released at https://github.com/sushizixin/CLIP4IDC.", "paper_url": "http://arxiv.org/abs/2206.00629v1", "pdf_url": "http://arxiv.org/pdf/2206.00629v1", "repo_url": "https://github.com/sushizixin/clip4idc"}, "2206.00621": {"publish_time": "2022-06-01", "title": "Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training", "author": "Yan Zeng et.al.", "abstract": "In this paper, we introduce Cross-View Language Modeling, a simple and effective language model pre-training framework that unifies cross-lingual cross-modal pre-training with shared architectures and objectives. Our approach is motivated by a key observation that cross-lingual and cross-modal pre-training share the same goal of aligning two different views of the same object into a common semantic space. To this end, the cross-view language modeling framework considers both multi-modal data (i.e., image-caption pairs) and multi-lingual data (i.e., parallel sentence pairs) as two different views of the same object, and trains the model to align the two views by maximizing the mutual information between them with conditional masked language modeling and contrastive learning. We pre-train CCLM, a Cross-lingual Cross-modal Language Model, with the cross-view language modeling framework. Empirical results on IGLUE, a multi-lingual multi-modal benchmark, and two multi-lingual image-text retrieval datasets show that while conceptually simpler, CCLM significantly outperforms the prior state-of-the-art with an average absolute improvement of over 10%. Notably, CCLM is the first multi-lingual multi-modal model that surpasses the translate-test performance of representative English vision-language models by zero-shot cross-lingual transfer.", "paper_url": "http://arxiv.org/abs/2206.00621v1", "pdf_url": "http://arxiv.org/pdf/2206.00621v1", "repo_url": null}, "2206.01204": {"publish_time": "2022-06-02", "title": "Siamese Image Modeling for Self-Supervised Vision Representation Learning", "author": "Chenxin Tao et.al.", "abstract": "Self-supervised learning (SSL) has delivered superior performance on a variety of downstream vision tasks. Two main-stream SSL frameworks have been proposed, i.e., Instance Discrimination (ID) and Masked Image Modeling (MIM). ID pulls together the representations of different views from the same image, while avoiding feature collapse. It does well on linear probing but is inferior in detection performance. On the other hand, MIM reconstructs the original content given a masked image. It excels at dense prediction but fails to perform well on linear probing. Their distinctions are caused by neglecting the representation requirements of either semantic alignment or spatial sensitivity. Specifically, we observe that (1) semantic alignment demands semantically similar views to be projected into nearby representation, which can be achieved by contrasting different views with strong augmentations; (2) spatial sensitivity requires to model the local structure within an image. Predicting dense representations with masked image is therefore beneficial because it models the conditional distribution of image content. Driven by these analysis, we propose Siamese Image Modeling (SIM), which predicts the dense representations of an augmented view, based on another masked view from the same image but with different augmentations. Our method uses a Siamese network with two branches. The online branch encodes the first view, and predicts the second view's representation according to the relative positions between these two views. The target branch produces the target by encoding the second view. In this way, we are able to achieve comparable linear probing and dense prediction performances with ID and MIM, respectively. We also demonstrate that decent linear probing result can be obtained without a global loss. Code shall be released.", "paper_url": "http://arxiv.org/abs/2206.01204v1", "pdf_url": "http://arxiv.org/pdf/2206.01204v1", "repo_url": null}, "2206.01202": {"publish_time": "2022-06-02", "title": "Unveiling The Mask of Position-Information Pattern Through the Mist of Image Features", "author": "Chieh Hubert Lin et.al.", "abstract": "Recent studies show that paddings in convolutional neural networks encode absolute position information which can negatively affect the model performance for certain tasks. However, existing metrics for quantifying the strength of positional information remain unreliable and frequently lead to erroneous results. To address this issue, we propose novel metrics for measuring (and visualizing) the encoded positional information. We formally define the encoded information as PPP (Position-information Pattern from Padding) and conduct a series of experiments to study its properties as well as its formation. The proposed metrics measure the presence of positional information more reliably than the existing metrics based on PosENet and a test in F-Conv. We also demonstrate that for any extant (and proposed) padding schemes, PPP is primarily a learning artifact and is less dependent on the characteristics of the underlying padding schemes.", "paper_url": "http://arxiv.org/abs/2206.01202v1", "pdf_url": "http://arxiv.org/pdf/2206.01202v1", "repo_url": null}, "2206.01203": {"publish_time": "2022-06-02", "title": "Semantic Instance Segmentation of 3D Scenes Through Weak Bounding Box Supervision", "author": "Julian Chibane et.al.", "abstract": "Current 3D segmentation methods heavily rely on large-scale point-cloud datasets, which are notoriously laborious to annotate. Few attempts have been made to circumvent the need for dense per-point annotations. In this work, we look at weakly-supervised 3D instance semantic segmentation. The key idea is to leverage 3D bounding box labels which are easier and faster to annotate. Indeed, we show that it is possible to train dense segmentation models using only weak bounding box labels. At the core of our method, Box2Mask, lies a deep model, inspired by classical Hough voting, that directly votes for bounding box parameters, and a clustering method specifically tailored to bounding box votes. This goes beyond commonly used center votes, which would not fully exploit the bounding box annotations. On ScanNet test, our weakly supervised model attains leading performance among other weakly supervised approaches (+18 mAP50). Remarkably, it also achieves 97% of the performance of fully supervised models. To prove the practicality of our approach, we show segmentation results on the recently released ARKitScenes dataset which is annotated with 3D bounding boxes only, and obtain, for the first time, compelling 3D instance segmentation results.", "paper_url": "http://arxiv.org/abs/2206.01203v1", "pdf_url": "http://arxiv.org/pdf/2206.01203v1", "repo_url": null}, "2206.01201": {"publish_time": "2022-06-02", "title": "REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering", "author": "Yuanze Lin et.al.", "abstract": "This paper revisits visual representation in knowledge-based visual question answering (VQA) and demonstrates that using regional information in a better way can significantly improve the performance. While visual representation is extensively studied in traditional VQA, it is under-explored in knowledge-based VQA even though these two tasks share the common spirit, i.e., rely on visual input to answer the question. Specifically, we observe that in most state-of-the-art knowledge-based VQA methods: 1) visual features are extracted either from the whole image or in a sliding window manner for retrieving knowledge, and the important relationship within/among object regions is neglected; 2) visual features are not well utilized in the final answering model, which is counter-intuitive to some extent. Based on these observations, we propose a new knowledge-based VQA method REVIVE, which tries to utilize the explicit information of object regions not only in the knowledge retrieval stage but also in the answering model. The key motivation is that object regions and inherent relationships are important for knowledge-based VQA. We perform extensive experiments on the standard OK-VQA dataset and achieve new state-of-the-art performance, i.e., 58.0% accuracy, surpassing previous state-of-the-art method by a large margin (+3.6%). We also conduct detailed analysis and show the necessity of regional information in different framework components for knowledge-based VQA.", "paper_url": "http://arxiv.org/abs/2206.01201v1", "pdf_url": "http://arxiv.org/pdf/2206.01201v1", "repo_url": null}, "2206.01198": {"publish_time": "2022-06-02", "title": "Pruning-as-Search: Efficient Neural Architecture Search via Channel Pruning and Structural Reparameterization", "author": "Yanyu Li et.al.", "abstract": "Neural architecture search (NAS) and network pruning are widely studied efficient AI techniques, but not yet perfect. NAS performs exhaustive candidate architecture search, incurring tremendous search cost. Though (structured) pruning can simply shrink model dimension, it remains unclear how to decide the per-layer sparsity automatically and optimally. In this work, we revisit the problem of layer-width optimization and propose Pruning-as-Search (PaS), an end-to-end channel pruning method to search out desired sub-network automatically and efficiently. Specifically, we add a depth-wise binary convolution to learn pruning policies directly through gradient descent. By combining the structural reparameterization and PaS, we successfully searched out a new family of VGG-like and lightweight networks, which enable the flexibility of arbitrary width with respect to each layer instead of each stage. Experimental results show that our proposed architecture outperforms prior arts by around $1.0\\%$ top-1 accuracy under similar inference speed on ImageNet-1000 classification task. Furthermore, we demonstrate the effectiveness of our width search on complex tasks including instance segmentation and image translation. Code and models are released.", "paper_url": "http://arxiv.org/abs/2206.01198v1", "pdf_url": "http://arxiv.org/pdf/2206.01198v1", "repo_url": null}, "2206.01724": {"publish_time": "2022-06-03", "title": "SNAKE: Shape-aware Neural 3D Keypoint Field", "author": "Chengliang Zhong et.al.", "abstract": "Detecting 3D keypoints from point clouds is important for shape reconstruction, while this work investigates the dual question: can shape reconstruction benefit 3D keypoint detection? Existing methods either seek salient features according to statistics of different orders or learn to predict keypoints that are invariant to transformation. Nevertheless, the idea of incorporating shape reconstruction into 3D keypoint detection is under-explored. We argue that this is restricted by former problem formulations. To this end, a novel unsupervised paradigm named SNAKE is proposed, which is short for shape-aware neural 3D keypoint field. Similar to recent coordinate-based radiance or distance field, our network takes 3D coordinates as inputs and predicts implicit shape indicators and keypoint saliency simultaneously, thus naturally entangling 3D keypoint detection and shape reconstruction. We achieve superior performance on various public benchmarks, including standalone object datasets ModelNet40, KeypointNet, SMPL meshes and scene-level datasets 3DMatch and Redwood. Intrinsic shape awareness brings several advantages as follows. (1) SNAKE generates 3D keypoints consistent with human semantic annotation, even without such supervision. (2) SNAKE outperforms counterparts in terms of repeatability, especially when the input point clouds are down-sampled. (3) the generated keypoints allow accurate geometric registration, notably in a zero-shot setting. Codes are available at https://github.com/zhongcl-thu/SNAKE", "paper_url": "http://arxiv.org/abs/2206.01724v1", "pdf_url": "http://arxiv.org/pdf/2206.01724v1", "repo_url": "https://github.com/zhongcl-thu/snake"}, "2206.01720": {"publish_time": "2022-06-03", "title": "Revisiting the \"Video\" in Video-Language Understanding", "author": "Shyamal Buch et.al.", "abstract": "What makes a video task uniquely suited for videos, beyond what can be understood from a single image? Building on recent progress in self-supervised image-language models, we revisit this question in the context of video and language tasks. We propose the atemporal probe (ATP), a new model for video-language analysis which provides a stronger bound on the baseline accuracy of multimodal models constrained by image-level understanding. By applying this model to standard discriminative video and language tasks, such as video question answering and text-to-video retrieval, we characterize the limitations and potential of current video-language benchmarks. We find that understanding of event temporality is often not necessary to achieve strong or state-of-the-art performance, even compared with recent large-scale video-language models and in contexts intended to benchmark deeper video-level understanding. We also demonstrate how ATP can improve both video-language dataset and model design. We describe a technique for leveraging ATP to better disentangle dataset subsets with a higher concentration of temporally challenging data, improving benchmarking efficacy for causal and temporal understanding. Further, we show that effectively integrating ATP into full video-level temporal models can improve efficiency and state-of-the-art accuracy.", "paper_url": "http://arxiv.org/abs/2206.01720v1", "pdf_url": "http://arxiv.org/pdf/2206.01720v1", "repo_url": null}, "2206.01718": {"publish_time": "2022-06-03", "title": "A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge", "author": "Dustin Schwenk et.al.", "abstract": "The Visual Question Answering (VQA) task aspires to provide a meaningful testbed for the development of AI models that can jointly reason over visual and natural language inputs. Despite a proliferation of VQA datasets, this goal is hindered by a set of common limitations. These include a reliance on relatively simplistic questions that are repetitive in both concepts and linguistic structure, little world knowledge needed outside of the paired image, and limited reasoning required to arrive at the correct answer. We introduce A-OKVQA, a crowdsourced dataset composed of a diverse set of about 25K questions requiring a broad base of commonsense and world knowledge to answer. In contrast to the existing knowledge-based VQA datasets, the questions generally cannot be answered by simply querying a knowledge base, and instead require some form of commonsense reasoning about the scene depicted in the image. We demonstrate the potential of this new dataset through a detailed analysis of its contents and baseline performance measurements over a variety of state-of-the-art vision-language models. Project page: http://a-okvqa.allenai.org/", "paper_url": "http://arxiv.org/abs/2206.01718v1", "pdf_url": "http://arxiv.org/pdf/2206.01718v1", "repo_url": null}, "2206.01714": {"publish_time": "2022-06-03", "title": "Compositional Visual Generation with Composable Diffusion Models", "author": "Nan Liu et.al.", "abstract": "Large text-guided diffusion models, such as DALLE-2, are able to generate stunning photorealistic images given natural language descriptions. While such models are highly flexible, they struggle to understand the composition of certain concepts, such as confusing the attributes of different objects or relations between objects. In this paper, we propose an alternative structured approach for compositional generation using diffusion models. An image is generated by composing a set of diffusion models, with each of them modeling a certain component of the image. To do this, we interpret diffusion models as energy-based models in which the data distributions defined by the energy functions may be explicitly combined. The proposed method can generate scenes at test time that are substantially more complex than those seen in training, composing sentence descriptions, object relations, human facial attributes, and even generalizing to new combinations that are rarely seen in the real world. We further illustrate how our approach may be used to compose pre-trained text-guided diffusion models and generate photorealistic images containing all the details described in the input descriptions, including the binding of certain object attributes that have been shown difficult for DALLE-2. These results point to the effectiveness of the proposed method in promoting structured generalization for visual generation.", "paper_url": "http://arxiv.org/abs/2206.01714v1", "pdf_url": "http://arxiv.org/pdf/2206.01714v1", "repo_url": null}, "2206.01705": {"publish_time": "2022-06-03", "title": "Gradient Obfuscation Checklist Test Gives a False Sense of Security", "author": "Nikola Popovic et.al.", "abstract": "One popular group of defense techniques against adversarial attacks is based on injecting stochastic noise into the network. The main source of robustness of such stochastic defenses however is often due to the obfuscation of the gradients, offering a false sense of security. Since most of the popular adversarial attacks are optimization-based, obfuscated gradients reduce their attacking ability, while the model is still susceptible to stronger or specifically tailored adversarial attacks. Recently, five characteristics have been identified, which are commonly observed when the improvement in robustness is mainly caused by gradient obfuscation. It has since become a trend to use these five characteristics as a sufficient test, to determine whether or not gradient obfuscation is the main source of robustness. However, these characteristics do not perfectly characterize all existing cases of gradient obfuscation, and therefore can not serve as a basis for a conclusive test. In this work, we present a counterexample, showing this test is not sufficient for concluding that gradient obfuscation is not the main cause of improvements in robustness.", "paper_url": "http://arxiv.org/abs/2206.01705v1", "pdf_url": "http://arxiv.org/pdf/2206.01705v1", "repo_url": null}, "2206.02780": {"publish_time": "2022-06-06", "title": "GenSDF: Two-Stage Learning of Generalizable Signed Distance Functions", "author": "Gene Chou et.al.", "abstract": "We investigate the generalization capabilities of neural signed distance functions (SDFs) for learning 3D object representations for unseen and unlabeled point clouds. Existing methods can fit SDFs to a handful of object classes and boast fine detail or fast inference speeds, but do not generalize well to unseen shapes. We introduce a two-stage semi-supervised meta-learning approach that transfers shape priors from labeled to unlabeled data to reconstruct unseen object categories. The first stage uses an episodic training scheme to simulate training on unlabeled data and meta-learns initial shape priors. The second stage then introduces unlabeled data with disjoint classes in a semi-supervised scheme to diversify these priors and achieve generalization. We assess our method on both synthetic data and real collected point clouds. Experimental results and analysis validate that our approach outperforms existing neural SDF methods and is capable of robust zero-shot inference on 100+ unseen classes. Code can be found at https://github.com/princeton-computational-imaging/gensdf.", "paper_url": "http://arxiv.org/abs/2206.02780v1", "pdf_url": "http://arxiv.org/pdf/2206.02780v1", "repo_url": null}, "2206.02779": {"publish_time": "2022-06-06", "title": "Blended Latent Diffusion", "author": "Omri Avrahami et.al.", "abstract": "The tremendous progress in neural image generation, coupled with the emergence of seemingly omnipotent vision-language models has finally enabled text-based interfaces for creating and editing images. Handling generic images requires a diverse underlying generative model, hence the latest works utilize diffusion models, which were shown to surpass GANs in terms of diversity. One major drawback of diffusion models, however, is their relatively slow inference time. In this paper, we present an accelerated solution to the task of local text-driven editing of generic images, where the desired edits are confined to a user-provided mask. Our solution leverages a recent text-to-image Latent Diffusion Model (LDM), which speeds up diffusion by operating in a lower-dimensional latent space. We first convert the LDM into a local image editor by incorporating Blended Diffusion into it. Next we propose an optimization-based solution for the inherent inability of this LDM to accurately reconstruct images. Finally, we address the scenario of performing local edits using thin masks. We evaluate our method against the available baselines both qualitatively and quantitatively and demonstrate that in addition to being faster, our method achieves better precision than the baselines while mitigating some of their artifacts. Project page is available at https://omriavrahami.com/blended-latent-diffusion-page/", "paper_url": "http://arxiv.org/abs/2206.02779v1", "pdf_url": "http://arxiv.org/pdf/2206.02779v1", "repo_url": null}, "2206.02777": {"publish_time": "2022-06-06", "title": "Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation", "author": "Feng Li et.al.", "abstract": "In this paper we present Mask DINO, a unified object detection and segmentation framework. Mask DINO extends DINO (DETR with Improved Denoising Anchor Boxes) by adding a mask prediction branch which supports all image segmentation tasks (instance, panoptic, and semantic). It makes use of the query embeddings from DINO to dot-product a high-resolution pixel embedding map to predict a set of binary masks. Some key components in DINO are extended for segmentation through a shared architecture and training process. Mask DINO is simple, efficient, scalable, and benefits from joint large-scale detection and segmentation datasets. Our experiments show that Mask DINO significantly outperforms all existing specialized segmentation methods, both on a ResNet-50 backbone and a pre-trained model with SwinL backbone. Notably, Mask DINO establishes the best results to date on instance segmentation (54.5 AP on COCO), panoptic segmentation (59.4 PQ on COCO), and semantic segmentation (60.8 mIoU on ADE20K). Code will be avaliable at \\url{https://github.com/IDEACVR/MaskDINO}.", "paper_url": "http://arxiv.org/abs/2206.02777v1", "pdf_url": "http://arxiv.org/pdf/2206.02777v1", "repo_url": null}, "2206.02776": {"publish_time": "2022-06-06", "title": "Volumetric Disentanglement for 3D Scene Manipulation", "author": "Sagie Benaim et.al.", "abstract": "Recently, advances in differential volumetric rendering enabled significant breakthroughs in the photo-realistic and fine-detailed reconstruction of complex 3D scenes, which is key for many virtual reality applications. However, in the context of augmented reality, one may also wish to effect semantic manipulations or augmentations of objects within a scene. To this end, we propose a volumetric framework for (i) disentangling or separating, the volumetric representation of a given foreground object from the background, and (ii) semantically manipulating the foreground object, as well as the background. Our framework takes as input a set of 2D masks specifying the desired foreground object for training views, together with the associated 2D views and poses, and produces a foreground-background disentanglement that respects the surrounding illumination, reflections, and partial occlusions, which can be applied to both training and novel views. Our method enables the separate control of pixel color and depth as well as 3D similarity transformations of both the foreground and background objects. We subsequently demonstrate the applicability of our framework on a number of downstream manipulation tasks including object camouflage, non-negative 3D object inpainting, 3D object translation, 3D object inpainting, and 3D text-based object manipulation. Full results are given in our project webpage at https://sagiebenaim.github.io/volumetric-disentanglement/", "paper_url": "http://arxiv.org/abs/2206.02776v1", "pdf_url": "http://arxiv.org/pdf/2206.02776v1", "repo_url": null}, "2206.02770": {"publish_time": "2022-06-06", "title": "Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts", "author": "Basil Mustafa et.al.", "abstract": "Large sparsely-activated models have obtained excellent performance in multiple domains. However, such models are typically trained on a single modality at a time. We present the Language-Image MoE, LIMoE, a sparse mixture of experts model capable of multimodal learning. LIMoE accepts both images and text simultaneously, while being trained using a contrastive loss. MoEs are a natural fit for a multimodal backbone, since expert layers can learn an appropriate partitioning of modalities. However, new challenges arise; in particular, training stability and balanced expert utilization, for which we propose an entropy-based regularization scheme. Across multiple scales, we demonstrate remarkable performance improvement over dense models of equivalent computational cost. LIMoE-L/16 trained comparably to CLIP-L/14 achieves 78.6% zero-shot ImageNet accuracy (vs. 76.2%), and when further scaled to H/14 (with additional data) it achieves 84.1%, comparable to state-of-the-art methods which use larger custom per-modality backbones and pre-training schemes. We analyse the quantitative and qualitative behavior of LIMoE, and demonstrate phenomena such as differing treatment of the modalities and the organic emergence of modality-specific experts.", "paper_url": "http://arxiv.org/abs/2206.02770v1", "pdf_url": "http://arxiv.org/pdf/2206.02770v1", "repo_url": null}, "2206.03484": {"publish_time": "2022-06-07", "title": "Detection Hub: Unifying Object Detection Datasets via Query Adaptation on Language Embedding", "author": "Lingchen Meng et.al.", "abstract": "Leveraging large-scale data can introduce performance gains on many computer vision tasks. Unfortunately, this does not happen in object detection when training a single model under multiple datasets together. We observe two main obstacles: taxonomy difference and bounding box annotation inconsistency, which introduces domain gaps in different datasets that prevents us from joint training. In this paper, we show that these two challenges can be effectively addressed by simply adapting object queries on language embedding of categories per dataset. We design a detection hub to dynamically adapt queries on category embedding based on the different distributions of datasets. Unlike previous methods attempted to learn a joint embedding for all datasets, our adaptation method can utilize the language embedding as semantic centers for common categories, while learning the semantic bias towards specific categories belonging to different datasets to handle annotation differences and make up the domain gaps. These novel improvements enable us to end-to-end train a single detector on multiple datasets simultaneously to fully take their advantages. Further experiments on joint training on multiple datasets demonstrate the significant performance gains over separate individual fine-tuned detectors.", "paper_url": "http://arxiv.org/abs/2206.03484v1", "pdf_url": "http://arxiv.org/pdf/2206.03484v1", "repo_url": null}, "2206.03480": {"publish_time": "2022-06-07", "title": "SHRED: 3D Shape Region Decomposition with Learned Local Operations", "author": "R. Kenny Jones et.al.", "abstract": "We present SHRED, a method for 3D SHape REgion Decomposition. SHRED takes a 3D point cloud as input and uses learned local operations to produce a segmentation that approximates fine-grained part instances. We endow SHRED with three decomposition operations: splitting regions, fixing the boundaries between regions, and merging regions together. Modules are trained independently and locally, allowing SHRED to generate high-quality segmentations for categories not seen during training. We train and evaluate SHRED with fine-grained segmentations from PartNet; using its merge-threshold hyperparameter, we show that SHRED produces segmentations that better respect ground-truth annotations compared with baseline methods, at any desired decomposition granularity. Finally, we demonstrate that SHRED is useful for downstream applications, out-performing all baselines on zero-shot fine-grained part instance segmentation and few-shot fine-grained semantic segmentation when combined with methods that learn to label shape regions.", "paper_url": "http://arxiv.org/abs/2206.03480v1", "pdf_url": "http://arxiv.org/pdf/2206.03480v1", "repo_url": null}, "2206.03461": {"publish_time": "2022-06-07", "title": "Fast Unsupervised Brain Anomaly Detection and Segmentation with Diffusion Models", "author": "Walter H. L. Pinaya et.al.", "abstract": "Deep generative models have emerged as promising tools for detecting arbitrary anomalies in data, dispensing with the necessity for manual labelling. Recently, autoregressive transformers have achieved state-of-the-art performance for anomaly detection in medical imaging. Nonetheless, these models still have some intrinsic weaknesses, such as requiring images to be modelled as 1D sequences, the accumulation of errors during the sampling process, and the significant inference times associated with transformers. Denoising diffusion probabilistic models are a class of non-autoregressive generative models recently shown to produce excellent samples in computer vision (surpassing Generative Adversarial Networks), and to achieve log-likelihoods that are competitive with transformers while having fast inference times. Diffusion models can be applied to the latent representations learnt by autoencoders, making them easily scalable and great candidates for application to high dimensional data, such as medical images. Here, we propose a method based on diffusion models to detect and segment anomalies in brain imaging. By training the models on healthy data and then exploring its diffusion and reverse steps across its Markov chain, we can identify anomalous areas in the latent space and hence identify anomalies in the pixel space. Our diffusion models achieve competitive performance compared with autoregressive approaches across a series of experiments with 2D CT and MRI data involving synthetic and real pathological lesions with much reduced inference times, making their usage clinically viable.", "paper_url": "http://arxiv.org/abs/2206.03461v1", "pdf_url": "http://arxiv.org/pdf/2206.03461v1", "repo_url": null}, "2206.03452": {"publish_time": "2022-06-07", "title": "Can CNNs Be More Robust Than Transformers?", "author": "Zeyu Wang et.al.", "abstract": "The recent success of Vision Transformers is shaking the long dominance of Convolutional Neural Networks (CNNs) in image recognition for a decade. Specifically, in terms of robustness on out-of-distribution samples, recent research finds that Transformers are inherently more robust than CNNs, regardless of different training setups. Moreover, it is believed that such superiority of Transformers should largely be credited to their self-attention-like architectures per se. In this paper, we question that belief by closely examining the design of Transformers. Our findings lead to three highly effective architecture designs for boosting robustness, yet simple enough to be implemented in several lines of code, namely a) patchifying input images, b) enlarging kernel size, and c) reducing activation layers and normalization layers. Bringing these components together, we are able to build pure CNN architectures without any attention-like operations that is as robust as, or even more robust than, Transformers. We hope this work can help the community better understand the design of robust neural architectures. The code is publicly available at https://github.com/UCSC-VLAA/RobustCNN.", "paper_url": "http://arxiv.org/abs/2206.03452v1", "pdf_url": "http://arxiv.org/pdf/2206.03452v1", "repo_url": "https://github.com/ucsc-vlaa/robustcnn"}, "2206.03430": {"publish_time": "2022-06-07", "title": "Robot Self-Calibration Using Actuated 3D Sensors", "author": "Arne Peters et.al.", "abstract": "Both, robot and hand-eye calibration haven been object to research for decades. While current approaches manage to precisely and robustly identify the parameters of a robot's kinematic model, they still rely on external devices, such as calibration objects, markers and/or external sensors. Instead of trying to fit the recorded measurements to a model of a known object, this paper treats robot calibration as an offline SLAM problem, where scanning poses are linked to a fixed point in space by a moving kinematic chain. As such, the presented framework allows robot calibration using nothing but an arbitrary eye-in-hand depth sensor, thus enabling fully autonomous self-calibration without any external tools. My new approach is utilizes a modified version of the Iterative Closest Point algorithm to run bundle adjustment on multiple 3D recordings estimating the optimal parameters of the kinematic model. A detailed evaluation of the system is shown on a real robot with various attached 3D sensors. The presented results show that the system reaches precision comparable to a dedicated external tracking system at a fraction of its cost.", "paper_url": "http://arxiv.org/abs/2206.03430v1", "pdf_url": "http://arxiv.org/pdf/2206.03430v1", "repo_url": null}, "2206.04046": {"publish_time": "2022-06-08", "title": "Sparse Fusion Mixture-of-Experts are Domain Generalizable Learners", "author": "Bo Li et.al.", "abstract": "Domain generalization (DG) aims at learning generalizable models under distribution shifts to avoid redundantly overfitting massive training data. Previous works with complex loss design and gradient constraint have not yet led to empirical success on large-scale benchmarks. In this work, we reveal the mixture-of-experts (MoE) model's generalizability on DG by leveraging to distributively handle multiple aspects of the predictive features across domains. To this end, we propose Sparse Fusion Mixture-of-Experts (SF-MoE), which incorporates sparsity and fusion mechanisms into the MoE framework to keep the model both sparse and predictive. SF-MoE has two dedicated modules: 1) sparse block and 2) fusion block, which disentangle and aggregate the diverse learned signals of an object, respectively. Extensive experiments demonstrate that SF-MoE is a domain-generalizable learner on large-scale benchmarks. It outperforms state-of-the-art counterparts by more than 2% across 5 large-scale DG datasets (e.g., DomainNet), with the same or even lower computational costs. We further reveal the internal mechanism of SF-MoE from distributed representation perspective (e.g., visual attributes). We hope this framework could facilitate future research to push generalizable object recognition to the real world. Code and models are released at https://github.com/Luodian/SF-MoE-DG.", "paper_url": "http://arxiv.org/abs/2206.04046v1", "pdf_url": "http://arxiv.org/pdf/2206.04046v1", "repo_url": "https://github.com/luodian/sf-moe-dg"}, "2206.04042": {"publish_time": "2022-06-08", "title": "Learning Ego 3D Representation as Ray Tracing", "author": "Jiachen Lu et.al.", "abstract": "A self-driving perception model aims to extract 3D semantic representations from multiple cameras collectively into the bird's-eye-view (BEV) coordinate frame of the ego car in order to ground downstream planner. Existing perception methods often rely on error-prone depth estimation of the whole scene or learning sparse virtual 3D representations without the target geometry structure, both of which remain limited in performance and/or capability. In this paper, we present a novel end-to-end architecture for ego 3D representation learning from an arbitrary number of unconstrained camera views. Inspired by the ray tracing principle, we design a polarized grid of \"imaginary eyes\" as the learnable ego 3D representation and formulate the learning process with the adaptive attention mechanism in conjunction with the 3D-to-2D projection. Critically, this formulation allows extracting rich 3D representation from 2D images without any depth supervision, and with the built-in geometry structure consistent w.r.t. BEV. Despite its simplicity and versatility, extensive experiments on standard BEV visual tasks (e.g., camera-based 3D object detection and BEV segmentation) show that our model outperforms all state-of-the-art alternatives significantly, with an extra advantage in computational efficiency from multi-task learning.", "paper_url": "http://arxiv.org/abs/2206.04042v1", "pdf_url": "http://arxiv.org/pdf/2206.04042v1", "repo_url": null}, "2206.04040": {"publish_time": "2022-06-08", "title": "An Improved One millisecond Mobile Backbone", "author": "Pavan Kumar Anasosalu Vasu et.al.", "abstract": "Efficient neural network backbones for mobile devices are often optimized for metrics such as FLOPs or parameter count. However, these metrics may not correlate well with latency of the network when deployed on a mobile device. Therefore, we perform extensive analysis of different metrics by deploying several mobile-friendly networks on a mobile device. We identify and analyze architectural and optimization bottlenecks in recent efficient neural networks and provide ways to mitigate these bottlenecks. To this end, we design an efficient backbone MobileOne, with variants achieving an inference time under 1 ms on an iPhone12 with 75.9% top-1 accuracy on ImageNet. We show that MobileOne achieves state-of-the-art performance within the efficient architectures while being many times faster on mobile. Our best model obtains similar performance on ImageNet as MobileFormer while being 38x faster. Our model obtains 2.3% better top-1 accuracy on ImageNet than EfficientNet at similar latency. Furthermore, we show that our model generalizes to multiple tasks - image classification, object detection, and semantic segmentation with significant improvements in latency and accuracy as compared to existing efficient architectures when deployed on a mobile device.", "paper_url": "http://arxiv.org/abs/2206.04040v1", "pdf_url": "http://arxiv.org/pdf/2206.04040v1", "repo_url": null}, "2206.04029": {"publish_time": "2022-06-08", "title": "Accelerating Score-based Generative Models for High-Resolution Image Synthesis", "author": "Hengyuan Ma et.al.", "abstract": "Score-based generative models (SGMs) have recently emerged as a promising class of generative models. The key idea is to produce high-quality images by recurrently adding Gaussian noises and gradients to a Gaussian sample until converging to the target distribution, a.k.a. the diffusion sampling. To ensure stability of convergence in sampling and generation quality, however, this sequential sampling process has to take a small step size and many sampling iterations (e.g., 2000). Several acceleration methods have been proposed with focus on low-resolution generation. In this work, we consider the acceleration of high-resolution generation with SGMs, a more challenging yet more important problem. We prove theoretically that this slow convergence drawback is primarily due to the ignorance of the target distribution. Further, we introduce a novel Target Distribution Aware Sampling (TDAS) method by leveraging the structural priors in space and frequency domains. Extensive experiments on CIFAR-10, CelebA, LSUN, and FFHQ datasets validate that TDAS can consistently accelerate state-of-the-art SGMs, particularly on more challenging high resolution (1024x1024) image generation tasks by up to 18.4x, whilst largely maintaining the synthesis quality. With fewer sampling iterations, TDAS can still generate good quality images. In contrast, the existing methods degrade drastically or even fails completely", "paper_url": "http://arxiv.org/abs/2206.04029v1", "pdf_url": "http://arxiv.org/pdf/2206.04029v1", "repo_url": null}, "2206.04028": {"publish_time": "2022-06-08", "title": "CO^3: Cooperative Unsupervised 3D Representation Learning for Autonomous Driving", "author": "Runjian Chen et.al.", "abstract": "Unsupervised contrastive learning for indoor-scene point clouds has achieved great successes. However, unsupervised learning point clouds in outdoor scenes remains challenging because previous methods need to reconstruct the whole scene and capture partial views for the contrastive objective. This is infeasible in outdoor scenes with moving objects, obstacles, and sensors. In this paper, we propose CO^3, namely Cooperative Contrastive Learning and Contextual Shape Prediction, to learn 3D representation for outdoor-scene point clouds in an unsupervised manner. CO^3 has several merits compared to existing methods. (1) It utilizes LiDAR point clouds from vehicle-side and infrastructure-side to build views that differ enough but meanwhile maintain common semantic information for contrastive learning, which are more appropriate than views built by previous methods. (2) Alongside the contrastive objective, shape context prediction is proposed as pre-training goal and brings more task-relevant information for unsupervised 3D point cloud representation learning, which are beneficial when transferring the learned representation to downstream detection tasks. (3) As compared to previous methods, representation learned by CO^3 is able to be transferred to different outdoor scene dataset collected by different type of LiDAR sensors. (4) CO^3 improves current state-of-the-art methods on both Once and KITTI datasets by up to 2.58 mAP. Codes and models will be released. We believe CO^3 will facilitate understanding LiDAR point clouds in outdoor scene.", "paper_url": "http://arxiv.org/abs/2206.04028v1", "pdf_url": "http://arxiv.org/pdf/2206.04028v1", "repo_url": null}, "2206.04674": {"publish_time": "2022-06-09", "title": "Uni-Perceiver-MoE: Learning Sparse Generalist Models with Conditional MoEs", "author": "Jinguo Zhu et.al.", "abstract": "To build an artificial neural network like the biological intelligence system, recent works have unified numerous tasks into a generalist model, which can process various tasks with shared parameters and do not have any task-specific modules. While generalist models achieve promising results on various benchmarks, they have performance degradation on some tasks compared with task-specialized models. In this work, we find that interference among different tasks and modalities is the main factor to this phenomenon. To mitigate such interference, we introduce the Conditional Mixture-of-Experts (Conditional MoEs) to generalist models. Routing strategies under different levels of conditions are proposed to take both the training/inference cost and generalization ability into account. By incorporating the proposed Conditional MoEs, the recently proposed generalist model Uni-Perceiver can effectively mitigate the interference across tasks and modalities, and achieves state-of-the-art results on a series of downstream tasks via prompt tuning on 1% of downstream data. Moreover, the introduction of Conditional MoEs still holds the generalization ability of generalist models to conduct zero-shot inference on new tasks, e.g., video-text retrieval and video caption. Code and pre-trained generalist models shall be released.", "paper_url": "http://arxiv.org/abs/2206.04674v1", "pdf_url": "http://arxiv.org/pdf/2206.04674v1", "repo_url": null}, "2206.04673": {"publish_time": "2022-06-09", "title": "Neural Prompt Search", "author": "Yuanhan Zhang et.al.", "abstract": "The size of vision models has grown exponentially over the last few years, especially after the emergence of Vision Transformer. This has motivated the development of parameter-efficient tuning methods, such as learning adapter layers or visual prompt tokens, which allow a tiny portion of model parameters to be trained whereas the vast majority obtained from pre-training are frozen. However, designing a proper tuning method is non-trivial: one might need to try out a lengthy list of design choices, not to mention that each downstream dataset often requires custom designs. In this paper, we view the existing parameter-efficient tuning methods as \"prompt modules\" and propose Neural prOmpt seArcH (NOAH), a novel approach that learns, for large vision models, the optimal design of prompt modules through a neural architecture search algorithm, specifically for each downstream dataset. By conducting extensive experiments on over 20 vision datasets, we demonstrate that NOAH (i) is superior to individual prompt modules, (ii) has a good few-shot learning ability, and (iii) is domain-generalizable. The code and models are available at https://github.com/Davidzhangyuanhan/NOAH.", "paper_url": "http://arxiv.org/abs/2206.04673v1", "pdf_url": "http://arxiv.org/pdf/2206.04673v1", "repo_url": "https://github.com/Davidzhangyuanhan/NOAH"}, "2206.04671": {"publish_time": "2022-06-09", "title": "Open Challenges in Deep Stereo: the Booster Dataset", "author": "Pierluigi Zama Ramirez et.al.", "abstract": "We present a novel high-resolution and challenging stereo dataset framing indoor scenes annotated with dense and accurate ground-truth disparities. Peculiar to our dataset is the presence of several specular and transparent surfaces, i.e. the main causes of failures for state-of-the-art stereo networks. Our acquisition pipeline leverages a novel deep space-time stereo framework which allows for easy and accurate labeling with sub-pixel precision. We release a total of 419 samples collected in 64 different scenes and annotated with dense ground-truth disparities. Each sample include a high-resolution pair (12 Mpx) as well as an unbalanced pair (Left: 12 Mpx, Right: 1.1 Mpx). Additionally, we provide manually annotated material segmentation masks and 15K unlabeled samples. We evaluate state-of-the-art deep networks based on our dataset, highlighting their limitations in addressing the open challenges in stereo and drawing hints for future research.", "paper_url": "http://arxiv.org/abs/2206.04671v1", "pdf_url": "http://arxiv.org/pdf/2206.04671v1", "repo_url": null}, "2206.04670": {"publish_time": "2022-06-09", "title": "PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies", "author": "Guocheng Qian et.al.", "abstract": "PointNet++ is one of the most influential neural architectures for point cloud understanding. Although the accuracy of PointNet++ has been largely surpassed by recent networks such as PointMLP and Point Transformer, we find that a large portion of the performance gain is due to improved training strategies, i.e. data augmentation and optimization techniques, and increased model sizes rather than architectural innovations. Thus, the full potential of PointNet++ has yet to be explored. In this work, we revisit the classical PointNet++ through a systematic study of model training and scaling strategies, and offer two major contributions. First, we propose a set of improved training strategies that significantly improve PointNet++ performance. For example, we show that, without any change in architecture, the overall accuracy (OA) of PointNet++ on ScanObjectNN object classification can be raised from 77.9\\% to 86.1\\%, even outperforming state-of-the-art PointMLP. Second, we introduce an inverted residual bottleneck design and separable MLPs into PointNet++ to enable efficient and effective model scaling and propose PointNeXt, the next version of PointNets. PointNeXt can be flexibly scaled up and outperforms state-of-the-art methods on both 3D classification and segmentation tasks. For classification, PointNeXt reaches an overall accuracy of $87.7\\%$ on ScanObjectNN, surpassing PointMLP by $2.3\\%$, while being $10 \\times$ faster in inference. For semantic segmentation, PointNeXt establishes a new state-of-the-art performance with $74.9\\%$ mean IoU on S3DIS (6-fold cross-validation), being superior to the recent Point Transformer. The code and models are available at https://github.com/guochengqian/pointnext.", "paper_url": "http://arxiv.org/abs/2206.04670v1", "pdf_url": "http://arxiv.org/pdf/2206.04670v1", "repo_url": "https://github.com/guochengqian/pointnext"}, "2206.04669": {"publish_time": "2022-06-09", "title": "Beyond RGB: Scene-Property Synthesis with Neural Radiance Fields", "author": "Mingtong Zhang et.al.", "abstract": "Comprehensive 3D scene understanding, both geometrically and semantically, is important for real-world applications such as robot perception. Most of the existing work has focused on developing data-driven discriminative models for scene understanding. This paper provides a new approach to scene understanding, from a synthesis model perspective, by leveraging the recent progress on implicit 3D representation and neural rendering. Building upon the great success of Neural Radiance Fields (NeRFs), we introduce Scene-Property Synthesis with NeRF (SS-NeRF) that is able to not only render photo-realistic RGB images from novel viewpoints, but also render various accurate scene properties (e.g., appearance, geometry, and semantics). By doing so, we facilitate addressing a variety of scene understanding tasks under a unified framework, including semantic segmentation, surface normal estimation, reshading, keypoint detection, and edge detection. Our SS-NeRF framework can be a powerful tool for bridging generative learning and discriminative learning, and thus be beneficial to the investigation of a wide range of interesting problems, such as studying task relationships within a synthesis paradigm, transferring knowledge to novel tasks, facilitating downstream discriminative tasks as ways of data augmentation, and serving as auto-labeller for data creation.", "paper_url": "http://arxiv.org/abs/2206.04669v1", "pdf_url": "http://arxiv.org/pdf/2206.04669v1", "repo_url": null}, "2206.05266": {"publish_time": "2022-06-10", "title": "Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?", "author": "Xiang Li et.al.", "abstract": "We investigate whether self-supervised learning (SSL) can improve online reinforcement learning (RL) from pixels. We extend the contrastive reinforcement learning framework (e.g., CURL) that jointly optimizes SSL and RL losses and conduct an extensive amount of experiments with various self-supervised losses. Our observations suggest that the existing SSL framework for RL fails to bring meaningful improvement over the baselines only taking advantage of image augmentation when the same amount of data and augmentation is used. We further perform an evolutionary search to find the optimal combination of multiple self-supervised losses for RL, but find that even such a loss combination fails to meaningfully outperform the methods that only utilize carefully designed image augmentations. Often, the use of self-supervised losses under the existing framework lowered RL performances. We evaluate the approach in multiple different environments including a real-world robot environment and confirm that no single self-supervised loss or image augmentation method can dominate all environments and that the current framework for joint optimization of SSL and RL is limited. Finally, we empirically investigate the pretraining framework for SSL + RL and the properties of representations learned with different approaches.", "paper_url": "http://arxiv.org/abs/2206.05266v1", "pdf_url": "http://arxiv.org/pdf/2206.05266v1", "repo_url": null}, "2206.05263": {"publish_time": "2022-06-10", "title": "Causal Balancing for Domain Generalization", "author": "Xinyi Wang et.al.", "abstract": "While machine learning models rapidly advance the state-of-the-art on various real-world tasks, out-of-domain (OOD) generalization remains a challenging problem given the vulnerability of these models to spurious correlations. While current domain generalization methods usually focus on enforcing certain invariance properties across different domains by new loss function designs, we propose a balanced mini-batch sampling strategy to reduce the domain-specific spurious correlations in the observed training distributions. More specifically, we propose a two-phased method that 1) identifies the source of spurious correlations, and 2) builds balanced mini-batches free from spurious correlations by matching on the identified source. We provide an identifiability guarantee of the source of spuriousness and show that our proposed approach provably samples from a balanced, spurious-free distribution over all training environments. Experiments are conducted on three computer vision datasets with documented spurious correlations, demonstrating empirically that our balanced mini-batch sampling strategy improves the performance of four different established domain generalization model baselines compared to the random mini-batch sampling strategy.", "paper_url": "http://arxiv.org/abs/2206.05263v1", "pdf_url": "http://arxiv.org/pdf/2206.05263v1", "repo_url": null}, "2206.05260": {"publish_time": "2022-06-10", "title": "Balanced Product of Experts for Long-Tailed Recognition", "author": "Emanuel Sanchez Aimar et.al.", "abstract": "Many real-world recognition problems suffer from an imbalanced or long-tailed label distribution. Those distributions make representation learning more challenging due to limited generalization over the tail classes. If the test distribution differs from the training distribution, e.g. uniform versus long-tailed, the problem of the distribution shift needs to be addressed. To this aim, recent works have extended softmax cross-entropy using margin modifications, inspired by Bayes' theorem. In this paper, we generalize several approaches with a Balanced Product of Experts (BalPoE), which combines a family of models with different test-time target distributions to tackle the imbalance in the data. The proposed experts are trained in a single stage, either jointly or independently, and fused seamlessly into a BalPoE. We show that BalPoE is Fisher consistent for minimizing the balanced error and perform extensive experiments to validate the effectiveness of our approach. Finally, we investigate the effect of Mixup in this setting, discovering that regularization is a key ingredient for learning calibrated experts. Our experiments show that a regularized BalPoE can perform remarkably well in test accuracy and calibration metrics, leading to state-of-the-art results on CIFAR-100-LT, ImageNet-LT, and iNaturalist-2018 datasets. The code will be made publicly available upon paper acceptance.", "paper_url": "http://arxiv.org/abs/2206.05260v1", "pdf_url": "http://arxiv.org/pdf/2206.05260v1", "repo_url": null}, "2206.05259": {"publish_time": "2022-06-10", "title": "Is Self-Supervised Learning More Robust Than Supervised Learning?", "author": "Yuanyi Zhong et.al.", "abstract": "Self-supervised contrastive learning is a powerful tool to learn visual representation without labels. Prior work has primarily focused on evaluating the recognition accuracy of various pre-training algorithms, but has overlooked other behavioral aspects. In addition to accuracy, distributional robustness plays a critical role in the reliability of machine learning models. We design and conduct a series of robustness tests to quantify the behavioral differences between contrastive learning and supervised learning to downstream or pre-training data distribution changes. These tests leverage data corruptions at multiple levels, ranging from pixel-level gamma distortion to patch-level shuffling and to dataset-level distribution shift. Our tests unveil intriguing robustness behaviors of contrastive and supervised learning. On the one hand, under downstream corruptions, we generally observe that contrastive learning is surprisingly more robust than supervised learning. On the other hand, under pre-training corruptions, we find contrastive learning vulnerable to patch shuffling and pixel intensity change, yet less sensitive to dataset-level distribution change. We attempt to explain these results through the role of data augmentation and feature space properties. Our insight has implications in improving the downstream robustness of supervised learning.", "paper_url": "http://arxiv.org/abs/2206.05259v1", "pdf_url": "http://arxiv.org/pdf/2206.05259v1", "repo_url": null}, "2206.05257": {"publish_time": "2022-06-10", "title": "Explaining Image Classifiers Using Contrastive Counterfactuals in Generative Latent Spaces", "author": "Kamran Alipour et.al.", "abstract": "Despite their high accuracies, modern complex image classifiers cannot be trusted for sensitive tasks due to their unknown decision-making process and potential biases. Counterfactual explanations are very effective in providing transparency for these black-box algorithms. Nevertheless, generating counterfactuals that can have a consistent impact on classifier outputs and yet expose interpretable feature changes is a very challenging task. We introduce a novel method to generate causal and yet interpretable counterfactual explanations for image classifiers using pretrained generative models without any re-training or conditioning. The generative models in this technique are not bound to be trained on the same data as the target classifier. We use this framework to obtain contrastive and causal sufficiency and necessity scores as global explanations for black-box classifiers. On the task of face attribute classification, we show how different attributes influence the classifier output by providing both causal and contrastive feature attributions, and the corresponding counterfactual images.", "paper_url": "http://arxiv.org/abs/2206.05257v1", "pdf_url": "http://arxiv.org/pdf/2206.05257v1", "repo_url": null}, "2206.06363": {"publish_time": "2022-06-13", "title": "Discovering Object Masks with Transformers for Unsupervised Semantic Segmentation", "author": "Wouter Van Gansbeke et.al.", "abstract": "The task of unsupervised semantic segmentation aims to cluster pixels into semantically meaningful groups. Specifically, pixels assigned to the same cluster should share high-level semantic properties like their object or part category. This paper presents MaskDistill: a novel framework for unsupervised semantic segmentation based on three key ideas. First, we advocate a data-driven strategy to generate object masks that serve as a pixel grouping prior for semantic segmentation. This approach omits handcrafted priors, which are often designed for specific scene compositions and limit the applicability of competing frameworks. Second, MaskDistill clusters the object masks to obtain pseudo-ground-truth for training an initial object segmentation model. Third, we leverage this model to filter out low-quality object masks. This strategy mitigates the noise in our pixel grouping prior and results in a clean collection of masks which we use to train a final segmentation model. By combining these components, we can considerably outperform previous works for unsupervised semantic segmentation on PASCAL (+11% mIoU) and COCO (+4% mask AP50). Interestingly, as opposed to existing approaches, our framework does not latch onto low-level image cues and is not limited to object-centric datasets. The code and models will be made available.", "paper_url": "http://arxiv.org/abs/2206.06363v1", "pdf_url": "http://arxiv.org/pdf/2206.06363v1", "repo_url": "https://github.com/wvangansbeke/MaskDistill"}, "2206.06360": {"publish_time": "2022-06-13", "title": "ARF: Artistic Radiance Fields", "author": "Kai Zhang et.al.", "abstract": "We present a method for transferring the artistic features of an arbitrary style image to a 3D scene. Previous methods that perform 3D stylization on point clouds or meshes are sensitive to geometric reconstruction errors for complex real-world scenes. Instead, we propose to stylize the more robust radiance field representation. We find that the commonly used Gram matrix-based loss tends to produce blurry results without faithful brushstrokes, and introduce a nearest neighbor-based loss that is highly effective at capturing style details while maintaining multi-view consistency. We also propose a novel deferred back-propagation method to enable optimization of memory-intensive radiance fields using style losses defined on full-resolution rendered images. Our extensive evaluation demonstrates that our method outperforms baselines by generating artistic appearance that more closely resembles the style image. Please check our project page for video results and open-source implementations: https://www.cs.cornell.edu/projects/arf/ .", "paper_url": "http://arxiv.org/abs/2206.06360v1", "pdf_url": "http://arxiv.org/pdf/2206.06360v1", "repo_url": null}, "2206.06359": {"publish_time": "2022-06-13", "title": "EnergyMatch: Energy-based Pseudo-Labeling for Semi-Supervised Learning", "author": "Zhuoran Yu et.al.", "abstract": "Recent state-of-the-art methods in semi-supervised learning (SSL) combine consistency regularization with confidence-based pseudo-labeling. To obtain high-quality pseudo-labels, a high confidence threshold is typically adopted. However, it has been shown that softmax-based confidence scores in deep networks can be arbitrarily high for samples far from the training data, and thus, the pseudo-labels for even high-confidence unlabeled samples may still be unreliable. In this work, we present a new perspective of pseudo-labeling: instead of relying on model confidence, we instead measure whether an unlabeled sample is likely to be \"in-distribution\"; i.e., close to the current training data. To classify whether an unlabeled sample is \"in-distribution\" or \"out-of-distribution\", we adopt the energy score from out-of-distribution detection literature. As training progresses and more unlabeled samples become in-distribution and contribute to training, the combined labeled and pseudo-labeled data can better approximate the true distribution to improve the model. Experiments demonstrate that our energy-based pseudo-labeling method, albeit conceptually simple, significantly outperforms confidence-based methods on imbalanced SSL benchmarks, and achieves competitive performance on class-balanced data. For example, it produces a 4-6% absolute accuracy improvement on CIFAR10-LT when the imbalance ratio is higher than 50. When combined with state-of-the-art long-tailed SSL methods, further improvements are attained.", "paper_url": "http://arxiv.org/abs/2206.06359v1", "pdf_url": "http://arxiv.org/pdf/2206.06359v1", "repo_url": null}, "2206.06346": {"publish_time": "2022-06-13", "title": "Bringing Image Scene Structure to Video via Frame-Clip Consistency of Object Tokens", "author": "Elad Ben-Avraham et.al.", "abstract": "Recent action recognition models have achieved impressive results by integrating objects, their locations and interactions. However, obtaining dense structured annotations for each frame is tedious and time-consuming, making these methods expensive to train and less scalable. At the same time, if a small set of annotated images is available, either within or outside the domain of interest, how could we leverage these for a video downstream task? We propose a learning framework StructureViT (SViT for short), which demonstrates how utilizing the structure of a small number of images only available during training can improve a video model. SViT relies on two key insights. First, as both images and videos contain structured information, we enrich a transformer model with a set of \\emph{object tokens} that can be used across images and videos. Second, the scene representations of individual frames in video should \"align\" with those of still images. This is achieved via a \\emph{Frame-Clip Consistency} loss, which ensures the flow of structured information between images and videos. We explore a particular instantiation of scene structure, namely a \\emph{Hand-Object Graph}, consisting of hands and objects with their locations as nodes, and physical relations of contact/no-contact as edges. SViT shows strong performance improvements on multiple video understanding tasks and datasets; and it wins first place in the Ego4D CVPR'22 Object State Localization challenge. For code and pretrained models, visit the project page at \\url{https://eladb3.github.io/SViT/}", "paper_url": "http://arxiv.org/abs/2206.06346v1", "pdf_url": "http://arxiv.org/pdf/2206.06346v1", "repo_url": null}, "2206.06341": {"publish_time": "2022-06-13", "title": "Unsupervised inter-frame motion correction for whole-body dynamic PET using convolutional long short-term memory in a convolutional neural network", "author": "Xueqi Guo et.al.", "abstract": "Subject motion in whole-body dynamic PET introduces inter-frame mismatch and seriously impacts parametric imaging. Traditional non-rigid registration methods are generally computationally intense and time-consuming. Deep learning approaches are promising in achieving high accuracy with fast speed, but have yet been investigated with consideration for tracer distribution changes or in the whole-body scope. In this work, we developed an unsupervised automatic deep learning-based framework to correct inter-frame body motion. The motion estimation network is a convolutional neural network with a combined convolutional long short-term memory layer, fully utilizing dynamic temporal features and spatial information. Our dataset contains 27 subjects each under a 90-min FDG whole-body dynamic PET scan. With 9-fold cross-validation, compared with both traditional and deep learning baselines, we demonstrated that the proposed network obtained superior performance in enhanced qualitative and quantitative spatial alignment between parametric $K_{i}$ and $V_{b}$ images and in significantly reduced parametric fitting error. We also showed the potential of the proposed motion correction method for impacting downstream analysis of the estimated parametric images, improving the ability to distinguish malignant from benign hypermetabolic regions of interest. Once trained, the motion estimation inference time of our proposed network was around 460 times faster than the conventional registration baseline, showing its potential to be easily applied in clinical settings.", "paper_url": "http://arxiv.org/abs/2206.06341v1", "pdf_url": "http://arxiv.org/pdf/2206.06341v1", "repo_url": null}, "2206.07047": {"publish_time": "2022-06-14", "title": "RGB-Multispectral Matching: Dataset, Learning Methodology, Evaluation", "author": "Fabio Tosi et.al.", "abstract": "We address the problem of registering synchronized color (RGB) and multi-spectral (MS) images featuring very different resolution by solving stereo matching correspondences. Purposely, we introduce a novel RGB-MS dataset framing 13 different scenes in indoor environments and providing a total of 34 image pairs annotated with semi-dense, high-resolution ground-truth labels in the form of disparity maps. To tackle the task, we propose a deep learning architecture trained in a self-supervised manner by exploiting a further RGB camera, required only during training data acquisition. In this setup, we can conveniently learn cross-modal matching in the absence of ground-truth labels by distilling knowledge from an easier RGB-RGB matching task based on a collection of about 11K unlabeled image triplets. Experiments show that the proposed pipeline sets a good performance bar (1.16 pixels average registration error) for future research on this novel, challenging task.", "paper_url": "http://arxiv.org/abs/2206.07047v1", "pdf_url": "http://arxiv.org/pdf/2206.07047v1", "repo_url": null}, "2206.07045": {"publish_time": "2022-06-14", "title": "ReCo: Retrieve and Co-segment for Zero-shot Transfer", "author": "Gyungin Shin et.al.", "abstract": "Semantic segmentation has a broad range of applications, but its real-world impact has been significantly limited by the prohibitive annotation costs necessary to enable deployment. Segmentation methods that forgo supervision can side-step these costs, but exhibit the inconvenient requirement to provide labelled examples from the target distribution to assign concept names to predictions. An alternative line of work in language-image pre-training has recently demonstrated the potential to produce models that can both assign names across large vocabularies of concepts and enable zero-shot transfer for classification, but do not demonstrate commensurate segmentation abilities. In this work, we strive to achieve a synthesis of these two approaches that combines their strengths. We leverage the retrieval abilities of one such language-image pre-trained model, CLIP, to dynamically curate training sets from unlabelled images for arbitrary collections of concept names, and leverage the robust correspondences offered by modern image representations to co-segment entities among the resulting collections. The synthetic segment collections are then employed to construct a segmentation model (without requiring pixel labels) whose knowledge of concepts is inherited from the scalable pre-training process of CLIP. We demonstrate that our approach, termed Retrieve and Co-segment (ReCo) performs favourably to unsupervised segmentation approaches while inheriting the convenience of nameable predictions and zero-shot transfer. We also demonstrate ReCo's ability to generate specialist segmenters for extremely rare objects.", "paper_url": "http://arxiv.org/abs/2206.07045v1", "pdf_url": "http://arxiv.org/pdf/2206.07045v1", "repo_url": "https://github.com/NoelShin/reco"}, "2206.07038": {"publish_time": "2022-06-14", "title": "AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos", "author": "Yanze Wu et.al.", "abstract": "This paper studies the problem of real-world video super-resolution (VSR) for animation videos, and reveals three key improvements for practical animation VSR. First, recent real-world super-resolution approaches typically rely on degradation simulation using basic operators without any learning capability, such as blur, noise, and compression. In this work, we propose to learn such basic operators from real low-quality animation videos, and incorporate the learned ones into the degradation generation pipeline. Such neural-network-based basic operators could help to better capture the distribution of real degradations. Second, a large-scale high-quality animation video dataset, AVC, is built to facilitate comprehensive training and evaluations for animation VSR. Third, we further investigate an efficient multi-scale network structure. It takes advantage of the efficiency of unidirectional recurrent networks and the effectiveness of sliding-window-based methods. Thanks to the above delicate designs, our method, AnimeSR, is capable of restoring real-world low-quality animation videos effectively and efficiently, achieving superior performance to previous state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2206.07038v1", "pdf_url": "http://arxiv.org/pdf/2206.07038v1", "repo_url": null}, "2206.07036": {"publish_time": "2022-06-14", "title": "Accurate 3D Body Shape Regression using Metric and Semantic Attributes", "author": "Vasileios Choutas et.al.", "abstract": "While methods that regress 3D human meshes from images have progressed rapidly, the estimated body shapes often do not capture the true human shape. This is problematic since, for many applications, accurate body shape is as important as pose. The key reason that body shape accuracy lags pose accuracy is the lack of data. While humans can label 2D joints, and these constrain 3D pose, it is not so easy to \"label\" 3D body shape. Since paired data with images and 3D body shape are rare, we exploit two sources of information: (1) we collect internet images of diverse \"fashion\" models together with a small set of anthropometric measurements; (2) we collect linguistic shape attributes for a wide range of 3D body meshes and the model images. Taken together, these datasets provide sufficient constraints to infer dense 3D shape. We exploit the anthropometric measurements and linguistic shape attributes in several novel ways to train a neural network, called SHAPY, that regresses 3D human pose and shape from an RGB image. We evaluate SHAPY on public benchmarks, but note that they either lack significant body shape variation, ground-truth shape, or clothing variation. Thus, we collect a new dataset for evaluating 3D human shape estimation, called HBW, containing photos of \"Human Bodies in the Wild\" for which we have ground-truth 3D body scans. On this new benchmark, SHAPY significantly outperforms state-of-the-art methods on the task of 3D body shape estimation. This is the first demonstration that 3D body shape regression from images can be trained from easy-to-obtain anthropometric measurements and linguistic shape attributes. Our model and data are available at: shapy.is.tue.mpg.de", "paper_url": "http://arxiv.org/abs/2206.07036v1", "pdf_url": "http://arxiv.org/pdf/2206.07036v1", "repo_url": null}, "2206.07028": {"publish_time": "2022-06-14", "title": "Learning 3D Object Shape and Layout without 3D Supervision", "author": "Georgia Gkioxari et.al.", "abstract": "A 3D scene consists of a set of objects, each with a shape and a layout giving their position in space. Understanding 3D scenes from 2D images is an important goal, with applications in robotics and graphics. While there have been recent advances in predicting 3D shape and layout from a single image, most approaches rely on 3D ground truth for training which is expensive to collect at scale. We overcome these limitations and propose a method that learns to predict 3D shape and layout for objects without any ground truth shape or layout information: instead we rely on multi-view images with 2D supervision which can more easily be collected at scale. Through extensive experiments on 3D Warehouse, Hypersim, and ScanNet we demonstrate that our approach scales to large datasets of realistic images, and compares favorably to methods relying on 3D ground truth. On Hypersim and ScanNet where reliable 3D ground truth is not available, our approach outperforms supervised approaches trained on smaller and less diverse datasets.", "paper_url": "http://arxiv.org/abs/2206.07028v1", "pdf_url": "http://arxiv.org/pdf/2206.07028v1", "repo_url": null}, "2206.07710": {"publish_time": "2022-06-15", "title": "PlanarRecon: Real-time 3D Plane Detection and Reconstruction from Posed Monocular Videos", "author": "Yiming Xie et.al.", "abstract": "We present PlanarRecon -- a novel framework for globally coherent detection and reconstruction of 3D planes from a posed monocular video. Unlike previous works that detect planes in 2D from a single image, PlanarRecon incrementally detects planes in 3D for each video fragment, which consists of a set of key frames, from a volumetric representation of the scene using neural networks. A learning-based tracking and fusion module is designed to merge planes from previous fragments to form a coherent global plane reconstruction. Such design allows PlanarRecon to integrate observations from multiple views within each fragment and temporal information across different ones, resulting in an accurate and coherent reconstruction of the scene abstraction with low-polygonal geometry. Experiments show that the proposed approach achieves state-of-the-art performances on the ScanNet dataset while being real-time.", "paper_url": "http://arxiv.org/abs/2206.07710v1", "pdf_url": "http://arxiv.org/pdf/2206.07710v1", "repo_url": null}, "2206.07707": {"publish_time": "2022-06-15", "title": "Variable Bitrate Neural Fields", "author": "Towaki Takikawa et.al.", "abstract": "Neural approximations of scalar and vector fields, such as signed distance functions and radiance fields, have emerged as accurate, high-quality representations. State-of-the-art results are obtained by conditioning a neural approximation with a lookup from trainable feature grids that take on part of the learning task and allow for smaller, more efficient neural networks. Unfortunately, these feature grids usually come at the cost of significantly increased memory consumption compared to stand-alone neural network models. We present a dictionary method for compressing such feature grids, reducing their memory consumption by up to 100x and permitting a multiresolution representation which can be useful for out-of-core streaming. We formulate the dictionary optimization as a vector-quantized auto-decoder problem which lets us learn end-to-end discrete neural representations in a space where no direct supervision is available and with dynamic topology and structure. Our source code will be available at https://github.com/nv-tlabs/vqad.", "paper_url": "http://arxiv.org/abs/2206.07707v1", "pdf_url": "http://arxiv.org/pdf/2206.07707v1", "repo_url": "https://github.com/nv-tlabs/vqad"}, "2206.07706": {"publish_time": "2022-06-15", "title": "Masked Frequency Modeling for Self-Supervised Visual Pre-Training", "author": "Jiahao Xie et.al.", "abstract": "We present Masked Frequency Modeling (MFM), a unified frequency-domain-based approach for self-supervised pre-training of visual models. Instead of randomly inserting mask tokens to the input embeddings in the spatial domain, in this paper, we shift the perspective to the frequency domain. Specifically, MFM first masks out a portion of frequency components of the input image and then predicts the missing frequencies on the frequency spectrum. Our key insight is that predicting masked components in the frequency domain is more ideal to reveal underlying image patterns rather than predicting masked patches in the spatial domain, due to the heavy spatial redundancy. Our findings suggest that with the right configuration of mask-and-predict strategy, both the structural information within high-frequency components and the low-level statistics among low-frequency counterparts are useful in learning good representations. For the first time, MFM demonstrates that, for both ViT and CNN, a simple non-Siamese framework can learn meaningful representations even using none of the following: (i) extra data, (ii) extra model, (iii) mask token. Experimental results on ImageNet and several robustness benchmarks show the competitive performance and advanced robustness of MFM compared with recent masked image modeling approaches. Furthermore, we also comprehensively investigate the effectiveness of classical image restoration tasks for representation learning from a unified frequency perspective and reveal their intriguing relations with our MFM approach. Project page: https://www.mmlab-ntu.com/project/mfm/index.html.", "paper_url": "http://arxiv.org/abs/2206.07706v1", "pdf_url": "http://arxiv.org/pdf/2206.07706v1", "repo_url": null}, "2206.07705": {"publish_time": "2022-06-15", "title": "LET-3D-AP: Longitudinal Error Tolerant 3D Average Precision for Camera-Only 3D Detection", "author": "Wei-Chih Hung et.al.", "abstract": "The popular object detection metric 3D Average Precision (3D AP) relies on the intersection over union between predicted bounding boxes and ground truth bounding boxes. However, depth estimation based on cameras has limited accuracy, which may cause otherwise reasonable predictions that suffer from such longitudinal localization errors to be treated as false positives and false negatives. We therefore propose variants of the popular 3D AP metric that are designed to be more permissive with respect to depth estimation errors. Specifically, our novel longitudinal error tolerant metrics, LET-3D-AP and LET-3D-APL, allow longitudinal localization errors of the predicted bounding boxes up to a given tolerance. The proposed metrics have been used in the Waymo Open Dataset 3D Camera-Only Detection Challenge. We believe that they will facilitate advances in the field of camera-only 3D detection by providing more informative performance signals.", "paper_url": "http://arxiv.org/abs/2206.07705v1", "pdf_url": "http://arxiv.org/pdf/2206.07705v1", "repo_url": "https://github.com/waymo-research/waymo-open-dataset"}, "2206.07704": {"publish_time": "2022-06-15", "title": "Waymo Open Dataset: Panoramic Video Panoptic Segmentation", "author": "Jieru Mei et.al.", "abstract": "Panoptic image segmentation is the computer vision task of finding groups of pixels in an image and assigning semantic classes and object instance identifiers to them. Research in image segmentation has become increasingly popular due to its critical applications in robotics and autonomous driving. The research community thereby relies on publicly available benchmark dataset to advance the state-of-the-art in computer vision. Due to the high costs of densely labeling the images, however, there is a shortage of publicly available ground truth labels that are suitable for panoptic segmentation. The high labeling costs also make it challenging to extend existing datasets to the video domain and to multi-camera setups. We therefore present the Waymo Open Dataset: Panoramic Video Panoptic Segmentation Dataset, a large-scale dataset that offers high-quality panoptic segmentation labels for autonomous driving. We generate our dataset using the publicly available Waymo Open Dataset, leveraging the diverse set of camera images. Our labels are consistent over time for video processing and consistent across multiple cameras mounted on the vehicles for full panoramic scene understanding. Specifically, we offer labels for 28 semantic categories and 2,860 temporal sequences that were captured by five cameras mounted on autonomous vehicles driving in three different geographical locations, leading to a total of 100k labeled camera images. To the best of our knowledge, this makes our dataset an order of magnitude larger than existing datasets that offer video panoptic segmentation labels. We further propose a new benchmark for Panoramic Video Panoptic Segmentation and establish a number of strong baselines based on the DeepLab family of models. We will make the benchmark and the code publicly available. Find the dataset at https://waymo.com/open.", "paper_url": "http://arxiv.org/abs/2206.07704v1", "pdf_url": "http://arxiv.org/pdf/2206.07704v1", "repo_url": null}, "2206.08368": {"publish_time": "2022-06-16", "title": "Unbiased 4D: Monocular 4D Reconstruction with a Neural Deformation Model", "author": "Erik C. M. Johnson et.al.", "abstract": "Capturing general deforming scenes is crucial for many computer graphics and vision applications, and it is especially challenging when only a monocular RGB video of the scene is available. Competing methods assume dense point tracks, 3D templates, large-scale training datasets, or only capture small-scale deformations. In contrast to those, our method, Ub4D, makes none of these assumptions while outperforming the previous state of the art in challenging scenarios. Our technique includes two new, in the context of non-rigid 3D reconstruction, components, i.e., 1) A coordinate-based and implicit neural representation for non-rigid scenes, which enables an unbiased reconstruction of dynamic scenes, and 2) A novel dynamic scene flow loss, which enables the reconstruction of larger deformations. Results on our new dataset, which will be made publicly available, demonstrate the clear improvement over the state of the art in terms of surface reconstruction accuracy and robustness to large deformations. Visit the project page https://4dqv.mpi-inf.mpg.de/Ub4D/.", "paper_url": "http://arxiv.org/abs/2206.08368v1", "pdf_url": "http://arxiv.org/pdf/2206.08368v1", "repo_url": null}, "2206.08367": {"publish_time": "2022-06-16", "title": "SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation", "author": "Tao Sun et.al.", "abstract": "Adapting to a continuously evolving environment is a safety-critical challenge inevitably faced by all autonomous driving systems. Existing image and video driving datasets, however, fall short of capturing the mutable nature of the real world. In this paper, we introduce the largest multi-task synthetic dataset for autonomous driving, SHIFT. It presents discrete and continuous shifts in cloudiness, rain and fog intensity, time of day, and vehicle and pedestrian density. Featuring a comprehensive sensor suite and annotations for several mainstream perception tasks, SHIFT allows investigating the degradation of a perception system performance at increasing levels of domain shift, fostering the development of continuous adaptation strategies to mitigate this problem and assess model robustness and generality. Our dataset and benchmark toolkit are publicly available at www.vis.xyz/shift.", "paper_url": "http://arxiv.org/abs/2206.08367v1", "pdf_url": "http://arxiv.org/pdf/2206.08367v1", "repo_url": null}, "2206.08365": {"publish_time": "2022-06-16", "title": "Virtual Correspondence: Humans as a Cue for Extreme-View Geometry", "author": "Wei-Chiu Ma et.al.", "abstract": "Recovering the spatial layout of the cameras and the geometry of the scene from extreme-view images is a longstanding challenge in computer vision. Prevailing 3D reconstruction algorithms often adopt the image matching paradigm and presume that a portion of the scene is co-visible across images, yielding poor performance when there is little overlap among inputs. In contrast, humans can associate visible parts in one image to the corresponding invisible components in another image via prior knowledge of the shapes. Inspired by this fact, we present a novel concept called virtual correspondences (VCs). VCs are a pair of pixels from two images whose camera rays intersect in 3D. Similar to classic correspondences, VCs conform with epipolar geometry; unlike classic correspondences, VCs do not need to be co-visible across views. Therefore VCs can be established and exploited even if images do not overlap. We introduce a method to find virtual correspondences based on humans in the scene. We showcase how VCs can be seamlessly integrated with classic bundle adjustment to recover camera poses across extreme views. Experiments show that our method significantly outperforms state-of-the-art camera pose estimation methods in challenging scenarios and is comparable in the traditional densely captured setup. Our approach also unleashes the potential of multiple downstream tasks such as scene reconstruction from multi-view stereo and novel view synthesis in extreme-view scenarios.", "paper_url": "http://arxiv.org/abs/2206.08365v1", "pdf_url": "http://arxiv.org/pdf/2206.08365v1", "repo_url": null}, "2206.08362": {"publish_time": "2022-06-16", "title": "Unified Fourier-based Kernel and Nonlinearity Design for Equivariant Networks on Homogeneous Spaces", "author": "Yinshuang Xu et.al.", "abstract": "We introduce a unified framework for group equivariant networks on homogeneous spaces derived from a Fourier perspective. We address the case of feature fields being tensor valued before and after a convolutional layer. We present a unified derivation of kernels via the Fourier domain by taking advantage of the sparsity of Fourier coefficients of the lifted feature fields. The sparsity emerges when the stabilizer subgroup of the homogeneous space is a compact Lie group. We further introduce an activation method via an elementwise nonlinearity on the regular representation after lifting and projecting back to the field through an equivariant convolution. We show that other methods treating features as the Fourier coefficients in the stabilizer subgroup are special cases of our activation. Experiments on $SO(3)$ and $SE(3)$ show state-of-the-art performance in spherical vector field regression, point cloud classification, and molecular completion.", "paper_url": "http://arxiv.org/abs/2206.08362v1", "pdf_url": "http://arxiv.org/pdf/2206.08362v1", "repo_url": null}, "2206.08361": {"publish_time": "2022-06-16", "title": "Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields", "author": "Keqiang Sun et.al.", "abstract": "Capitalizing on the recent advances in image generation models, existing controllable face image synthesis methods are able to generate high-fidelity images with some levels of controllability, e.g., controlling the shapes, expressions, textures, and poses of the generated face images. However, these methods focus on 2D image generative models, which are prone to producing inconsistent face images under large expression and pose changes. In this paper, we propose a new NeRF-based conditional 3D face synthesis framework, which enables 3D controllability over the generated face images by imposing explicit 3D conditions from 3D face priors. At its core is a conditional Generative Occupancy Field (cGOF) that effectively enforces the shape of the generated face to commit to a given 3D Morphable Model (3DMM) mesh. To achieve accurate control over fine-grained 3D face shapes of the synthesized image, we additionally incorporate a 3D landmark loss as well as a volume warping loss into our synthesis algorithm. Experiments validate the effectiveness of the proposed method, which is able to generate high-fidelity face images and shows more precise 3D controllability than state-of-the-art 2D-based controllable face synthesis methods. Find code and demo at https://keqiangsun.github.io/projects/cgof.", "paper_url": "http://arxiv.org/abs/2206.08361v1", "pdf_url": "http://arxiv.org/pdf/2206.08361v1", "repo_url": null}, "2206.08929": {"publish_time": "2022-06-17", "title": "TAVA: Template-free Animatable Volumetric Actors", "author": "Ruilong Li et.al.", "abstract": "Coordinate-based volumetric representations have the potential to generate photo-realistic virtual avatars from images. However, virtual avatars also need to be controllable even to a novel pose that may not have been observed. Traditional techniques, such as LBS, provide such a function; yet it usually requires a hand-designed body template, 3D scan data, and limited appearance models. On the other hand, neural representation has been shown to be powerful in representing visual details, but are under explored on deforming dynamic articulated actors. In this paper, we propose TAVA, a method to create T emplate-free Animatable Volumetric Actors, based on neural representations. We rely solely on multi-view data and a tracked skeleton to create a volumetric model of an actor, which can be animated at the test time given novel pose. Since TAVA does not require a body template, it is applicable to humans as well as other creatures such as animals. Furthermore, TAVA is designed such that it can recover accurate dense correspondences, making it amenable to content-creation and editing tasks. Through extensive experiments, we demonstrate that the proposed method generalizes well to novel poses as well as unseen views and showcase basic editing capabilities.", "paper_url": "http://arxiv.org/abs/2206.08929v1", "pdf_url": "http://arxiv.org/pdf/2206.08929v1", "repo_url": null}, "2206.08927": {"publish_time": "2022-06-17", "title": "Cross-task Attention Mechanism for Dense Multi-task Learning", "author": "Ivan Lopes et.al.", "abstract": "Multi-task learning has recently become a promising solution for a comprehensive understanding of complex scenes. Not only being memory-efficient, multi-task models with an appropriate design can favor exchange of complementary signals across tasks. In this work, we jointly address 2D semantic segmentation, and two geometry-related tasks, namely dense depth, surface normal estimation as well as edge estimation showing their benefit on indoor and outdoor datasets. We propose a novel multi-task learning architecture that exploits pair-wise cross-task exchange through correlation-guided attention and self-attention to enhance the average representation learning for all tasks. We conduct extensive experiments considering three multi-task setups, showing the benefit of our proposal in comparison to competitive baselines in both synthetic and real benchmarks. We also extend our method to the novel multi-task unsupervised domain adaptation setting. Our code is available at https://github.com/cv-rits/DenseMTL.", "paper_url": "http://arxiv.org/abs/2206.08927v1", "pdf_url": "http://arxiv.org/pdf/2206.08927v1", "repo_url": "https://github.com/cv-rits/densemtl"}, "2206.08920": {"publish_time": "2022-06-17", "title": "VectorMapNet: End-to-end Vectorized HD Map Learning", "author": "Yicheng Liu et.al.", "abstract": "Autonomous driving systems require a good understanding of surrounding environments, including moving obstacles and static High-Definition (HD) semantic maps. Existing methods approach the semantic map problem by offline manual annotations, which suffer from serious scalability issues. More recent learning-based methods produce dense rasterized segmentation predictions which do not include instance information of individual map elements and require heuristic post-processing that involves many hand-designed components, to obtain vectorized maps. To that end, we introduce an end-to-end vectorized HD map learning pipeline, termed VectorMapNet. VectorMapNet takes onboard sensor observations and predicts a sparse set of polylines primitives in the bird's-eye view to model the geometry of HD maps. Based on this pipeline, our method can explicitly model the spatial relation between map elements and generate vectorized maps that are friendly for downstream autonomous driving tasks without the need for post-processing. In our experiments, VectorMapNet achieves strong HD map learning performance on nuScenes dataset, surpassing previous state-of-the-art methods by 14.2 mAP. Qualitatively, we also show that VectorMapNet is capable of generating comprehensive maps and capturing more fine-grained details of road geometry. To the best of our knowledge, VectorMapNet is the first work designed toward end-to-end vectorized HD map learning problems.", "paper_url": "http://arxiv.org/abs/2206.08920v1", "pdf_url": "http://arxiv.org/pdf/2206.08920v1", "repo_url": null}, "2206.08919": {"publish_time": "2022-06-17", "title": "VLMixer: Unpaired Vision-Language Pre-training via Cross-Modal CutMix", "author": "Teng Wang et.al.", "abstract": "Existing vision-language pre-training (VLP) methods primarily rely on paired image-text datasets, which are either annotated by enormous human labors, or crawled from the internet followed by elaborate data cleaning techniques. To reduce the dependency on well-aligned image-text pairs, it is promising to directly leverage the large-scale text-only and image-only corpora. This paper proposes a data augmentation method, namely cross-modal CutMix (CMC), for implicit cross-modal alignment learning in unpaired VLP. Specifically, CMC transforms natural sentences from the textual view into a multi-modal view, where visually-grounded words in a sentence are randomly replaced by diverse image patches with similar semantics. There are several appealing proprieties of the proposed CMC. First, it enhances the data diversity while keeping the semantic meaning intact for tackling problems where the aligned data are scarce; Second, by attaching cross-modal noise on uni-modal data, it guides models to learn token-level interactions across modalities for better denoising. Furthermore, we present a new unpaired VLP method, dubbed as VLMixer, that integrates CMC with contrastive learning to pull together the uni-modal and multi-modal views for better instance-level alignments among different modalities. Extensive experiments on five downstream tasks show that VLMixer could surpass previous state-of-the-art unpaired VLP methods.", "paper_url": "http://arxiv.org/abs/2206.08919v1", "pdf_url": "http://arxiv.org/pdf/2206.08919v1", "repo_url": "https://github.com/ttengwang/vlmixer"}, "2206.08916": {"publish_time": "2022-06-17", "title": "Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks", "author": "Jiasen Lu et.al.", "abstract": "We propose Unified-IO, a model that performs a large variety of AI tasks spanning classical computer vision tasks, including pose estimation, object detection, depth estimation and image generation, vision-and-language tasks such as region captioning and referring expression comprehension, to natural language processing tasks such as question answering and paraphrasing. Developing a single unified model for such a large variety of tasks poses unique challenges due to the heterogeneous inputs and outputs pertaining to each task, including RGB images, per-pixel maps, binary masks, bounding boxes, and language. We achieve this unification by homogenizing every supported input and output into a sequence of discrete vocabulary tokens. This common representation across all tasks allows us to train a single transformer-based architecture, jointly on over 80 diverse datasets in the vision and language fields. Unified-IO is the first model capable of performing all 7 tasks on the GRIT benchmark and produces strong results across 16 diverse benchmarks like NYUv2-Depth, ImageNet, VQA2.0, OK-VQA, Swig, VizWizGround, BoolQ, and SciTail, with no task or benchmark specific fine-tuning. Demos for Unified-IO are available at https://unified-io.allenai.org.", "paper_url": "http://arxiv.org/abs/2206.08916v1", "pdf_url": "http://arxiv.org/pdf/2206.08916v1", "repo_url": null}, "2206.10590": {"publish_time": "2022-06-21", "title": "Temporally Consistent Semantic Video Editing", "author": "Yiran Xu et.al.", "abstract": "Generative adversarial networks (GANs) have demonstrated impressive image generation quality and semantic editing capability of real images, e.g., changing object classes, modifying attributes, or transferring styles. However, applying these GAN-based editing to a video independently for each frame inevitably results in temporal flickering artifacts. We present a simple yet effective method to facilitate temporally coherent video editing. Our core idea is to minimize the temporal photometric inconsistency by optimizing both the latent code and the pre-trained generator. We evaluate the quality of our editing on different domains and GAN inversion techniques and show favorable results against the baselines.", "paper_url": "http://arxiv.org/abs/2206.10590v1", "pdf_url": "http://arxiv.org/pdf/2206.10590v1", "repo_url": null}, "2206.10589": {"publish_time": "2022-06-21", "title": "EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications", "author": "Muhammad Maaz et.al.", "abstract": "In the pursuit of achieving ever-increasing accuracy, large and complex neural networks are usually developed. Such models demand high computational resources and therefore cannot be deployed on edge devices. It is of great interest to build resource-efficient general purpose networks due to their usefulness in several application areas. In this work, we strive to effectively combine the strengths of both CNN and Transformer models and propose a new efficient hybrid architecture EdgeNeXt. Specifically in EdgeNeXt, we introduce split depth-wise transpose attention (SDTA) encoder that splits input tensors into multiple channel groups and utilizes depth-wise convolution along with self-attention across channel dimensions to implicitly increase the receptive field and encode multi-scale features. Our extensive experiments on classification, detection and segmentation tasks, reveal the merits of the proposed approach, outperforming state-of-the-art methods with comparatively lower compute requirements. Our EdgeNeXt model with 1.3M parameters achieves 71.2\\% top-1 accuracy on ImageNet-1K, outperforming MobileViT with an absolute gain of 2.2\\% with 28\\% reduction in FLOPs. Further, our EdgeNeXt model with 5.6M parameters achieves 79.4\\% top-1 accuracy on ImageNet-1K. The code and models are publicly available at https://t.ly/_Vu9.", "paper_url": "http://arxiv.org/abs/2206.10589v1", "pdf_url": "http://arxiv.org/pdf/2206.10589v1", "repo_url": null}, "2206.10587": {"publish_time": "2022-06-21", "title": "Guiding Visual Attention in Deep Convolutional Neural Networks Based on Human Eye Movements", "author": "Leonard E. van Dyck et.al.", "abstract": "Deep Convolutional Neural Networks (DCNNs) were originally inspired by principles of biological vision, have evolved into best current computational models of object recognition, and consequently indicate strong architectural and functional parallelism with the ventral visual pathway throughout comparisons with neuroimaging and neural time series data. As recent advances in deep learning seem to decrease this similarity, computational neuroscience is challenged to reverse-engineer the biological plausibility to obtain useful models. While previous studies have shown that biologically inspired architectures are able to amplify the human-likeness of the models, in this study, we investigate a purely data-driven approach. We use human eye tracking data to directly modify training examples and thereby guide the models' visual attention during object recognition in natural images either towards or away from the focus of human fixations. We compare and validate different manipulation types (i.e., standard, human-like, and non-human-like attention) through GradCAM saliency maps against human participant eye tracking data. Our results demonstrate that the proposed guided focus manipulation works as intended in the negative direction and non-human-like models focus on significantly dissimilar image parts compared to humans. The observed effects were highly category-specific, enhanced by animacy and face presence, developed only after feedforward processing was completed, and indicated a strong influence on face detection. With this approach, however, no significantly increased human-likeness was found. Possible applications of overt visual attention in DCNNs and further implications for theories of face detection are discussed.", "paper_url": "http://arxiv.org/abs/2206.10587v1", "pdf_url": "http://arxiv.org/pdf/2206.10587v1", "repo_url": null}, "2206.10573": {"publish_time": "2022-06-21", "title": "H&E-based Computational Biomarker Enables Universal EGFR Screening for Lung Adenocarcinoma", "author": "Gabriele Campanella et.al.", "abstract": "Lung cancer is the leading cause of cancer death worldwide, with lung adenocarcinoma being the most prevalent form of lung cancer. EGFR positive lung adenocarcinomas have been shown to have high response rates to TKI therapy, underlying the essential nature of molecular testing for lung cancers. Despite current guidelines consider testing necessary, a large portion of patients are not routinely profiled, resulting in millions of people not receiving the optimal treatment for their lung cancer. Sequencing is the gold standard for molecular testing of EGFR mutations, but it can take several weeks for results to come back, which is not ideal in a time constrained scenario. The development of alternative screening tools capable of detecting EGFR mutations quickly and cheaply while preserving tissue for sequencing could help reduce the amount of sub-optimally treated patients. We propose a multi-modal approach which integrates pathology images and clinical variables to predict EGFR mutational status achieving an AUC of 84% on the largest clinical cohort to date. Such a computational model could be deployed at large at little additional cost. Its clinical application could reduce the number of patients who receive sub-optimal treatments by 53.1% in China, and up to 96.6% in the US.", "paper_url": "http://arxiv.org/abs/2206.10573v1", "pdf_url": "http://arxiv.org/pdf/2206.10573v1", "repo_url": null}, "2206.10571": {"publish_time": "2022-06-21", "title": "Toward Unpaired Multi-modal Medical Image Segmentation via Learning Structured Semantic Consistency", "author": "Jie Yang et.al.", "abstract": "Integrating multi-modal data to improve medical image analysis has received great attention recently. However, due to the modal discrepancy, how to use a single model to process the data from multiple modalities is still an open issue. In this paper, we propose a novel scheme to achieve better pixel-level segmentation for unpaired multi-modal medical images. Different from previous methods which adopted both modality-specific and modality-shared modules to accommodate the appearance variance of different modalities while extracting the common semantic information, our method is based on a single Transformer with a carefully designed External Attention Module (EAM) to learn the structured semantic consistency (i.e. semantic class representations and their correlations) between modalities in the training phase. In practice, the above-mentioned structured semantic consistency across modalities can be progressively achieved by implementing the consistency regularization at the modality-level and image-level respectively. The proposed EAMs are adopted to learn the semantic consistency for different scale representations and can be discarded once the model is optimized. Therefore, during the testing phase, we only need to maintain one Transformer for all modal predictions, which nicely balances the model's ease of use and simplicity. To demonstrate the effectiveness of the proposed method, we conduct the experiments on two medical image segmentation scenarios: (1) cardiac structure segmentation, and (2) abdominal multi-organ segmentation. Extensive results show that the proposed method outperforms the state-of-the-art methods by a wide margin, and even achieves competitive performance with extremely limited training samples (e.g., 1 or 3 annotated CT or MRI images) for one specific modality.", "paper_url": "http://arxiv.org/abs/2206.10571v1", "pdf_url": "http://arxiv.org/pdf/2206.10571v1", "repo_url": "https://github.com/yangjie18/lssc"}, "2206.11253": {"publish_time": "2022-06-22", "title": "Towards Robust Blind Face Restoration with Codebook Lookup Transformer", "author": "Shangchen Zhou et.al.", "abstract": "Blind face restoration is a highly ill-posed problem that often requires auxiliary guidance to 1) improve the mapping from degraded inputs to desired outputs, or 2) complement high-quality details lost in the inputs. In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of restoration mapping by casting blind face restoration as a code prediction task, while providing rich visual atoms for generating high-quality faces. Under this paradigm, we propose a Transformer-based prediction network, named CodeFormer, to model global composition and context of the low-quality faces for code prediction, enabling the discovery of natural faces that closely approximate the target faces even when the inputs are severely degraded. To enhance the adaptiveness for different degradation, we also propose a controllable feature transformation module that allows a flexible trade-off between fidelity and quality. Thanks to the expressive codebook prior and global modeling, CodeFormer outperforms state of the arts in both quality and fidelity, showing superior robustness to degradation. Extensive experimental results on synthetic and real-world datasets verify the effectiveness of our method.", "paper_url": "http://arxiv.org/abs/2206.11253v1", "pdf_url": "http://arxiv.org/pdf/2206.11253v1", "repo_url": null}, "2206.11251": {"publish_time": "2022-06-22", "title": "Behavior Transformers: Cloning $k$ modes with one stone", "author": "Nur Muhammad Mahi Shafiullah et.al.", "abstract": "While behavior learning has made impressive progress in recent times, it lags behind computer vision and natural language processing due to its inability to leverage large, human-generated datasets. Human behaviors have wide variance, multiple modes, and human demonstrations typically do not come with reward labels. These properties limit the applicability of current methods in Offline RL and Behavioral Cloning to learn from large, pre-collected datasets. In this work, we present Behavior Transformer (BeT), a new technique to model unlabeled demonstration data with multiple modes. BeT retrofits standard transformer architectures with action discretization coupled with a multi-task action correction inspired by offset prediction in object detection. This allows us to leverage the multi-modal modeling ability of modern transformers to predict multi-modal continuous actions. We experimentally evaluate BeT on a variety of robotic manipulation and self-driving behavior datasets. We show that BeT significantly improves over prior state-of-the-art work on solving demonstrated tasks while capturing the major modes present in the pre-collected datasets. Finally, through an extensive ablation study, we analyze the importance of every crucial component in BeT. Videos of behavior generated by BeT are available at https://notmahi.github.io/bet", "paper_url": "http://arxiv.org/abs/2206.11251v1", "pdf_url": "http://arxiv.org/pdf/2206.11251v1", "repo_url": "https://github.com/notmahi/bet"}, "2206.11250": {"publish_time": "2022-06-22", "title": "Depth-aware Glass Surface Detection with Cross-modal Context Mining", "author": "Jiaying Lin et.al.", "abstract": "Glass surfaces are becoming increasingly ubiquitous as modern buildings tend to use a lot of glass panels. This however poses substantial challenges on the operations of autonomous systems such as robots, self-driving cars and drones, as the glass panels can become transparent obstacles to the navigation.Existing works attempt to exploit various cues, including glass boundary context or reflections, as a prior. However, they are all based on input RGB images.We observe that the transmission of 3D depth sensor light through glass surfaces often produces blank regions in the depth maps, which can offer additional insights to complement the RGB image features for glass surface detection. In this paper, we propose a novel framework for glass surface detection by incorporating RGB-D information, with two novel modules: (1) a cross-modal context mining (CCM) module to adaptively learn individual and mutual context features from RGB and depth information, and (2) a depth-missing aware attention (DAA) module to explicitly exploit spatial locations where missing depths occur to help detect the presence of glass surfaces. In addition, we propose a large-scale RGB-D glass surface detection dataset, called \\textit{RGB-D GSD}, for RGB-D glass surface detection. Our dataset comprises 3,009 real-world RGB-D glass surface images with precise annotations. Extensive experimental results show that our proposed model outperforms state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2206.11250v1", "pdf_url": "http://arxiv.org/pdf/2206.11250v1", "repo_url": null}, "2206.11215": {"publish_time": "2022-06-22", "title": "Correct and Certify: A New Approach to Self-Supervised 3D-Object Perception", "author": "Rajat Talak et.al.", "abstract": "We consider an object pose estimation and model fitting problem, where - given a partial point cloud of an object - the goal is to estimate the object pose by fitting a CAD model to the sensor data. We solve this problem by combining (i) a semantic keypoint-based pose estimation model, (ii) a novel self-supervised training approach, and (iii) a certification procedure, that not only verifies whether the output produced by the model is correct or not, but also flags uniqueness of the produced solution. The semantic keypoint detector model is initially trained in simulation and does not perform well on real-data due to the domain gap. Our self-supervised training procedure uses a corrector and a certification module to improve the detector. The corrector module corrects the detected keypoints to compensate for the domain gap, and is implemented as a declarative layer, for which we develop a simple differentiation rule. The certification module declares whether the corrected output produced by the model is certifiable (i.e. correct) or not. At each iteration, the approach optimizes over the loss induced only by the certifiable input-output pairs. As training progresses, we see that the fraction of outputs that are certifiable increases, eventually reaching near $100\\%$ in many cases. We also introduce the notion of strong certifiability wherein the model can determine if the predicted object model fit is unique or not. The detected semantic keypoints help us implement this in the forward pass. We conduct extensive experiments to evaluate the performance of the corrector, the certification, and the proposed self-supervised training using the ShapeNet and YCB datasets, and show the proposed approach achieves performance comparable to fully supervised baselines while not requiring pose or keypoint supervision on real data.", "paper_url": "http://arxiv.org/abs/2206.11215v1", "pdf_url": "http://arxiv.org/pdf/2206.11215v1", "repo_url": null}, "2206.11212": {"publish_time": "2022-06-22", "title": "VisFIS: Visual Feature Importance Supervision with Right-for-the-Right-Reason Objectives", "author": "Zhuofan Ying et.al.", "abstract": "Many past works aim to improve visual reasoning in models by supervising feature importance (estimated by model explanation techniques) with human annotations such as highlights of important image regions. However, recent work has shown that performance gains from feature importance (FI) supervision for Visual Question Answering (VQA) tasks persist even with random supervision, suggesting that these methods do not meaningfully align model FI with human FI. In this paper, we show that model FI supervision can meaningfully improve VQA model accuracy as well as performance on several Right-for-the-Right-Reason (RRR) metrics by optimizing for four key model objectives: (1) accurate predictions given limited but sufficient information (Sufficiency); (2) max-entropy predictions given no important information (Uncertainty); (3) invariance of predictions to changes in unimportant features (Invariance); and (4) alignment between model FI explanations and human FI explanations (Plausibility). Our best performing method, Visual Feature Importance Supervision (VisFIS), outperforms strong baselines on benchmark VQA datasets in terms of both in-distribution and out-of-distribution accuracy. While past work suggests that the mechanism for improved accuracy is through improved explanation plausibility, we show that this relationship depends crucially on explanation faithfulness (whether explanations truly represent the model's internal reasoning). Predictions are more accurate when explanations are plausible and faithful, and not when they are plausible but not faithful. Lastly, we show that, surprisingly, RRR metrics are not predictive of out-of-distribution model accuracy when controlling for a model's in-distribution accuracy, which calls into question the value of these metrics for evaluating model reasoning. All supporting code is available at https://github.com/zfying/visfis", "paper_url": "http://arxiv.org/abs/2206.11212v1", "pdf_url": "http://arxiv.org/pdf/2206.11212v1", "repo_url": "https://github.com/zfying/visfis"}, "2206.11896": {"publish_time": "2022-06-23", "title": "EventNeRF: Neural Radiance Fields from a Single Colour Event Camera", "author": "Viktor Rudnev et.al.", "abstract": "Learning coordinate-based volumetric 3D scene representations such as neural radiance fields (NeRF) has been so far studied assuming RGB or RGB-D images as inputs. At the same time, it is known from the neuroscience literature that human visual system (HVS) is tailored to process asynchronous brightness changes rather than synchronous RGB images, in order to build and continuously update mental 3D representations of the surroundings for navigation and survival. Visual sensors that were inspired by HVS principles are event cameras. Thus, events are sparse and asynchronous per-pixel brightness (or colour channel) change signals. In contrast to existing works on neural 3D scene representation learning, this paper approaches the problem from a new perspective. We demonstrate that it is possible to learn NeRF suitable for novel-view synthesis in the RGB space from asynchronous event streams. Our models achieve high visual accuracy of the rendered novel views of challenging scenes in the RGB space, even though they are trained with substantially fewer data (i.e., event streams from a single event camera moving around the object) and more efficiently (due to the inherent sparsity of event streams) than the existing NeRF models trained with RGB images. We will release our datasets and the source code, see https://4dqv.mpi-inf.mpg.de/EventNeRF/.", "paper_url": "http://arxiv.org/abs/2206.11896v1", "pdf_url": "http://arxiv.org/pdf/2206.11896v1", "repo_url": null}, "2206.11895": {"publish_time": "2022-06-23", "title": "Learning Viewpoint-Agnostic Visual Representations by Recovering Tokens in 3D Space", "author": "Jinghuan Shang et.al.", "abstract": "Humans are remarkably flexible in understanding viewpoint changes due to visual cortex supporting the perception of 3D structure. In contrast, most of the computer vision models that learn visual representation from a pool of 2D images often fail to generalize over novel camera viewpoints. Recently, the vision architectures have shifted towards convolution-free architectures, visual Transformers, which operate on tokens derived from image patches. However, neither these Transformers nor 2D convolutional networks perform explicit operations to learn viewpoint-agnostic representation for visual understanding. To this end, we propose a 3D Token Representation Layer (3DTRL) that estimates the 3D positional information of the visual tokens and leverages it for learning viewpoint-agnostic representations. The key elements of 3DTRL include a pseudo-depth estimator and a learned camera matrix to impose geometric transformations on the tokens. These enable 3DTRL to recover the 3D positional information of the tokens from 2D patches. In practice, 3DTRL is easily plugged-in into a Transformer. Our experiments demonstrate the effectiveness of 3DTRL in many vision tasks including image classification, multi-view video alignment, and action recognition. The models with 3DTRL outperform their backbone Transformers in all the tasks with minimal added computation. Our project page is at https://www3.cs.stonybrook.edu/~jishang/3dtrl/3dtrl.html", "paper_url": "http://arxiv.org/abs/2206.11895v1", "pdf_url": "http://arxiv.org/pdf/2206.11895v1", "repo_url": null}, "2206.11894": {"publish_time": "2022-06-23", "title": "MaskViT: Masked Visual Pre-Training for Video Prediction", "author": "Agrim Gupta et.al.", "abstract": "The ability to predict future visual observations conditioned on past observations and motor commands can enable embodied agents to plan solutions to a variety of tasks in complex environments. This work shows that we can create good video prediction models by pre-training transformers via masked visual modeling. Our approach, named MaskViT, is based on two simple design decisions. First, for memory and training efficiency, we use two types of window attention: spatial and spatiotemporal. Second, during training, we mask a variable percentage of tokens instead of a fixed mask ratio. For inference, MaskViT generates all tokens via iterative refinement where we incrementally decrease the masking ratio following a mask scheduling function. On several datasets we demonstrate that MaskViT outperforms prior works in video prediction, is parameter efficient, and can generate high-resolution videos (256x256). Further, we demonstrate the benefits of inference speedup (up to 512x) due to iterative decoding by using MaskViT for planning on a real robot. Our work suggests that we can endow embodied agents with powerful predictive models by leveraging the general framework of masked visual modeling with minimal domain knowledge.", "paper_url": "http://arxiv.org/abs/2206.11894v1", "pdf_url": "http://arxiv.org/pdf/2206.11894v1", "repo_url": null}, "2206.11892": {"publish_time": "2022-06-23", "title": "Remote Sensing Change Detection (Segmentation) using Denoising Diffusion Probabilistic Models", "author": "Wele Gedara Chaminda Bandara et.al.", "abstract": "Human civilization has an increasingly powerful influence on the earth system, and earth observations are an invaluable tool for assessing and mitigating the negative impacts. To this end, observing precisely defined changes on Earth's surface is essential, and we propose an effective way to achieve this goal. Notably, our change detection (CD)/ segmentation method proposes a novel way to incorporate the millions of off-the-shelf, unlabeled, remote sensing images available through different earth observation programs into the training process through denoising diffusion probabilistic models. We first leverage the information from these off-the-shelf, uncurated, and unlabeled remote sensing images by using a pre-trained denoising diffusion probabilistic model and then employ the multi-scale feature representations from the diffusion model decoder to train a lightweight CD classifier to detect precise changes. The experiments performed on four publically available CD datasets show that the proposed approach achieves remarkably better results than the state-of-the-art methods in F1, IoU, and overall accuracy. Code and pre-trained models are available at: https://github.com/wgcban/ddpm-cd", "paper_url": "http://arxiv.org/abs/2206.11892v1", "pdf_url": "http://arxiv.org/pdf/2206.11892v1", "repo_url": "https://github.com/wgcban/ddpm-cd"}, "2206.11849": {"publish_time": "2022-06-23", "title": "Sample Condensation in Online Continual Learning", "author": "Mattia Sangermano et.al.", "abstract": "Online Continual learning is a challenging learning scenario where the model must learn from a non-stationary stream of data where each sample is seen only once. The main challenge is to incrementally learn while avoiding catastrophic forgetting, namely the problem of forgetting previously acquired knowledge while learning from new data. A popular solution in these scenario is to use a small memory to retain old data and rehearse them over time. Unfortunately, due to the limited memory size, the quality of the memory will deteriorate over time. In this paper we propose OLCGM, a novel replay-based continual learning strategy that uses knowledge condensation techniques to continuously compress the memory and achieve a better use of its limited size. The sample condensation step compresses old samples, instead of removing them like other replay strategies. As a result, the experiments show that, whenever the memory budget is limited compared to the complexity of the data, OLCGM improves the final accuracy compared to state-of-the-art replay strategies.", "paper_url": "http://arxiv.org/abs/2206.11849v1", "pdf_url": "http://arxiv.org/pdf/2206.11849v1", "repo_url": null}, "2206.12403": {"publish_time": "2022-06-24", "title": "ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings", "author": "Arjun Majumdar et.al.", "abstract": "We present a scalable approach for learning open-world object-goal navigation (ObjectNav) -- the task of asking a virtual robot (agent) to find any instance of an object in an unexplored environment (e.g., \"find a sink\"). Our approach is entirely zero-shot -- i.e., it does not require ObjectNav rewards or demonstrations of any kind. Instead, we train on the image-goal navigation (ImageNav) task, in which agents find the location where a picture (i.e., goal image) was captured. Specifically, we encode goal images into a multimodal, semantic embedding space to enable training semantic-goal navigation (SemanticNav) agents at scale in unannotated 3D environments (e.g., HM3D). After training, SemanticNav agents can be instructed to find objects described in free-form natural language (e.g., \"sink\", \"bathroom sink\", etc.) by projecting language goals into the same multimodal, semantic embedding space. As a result, our approach enables open-world ObjectNav. We extensively evaluate our agents on three ObjectNav datasets (Gibson, HM3D, and MP3D) and observe absolute improvements in success of 4.2% - 20.0% over existing zero-shot methods. For reference, these gains are similar or better than the 5% improvement in success between the Habitat 2020 and 2021 ObjectNav challenge winners. In an open-world setting, we discover that our agents can generalize to compound instructions with a room explicitly mentioned (e.g., \"Find a kitchen sink\") and when the target room can be inferred (e.g., \"Find a sink and a stove\").", "paper_url": "http://arxiv.org/abs/2206.12403v1", "pdf_url": "http://arxiv.org/pdf/2206.12403v1", "repo_url": null}, "2206.12396": {"publish_time": "2022-06-24", "title": "Text-Driven Stylization of Video Objects", "author": "Sebastian Loeschcke et.al.", "abstract": "We tackle the task of stylizing video objects in an intuitive and semantic manner following a user-specified text prompt. This is a challenging task as the resulting video must satisfy multiple properties: (1) it has to be temporally consistent and avoid jittering or similar artifacts, (2) the resulting stylization must preserve both the global semantics of the object and its fine-grained details, and (3) it must adhere to the user-specified text prompt. To this end, our method stylizes an object in a video according to a global target text prompt that describes the global semantics and a local target text prompt that describes the local semantics. To modify the style of an object, we harness the representational power of CLIP to get a similarity score between (1) the local target text and a set of local stylized views, and (2) a global target text and a set of stylized global views. We use a pretrained atlas decomposition network to propagate the edits in a temporally consistent manner. We demonstrate that our method can generate consistent style changes in time for a variety of objects and videos, that adhere to the specification of the target texts. We also show how varying the specificity of the target texts, and augmenting the texts with a set of prefixes results in stylizations with different levels of detail. Full results are given on our project webpage: https://sloeschcke.github.io/Text-Driven-Stylization-of-Video-Objects/", "paper_url": "http://arxiv.org/abs/2206.12396v1", "pdf_url": "http://arxiv.org/pdf/2206.12396v1", "repo_url": null}, "2206.12381": {"publish_time": "2022-06-24", "title": "Defending Backdoor Attacks on Vision Transformer via Patch Processing", "author": "Khoa D. Doan et.al.", "abstract": "Vision Transformers (ViTs) have a radically different architecture with significantly less inductive bias than Convolutional Neural Networks. Along with the improvement in performance, security and robustness of ViTs are also of great importance to study. In contrast to many recent works that exploit the robustness of ViTs against adversarial examples, this paper investigates a representative causative attack, i.e., backdoor. We first examine the vulnerability of ViTs against various backdoor attacks and find that ViTs are also quite vulnerable to existing attacks. However, we observe that the clean-data accuracy and backdoor attack success rate of ViTs respond distinctively to patch transformations before the positional encoding. Then, based on this finding, we propose an effective method for ViTs to defend both patch-based and blending-based trigger backdoor attacks via patch processing. The performances are evaluated on several benchmark datasets, including CIFAR10, GTSRB, and TinyImageNet, which show the proposed novel defense is very successful in mitigating backdoor attacks for ViTs. To the best of our knowledge, this paper presents the first defensive strategy that utilizes a unique characteristic of ViTs against backdoor attacks.", "paper_url": "http://arxiv.org/abs/2206.12381v1", "pdf_url": "http://arxiv.org/pdf/2206.12381v1", "repo_url": null}, "2206.12372": {"publish_time": "2022-06-24", "title": "QReg: On Regularization Effects of Quantization", "author": "MohammadHossein AskariHemmat et.al.", "abstract": "In this paper we study the effects of quantization in DNN training. We hypothesize that weight quantization is a form of regularization and the amount of regularization is correlated with the quantization level (precision). We confirm our hypothesis by providing analytical study and empirical results. By modeling weight quantization as a form of additive noise to weights, we explore how this noise propagates through the network at training time. We then show that the magnitude of this noise is correlated with the level of quantization. To confirm our analytical study, we performed an extensive list of experiments summarized in this paper in which we show that the regularization effects of quantization can be seen in various vision tasks and models, over various datasets. Based on our study, we propose that 8-bit quantization provides a reliable form of regularization in different vision tasks and models.", "paper_url": "http://arxiv.org/abs/2206.12372v1", "pdf_url": "http://arxiv.org/pdf/2206.12372v1", "repo_url": null}, "2206.12370": {"publish_time": "2022-06-24", "title": "Online Distillation with Mixed Sample Augmentation", "author": "Yiqing Shen et.al.", "abstract": "Mixed Sample Regularization (MSR), such as MixUp or CutMix, is a powerful data augmentation strategy to generalize convolutional neural networks. Previous empirical analysis has illustrated an orthogonal performance gain between MSR and the conventional offline Knowledge Distillation (KD). To be more specific, student networks can be enhanced with the involvement of MSR in the training stage of the sequential distillation. Yet, the interplay between MSR and online knowledge distillation, a stronger distillation paradigm, where an ensemble of peer students learn mutually from each other, remains unexplored. To bridge the gap, we make the first attempt at incorporating CutMix into online distillation, where we empirically observe a significant improvement. Encouraged by this fact, we propose an even stronger MSR specifically for online distillation, named as Cut^nMix. Furthermore, a novel online distillation framework is designed upon Cut^nMix, to enhance the distillation with feature level mutual learning and a self-ensemble teacher. Comprehensive evaluations on CIFAR10 and CIFAR100 with six network architectures show that our approach can consistently outperform state-of-the-art distillation methods.", "paper_url": "http://arxiv.org/abs/2206.12370v1", "pdf_url": "http://arxiv.org/pdf/2206.12370v1", "repo_url": null}, "2206.13502": {"publish_time": "2022-06-27", "title": "Programmatic Concept Learning for Human Motion Description and Synthesis", "author": "Sumith Kulal et.al.", "abstract": "We introduce Programmatic Motion Concepts, a hierarchical motion representation for human actions that captures both low-level motion and high-level description as motion concepts. This representation enables human motion description, interactive editing, and controlled synthesis of novel video sequences within a single framework. We present an architecture that learns this concept representation from paired video and action sequences in a semi-supervised manner. The compactness of our representation also allows us to present a low-resource training recipe for data-efficient learning. By outperforming established baselines, especially in the small data regime, we demonstrate the efficiency and effectiveness of our framework for multiple applications.", "paper_url": "http://arxiv.org/abs/2206.13502v1", "pdf_url": "http://arxiv.org/pdf/2206.13502v1", "repo_url": null}, "2206.13500": {"publish_time": "2022-06-27", "title": "Neural Neural Textures Make Sim2Real Consistent", "author": "Ryan Burgert et.al.", "abstract": "Unpaired image translation algorithms can be used for sim2real tasks, but many fail to generate temporally consistent results. We present a new approach that combines differentiable rendering with image translation to achieve temporal consistency over indefinite timescales, using surface consistency losses and \\emph{neural neural textures}. We call this algorithm TRITON (Texture Recovering Image Translation Network): an unsupervised, end-to-end, stateless sim2real algorithm that leverages the underlying 3D geometry of input scenes by generating realistic-looking learnable neural textures. By settling on a particular texture for the objects in a scene, we ensure consistency between frames statelessly. Unlike previous algorithms, TRITON is not limited to camera movements -- it can handle the movement of objects as well, making it useful for downstream tasks such as robotic manipulation.", "paper_url": "http://arxiv.org/abs/2206.13500v1", "pdf_url": "http://arxiv.org/pdf/2206.13500v1", "repo_url": null}, "2206.13499": {"publish_time": "2022-06-27", "title": "Prompting Decision Transformer for Few-Shot Policy Generalization", "author": "Mengdi Xu et.al.", "abstract": "Humans can leverage prior experience and learn novel tasks from a handful of demonstrations. In contrast to offline meta-reinforcement learning, which aims to achieve quick adaptation through better algorithm design, we investigate the effect of architecture inductive bias on the few-shot learning capability. We propose a Prompt-based Decision Transformer (Prompt-DT), which leverages the sequential modeling ability of the Transformer architecture and the prompt framework to achieve few-shot adaptation in offline RL. We design the trajectory prompt, which contains segments of the few-shot demonstrations, and encodes task-specific information to guide policy generation. Our experiments in five MuJoCo control benchmarks show that Prompt-DT is a strong few-shot learner without any extra finetuning on unseen target tasks. Prompt-DT outperforms its variants and strong meta offline RL baselines by a large margin with a trajectory prompt containing only a few timesteps. Prompt-DT is also robust to prompt length changes and can generalize to out-of-distribution (OOD) environments.", "paper_url": "http://arxiv.org/abs/2206.13499v1", "pdf_url": "http://arxiv.org/pdf/2206.13499v1", "repo_url": null}, "2206.13498": {"publish_time": "2022-06-27", "title": "Auditing Visualizations: Transparency Methods Struggle to Detect Anomalous Behavior", "author": "Jean-Stanislas Denain et.al.", "abstract": "Transparency methods such as model visualizations provide information that outputs alone might miss, since they describe the internals of neural networks. But can we trust that model explanations reflect model behavior? For instance, can they diagnose abnormal behavior such as backdoors or shape bias? To evaluate model explanations, we define a model as anomalous if it differs from a reference set of normal models, and we test whether transparency methods assign different explanations to anomalous and normal models. We find that while existing methods can detect stark anomalies such as shape bias or adversarial training, they struggle to identify more subtle anomalies such as models trained on incomplete data. Moreover, they generally fail to distinguish the inputs that induce anomalous behavior, e.g. images containing a backdoor trigger. These results reveal new blind spots in existing model explanations, pointing to the need for further method development.", "paper_url": "http://arxiv.org/abs/2206.13498v1", "pdf_url": "http://arxiv.org/pdf/2206.13498v1", "repo_url": "https://github.com/js-d/auditing-vis"}, "2206.13497": {"publish_time": "2022-06-27", "title": "Robustness Implies Generalization via Data-Dependent Generalization Bounds", "author": "Kenji Kawaguchi et.al.", "abstract": "This paper proves that robustness implies generalization via data-dependent generalization bounds. As a result, robustness and generalization are shown to be connected closely in a data-dependent manner. Our bounds improve previous bounds in two directions, to solve an open problem that has seen little development since 2010. The first is to reduce the dependence on the covering number. The second is to remove the dependence on the hypothesis space. We present several examples, including ones for lasso and deep learning, in which our bounds are provably preferable. The experiments on real-world data and theoretical models demonstrate near-exponential improvements in various situations. To achieve these improvements, we do not require additional assumptions on the unknown distribution; instead, we only incorporate an observable and computable property of the training samples. A key technical innovation is an improved concentration bound for multinomial random variables that is of independent interest beyond robustness and generalization.", "paper_url": "http://arxiv.org/abs/2206.13497v1", "pdf_url": "http://arxiv.org/pdf/2206.13497v1", "repo_url": null}, "2206.14195": {"publish_time": "2022-06-28", "title": "Pedestrian 3D Bounding Box Prediction", "author": "Saeed Saadatnejad et.al.", "abstract": "Safety is still the main issue of autonomous driving, and in order to be globally deployed, they need to predict pedestrians' motions sufficiently in advance. While there is a lot of research on coarse-grained (human center prediction) and fine-grained predictions (human body keypoints prediction), we focus on 3D bounding boxes, which are reasonable estimates of humans without modeling complex motion details for autonomous vehicles. This gives the flexibility to predict in longer horizons in real-world settings. We suggest this new problem and present a simple yet effective model for pedestrians' 3D bounding box prediction. This method follows an encoder-decoder architecture based on recurrent neural networks, and our experiments show its effectiveness in both the synthetic (JTA) and real-world (NuScenes) datasets. The learned representation has useful information to enhance the performance of other tasks, such as action anticipation. Our code is available online: https://github.com/vita-epfl/bounding-box-prediction", "paper_url": "http://arxiv.org/abs/2206.14195v1", "pdf_url": "http://arxiv.org/pdf/2206.14195v1", "repo_url": "https://github.com/vita-epfl/bounding-box-prediction"}, "2206.14180": {"publish_time": "2022-06-28", "title": "High-Resolution Virtual Try-On with Misalignment and Occlusion-Handled Conditions", "author": "Sangyun Lee et.al.", "abstract": "Image-based virtual try-on aims to synthesize an image of a person wearing a given clothing item. To solve the task, the existing methods warp the clothing item to fit the person's body and generate the segmentation map of the person wearing the item, before fusing the item with the person. However, when the warping and the segmentation generation stages operate individually without information exchange, the misalignment between the warped clothes and the segmentation map occurs, which leads to the artifacts in the final image. The information disconnection also causes excessive warping near the clothing regions occluded by the body parts, so called pixel-squeezing artifacts. To settle the issues, we propose a novel try-on condition generator as a unified module of the two stages (i.e., warping and segmentation generation stages). A newly proposed feature fusion block in the condition generator implements the information exchange, and the condition generator does not create any misalignment or pixel-squeezing artifacts. We also introduce discriminator rejection that filters out the incorrect segmentation map predictions and assures the performance of virtual try-on frameworks. Experiments on a high-resolution dataset demonstrate that our model successfully handles the misalignment and the occlusion, and significantly outperforms the baselines. Code is available at https://github.com/sangyun884/HR-VITON.", "paper_url": "http://arxiv.org/abs/2206.14180v1", "pdf_url": "http://arxiv.org/pdf/2206.14180v1", "repo_url": null}, "2206.14164": {"publish_time": "2022-06-28", "title": "Visualizing and Alleviating the Effect of Radial Distortion on Camera Calibration Using Principal Lines", "author": "Jen-Hui Chuang et.al.", "abstract": "Preparing appropriate images for camera calibration is crucial to obtain accurate results. In this paper, new suggestions for preparing such data to alleviate the adverse effect of radial distortion for a calibration procedure using principal lines are developed through the investigations of: (i) identifying directions of checkerboard movements in an image which will result in maximum (and minimum) influence on the calibration results, and (ii) inspecting symmetry and monotonicity of such effect in (i) using the above principal lines. Accordingly, it is suggested that the estimation of principal point should based on linearly independent pairs of nearly parallel principal lines, with a member in each pair corresponds to a near 180-degree rotation (in the image plane) of the other. Experimental results show that more robust and consistent calibration results for the foregoing estimation can actually be obtained, compared with the renowned algebraic methods which estimate distortion parameters explicitly.", "paper_url": "http://arxiv.org/abs/2206.14164v1", "pdf_url": "http://arxiv.org/pdf/2206.14164v1", "repo_url": null}, "2206.14116": {"publish_time": "2022-06-28", "title": "SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous Driving", "author": "Prarthana Bhattacharyya et.al.", "abstract": "Self-supervised learning (SSL) is an emerging technique that has been successfully employed to train convolutional neural networks (CNNs) and graph neural networks (GNNs) for more transferable, generalizable, and robust representation learning. However its potential in motion forecasting for autonomous driving has rarely been explored. In this study, we report the first systematic exploration and assessment of incorporating self-supervision into motion forecasting. We first propose to investigate four novel self-supervised learning tasks for motion forecasting with theoretical rationale and quantitative and qualitative comparisons on the challenging large-scale Argoverse dataset. Secondly, we point out that our auxiliary SSL-based learning setup not only outperforms forecasting methods which use transformers, complicated fusion mechanisms and sophisticated online dense goal candidate optimization algorithms in terms of performance accuracy, but also has low inference time and architectural complexity. Lastly, we conduct several experiments to understand why SSL improves motion forecasting. Code is open-sourced at \\url{https://github.com/AutoVision-cloud/SSL-Lanes}.", "paper_url": "http://arxiv.org/abs/2206.14116v1", "pdf_url": "http://arxiv.org/pdf/2206.14116v1", "repo_url": null}, "2206.14098": {"publish_time": "2022-06-28", "title": "RevBiFPN: The Fully Reversible Bidirectional Feature Pyramid Network", "author": "Vitaliy Chiley et.al.", "abstract": "This work introduces the RevSilo, the first reversible module for bidirectional multi-scale feature fusion. Like other reversible methods, RevSilo eliminates the need to store hidden activations by recomputing them. Existing reversible methods, however, do not apply to multi-scale feature fusion and are therefore not applicable to a large class of networks. Bidirectional multi-scale feature fusion promotes local and global coherence and has become a de facto design principle for networks targeting spatially sensitive tasks e.g. HRNet and EfficientDet. When paired with high-resolution inputs, these networks achieve state-of-the-art results across various computer vision tasks, but training them requires substantial accelerator memory for saving large, multi-resolution activations. These memory requirements cap network size and limit progress. Using reversible recomputation, the RevSilo alleviates memory issues while still operating across resolution scales. Stacking RevSilos, we create RevBiFPN, a fully reversible bidirectional feature pyramid network. For classification, RevBiFPN is competitive with networks such as EfficientNet while using up to 19.8x lesser training memory. When fine-tuned on COCO, RevBiFPN provides up to a 2.5% boost in AP over HRNet using fewer MACs and a 2.4x reduction in training-time memory.", "paper_url": "http://arxiv.org/abs/2206.14098v1", "pdf_url": "http://arxiv.org/pdf/2206.14098v1", "repo_url": null}, "2206.14797": {"publish_time": "2022-06-29", "title": "3D-Aware Video Generation", "author": "Sherwin Bahmani et.al.", "abstract": "Generative models have emerged as an essential building block for many image synthesis and editing tasks. Recent advances in this field have also enabled high-quality 3D or video content to be generated that exhibits either multi-view or temporal consistency. With our work, we explore 4D generative adversarial networks (GANs) that learn unconditional generation of 3D-aware videos. By combining neural implicit representations with time-aware discriminator, we develop a GAN framework that synthesizes 3D video supervised only with monocular videos. We show that our method learns a rich embedding of decomposable 3D structures and motions that enables new visual effects of spatio-temporal renderings while producing imagery with quality comparable to that of existing 3D or video GANs.", "paper_url": "http://arxiv.org/abs/2206.14797v1", "pdf_url": "http://arxiv.org/pdf/2206.14797v1", "repo_url": null}, "2206.14746": {"publish_time": "2022-06-29", "title": "Placenta Segmentation in Ultrasound Imaging: Addressing Sources of Uncertainty and Limited Field-of-View", "author": "Veronika A. Zimmer et.al.", "abstract": "Automatic segmentation of the placenta in fetal ultrasound (US) is challenging due to the (i) high diversity of placenta appearance, (ii) the restricted quality in US resulting in highly variable reference annotations, and (iii) the limited field-of-view of US prohibiting whole placenta assessment at late gestation. In this work, we address these three challenges with a multi-task learning approach that combines the classification of placental location (e.g., anterior, posterior) and semantic placenta segmentation in a single convolutional neural network. Through the classification task the model can learn from larger and more diverse datasets while improving the accuracy of the segmentation task in particular in limited training set conditions. With this approach we investigate the variability in annotations from multiple raters and show that our automatic segmentations (Dice of 0.86 for anterior and 0.83 for posterior placentas) achieve human-level performance as compared to intra- and inter-observer variability. Lastly, our approach can deliver whole placenta segmentation using a multi-view US acquisition pipeline consisting of three stages: multi-probe image acquisition, image fusion and image segmentation. This results in high quality segmentation of larger structures such as the placenta in US with reduced image artifacts which are beyond the field-of-view of single probes.", "paper_url": "http://arxiv.org/abs/2206.14746v1", "pdf_url": "http://arxiv.org/pdf/2206.14746v1", "repo_url": "https://github.com/vamzimmer/multitask_seg_placenta"}, "2206.14735": {"publish_time": "2022-06-29", "title": "GO-Surf: Neural Feature Grid Optimization for Fast, High-Fidelity RGB-D Surface Reconstruction", "author": "Jingwen Wang et.al.", "abstract": "We present GO-Surf, a direct feature grid optimization method for accurate and fast surface reconstruction from RGB-D sequences. We model the underlying scene with a learned hierarchical feature voxel grid that encapsulates multi-level geometric and appearance local information. Feature vectors are directly optimized such that after being tri-linearly interpolated, decoded by two shallow MLPs into signed distance and radiance values, and rendered via surface volume rendering, the discrepancy between synthesized and observed RGB/depth values is minimized. Our supervision signals -- RGB, depth and approximate SDF -- can be obtained directly from input images without any need for fusion or post-processing. We formulate a novel SDF gradient regularization term that encourages surface smoothness and hole filling while maintaining high frequency details. GO-Surf can optimize sequences of $1$-$2$K frames in $15$-$45$ minutes, a speedup of $\\times60$ over NeuralRGB-D, the most related approach based on an MLP representation, while maintaining on par performance on standard benchmarks. Project page: https://jingwenwang95.github.io/go_surf/", "paper_url": "http://arxiv.org/abs/2206.14735v1", "pdf_url": "http://arxiv.org/pdf/2206.14735v1", "repo_url": null}, "2206.14718": {"publish_time": "2022-06-29", "title": "LViT: Language meets Vision Transformer in Medical Image Segmentation", "author": "Zihan Li et.al.", "abstract": "Deep learning has been widely used in medical image segmentation and other aspects. However, the performance of existing medical image segmentation models has been limited by the challenge of obtaining sufficient number of high-quality data with the high cost of data annotation. To overcome the limitation, we propose a new vision-language medical image segmentation model LViT (Language meets Vision Transformer). In our model, medical text annotation is introduced to compensate for the quality deficiency in image data. In addition, the text information can guide the generation of pseudo labels to a certain extent and further guarantee the quality of pseudo labels in semi-supervised learning. We also propose the Exponential Pseudo label Iteration mechanism (EPI) to help extend the semi-supervised version of LViT and the Pixel-Level Attention Module (PLAM) to preserve local features of images. In our model, LV (Language-Vision) loss is designed to supervise the training of unlabeled images using text information directly. To validate the performance of LViT, we construct multimodal medical segmentation datasets (image + text) containing pathological images, X-rays,etc. Experimental results show that our proposed LViT has better segmentation performance in both fully and semi-supervised conditions. Code and datasets are available at https://github.com/HUANGLIZI/LViT.", "paper_url": "http://arxiv.org/abs/2206.14718v1", "pdf_url": "http://arxiv.org/pdf/2206.14718v1", "repo_url": "https://github.com/huanglizi/lvit"}, "2206.14713": {"publish_time": "2022-06-29", "title": "CONVIQT: Contrastive Video Quality Estimator", "author": "Pavan C. Madhusudana et.al.", "abstract": "Perceptual video quality assessment (VQA) is an integral component of many streaming and video sharing platforms. Here we consider the problem of learning perceptually relevant video quality representations in a self-supervised manner. Distortion type identification and degradation level determination is employed as an auxiliary task to train a deep learning model containing a deep Convolutional Neural Network (CNN) that extracts spatial features, as well as a recurrent unit that captures temporal information. The model is trained using a contrastive loss and we therefore refer to this training framework and resulting model as CONtrastive VIdeo Quality EstimaTor (CONVIQT). During testing, the weights of the trained model are frozen, and a linear regressor maps the learned features to quality scores in a no-reference (NR) setting. We conduct comprehensive evaluations of the proposed model on multiple VQA databases by analyzing the correlations between model predictions and ground-truth quality ratings, and achieve competitive performance when compared to state-of-the-art NR-VQA models, even though it is not trained on those databases. Our ablation experiments demonstrate that the learned representations are highly robust and generalize well across synthetic and realistic distortions. Our results indicate that compelling representations with perceptual bearing can be obtained using self-supervised learning. The implementations used in this work have been made available at https://github.com/pavancm/CONVIQT.", "paper_url": "http://arxiv.org/abs/2206.14713v1", "pdf_url": "http://arxiv.org/pdf/2206.14713v1", "repo_url": "https://github.com/pavancm/conviqt"}, "2206.15472": {"publish_time": "2022-06-30", "title": "On-Device Training Under 256KB Memory", "author": "Ji Lin et.al.", "abstract": "On-device training enables the model to adapt to new data collected from the sensors by fine-tuning a pre-trained model. However, the training memory consumption is prohibitive for IoT devices that have tiny memory resources. We propose an algorithm-system co-design framework to make on-device training possible with only 256KB of memory. On-device training faces two unique challenges: (1) the quantized graphs of neural networks are hard to optimize due to mixed bit-precision and the lack of normalization; (2) the limited hardware resource (memory and computation) does not allow full backward computation. To cope with the optimization difficulty, we propose Quantization-Aware Scaling to calibrate the gradient scales and stabilize quantized training. To reduce the memory footprint, we propose Sparse Update to skip the gradient computation of less important layers and sub-tensors. The algorithm innovation is implemented by a lightweight training system, Tiny Training Engine, which prunes the backward computation graph to support sparse updates and offloads the runtime auto-differentiation to compile time. Our framework is the first practical solution for on-device transfer learning of visual recognition on tiny IoT devices (e.g., a microcontroller with only 256KB SRAM), using less than 1/100 of the memory of existing frameworks while matching the accuracy of cloud training+edge deployment for the tinyML application VWW. Our study enables IoT devices to not only perform inference but also continuously adapt to new data for on-device lifelong learning.", "paper_url": "http://arxiv.org/abs/2206.15472v1", "pdf_url": "http://arxiv.org/pdf/2206.15472v1", "repo_url": null}, "2206.15470": {"publish_time": "2022-06-30", "title": "Dressing Avatars: Deep Photorealistic Appearance for Physically Simulated Clothing", "author": "Donglai Xiang et.al.", "abstract": "Despite recent progress in developing animatable full-body avatars, realistic modeling of clothing - one of the core aspects of human self-expression - remains an open challenge. State-of-the-art physical simulation methods can generate realistically behaving clothing geometry at interactive rate. Modeling photorealistic appearance, however, usually requires physically-based rendering which is too expensive for interactive applications. On the other hand, data-driven deep appearance models are capable of efficiently producing realistic appearance, but struggle at synthesizing geometry of highly dynamic clothing and handling challenging body-clothing configurations. To this end, we introduce pose-driven avatars with explicit modeling of clothing that exhibit both realistic clothing dynamics and photorealistic appearance learned from real-world data. The key idea is to introduce a neural clothing appearance model that operates on top of explicit geometry: at train time we use high-fidelity tracking, whereas at animation time we rely on physically simulated geometry. Our key contribution is a physically-inspired appearance network, capable of generating photorealistic appearance with view-dependent and dynamic shadowing effects even for unseen body-clothing configurations. We conduct a thorough evaluation of our model and demonstrate diverse animation results on several subjects and different types of clothing. Unlike previous work on photorealistic full-body avatars, our approach can produce much richer dynamics and more realistic deformations even for loose clothing. We also demonstrate that our formulation naturally allows clothing to be used with avatars of different people while staying fully animatable, thus enabling, for the first time, photorealistic avatars with novel clothing.", "paper_url": "http://arxiv.org/abs/2206.15470v1", "pdf_url": "http://arxiv.org/pdf/2206.15470v1", "repo_url": null}, "2206.15469": {"publish_time": "2022-06-30", "title": "Watch and Match: Supercharging Imitation with Regularized Optimal Transport", "author": "Siddhant Haldar et.al.", "abstract": "Imitation learning holds tremendous promise in learning policies efficiently for complex decision making problems. Current state-of-the-art algorithms often use inverse reinforcement learning (IRL), where given a set of expert demonstrations, an agent alternatively infers a reward function and the associated optimal policy. However, such IRL approaches often require substantial online interactions for complex control problems. In this work, we present Regularized Optimal Transport (ROT), a new imitation learning algorithm that builds on recent advances in optimal transport based trajectory-matching. Our key technical insight is that adaptively combining trajectory-matching rewards with behavior cloning can significantly accelerate imitation even with only a few demonstrations. Our experiments on 20 visual control tasks across the DeepMind Control Suite, the OpenAI Robotics Suite, and the Meta-World Benchmark demonstrate an average of 7.8X faster imitation to reach 90% of expert performance compared to prior state-of-the-art methods. On real-world robotic manipulation, with just one demonstration and an hour of online training, ROT achieves an average success rate of 90.1% across 14 tasks.", "paper_url": "http://arxiv.org/abs/2206.15469v1", "pdf_url": "http://arxiv.org/pdf/2206.15469v1", "repo_url": null}, "2206.15462": {"publish_time": "2022-06-30", "title": "Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations", "author": "Ziyan Yang et.al.", "abstract": "We propose a margin-based loss for vision-language model pretraining that encourages gradient-based explanations that are consistent with region-level annotations. We refer to this objective as Attention Mask Consistency (AMC) and demonstrate that it produces superior visual grounding performance compared to models that rely instead on region-level annotations for explicitly training an object detector such as Faster R-CNN. AMC works by encouraging gradient-based explanation masks that focus their attention scores mostly within annotated regions of interest for images that contain such annotations. Particularly, a model trained with AMC on top of standard vision-language modeling objectives obtains a state-of-the-art accuracy of 86.59% in the Flickr30k visual grounding benchmark, an absolute improvement of 5.48% when compared to the best previous model. Our approach also performs exceedingly well on established benchmarks for referring expression comprehension and offers the added benefit by design of gradient-based explanations that better align with human annotations.", "paper_url": "http://arxiv.org/abs/2206.15462v1", "pdf_url": "http://arxiv.org/pdf/2206.15462v1", "repo_url": null}, "2206.15445": {"publish_time": "2022-06-30", "title": "Asymmetry Disentanglement Network for Interpretable Acute Ischemic Stroke Infarct Segmentation in Non-Contrast CT Scans", "author": "Haomiao Ni et.al.", "abstract": "Accurate infarct segmentation in non-contrast CT (NCCT) images is a crucial step toward computer-aided acute ischemic stroke (AIS) assessment. In clinical practice, bilateral symmetric comparison of brain hemispheres is usually used to locate pathological abnormalities. Recent research has explored asymmetries to assist with AIS segmentation. However, most previous symmetry-based work mixed different types of asymmetries when evaluating their contribution to AIS. In this paper, we propose a novel Asymmetry Disentanglement Network (ADN) to automatically separate pathological asymmetries and intrinsic anatomical asymmetries in NCCTs for more effective and interpretable AIS segmentation. ADN first performs asymmetry disentanglement based on input NCCTs, which produces different types of 3D asymmetry maps. Then a synthetic, intrinsic-asymmetry-compensated and pathology-asymmetry-salient NCCT volume is generated and later used as input to a segmentation network. The training of ADN incorporates domain knowledge and adopts a tissue-type aware regularization loss function to encourage clinically-meaningful pathological asymmetry extraction. Coupled with an unsupervised 3D transformation network, ADN achieves state-of-the-art AIS segmentation performance on a public NCCT dataset. In addition to the superior performance, we believe the learned clinically-interpretable asymmetry maps can also provide insights towards a better understanding of AIS assessment. Our code is available at https://github.com/nihaomiao/MICCAI22_ADN.", "paper_url": "http://arxiv.org/abs/2206.15445v1", "pdf_url": "http://arxiv.org/pdf/2206.15445v1", "repo_url": "https://github.com/nihaomiao/miccai22_adn"}, "2207.00579": {"publish_time": "2022-07-01", "title": "Video + CLIP Baseline for Ego4D Long-term Action Anticipation", "author": "Srijan Das et.al.", "abstract": "In this report, we introduce our adaptation of image-text models for long-term action anticipation. Our Video + CLIP framework makes use of a large-scale pre-trained paired image-text model: CLIP and a video encoder Slowfast network. The CLIP embedding provides fine-grained understanding of objects relevant for an action whereas the slowfast network is responsible for modeling temporal information within a video clip of few frames. We show that the features obtained from both encoders are complementary to each other, thus outperforming the baseline on Ego4D for the task of long-term action anticipation. Our code is available at github.com/srijandas07/clip_baseline_LTA_Ego4d.", "paper_url": "http://arxiv.org/abs/2207.00579v1", "pdf_url": "http://arxiv.org/pdf/2207.00579v1", "repo_url": "https://github.com/srijandas07/clip_baseline_lta_ego4d"}, "2207.00572": {"publish_time": "2022-07-01", "title": "How can spherical CNNs benefit ML-based diffusion MRI parameter estimation?", "author": "Tobias Goodwin-Allcock et.al.", "abstract": "This paper demonstrates spherical convolutional neural networks (S-CNN) offer distinct advantages over conventional fully-connected networks (FCN) at estimating scalar parameters of tissue microstructure from diffusion MRI (dMRI). Such microstructure parameters are valuable for identifying pathology and quantifying its extent. However, current clinical practice commonly acquires dMRI data consisting of only 6 diffusion weighted images (DWIs), limiting the accuracy and precision of estimated microstructure indices. Machine learning (ML) has been proposed to address this challenge. However, existing ML-based methods are not robust to differing dMRI gradient sampling schemes, nor are they rotation equivariant. Lack of robustness to sampling schemes requires a new network to be trained for each scheme, complicating the analysis of data from multiple sources. A possible consequence of the lack of rotational equivariance is that the training dataset must contain a diverse range of microstucture orientations. Here, we show spherical CNNs represent a compelling alternative that is robust to new sampling schemes as well as offering rotational equivariance. We show the latter can be leveraged to decrease the number of training datapoints required.", "paper_url": "http://arxiv.org/abs/2207.00572v1", "pdf_url": "http://arxiv.org/pdf/2207.00572v1", "repo_url": null}, "2207.00545": {"publish_time": "2022-07-01", "title": "Transforming Image Generation from Scene Graphs", "author": "Renato Sortino et.al.", "abstract": "Generating images from semantic visual knowledge is a challenging task, that can be useful to condition the synthesis process in complex, subtle, and unambiguous ways, compared to alternatives such as class labels or text descriptions. Although generative methods conditioned by semantic representations exist, they do not provide a way to control the generation process aside from the specification of constraints between objects. As an example, the possibility to iteratively generate or modify images by manually adding specific items is a desired property that, to our knowledge, has not been fully investigated in the literature. In this work we propose a transformer-based approach conditioned by scene graphs that, conversely to recent transformer-based methods, also employs a decoder to autoregressively compose images, making the synthesis process more effective and controllable. The proposed architecture is composed by three modules: 1) a graph convolutional network, to encode the relationships of the input graph; 2) an encoder-decoder transformer, which autoregressively composes the output image; 3) an auto-encoder, employed to generate representations used as input/output of each generation step by the transformer. Results obtained on CIFAR10 and MNIST images show that our model is able to satisfy semantic constraints defined by a scene graph and to model relations between visual objects in the scene by taking into account a user-provided partial rendering of the desired target.", "paper_url": "http://arxiv.org/abs/2207.00545v1", "pdf_url": "http://arxiv.org/pdf/2207.00545v1", "repo_url": null}, "2207.00531": {"publish_time": "2022-07-01", "title": "Masked Autoencoders for Self-Supervised Learning on Automotive Point Clouds", "author": "Georg Hess et.al.", "abstract": "Masked autoencoding has become a successful pre-training paradigm for Transformer models for text, images, and recently, point clouds. Raw automotive datasets are a suitable candidate for self-supervised pre-training as they generally are cheap to collect compared to annotations for tasks like 3D object detection (OD). However, development of masked autoencoders for point clouds has focused solely on synthetic and indoor data. Consequently, existing methods have tailored their representations and models toward point clouds which are small, dense and have homogeneous point density. In this work, we study masked autoencoding for point clouds in an automotive setting, which are sparse and for which the point density can vary drastically among objects in the same scene. To this end, we propose Voxel-MAE, a simple masked autoencoding pre-training scheme designed for voxel representations. We pre-train the backbone of a Transformer-based 3D object detector to reconstruct masked voxels and to distinguish between empty and non-empty voxels. Our method improves the 3D OD performance by 1.75 mAP points and 1.05 NDS on the challenging nuScenes dataset. Compared to existing self-supervised methods for automotive data, Voxel-MAE displays up to $2\\times$ performance increase. Further, we show that by pre-training with Voxel-MAE, we require only 40% of the annotated data to outperform a randomly initialized equivalent. Code will be released.", "paper_url": "http://arxiv.org/abs/2207.00531v1", "pdf_url": "http://arxiv.org/pdf/2207.00531v1", "repo_url": null}, "2207.00522": {"publish_time": "2022-07-01", "title": "Ray-Space Motion Compensation for Lenslet Plenoptic Video Coding", "author": "Thuc Nguyen Huu et.al.", "abstract": "Plenoptic images and videos bearing rich information demand a tremendous amount of data storage and high transmission cost. While there has been much study on plenoptic image coding, investigations into plenoptic video coding have been very limited. We investigate the motion compensation for plenoptic video coding from a slightly different perspective by looking at the problem in the ray-space domain instead of in the conventional pixel domain. Here, we develop a novel motion compensation scheme for lenslet video under two sub-cases of ray-space motion, that is, integer ray-space motion and fractional ray-space motion. The proposed new scheme of light field motion-compensated prediction is designed such that it can be easily integrated into well-known video coding techniques such as HEVC. Experimental results compared to relevant existing methods have shown remarkable compression efficiency with an average gain of 19.63% and a peak gain of 29.1%.", "paper_url": "http://arxiv.org/abs/2207.00522v1", "pdf_url": "http://arxiv.org/pdf/2207.00522v1", "repo_url": null}, "2207.01614": {"publish_time": "2022-07-04", "title": "Beyond mAP: Re-evaluating and Improving Performance in Instance Segmentation with Semantic Sorting and Contrastive Flow", "author": "Rohit Jena et.al.", "abstract": "Top-down instance segmentation methods improve mAP by hedging bets on low-confidence predictions to match a ground truth. Moreover, the query-key paradigm of top-down methods leads to the instance merging problem. An excessive number of duplicate predictions leads to the (over)counting error, and the independence of category and localization branches leads to the naming error. The de-facto mAP metric doesn't capture these errors, as we show that a trivial dithering scheme can simultaneously increase mAP with hedging errors. To this end, we propose two graph-based metrics that quantifies the amount of hedging both inter-and intra-class. We conjecture the source of the hedging problem is due to feature merging and propose a) Contrastive Flow Field to encode contextual differences between instances as a supervisory signal, and b) Semantic Sorting and NMS step to suppress duplicates and incorrectly categorized prediction. Ablations show that our method encodes contextual information better than baselines, and experiments on COCO our method simultaneously reduces merging and hedging errors compared to state-of-the-art instance segmentation methods.", "paper_url": "http://arxiv.org/abs/2207.01614v1", "pdf_url": "http://arxiv.org/pdf/2207.01614v1", "repo_url": null}, "2207.01610": {"publish_time": "2022-07-04", "title": "PVO: Panoptic Visual Odometry", "author": "Weicai Ye et.al.", "abstract": "We present a novel panoptic visual odometry framework, termed PVO, to achieve a more comprehensive modeling of the scene's motion, geometry, and panoptic segmentation information. PVO models visual odometry (VO) and video panoptic segmentation (VPS) in a unified view, enabling the two tasks to facilitate each other. Specifically, we introduce a panoptic update module into the VO module, which operates on the image panoptic segmentation. This Panoptic-Enhanced VO module can trim the interference of dynamic objects in the camera pose estimation by adjusting the weights of optimized camera poses. On the other hand, the VO-Enhanced VPS module improves the segmentation accuracy by fusing the panoptic segmentation result of the current frame on the fly to the adjacent frames, using geometric information such as camera pose, depth, and optical flow obtained from the VO module. These two modules contribute to each other through a recurrent iterative optimization. Extensive experiments demonstrate that PVO outperforms state-of-the-art methods in both visual odometry and video panoptic segmentation tasks. Code and data are available on the project webpage: \\urlstyle{tt} \\textcolor{url_color}{\\url{https://zju3dv.github.io/pvo/}}.", "paper_url": "http://arxiv.org/abs/2207.01610v1", "pdf_url": "http://arxiv.org/pdf/2207.01610v1", "repo_url": null}, "2207.01600": {"publish_time": "2022-07-04", "title": "CRFormer: A Cross-Region Transformer for Shadow Removal", "author": "Jin Wan et.al.", "abstract": "Aiming to restore the original intensity of shadow regions in an image and make them compatible with the remaining non-shadow regions without a trace, shadow removal is a very challenging problem that benefits many downstream image/video-related tasks. Recently, transformers have shown their strong capability in various applications by capturing global pixel interactions and this capability is highly desirable in shadow removal. However, applying transformers to promote shadow removal is non-trivial for the following two reasons: 1) The patchify operation is not suitable for shadow removal due to irregular shadow shapes; 2) shadow removal only needs one-way interaction from the non-shadow region to the shadow region instead of the common two-way interactions among all pixels in the image. In this paper, we propose a novel cross-region transformer, namely CRFormer, for shadow removal which differs from existing transformers by only considering the pixel interactions from the non-shadow region to the shadow region without splitting images into patches. This is achieved by a carefully designed region-aware cross-attention operation that can aggregate the recovered shadow region features conditioned on the non-shadow region features. Extensive experiments on ISTD, AISTD, SRD, and Video Shadow Removal datasets demonstrate the superiority of our method compared to other state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2207.01600v1", "pdf_url": "http://arxiv.org/pdf/2207.01600v1", "repo_url": null}, "2207.01584": {"publish_time": "2022-07-04", "title": "Classification of Alzheimer's Disease Using the Convolutional Neural Network (CNN) with Transfer Learning and Weighted Loss", "author": "Muhammad Wildan Oktavian et.al.", "abstract": "Alzheimer's disease is a progressive neurodegenerative disorder that gradually deprives the patient of cognitive function and can end in death. With the advancement of technology today, it is possible to detect Alzheimer's disease through Magnetic Resonance Imaging (MRI) scans. So that MRI is the technique most often used for the diagnosis and analysis of the progress of Alzheimer's disease. With this technology, image recognition in the early diagnosis of Alzheimer's disease can be achieved automatically using machine learning. Although machine learning has many advantages, currently the use of deep learning is more widely applied because it has stronger learning capabilities and is more suitable for solving image recognition problems. However, there are still several challenges that must be faced to implement deep learning, such as the need for large datasets, requiring large computing resources, and requiring careful parameter setting to prevent overfitting or underfitting. In responding to the challenge of classifying Alzheimer's disease using deep learning, this study propose the Convolutional Neural Network (CNN) method with the Residual Network 18 Layer (ResNet-18) architecture. To overcome the need for a large and balanced dataset, transfer learning from ImageNet is used and weighting the loss function values so that each class has the same weight. And also in this study conducted an experiment by changing the network activation function to a mish activation function to increase accuracy. From the results of the tests that have been carried out, the accuracy of the model is 88.3 % using transfer learning, weighted loss and the mish activation function. This accuracy value increases from the baseline model which only gets an accuracy of 69.1 %.", "paper_url": "http://arxiv.org/abs/2207.01584v1", "pdf_url": "http://arxiv.org/pdf/2207.01584v1", "repo_url": null}, "2207.01583": {"publish_time": "2022-07-04", "title": "LaTeRF: Label and Text Driven Object Radiance Fields", "author": "Ashkan Mirzaei et.al.", "abstract": "Obtaining 3D object representations is important for creating photo-realistic simulators and collecting assets for AR/VR applications. Neural fields have shown their effectiveness in learning a continuous volumetric representation of a scene from 2D images, but acquiring object representations from these models with weak supervision remains an open challenge. In this paper we introduce LaTeRF, a method for extracting an object of interest from a scene given 2D images of the entire scene and known camera poses, a natural language description of the object, and a small number of point-labels of object and non-object points in the input images. To faithfully extract the object from the scene, LaTeRF extends the NeRF formulation with an additional `objectness' probability at each 3D point. Additionally, we leverage the rich latent space of a pre-trained CLIP model combined with our differentiable object renderer, to inpaint the occluded parts of the object. We demonstrate high-fidelity object extraction on both synthetic and real datasets and justify our design choices through an extensive ablation study.", "paper_url": "http://arxiv.org/abs/2207.01583v1", "pdf_url": "http://arxiv.org/pdf/2207.01583v1", "repo_url": null}, "2207.02206": {"publish_time": "2022-07-05", "title": "Segmenting Moving Objects via an Object-Centric Layered Representation", "author": "Junyu Xie et.al.", "abstract": "The objective of this paper is a model that is able to discover, track and segment multiple moving objects in a video. We make four contributions: First, we introduce an object-centric segmentation model with a depth-ordered layer representation. This is implemented using a variant of the transformer architecture that ingests optical flow, where each query vector specifies an object and its layer for the entire video. The model can effectively discover multiple moving objects and handle mutual occlusions; Second, we introduce a scalable pipeline for generating synthetic training data with multiple objects, significantly reducing the requirements for labour-intensive annotations, and supporting Sim2Real generalisation; Third, we show that the model is able to learn object permanence and temporal shape consistency, and is able to predict amodal segmentation masks; Fourth, we evaluate the model on standard video segmentation benchmarks, DAVIS, MoCA, SegTrack, FBMS-59, and achieve state-of-the-art unsupervised segmentation performance, even outperforming several supervised approaches. With test-time adaptation, we observe further performance boosts.", "paper_url": "http://arxiv.org/abs/2207.02206v1", "pdf_url": "http://arxiv.org/pdf/2207.02206v1", "repo_url": null}, "2207.02205": {"publish_time": "2022-07-05", "title": "Clustered Saliency Prediction", "author": "Rezvan Sherkati et.al.", "abstract": "We present a new method for image salience prediction, Clustered Saliency Prediction. This method divides individuals into clusters based on their personal features and their known saliency maps, and generates a separate image salience model for each cluster. We test our approach on a public dataset of personalized saliency maps, with varying importance weights for personal feature factors and observe the effects on the clusters. For each cluster, we use an image-to-image translation method, mainly Pix2Pix model, to convert universal saliency maps to saliency maps of that cluster. We try three state-of-the-art universal saliency prediction methods, DeepGaze II, ML-Net and SalGAN, and see their impact on the results. We show that our Clustered Saliency Prediction technique outperforms the state-of-the-art universal saliency prediction models. Also we demonstrate the effectiveness of our clustering method by comparing the results of Clustered Saliency Prediction using clusters obtained by Subject Similarity Clustering algorithm with two baseline methods. We propose an approach to assign new people to the most appropriate cluster, based on their personal features and any known saliency maps. In our experiments we see that this method of assigning new people to a cluster on average chooses the cluster that gives higher saliency scores.", "paper_url": "http://arxiv.org/abs/2207.02205v1", "pdf_url": "http://arxiv.org/pdf/2207.02205v1", "repo_url": null}, "2207.02204": {"publish_time": "2022-07-05", "title": "Detecting and Recovering Sequential DeepFake Manipulation", "author": "Rui Shao et.al.", "abstract": "Since photorealistic faces can be readily generated by facial manipulation technologies nowadays, potential malicious abuse of these technologies has drawn great concerns. Numerous deepfake detection methods are thus proposed. However, existing methods only focus on detecting one-step facial manipulation. As the emergence of easy-accessible facial editing applications, people can easily manipulate facial components using multi-step operations in a sequential manner. This new threat requires us to detect a sequence of facial manipulations, which is vital for both detecting deepfake media and recovering original faces afterwards. Motivated by this observation, we emphasize the need and propose a novel research problem called Detecting Sequential DeepFake Manipulation (Seq-DeepFake). Unlike the existing deepfake detection task only demanding a binary label prediction, detecting Seq-DeepFake manipulation requires correctly predicting a sequential vector of facial manipulation operations. To support a large-scale investigation, we construct the first Seq-DeepFake dataset, where face images are manipulated sequentially with corresponding annotations of sequential facial manipulation vectors. Based on this new dataset, we cast detecting Seq-DeepFake manipulation as a specific image-to-sequence (e.g. image captioning) task and propose a concise yet effective Seq-DeepFake Transformer (SeqFakeFormer). Moreover, we build a comprehensive benchmark and set up rigorous evaluation protocols and metrics for this new research problem. Extensive experiments demonstrate the effectiveness of SeqFakeFormer. Several valuable observations are also revealed to facilitate future research in broader deepfake detection problems.", "paper_url": "http://arxiv.org/abs/2207.02204v1", "pdf_url": "http://arxiv.org/pdf/2207.02204v1", "repo_url": "https://github.com/rshaojimmy/seqdeepfake"}, "2207.02202": {"publish_time": "2022-07-05", "title": "CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers", "author": "Runsheng Xu et.al.", "abstract": "Bird's eye view (BEV) semantic segmentation plays a crucial role in spatial sensing for autonomous driving. Although recent literature has made significant progress on BEV map understanding, they are all based on single-agent camera-based systems which are difficult to handle occlusions and detect distant objects in complex traffic scenes. Vehicle-to-Vehicle (V2V) communication technologies have enabled autonomous vehicles to share sensing information, which can dramatically improve the perception performance and range as compared to single-agent systems. In this paper, we propose CoBEVT, the first generic multi-agent multi-camera perception framework that can cooperatively generate BEV map predictions. To efficiently fuse camera features from multi-view and multi-agent data in an underlying Transformer architecture, we design a fused axial attention or FAX module, which can capture sparsely local and global spatial interactions across views and agents. The extensive experiments on the V2V perception dataset, OPV2V, demonstrate that CoBEVT achieves state-of-the-art performance for cooperative BEV semantic segmentation. Moreover, CoBEVT is shown to be generalizable to other tasks, including 1) BEV segmentation with single-agent multi-camera and 2) 3D object detection with multi-agent LiDAR systems, and achieves state-of-the-art performance with real-time inference speed.", "paper_url": "http://arxiv.org/abs/2207.02202v1", "pdf_url": "http://arxiv.org/pdf/2207.02202v1", "repo_url": null}, "2207.02201": {"publish_time": "2022-07-05", "title": "Efficient Spatial-Temporal Information Fusion for LiDAR-Based 3D Moving Object Segmentation", "author": "Jiadai Sun et.al.", "abstract": "Accurate moving object segmentation is an essential task for autonomous driving. It can provide effective information for many downstream tasks, such as collision avoidance, path planning, and static map construction. How to effectively exploit the spatial-temporal information is a critical question for 3D LiDAR moving object segmentation (LiDAR-MOS). In this work, we propose a novel deep neural network exploiting both spatial-temporal information and different representation modalities of LiDAR scans to improve LiDAR-MOS performance. Specifically, we first use a range image-based dual-branch structure to separately deal with spatial and temporal information that can be obtained from sequential LiDAR scans, and later combine them using motion-guided attention modules. We also use a point refinement module via 3D sparse convolution to fuse the information from both LiDAR range image and point cloud representations and reduce the artifacts on the borders of the objects. We verify the effectiveness of our proposed approach on the LiDAR-MOS benchmark of SemanticKITTI. Our method outperforms the state-of-the-art methods significantly in terms of LiDAR-MOS IoU. Benefiting from the devised coarse-to-fine architecture, our method operates online at sensor frame rate. The implementation of our method is available as open source at: https://github.com/haomo-ai/MotionSeg3D.", "paper_url": "http://arxiv.org/abs/2207.02201v1", "pdf_url": "http://arxiv.org/pdf/2207.02201v1", "repo_url": "https://github.com/haomo-ai/motionseg3d"}, "2207.02812": {"publish_time": "2022-07-06", "title": "Towards Counterfactual Image Manipulation via CLIP", "author": "Yingchen Yu et.al.", "abstract": "Leveraging StyleGAN's expressivity and its disentangled latent codes, existing methods can achieve realistic editing of different visual attributes such as age and gender of facial images. An intriguing yet challenging problem arises: Can generative models achieve counterfactual editing against their learnt priors? Due to the lack of counterfactual samples in natural datasets, we investigate this problem in a text-driven manner with Contrastive-Language-Image-Pretraining (CLIP), which can offer rich semantic knowledge even for various counterfactual concepts. Different from in-domain manipulation, counterfactual manipulation requires more comprehensive exploitation of semantic knowledge encapsulated in CLIP as well as more delicate handling of editing directions for avoiding being stuck in local minimum or undesired editing. To this end, we design a novel contrastive loss that exploits predefined CLIP-space directions to guide the editing toward desired directions from different perspectives. In addition, we design a simple yet effective scheme that explicitly maps CLIP embeddings (of target text) to the latent space and fuses them with latent codes for effective latent code optimization and accurate editing. Extensive experiments show that our design achieves accurate and realistic editing while driving by target texts with various counterfactual concepts.", "paper_url": "http://arxiv.org/abs/2207.02812v1", "pdf_url": "http://arxiv.org/pdf/2207.02812v1", "repo_url": "https://github.com/yingchen001/cf-clip"}, "2207.02811": {"publish_time": "2022-07-06", "title": "Multi-View Object Pose Refinement With Differentiable Renderer", "author": "Ivan Shugurov et.al.", "abstract": "This paper introduces a novel multi-view 6 DoF object pose refinement approach focusing on improving methods trained on synthetic data. It is based on the DPOD detector, which produces dense 2D-3D correspondences between the model vertices and the image pixels in each frame. We have opted for the use of multiple frames with known relative camera transformations, as it allows introduction of geometrical constraints via an interpretable ICP-like loss function. The loss function is implemented with a differentiable renderer and is optimized iteratively. We also demonstrate that a full detection and refinement pipeline, which is trained solely on synthetic data, can be used for auto-labeling real data. We perform quantitative evaluation on LineMOD, Occlusion, Homebrewed and YCB-V datasets and report excellent performance in comparison to the state-of-the-art methods trained on the synthetic and real data. We demonstrate empirically that our approach requires only a few frames and is robust to close camera locations and noise in extrinsic camera calibration, making its practical usage easier and more ubiquitous.", "paper_url": "http://arxiv.org/abs/2207.02811v1", "pdf_url": "http://arxiv.org/pdf/2207.02811v1", "repo_url": null}, "2207.02805": {"publish_time": "2022-07-06", "title": "DPODv2: Dense Correspondence-Based 6 DoF Pose Estimation", "author": "Ivan Shugurov et.al.", "abstract": "We propose a three-stage 6 DoF object detection method called DPODv2 (Dense Pose Object Detector) that relies on dense correspondences. We combine a 2D object detector with a dense correspondence estimation network and a multi-view pose refinement method to estimate a full 6 DoF pose. Unlike other deep learning methods that are typically restricted to monocular RGB images, we propose a unified deep learning network allowing different imaging modalities to be used (RGB or Depth). Moreover, we propose a novel pose refinement method, that is based on differentiable rendering. The main concept is to compare predicted and rendered correspondences in multiple views to obtain a pose which is consistent with predicted correspondences in all views. Our proposed method is evaluated rigorously on different data modalities and types of training data in a controlled setup. The main conclusions is that RGB excels in correspondence estimation, while depth contributes to the pose accuracy if good 3D-3D correspondences are available. Naturally, their combination achieves the overall best performance. We perform an extensive evaluation and an ablation study to analyze and validate the results on several challenging datasets. DPODv2 achieves excellent results on all of them while still remaining fast and scalable independent of the used data modality and the type of training data", "paper_url": "http://arxiv.org/abs/2207.02805v1", "pdf_url": "http://arxiv.org/pdf/2207.02805v1", "repo_url": null}, "2207.02803": {"publish_time": "2022-07-06", "title": "Delving into Sequential Patches for Deepfake Detection", "author": "Jiazhi Guan et.al.", "abstract": "Recent advances in face forgery techniques produce nearly visually untraceable deepfake videos, which could be leveraged with malicious intentions. As a result, researchers have been devoted to deepfake detection. Previous studies has identified the importance of local low-level cues and temporal information in pursuit to generalize well across deepfake methods, however, they still suffer from robustness problem against post-processings. In this work, we propose the Local- & Temporal-aware Transformer-based Deepfake Detection (LTTD) framework, which adopts a local-to-global learning protocol with a particular focus on the valuable temporal information within local sequences. Specifically, we propose a Local Sequence Transformer (LST), which models the temporal consistency on sequences of restricted spatial regions, where low-level information is hierarchically enhanced with shallow layers of learned 3D filters. Based on the local temporal embeddings, we then achieve the final classification in a global contrastive way. Extensive experiments on popular datasets validate that our approach effectively spots local forgery cues and achieves state-of-the-art performance.", "paper_url": "http://arxiv.org/abs/2207.02803v1", "pdf_url": "http://arxiv.org/pdf/2207.02803v1", "repo_url": null}, "2207.02797": {"publish_time": "2022-07-06", "title": "The Intrinsic Manifolds of Radiological Images and their Role in Deep Learning", "author": "Nicholas Konz et.al.", "abstract": "The manifold hypothesis is a core mechanism behind the success of deep learning, so understanding the intrinsic manifold structure of image data is central to studying how neural networks learn from the data. Intrinsic dataset manifolds and their relationship to learning difficulty have recently begun to be studied for the common domain of natural images, but little such research has been attempted for radiological images. We address this here. First, we compare the intrinsic manifold dimensionality of radiological and natural images. We also investigate the relationship between intrinsic dimensionality and generalization ability over a wide range of datasets. Our analysis shows that natural image datasets generally have a higher number of intrinsic dimensions than radiological images. However, the relationship between generalization ability and intrinsic dimensionality is much stronger for medical images, which could be explained as radiological images having intrinsic features that are more difficult to learn. These results give a more principled underpinning for the intuition that radiological images can be more challenging to apply deep learning to than natural image datasets common to machine learning research. We believe rather than directly applying models developed for natural images to the radiological imaging domain, more care should be taken to developing architectures and algorithms that are more tailored to the specific characteristics of this domain. The research shown in our paper, demonstrating these characteristics and the differences from natural images, is an important first step in this direction.", "paper_url": "http://arxiv.org/abs/2207.02797v1", "pdf_url": "http://arxiv.org/pdf/2207.02797v1", "repo_url": "https://github.com/mazurowski-lab/radiologyintrinsicmanifolds"}, "2207.03483": {"publish_time": "2022-07-07", "title": "Finding Fallen Objects Via Asynchronous Audio-Visual Integration", "author": "Chuang Gan et.al.", "abstract": "The way an object looks and sounds provide complementary reflections of its physical properties. In many settings cues from vision and audition arrive asynchronously but must be integrated, as when we hear an object dropped on the floor and then must find it. In this paper, we introduce a setting in which to study multi-modal object localization in 3D virtual environments. An object is dropped somewhere in a room. An embodied robot agent, equipped with a camera and microphone, must determine what object has been dropped -- and where -- by combining audio and visual signals with knowledge of the underlying physics. To study this problem, we have generated a large-scale dataset -- the Fallen Objects dataset -- that includes 8000 instances of 30 physical object categories in 64 rooms. The dataset uses the ThreeDWorld platform which can simulate physics-based impact sounds and complex physical interactions between objects in a photorealistic setting. As a first step toward addressing this challenge, we develop a set of embodied agent baselines, based on imitation learning, reinforcement learning, and modular planning, and perform an in-depth analysis of the challenge of this new task.", "paper_url": "http://arxiv.org/abs/2207.03483v1", "pdf_url": "http://arxiv.org/pdf/2207.03483v1", "repo_url": null}, "2207.03482": {"publish_time": "2022-07-07", "title": "Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection", "author": "Hanoona Rasheed et.al.", "abstract": "Existing open-vocabulary object detectors typically enlarge their vocabulary sizes by leveraging different forms of weak supervision. This helps generalize to novel objects at inference. Two popular forms of weak-supervision used in open-vocabulary detection (OVD) include pretrained CLIP model and image-level supervision. We note that both these modes of supervision are not optimally aligned for the detection task: CLIP is trained with image-text pairs and lacks precise localization of objects while the image-level supervision has been used with heuristics that do not accurately specify local object regions. In this work, we propose to address this problem by performing object-centric alignment of the language embeddings from the CLIP model. Furthermore, we visually ground the objects with only image-level supervision using a pseudo-labeling process that provides high-quality object proposals and helps expand the vocabulary during training. We establish a bridge between the above two object-alignment strategies via a novel weight transfer function that aggregates their complimentary strengths. In essence, the proposed model seeks to minimize the gap between object and image-centric representations in the OVD setting. On the COCO benchmark, our proposed approach achieves 40.3 AP50 on novel classes, an absolute 11.9 gain over the previous best performance.For LVIS, we surpass the state-of-the-art ViLD model by 5.0 mask AP for rare categories and 3.4 overall. Code: https://bit.ly/3byZoQp.", "paper_url": "http://arxiv.org/abs/2207.03482v1", "pdf_url": "http://arxiv.org/pdf/2207.03482v1", "repo_url": "https://github.com/hanoonaR/object-centric-ovd"}, "2207.03478": {"publish_time": "2022-07-07", "title": "Red PANDA: Disambiguating Anomaly Detection by Removing Nuisance Factors", "author": "Niv Cohen et.al.", "abstract": "Anomaly detection methods strive to discover patterns that differ from the norm in a semantic way. This goal is ambiguous as a data point differing from the norm by an attribute e.g., age, race or gender, may be considered anomalous by some operators while others may consider this attribute irrelevant. Breaking from previous research, we present a new anomaly detection method that allows operators to exclude an attribute from being considered as relevant for anomaly detection. Our approach then learns representations which do not contain information over the nuisance attributes. Anomaly scoring is performed using a density-based approach. Importantly, our approach does not require specifying the attributes that are relevant for detecting anomalies, which is typically impossible in anomaly detection, but only attributes to ignore. An empirical investigation is presented verifying the effectiveness of our approach.", "paper_url": "http://arxiv.org/abs/2207.03478v1", "pdf_url": "http://arxiv.org/pdf/2207.03478v1", "repo_url": null}, "2207.03450": {"publish_time": "2022-07-07", "title": "TFCNs: A CNN-Transformer Hybrid Network for Medical Image Segmentation", "author": "Zihan Li et.al.", "abstract": "Medical image segmentation is one of the most fundamental tasks concerning medical information analysis. Various solutions have been proposed so far, including many deep learning-based techniques, such as U-Net, FC-DenseNet, etc. However, high-precision medical image segmentation remains a highly challenging task due to the existence of inherent magnification and distortion in medical images as well as the presence of lesions with similar density to normal tissues. In this paper, we propose TFCNs (Transformers for Fully Convolutional denseNets) to tackle the problem by introducing ResLinear-Transformer (RL-Transformer) and Convolutional Linear Attention Block (CLAB) to FC-DenseNet. TFCNs is not only able to utilize more latent information from the CT images for feature extraction, but also can capture and disseminate semantic features and filter non-semantic features more effectively through the CLAB module. Our experimental results show that TFCNs can achieve state-of-the-art performance with dice scores of 83.72\\% on the Synapse dataset. In addition, we evaluate the robustness of TFCNs for lesion area effects on the COVID-19 public datasets. The Python code will be made publicly available on https://github.com/HUANGLIZI/TFCNs.", "paper_url": "http://arxiv.org/abs/2207.03450v1", "pdf_url": "http://arxiv.org/pdf/2207.03450v1", "repo_url": "https://github.com/huanglizi/tfcns"}, "2207.03447": {"publish_time": "2022-07-07", "title": "Learning to restore images degraded by atmospheric turbulence using uncertainty", "author": "Rajeev Yasarla et.al.", "abstract": "Atmospheric turbulence can significantly degrade the quality of images acquired by long-range imaging systems by causing spatially and temporally random fluctuations in the index of refraction of the atmosphere. Variations in the refractive index causes the captured images to be geometrically distorted and blurry. Hence, it is important to compensate for the visual degradation in images caused by atmospheric turbulence. In this paper, we propose a deep learning-based approach for restring a single image degraded by atmospheric turbulence. We make use of the epistemic uncertainty based on Monte Carlo dropouts to capture regions in the image where the network is having hard time restoring. The estimated uncertainty maps are then used to guide the network to obtain the restored image. Extensive experiments are conducted on synthetic and real images to show the significance of the proposed work. Code is available at : https://github.com/rajeevyasarla/AT-Net", "paper_url": "http://arxiv.org/abs/2207.03447v1", "pdf_url": "http://arxiv.org/pdf/2207.03447v1", "repo_url": "https://github.com/rajeevyasarla/at-net"}}}, "NLP": {"NLP": {"2202.12875": {"publish_time": "2022-02-25", "title": "DataLab: A Platform for Data Analysis and Intervention", "author": "Yang Xiao et.al.", "abstract": "Despite data's crucial role in machine learning, most existing tools and research tend to focus on systems on top of existing data rather than how to interpret and manipulate data. In this paper, we propose DataLab, a unified data-oriented platform that not only allows users to interactively analyze the characteristics of data, but also provides a standardized interface for different data processing operations. Additionally, in view of the ongoing proliferation of datasets, \\toolname has features for dataset recommendation and global vision analysis that help researchers form a better view of the data ecosystem. So far, DataLab covers 1,715 datasets and 3,583 of its transformed version (e.g., hyponyms replacement), where 728 datasets support various analyses (e.g., with respect to gender bias) with the help of 140M samples annotated by 318 feature functions. DataLab is under active development and will be supported going forward. We have released a web platform, web API, Python SDK, PyPI published package and online documentation, which hopefully, can meet the diverse needs of researchers.", "paper_url": "http://arxiv.org/abs/2202.12875v1", "pdf_url": "http://arxiv.org/pdf/2202.12875v1", "repo_url": null}, "2202.12837": {"publish_time": "2022-02-25", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?", "author": "Sewon Min et.al.", "abstract": "Large language models (LMs) are able to in-context learn -- perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. In this paper, we show that ground truth demonstrations are in fact not required -- randomly replacing labels in the demonstrations barely hurts performance, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of end task performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.", "paper_url": "http://arxiv.org/abs/2202.12837v1", "pdf_url": "http://arxiv.org/pdf/2202.12837v1", "repo_url": null}, "2202.12832": {"publish_time": "2022-02-25", "title": "Morphology Without Borders: Clause-Level Morphological Annotation", "author": "Omer Goldman et.al.", "abstract": "Morphological tasks use large multi-lingual datasets that organize words into inflection tables, which then serve as training and evaluation data for various tasks. However, a closer inspection of these data reveals profound cross-linguistic inconsistencies, that arise from the lack of a clear linguistic and operational definition of what is a word, and that severely impair the universality of the derived tasks. To overcome this deficiency, we propose to view morphology as a clause-level phenomenon, rather than word-level. It is anchored in a fixed yet inclusive set of features homogeneous across languages, that encapsulates all functions realized in a saturated clause. We deliver MightyMorph, a novel dataset for clause-level morphology covering 4 typologically-different languages: English, German, Turkish and Hebrew. We use this dataset to derive 3 clause-level morphological tasks: inflection, reinflection and analysis. Our experiments show that the clause-level tasks are substantially harder than the respective word-level tasks, while having comparable complexity across languages. Furthermore, redefining morphology to the clause-level provides a neat interface with contextualized language models (LMs) and can be used to probe LMs capacity to encode complex morphology. Taken together, this work opens up new horizons in the study of computational morphology, leaving ample space for studying neural morphological modeling cross-linguistically.", "paper_url": "http://arxiv.org/abs/2202.12832v1", "pdf_url": "http://arxiv.org/pdf/2202.12832v1", "repo_url": null}, "2202.12814": {"publish_time": "2022-02-25", "title": "The Reality of Multi-Lingual Machine Translation", "author": "Tom Kocmi et.al.", "abstract": "Our book \"The Reality of Multi-Lingual Machine Translation\" discusses the benefits and perils of using more than two languages in machine translation systems. While focused on the particular task of sequence-to-sequence processing and multi-task learning, the book targets somewhat beyond the area of natural language processing. Machine translation is for us a prime example of deep learning applications where human skills and learning capabilities are taken as a benchmark that many try to match and surpass. We document that some of the gains observed in multi-lingual translation may result from simpler effects than the assumed cross-lingual transfer of knowledge.   In the first, rather general part, the book will lead you through the motivation for multi-linguality, the versatility of deep neural networks especially in sequence-to-sequence tasks to complications of this learning. We conclude the general part with warnings against too optimistic and unjustified explanations of the gains that neural networks demonstrate.   In the second part, we fully delve into multi-lingual models, with a particularly careful examination of transfer learning as one of the more straightforward approaches utilizing additional languages. The recent multi-lingual techniques, including massive models, are surveyed and practical aspects of deploying systems for many languages are discussed. The conclusion highlights the open problem of machine understanding and reminds of two ethical aspects of building large-scale models: the inclusivity of research and its ecological trace.", "paper_url": "http://arxiv.org/abs/2202.12814v1", "pdf_url": "http://arxiv.org/pdf/2202.12814v1", "repo_url": null}, "2202.12801": {"publish_time": "2022-02-25", "title": "On the data requirements of probing", "author": "Zining Zhu et.al.", "abstract": "As large and powerful neural language models are developed, researchers have been increasingly interested in developing diagnostic tools to probe them. There are many papers with conclusions of the form \"observation X is found in model Y\", using their own datasets with varying sizes. Larger probing datasets bring more reliability, but are also expensive to collect. There is yet to be a quantitative method for estimating reasonable probing dataset sizes. We tackle this omission in the context of comparing two probing configurations: after we have collected a small dataset from a pilot study, how many additional data samples are sufficient to distinguish two different configurations? We present a novel method to estimate the required number of data samples in such experiments and, across several case studies, we verify that our estimations have sufficient statistical power. Our framework helps to systematically construct probing datasets to diagnose neural NLP models.", "paper_url": "http://arxiv.org/abs/2202.12801v1", "pdf_url": "http://arxiv.org/pdf/2202.12801v1", "repo_url": null}, "2202.14035": {"publish_time": "2022-02-28", "title": "ParaNames: A Massively Multilingual Entity Name Corpus", "author": "Jonne S\u00e4lev\u00e4 et.al.", "abstract": "This preprint describes work in progress on ParaNames, a multilingual parallel name resource consisting of names for approximately 14 million entities. The included names span over 400 languages, and almost all entities are mapped to standardized entity types (PER/LOC/ORG). Using Wikidata as a source, we create the largest resource of this type to-date. We describe our approach to filtering and standardizing the data to provide the best quality possible. ParaNames is useful for multilingual language processing, both in defining tasks for name translation/transliteration and as supplementary data for tasks such as named entity recognition and linking. Our resource is released on GitHub (https://github.com/bltlab/paranames) under a Creative Commons license (CC BY 4.0).", "paper_url": "http://arxiv.org/abs/2202.14035v1", "pdf_url": "http://arxiv.org/pdf/2202.14035v1", "repo_url": null}, "2202.13972": {"publish_time": "2022-02-28", "title": "The impact of lexical and grammatical processing on generating code from natural language", "author": "Nathana\u00ebl Beau et.al.", "abstract": "Considering the seq2seq architecture of TranX for natural language to code translation, we identify four key components of importance: grammatical constraints, lexical preprocessing, input representations, and copy mechanisms. To study the impact of these components, we use a state-of-the-art architecture that relies on BERT encoder and a grammar-based decoder for which a formalization is provided. The paper highlights the importance of the lexical substitution component in the current natural language to code systems.", "paper_url": "http://arxiv.org/abs/2202.13972v1", "pdf_url": "http://arxiv.org/pdf/2202.13972v1", "repo_url": null}, "2202.13914": {"publish_time": "2022-02-28", "title": "Combining Modular Skills in Multitask Learning", "author": "Edoardo M. Ponti et.al.", "abstract": "A modular design encourages neural models to disentangle and recombine different facets of knowledge to generalise more systematically to new tasks. In this work, we assume that each task is associated with a subset of latent discrete skills from a (potentially small) inventory. In turn, skills correspond to parameter-efficient (sparse / low-rank) model parameterisations. By jointly learning these and a task-skill allocation matrix, the network for each task is instantiated as the average of the parameters of active skills. To favour non-trivial soft partitions of skills across tasks, we experiment with a series of inductive biases, such as an Indian Buffet Process prior and a two-speed learning rate. We evaluate our latent-skill model on two main settings: 1) multitask reinforcement learning for grounded instruction following on 8 levels of the BabyAI platform; and 2) few-shot adaptation of pre-trained text-to-text generative models on CrossFit, a benchmark comprising 160 NLP tasks. We find that the modular design of a network significantly increases sample efficiency in reinforcement learning and few-shot generalisation in supervised learning, compared to baselines with fully shared, task-specific, or conditionally generated parameters where knowledge is entangled across tasks. In addition, we show how discrete skills help interpretability, as they yield an explicit hierarchy of tasks.", "paper_url": "http://arxiv.org/abs/2202.13914v1", "pdf_url": "http://arxiv.org/pdf/2202.13914v1", "repo_url": null}, "2202.13887": {"publish_time": "2022-02-28", "title": "Probing the Robustness of Trained Metrics for Conversational Dialogue Systems", "author": "Jan Deriu et.al.", "abstract": "This paper introduces an adversarial method to stress-test trained metrics to evaluate conversational dialogue systems. The method leverages Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics. We apply our method to test recently proposed trained metrics. We find that they all are susceptible to giving high scores to responses generated by relatively simple and obviously flawed strategies that our method converges on. For instance, simply copying parts of the conversation context to form a response yields competitive scores or even outperforms responses written by humans.", "paper_url": "http://arxiv.org/abs/2202.13887v1", "pdf_url": "http://arxiv.org/pdf/2202.13887v1", "repo_url": null}, "2202.13876": {"publish_time": "2022-02-28", "title": "PMC-Patients: A Large-scale Dataset of Patient Notes and Relations Extracted from Case Reports in PubMed Central", "author": "Zhengyun Zhao et.al.", "abstract": "We present PMC-Patients, a dataset consisting of 167k patient notes with 3.1M relevant article annotations and 293k similar patient annotations. The patient notes are extracted by identifying certain sections from case reports in PubMed Central, and those with at least CC BY-NC-SA license are re-distributed. Patient-article relevance and patient-patient similarity are defined by citation relationships in PubMed. We also perform four tasks with PMC-Patients to demonstrate its utility, including Patient Note Recognition (PNR), Patient-Patient Similarity (PPS), Patient-Patient Retrieval (PPR), and Patient-Article Retrieval (PAR). In summary, PMC-Patients provides the largest-scale patient notes with high quality, diverse conditions, easy access, and rich annotations.", "paper_url": "http://arxiv.org/abs/2202.13876v1", "pdf_url": "http://arxiv.org/pdf/2202.13876v1", "repo_url": "https://github.com/zhao-zy15/pmc-patients"}, "2203.00674": {"publish_time": "2022-03-01", "title": "Advancing an Interdisciplinary Science of Conversation: Insights from a Large Multimodal Corpus of Human Speech", "author": "Andrew Reece et.al.", "abstract": "People spend a substantial portion of their lives engaged in conversation, and yet our scientific understanding of conversation is still in its infancy. In this report we advance an interdisciplinary science of conversation, with findings from a large, novel, multimodal corpus of 1,656 recorded conversations in spoken English. This 7+ million word, 850 hour corpus totals over 1TB of audio, video, and transcripts, with moment-to-moment measures of vocal, facial, and semantic expression, along with an extensive survey of speaker post conversation reflections. We leverage the considerable scope of the corpus to (1) extend key findings from the literature, such as the cooperativeness of human turn-taking; (2) define novel algorithmic procedures for the segmentation of speech into conversational turns; (3) apply machine learning insights across various textual, auditory, and visual features to analyze what makes conversations succeed or fail; and (4) explore how conversations are related to well-being across the lifespan. We also report (5) a comprehensive mixed-method report, based on quantitative analysis and qualitative review of each recording, that showcases how individuals from diverse backgrounds alter their communication patterns and find ways to connect. We conclude with a discussion of how this large-scale public dataset may offer new directions for future research, especially across disciplinary boundaries, as scholars from a variety of fields appear increasingly interested in the study of conversation.", "paper_url": "http://arxiv.org/abs/2203.00674v1", "pdf_url": "http://arxiv.org/pdf/2203.00674v1", "repo_url": null}, "2203.00648": {"publish_time": "2022-03-01", "title": "Measuring the Impact of Individual Domain Factors in Self-Supervised Pre-Training", "author": "Ramon Sanabria et.al.", "abstract": "Human speech data comprises a rich set of domain factors such as accent, syntactic and semantic variety, or acoustic environment. Previous work explores the effect of domain mismatch in automatic speech recognition between pre-training and fine-tuning as a whole but does not dissect the contribution of individual factors. In this paper, we present a controlled study to better understand the effect of such factors on the performance of pre-trained representations. To do so, we pre-train models either on modified natural speech or synthesized audio, with a single domain factor modified, and then measure performance on automatic speech recognition after fine tuning. Results show that phonetic domain factors play an important role during pre-training while grammatical and syntactic factors are far less important. To our knowledge, this is the first study to better understand the domain characteristics in self-supervised pre-training for speech.", "paper_url": "http://arxiv.org/abs/2203.00648v1", "pdf_url": "http://arxiv.org/pdf/2203.00648v1", "repo_url": null}, "2203.00633": {"publish_time": "2022-03-01", "title": "Transformer Grammars: Augmenting Transformer Language Models with Syntactic Inductive Biases at Scale", "author": "Laurent Sartran et.al.", "abstract": "Transformer language models that are trained on vast amounts of data have achieved remarkable success at various NLP benchmarks. Intriguingly, this success is achieved by models that lack an explicit modeling of hierarchical syntactic structures, which were hypothesized by decades of linguistic research to be necessary for good generalization. This naturally leaves a question: to what extent can we further improve the performance of Transformer language models, through an inductive bias that encourages the model to explain the data through the lens of recursive syntactic compositions? Although the benefits of modeling recursive syntax have been shown at the small data and model scales, it remains an open question whether -- and to what extent -- a similar design principle is still beneficial in the case of powerful Transformer language models that work well at scale. To answer these questions, we introduce Transformer Grammars -- a novel class of Transformer language models that combine: (i) the expressive power, scalability, and strong performance of Transformers, and (ii) recursive syntactic compositions, which here are implemented through a special attention mask. We find that Transformer Grammars outperform various strong baselines on multiple syntax-sensitive language modeling evaluation metrics, in addition to sentence-level language modeling perplexity. Nevertheless, we find that the recursive syntactic composition bottleneck harms perplexity on document-level modeling, providing evidence that a different kind of memory mechanism -- that works independently of syntactic structures -- plays an important role in the processing of long-form text.", "paper_url": "http://arxiv.org/abs/2203.00633v1", "pdf_url": "http://arxiv.org/pdf/2203.00633v1", "repo_url": null}, "2203.00613": {"publish_time": "2022-03-01", "title": "Towards a Common Speech Analysis Engine", "author": "Hagai Aronowitz et.al.", "abstract": "Recent innovations in self-supervised representation learning have led to remarkable advances in natural language processing. That said, in the speech processing domain, self-supervised representation learning-based systems are not yet considered state-of-the-art. We propose leveraging recent advances in self-supervised-based speech processing to create a common speech analysis engine. Such an engine should be able to handle multiple speech processing tasks, using a single architecture, to obtain state-of-the-art accuracy. The engine must also enable support for new tasks with small training datasets. Beyond that, a common engine should be capable of supporting distributed training with client in-house private data. We present the architecture for a common speech analysis engine based on the HuBERT self-supervised speech representation. Based on experiments, we report our results for language identification and emotion recognition on the standard evaluations NIST-LRE 07 and IEMOCAP. Our results surpass the state-of-the-art performance reported so far on these tasks. We also analyzed our engine on the emotion recognition task using reduced amounts of training data and show how to achieve improved results.", "paper_url": "http://arxiv.org/abs/2203.00613v1", "pdf_url": "http://arxiv.org/pdf/2203.00613v1", "repo_url": null}, "2203.00588": {"publish_time": "2022-03-01", "title": "Structural invariants and semantic fingerprints in the \"ego network\" of words", "author": "Kilian Ollivier et.al.", "abstract": "Well-established cognitive models coming from anthropology have shown that, due to the cognitive constraints that limit our \"bandwidth\" for social interactions, humans organize their social relations according to a regular structure. In this work, we postulate that similar regularities can be found in other cognitive processes, such as those involving language production. In order to investigate this claim, we analyse a dataset containing tweets of a heterogeneous group of Twitter users (regular users and professional writers). Leveraging a methodology similar to the one used to uncover the well-established social cognitive constraints, we find regularities at both the structural and semantic level. At the former, we find that a concentric layered structure (which we call ego network of words, in analogy to the ego network of social relationships) very well captures how individuals organise the words they use. The size of the layers in this structure regularly grows (approximately 2-3 times with respect to the previous one) when moving outwards, and the two penultimate external layers consistently account for approximately 60% and 30% of the used words, irrespective of the number of the total number of layers of the user. For the semantic analysis, each ring of each ego network is described by a semantic profile, which captures the topics associated with the words in the ring. We find that ring #1 has a special role in the model. It is semantically the most dissimilar and the most diverse among the rings. We also show that the topics that are important in the innermost ring also have the characteristic of being predominant in each of the other rings, as well as in the entire ego network. In this respect, ring #1 can be seen as the semantic fingerprint of the ego network of words.", "paper_url": "http://arxiv.org/abs/2203.00588v1", "pdf_url": "http://arxiv.org/pdf/2203.00588v1", "repo_url": null}, "2203.01311": {"publish_time": "2022-03-02", "title": "HighMMT: Towards Modality and Task Generalization for High-Modality Representation Learning", "author": "Paul Pu Liang et.al.", "abstract": "Learning multimodal representations involves discovering correspondences and integrating information from multiple heterogeneous sources of data. While recent research has begun to explore the design of more general-purpose multimodal models (contrary to prior focus on domain and modality-specific architectures), these methods are still largely focused on a small set of modalities in the language, vision, and audio space. In order to accelerate generalization towards diverse and understudied modalities, we investigate methods for high-modality (a large set of diverse modalities) and partially-observable (each task only defined on a small subset of modalities) scenarios. To tackle these challenges, we design a general multimodal model that enables multitask and transfer learning: multitask learning with shared parameters enables stable parameter counts (addressing scalability), and cross-modal transfer learning enables information sharing across modalities and tasks (addressing partial observability). Our resulting model generalizes across text, image, video, audio, time-series, sensors, tables, and set modalities from different research areas, improves the tradeoff between performance and efficiency, transfers to new modalities and tasks, and reveals surprising insights on the nature of information sharing in multitask models. We release our code and benchmarks which we hope will present a unified platform for subsequent theoretical and empirical analysis: https://github.com/pliang279/HighMMT.", "paper_url": "http://arxiv.org/abs/2203.01311v1", "pdf_url": "http://arxiv.org/pdf/2203.01311v1", "repo_url": null}, "2203.01294": {"publish_time": "2022-03-02", "title": "Providing Insights for Open-Response Surveys via End-to-End Context-Aware Clustering", "author": "Soheil Esmaeilzadeh et.al.", "abstract": "Teachers often conduct surveys in order to collect data from a predefined group of students to gain insights into topics of interest. When analyzing surveys with open-ended textual responses, it is extremely time-consuming, labor-intensive, and difficult to manually process all the responses into an insightful and comprehensive report. In the analysis step, traditionally, the teacher has to read each of the responses and decide on how to group them in order to extract insightful information. Even though it is possible to group the responses only using certain keywords, such an approach would be limited since it not only fails to account for embedded contexts but also cannot detect polysemous words or phrases and semantics that are not expressible in single words. In this work, we present a novel end-to-end context-aware framework that extracts, aggregates, and abbreviates embedded semantic patterns in open-response survey data. Our framework relies on a pre-trained natural language model in order to encode the textual data into semantic vectors. The encoded vectors then get clustered either into an optimally tuned number of groups or into a set of groups with pre-specified titles. In the former case, the clusters are then further analyzed to extract a representative set of keywords or summary sentences that serve as the labels of the clusters. In our framework, for the designated clusters, we finally provide context-aware wordclouds that demonstrate the semantically prominent keywords within each group. Honoring user privacy, we have successfully built the on-device implementation of our framework suitable for real-time analysis on mobile devices and have tested it on a synthetic dataset. Our framework reduces the costs at-scale by automating the process of extracting the most insightful information pieces from survey data.", "paper_url": "http://arxiv.org/abs/2203.01294v1", "pdf_url": "http://arxiv.org/pdf/2203.01294v1", "repo_url": null}, "2203.01282": {"publish_time": "2022-03-02", "title": "$\\texttt{py-irt}$: A Scalable Item Response Theory Library for Python", "author": "John P. Lalor et.al.", "abstract": "$\\texttt{py-irt}$ is a Python library for fitting Bayesian Item Response Theory (IRT) models. $\\texttt{py-irt}$ estimates latent traits of subjects and items, making it appropriate for use in IRT tasks as well as ideal-point models. $\\texttt{py-irt}$ is built on top of the Pyro and PyTorch frameworks and uses GPU-accelerated training to scale to large data sets. Code, documentation, and examples can be found at https://github.com/nd-ball/py-irt. $\\texttt{py-irt}$ can be installed from the GitHub page or the Python Package Index (PyPI).", "paper_url": "http://arxiv.org/abs/2203.01282v1", "pdf_url": "http://arxiv.org/pdf/2203.01282v1", "repo_url": "https://github.com/nd-ball/py-irt"}, "2203.01215": {"publish_time": "2022-03-02", "title": "Mukayese: Turkish NLP Strikes Back", "author": "Ali Safaya et.al.", "abstract": "Having sufficient resources for language X lifts it from the under-resourced languages class, but not necessarily from the under-researched class. In this paper, we address the problem of the absence of organized benchmarks in the Turkish language. We demonstrate that languages such as Turkish are left behind the state-of-the-art in NLP applications. As a solution, we present Mukayese, a set of NLP benchmarks for the Turkish language that contains several NLP tasks. We work on one or more datasets for each benchmark and present two or more baselines. Moreover, we present four new benchmarking datasets in Turkish for language modeling, sentence segmentation, and spell checking. All datasets and baselines are available under: https://github.com/alisafaya/mukayese", "paper_url": "http://arxiv.org/abs/2203.01215v1", "pdf_url": "http://arxiv.org/pdf/2203.01215v1", "repo_url": "https://github.com/alisafaya/mukayese"}, "2203.01111": {"publish_time": "2022-03-02", "title": "Large-Scale Hate Speech Detection with Cross-Domain Transfer", "author": "Cagri Toraman et.al.", "abstract": "The performance of hate speech detection models relies on the datasets on which the models are trained. Existing datasets are mostly prepared with a limited number of instances or hate domains that define hate topics. This hinders large-scale analysis and transfer learning with respect to hate domains. In this study, we construct large-scale tweet datasets for hate speech detection in English and a low-resource language, Turkish, consisting of human-labeled 100k tweets per each. Our datasets are designed to have equal number of tweets distributed over five domains. The experimental results supported by statistical tests show that Transformer-based language models outperform conventional bag-of-words and neural models by at least 5% in English and 10% in Turkish for large-scale hate speech detection. The performance is also scalable to different training sizes, such that 98% of performance in English, and 97% in Turkish, are recovered when 20% of training instances are used. We further examine the generalization ability of cross-domain transfer among hate domains. We show that 96% of the performance of a target domain in average is recovered by other domains for English, and 92% for Turkish. Gender and religion are more successful to generalize to other domains, while sports fail most.", "paper_url": "http://arxiv.org/abs/2203.01111v1", "pdf_url": "http://arxiv.org/pdf/2203.01111v1", "repo_url": "https://github.com/avaapm/hatespeech"}, "2203.01927": {"publish_time": "2022-03-03", "title": "As Little as Possible, as Much as Necessary: Detecting Over- and Undertranslations with Contrastive Conditioning", "author": "Jannis Vamvas et.al.", "abstract": "Omission and addition of content is a typical issue in neural machine translation. We propose a method for detecting such phenomena with off-the-shelf translation models. Using contrastive conditioning, we compare the likelihood of a full sequence under a translation model to the likelihood of its parts, given the corresponding source or target sequence. This allows to pinpoint superfluous words in the translation and untranslated words in the source even in the absence of a reference translation. The accuracy of our method is comparable to a supervised method that requires a custom quality estimation model.", "paper_url": "http://arxiv.org/abs/2203.01927v1", "pdf_url": "http://arxiv.org/pdf/2203.01927v1", "repo_url": "https://github.com/zurichnlp/coverage-contrastive-conditioning"}, "2203.01922": {"publish_time": "2022-03-03", "title": "Vision-Language Intelligence: Tasks, Representation Learning, and Large Models", "author": "Feng Li et.al.", "abstract": "This paper presents a comprehensive survey of vision-language (VL) intelligence from the perspective of time. This survey is inspired by the remarkable progress in both computer vision and natural language processing, and recent trends shifting from single modality processing to multiple modality comprehension. We summarize the development in this field into three time periods, namely task-specific methods, vision-language pre-training (VLP) methods, and larger models empowered by large-scale weakly-labeled data. We first take some common VL tasks as examples to introduce the development of task-specific methods. Then we focus on VLP methods and comprehensively review key components of the model structures and training methods. After that, we show how recent work utilizes large-scale raw image-text data to learn language-aligned visual representations that generalize better on zero or few shot learning tasks. Finally, we discuss some potential future trends towards modality cooperation, unified representation, and knowledge incorporation. We believe that this review will be of help for researchers and practitioners of AI and ML, especially those interested in computer vision and natural language processing.", "paper_url": "http://arxiv.org/abs/2203.01922v1", "pdf_url": "http://arxiv.org/pdf/2203.01922v1", "repo_url": null}, "2203.01849": {"publish_time": "2022-03-03", "title": "Context Enhanced Short Text Matching using Clickthrough Data", "author": "Mao Yan Chen et.al.", "abstract": "The short text matching task employs a model to determine whether two short texts have the same semantic meaning or intent. Existing short text matching models usually rely on the content of short texts which are lack information or missing some key clues. Therefore, the short texts need external knowledge to complete their semantic meaning. To address this issue, we propose a new short text matching framework for introducing external knowledge to enhance the short text contextual representation. In detail, we apply a self-attention mechanism to enrich short text representation with external contexts. Experiments on two Chinese datasets and one English dataset demonstrate that our framework outperforms the state-of-the-art short text matching models.", "paper_url": "http://arxiv.org/abs/2203.01849v1", "pdf_url": "http://arxiv.org/pdf/2203.01849v1", "repo_url": null}, "2203.01769": {"publish_time": "2022-03-03", "title": "PeerSum: A Peer Review Dataset for Abstractive Multi-document Summarization", "author": "Miao Li et.al.", "abstract": "We present PeerSum, a new MDS dataset using peer reviews of scientific publications. Our dataset differs from the existing MDS datasets in that our summaries (i.e., the meta-reviews) are highly abstractive and they are real summaries of the source documents (i.e., the reviews) and it also features disagreements among source documents. We found that current state-of-the-art MDS models struggle to generate high-quality summaries for PeerSum, offering new research opportunities.", "paper_url": "http://arxiv.org/abs/2203.01769v1", "pdf_url": "http://arxiv.org/pdf/2203.01769v1", "repo_url": "https://github.com/oaimli/peersum"}, "2203.01677": {"publish_time": "2022-03-03", "title": "Detection of Word Adversarial Examples in Text Classification: Benchmark and Baseline via Robust Density Estimation", "author": "KiYoon Yoo et.al.", "abstract": "Word-level adversarial attacks have shown success in NLP models, drastically decreasing the performance of transformer-based models in recent years. As a countermeasure, adversarial defense has been explored, but relatively few efforts have been made to detect adversarial examples. However, detecting adversarial examples may be crucial for automated tasks (e.g. review sentiment analysis) that wish to amass information about a certain population and additionally be a step towards a robust defense system. To this end, we release a dataset for four popular attack methods on four datasets and four models to encourage further research in this field. Along with it, we propose a competitive baseline based on density estimation that has the highest AUC on 29 out of 30 dataset-attack-model combinations. Source code is available in https://github.com/anoymous92874838/text-adv-detection.", "paper_url": "http://arxiv.org/abs/2203.01677v1", "pdf_url": "http://arxiv.org/pdf/2203.01677v1", "repo_url": "https://github.com/anoymous92874838/text-adv-detection"}, "2203.02459": {"publish_time": "2022-03-04", "title": "From Simultaneous to Streaming Machine Translation by Leveraging Streaming History", "author": "Javier Iranzo-S\u00e1nchez et.al.", "abstract": "Simultaneous Machine Translation is the task of incrementally translating an input sentence before it is fully available. Currently, simultaneous translation is carried out by translating each sentence independently of the previously translated text. More generally, Streaming MT can be understood as an extension of Simultaneous MT to the incremental translation of a continuous input text stream. In this work, a state-of-the-art simultaneous sentence-level MT system is extended to the streaming setup by leveraging the streaming history. Extensive empirical results are reported on IWSLT Translation Tasks, showing that leveraging the streaming history leads to significant quality gains. In particular, the proposed system proves to compare favorably to the best performing systems.", "paper_url": "http://arxiv.org/abs/2203.02459v1", "pdf_url": "http://arxiv.org/pdf/2203.02459v1", "repo_url": null}, "2203.02458": {"publish_time": "2022-03-04", "title": "Comprehension of Subtitles from Re-Translating Simultaneous Speech Translation", "author": "D\u00e1vid Javorsk\u00fd et.al.", "abstract": "In simultaneous speech translation, one can vary the size of the output window, system latency and sometimes the allowed level of rewriting. The effect of these properties on readability and comprehensibility has not been tested with modern neural translation systems. In this work, we propose an evaluation method and investigate the effects on comprehension and user preferences. It is a pilot study with 14 users on 2 hours of German documentaries or speeches with online translations into Czech. We collect continuous feedback and answers on factual questions. Our results show that the subtitling layout or flicker have a little effect on comprehension, in contrast to machine translation itself and individual competence. Other results show that users with a limited knowledge of the source language have different preferences to stability and latency than the users with zero knowledge. The results are statistically insignificant, however, we show that our method works and can be reproduced in larger volume.", "paper_url": "http://arxiv.org/abs/2203.02458v1", "pdf_url": "http://arxiv.org/pdf/2203.02458v1", "repo_url": null}, "2203.02392": {"publish_time": "2022-03-04", "title": "Beyond Plain Toxic: Detection of Inappropriate Statements on Flammable Topics for the Russian Language", "author": "Nikolay Babakov et.al.", "abstract": "Toxicity on the Internet, such as hate speech, offenses towards particular users or groups of people, or the use of obscene words, is an acknowledged problem. However, there also exist other types of inappropriate messages which are usually not viewed as toxic, e.g. as they do not contain explicit offences. Such messages can contain covered toxicity or generalizations, incite harmful actions (crime, suicide, drug use), provoke \"heated\" discussions. Such messages are often related to particular sensitive topics, e.g. on politics, sexual minorities, social injustice which more often than other topics, e.g. cars or computing, yield toxic emotional reactions. At the same time, clearly not all messages within such flammable topics are inappropriate.   Towards this end, in this work, we present two text collections labelled according to binary notion of inapropriateness and a multinomial notion of sensitive topic. Assuming that the notion of inappropriateness is common among people of the same culture, we base our approach on human intuitive understanding of what is not acceptable and harmful. To objectivise the notion of inappropriateness, we define it in a data-driven way though crowdsourcing. Namely we run a large-scale annotation study asking workers if a given chatbot textual statement could harm reputation of a company created it. Acceptably high values of inter-annotator agreement suggest that the notion of inappropriateness exists and can be uniformly understood by different people. To define the notion of sensitive topics in an objective way we use on guidelines suggested commonly by specialists of legal and PR department of a large public company as potentially harmful.", "paper_url": "http://arxiv.org/abs/2203.02392v1", "pdf_url": "http://arxiv.org/pdf/2203.02392v1", "repo_url": null}, "2203.02385": {"publish_time": "2022-03-04", "title": "MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations", "author": "Dou Hu et.al.", "abstract": "Emotion Recognition in Conversations (ERC) has considerable prospects for developing empathetic machines. For multimodal ERC, it is vital to understand context and fuse modality information in conversations. Recent graph-based fusion methods generally aggregate multimodal information by exploring unimodal and cross-modal interactions in a graph. However, they accumulate redundant information at each layer, limiting the context understanding between modalities. In this paper, we propose a novel Multimodal Dynamic Fusion Network (MM-DFN) to recognize emotions by fully understanding multimodal conversational context. Specifically, we design a new graph-based dynamic fusion module to fuse multimodal contextual features in a conversation. The module reduces redundancy and enhances complementarity between modalities by capturing the dynamics of contextual information in different semantic spaces. Extensive experiments on two public benchmark datasets demonstrate the effectiveness and superiority of MM-DFN.", "paper_url": "http://arxiv.org/abs/2203.02385v1", "pdf_url": "http://arxiv.org/pdf/2203.02385v1", "repo_url": "https://github.com/zerohd4869/mm-dfn"}, "2203.02244": {"publish_time": "2022-03-04", "title": "IISERB Brains at SemEval 2022 Task 6: A Deep-learning Framework to Identify Intended Sarcasm in English", "author": "Tanuj Singh Shekhawat et.al.", "abstract": "This paper describes the system architectures and the models submitted by our team \"IISERBBrains\" to SemEval 2022 Task 6 competition. We contested for all three sub-tasks floated for the English dataset. On the leader-board, wegot19th rank out of43 teams for sub-taskA, the 8th rank out of22 teams for sub-task B,and13th rank out of 16 teams for sub-taskC. Apart from the submitted results and models, we also report the other models and results that we obtained through our experiments after organizers published the gold labels of their evaluation data", "paper_url": "http://arxiv.org/abs/2203.02244v1", "pdf_url": "http://arxiv.org/pdf/2203.02244v1", "repo_url": "https://github.com/manojmahan/isarcasmeval-intended-sarcasm-detection-in-english-main"}, "2203.03601": {"publish_time": "2022-03-07", "title": "Creating Speech-to-Speech Corpus from Dubbed Series", "author": "Massa Baali et.al.", "abstract": "Dubbed series are gaining a lot of popularity in recent years with strong support from major media service providers. Such popularity is fueled by studies that showed that dubbed versions of TV shows are more popular than their subtitled equivalents. We propose an unsupervised approach to construct speech-to-speech corpus, aligned on short segment levels, to produce a parallel speech corpus in the source- and target- languages. Our methodology exploits video frames, speech recognition, machine translation, and noisy frames removal algorithms to match segments in both languages. To verify the performance of the proposed method, we apply it on long and short dubbed clips. Out of 36 hours TR-AR dubbed series, our pipeline was able to generate 17 hours of paired segments, which is about 47% of the corpus. We applied our method on another language pair, EN-AR, to ensure it is robust enough and not tuned for a specific language or a specific corpus. Regardless of the language pairs, the accuracy of the paired segments was around 70% when evaluated using human subjective evaluation. The corpus will be freely available for the research community.", "paper_url": "http://arxiv.org/abs/2203.03601v1", "pdf_url": "http://arxiv.org/pdf/2203.03601v1", "repo_url": "https://github.com/massabaali7/speech_parallel_corpus"}, "2203.03598": {"publish_time": "2022-03-07", "title": "Audio-visual Generalised Zero-shot Learning with Cross-modal Attention and Language", "author": "Otniel-Bogdan Mercea et.al.", "abstract": "Learning to classify video data from classes not included in the training data, i.e. video-based zero-shot learning, is challenging. We conjecture that the natural alignment between the audio and visual modalities in video data provides a rich training signal for learning discriminative multi-modal representations. Focusing on the relatively underexplored task of audio-visual zero-shot learning, we propose to learn multi-modal representations from audio-visual data using cross-modal attention and exploit textual label embeddings for transferring knowledge from seen classes to unseen classes. Taking this one step further, in our generalised audio-visual zero-shot learning setting, we include all the training classes in the test-time search space which act as distractors and increase the difficulty while making the setting more realistic. Due to the lack of a unified benchmark in this domain, we introduce a (generalised) zero-shot learning benchmark on three audio-visual datasets of varying sizes and difficulty, VGGSound, UCF, and ActivityNet, ensuring that the unseen test classes do not appear in the dataset used for supervised training of the backbone deep models. Comparing multiple relevant and recent methods, we demonstrate that our proposed AVCA model achieves state-of-the-art performance on all three datasets. Code and data will be available at \\url{https://github.com/ExplainableML/AVCA-GZSL}.", "paper_url": "http://arxiv.org/abs/2203.03598v1", "pdf_url": "http://arxiv.org/pdf/2203.03598v1", "repo_url": "https://github.com/explainableml/avca-gzsl"}, "2203.03463": {"publish_time": "2022-03-07", "title": "Hierarchical Sketch Induction for Paraphrase Generation", "author": "Tom Hosking et.al.", "abstract": "We propose a generative model of paraphrase generation, that encourages syntactic diversity by conditioning on an explicit syntactic sketch. We introduce Hierarchical Refinement Quantized Variational Autoencoders (HRQ-VAE), a method for learning decompositions of dense encodings as a sequence of discrete latent variables that make iterative refinements of increasing granularity. This hierarchy of codes is learned through end-to-end training, and represents fine-to-coarse grained information about the input. We use HRQ-VAE to encode the syntactic form of an input sentence as a path through the hierarchy, allowing us to more easily predict syntactic sketches at test time. Extensive experiments, including a human evaluation, confirm that HRQ-VAE learns a hierarchical representation of the input space, and generates paraphrases of higher quality than previous systems.", "paper_url": "http://arxiv.org/abs/2203.03463v1", "pdf_url": "http://arxiv.org/pdf/2203.03463v1", "repo_url": "https://github.com/tomhosking/hrq-vae"}, "2203.03442": {"publish_time": "2022-03-07", "title": "Towards Automated Real-time Evaluation in Text-based Counseling", "author": "Anqi Li et.al.", "abstract": "Automated real-time evaluation of counselor-client interaction is important for ensuring quality counseling but the rules are difficult to articulate. Recent advancements in machine learning methods show the possibility of learning such rules automatically. However, these methods often demand large scale and high quality counseling data, which are difficult to collect. To address this issue, we build an online counseling platform, which allows professional psychotherapists to provide free counseling services to those are in need. In exchange, we collect the counseling transcripts. Within a year of its operation, we manage to get one of the largest set of (675) transcripts of counseling sessions. To further leverage the valuable data we have, we label our dataset using both coarse- and fine-grained labels and use a set of pretraining techniques. In the end, we are able to achieve practically useful accuracy in both labeling system.", "paper_url": "http://arxiv.org/abs/2203.03442v1", "pdf_url": "http://arxiv.org/pdf/2203.03442v1", "repo_url": null}, "2203.03441": {"publish_time": "2022-03-07", "title": "Multi-Modal Attribute Extraction for E-Commerce", "author": "Alo\u00efs De la Comble et.al.", "abstract": "To improve users' experience as they navigate the myriad of options offered by online marketplaces, it is essential to have well-organized product catalogs. One key ingredient to that is the availability of product attributes such as color or material. However, on some marketplaces such as Rakuten-Ichiba, which we focus on, attribute information is often incomplete or even missing. One promising solution to this problem is to rely on deep models pre-trained on large corpora to predict attributes from unstructured data, such as product descriptive texts and images (referred to as modalities in this paper). However, we find that achieving satisfactory performance with this approach is not straightforward but rather the result of several refinements, which we discuss in this paper. We provide a detailed description of our approach to attribute extraction, from investigating strong single-modality methods, to building a solid multimodal model combining textual and visual information. One key component of our multimodal architecture is a novel approach to seamlessly combine modalities, which is inspired by our single-modality investigations. In practice, we notice that this new modality-merging method may suffer from a modality collapse issue, i.e., it neglects one modality. Hence, we further propose a mitigation to this problem based on a principled regularization scheme. Experiments on Rakuten-Ichiba data provide empirical evidence for the benefits of our approach, which has been also successfully deployed to Rakuten-Ichiba. We also report results on publicly available datasets showing that our model is competitive compared to several recent multimodal and unimodal baselines.", "paper_url": "http://arxiv.org/abs/2203.03441v1", "pdf_url": "http://arxiv.org/pdf/2203.03441v1", "repo_url": null}, "2203.04218": {"publish_time": "2022-03-08", "title": "Learning Bidirectional Translation between Descriptions and Actions with Small Paired Data", "author": "Minori Toyoda et.al.", "abstract": "This study achieved bidirectional translation between descriptions and actions using small paired data. The ability to mutually generate descriptions and actions is essential for robots to collaborate with humans in their daily lives. The robot is required to associate real-world objects with linguistic expressions, and large-scale paired data are required for machine learning approaches. However, a paired dataset is expensive to construct and difficult to collect. This study proposes a two-stage training method for bidirectional translation. In the proposed method, we train recurrent autoencoders (RAEs) for descriptions and actions with a large amount of non-paired data. Then, we fine-tune the entire model to bind their intermediate representations using small paired data. Because the data used for pre-training do not require pairing, behavior-only data or a large language corpus can be used. We experimentally evaluated our method using a paired dataset consisting of motion-captured actions and descriptions. The results showed that our method performed well, even when the amount of paired data to train was small. The visualization of the intermediate representations of each RAE showed that similar actions were encoded in a clustered position and the corresponding feature vectors well aligned.", "paper_url": "http://arxiv.org/abs/2203.04218v1", "pdf_url": "http://arxiv.org/pdf/2203.04218v1", "repo_url": null}, "2203.04212": {"publish_time": "2022-03-08", "title": "Measuring the Mixing of Contextual Information in the Transformer", "author": "Javier Ferrando et.al.", "abstract": "The Transformer architecture aggregates input information through the self-attention mechanism, but there is no clear understanding of how this information is mixed across the entire model. Additionally, recent works have demonstrated that attention weights alone are not enough to describe the flow of information. In this paper, we consider the whole attention block --multi-head attention, residual connection, and layer normalization-- and define a metric to measure token-to-token interactions within each layer, considering the characteristics of the representation space. Then, we aggregate layer-wise interpretations to provide input attribution scores for model predictions. Experimentally, we show that our method, ALTI (Aggregation of Layer-wise Token-to-token Interactions), provides faithful explanations and outperforms similar aggregation methods.", "paper_url": "http://arxiv.org/abs/2203.04212v1", "pdf_url": "http://arxiv.org/pdf/2203.04212v1", "repo_url": "https://github.com/mt-upc/transformer-contributions"}, "2203.04111": {"publish_time": "2022-03-08", "title": "Plumeria at SemEval-2022 Task 6: Robust Approaches for Sarcasm Detection for English and Arabic Using Transformers and Data Augmentation", "author": "Shubham Kumar Nigam et.al.", "abstract": "This paper describes our submission to SemEval-2022 Task 6 on sarcasm detection and its five subtasks for English and Arabic. Sarcasm conveys a meaning which contradicts the literal meaning, and it is mainly found on social networks. It has a significant role in understanding the intention of the user. For detecting sarcasm, we used deep learning techniques based on transformers due to its success in the field of Natural Language Processing (NLP) without the need for feature engineering. The datasets were taken from tweets. We created new datasets by augmenting with external data or by using word embeddings and repetition of instances. Experiments were done on the datasets with different types of preprocessing because it is crucial in this task. The rank of our team was consistent across four subtasks (fourth rank in three subtasks and sixth rank in one subtask); whereas other teams might be in the top ranks for some subtasks but rank drastically less in other subtasks. This implies the robustness and stability of the models and the techniques we used.", "paper_url": "http://arxiv.org/abs/2203.04111v1", "pdf_url": "http://arxiv.org/pdf/2203.04111v1", "repo_url": null}, "2203.04076": {"publish_time": "2022-03-08", "title": "Semantic Distillation Guided Salient Object Detection", "author": "Bo Xu et.al.", "abstract": "Most existing CNN-based salient object detection methods can identify local segmentation details like hair and animal fur, but often misinterpret the real saliency due to the lack of global contextual information caused by the subjectiveness of the SOD task and the locality of convolution layers. Moreover, due to the unrealistically expensive labeling costs, the current existing SOD datasets are insufficient to cover the real data distribution. The limitation and bias of the training data add additional difficulty to fully exploring the semantic association between object-to-object and object-to-environment in a given image. In this paper, we propose a semantic distillation guided SOD (SDG-SOD) method that produces accurate results by fusing semantically distilled knowledge from generated image captioning into the Vision-Transformer-based SOD framework. SDG-SOD can better uncover inter-objects and object-to-environment saliency and cover the gap between the subjective nature of SOD and its expensive labeling. Comprehensive experiments on five benchmark datasets demonstrate that the SDG-SOD outperforms the state-of-the-art approaches on four evaluation metrics, and largely improves the model performance on DUTS, ECSSD, DUT, HKU-IS, and PASCAL-S datasets.", "paper_url": "http://arxiv.org/abs/2203.04076v1", "pdf_url": "http://arxiv.org/pdf/2203.04076v1", "repo_url": null}, "2203.04045": {"publish_time": "2022-03-08", "title": "Towards Generalized Models for Task-oriented Dialogue Modeling on Spoken Conversations", "author": "Ruijie Yan et.al.", "abstract": "Building robust and general dialogue models for spoken conversations is challenging due to the gap in distributions of spoken and written data. This paper presents our approach to build generalized models for the Knowledge-grounded Task-oriented Dialogue Modeling on Spoken Conversations Challenge of DSTC-10. In order to mitigate the discrepancies between spoken and written text, we mainly employ extensive data augmentation strategies on written data, including artificial error injection and round-trip text-speech transformation. To train robust models for spoken conversations, we improve pre-trained language models, and apply ensemble algorithms for each sub-task. Typically, for the detection task, we fine-tune \\roberta and ELECTRA, and run an error-fixing ensemble algorithm. For the selection task, we adopt a two-stage framework that consists of entity tracking and knowledge ranking, and propose a multi-task learning method to learn multi-level semantic information by domain classification and entity selection. For the generation task, we adopt a cross-validation data process to improve pre-trained generative language models, followed by a consensus decoding algorithm, which can add arbitrary features like relative \\rouge metric, and tune associated feature weights toward \\bleu directly. Our approach ranks third on the objective evaluation and second on the final official human evaluation.", "paper_url": "http://arxiv.org/abs/2203.04045v1", "pdf_url": "http://arxiv.org/pdf/2203.04045v1", "repo_url": null}, "2203.04911": {"publish_time": "2022-03-09", "title": "DUAL: Textless Spoken Question Answering with Speech Discrete Unit Adaptive Learning", "author": "Guan-Ting Lin et.al.", "abstract": "Spoken Question Answering (SQA) has gained research attention and made remarkable progress in recent years. However, existing SQA methods rely on Automatic Speech Recognition (ASR) transcripts, which are time and cost-prohibitive to collect. This work proposes an ASR transcript-free SQA framework named Discrete Unit Adaptive Learning (DUAL), which leverages unlabeled data for pre-training and is fine-tuned by the SQA downstream task. DAUL can directly predict the time interval of the spoken answer from the spoken document. We also release a new SQA benchmark corpus Natural Multi-speaker Spoken Question Answering (NMSQA) for testing SQA in realistic scenarios. The experimental results show that DUAL performs competitively with the cascade approach (ASR + text QA), and DUAL is robust to real-world speech. We will open-source our code and model to inspire more SQA innovations from the community", "paper_url": "http://arxiv.org/abs/2203.04911v1", "pdf_url": "http://arxiv.org/pdf/2203.04911v1", "repo_url": null}, "2203.04907": {"publish_time": "2022-03-09", "title": "Pose Guided Multi-person Image Generation From Text", "author": "Soon Yau Cheong et.al.", "abstract": "Transformers have recently been shown to generate high quality images from texts. However, existing methods struggle to create high fidelity full-body images, especially multiple people. A person's pose has a high degree of freedom that is difficult to describe using words only; this creates errors in the generated image, such as incorrect body proportions and pose. We propose a pose-guided text-to-image model, using pose as an additional input constraint. Using the proposed Keypoint Pose Encoding (KPE) to encode human pose into low dimensional representation, our model can generate novel multi-person images accurately representing the pose and text descriptions provided, with minimal errors. We demonstrate that KPE is invariant to changes in the target image domain and image resolution; we show results on the Deepfashion dataset and create a new multi-person Deepfashion dataset to demonstrate the multi-capabilities of our approach.", "paper_url": "http://arxiv.org/abs/2203.04907v1", "pdf_url": "http://arxiv.org/pdf/2203.04907v1", "repo_url": null}, "2203.04904": {"publish_time": "2022-03-09", "title": "Model-Agnostic Multitask Fine-tuning for Few-shot Vision-Language Transfer Learning", "author": "Zhenhailong Wang et.al.", "abstract": "Despite achieving state-of-the-art zero-shot performance, existing vision-language models, e.g., CLIP, still fall short of domain-specific classification tasks, e.g., Fungi Classification. In the context of few-shot transfer learning, traditional fine-tuning fails to prevent highly expressive model from exploiting spurious correlations in the training data. On the other hand, although model-agnostic meta-learning (MAML) presents as a natural alternative for transfer learning, the expensive computation due to implicit second-order optimization limits its use in large-scale models and datasets. In this work we aim to further improve the generalization of existing vision-language models on unseen tasks via a simple yet efficient fine-tuning strategy based on uniform task sampling. We term our method as Model-Agnostic Multitask Fine-tuning (MAMF). Compared with MAML, MAMF discards the bi-level optimization and uses only first-order gradients, which makes it easily scalable and computationally efficient. Due to the uniform task sampling procedure, MAMF consistently outperforms the classical fine-tuning method for few-shot transfer learning on five benchmark datasets. Empirically, we further discover that the effectiveness of first-order MAML is highly dependent on the zero-shot performance of the pretrained model, and our simple algorithm can outperform first-order MAML on more challenging datasets with low zero-shot performance.", "paper_url": "http://arxiv.org/abs/2203.04904v1", "pdf_url": "http://arxiv.org/pdf/2203.04904v1", "repo_url": null}, "2203.04863": {"publish_time": "2022-03-09", "title": "Unsupervised Alignment of Distributional Word Embeddings", "author": "Aissatou Diallo et.al.", "abstract": "Cross-domain alignment play a key roles in tasks ranging from machine translation to transfer learning. Recently, purely unsupervised methods operating on monolingual embeddings have successfully been used to infer a bilingual lexicon without relying on supervision. However, current state-of-the art methods only focus on point vectors although distributional embeddings have proven to embed richer semantic information when representing words. In this paper, we propose stochastic optimization approach for aligning probabilistic embeddings. Finally, we evaluate our method on the problem of unsupervised word translation, by aligning word embeddings trained on monolingual data. We show that the proposed approach achieves good performance on the bilingual lexicon induction task across several language pairs and performs better than the point-vector based approach.", "paper_url": "http://arxiv.org/abs/2203.04863v1", "pdf_url": "http://arxiv.org/pdf/2203.04863v1", "repo_url": null}, "2203.04860": {"publish_time": "2022-03-09", "title": "PET: A new Dataset for Process Extraction from Natural Language Text", "author": "Patrizio Bellan et.al.", "abstract": "Although there is a long tradition of work in NLP on extracting entities and relations from text, to date there exists little work on the acquisition of business processes from unstructured data such as textual corpora of process descriptions. With this work we aim at filling this gap and establishing the first steps towards bridging data-driven information extraction methodologies from Natural Language Processing and the model-based formalization that is aimed from Business Process Management. For this, we develop the first corpus of business process descriptions annotated with activities, gateways, actors and flow information. We present our new resource, including a detailed overview of the annotation schema and guidelines, as well as a variety of baselines to benchmark the difficulty and challenges of business process extraction from text.", "paper_url": "http://arxiv.org/abs/2203.04860v1", "pdf_url": "http://arxiv.org/pdf/2203.04860v1", "repo_url": null}, "2203.05557": {"publish_time": "2022-03-10", "title": "Conditional Prompt Learning for Vision-Language Models", "author": "Kaiyang Zhou et.al.", "abstract": "With the rise of powerful pre-trained vision-language models like CLIP, it becomes essential to investigate ways to adapt these models to downstream datasets. A recently proposed method named Context Optimization (CoOp) introduces the concept of prompt learning -- a recent trend in NLP -- to the vision domain for adapting pre-trained vision-language models. Specifically, CoOp turns context words in a prompt into a set of learnable vectors and, with only a few labeled images for learning, can achieve huge improvements over intensively-tuned manual prompts. In our study we identify a critical problem of CoOp: the learned context is not generalizable to wider unseen classes within the same dataset, suggesting that CoOp overfits base classes observed during training. To address the problem, we propose Conditional Context Optimization (CoCoOp), which extends CoOp by further learning a lightweight neural network to generate for each image an input-conditional token (vector). Compared to CoOp's static prompts, our dynamic prompts adapt to each instance and are thus less sensitive to class shift. Extensive experiments show that CoCoOp generalizes much better than CoOp to unseen classes, even showing promising transferability beyond a single dataset; and yields stronger domain generalization performance as well. Code is available at https://github.com/KaiyangZhou/CoOp.", "paper_url": "http://arxiv.org/abs/2203.05557v1", "pdf_url": "http://arxiv.org/pdf/2203.05557v1", "repo_url": "https://github.com/kaiyangzhou/coop"}, "2203.05482": {"publish_time": "2022-03-10", "title": "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time", "author": "Mitchell Wortsman et.al.", "abstract": "The conventional recipe for maximizing model accuracy is to (1) train multiple models with various hyperparameters and (2) pick the individual model which performs best on a held-out validation set, discarding the remainder. In this paper, we revisit the second step of this procedure in the context of fine-tuning large pre-trained models, where fine-tuned models often appear to lie in a single low error basin. We show that averaging the weights of multiple models fine-tuned with different hyperparameter configurations often improves accuracy and robustness. Unlike a conventional ensemble, we may average many models without incurring any additional inference or memory costs -- we call the results \"model soups.\" When fine-tuning large pre-trained models such as CLIP, ALIGN, and a ViT-G pre-trained on JFT, our soup recipe provides significant improvements over the best model in a hyperparameter sweep on ImageNet. As a highlight, the resulting ViT-G model attains 90.94% top-1 accuracy on ImageNet, a new state of the art. Furthermore, we show that the model soup approach extends to multiple image classification and natural language processing tasks, improves out-of-distribution performance, and improves zero-shot performance on new downstream tasks. Finally, we analytically relate the performance similarity of weight-averaging and logit-ensembling to flatness of the loss and confidence of the predictions, and validate this relation empirically.", "paper_url": "http://arxiv.org/abs/2203.05482v1", "pdf_url": "http://arxiv.org/pdf/2203.05482v1", "repo_url": null}, "2203.05465": {"publish_time": "2022-03-10", "title": "LoopITR: Combining Dual and Cross Encoder Architectures for Image-Text Retrieval", "author": "Jie Lei et.al.", "abstract": "Dual encoders and cross encoders have been widely used for image-text retrieval. Between the two, the dual encoder encodes the image and text independently followed by a dot product, while the cross encoder jointly feeds image and text as the input and performs dense multi-modal fusion. These two architectures are typically modeled separately without interaction. In this work, we propose LoopITR, which combines them in the same network for joint learning. Specifically, we let the dual encoder provide hard negatives to the cross encoder, and use the more discriminative cross encoder to distill its predictions back to the dual encoder. Both steps are efficiently performed together in the same model. Our work centers on empirical analyses of this combined architecture, putting the main focus on the design of the distillation objective. Our experimental results highlight the benefits of training the two encoders in the same network, and demonstrate that distillation can be quite effective with just a few hard negative examples. Experiments on two standard datasets (Flickr30K and COCO) show our approach achieves state-of-the-art dual encoder performance when compared with approaches using a similar amount of data.", "paper_url": "http://arxiv.org/abs/2203.05465v1", "pdf_url": "http://arxiv.org/pdf/2203.05465v1", "repo_url": null}, "2203.05437": {"publish_time": "2022-03-10", "title": "IndicNLG Suite: Multilingual Datasets for Diverse NLG Tasks in Indic Languages", "author": "Aman Kumar et.al.", "abstract": "In this paper, we present the IndicNLG suite, a collection of datasets for benchmarking Natural Language Generation (NLG) for 11 Indic languages. We focus on five diverse tasks, namely, biography generation using Wikipedia infoboxes (WikiBio), news headline generation, sentence summarization, question generation and paraphrase generation. We describe the process of creating the datasets and present statistics of the dataset, following which we train and report a variety of strong monolingual and multilingual baselines that leverage pre-trained sequence-to-sequence models and analyze the results to understand the challenges involved in Indic language NLG. To the best of our knowledge, this is the first NLG dataset for Indic languages and also the largest multilingual NLG dataset. Our methods can also be easily applied to modest-resource languages with reasonable monolingual and parallel corpora, as well as corpora containing structured data like Wikipedia. We hope this dataset spurs research in NLG on diverse languages and tasks, particularly for Indic languages. The datasets and models are publicly available at https://indicnlp.ai4bharat.org/indicnlg-suite.", "paper_url": "http://arxiv.org/abs/2203.05437v1", "pdf_url": "http://arxiv.org/pdf/2203.05437v1", "repo_url": null}, "2203.05425": {"publish_time": "2022-03-10", "title": "Semantic Norm Recognition and its application to Portuguese Law", "author": "Maria Duarte et.al.", "abstract": "Being able to clearly interpret legal texts and fully understanding our rights, obligations and other legal norms has become progressively more important in the digital society. However, simply giving citizens access to the laws is not enough, as there is a need to provide meaningful information that cater to their specific queries and needs. For this, it is necessary to extract the relevant semantic information present in legal texts. Thus, we introduce the SNR (Semantic Norm Recognition) system, an automatic semantic information extraction system trained on a domain-specific (legal) text corpus taken from Portuguese Consumer Law. The SNR system uses the Portuguese Bert (BERTimbau) and was trained on a legislative Portuguese corpus. We demonstrate how our system achieved good results (81.44\\% F1-score) on this domain-specific corpus, despite existing noise, and how it can be used to improve downstream tasks such as information retrieval.", "paper_url": "http://arxiv.org/abs/2203.05425v1", "pdf_url": "http://arxiv.org/pdf/2203.05425v1", "repo_url": null}, "2203.06169": {"publish_time": "2022-03-11", "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval", "author": "Canwen Xu et.al.", "abstract": "In this paper, we propose LaPraDoR, a pretrained dual-tower dense retriever that does not require any supervised data for training. Specifically, we first present Iterative Contrastive Learning (ICoL) that iteratively trains the query and document encoders with a cache mechanism. ICoL not only enlarges the number of negative instances but also keeps representations of cached examples in the same hidden space. We then propose Lexicon-Enhanced Dense Retrieval (LEDR) as a simple yet effective way to enhance dense retrieval with lexical matching. We evaluate LaPraDoR on the recently proposed BEIR benchmark, including 18 datasets of 9 zero-shot text retrieval tasks. Experimental results show that LaPraDoR achieves state-of-the-art performance compared with supervised dense retrieval models, and further analysis reveals the effectiveness of our training strategy and objectives. Compared to re-ranking, our lexicon-enhanced approach can be run in milliseconds (22.5x faster) while achieving superior performance.", "paper_url": "http://arxiv.org/abs/2203.06169v1", "pdf_url": "http://arxiv.org/pdf/2203.06169v1", "repo_url": "https://github.com/jetrunner/laprador"}, "2203.06096": {"publish_time": "2022-03-11", "title": "WLASL-LEX: a Dataset for Recognising Phonological Properties in American Sign Language", "author": "Federico Tavella et.al.", "abstract": "Signed Language Processing (SLP) concerns the automated processing of signed languages, the main means of communication of Deaf and hearing impaired individuals. SLP features many different tasks, ranging from sign recognition to translation and production of signed speech, but has been overlooked by the NLP community thus far. In this paper, we bring to attention the task of modelling the phonology of sign languages. We leverage existing resources to construct a large-scale dataset of American Sign Language signs annotated with six different phonological properties. We then conduct an extensive empirical study to investigate whether data-driven end-to-end and feature-based approaches can be optimised to automatically recognise these properties. We find that, despite the inherent challenges of the task, graph-based neural networks that operate over skeleton features extracted from raw videos are able to succeed at the task to a varying degree. Most importantly, we show that this performance pertains even on signs unobserved during training.", "paper_url": "http://arxiv.org/abs/2203.06096v1", "pdf_url": "http://arxiv.org/pdf/2203.06096v1", "repo_url": null}, "2203.06063": {"publish_time": "2022-03-11", "title": "Active Evaluation: Efficient NLG Evaluation with Few Pairwise Comparisons", "author": "Akash Kumar Mohankumar et.al.", "abstract": "Recent studies have shown the advantages of evaluating NLG systems using pairwise comparisons as opposed to direct assessment. Given $k$ systems, a naive approach for identifying the top-ranked system would be to uniformly obtain pairwise comparisons from all ${k \\choose 2}$ pairs of systems. However, this can be very expensive as the number of human annotations required would grow quadratically with $k$. In this work, we introduce Active Evaluation, a framework to efficiently identify the top-ranked system by actively choosing system pairs for comparison using dueling bandit algorithms. We perform extensive experiments with 13 dueling bandits algorithms on 13 NLG evaluation datasets spanning 5 tasks and show that the number of human annotations can be reduced by 80%. To further reduce the number of human annotations, we propose model-based dueling bandit algorithms which combine automatic evaluation metrics with human evaluations. Specifically, we eliminate sub-optimal systems even before the human annotation process and perform human evaluations only on test examples where the automatic metric is highly uncertain. This reduces the number of human annotations required further by 89%. In effect, we show that identifying the top-ranked system requires only a few hundred human annotations, which grow linearly with $k$. Lastly, we provide practical recommendations and best practices to identify the top-ranked system efficiently. Our code has been made publicly available at https://github.com/akashkm99/duelnlg", "paper_url": "http://arxiv.org/abs/2203.06063v1", "pdf_url": "http://arxiv.org/pdf/2203.06063v1", "repo_url": "https://github.com/akashkm99/duelnlg"}, "2203.05948": {"publish_time": "2022-03-11", "title": "Block-Sparse Adversarial Attack to Fool Transformer-Based Text Classifiers", "author": "Sahar Sadrizadeh et.al.", "abstract": "Recently, it has been shown that, in spite of the significant performance of deep neural networks in different fields, those are vulnerable to adversarial examples. In this paper, we propose a gradient-based adversarial attack against transformer-based text classifiers. The adversarial perturbation in our method is imposed to be block-sparse so that the resultant adversarial example differs from the original sentence in only a few words. Due to the discrete nature of textual data, we perform gradient projection to find the minimizer of our proposed optimization problem. Experimental results demonstrate that, while our adversarial attack maintains the semantics of the sentence, it can reduce the accuracy of GPT-2 to less than 5% on different datasets (AG News, MNLI, and Yelp Reviews). Furthermore, the block-sparsity constraint of the proposed optimization problem results in small perturbations in the adversarial example.", "paper_url": "http://arxiv.org/abs/2203.05948v1", "pdf_url": "http://arxiv.org/pdf/2203.05948v1", "repo_url": null}, "2203.05936": {"publish_time": "2022-03-11", "title": "Are discrete units necessary for Spoken Language Modeling?", "author": "Tu Anh Nguyen et.al.", "abstract": "Recent work in spoken language modeling shows the possibility of learning a language unsupervisedly from raw audio without any text labels. The approach relies first on transforming the audio into a sequence of discrete units (or pseudo-text) and then training a language model directly on such pseudo-text. Is such a discrete bottleneck necessary, potentially introducing irreversible errors in the encoding of the speech signal, or could we learn a language model without discrete units at all? In this work, show that discretization is indeed essential for good results in spoken language modeling, but that can omit the discrete bottleneck if we use using discrete target features from a higher level than the input features. We also show that an end-to-end model trained with discrete target like HuBERT achieves similar results as the best language model trained on pseudo-text on a set of zero-shot spoken language modeling metrics from the Zero Resource Speech Challenge 2021.", "paper_url": "http://arxiv.org/abs/2203.05936v1", "pdf_url": "http://arxiv.org/pdf/2203.05936v1", "repo_url": null}, "2203.07362": {"publish_time": "2022-03-14", "title": "CoNTACT: A Dutch COVID-19 Adapted BERT for Vaccine Hesitancy and Argumentation Detection", "author": "Jens Lemmens et.al.", "abstract": "We present CoNTACT: a Dutch language model adapted to the domain of COVID-19 tweets. The model was developed by continuing the pre-training phase of RobBERT (Delobelle, 2020) by using 2.8M Dutch COVID-19 related tweets posted in 2021. In order to test the performance of the model and compare it to RobBERT, the two models were tested on two tasks: (1) binary vaccine hesitancy detection and (2) detection of arguments for vaccine hesitancy. For both tasks, not only Twitter but also Facebook data was used to show cross-genre performance. In our experiments, CoNTACT showed statistically significant gains over RobBERT in all experiments for task 1. For task 2, we observed substantial improvements in virtually all classes in all experiments. An error analysis indicated that the domain adaptation yielded better representations of domain-specific terminology, causing CoNTACT to make more accurate classification decisions.", "paper_url": "http://arxiv.org/abs/2203.07362v1", "pdf_url": "http://arxiv.org/pdf/2203.07362v1", "repo_url": null}, "2203.07285": {"publish_time": "2022-03-14", "title": "Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts", "author": "Wenhao Yu et.al.", "abstract": "Generative commonsense reasoning (GCR) in natural language is to reason about the commonsense while generating coherent text. Recent years have seen a surge of interest in improving the generation quality of commonsense reasoning tasks. Nevertheless, these approaches have seldom investigated diversity in the GCR tasks, which aims to generate alternative explanations for a real-world situation or predict all possible outcomes. Diversifying GCR is challenging as it expects to generate multiple outputs that are not only semantically different but also grounded in commonsense knowledge. In this paper, we propose MoKGE, a novel method that diversifies the generative reasoning by a mixture of expert (MoE) strategy on commonsense knowledge graphs (KG). A set of knowledge experts seek diverse reasoning on KG to encourage various generation outputs. Empirical experiments demonstrated that MoKGE can significantly improve the diversity while achieving on par performance on accuracy on two GCR benchmarks, based on both automatic and human evaluations.", "paper_url": "http://arxiv.org/abs/2203.07285v1", "pdf_url": "http://arxiv.org/pdf/2203.07285v1", "repo_url": "https://github.com/DM2-ND/MoKGE"}, "2203.07281": {"publish_time": "2022-03-14", "title": "GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models", "author": "Archiki Prasad et.al.", "abstract": "Providing natural language instructions in prompts is a useful new paradigm for improving task performance of large language models in a zero-shot setting. Recent work has aimed to improve such prompts via manual rewriting or gradient-based tuning. However, manual rewriting is time-consuming and requires subjective interpretation, while gradient-based tuning can be extremely computationally demanding for large models and requires full access to model weights, which may not be available for API-based models. In this work, we introduce Gradient-free Instructional Prompt Search (GrIPS), a gradient-free, edit-based search approach for improving task instructions for large language models. GrIPS takes in instructions designed for humans and automatically returns an improved, edited prompt, while allowing for API-based tuning. The instructions in our search are iteratively edited using four operations (delete, add, swap, paraphrase) on text at the phrase-level. With InstructGPT models, GrIPS improves the average task performance by up to 4.30 percentage points on eight classification tasks from the Natural-Instructions dataset. We see improvements for both instruction-only prompts and for k-shot example+instruction prompts. Notably, GrIPS outperforms manual rewriting following the guidelines in Mishra et al. (2022) and also outperforms purely example-based prompts while controlling for the available compute and data budget. Lastly, we provide qualitative analysis of the edited instructions across several scales of GPT models. Our code is available at: https://github.com/archiki/GrIPS", "paper_url": "http://arxiv.org/abs/2203.07281v1", "pdf_url": "http://arxiv.org/pdf/2203.07281v1", "repo_url": "https://github.com/archiki/grips"}, "2203.07264": {"publish_time": "2022-03-14", "title": "Show Me More Details: Discovering Hierarchies of Procedures from Semi-structured Web Data", "author": "Shuyan Zhou et.al.", "abstract": "Procedures are inherently hierarchical. To \"make videos\", one may need to \"purchase a camera\", which in turn may require one to \"set a budget\". While such hierarchical knowledge is critical for reasoning about complex procedures, most existing work has treated procedures as shallow structures without modeling the parent-child relation.In this work, we attempt to construct an open-domain hierarchical knowledge-base (KB) of procedures based on wikiHow, a website containing more than 110k instructional articles, each documenting the steps to carry out a complex procedure. To this end, we develop a simple and efficient method that links steps (e.g., \"purchase a camera\") in an article to other articles with similar goals (e.g., \"how to choose a camera\"), recursively constructing the KB. Our method significantly outperforms several strong baselines according to automatic evaluation, human judgment, and application to downstream tasks such as instructional video retrieval.   A demo with partial data can be found at https://wikihow-hierarchy.github.io. The code and the data are at https://github.com/shuyanzhou/wikihow_hierarchy.", "paper_url": "http://arxiv.org/abs/2203.07264v1", "pdf_url": "http://arxiv.org/pdf/2203.07264v1", "repo_url": "https://github.com/shuyanzhou/wikihow_hierarchy"}, "2203.07259": {"publish_time": "2022-03-14", "title": "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models", "author": "Eldar Kurtic et.al.", "abstract": "Pre-trained Transformer-based language models have become a key building block for natural language processing (NLP) tasks. While these models are extremely accurate, they can be too large and computationally intensive to run on standard deployments. A variety of compression methods, including distillation, quantization, structured and unstructured pruning are known to be applicable to decrease model size and increase inference speed. In this context, this paper's contributions are two-fold. We begin with an in-depth study of the accuracy-compression trade-off for unstructured weight pruning in the context of BERT models, and introduce Optimal BERT Surgeon (O-BERT-S), an efficient and accurate weight pruning method based on approximate second-order information, which we show to yield state-of-the-art results in terms of the compression/accuracy trade-off. Specifically, Optimal BERT Surgeon extends existing work on second-order pruning by allowing for pruning blocks of weights, and by being applicable at BERT scale. Second, we investigate the impact of this pruning method when compounding compression approaches for Transformer-based models, which allows us to combine state-of-the-art structured and unstructured pruning together with quantization, in order to obtain highly compressed, but accurate models. The resulting compression framework is powerful, yet general and efficient: we apply it to both the fine-tuning and pre-training stages of language tasks, to obtain state-of-the-art results on the accuracy-compression trade-off with relatively simple compression recipes. For example, we obtain 10x model size compression with < 1% relative drop in accuracy to the dense BERT-base, 10x end-to-end CPU-inference speedup with < 2% relative drop in accuracy, and 29x inference speedups with < 7.5% relative accuracy drop.", "paper_url": "http://arxiv.org/abs/2203.07259v1", "pdf_url": "http://arxiv.org/pdf/2203.07259v1", "repo_url": null}, "2203.08118": {"publish_time": "2022-03-15", "title": "Representation Learning for Resource-Constrained Keyphrase Generation", "author": "Di Wu et.al.", "abstract": "State-of-the-art keyphrase generation methods generally depend on large annotated datasets, limiting their performance in domains with constrained resources. To overcome this challenge, we investigate strategies to learn an intermediate representation suitable for the keyphrase generation task. We introduce salient span recovery and salient span prediction as guided denoising language modeling objectives that condense the domain-specific knowledge essential for keyphrase generation. Through experiments on multiple scientific keyphrase generation benchmarks, we show the effectiveness of the proposed approach for facilitating low-resource and zero-shot keyphrase generation. Furthermore, we observe that our method especially benefits the generation of absent keyphrases, approaching the performance of SOTA methods trained with large training sets.", "paper_url": "http://arxiv.org/abs/2203.08118v1", "pdf_url": "http://arxiv.org/pdf/2203.08118v1", "repo_url": "https://github.com/xiaowu0162/low-resource-kpgen"}, "2203.08111": {"publish_time": "2022-03-15", "title": "Does Corpus Quality Really Matter for Low-Resource Languages?", "author": "Mikel Artetxe et.al.", "abstract": "The vast majority of non-English corpora are derived from automatically filtered versions of CommonCrawl. While prior work has identified major issues on the quality of these datasets (Kreutzer et al., 2021), it is not clear how this impacts downstream performance. Taking Basque as a case study, we explore tailored crawling (manually identifying and scraping websites with high-quality content) as an alternative to filtering CommonCrawl. Our new corpus, called EusCrawl, is similar in size to the Basque portion of popular multilingual corpora like CC100 and mC4, yet it has a much higher quality according to native annotators. For instance, 66% of documents are rated as high-quality for EusCrawl, in contrast with <33% for both mC4 and CC100. Nevertheless, we obtain similar results on downstream tasks regardless of the corpus used for pre-training. Our work suggests that NLU performance in low-resource languages is primarily constrained by the quantity rather than the quality of the data, prompting for methods to exploit more diverse data sources.", "paper_url": "http://arxiv.org/abs/2203.08111v1", "pdf_url": "http://arxiv.org/pdf/2203.08111v1", "repo_url": null}, "2203.08085": {"publish_time": "2022-03-15", "title": "Measuring the Impact of (Psycho-)Linguistic and Readability Features and Their Spill Over Effects on the Prediction of Eye Movement Patterns", "author": "Daniel Wiechmann et.al.", "abstract": "There is a growing interest in the combined use of NLP and machine learning methods to predict gaze patterns during naturalistic reading. While promising results have been obtained through the use of transformer-based language models, little work has been undertaken to relate the performance of such models to general text characteristics. In this paper we report on experiments with two eye-tracking corpora of naturalistic reading and two language models (BERT and GPT-2). In all experiments, we test effects of a broad spectrum of features for predicting human reading behavior that fall into five categories (syntactic complexity, lexical richness, register-based multiword combinations, readability and psycholinguistic word properties). Our experiments show that both the features included and the architecture of the transformer-based language models play a role in predicting multiple eye-tracking measures during naturalistic reading. We also report the results of experiments aimed at determining the relative importance of features from different groups using SP-LIME.", "paper_url": "http://arxiv.org/abs/2203.08085v1", "pdf_url": "http://arxiv.org/pdf/2203.08085v1", "repo_url": null}, "2203.08075": {"publish_time": "2022-03-15", "title": "Things not Written in Text: Exploring Spatial Commonsense from Visual Signals", "author": "Xiao Liu et.al.", "abstract": "Spatial commonsense, the knowledge about spatial position and relationship between objects (like the relative size of a lion and a girl, and the position of a boy relative to a bicycle when cycling), is an important part of commonsense knowledge. Although pretrained language models (PLMs) succeed in many NLP tasks, they are shown to be ineffective in spatial commonsense reasoning. Starting from the observation that images are more likely to exhibit spatial commonsense than texts, we explore whether models with visual signals learn more spatial commonsense than text-based PLMs. We propose a spatial commonsense benchmark that focuses on the relative scales of objects, and the positional relationship between people and objects under different actions. We probe PLMs and models with visual signals, including vision-language pretrained models and image synthesis models, on this benchmark, and find that image synthesis models are more capable of learning accurate and consistent spatial knowledge than other models. The spatial knowledge from image synthesis models also helps in natural language understanding tasks that require spatial commonsense.", "paper_url": "http://arxiv.org/abs/2203.08075v1", "pdf_url": "http://arxiv.org/pdf/2203.08075v1", "repo_url": "https://github.com/xxxiaol/spatial-commonsense"}, "2203.08055": {"publish_time": "2022-03-15", "title": "Modular and Parameter-Efficient Multimodal Fusion with Prompting", "author": "Sheng Liang et.al.", "abstract": "Recent research has made impressive progress in large-scale multimodal pre-training. In the context of the rapid growth of model size, it is necessary to seek efficient and flexible methods other than finetuning. In this paper, we propose to use prompt vectors to align the modalities. Our method achieves comparable performance to several other multimodal fusion methods in low-resource settings. We further show that our method is modular and parameter-efficient for processing tasks involving two or more data modalities.", "paper_url": "http://arxiv.org/abs/2203.08055v1", "pdf_url": "http://arxiv.org/pdf/2203.08055v1", "repo_url": null}, "2203.08788": {"publish_time": "2022-03-16", "title": "Are Shortest Rationales the Best Explanations for Human Understanding?", "author": "Hua Shen et.al.", "abstract": "Existing self-explaining models typically favor extracting the shortest possible rationales - snippets of an input text \"responsible for\" corresponding output - to explain the model prediction, with the assumption that shorter rationales are more intuitive to humans. However, this assumption has yet to be validated. Is the shortest rationale indeed the most human-understandable? To answer this question, we design a self-explaining model, LimitedInk, which allows users to extract rationales at any target length. Compared to existing baselines, LimitedInk achieves compatible end-task performance and human-annotated rationale agreement, making it a suitable representation of the recent class of self-explaining models. We use LimitedInk to conduct a user study on the impact of rationale length, where we ask human judges to predict the sentiment label of documents based only on LimitedInk-generated rationales with different lengths. We show rationales that are too short do not help humans predict labels better than randomly masked text, suggesting the need for more careful design of the best human rationales.", "paper_url": "http://arxiv.org/abs/2203.08788v1", "pdf_url": "http://arxiv.org/pdf/2203.08788v1", "repo_url": null}, "2203.08774": {"publish_time": "2022-03-16", "title": "CUE Vectors: Modular Training of Language Models Conditioned on Diverse Contextual Signals", "author": "Scott Novotney et.al.", "abstract": "We propose a framework to modularize the training of neural language models that use diverse forms of sentence-external context (including metadata) by eliminating the need to jointly train sentence-external and within-sentence encoders. Our approach, contextual universal embeddings (CUE), trains LMs on one set of context, such as date and author, and adapts to novel metadata types, such as article title, or previous sentence. The model consists of a pretrained neural sentence LM, a BERT-based context encoder, and a masked transformer decoder that estimates LM probabilities using sentence-internal and sentence-external information. When context or metadata are unavailable, our model learns to combine contextual and sentence-internal information using noisy oracle unigram embeddings as a proxy. Real contextual information can be introduced later and used to adapt a small number of parameters that map contextual data into the decoder's embedding space. We validate the CUE framework on a NYTimes text corpus with multiple metadata types, for which the LM perplexity can be lowered from 36.6 to 27.4 by conditioning on context. Bootstrapping a contextual LM with only a subset of the context/metadata during training retains 85\\% of the achievable gain. Training the model initially with proxy context retains 67% of the perplexity gain after adapting to real context. Furthermore, we can swap one type of pretrained sentence LM for another without retraining the context encoders, by only adapting the decoder model. Overall, we obtain a modular framework that allows incremental, scalable training of context-enhanced LMs.", "paper_url": "http://arxiv.org/abs/2203.08774v1", "pdf_url": "http://arxiv.org/pdf/2203.08774v1", "repo_url": null}, "2203.08773": {"publish_time": "2022-03-16", "title": "Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data", "author": "Shuohang Wang et.al.", "abstract": "Retrieval-based methods have been shown to be effective in NLP tasks via introducing external knowledge. However, the indexing and retrieving of large-scale corpora bring considerable computational cost. Surprisingly, we found that REtrieving from the traINing datA (REINA) only can lead to significant gains on multiple NLG and NLU tasks. We retrieve the labeled training instances most similar to the input text and then concatenate them with the input to feed into the model to generate the output. Experimental results show that this simple method can achieve significantly better performance on a variety of NLU and NLG tasks, including summarization, machine translation, language modeling, and question answering tasks. For instance, our proposed method achieved state-of-the-art results on XSum, BigPatent, and CommonsenseQA. Our code is released, https://github.com/microsoft/REINA .", "paper_url": "http://arxiv.org/abs/2203.08773v1", "pdf_url": "http://arxiv.org/pdf/2203.08773v1", "repo_url": "https://github.com/microsoft/reina"}, "2203.08757": {"publish_time": "2022-03-16", "title": "Sample, Translate, Recombine: Leveraging Audio Alignments for Data Augmentation in End-to-end Speech Translation", "author": "Tsz Kin Lam et.al.", "abstract": "End-to-end speech translation relies on data that pair source-language speech inputs with corresponding translations into a target language. Such data are notoriously scarce, making synthetic data augmentation by back-translation or knowledge distillation a necessary ingredient of end-to-end training. In this paper, we present a novel approach to data augmentation that leverages audio alignments, linguistic properties, and translation. First, we augment a transcription by sampling from a suffix memory that stores text and audio data. Second, we translate the augmented transcript. Finally, we recombine concatenated audio segments and the generated translation. Besides training an MT-system, we only use basic off-the-shelf components without fine-tuning. While having similar resource demands as knowledge distillation, adding our method delivers consistent improvements of up to 0.9 and 1.1 BLEU points on five language pairs on CoVoST 2 and on two language pairs on Europarl-ST, respectively.", "paper_url": "http://arxiv.org/abs/2203.08757v1", "pdf_url": "http://arxiv.org/pdf/2203.08757v1", "repo_url": null}, "2203.08745": {"publish_time": "2022-03-16", "title": "Multi-Stage Prompting for Knowledgeable Dialogue Generation", "author": "Zihan Liu et.al.", "abstract": "Existing knowledge-grounded dialogue systems typically use finetuned versions of a pretrained language model (LM) and large-scale knowledge bases. These models typically fail to generalize on topics outside of the knowledge base, and require maintaining separate potentially large checkpoints each time finetuning is needed. In this paper, we aim to address these limitations by leveraging the inherent knowledge stored in the pretrained LM as well as its powerful generation ability. We propose a multi-stage prompting approach to generate knowledgeable responses from a single pretrained LM. We first prompt the LM to generate knowledge based on the dialogue context. Then, we further prompt it to generate responses based on the dialogue context and the previously generated knowledge. Results show that our knowledge generator outperforms the state-of-the-art retrieval-based model by 5.8% when combining knowledge relevance and correctness. In addition, our multi-stage prompting outperforms the finetuning-based dialogue model in terms of response knowledgeability and engagement by up to 10% and 5%, respectively. Furthermore, we scale our model up to 530 billion parameters and show that larger LMs improve the generation correctness score by up to 10%, and response relevance, knowledgeability and engagement by up to 10%. Our code is available at: https://github.com/NVIDIA/Megatron-LM.", "paper_url": "http://arxiv.org/abs/2203.08745v1", "pdf_url": "http://arxiv.org/pdf/2203.08745v1", "repo_url": "https://github.com/NVIDIA/Megatron-LM"}, "2203.09509": {"publish_time": "2022-03-17", "title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection", "author": "Thomas Hartvigsen et.al.", "abstract": "Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create ToxiGen, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model. Controlling machine generation in this way allows ToxiGen to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of ToxiGen and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that ToxiGen can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset.", "paper_url": "http://arxiv.org/abs/2203.09509v1", "pdf_url": "http://arxiv.org/pdf/2203.09509v1", "repo_url": null}, "2203.09498": {"publish_time": "2022-03-17", "title": "The Frost Hollow Experiments: Pavlovian Signalling as a Path to Coordination and Communication Between Agents", "author": "Patrick M. Pilarski et.al.", "abstract": "Learned communication between agents is a powerful tool when approaching decision-making problems that are hard to overcome by any single agent in isolation. However, continual coordination and communication learning between machine agents or human-machine partnerships remains a challenging open problem. As a stepping stone toward solving the continual communication learning problem, in this paper we contribute a multi-faceted study into what we term Pavlovian signalling -- a process by which learned, temporally extended predictions made by one agent inform decision-making by another agent with different perceptual access to their shared environment. We seek to establish how different temporal processes and representational choices impact Pavlovian signalling between learning agents. To do so, we introduce a partially observable decision-making domain we call the Frost Hollow. In this domain a prediction learning agent and a reinforcement learning agent are coupled into a two-part decision-making system that seeks to acquire sparse reward while avoiding time-conditional hazards. We evaluate two domain variations: 1) machine prediction and control learning in a linear walk, and 2) a prediction learning machine interacting with a human participant in a virtual reality environment. Our results showcase the speed of learning for Pavlovian signalling, the impact that different temporal representations do (and do not) have on agent-agent coordination, and how temporal aliasing impacts agent-agent and human-agent interactions differently. As a main contribution, we establish Pavlovian signalling as a natural bridge between fixed signalling paradigms and fully adaptive communication learning. Our results therefore point to an actionable, constructivist path towards continual communication learning between reinforcement learning agents, with potential impact in a range of real-world settings.", "paper_url": "http://arxiv.org/abs/2203.09498v1", "pdf_url": "http://arxiv.org/pdf/2203.09498v1", "repo_url": null}, "2203.09486": {"publish_time": "2022-03-17", "title": "An Imitation Learning Curriculum for Text Editing with Non-Autoregressive Models", "author": "Sweta Agrawal et.al.", "abstract": "We propose a framework for training non-autoregressive sequence-to-sequence models for editing tasks, where the original input sequence is iteratively edited to produce the output. We show that the imitation learning algorithms designed to train such models for machine translation introduces mismatches between training and inference that lead to undertraining and poor generalization in editing scenarios. We address this issue with two complementary strategies: 1) a roll-in policy that exposes the model to intermediate training sequences that it is more likely to encounter during inference, 2) a curriculum that presents easy-to-learn edit operations first, gradually increasing the difficulty of training samples as the model becomes competent. We show the efficacy of these strategies on two challenging English editing tasks: controllable text simplification and abstractive summarization. Our approach significantly improves output quality on both tasks and controls output complexity better on the simplification task.", "paper_url": "http://arxiv.org/abs/2203.09486v1", "pdf_url": "http://arxiv.org/pdf/2203.09486v1", "repo_url": null}, "2203.09435": {"publish_time": "2022-03-17", "title": "Expanding Pretrained Models to Thousands More Languages via Lexicon-based Adaptation", "author": "Xinyi Wang et.al.", "abstract": "The performance of multilingual pretrained models is highly dependent on the availability of monolingual or parallel text present in a target language. Thus, the majority of the world's languages cannot benefit from recent progress in NLP as they have no or limited textual data. To expand possibilities of using NLP technology in these under-represented languages, we systematically study strategies that relax the reliance on conventional language resources through the use of bilingual lexicons, an alternative resource with much better language coverage. We analyze different strategies to synthesize textual or labeled data using lexicons, and how this data can be combined with monolingual or parallel text when available. For 19 under-represented languages across 3 tasks, our methods lead to consistent improvements of up to 5 and 15 points with and without extra monolingual text respectively. Overall, our study highlights how NLP methods can be adapted to thousands more languages that are under-served by current technology", "paper_url": "http://arxiv.org/abs/2203.09435v1", "pdf_url": "http://arxiv.org/pdf/2203.09435v1", "repo_url": "https://github.com/cindyxinyiwang/expand-via-lexicon-based-adaptation"}, "2203.09424": {"publish_time": "2022-03-17", "title": "elBERto: Self-supervised Commonsense Learning for Question Answering", "author": "Xunlin Zhan et.al.", "abstract": "Commonsense question answering requires reasoning about everyday situations and causes and effects implicit in context. Typically, existing approaches first retrieve external evidence and then perform commonsense reasoning using these evidence. In this paper, we propose a Self-supervised Bidirectional Encoder Representation Learning of Commonsense (elBERto) framework, which is compatible with off-the-shelf QA model architectures. The framework comprises five self-supervised tasks to force the model to fully exploit the additional training signals from contexts containing rich commonsense. The tasks include a novel Contrastive Relation Learning task to encourage the model to distinguish between logically contrastive contexts, a new Jigsaw Puzzle task that requires the model to infer logical chains in long contexts, and three classic SSL tasks to maintain pre-trained models language encoding ability. On the representative WIQA, CosmosQA, and ReClor datasets, elBERto outperforms all other methods, including those utilizing explicit graph reasoning and external knowledge retrieval. Moreover, elBERto achieves substantial improvements on out-of-paragraph and no-effect questions where simple lexical similarity comparison does not help, indicating that it successfully learns commonsense and is able to leverage it when given dynamic context.", "paper_url": "http://arxiv.org/abs/2203.09424v1", "pdf_url": "http://arxiv.org/pdf/2203.09424v1", "repo_url": null}, "2203.10079": {"publish_time": "2022-03-18", "title": "Simulating Bandit Learning from User Feedback for Extractive Question Answering", "author": "Ge Gao et.al.", "abstract": "We study learning from user feedback for extractive question answering by simulating feedback using supervised data. We cast the problem as contextual bandit learning, and analyze the characteristics of several learning scenarios with focus on reducing data annotation. We show that systems initially trained on a small number of examples can dramatically improve given feedback from users on model-predicted answers, and that one can use existing datasets to deploy systems in new domains without any annotation, but instead improving the system on-the-fly via user feedback.", "paper_url": "http://arxiv.org/abs/2203.10079v1", "pdf_url": "http://arxiv.org/pdf/2203.10079v1", "repo_url": "https://github.com/lil-lab/bandit-qa"}, "2203.10053": {"publish_time": "2022-03-18", "title": "RELIC: Retrieving Evidence for Literary Claims", "author": "Katherine Thai et.al.", "abstract": "Humanities scholars commonly provide evidence for claims that they make about a work of literature (e.g., a novel) in the form of quotations from the work. We collect a large-scale dataset (RELiC) of 78K literary quotations and surrounding critical analysis and use it to formulate the novel task of literary evidence retrieval, in which models are given an excerpt of literary analysis surrounding a masked quotation and asked to retrieve the quoted passage from the set of all passages in the work. Solving this retrieval task requires a deep understanding of complex literary and linguistic phenomena, which proves challenging to methods that overwhelmingly rely on lexical and semantic similarity matching. We implement a RoBERTa-based dense passage retriever for this task that outperforms existing pretrained information retrieval baselines; however, experiments and analysis by human domain experts indicate that there is substantial room for improvement over our dense retriever.", "paper_url": "http://arxiv.org/abs/2203.10053v1", "pdf_url": "http://arxiv.org/pdf/2203.10053v1", "repo_url": null}, "2203.10024": {"publish_time": "2022-03-18", "title": "Offensive Language Detection in Under-resourced Algerian Dialectal Arabic Language", "author": "Oussama Boucherit et.al.", "abstract": "This paper addresses the problem of detecting the offensive and abusive content in Facebook comments, where we focus on the Algerian dialectal Arabic which is one of under-resourced languages. The latter has a variety of dialects mixed with different languages (i.e. Berber, French and English). In addition, we deal with texts written in both Arabic and Roman scripts (i.e. Arabizi). Due to the scarcity of works on the same language, we have built a new corpus regrouping more than 8.7k texts manually annotated as normal, abusive and offensive. We have conducted a series of experiments using the state-of-the-art classifiers of text categorisation, namely: BiLSTM, CNN, FastText, SVM and NB. The results showed acceptable performances, but the problem requires further investigation on linguistic features to increase the identification accuracy.", "paper_url": "http://arxiv.org/abs/2203.10024v1", "pdf_url": "http://arxiv.org/pdf/2203.10024v1", "repo_url": "https://github.com/xprogramer/dziriofn"}, "2203.10020": {"publish_time": "2022-03-18", "title": "Challenges and Strategies in Cross-Cultural NLP", "author": "Daniel Hershcovich et.al.", "abstract": "Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies.", "paper_url": "http://arxiv.org/abs/2203.10020v1", "pdf_url": "http://arxiv.org/pdf/2203.10020v1", "repo_url": null}, "2203.10012": {"publish_time": "2022-03-18", "title": "Report from the NSF Future Directions Workshop on Automatic Evaluation of Dialog: Research Directions and Challenges", "author": "Shikib Mehri et.al.", "abstract": "This is a report on the NSF Future Directions Workshop on Automatic Evaluation of Dialog. The workshop explored the current state of the art along with its limitations and suggested promising directions for future work in this important and very rapidly changing area of research.", "paper_url": "http://arxiv.org/abs/2203.10012v1", "pdf_url": "http://arxiv.org/pdf/2203.10012v1", "repo_url": null}, "2203.11187": {"publish_time": "2022-03-21", "title": "Relevant CommonSense Subgraphs for \"What if...\" Procedural Reasoning", "author": "Chen Zheng et.al.", "abstract": "We study the challenge of learning causal reasoning over procedural text to answer \"What if...\" questions when external commonsense knowledge is required. We propose a novel multi-hop graph reasoning model to 1) efficiently extract a commonsense subgraph with the most relevant information from a large knowledge graph; 2) predict the causal answer by reasoning over the representations obtained from the commonsense subgraph and the contextual interactions between the questions and context. We evaluate our model on WIQA benchmark and achieve state-of-the-art performance compared to the recent models.", "paper_url": "http://arxiv.org/abs/2203.11187v1", "pdf_url": "http://arxiv.org/pdf/2203.11187v1", "repo_url": null}, "2203.11171": {"publish_time": "2022-03-21", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models", "author": "Xuezhi Wang et.al.", "abstract": "We explore a simple ensemble strategy, self-consistency, that significantly improves the reasoning accuracy of large language models. The idea is to sample a diverse set of outputs from a language model and return the most consistent answer in the set. Such ensembling method improves reasoning accuracy when combined with chain of thought prompting. For arithmetic and commonsense reasoning benchmarks we find that self-consistency yields significant accuracy improvements in a variety of datasets, such as GSM8K (+10%), SVAMP (+14%), MultiArith (+24%), CommonsenseQA (+5%) and ARC (easy +4%, challenge +5%).", "paper_url": "http://arxiv.org/abs/2203.11171v1", "pdf_url": "http://arxiv.org/pdf/2203.11171v1", "repo_url": null}, "2203.11147": {"publish_time": "2022-03-21", "title": "Teaching language models to support answers with verified quotes", "author": "Jacob Menick et.al.", "abstract": "Recent large language models often answer factual questions correctly. But users can't trust any given claim a model makes without fact-checking, because language models can hallucinate convincing nonsense. In this work we use reinforcement learning from human preferences (RLHP) to train \"open-book\" QA models that generate answers whilst also citing specific evidence for their claims, which aids in the appraisal of correctness. Supporting evidence is drawn from multiple documents found via a search engine, or from a single user-provided document. Our 280 billion parameter model, GopherCite, is able to produce answers with high quality supporting evidence and abstain from answering when unsure. We measure the performance of GopherCite by conducting human evaluation of answers to questions in a subset of the NaturalQuestions and ELI5 datasets. The model's response is found to be high-quality 80\\% of the time on this Natural Questions subset, and 67\\% of the time on the ELI5 subset. Abstaining from the third of questions for which it is most unsure improves performance to 90\\% and 80\\% respectively, approaching human baselines. However, analysis on the adversarial TruthfulQA dataset shows why citation is only one part of an overall strategy for safety and trustworthiness: not all claims supported by evidence are true.", "paper_url": "http://arxiv.org/abs/2203.11147v1", "pdf_url": "http://arxiv.org/pdf/2203.11147v1", "repo_url": null}, "2203.11131": {"publish_time": "2022-03-21", "title": "Towards Explainable Evaluation Metrics for Natural Language Generation", "author": "Christoph Leiter et.al.", "abstract": "Unlike classical lexical overlap metrics such as BLEU, most current evaluation metrics (such as BERTScore or MoverScore) are based on black-box language models such as BERT or XLM-R. They often achieve strong correlations with human judgments, but recent research indicates that the lower-quality classical metrics remain dominant, one of the potential reasons being that their decision processes are transparent. To foster more widespread acceptance of the novel high-quality metrics, explainability thus becomes crucial. In this concept paper, we identify key properties and propose key goals of explainable machine translation evaluation metrics. We also provide a synthesizing overview over recent approaches for explainable machine translation metrics and discuss how they relate to those goals and properties. Further, we conduct own novel experiments, which (among others) find that current adversarial NLP techniques are unsuitable for automatically identifying limitations of high-quality black-box evaluation metrics, as they are not meaning-preserving. Finally, we provide a vision of future approaches to explainable evaluation metrics and their evaluation. We hope that our work can help catalyze and guide future research on explainable evaluation metrics and, mediately, also contribute to better and more transparent text generation systems.", "paper_url": "http://arxiv.org/abs/2203.11131v1", "pdf_url": "http://arxiv.org/pdf/2203.11131v1", "repo_url": null}, "2203.11130": {"publish_time": "2022-03-21", "title": "PACS: A Dataset for Physical Audiovisual CommonSense Reasoning", "author": "Samuel Yu et.al.", "abstract": "In order for AI to be safely deployed in real-world scenarios such as hospitals, schools, and the workplace, they should be able to reason about the physical world by understanding the physical properties and affordances of available objects, how they can be manipulated, and how they interact with other physical objects. This research field of physical commonsense reasoning is fundamentally a multi-sensory task since physical properties are manifested through multiple modalities, two of them being vision and acoustics. Our paper takes a step towards real-world physical commonsense reasoning by contributing PACS: the first audiovisual benchmark annotated for physical commonsense attributes. PACS contains a total of 13,400 question-answer pairs, involving 1,377 unique physical commonsense questions and 1,526 videos. Our dataset provides new opportunities to advance the research field of physical reasoning by bringing audio as a core component of this multimodal problem. Using PACS, we evaluate multiple state-of-the-art models on this new challenging task. While some models show promising results (70% accuracy), they all fall short of human performance (95% accuracy). We conclude the paper by demonstrating the importance of multimodal reasoning and providing possible avenues for future research.", "paper_url": "http://arxiv.org/abs/2203.11130v1", "pdf_url": "http://arxiv.org/pdf/2203.11130v1", "repo_url": null}, "2203.11933": {"publish_time": "2022-03-22", "title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning", "author": "Hugo Berg et.al.", "abstract": "Vision-language models can encode societal biases and stereotypes, but there are challenges to measuring and mitigating these harms. Prior proposed bias measurements lack robustness and feature degradation occurs when mitigating bias without access to pretraining data. We address both of these challenges in this paper: First, we evaluate different bias measures and propose the use of retrieval metrics to image-text representations via a bias measuring framework. Second, we investigate debiasing methods and show that optimizing for adversarial loss via learnable token embeddings minimizes various bias measures without substantially degrading feature representations.", "paper_url": "http://arxiv.org/abs/2203.11933v1", "pdf_url": "http://arxiv.org/pdf/2203.11933v1", "repo_url": "https://github.com/oxai/debias-vision-lang"}, "2203.11899": {"publish_time": "2022-03-22", "title": "Transformer based ensemble for emotion detection", "author": "Aditya Kane et.al.", "abstract": "Detecting emotions in languages is important to accomplish a complete interaction between humans and machines. This paper describes our contribution to the WASSA 2022 shared task which handles this crucial task of emotion detection. We have to identify the following emotions: sadness, surprise, neutral, anger, fear, disgust, joy based on a given essay text. We are using an ensemble of ELECTRA and BERT models to tackle this problem achieving an F1 score of 62.76%. Our codebase (https://bit.ly/WASSA_shared_task) and our WandB project (https://wandb.ai/acl_wassa_pictxmanipal/acl_wassa) is available.", "paper_url": "http://arxiv.org/abs/2203.11899v1", "pdf_url": "http://arxiv.org/pdf/2203.11899v1", "repo_url": null}, "2203.11856": {"publish_time": "2022-03-22", "title": "A Computational Approach to Understand Mental Health from Reddit: Knowledge-aware Multitask Learning Framework", "author": "Usha Lokala et.al.", "abstract": "Analyzing gender is critical to study mental health (MH) support in CVD (cardiovascular disease). The existing studies on using social media for extracting MH symptoms consider symptom detection and tend to ignore user context, disease, or gender. The current study aims to design and evaluate a system to capture how MH symptoms associated with CVD are expressed differently with the gender on social media. We observe that the reliable detection of MH symptoms expressed by persons with heart disease in user posts is challenging because of the co-existence of (dis)similar MH symptoms in one post and due to variation in the description of symptoms based on gender. We collect a corpus of $150k$ items (posts and comments) annotated using the subreddit labels and transfer learning approaches. We propose GeM, a novel task-adaptive multi-task learning approach to identify the MH symptoms in CVD patients based on gender. Specifically, we adapt a knowledge-assisted RoBERTa based bi-encoder model to capture CVD-related MH symptoms. Moreover, it enhances the reliability for differentiating the gender language in MH symptoms when compared to the state-of-art language models. Our model achieves high (statistically significant) performance and predicts four labels of MH issues and two gender labels, which outperforms RoBERTa, improving the recall by 2.14% on the symptom identification task and by 2.55% on the gender identification task.", "paper_url": "http://arxiv.org/abs/2203.11856v1", "pdf_url": "http://arxiv.org/pdf/2203.11856v1", "repo_url": null}, "2203.11849": {"publish_time": "2022-03-22", "title": "A Girl Has A Name, And It's ... Adversarial Authorship Attribution for Deobfuscation", "author": "Wanyue Zhai et.al.", "abstract": "Recent advances in natural language processing have enabled powerful privacy-invasive authorship attribution. To counter authorship attribution, researchers have proposed a variety of rule-based and learning-based text obfuscation approaches. However, existing authorship obfuscation approaches do not consider the adversarial threat model. Specifically, they are not evaluated against adversarially trained authorship attributors that are aware of potential obfuscation. To fill this gap, we investigate the problem of adversarial authorship attribution for deobfuscation. We show that adversarially trained authorship attributors are able to degrade the effectiveness of existing obfuscators from 20-30% to 5-10%. We also evaluate the effectiveness of adversarial training when the attributor makes incorrect assumptions about whether and which obfuscator was used. While there is a a clear degradation in attribution accuracy, it is noteworthy that this degradation is still at or above the attribution accuracy of the attributor that is not adversarially trained at all. Our results underline the need for stronger obfuscation approaches that are resistant to deobfuscation", "paper_url": "http://arxiv.org/abs/2203.11849v1", "pdf_url": "http://arxiv.org/pdf/2203.11849v1", "repo_url": null}, "2203.11841": {"publish_time": "2022-03-22", "title": "SU-NLP at SemEval-2022 Task 11: Complex Named Entity Recognition with Entity Linking", "author": "Buse \u00c7ar\u0131k et.al.", "abstract": "This paper describes the system proposed by Sabanc{\\i} University Natural Language Processing Group in the SemEval-2022 MultiCoNER task. We developed an unsupervised entity linking pipeline that detects potential entity mentions with the help of Wikipedia and also uses the corresponding Wikipedia context to help the classifier in finding the named entity type of that mention. Our results showed that our pipeline improved performance significantly, especially for complex entities in low-context settings.", "paper_url": "http://arxiv.org/abs/2203.11841v1", "pdf_url": "http://arxiv.org/pdf/2203.11841v1", "repo_url": null}, "2203.12574": {"publish_time": "2022-03-23", "title": "Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal", "author": "Umang Gupta et.al.", "abstract": "Language models excel at generating coherent text, and model compression techniques such as knowledge distillation have enabled their use in resource-constrained settings. However, these models can be biased in multiple ways, including the unfounded association of male and female genders with gender-neutral professions. Therefore, knowledge distillation without any fairness constraints may preserve or exaggerate the teacher model's biases onto the distilled model. To this end, we present a novel approach to mitigate gender disparity in text generation by learning a fair model during knowledge distillation. We propose two modifications to the base knowledge distillation based on counterfactual role reversal$\\unicode{x2014}$modifying teacher probabilities and augmenting the training set. We evaluate gender polarity across professions in open-ended text generated from the resulting distilled and finetuned GPT$\\unicode{x2012}$2 models and demonstrate a substantial reduction in gender disparity with only a minor compromise in utility. Finally, we observe that language models that reduce gender polarity in language generation do not improve embedding fairness or downstream classification fairness.", "paper_url": "http://arxiv.org/abs/2203.12574v1", "pdf_url": "http://arxiv.org/pdf/2203.12574v1", "repo_url": null}, "2203.12536": {"publish_time": "2022-03-23", "title": "Dynamically Refined Regularization for Improving Cross-corpora Hate Speech Detection", "author": "Tulika Bose et.al.", "abstract": "Hate speech classifiers exhibit substantial performance degradation when evaluated on datasets different from the source. This is due to learning spurious correlations between words that are not necessarily relevant to hateful language, and hate speech labels from the training corpus. Previous work has attempted to mitigate this problem by regularizing specific terms from pre-defined static dictionaries. While this has been demonstrated to improve the generalizability of classifiers, the coverage of such methods is limited and the dictionaries require regular manual updates from human experts. In this paper, we propose to automatically identify and reduce spurious correlations using attribution methods with dynamic refinement of the list of terms that need to be regularized during training. Our approach is flexible and improves the cross-corpora performance over previous work independently and in combination with pre-defined dictionaries.", "paper_url": "http://arxiv.org/abs/2203.12536v1", "pdf_url": "http://arxiv.org/pdf/2203.12536v1", "repo_url": "https://github.com/tbose20/d-ref"}, "2203.12524": {"publish_time": "2022-03-23", "title": "Computational historical linguistics and language diversity in South Asia", "author": "Aryaman Arora et.al.", "abstract": "South Asia is home to a plethora of languages, many of which severely lack access to new language technologies. This linguistic diversity also results in a research environment conducive to the study of comparative, contact, and historical linguistics -- fields which necessitate the gathering of extensive data from many languages. We claim that data scatteredness (rather than scarcity) is the primary obstacle in the development of South Asian language technology, and suggest that the study of language history is uniquely aligned with surmounting this obstacle. We review recent developments in and at the intersection of South Asian NLP and historical-comparative linguistics, describing our and others' current efforts in this area. We also offer new strategies towards breaking the data barrier.", "paper_url": "http://arxiv.org/abs/2203.12524v1", "pdf_url": "http://arxiv.org/pdf/2203.12524v1", "repo_url": null}, "2203.12515": {"publish_time": "2022-03-23", "title": "A Survey on Cross-Lingual Summarization", "author": "Jiaan Wang et.al.", "abstract": "Cross-lingual summarization is the task of generating a summary in one language (e.g., English) for the given document(s) in a different language (e.g., Chinese). Under the globalization background, this task has attracted increasing attention of the computational linguistics community. Nevertheless, there still remains a lack of comprehensive review for this task. Therefore, we present the first systematic critical review on the datasets, approaches and challenges in this field. Specifically, we carefully organize existing datasets and approaches according to different construction methods and solution paradigms, respectively. For each type of datasets or approaches, we thoroughly introduce and summarize previous efforts and further compare them with each other to provide deeper analyses. In the end, we also discuss promising directions and offer our thoughts to facilitate future research. This survey is for both beginners and experts in cross-lingual summarization, and we hope it will serve as a starting point as well as a source of new ideas for researchers and engineers interested in this area.", "paper_url": "http://arxiv.org/abs/2203.12515v1", "pdf_url": "http://arxiv.org/pdf/2203.12515v1", "repo_url": null}, "2203.12487": {"publish_time": "2022-03-23", "title": "A Context-Aware Feature Fusion Framework for Punctuation Restoration", "author": "Yangjun Wu et.al.", "abstract": "To accomplish the punctuation restoration task, most existing approaches focused on leveraging extra information (e.g., part-of-speech tags) or addressing the class imbalance problem. Recent works have widely applied the transformer-based language models and significantly improved their effectiveness. To the best of our knowledge, an inherent issue has remained neglected: the attention of individual heads in the transformer will be diluted or powerless while feeding the long non-punctuation utterances. Since those previous contexts, not the followings, are comparatively more valuable to the current position, it's hard to achieve a good balance by independent attention. In this paper, we propose a novel Feature Fusion framework based on two-type Attentions (FFA) to alleviate the shortage. It introduces a two-stream architecture. One module involves interaction between attention heads to encourage the communication, and another masked attention module captures the dependent feature representation. Then, it aggregates two feature embeddings to fuse information and enhances context-awareness. The experiments on the popular benchmark dataset IWSLT demonstrate that our approach is effective. Without additional data, it obtains comparable performance to the current state-of-the-art models.", "paper_url": "http://arxiv.org/abs/2203.12487v1", "pdf_url": "http://arxiv.org/pdf/2203.12487v1", "repo_url": "https://github.com/young1993/ffa"}, "2203.13240": {"publish_time": "2022-03-24", "title": "Token Dropping for Efficient BERT Pretraining", "author": "Le Hou et.al.", "abstract": "Transformer-based models generally allocate the same amount of computation for each token in a given sequence. We develop a simple but effective \"token dropping\" method to accelerate the pretraining of transformer models, such as BERT, without degrading its performance on downstream tasks. In short, we drop unimportant tokens starting from an intermediate layer in the model to make the model focus on important tokens; the dropped tokens are later picked up by the last layer of the model so that the model still produces full-length sequences. We leverage the already built-in masked language modeling (MLM) loss to identify unimportant tokens with practically no computational overhead. In our experiments, this simple approach reduces the pretraining cost of BERT by 25% while achieving similar overall fine-tuning performance on standard downstream tasks.", "paper_url": "http://arxiv.org/abs/2203.13240v1", "pdf_url": "http://arxiv.org/pdf/2203.13240v1", "repo_url": null}, "2203.13226": {"publish_time": "2022-03-24", "title": "SMARAGD: Synthesized sMatch for Accurate and Rapid AMR Graph Distance", "author": "Juri Opitz et.al.", "abstract": "The semantic similarity of graph-based meaning representations, such as Abstract Meaning Representation (AMR), is typically assessed using graph matching algorithms, such as SMATCH (Cai and Knight, 2013). However, SMATCH suffers from NP-completeness, making its large-scale application, e.g., for AMR clustering or semantic search, infeasible. To mitigate this issue, we propose SMARAGD (Synthesized sMatch for accurate and rapid AMR graph distance). We show the potential of neural networks to approximate the SMATCH scores and graph alignments, i) in linear time using a machine translation framework to predict the alignments, or ii) in constant time using a Siamese CNN to directly predict SMATCH scores. We show that the approximation error can be substantially reduced by applying data augmentation and AMR graph anonymization.", "paper_url": "http://arxiv.org/abs/2203.13226v1", "pdf_url": "http://arxiv.org/pdf/2203.13226v1", "repo_url": null}, "2203.13224": {"publish_time": "2022-03-24", "title": "Language Models that Seek for Knowledge: Modular Search & Generation for Dialogue and Prompt Completion", "author": "Kurt Shuster et.al.", "abstract": "Language models (LMs) have recently been shown to generate more factual responses by employing modularity (Zhou et al., 2021) in combination with retrieval (Adolphs et al., 2021). We extend the recent approach of Adolphs et al. (2021) to include internet search as a module. Our SeeKeR (Search engine->Knowledge->Response) method thus applies a single LM to three modular tasks in succession: search, generating knowledge, and generating a final response. We show that, when using SeeKeR as a dialogue model, it outperforms the state-of-the-art model BlenderBot 2 (Chen et al., 2021) on open-domain knowledge-grounded conversations for the same number of parameters, in terms of consistency, knowledge and per-turn engagingness. SeeKeR applied to topical prompt completions as a standard language model outperforms GPT2 (Radford et al., 2019) and GPT3 (Brown et al., 2020) in terms of factuality and topicality, despite GPT3 being a vastly larger model. Our code and models are made publicly available.", "paper_url": "http://arxiv.org/abs/2203.13224v1", "pdf_url": "http://arxiv.org/pdf/2203.13224v1", "repo_url": null}, "2203.13209": {"publish_time": "2022-03-24", "title": "Direct parsing to sentiment graphs", "author": "David Samuel et.al.", "abstract": "This paper demonstrates how a graph-based semantic parser can be applied to the task of structured sentiment analysis, directly predicting sentiment graphs from text. We advance the state of the art on 4 out of 5 standard benchmark sets. We release the source code, models and predictions.", "paper_url": "http://arxiv.org/abs/2203.13209v1", "pdf_url": "http://arxiv.org/pdf/2203.13209v1", "repo_url": "https://github.com/jerbarnes/direct_parsing_to_sent_graph"}, "2203.13176": {"publish_time": "2022-03-24", "title": "Emergence of hierarchical reference systems in multi-agent communication", "author": "Xenia Ohmer et.al.", "abstract": "In natural language, referencing objects at different levels of specificity is a fundamental pragmatic mechanism for efficient communication in context. We develop a novel communication game, the hierarchical reference game, to study the emergence of such reference systems in artificial agents. We consider a simplified world, in which concepts are abstractions over a set of primitive attributes (e.g., color, style, shape). Depending on how many attributes are combined, concepts are more general (\"circle\") or more specific (\"red dotted circle\"). Based on the context, the agents have to communicate at different levels of this hierarchy. Our results show, that the agents learn to play the game successfully and can even generalize to novel concepts. To achieve abstraction, they use implicit (omitting irrelevant information) and explicit (indicating that attributes are irrelevant) strategies. In addition, the compositional structure underlying the concept hierarchy is reflected in the emergent protocols, indicating that the need to develop hierarchical reference systems supports the emergence of compositionality.", "paper_url": "http://arxiv.org/abs/2203.13176v1", "pdf_url": "http://arxiv.org/pdf/2203.13176v1", "repo_url": "https://github.com/xeniaohmer/hierarchical_reference_game"}, "2203.13778": {"publish_time": "2022-03-25", "title": "L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and BERT models", "author": "Abhishek Velankar et.al.", "abstract": "Social media platforms are used by a large number of people prominently to express their thoughts and opinions. However, these platforms have contributed to a substantial amount of hateful and abusive content as well. Therefore, it is important to curb the spread of hate speech on these platforms. In India, Marathi is one of the most popular languages used by a wide audience. In this work, we present L3Cube-MahaHate, the first major Hate Speech Dataset in Marathi. The dataset is curated from Twitter, annotated manually. Our dataset consists of over 25000 distinct tweets labeled into four major classes i.e hate, offensive, profane, and not. We present the approaches used for collecting and annotating the data and the challenges faced during the process. Finally, we present baseline classification results using deep learning models based on CNN, LSTM, and Transformers. We explore mono-lingual and multi-lingual variants of BERT like MahaBERT, IndicBERT, mBERT, and xlm-RoBERTa and show that mono-lingual models perform better than their multi-lingual counterparts. The MahaBERT model provides the best results on L3Cube-MahaHate Corpus. The data and models are available at https://github.com/l3cube-pune/MarathiNLP .", "paper_url": "http://arxiv.org/abs/2203.13778v1", "pdf_url": "http://arxiv.org/pdf/2203.13778v1", "repo_url": null}, "2203.13722": {"publish_time": "2022-03-25", "title": "Probing Pre-Trained Language Models for Cross-Cultural Differences in Values", "author": "Arnav Arora et.al.", "abstract": "Language embeds information about social, cultural, and political values people hold. Prior work has explored social and potentially harmful biases encoded in Pre-Trained Language models (PTLMs). However, there has been no systematic study investigating how values embedded in these models vary across cultures. In this paper, we introduce probes to study which values across cultures are embedded in these models, and whether they align with existing theories and cross-cultural value surveys. We find that PTLMs capture differences in values across cultures, but those only weakly align with established value surveys. We discuss implications of using mis-aligned models in cross-cultural settings, as well as ways of aligning PTLMs with value surveys.", "paper_url": "http://arxiv.org/abs/2203.13722v1", "pdf_url": "http://arxiv.org/pdf/2203.13722v1", "repo_url": null}, "2203.13696": {"publish_time": "2022-03-25", "title": "Speech-enhanced and Noise-aware Networks for Robust Speech Recognition", "author": "Hung-Shin Lee et.al.", "abstract": "Compensation for channel mismatch and noise interference is essential for robust automatic speech recognition. Enhanced speech has been introduced into the multi-condition training of acoustic models to improve their generalization ability. In this paper, a noise-aware training framework based on two cascaded neural structures is proposed to jointly optimize speech enhancement and speech recognition. The feature enhancement module is composed of a multi-task autoencoder, where noisy speech is decomposed into clean speech and noise. By concatenating its enhanced, noise-aware, and noisy features for each frame, the acoustic-modeling module maps each feature-augmented frame into a triphone state by optimizing the lattice-free maximum mutual information and cross entropy between the predicted and actual state sequences. On top of the factorized time delay neural network (TDNN-F) and its convolutional variant (CNN-TDNNF), both with SpecAug, the two proposed systems achieve word error rate (WER) of 3.90% and 3.55%, respectively, on the Aurora-4 task. Compared with the best existing systems that use bigram and trigram language models for decoding, the proposed CNN-TDNNF-based system achieves a relative WER reduction of 15.20% and 33.53%, respectively. In addition, the proposed CNN-TDNNF-based system also outperforms the baseline CNN-TDNNF system on the AMI task.", "paper_url": "http://arxiv.org/abs/2203.13696v1", "pdf_url": "http://arxiv.org/pdf/2203.13696v1", "repo_url": null}, "2203.13693": {"publish_time": "2022-03-25", "title": "UKP-SQUARE: An Online Platform for Question Answering Research", "author": "Tim Baumg\u00e4rtner et.al.", "abstract": "Recent advances in NLP and information retrieval have given rise to a diverse set of question answering tasks that are of different formats (e.g., extractive, abstractive), require different model architectures (e.g., generative, discriminative), and setups (e.g., with or without retrieval). Despite having a large number of powerful, specialized QA pipelines (which we refer to as Skills) that consider a single domain, model or setup, there exists no framework where users can easily explore and compare such pipelines and can extend them according to their needs. To address this issue, we present UKP-SQUARE, an extensible online QA platform for researchers which allows users to query and analyze a large collection of modern Skills via a user-friendly web interface and integrated behavioural tests. In addition, QA researchers can develop, manage, and share their custom Skills using our microservices that support a wide range of models (Transformers, Adapters, ONNX), datastores and retrieval techniques (e.g., sparse and dense). UKP-SQUARE is available on https://square.ukp-lab.de.", "paper_url": "http://arxiv.org/abs/2203.13693v1", "pdf_url": "http://arxiv.org/pdf/2203.13693v1", "repo_url": null}, "2203.13687": {"publish_time": "2022-03-25", "title": "Chain-based Discriminative Autoencoders for Speech Recognition", "author": "Hung-Shin Lee et.al.", "abstract": "In our previous work, we proposed a discriminative autoencoder (DcAE) for speech recognition. DcAE combines two training schemes into one. First, since DcAE aims to learn encoder-decoder mappings, the squared error between the reconstructed speech and the input speech is minimized. Second, in the code layer, frame-based phonetic embeddings are obtained by minimizing the categorical cross-entropy between ground truth labels and predicted triphone-state scores. DcAE is developed based on the Kaldi toolkit by treating various TDNN models as encoders. In this paper, we further propose three new versions of DcAE. First, a new objective function that considers both categorical cross-entropy and mutual information between ground truth and predicted triphone-state sequences is used. The resulting DcAE is called a chain-based DcAE (c-DcAE). For application to robust speech recognition, we further extend c-DcAE to hierarchical and parallel structures, resulting in hc-DcAE and pc-DcAE. In these two models, both the error between the reconstructed noisy speech and the input noisy speech and the error between the enhanced speech and the reference clean speech are taken into the objective function. Experimental results on the WSJ and Aurora-4 corpora show that our DcAE models outperform baseline systems.", "paper_url": "http://arxiv.org/abs/2203.13687v1", "pdf_url": "http://arxiv.org/pdf/2203.13687v1", "repo_url": null}, "2203.14936": {"publish_time": "2022-03-28", "title": "FedVLN: Privacy-preserving Federated Vision-and-Language Navigation", "author": "Kaiwen Zhou et.al.", "abstract": "Data privacy is a central problem for embodied agents that can perceive the environment, communicate with humans, and act in the real world. While helping humans complete tasks, the agent may observe and process sensitive information of users, such as house environments, human activities, etc. In this work, we introduce privacy-preserving embodied agent learning for the task of Vision-and-Language Navigation (VLN), where an embodied agent navigates house environments by following natural language instructions. We view each house environment as a local client, which shares nothing other than local updates with the cloud server and other clients, and propose a novel federated vision-and-language navigation (FedVLN) framework to protect data privacy during both training and pre-exploration. Particularly, we propose a decentralized training strategy to limit the data of each client to its local model training and a federated pre-exploration method to do partial model aggregation to improve model generalizability to unseen environments. Extensive results on R2R and RxR datasets show that under our FedVLN framework, decentralized VLN models achieve comparable results with centralized training while protecting seen environment privacy, and federated pre-exploration significantly outperforms centralized pre-exploration while preserving unseen environment privacy.", "paper_url": "http://arxiv.org/abs/2203.14936v1", "pdf_url": "http://arxiv.org/pdf/2203.14936v1", "repo_url": null}, "2203.14920": {"publish_time": "2022-03-28", "title": "UTSA NLP at SemEval-2022 Task 4: An Exploration of Simple Ensembles of Transformers, Convolutional, and Recurrent Neural Networks", "author": "Xingmeng Zhao et.al.", "abstract": "The act of appearing kind or helpful via the use of but having a feeling of superiority condescending and patronizing language can have have serious mental health implications to those that experience it. Thus, detecting this condescending and patronizing language online can be useful for online moderation systems. Thus, in this manuscript, we describe the system developed by Team UTSA SemEval-2022 Task 4, Detecting Patronizing and Condescending Language. Our approach explores the use of several deep learning architectures including RoBERTa, convolutions neural networks, and Bidirectional Long Short-Term Memory Networks. Furthermore, we explore simple and effective methods to create ensembles of neural network models. Overall, we experimented with several ensemble models and found that the a simple combination of five RoBERTa models achieved an F-score of .6441 on the development dataset and .5745 on the final test dataset. Finally, we also performed a comprehensive error analysis to better understand the limitations of the model and provide ideas for further research.", "paper_url": "http://arxiv.org/abs/2203.14920v1", "pdf_url": "http://arxiv.org/pdf/2203.14920v1", "repo_url": null}, "2203.14876": {"publish_time": "2022-03-28", "title": "Finnish Parliament ASR corpus - Analysis, benchmarks and statistics", "author": "Anja Virkkunen et.al.", "abstract": "Public sources like parliament meeting recordings and transcripts provide ever-growing material for the training and evaluation of automatic speech recognition (ASR) systems. In this paper, we publish and analyse the Finnish parliament ASR corpus, the largest publicly available collection of manually transcribed speech data for Finnish with over 3000 hours of speech and 449 speakers for which it provides rich demographic metadata. This corpus builds on earlier initial work, and as a result the corpus has a natural split into two training subsets from two periods of time. Similarly, there are two official, corrected test sets covering different times, setting an ASR task with longitudinal distribution-shift characteristics. An official development set is also provided. We develop a complete Kaldi-based data preparation pipeline, and hidden Markov model (HMM), hybrid deep neural network (HMM-DNN) and attention-based encoder-decoder (AED) ASR recipes. We set benchmarks on the official test sets, as well as multiple other recently used test sets. Both temporal corpus subsets are already large, and we observe that beyond their scale, ASR performance on the official test sets plateaus, whereas other domains benefit from added data. The HMM-DNN and AED approaches are compared in a carefully matched equal data setting, with the HMM-DNN system consistently performing better. Finally, the variation of the ASR accuracy is compared between the speaker categories available in the parliament metadata to detect potential biases based on factors such as gender, age, and education.", "paper_url": "http://arxiv.org/abs/2203.14876v1", "pdf_url": "http://arxiv.org/pdf/2203.14876v1", "repo_url": null}, "2203.14835": {"publish_time": "2022-03-28", "title": "Multilingual Simultaneous Speech Translation", "author": "Shashank Subramanya et.al.", "abstract": "Applications designed for simultaneous speech translation during events such as conferences or meetings need to balance quality and lag while displaying translated text to deliver a good user experience. One common approach to building online spoken language translation systems is by leveraging models built for offline speech translation. Based on a technique to adapt end-to-end monolingual models, we investigate multilingual models and different architectures (end-to-end and cascade) on the ability to perform online speech translation. On the multilingual TEDx corpus, we show that the approach generalizes to different architectures. We see similar gains in latency reduction (40% relative) across languages and architectures. However, the end-to-end architecture leads to smaller translation quality losses after adapting to the online model. Furthermore, the approach even scales to zero-shot directions.", "paper_url": "http://arxiv.org/abs/2203.14835v1", "pdf_url": "http://arxiv.org/pdf/2203.14835v1", "repo_url": null}, "2203.14757": {"publish_time": "2022-03-28", "title": "STUDIES: Corpus of Japanese Empathetic Dialogue Speech Towards Friendly Voice Agent", "author": "Yuki Saito et.al.", "abstract": "We present STUDIES, a new speech corpus for developing a voice agent that can speak in a friendly manner. Humans naturally control their speech prosody to empathize with each other. By incorporating this \"empathetic dialogue\" behavior into a spoken dialogue system, we can develop a voice agent that can respond to a user more naturally. We designed the STUDIES corpus to include a speaker who speaks with empathy for the interlocutor's emotion explicitly. We describe our methodology to construct an empathetic dialogue speech corpus and report the analysis results of the STUDIES corpus. We conducted a text-to-speech experiment to initially investigate how we can develop more natural voice agent that can tune its speaking style corresponding to the interlocutor's emotion. The results show that the use of interlocutor's emotion label and conversational context embedding can produce speech with the same degree of naturalness as that synthesized by using the agent's emotion label. Our project page of the STUDIES corpus is http://sython.org/Corpus/STUDIES.", "paper_url": "http://arxiv.org/abs/2203.14757v1", "pdf_url": "http://arxiv.org/pdf/2203.14757v1", "repo_url": null}, "2203.15773": {"publish_time": "2022-03-29", "title": "Streaming parallel transducer beam search with fast-slow cascaded encoders", "author": "Jay Mahadeokar et.al.", "abstract": "Streaming ASR with strict latency constraints is required in many speech recognition applications. In order to achieve the required latency, streaming ASR models sacrifice accuracy compared to non-streaming ASR models due to lack of future input context. Previous research has shown that streaming and non-streaming ASR for RNN Transducers can be unified by cascading causal and non-causal encoders. This work improves upon this cascaded encoders framework by leveraging two streaming non-causal encoders with variable input context sizes that can produce outputs at different audio intervals (e.g. fast and slow). We propose a novel parallel time-synchronous beam search algorithm for transducers that decodes from fast-slow encoders, where the slow encoder corrects the mistakes generated from the fast encoder. The proposed algorithm, achieves up to 20% WER reduction with a slight increase in token emission delays on the public Librispeech dataset and in-house datasets. We also explore techniques to reduce the computation by distributing processing between the fast and slow encoders. Lastly, we explore sharing the parameters in the fast encoder to reduce the memory footprint. This enables low latency processing on edge devices with low computation cost and a low memory footprint.", "paper_url": "http://arxiv.org/abs/2203.15773v1", "pdf_url": "http://arxiv.org/pdf/2203.15773v1", "repo_url": null}, "2203.15754": {"publish_time": "2022-03-29", "title": "Evaluating Prompts Across Multiple Choice Tasks In a Zero-Shot Setting", "author": "Gabriel Orlanski et.al.", "abstract": "Large language models have shown that impressive zero-shot performance can be achieved through natural language prompts (Radford et al., 2019; Brown et al., 2020; Sanh et al., 2021). Creating an effective prompt, however, requires significant trial and error. That \\textit{prompts} the question: how do the qualities of a prompt effects its performance? To this end, we collect and standardize prompts from a diverse range of tasks for use with tasks they were not designed for. We then evaluate these prompts across fixed multiple choice datasets for a quantitative analysis of how certain attributes of a prompt affect performance. We find that including the choices and using prompts not used during pre-training provide significant improvements. All experiments and code can be found https://github.com/gabeorlanski/zero-shot-cross-task.", "paper_url": "http://arxiv.org/abs/2203.15754v1", "pdf_url": "http://arxiv.org/pdf/2203.15754v1", "repo_url": "https://github.com/gabeorlanski/zero-shot-cross-task"}, "2203.15721": {"publish_time": "2022-03-29", "title": "On Decoding Strategies for Neural Text Generators", "author": "Gian Wiher et.al.", "abstract": "When generating text from probabilistic models, the chosen decoding strategy has a profound effect on the resulting text. Yet the properties elicited by various decoding strategies do not always transfer across natural language generation tasks. For example, while mode-seeking methods like beam search perform remarkably well for machine translation, they have been observed to lead to incoherent and repetitive text in story generation. Despite such observations, the effectiveness of decoding strategies is often assessed with respect to only a single task. This work -- in contrast -- provides a comprehensive analysis of the interaction between language generation tasks and decoding strategies. Specifically, we measure changes in attributes of generated text as a function of both decoding strategy and task using human and automatic evaluation. Our results reveal both previously-observed and surprising findings. For example, the nature of the diversity-quality trade-off in language generation is very task-specific; the length bias often attributed to beam search is not constant across tasks.", "paper_url": "http://arxiv.org/abs/2203.15721v1", "pdf_url": "http://arxiv.org/pdf/2203.15721v1", "repo_url": null}, "2203.15686": {"publish_time": "2022-03-29", "title": "Forecasting with Economic News", "author": "Luca Barbaglia et.al.", "abstract": "The goal of this paper is to evaluate the informational content of sentiment extracted from news articles about the state of the economy. We propose a fine-grained aspect-based sentiment analysis that has two main characteristics: 1) we consider only the text in the article that is semantically dependent on a term of interest (aspect-based) and, 2) assign a sentiment score to each word based on a dictionary that we develop for applications in economics and finance (fine-grained). Our data set includes six large US newspapers, for a total of over 6.6 million articles and 4.2 billion words. Our findings suggest that several measures of economic sentiment track closely business cycle fluctuations and that they are relevant predictors for four major macroeconomic variables. We find that there are significant improvements in forecasting when sentiment is considered along with macroeconomic factors. In addition, we also find that sentiment matters to explains the tails of the probability distribution across several macroeconomic variables.", "paper_url": "http://arxiv.org/abs/2203.15686v1", "pdf_url": "http://arxiv.org/pdf/2203.15686v1", "repo_url": null}, "2203.15685": {"publish_time": "2022-03-29", "title": "EnvEdit: Environment Editing for Vision-and-Language Navigation", "author": "Jialu Li et.al.", "abstract": "In Vision-and-Language Navigation (VLN), an agent needs to navigate through the environment based on natural language instructions. Due to limited available data for agent training and finite diversity in navigation environments, it is challenging for the agent to generalize to new, unseen environments. To address this problem, we propose EnvEdit, a data augmentation method that creates new environments by editing existing environments, which are used to train a more generalizable agent. Our augmented environments can differ from the seen environments in three diverse aspects: style, object appearance, and object classes. Training on these edit-augmented environments prevents the agent from overfitting to existing environments and helps generalize better to new, unseen environments. Empirically, on both the Room-to-Room and the multi-lingual Room-Across-Room datasets, we show that our proposed EnvEdit method gets significant improvements in all metrics on both pre-trained and non-pre-trained VLN agents, and achieves the new state-of-the-art on the test leaderboard. We further ensemble the VLN agents augmented on different edited environments and show that these edit methods are complementary. Code and data are available at https://github.com/jialuli-luka/EnvEdit", "paper_url": "http://arxiv.org/abs/2203.15685v1", "pdf_url": "http://arxiv.org/pdf/2203.15685v1", "repo_url": "https://github.com/jialuli-luka/envedit"}, "2203.16512": {"publish_time": "2022-03-30", "title": "Vakyansh: ASR Toolkit for Low Resource Indic languages", "author": "Harveen Singh Chadha et.al.", "abstract": "We present Vakyansh, an end to end toolkit for Speech Recognition in Indic languages. India is home to almost 121 languages and around 125 crore speakers. Yet most of the languages are low resource in terms of data and pretrained models. Through Vakyansh, we introduce automatic data pipelines for data creation, model training, model evaluation and deployment. We create 14,000 hours of speech data in 23 Indic languages and train wav2vec 2.0 based pretrained models. These pretrained models are then finetuned to create state of the art speech recognition models for 18 Indic languages which are followed by language models and punctuation restoration models. We open source all these resources with a mission that this will inspire the speech community to develop speech first applications using our ASR models in Indic languages.", "paper_url": "http://arxiv.org/abs/2203.16512v1", "pdf_url": "http://arxiv.org/pdf/2203.16512v1", "repo_url": null}, "2203.16502": {"publish_time": "2022-03-30", "title": "Generative Spoken Dialogue Language Modeling", "author": "Tu Anh Nguyen et.al.", "abstract": "We introduce dGSLM, the first \"textless\" model able to generate audio samples of naturalistic spoken dialogues. It uses recent work on unsupervised spoken unit discovery coupled with a dual-tower transformer architecture with cross-attention trained on 2000 hours of two-channel raw conversational audio (Fisher dataset) without any text or labels. It is able to generate speech, laughter and other paralinguistic signals in the two channels simultaneously and reproduces naturalistic turn taking. Generation samples can be found at: https://speechbot.github.io/dgslm.", "paper_url": "http://arxiv.org/abs/2203.16502v1", "pdf_url": "http://arxiv.org/pdf/2203.16502v1", "repo_url": null}, "2203.16487": {"publish_time": "2022-03-30", "title": "Lossless Speedup of Autoregressive Translation with Generalized Aggressive Decoding", "author": "Heming Xia et.al.", "abstract": "In this paper, we propose Generalized Aggressive Decoding (GAD) -- a novel approach to accelerating autoregressive translation with no quality loss, through the collaboration of autoregressive and non-autoregressive translation (NAT) of the Transformer. At each decoding iteration, GAD aggressively decodes a number of tokens in parallel as a draft through NAT and then verifies them in the autoregressive manner, where only the tokens that pass the verification are kept as decoded tokens. GAD can achieve the same performance as autoregressive translation but perform much more efficiently because both NAT drafting and autoregressive verification are fast due to parallel computing. We conduct experiments in the WMT14 English-German translation task and confirm that the vanilla GAD yields exactly the same results as greedy decoding with about 3x speedup, and that its variant (GAD++) with an advanced verification strategy not only outperforms the greedy translation and even achieves the comparable translation quality with the beam search result, but also further improves the decoding speed, resulting in an around 5x speedup over autoregressive translation.", "paper_url": "http://arxiv.org/abs/2203.16487v1", "pdf_url": "http://arxiv.org/pdf/2203.16487v1", "repo_url": null}, "2203.16474": {"publish_time": "2022-03-30", "title": "Zero Shot Crosslingual Eye-Tracking Data Prediction using Multilingual Transformer Models", "author": "Harshvardhan Srivastava et.al.", "abstract": "Eye tracking data during reading is a useful source of information to understand the cognitive processes that take place during language comprehension processes. Different languages account for different brain triggers , however there seems to be some uniform indicators. In this paper, we describe our submission to the CMCL 2022 shared task on predicting human reading patterns for multi-lingual dataset. Our model uses text representations from transformers and some hand engineered features with a regression layer on top to predict statistical measures of mean and standard deviation for 2 main eye-tracking features. We train an end to end model to extract meaningful information from different languages and test our model on two seperate datasets. We compare different transformer models and show ablation studies affecting model performance. Our final submission ranked 4th place for SubTask-1 and 1st place for SubTask-2 for the shared task.", "paper_url": "http://arxiv.org/abs/2203.16474v1", "pdf_url": "http://arxiv.org/pdf/2203.16474v1", "repo_url": null}, "2203.16434": {"publish_time": "2022-03-30", "title": "TubeDETR: Spatio-Temporal Video Grounding with Transformers", "author": "Antoine Yang et.al.", "abstract": "We consider the problem of localizing a spatio-temporal tube in a video corresponding to a given text query. This is a challenging task that requires the joint and efficient modeling of temporal, spatial and multi-modal interactions. To address this task, we propose TubeDETR, a transformer-based architecture inspired by the recent success of such models for text-conditioned object detection. Our model notably includes: (i) an efficient video and text encoder that models spatial multi-modal interactions over sparsely sampled frames and (ii) a space-time decoder that jointly performs spatio-temporal localization. We demonstrate the advantage of our proposed components through an extensive ablation study. We also evaluate our full approach on the spatio-temporal video grounding task and demonstrate improvements over the state of the art on the challenging VidSTG and HC-STVG benchmarks. Code and trained models are publicly available at https://antoyang.github.io/tubedetr.html.", "paper_url": "http://arxiv.org/abs/2203.16434v1", "pdf_url": "http://arxiv.org/pdf/2203.16434v1", "repo_url": "https://github.com/antoyang/TubeDETR"}, "2203.17225": {"publish_time": "2022-03-31", "title": "A Baseline Readability Model for Cebuano", "author": "Lloyd Lois Antonie Reyes et.al.", "abstract": "In this study, we developed the first baseline readability model for the Cebuano language. Cebuano is the second most-used native language in the Philippines with about 27.5 million speakers. As the baseline, we extracted traditional or surface-based features, syllable patterns based from Cebuano's documented orthography, and neural embeddings from the multilingual BERT model. Results show that the use of the first two handcrafted linguistic features obtained the best performance trained on an optimized Random Forest model with approximately 84\\% across all metrics. The feature sets and algorithm used also is similar to previous results in readability assessment for the Filipino language showing potential of crosslingual application. To encourage more work for readability assessment in Philippine languages such as Cebuano, we open-sourced both code and data.", "paper_url": "http://arxiv.org/abs/2203.17225v1", "pdf_url": "http://arxiv.org/pdf/2203.17225v1", "repo_url": "https://github.com/imperialite/cebuano-readability"}, "2203.17217": {"publish_time": "2022-03-31", "title": "On the probability-quality paradox in language generation", "author": "Clara Meister et.al.", "abstract": "When generating natural language from neural probabilistic models, high probability does not always coincide with high quality: It has often been observed that mode-seeking decoding methods, i.e., those that produce high-probability text under the model, lead to unnatural language. On the other hand, the lower-probability text generated by stochastic methods is perceived as more human-like. In this note, we offer an explanation for this phenomenon by analyzing language generation through an information-theoretic lens. Specifically, we posit that human-like language should contain an amount of information (quantified as negative log-probability) that is close to the entropy of the distribution over natural strings. Further, we posit that language with substantially more (or less) information is undesirable. We provide preliminary empirical evidence in favor of this hypothesis; quality ratings of both human and machine-generated text -- covering multiple tasks and common decoding strategies -- suggest high-quality text has an information content significantly closer to the entropy than we would expect by chance.", "paper_url": "http://arxiv.org/abs/2203.17217v1", "pdf_url": "http://arxiv.org/pdf/2203.17217v1", "repo_url": null}, "2203.17213": {"publish_time": "2022-03-31", "title": "Analyzing Wrap-Up Effects through an Information-Theoretic Lens", "author": "Clara Meister et.al.", "abstract": "Numerous analyses of reading time (RT) data have been implemented -- all in an effort to better understand the cognitive processes driving reading comprehension. However, data measured on words at the end of a sentence -- or even at the end of a clause -- is often omitted due to the confounding factors introduced by so-called \"wrap-up effects,\" which manifests as a skewed distribution of RTs for these words. Consequently, the understanding of the cognitive processes that might be involved in these wrap-up effects is limited. In this work, we attempt to learn more about these processes by examining the relationship between wrap-up effects and information-theoretic quantities, such as word and context surprisals. We find that the distribution of information in prior contexts is often predictive of sentence- and clause-final RTs (while not of sentence-medial RTs). This lends support to several prior hypotheses about the processes involved in wrap-up effects.", "paper_url": "http://arxiv.org/abs/2203.17213v1", "pdf_url": "http://arxiv.org/pdf/2203.17213v1", "repo_url": null}, "2203.17196": {"publish_time": "2022-03-31", "title": "CatIss: An Intelligent Tool for Categorizing Issues Reports using Transformers", "author": "Maliheh Izadi et.al.", "abstract": "Users use Issue Tracking Systems to keep track and manage issue reports in their repositories. An issue is a rich source of software information that contains different reports including a problem, a request for new features, or merely a question about the software product. As the number of these issues increases, it becomes harder to manage them manually. Thus, automatic approaches are proposed to help facilitate the management of issue reports.   This paper describes CatIss, an automatic CATegorizer of ISSue reports which is built upon the Transformer-based pre-trained RoBERTa model. CatIss classifies issue reports into three main categories of Bug reports, Enhancement/feature requests, and Questions. First, the datasets provided for the NLBSE tool competition are cleaned and preprocessed. Then, the pre-trained RoBERTa model is fine-tuned on the preprocessed dataset. Evaluating CatIss on about 80 thousand issue reports from GitHub, indicates that it performs very well surpassing the competition baseline, TicketTagger, and achieving 87.2% F1-score (micro average). Additionally, as CatIss is trained on a wide set of repositories, it is a generic prediction model, hence applicable for any unseen software project or projects with little historical data. Scripts for cleaning the datasets, training CatIss, and evaluating the model are publicly available.", "paper_url": "http://arxiv.org/abs/2203.17196v1", "pdf_url": "http://arxiv.org/pdf/2203.17196v1", "repo_url": "https://github.com/malihehizadi/catiss"}, "2203.17190": {"publish_time": "2022-03-31", "title": "Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme Representations for Text to Speech", "author": "Guangyan Zhang et.al.", "abstract": "Recently, leveraging BERT pre-training to improve the phoneme encoder in text to speech (TTS) has drawn increasing attention. However, the works apply pre-training with character-based units to enhance the TTS phoneme encoder, which is inconsistent with the TTS fine-tuning that takes phonemes as input. Pre-training only with phonemes as input can alleviate the input mismatch but lack the ability to model rich representations and semantic information due to limited phoneme vocabulary. In this paper, we propose MixedPhoneme BERT, a novel variant of the BERT model that uses mixed phoneme and sup-phoneme representations to enhance the learning capability. Specifically, we merge the adjacent phonemes into sup-phonemes and combine the phoneme sequence and the merged sup-phoneme sequence as the model input, which can enhance the model capacity to learn rich contextual representations. Experiment results demonstrate that our proposed Mixed-Phoneme BERT significantly improves the TTS performance with 0.30 CMOS gain compared with the FastSpeech 2 baseline. The Mixed-Phoneme BERT achieves 3x inference speedup and similar voice quality to the previous TTS pre-trained model PnG BERT", "paper_url": "http://arxiv.org/abs/2203.17190v1", "pdf_url": "http://arxiv.org/pdf/2203.17190v1", "repo_url": null}, "2204.00598": {"publish_time": "2022-04-01", "title": "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language", "author": "Andy Zeng et.al.", "abstract": "Large foundation models can exhibit unique capabilities depending on the domain of data they are trained on. While these domains are generic, they may only barely overlap. For example, visual-language models (VLMs) are trained on Internet-scale image captions, but large language models (LMs) are further trained on Internet-scale text with no images (e.g. from spreadsheets, to SAT questions). As a result, these models store different forms of commonsense knowledge across different domains. In this work, we show that this model diversity is symbiotic, and can be leveraged to build AI systems with structured Socratic dialogue -- in which new multimodal tasks are formulated as a guided language-based exchange between different pre-existing foundation models, without additional finetuning. In the context of egocentric perception, we present a case study of Socratic Models (SMs) that can provide meaningful results for complex tasks such as generating free-form answers to contextual questions about egocentric video, by formulating video Q&A as short story Q&A, i.e. summarizing the video into a short story, then answering questions about it. Additionally, SMs can generate captions for Internet images, and are competitive with state-of-the-art on zero-shot video-to-text retrieval with 42.8 R@1 on MSR-VTT 1k-A. SMs demonstrate how to compose foundation models zero-shot to capture new multimodal functionalities, without domain-specific data collection. Prototypes are available at socraticmodels.github.io.", "paper_url": "http://arxiv.org/abs/2204.00598v1", "pdf_url": "http://arxiv.org/pdf/2204.00598v1", "repo_url": null}, "2204.00558": {"publish_time": "2022-04-01", "title": "Multi-task RNN-T with Semantic Decoder for Streamable Spoken Language Understanding", "author": "Xuandi Fu et.al.", "abstract": "End-to-end Spoken Language Understanding (E2E SLU) has attracted increasing interest due to its advantages of joint optimization and low latency when compared to traditionally cascaded pipelines. Existing E2E SLU models usually follow a two-stage configuration where an Automatic Speech Recognition (ASR) network first predicts a transcript which is then passed to a Natural Language Understanding (NLU) module through an interface to infer semantic labels, such as intent and slot tags. This design, however, does not consider the NLU posterior while making transcript predictions, nor correct the NLU prediction error immediately by considering the previously predicted word-pieces. In addition, the NLU model in the two-stage system is not streamable, as it must wait for the audio segments to complete processing, which ultimately impacts the latency of the SLU system. In this work, we propose a streamable multi-task semantic transducer model to address these considerations. Our proposed architecture predicts ASR and NLU labels auto-regressively and uses a semantic decoder to ingest both previously predicted word-pieces and slot tags while aggregating them through a fusion network. Using an industry scale SLU and a public FSC dataset, we show the proposed model outperforms the two-stage E2E SLU model for both ASR and NLU metrics.", "paper_url": "http://arxiv.org/abs/2204.00558v1", "pdf_url": "http://arxiv.org/pdf/2204.00558v1", "repo_url": null}, "2204.00556": {"publish_time": "2022-04-01", "title": "Nowruz at SemEval-2022 Task 7: Tackling Cloze Tests with Transformers and Ordinal Regression", "author": "Mohammadmahdi Nouriborji et.al.", "abstract": "This paper outlines the system using which team Nowruz participated in SemEval 2022 Task 7 Identifying Plausible Clarifications of Implicit and Underspecified Phrases for both subtasks A and B. Using a pre-trained transformer as a backbone, the model targeted the task of multi-task classification and ranking in the context of finding the best fillers for a cloze task related to instructional texts on the website Wikihow.   The system employed a combination of two ordinal regression components to tackle this task in a multi-task learning scenario. According to the official leaderboard of the shared task, this system was ranked 5th in the ranking and 7th in the classification subtasks out of 21 participating teams. With additional experiments, the models have since been further optimised.", "paper_url": "http://arxiv.org/abs/2204.00556v1", "pdf_url": "http://arxiv.org/pdf/2204.00556v1", "repo_url": null}, "2204.00548": {"publish_time": "2022-04-01", "title": "Unified and Effective Ensemble Knowledge Distillation", "author": "Chuhan Wu et.al.", "abstract": "Ensemble knowledge distillation can extract knowledge from multiple teacher models and encode it into a single student model. Many existing methods learn and distill the student model on labeled data only. However, the teacher models are usually learned on the same labeled data, and their predictions have high correlations with groudtruth labels. Thus, they cannot provide sufficient knowledge complementary to task labels for student teaching. Distilling on unseen unlabeled data has the potential to enhance the knowledge transfer from the teachers to the student. In this paper, we propose a unified and effective ensemble knowledge distillation method that distills a single student model from an ensemble of teacher models on both labeled and unlabeled data. Since different teachers may have diverse prediction correctness on the same sample, on labeled data we weight the predictions of different teachers according to their correctness. In addition, we weight the distillation loss based on the overall prediction correctness of the teacher ensemble to distill high-quality knowledge. On unlabeled data, there is no groundtruth to evaluate prediction correctness. Fortunately, the disagreement among teachers is an indication of sample hardness, and thereby we weight the distillation loss based on teachers' disagreement to emphasize knowledge distillation on important samples. Extensive experiments on four datasets show the effectiveness of our proposed ensemble distillation method.", "paper_url": "http://arxiv.org/abs/2204.00548v1", "pdf_url": "http://arxiv.org/pdf/2204.00548v1", "repo_url": null}, "2204.00545": {"publish_time": "2022-04-01", "title": "A Novel Multimodal Approach for Studying the Dynamics of Curiosity in Small Group Learning", "author": "Tanmay Sinha et.al.", "abstract": "Curiosity is a vital metacognitive skill in educational contexts, leading to creativity, and a love of learning. And while many school systems increasingly undercut curiosity by teaching to the test, teachers are increasingly interested in how to evoke curiosity in their students to prepare them for a world in which lifelong learning and reskilling will be more and more important. One aspect of curiosity that has received little attention, however, is the role of peers in eliciting curiosity. We present what we believe to be the first theoretical framework that articulates an integrated socio-cognitive account of curiosity that ties observable behaviors in peers to underlying curiosity states. We make a bipartite distinction between individual and interpersonal functions that contribute to curiosity, and multimodal behaviors that fulfill these functions. We validate the proposed framework by leveraging a longitudinal latent variable modeling approach. Findings confirm a positive predictive relationship between the latent variables of individual and interpersonal functions and curiosity, with the interpersonal functions exercising a comparatively stronger influence. Prominent behavioral realizations of these functions are also discovered in a data-driven manner. We instantiate the proposed theoretical framework in a set of strategies and tactics that can be incorporated into learning technologies to indicate, evoke, and scaffold curiosity. This work is a step towards designing learning technologies that can recognize and evoke moment-by-moment curiosity during learning in social contexts and towards a more complete multimodal learning analytics. The underlying rationale is applicable more generally for developing computer support for other metacognitive and socio-emotional skills.", "paper_url": "http://arxiv.org/abs/2204.00545v1", "pdf_url": "http://arxiv.org/pdf/2204.00545v1", "repo_url": null}, "2204.01691": {"publish_time": "2022-04-04", "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances", "author": "Michael Ahn et.al.", "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's \"hands and eyes,\" while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally-extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at https://say-can.github.io/", "paper_url": "http://arxiv.org/abs/2204.01691v1", "pdf_url": "http://arxiv.org/pdf/2204.01691v1", "repo_url": null}, "2204.01677": {"publish_time": "2022-04-04", "title": "Self-Supervised Speech Representations Preserve Speech Characteristics while Anonymizing Voices", "author": "Abner Hernandez et.al.", "abstract": "Collecting speech data is an important step in training speech recognition systems and other speech-based machine learning models. However, the issue of privacy protection is an increasing concern that must be addressed. The current study investigates the use of voice conversion as a method for anonymizing voices. In particular, we train several voice conversion models using self-supervised speech representations including Wav2Vec2.0, Hubert and UniSpeech. Converted voices retain a low word error rate within 1% of the original voice. Equal error rate increases from 1.52% to 46.24% on the LibriSpeech test set and from 3.75% to 45.84% on speakers from the VCTK corpus which signifies degraded performance on speaker verification. Lastly, we conduct experiments on dysarthric speech data to show that speech features relevant to articulation, prosody, phonation and phonology can be extracted from anonymized voices for discriminating between healthy and pathological speech.", "paper_url": "http://arxiv.org/abs/2204.01677v1", "pdf_url": "http://arxiv.org/pdf/2204.01677v1", "repo_url": null}, "2204.01670": {"publish_time": "2022-04-04", "title": "Cross-lingual Self-Supervised Speech Representations for Improved Dysarthric Speech Recognition", "author": "Abner Hernandez et.al.", "abstract": "State-of-the-art automatic speech recognition (ASR) systems perform well on healthy speech. However, the performance on impaired speech still remains an issue. The current study explores the usefulness of using Wav2Vec self-supervised speech representations as features for training an ASR system for dysarthric speech. Dysarthric speech recognition is particularly difficult as several aspects of speech such as articulation, prosody and phonation can be impaired. Specifically, we train an acoustic model with features extracted from Wav2Vec, Hubert, and the cross-lingual XLSR model. Results suggest that speech representations pretrained on large unlabelled data can improve word error rate (WER) performance. In particular, features from the multilingual model led to lower WERs than filterbanks (Fbank) or models trained on a single language. Improvements were observed in English speakers with cerebral palsy caused dysarthria (UASpeech corpus), Spanish speakers with Parkinsonian dysarthria (PC-GITA corpus) and Italian speakers with paralysis-based dysarthria (EasyCall corpus). Compared to using Fbank features, XLSR-based features reduced WERs by 6.8%, 22.0%, and 7.0% for the UASpeech, PC-GITA, and EasyCall corpus, respectively.", "paper_url": "http://arxiv.org/abs/2204.01670v1", "pdf_url": "http://arxiv.org/pdf/2204.01670v1", "repo_url": null}, "2204.01614": {"publish_time": "2022-04-04", "title": "MetaAID: A Flexible Framework for Developing Metaverse Applications via AI Technology and Human Editing", "author": "Hongyin Zhu et.al.", "abstract": "Achieving the expansion of domestic demand and the economic internal circulation requires balanced and coordinated support from multiple industries (domains) such as consumption, education, entertainment, engineering infrastructure, etc., which is indispensable for maintaining economic development. Metaverse applications may help with this task and can make many industries more interesting, more efficient, and provide a better user experience. The first challenge is that metaverse application development inevitably requires the support of various artificial intelligence (AI) technologies such as natural language processing (NLP), knowledge graph (KG), computer vision (CV), and machine learning (ML), etc. However, existing metaverse application development lacks a lightweight AI technology framework. This paper proposes a flexible metaverse AI technology framework metaAID that aims to support language and semantic technologies in the development of digital twins and virtual humans. The second challenge is that the development process of metaverse applications involves both technical development tasks and manual editing work, and often becomes a heavyweight multi-team collaboration project, not to mention the development of metaverse applications in multiple industries. Our framework summarizes common AI technologies and application development templates with common functional modules and interfaces. Based on this framework, we have designed 5 applications for 3 industries around the expansion of domestic demand and economic internal circulation. Experimental results show that our framework can support AI technologies when developing metaverse applications in different industries.", "paper_url": "http://arxiv.org/abs/2204.01614v1", "pdf_url": "http://arxiv.org/pdf/2204.01614v1", "repo_url": null}, "2204.01512": {"publish_time": "2022-04-04", "title": "LPAttack: A Feasible Annotation Scheme for Capturing Logic Pattern of Attacks in Arguments", "author": "Farjana Sultana Mim et.al.", "abstract": "In argumentative discourse, persuasion is often achieved by refuting or attacking others arguments. Attacking is not always straightforward and often comprise complex rhetorical moves such that arguers might agree with a logic of an argument while attacking another logic. Moreover, arguer might neither deny nor agree with any logics of an argument, instead ignore them and attack the main stance of the argument by providing new logics and presupposing that the new logics have more value or importance than the logics present in the attacked argument. However, no existing studies in the computational argumentation capture such complex rhetorical moves in attacks or the presuppositions or value judgements in them. In order to address this gap, we introduce LPAttack, a novel annotation scheme that captures the common modes and complex rhetorical moves in attacks along with the implicit presuppositions and value judgements in them. Our annotation study shows moderate inter-annotator agreement, indicating that human annotation for the proposed scheme is feasible. We publicly release our annotated corpus and the annotation guidelines.", "paper_url": "http://arxiv.org/abs/2204.01512v1", "pdf_url": "http://arxiv.org/pdf/2204.01512v1", "repo_url": null}, "2204.02380": {"publish_time": "2022-04-05", "title": "CLEVR-X: A Visual Reasoning Dataset for Natural Language Explanations", "author": "Leonard Salewski et.al.", "abstract": "Providing explanations in the context of Visual Question Answering (VQA) presents a fundamental problem in machine learning. To obtain detailed insights into the process of generating natural language explanations for VQA, we introduce the large-scale CLEVR-X dataset that extends the CLEVR dataset with natural language explanations. For each image-question pair in the CLEVR dataset, CLEVR-X contains multiple structured textual explanations which are derived from the original scene graphs. By construction, the CLEVR-X explanations are correct and describe the reasoning and visual information that is necessary to answer a given question. We conducted a user study to confirm that the ground-truth explanations in our proposed dataset are indeed complete and relevant. We present baseline results for generating natural language explanations in the context of VQA using two state-of-the-art frameworks on the CLEVR-X dataset. Furthermore, we provide a detailed analysis of the explanation generation quality for different question and answer types. Additionally, we study the influence of using different numbers of ground-truth explanations on the convergence of natural language generation (NLG) metrics. The CLEVR-X dataset is publicly available at \\url{https://explainableml.github.io/CLEVR-X/}.", "paper_url": "http://arxiv.org/abs/2204.02380v1", "pdf_url": "http://arxiv.org/pdf/2204.02380v1", "repo_url": "https://github.com/explainableml/clevr-x"}, "2204.02363": {"publish_time": "2022-04-05", "title": "Towards Best Practices for Training Multilingual Dense Retrieval Models", "author": "Xinyu Zhang et.al.", "abstract": "Dense retrieval models using a transformer-based bi-encoder design have emerged as an active area of research. In this work, we focus on the task of monolingual retrieval in a variety of typologically diverse languages using one such design. Although recent work with multilingual transformers demonstrates that they exhibit strong cross-lingual generalization capabilities, there remain many open research questions, which we tackle here. Our study is organized as a \"best practices\" guide for training multilingual dense retrieval models, broken down into three main scenarios: where a multilingual transformer is available, but relevance judgments are not available in the language of interest; where both models and training data are available; and, where training data are available not but models. In considering these scenarios, we gain a better understanding of the role of multi-stage fine-tuning, the strength of cross-lingual transfer under various conditions, the usefulness of out-of-language data, and the advantages of multilingual vs. monolingual transformers. Our recommendations offer a guide for practitioners building search applications, particularly for low-resource languages, and while our work leaves open a number of research questions, we provide a solid foundation for future work.", "paper_url": "http://arxiv.org/abs/2204.02363v1", "pdf_url": "http://arxiv.org/pdf/2204.02363v1", "repo_url": null}, "2204.02329": {"publish_time": "2022-04-05", "title": "Can language models learn from explanations in context?", "author": "Andrew K. Lampinen et.al.", "abstract": "Large language models can perform new tasks by adapting to a few in-context examples. For humans, rapid learning from examples can benefit from explanations that connect examples to task principles. We therefore investigate whether explanations of few-shot examples can allow language models to adapt more effectively. We annotate a set of 40 challenging tasks from BIG-Bench with explanations of answers to a small subset of questions, as well as a variety of matched control explanations. We evaluate the effects of various zero-shot and few-shot prompts that include different types of explanations, instructions, and controls on the performance of a range of large language models. We analyze these results using statistical multilevel modeling techniques that account for the nested dependencies among conditions, tasks, prompts, and models. We find that explanations of examples can improve performance. Adding untuned explanations to a few-shot prompt offers a modest improvement in performance; about 1/3 the effect size of adding few-shot examples, but twice the effect size of task instructions. We then show that explanations tuned for performance on a small validation set offer substantially larger benefits; building a prompt by selecting examples and explanations together substantially improves performance over selecting examples alone. Hand-tuning explanations can substantially improve performance on challenging tasks. Furthermore, even untuned explanations outperform carefully matched controls, suggesting that the benefits are due to the link between an example and its explanation, rather than lower-level features of the language used. However, only large models can benefit from explanations. In summary, explanations can support the in-context learning abilities of large language models on", "paper_url": "http://arxiv.org/abs/2204.02329v1", "pdf_url": "http://arxiv.org/pdf/2204.02329v1", "repo_url": null}, "2204.02311": {"publish_time": "2022-04-05", "title": "PaLM: Scaling Language Modeling with Pathways", "author": "Aakanksha Chowdhery et.al.", "abstract": "Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.", "paper_url": "http://arxiv.org/abs/2204.02311v1", "pdf_url": "http://arxiv.org/pdf/2204.02311v1", "repo_url": null}, "2204.02292": {"publish_time": "2022-04-05", "title": "Parameter-Efficient Neural Reranking for Cross-Lingual and Multilingual Retrieval", "author": "Robert Litschko et.al.", "abstract": "State-of-the-art neural (re)rankers are notoriously data hungry which - given the lack of large-scale training data in languages other than English - makes them rarely used in multilingual and cross-lingual retrieval settings. Current approaches therefore typically transfer rankers trained on English data to other languages and cross-lingual setups by means of multilingual encoders: they fine-tune all the parameters of a pretrained massively multilingual Transformer (MMT, e.g., multilingual BERT) on English relevance judgments and then deploy it in the target language. In this work, we show that two parameter-efficient approaches to cross-lingual transfer, namely Sparse Fine-Tuning Masks (SFTMs) and Adapters, allow for a more lightweight and more effective zero-shot transfer to multilingual and cross-lingual retrieval tasks. We first train language adapters (or SFTMs) via Masked Language Modelling and then train retrieval (i.e., reranking) adapters (SFTMs) on top while keeping all other parameters fixed. At inference, this modular design allows us to compose the ranker by applying the task adapter (or SFTM) trained with source language data together with the language adapter (or SFTM) of a target language. Besides improved transfer performance, these two approaches offer faster ranker training, with only a fraction of parameters being updated compared to full MMT fine-tuning. We benchmark our models on the CLEF-2003 benchmark, showing that our parameter-efficient methods outperform standard zero-shot transfer with full MMT fine-tuning, while enabling modularity and reducing training times. Further, we show on the example of Swahili and Somali that, for low(er)-resource languages, our parameter-efficient neural re-rankers can improve the ranking of the competitive machine translation-based ranker.", "paper_url": "http://arxiv.org/abs/2204.02292v1", "pdf_url": "http://arxiv.org/pdf/2204.02292v1", "repo_url": null}, "2204.02967": {"publish_time": "2022-04-06", "title": "Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation", "author": "Sravya Popuri et.al.", "abstract": "Direct speech-to-speech translation (S2ST) models suffer from data scarcity issues as there exists little parallel S2ST data, compared to the amount of data available for conventional cascaded systems that consist of automatic speech recognition (ASR), machine translation (MT), and text-to-speech (TTS) synthesis. In this work, we explore self-supervised pre-training with unlabeled speech data and data augmentation to tackle this issue. We take advantage of a recently proposed speech-to-unit translation (S2UT) framework that encodes target speech into discrete representations, and transfer pre-training and efficient partial finetuning techniques that work well for speech-to-text translation (S2T) to the S2UT domain by studying both speech encoder and discrete unit decoder pre-training. Our experiments show that self-supervised pre-training consistently improves model performance compared with multitask learning with a BLEU gain of 4.3-12.0 under various data setups, and it can be further combined with data augmentation techniques that apply MT to create weakly supervised training data. Audio samples are available at: https://facebookresearch.github.io/speech_translation/enhanced_direct_s2st_units/index.html .", "paper_url": "http://arxiv.org/abs/2204.02967v1", "pdf_url": "http://arxiv.org/pdf/2204.02967v1", "repo_url": null}, "2204.02952": {"publish_time": "2022-04-06", "title": "Inducing Positive Perspectives with Text Reframing", "author": "Caleb Ziems et.al.", "abstract": "Sentiment transfer is one popular example of a text style transfer task, where the goal is to reverse the sentiment polarity of a text. With a sentiment reversal comes also a reversal in meaning. We introduce a different but related task called positive reframing in which we neutralize a negative point of view and generate a more positive perspective for the author without contradicting the original meaning. Our insistence on meaning preservation makes positive reframing a challenging and semantically rich task. To facilitate rapid progress, we introduce a large-scale benchmark, Positive Psychology Frames, with 8,349 sentence pairs and 12,755 structured annotations to explain positive reframing in terms of six theoretically-motivated reframing strategies. Then we evaluate a set of state-of-the-art text style transfer models, and conclude by discussing key challenges and directions for future work.", "paper_url": "http://arxiv.org/abs/2204.02952v1", "pdf_url": "http://arxiv.org/pdf/2204.02952v1", "repo_url": "https://github.com/gt-salt/positive-frames"}, "2204.02922": {"publish_time": "2022-04-06", "title": "Paying More Attention to Self-attention: Improving Pre-trained Language Models via Attention Guiding", "author": "Shanshan Wang et.al.", "abstract": "Pre-trained language models (PLM) have demonstrated their effectiveness for a broad range of information retrieval and natural language processing tasks. As the core part of PLM, multi-head self-attention is appealing for its ability to jointly attend to information from different positions. However, researchers have found that PLM always exhibits fixed attention patterns regardless of the input (e.g., excessively paying attention to [CLS] or [SEP]), which we argue might neglect important information in the other positions. In this work, we propose a simple yet effective attention guiding mechanism to improve the performance of PLM by encouraging attention towards the established goals. Specifically, we propose two kinds of attention guiding methods, i.e., map discrimination guiding (MDG) and attention pattern decorrelation guiding (PDG). The former definitely encourages the diversity among multiple self-attention heads to jointly attend to information from different representation subspaces, while the latter encourages self-attention to attend to as many different positions of the input as possible. We conduct experiments with multiple general pre-trained models (i.e., BERT, ALBERT, and Roberta) and domain-specific pre-trained models (i.e., BioBERT, ClinicalBERT, BlueBert, and SciBERT) on three benchmark datasets (i.e., MultiNLI, MedNLI, and Cross-genre-IR). Extensive experimental results demonstrate that our proposed MDG and PDG bring stable performance improvements on all datasets with high efficiency and low cost.", "paper_url": "http://arxiv.org/abs/2204.02922v1", "pdf_url": "http://arxiv.org/pdf/2204.02922v1", "repo_url": null}, "2204.02908": {"publish_time": "2022-04-06", "title": "Question Generation for Reading Comprehension Assessment by Modeling How and What to Ask", "author": "Bilal Ghanem et.al.", "abstract": "Reading is integral to everyday life, and yet learning to read is a struggle for many young learners. During lessons, teachers can use comprehension questions to increase engagement, test reading skills, and improve retention. Historically such questions were written by skilled teachers, but recently language models have been used to generate comprehension questions. However, many existing Question Generation (QG) systems focus on generating literal questions from the text, and have no way to control the type of the generated question. In this paper, we study QG for reading comprehension where inferential questions are critical and extractive techniques cannot be used. We propose a two-step model (HTA-WTA) that takes advantage of previous datasets, and can generate questions for a specific targeted comprehension skill. We propose a new reading comprehension dataset that contains questions annotated with story-based reading comprehension skills (SBRCS), allowing for a more complete reader assessment. Across several experiments, our results show that HTA-WTA outperforms multiple strong baselines on this new dataset. We show that the HTA-WTA model tests for strong SCRS by asking deep inferential questions.", "paper_url": "http://arxiv.org/abs/2204.02908v1", "pdf_url": "http://arxiv.org/pdf/2204.02908v1", "repo_url": null}, "2204.02906": {"publish_time": "2022-04-06", "title": "Knowledge Base Index Compression via Dimensionality and Precision Reduction", "author": "Vil\u00e9m Zouhar et.al.", "abstract": "Recently neural network based approaches to knowledge-intensive NLP tasks, such as question answering, started to rely heavily on the combination of neural retrievers and readers. Retrieval is typically performed over a large textual knowledge base (KB) which requires significant memory and compute resources, especially when scaled up. On HotpotQA we systematically investigate reducing the size of the KB index by means of dimensionality (sparse random projections, PCA, autoencoders) and numerical precision reduction.   Our results show that PCA is an easy solution that requires very little data and is only slightly worse than autoencoders, which are less stable. All methods are sensitive to pre- and post-processing and data should always be centered and normalized both before and after dimension reduction. Finally, we show that it is possible to combine PCA with using 1bit per dimension. Overall we achieve (1) 100$\\times$ compression with 75%, and (2) 24$\\times$ compression with 92% original retrieval performance.", "paper_url": "http://arxiv.org/abs/2204.02906v1", "pdf_url": "http://arxiv.org/pdf/2204.02906v1", "repo_url": null}, "2204.03637": {"publish_time": "2022-04-07", "title": "tmVar 3.0: an improved variant concept recognition and normalization tool", "author": "Chih-Hsuan Wei et.al.", "abstract": "Previous studies have shown that automated text-mining tools are becoming increasingly important for successfully unlocking variant information in scientific literature at large scale. Despite multiple attempts in the past, existing tools are still of limited recognition scope and precision. We propose tmVar 3.0: an improved variant recognition and normalization tool. Compared to its predecessors, tmVar 3.0 is able to recognize a wide spectrum of variant related entities (e.g., allele and copy number variants), and to group different variant mentions belonging to the same concept in an article for improved accuracy. Moreover, tmVar3 provides additional variant normalization options such as allele-specific identifiers from the ClinGen Allele Registry. tmVar3 exhibits a state-of-the-art performance with over 90% accuracy in F-measure in variant recognition and normalization, when evaluated on three independent benchmarking datasets. tmVar3 is freely available for download. We have also processed the entire PubMed and PMC with tmVar3 and released its annotations on our FTP. Availability: ftp://ftp.ncbi.nlm.nih.gov/pub/lu/tmVar3", "paper_url": "http://arxiv.org/abs/2204.03637v1", "pdf_url": "http://arxiv.org/pdf/2204.03637v1", "repo_url": null}, "2204.03619": {"publish_time": "2022-04-07", "title": "Modeling Label Correlations for Second-Order Semantic Dependency Parsing with Mean-Field Inference", "author": "Songlin Yang et.al.", "abstract": "Second-order semantic parsing with end-to-end mean-field inference has been shown good performance. In this work we aim to improve this method by modeling label correlations between adjacent arcs. However, direct modeling leads to memory explosion because second-order score tensors have sizes of $O(n^3L^2)$ ($n$ is the sentence length and $L$ is the number of labels), which is not affordable. To tackle this computational challenge, we leverage tensor decomposition techniques, and interestingly, we show that the large second-order score tensors have no need to be materialized during mean-field inference, thereby reducing the computational complexity from cubic to quadratic. We conduct experiments on SemEval 2015 Task 18 English datasets, showing the effectiveness of modeling label correlations. Our code is publicly available at https://github.com/sustcsonglin/mean-field-dep-parsing.", "paper_url": "http://arxiv.org/abs/2204.03619v1", "pdf_url": "http://arxiv.org/pdf/2204.03619v1", "repo_url": null}, "2204.03592": {"publish_time": "2022-04-07", "title": "Testing the limits of natural language models for predicting human language judgments", "author": "Tal Golan et.al.", "abstract": "Neural network language models can serve as computational hypotheses about how humans process language. We compared the model-human consistency of diverse language models using a novel experimental approach: controversial sentence pairs. For each controversial sentence pair, two language models disagree about which sentence is more likely to occur in natural text. Considering nine language models (including n-gram, recurrent neural networks, and transformer models), we created hundreds of such controversial sentence pairs by either selecting sentences from a corpus or synthetically optimizing sentence pairs to be highly controversial. Human subjects then provided judgments indicating for each pair which of the two sentences is more likely. Controversial sentence pairs proved highly effective at revealing model failures and identifying models that aligned most closely with human judgments. The most human-consistent model tested was GPT-2, although experiments also revealed significant shortcomings of its alignment with human perception.", "paper_url": "http://arxiv.org/abs/2204.03592v1", "pdf_url": "http://arxiv.org/pdf/2204.03592v1", "repo_url": "https://github.com/dpmlab/contstimlang"}, "2204.03574": {"publish_time": "2022-04-07", "title": "Learning to Compose Soft Prompts for Compositional Zero-Shot Learning", "author": "Nihal V. Nayak et.al.", "abstract": "We introduce compositional soft prompting (CSP), a parameter-efficient learning technique to improve the zero-shot compositionality of large-scale pretrained vision-language models (VLMs) without the overhead of fine-tuning the entire model. VLMs can represent arbitrary classes as natural language prompts in their flexible text encoders but they underperform state-of-the-art methods on compositional zero-shot benchmark tasks. To improve VLMs, we propose a novel form of soft prompting. We treat the attributes and objects that are composed to define classes as learnable tokens of vocabulary and tune them on multiple prompt compositions. During inference, we recompose the learned attribute-object vocabulary in new combinations and show that CSP outperforms the original VLM on benchmark datasets by an average of 14.7 percentage points of accuracy. CSP also achieves new state-of-the-art accuracies on two out of three benchmark datasets, while only fine-tuning a small number of parameters. Further, we show that CSP improves generalization to higher-order attribute-attribute-object compositions and combinations of pretrained attributes and fine-tuned objects.", "paper_url": "http://arxiv.org/abs/2204.03574v1", "pdf_url": "http://arxiv.org/pdf/2204.03574v1", "repo_url": "https://github.com/batsresearch/csp"}, "2204.03558": {"publish_time": "2022-04-07", "title": "Mapping the Multilingual Margins: Intersectional Biases of Sentiment Analysis Systems in English, Spanish, and Arabic", "author": "Ant\u00f3nio C\u00e2mara et.al.", "abstract": "As natural language processing systems become more widespread, it is necessary to address fairness issues in their implementation and deployment to ensure that their negative impacts on society are understood and minimized. However, there is limited work that studies fairness using a multilingual and intersectional framework or on downstream tasks. In this paper, we introduce four multilingual Equity Evaluation Corpora, supplementary test sets designed to measure social biases, and a novel statistical framework for studying unisectional and intersectional social biases in natural language processing. We use these tools to measure gender, racial, ethnic, and intersectional social biases across five models trained on emotion regression tasks in English, Spanish, and Arabic. We find that many systems demonstrate statistically significant unisectional and intersectional social biases.", "paper_url": "http://arxiv.org/abs/2204.03558v1", "pdf_url": "http://arxiv.org/pdf/2204.03558v1", "repo_url": null}, "2204.04179": {"publish_time": "2022-04-08", "title": "GRAM: Fast Fine-tuning of Pre-trained Language Models for Content-based Collaborative Filtering", "author": "Yoonseok Yang et.al.", "abstract": "Content-based collaborative filtering (CCF) provides personalized item recommendations based on both users' interaction history and items' content information. Recently, pre-trained language models (PLM) have been used to extract high-quality item encodings for CCF. However, it is resource-intensive to finetune PLM in an end-to-end (E2E) manner in CCF due to its multi-modal nature: optimization involves redundant content encoding for interactions from users. For this, we propose GRAM (GRadient Accumulation for Multi-modality): (1) Single-step GRAM which aggregates gradients for each item while maintaining theoretical equivalence with E2E, and (2) Multi-step GRAM which further accumulates gradients across multiple training steps, with less than 40\\% GPU memory footprint of E2E. We empirically confirm that GRAM achieves a remarkable boost in training efficiency based on five datasets from two task domains of Knowledge Tracing and News Recommendation, where single-step and multi-step GRAM achieve 4x and 45x training speedup on average, respectively.", "paper_url": "http://arxiv.org/abs/2204.04179v1", "pdf_url": "http://arxiv.org/pdf/2204.04179v1", "repo_url": null}, "2204.04163": {"publish_time": "2022-04-08", "title": "Contextual Representation Learning beyond Masked Language Modeling", "author": "Zhiyi Fu et.al.", "abstract": "How do masked language models (MLMs) such as BERT learn contextual representations? In this work, we analyze the learning dynamics of MLMs. We find that MLMs adopt sampled embeddings as anchors to estimate and inject contextual semantics to representations, which limits the efficiency and effectiveness of MLMs. To address these issues, we propose TACO, a simple yet effective representation learning approach to directly model global semantics. TACO extracts and aligns contextual semantics hidden in contextualized representations to encourage models to attend global semantics when generating contextualized representations. Experiments on the GLUE benchmark show that TACO achieves up to 5x speedup and up to 1.2 points average improvement over existing MLMs. The code is available at https://github.com/FUZHIYI/TACO.", "paper_url": "http://arxiv.org/abs/2204.04163v1", "pdf_url": "http://arxiv.org/pdf/2204.04163v1", "repo_url": null}, "2204.04080": {"publish_time": "2022-04-08", "title": "Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese", "author": "Chenxuan Cui et.al.", "abstract": "Coordinate compounds (CCs) and elaborate expressions (EEs) are coordinate constructions common in languages of East and Southeast Asia. Mortensen (2006) claims that (1) the linear ordering of EEs and CCs in Hmong, Lahu, and Chinese can be predicted via phonological hierarchies and (2) these phonological hierarchies lack a clear phonetic rationale. These claims are significant because morphosyntax has often been seen as in a feed-forward relationship with phonology, and phonological generalizations have often been assumed to be phonetically \"natural\". We investigate whether the ordering of CCs and EEs can be learned empirically and whether computational models (classifiers and sequence labeling models) learn unnatural hierarchies similar to those posited by Mortensen (2006). We find that decision trees and SVMs learn to predict the order of CCs/EEs on the basis of phonology, with DTs learning hierarchies strikingly similar to those proposed by Mortensen. However, we also find that a neural sequence labeling model is able to learn the ordering of elaborate expressions in Hmong very effectively without using any phonological information. We argue that EE ordering can be learned through two independent routes: phonology and lexical distribution, presenting a more nuanced picture than previous work. [ISO 639-3:hmn, lhu, cmn]", "paper_url": "http://arxiv.org/abs/2204.04080v1", "pdf_url": "http://arxiv.org/pdf/2204.04080v1", "repo_url": null}, "2204.04058": {"publish_time": "2022-04-08", "title": "Improving Tokenisation by Alternative Treatment of Spaces", "author": "Edward Gow-Smith et.al.", "abstract": "Tokenisation is the first step in almost all NLP tasks, and state-of-the-art transformer-based language models all use subword tokenisation algorithms to process input text. Existing algorithms have problems, often producing tokenisations of limited linguistic validity, and representing equivalent strings differently depending on their position within a word. We hypothesise that these problems hinder the ability of transformer-based models to handle complex words, and suggest that these problems are a result of allowing tokens to include spaces. We thus experiment with an alternative tokenisation approach where spaces are always treated as individual tokens. Specifically, we apply this modification to the BPE and Unigram algorithms. We find that our modified algorithms lead to improved performance on downstream NLP tasks that involve handling complex words, whilst having no detrimental effect on performance in general natural language understanding tasks. Intrinsically, we find our modified algorithms give more morphologically correct tokenisations, in particular when handling prefixes. Given the results of our experiments, we advocate for always treating spaces as individual tokens as an improved tokenisation method.", "paper_url": "http://arxiv.org/abs/2204.04058v1", "pdf_url": "http://arxiv.org/pdf/2204.04058v1", "repo_url": "https://github.com/edwardgowsmith/improved-tokenisation-methods"}, "2204.04043": {"publish_time": "2022-04-08", "title": "C-NMT: A Collaborative Inference Framework for Neural Machine Translation", "author": "Yukai Chen et.al.", "abstract": "Collaborative Inference (CI) optimizes the latency and energy consumption of deep learning inference through the inter-operation of edge and cloud devices. Albeit beneficial for other tasks, CI has never been applied to the sequence- to-sequence mapping problem at the heart of Neural Machine Translation (NMT). In this work, we address the specific issues of collaborative NMT, such as estimating the latency required to generate the (unknown) output sequence, and show how existing CI methods can be adapted to these applications. Our experiments show that CI can reduce the latency of NMT by up to 44% compared to a non-collaborative approach.", "paper_url": "http://arxiv.org/abs/2204.04043v1", "pdf_url": "http://arxiv.org/pdf/2204.04043v1", "repo_url": null}, "2204.05307": {"publish_time": "2022-04-11", "title": "Toward More Effective Human Evaluation for Machine Translation", "author": "Bel\u00e9n Sald\u00edas et.al.", "abstract": "Improvements in text generation technologies such as machine translation have necessitated more costly and time-consuming human evaluation procedures to ensure an accurate signal. We investigate a simple way to reduce cost by reducing the number of text segments that must be annotated in order to accurately predict a score for a complete test set. Using a sampling approach, we demonstrate that information from document membership and automatic metrics can help improve estimates compared to a pure random sampling baseline. We achieve gains of up to 20% in average absolute error by leveraging stratified sampling and control variates. Our techniques can improve estimates made from a fixed annotation budget, are easy to implement, and can be applied to any problem with structure similar to the one we study.", "paper_url": "http://arxiv.org/abs/2204.05307v1", "pdf_url": "http://arxiv.org/pdf/2204.05307v1", "repo_url": null}, "2204.05248": {"publish_time": "2022-04-11", "title": "Learning Downstream Task by Selectively Capturing Complementary Knowledge from Multiple Self-supervisedly Learning Pretexts", "author": "Quan Feng et.al.", "abstract": "Self-supervised learning (SSL), as a newly emerging unsupervised representation learning paradigm, generally follows a two-stage learning pipeline: 1) learning invariant and discriminative representations with auto-annotation pretext(s), then 2) transferring the representations to assist downstream task(s). Such two stages are usually implemented separately, making the learned representation learned agnostic to the downstream tasks. Currently, most works are devoted to exploring the first stage. Whereas, it is less studied on how to learn downstream tasks with limited labeled data using the already learned representations. Especially, it is crucial and challenging to selectively utilize the complementary representations from diverse pretexts for a downstream task. In this paper, we technically propose a novel solution by leveraging the attention mechanism to adaptively squeeze suitable representations for the tasks. Meanwhile, resorting to information theory, we theoretically prove that gathering representation from diverse pretexts is more effective than a single one. Extensive experiments validate that our scheme significantly exceeds current popular pretext-matching based methods in gathering knowledge and relieving negative transfer in downstream tasks.", "paper_url": "http://arxiv.org/abs/2204.05248v1", "pdf_url": "http://arxiv.org/pdf/2204.05248v1", "repo_url": null}, "2204.05239": {"publish_time": "2022-04-11", "title": "Exploring the Universal Vulnerability of Prompt-based Learning Paradigm", "author": "Lei Xu et.al.", "abstract": "Prompt-based learning paradigm bridges the gap between pre-training and fine-tuning, and works effectively under the few-shot setting. However, we find that this learning paradigm inherits the vulnerability from the pre-training stage, where model predictions can be misled by inserting certain triggers into the text. In this paper, we explore this universal vulnerability by either injecting backdoor triggers or searching for adversarial triggers on pre-trained language models using only plain text. In both scenarios, we demonstrate that our triggers can totally control or severely decrease the performance of prompt-based models fine-tuned on arbitrary downstream tasks, reflecting the universal vulnerability of the prompt-based learning paradigm. Further experiments show that adversarial triggers have good transferability among language models. We also find conventional fine-tuning models are not vulnerable to adversarial triggers constructed from pre-trained language models. We conclude by proposing a potential solution to mitigate our attack methods. Code and data are publicly available at https://github.com/leix28/prompt-universal-vulnerability", "paper_url": "http://arxiv.org/abs/2204.05239v1", "pdf_url": "http://arxiv.org/pdf/2204.05239v1", "repo_url": "https://github.com/leix28/prompt-universal-vulnerability"}, "2204.05232": {"publish_time": "2022-04-11", "title": "Survey of Aspect-based Sentiment Analysis Datasets", "author": "Siva Uday Sampreeth Chebolu et.al.", "abstract": "Aspect-based sentiment analysis (ABSA) is a natural language processing problem that requires analyzing user-generated reviews in order to determine: a) The target entity being reviewed, b) The high-level aspect to which it belongs, and c) The sentiment expressed toward the targets and the aspects. Numerous yet scattered corpora for ABSA make it difficult for researchers to quickly identify corpora best suited for a specific ABSA subtask. This study aims to present a database of corpora that can be used to train and assess autonomous ABSA systems. Additionally, we provide an overview of the major corpora concerning the various ABSA and its subtasks and highlight several corpus features that researchers should consider when selecting a corpus. We conclude that further large-scale ABSA corpora are required. Additionally, because each corpus is constructed differently, it is time-consuming for researchers to experiment with a novel ABSA algorithm on many corpora and often employ just one or a few corpora. The field would benefit from an agreement on a data standard for ABSA corpora. Finally, we discuss the advantages and disadvantages of current collection approaches and make recommendations for future ABSA dataset gathering.", "paper_url": "http://arxiv.org/abs/2204.05232v1", "pdf_url": "http://arxiv.org/pdf/2204.05232v1", "repo_url": null}, "2204.05231": {"publish_time": "2022-04-11", "title": "Towards Generalizeable Semantic Product Search by Text Similarity Pre-training on Search Click Logs", "author": "Zheng Liu et.al.", "abstract": "Recently, semantic search has been successfully applied to e-commerce product search and the learned semantic space(s) for query and product encoding are expected to generalize to unseen queries or products. Yet, whether generalization can conveniently emerge has not been thoroughly studied in the domain thus far. In this paper, we examine several general-domain and domain-specific pre-trained Roberta variants and discover that general-domain fine-tuning does not help generalization, which aligns with the discovery of prior art. Proper domain-specific fine-tuning with clickstream data can lead to better model generalization, based on a bucketed analysis of a publicly available manual annotated query-product pair data.", "paper_url": "http://arxiv.org/abs/2204.05231v1", "pdf_url": "http://arxiv.org/pdf/2204.05231v1", "repo_url": null}, "2204.05991": {"publish_time": "2022-04-12", "title": "ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension", "author": "Sanjay Subramanian et.al.", "abstract": "Training a referring expression comprehension (ReC) model for a new visual domain requires collecting referring expressions, and potentially corresponding bounding boxes, for images in the domain. While large-scale pre-trained models are useful for image classification across domains, it remains unclear if they can be applied in a zero-shot manner to more complex tasks like ReC. We present ReCLIP, a simple but strong zero-shot baseline that repurposes CLIP, a state-of-the-art large-scale model, for ReC. Motivated by the close connection between ReC and CLIP's contrastive pre-training objective, the first component of ReCLIP is a region-scoring method that isolates object proposals via cropping and blurring, and passes them to CLIP. However, through controlled experiments on a synthetic dataset, we find that CLIP is largely incapable of performing spatial reasoning off-the-shelf. Thus, the second component of ReCLIP is a spatial relation resolver that handles several types of spatial relations. We reduce the gap between zero-shot baselines from prior work and supervised models by as much as 29% on RefCOCOg, and on RefGTA (video game imagery), ReCLIP's relative improvement over supervised ReC models trained on real images is 8%.", "paper_url": "http://arxiv.org/abs/2204.05991v1", "pdf_url": "http://arxiv.org/pdf/2204.05991v1", "repo_url": "https://github.com/allenai/reclip"}, "2204.05990": {"publish_time": "2022-04-12", "title": "Detection, Disambiguation, Re-ranking: Autoregressive Entity Linking as a Multi-Task Problem", "author": "Khalil Mrini et.al.", "abstract": "We propose an autoregressive entity linking model, that is trained with two auxiliary tasks, and learns to re-rank generated samples at inference time. Our proposed novelties address two weaknesses in the literature. First, a recent method proposes to learn mention detection and then entity candidate selection, but relies on predefined sets of candidates. We use encoder-decoder autoregressive entity linking in order to bypass this need, and propose to train mention detection as an auxiliary task instead. Second, previous work suggests that re-ranking could help correct prediction errors. We add a new, auxiliary task, match prediction, to learn re-ranking. Without the use of a knowledge base or candidate sets, our model sets a new state of the art in two benchmark datasets of entity linking: COMETA in the biomedical domain, and AIDA-CoNLL in the news domain. We show through ablation studies that each of the two auxiliary tasks increases performance, and that re-ranking is an important factor to the increase. Finally, our low-resource experimental results suggest that performance on the main task benefits from the knowledge learned by the auxiliary tasks, and not just from the additional training data.", "paper_url": "http://arxiv.org/abs/2204.05990v1", "pdf_url": "http://arxiv.org/pdf/2204.05990v1", "repo_url": null}, "2204.05961": {"publish_time": "2022-04-12", "title": "Quantified Reproducibility Assessment of NLP Results", "author": "Anya Belz et.al.", "abstract": "This paper describes and tests a method for carrying out quantified reproducibility assessment (QRA) that is based on concepts and definitions from metrology. QRA produces a single score estimating the degree of reproducibility of a given system and evaluation measure, on the basis of the scores from, and differences between, different reproductions. We test QRA on 18 system and evaluation measure combinations (involving diverse NLP tasks and types of evaluation), for each of which we have the original results and one to seven reproduction results. The proposed QRA method produces degree-of-reproducibility scores that are comparable across multiple reproductions not only of the same, but of different original studies. We find that the proposed method facilitates insights into causes of variation between reproductions, and allows conclusions to be drawn about what changes to system and/or evaluation design might lead to improved reproducibility.", "paper_url": "http://arxiv.org/abs/2204.05961v1", "pdf_url": "http://arxiv.org/pdf/2204.05961v1", "repo_url": null}, "2204.05953": {"publish_time": "2022-04-12", "title": "Explore More Guidance: A Task-aware Instruction Network for Sign Language Translation Enhanced with Data Augmentation", "author": "Yong Cao et.al.", "abstract": "Sign language recognition and translation first uses a recognition module to generate glosses from sign language videos and then employs a translation module to translate glosses into spoken sentences. Most existing works focus on the recognition step, while paying less attention to sign language translation. In this work, we propose a task-aware instruction network, namely TIN-SLT, for sign language translation, by introducing the instruction module and the learning-based feature fuse strategy into a Transformer network. In this way, the pre-trained model's language ability can be well explored and utilized to further boost the translation performance. Moreover, by exploring the representation space of sign language glosses and target spoken language, we propose a multi-level data augmentation scheme to adjust the data distribution of the training set. We conduct extensive experiments on two challenging benchmark datasets, PHOENIX-2014-T and ASLG-PC12, on which our method outperforms former best solutions by 1.65 and 1.42 in terms of BLEU-4. Our code is published at https://github.com/yongcaoplus/TIN-SLT.", "paper_url": "http://arxiv.org/abs/2204.05953v1", "pdf_url": "http://arxiv.org/pdf/2204.05953v1", "repo_url": "https://github.com/yongcaoplus/tin-slt"}, "2204.05939": {"publish_time": "2022-04-12", "title": "Mining Logical Event Schemas From Pre-Trained Language Models", "author": "Lane Lawley et.al.", "abstract": "We present NESL (the Neuro-Episodic Schema Learner), an event schema learning system that combines large language models, FrameNet parsing, a powerful logical representation of language, and a set of simple behavioral schemas meant to bootstrap the learning process. In lieu of a pre-made corpus of stories, our dataset is a continuous feed of \"situation samples\" from a pre-trained language model, which are then parsed into FrameNet frames, mapped into simple behavioral schemas, and combined and generalized into complex, hierarchical schemas for a variety of everyday scenarios. We show that careful sampling from the language model can help emphasize stereotypical properties of situations and de-emphasize irrelevant details, and that the resulting schemas specify situations more comprehensively than those learned by other systems.", "paper_url": "http://arxiv.org/abs/2204.05939v1", "pdf_url": "http://arxiv.org/pdf/2204.05939v1", "repo_url": null}, "2204.06555": {"publish_time": "2022-04-13", "title": "Fast Few-shot Debugging for NLU Test Suites", "author": "Christopher Malon et.al.", "abstract": "We study few-shot debugging of transformer based natural language understanding models, using recently popularized test suites to not just diagnose but correct a problem. Given a few debugging examples of a certain phenomenon, and a held-out test set of the same phenomenon, we aim to maximize accuracy on the phenomenon at a minimal cost of accuracy on the original test set. We examine several methods that are faster than full epoch retraining. We introduce a new fast method, which samples a few in-danger examples from the original training set. Compared to fast methods using parameter distance constraints or Kullback-Leibler divergence, we achieve superior original accuracy for comparable debugging accuracy.", "paper_url": "http://arxiv.org/abs/2204.06555v1", "pdf_url": "http://arxiv.org/pdf/2204.06555v1", "repo_url": "https://github.com/necla-ml/debug-test-suites"}, "2204.06546": {"publish_time": "2022-04-13", "title": "Better Uncertainty Quantification for Machine Translation Evaluation", "author": "Chrysoula Zerva et.al.", "abstract": "Neural-based machine translation (MT) evaluation metrics are progressing fast. However, these systems are often hard to interpret and might produce unreliable scores when human references or assessments are noisy or when data is out-of-domain. Recent work leveraged uncertainty quantification techniques such as Monte Carlo dropout and deep ensembles to provide confidence intervals, but these techniques (as we show) are limited in several ways. In this paper we investigate more powerful and efficient uncertainty predictors for MT evaluation metrics and their potential to capture aleatoric and epistemic uncertainty. To this end we train the COMET metric with new heteroscedastic regression, divergence minimization, and direct uncertainty prediction objectives. Our experiments show improved results on WMT20 and WMT21 metrics task datasets and a substantial reduction in computational costs. Moreover, they demonstrate the ability of our predictors to identify low quality references and to reveal model uncertainty due to out-of-domain data.", "paper_url": "http://arxiv.org/abs/2204.06546v1", "pdf_url": "http://arxiv.org/pdf/2204.06546v1", "repo_url": null}, "2204.06535": {"publish_time": "2022-04-13", "title": "Multilingual Event Linking to Wikidata", "author": "Adithya Pratapa et.al.", "abstract": "We present a task of multilingual linking of events to a knowledge base. We automatically compile a large-scale dataset for this task, comprising of 1.8M mentions across 44 languages referring to over 10.9K events from Wikidata. We propose two variants of the event linking task: 1) multilingual, where event descriptions are from the same language as the mention, and 2) crosslingual, where all event descriptions are in English. On the two proposed tasks, we compare multiple event linking systems including BM25+ (Lv and Zhai, 2011) and multilingual adaptations of the biencoder and crossencoder architectures from BLINK (Wu et al., 2020). In our experiments on the two task variants, we find both biencoder and crossencoder models significantly outperform the BM25+ baseline. Our results also indicate that the crosslingual task is in general more challenging than the multilingual task. To test the out-of-domain generalization of the proposed linking systems, we additionally create a Wikinews-based evaluation set. We present qualitative analysis highlighting various aspects captured by the proposed dataset, including the need for temporal reasoning over context and tackling diverse event descriptions across languages.", "paper_url": "http://arxiv.org/abs/2204.06535v1", "pdf_url": "http://arxiv.org/pdf/2204.06535v1", "repo_url": null}, "2204.06514": {"publish_time": "2022-04-13", "title": "Scalable Training of Language Models using JAX pjit and TPUv4", "author": "Joanna Yoo et.al.", "abstract": "Modern large language models require distributed training strategies due to their size. The challenges of efficiently and robustly training them are met with rapid developments on both software and hardware frontiers. In this technical report, we explore challenges and design decisions associated with developing a scalable training framework, and present a quantitative analysis of efficiency improvements coming from adopting new software and hardware solutions.", "paper_url": "http://arxiv.org/abs/2204.06514v1", "pdf_url": "http://arxiv.org/pdf/2204.06514v1", "repo_url": null}, "2204.06508": {"publish_time": "2022-04-13", "title": "FactGraph: Evaluating Factuality in Summarization with Semantic Graph Representations", "author": "Leonardo F. R. Ribeiro et.al.", "abstract": "Despite recent improvements in abstractive summarization, most current approaches generate summaries that are not factually consistent with the source document, severely restricting their trust and usage in real-world applications. Recent works have shown promising improvements in factuality error identification using text or dependency arc entailments; however, they do not consider the entire semantic graph simultaneously. To this end, we propose FactGraph, a method that decomposes the document and the summary into structured meaning representations (MR), which are more suitable for factuality evaluation. MRs describe core semantic concepts and their relations, aggregating the main content in both document and summary in a canonical form, and reducing data sparsity. FactGraph encodes such graphs using a graph encoder augmented with structure-aware adapters to capture interactions among the concepts based on the graph connectivity, along with text representations using an adapter-based text encoder. Experiments on different benchmarks for evaluating factuality show that FactGraph outperforms previous approaches by up to 15%. Furthermore, FactGraph improves performance on identifying content verifiability errors and better captures subsentence-level factual inconsistencies.", "paper_url": "http://arxiv.org/abs/2204.06508v1", "pdf_url": "http://arxiv.org/pdf/2204.06508v1", "repo_url": null}, "2204.07150": {"publish_time": "2022-04-14", "title": "FREDA: Flexible Relation Extraction Data Annotation", "author": "Michael Strobl et.al.", "abstract": "To effectively train accurate Relation Extraction models, sufficient and properly labeled data is required. Adequately labeled data is difficult to obtain and annotating such data is a tricky undertaking. Previous works have shown that either accuracy has to be sacrificed or the task is extremely time-consuming, if done accurately. We are proposing an approach in order to produce high-quality datasets for the task of Relation Extraction quickly. Neural models, trained to do Relation Extraction on the created datasets, achieve very good results and generalize well to other datasets. In our study, we were able to annotate 10,022 sentences for 19 relations in a reasonable amount of time, and trained a commonly used baseline model for each relation.", "paper_url": "http://arxiv.org/abs/2204.07150v1", "pdf_url": "http://arxiv.org/pdf/2204.07150v1", "repo_url": null}, "2204.07142": {"publish_time": "2022-04-14", "title": "CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations", "author": "Rakesh R Menon et.al.", "abstract": "Supervised learning has traditionally focused on inductive learning by observing labeled examples of a task. In contrast, humans have the ability to learn new concepts from language. Here, we explore training zero-shot classifiers for structured data purely from language. For this, we introduce CLUES, a benchmark for Classifier Learning Using natural language ExplanationS, consisting of a range of classification tasks over structured data along with natural language supervision in the form of explanations. CLUES consists of 36 real-world and 144 synthetic classification tasks. It contains crowdsourced explanations describing real-world tasks from multiple teachers and programmatically generated explanations for the synthetic tasks. To model the influence of explanations in classifying an example, we develop ExEnt, an entailment-based model that learns classifiers using explanations. ExEnt generalizes up to 18% better (relative) on novel tasks than a baseline that does not use explanations. We delineate key challenges for automated learning from explanations, addressing which can lead to progress on CLUES in the future. Code and datasets are available at: https://clues-benchmark.github.io.", "paper_url": "http://arxiv.org/abs/2204.07142v1", "pdf_url": "http://arxiv.org/pdf/2204.07142v1", "repo_url": null}, "2204.07135": {"publish_time": "2022-04-14", "title": "Scalable and Robust Self-Learning for Skill Routing in Large-Scale Conversational AI Systems", "author": "Mohammad Kachuee et.al.", "abstract": "Skill routing is an important component in large-scale conversational systems. In contrast to traditional rule-based skill routing, state-of-the-art systems use a model-based approach to enable natural conversations. To provide supervision signal required to train such models, ideas such as human annotation, replication of a rule-based system, relabeling based on user paraphrases, and bandit-based learning were suggested. However, these approaches: (a) do not scale in terms of the number of skills and skill on-boarding, (b) require a very costly expert annotation/rule-design, (c) introduce risks in the user experience with each model update. In this paper, we present a scalable self-learning approach to explore routing alternatives without causing abrupt policy changes that break the user experience, learn from the user interaction, and incrementally improve the routing via frequent model refreshes. To enable such robust frequent model updates, we suggest a simple and effective approach that ensures controlled policy updates for individual domains, followed by an off-policy evaluation for making deployment decisions without any need for lengthy A/B experimentation. We conduct various offline and online A/B experiments on a commercial large-scale conversational system to demonstrate the effectiveness of the proposed method in real-world production settings.", "paper_url": "http://arxiv.org/abs/2204.07135v1", "pdf_url": "http://arxiv.org/pdf/2204.07135v1", "repo_url": null}, "2204.07128": {"publish_time": "2022-04-14", "title": "Label Semantic Aware Pre-training for Few-shot Text Classification", "author": "Aaron Mueller et.al.", "abstract": "In text classification tasks, useful information is encoded in the label names. Label semantic aware systems have leveraged this information for improved text classification performance during fine-tuning and prediction. However, use of label-semantics during pre-training has not been extensively explored. We therefore propose Label Semantic Aware Pre-training (LSAP) to improve the generalization and data efficiency of text classification systems. LSAP incorporates label semantics into pre-trained generative models (T5 in our case) by performing secondary pre-training on labeled sentences from a variety of domains. As domain-general pre-training requires large amounts of data, we develop a filtering and labeling pipeline to automatically create sentence-label pairs from unlabeled text. We perform experiments on intent (ATIS, Snips, TOPv2) and topic classification (AG News, Yahoo! Answers). LSAP obtains significant accuracy improvements over state-of-the-art models for few-shot text classification while maintaining performance comparable to state of the art in high-resource settings.", "paper_url": "http://arxiv.org/abs/2204.07128v1", "pdf_url": "http://arxiv.org/pdf/2204.07128v1", "repo_url": null}, "2204.07120": {"publish_time": "2022-04-14", "title": "Exploring Dual Encoder Architectures for Question Answering", "author": "Zhe Dong et.al.", "abstract": "Dual encoders have been used for question-answering (QA) and information retrieval (IR) tasks with good results. There are two major types of dual encoders, Siamese Dual Encoders (SDE), with parameters shared across two encoders, and Asymmetric Dual Encoder (ADE), with two distinctly parameterized encoders. In this work, we explore the dual encoder architectures for QA retrieval tasks. By evaluating on MS MARCO and the MultiReQA benchmark, we show that SDE performs significantly better than ADE. We further propose three different improved versions of ADEs. Based on the evaluation of QA retrieval tasks and direct analysis of the embeddings, we demonstrate that sharing parameters in projection layers would enable ADEs to perform competitively with SDEs.", "paper_url": "http://arxiv.org/abs/2204.07120v1", "pdf_url": "http://arxiv.org/pdf/2204.07120v1", "repo_url": null}, "2204.07571": {"publish_time": "2022-04-15", "title": "Evaluation Benchmarks for Spanish Sentence Representations", "author": "Vladimir Araujo et.al.", "abstract": "Due to the success of pre-trained language models, versions of languages other than English have been released in recent years. This fact implies the need for resources to evaluate these models. In the case of Spanish, there are few ways to systematically assess the models' quality. In this paper, we narrow the gap by building two evaluation benchmarks. Inspired by previous work (Conneau and Kiela, 2018; Chen et al., 2019), we introduce Spanish SentEval and Spanish DiscoEval, aiming to assess the capabilities of stand-alone and discourse-aware sentence representations, respectively. Our benchmarks include considerable pre-existing and newly constructed datasets that address different tasks from various domains. In addition, we evaluate and analyze the most recent pre-trained Spanish language models to exhibit their capabilities and limitations. As an example, we discover that for the case of discourse evaluation tasks, mBERT, a language model trained on multiple languages, usually provides a richer latent representation than models trained only with documents in Spanish. We hope our contribution will motivate a fairer, more comparable, and less cumbersome way to evaluate future Spanish language models.", "paper_url": "http://arxiv.org/abs/2204.07571v1", "pdf_url": "http://arxiv.org/pdf/2204.07571v1", "repo_url": null}, "2204.07562": {"publish_time": "2022-04-15", "title": "Evaluating Factuality in Text Simplification", "author": "Ashwin Devaraj et.al.", "abstract": "Automated simplification models aim to make input texts more readable. Such methods have the potential to make complex information accessible to a wider audience, e.g., providing access to recent medical literature which might otherwise be impenetrable for a lay reader. However, such models risk introducing errors into automatically simplified texts, for instance by inserting statements unsupported by the corresponding original text, or by omitting key information. Providing more readable but inaccurate versions of texts may in many cases be worse than providing no such access at all. The problem of factual accuracy (and the lack thereof) has received heightened attention in the context of summarization models, but the factuality of automatically simplified texts has not been investigated. We introduce a taxonomy of errors that we use to analyze both references drawn from standard simplification datasets and state-of-the-art model outputs. We find that errors often appear in both that are not captured by existing evaluation metrics, motivating a need for research into ensuring the factual accuracy of automated simplification models.", "paper_url": "http://arxiv.org/abs/2204.07562v1", "pdf_url": "http://arxiv.org/pdf/2204.07562v1", "repo_url": "https://github.com/ashologn/evaluating-factuality-in-text-simplification"}, "2204.07556": {"publish_time": "2022-04-15", "title": "Streaming Align-Refine for Non-autoregressive Deliberation", "author": "Weiran Wang et.al.", "abstract": "We propose a streaming non-autoregressive (non-AR) decoding algorithm to deliberate the hypothesis alignment of a streaming RNN-T model. Our algorithm facilitates a simple greedy decoding procedure, and at the same time is capable of producing the decoding result at each frame with limited right context, thus enjoying both high efficiency and low latency. These advantages are achieved by converting the offline Align-Refine algorithm to be streaming-compatible, with a novel transformer decoder architecture that performs local self-attentions for both text and audio, and a time-aligned cross-attention at each layer. Furthermore, we perform discriminative training of our model with the minimum word error rate (MWER) criterion, which has not been done in the non-AR decoding literature. Experiments on voice search datasets and Librispeech show that with reasonable right context, our streaming model performs as well as the offline counterpart, and discriminative training leads to further WER gain when the first-pass model has small capacity.", "paper_url": "http://arxiv.org/abs/2204.07556v1", "pdf_url": "http://arxiv.org/pdf/2204.07556v1", "repo_url": null}, "2204.07555": {"publish_time": "2022-04-15", "title": "Chinese Idiom Paraphrasing", "author": "Jipeng Qiang et.al.", "abstract": "Idioms, are a kind of idiomatic expression in Chinese, most of which consist of four Chinese characters. Due to the properties of non-compositionality and metaphorical meaning, Chinese Idioms are hard to be understood by children and non-native speakers. This study proposes a novel task, denoted as Chinese Idiom Paraphrasing (CIP). CIP aims to rephrase idioms-included sentences to non-idiomatic ones under the premise of preserving the original sentence's meaning. Since the sentences without idioms are easier handled by Chinese NLP systems, CIP can be used to pre-process Chinese datasets, thereby facilitating and improving the performance of Chinese NLP tasks, e.g., machine translation system, Chinese idiom cloze, and Chinese idiom embeddings. In this study, CIP task is treated as a special paraphrase generation task. To circumvent difficulties in acquiring annotations, we first establish a large-scale CIP dataset based on human and machine collaboration, which consists of 115,530 sentence pairs. We further deploy three baselines and two novel CIP approaches to deal with CIP problems. The results show that the proposed methods have better performances than the baselines based on the established CIP dataset.", "paper_url": "http://arxiv.org/abs/2204.07555v1", "pdf_url": "http://arxiv.org/pdf/2204.07555v1", "repo_url": null}, "2204.07553": {"publish_time": "2022-04-15", "title": "Improving Rare Word Recognition with LM-aware MWER Training", "author": "Weiran Wang et.al.", "abstract": "Language models (LMs) significantly improve the recognition accuracy of end-to-end (E2E) models on words rarely seen during training, when used in either the shallow fusion or the rescoring setups. In this work, we introduce LMs in the learning of hybrid autoregressive transducer (HAT) models in the discriminative training framework, to mitigate the training versus inference gap regarding the use of LMs. For the shallow fusion setup, we use LMs during both hypotheses generation and loss computation, and the LM-aware MWER-trained model achieves 10\\% relative improvement over the model trained with standard MWER on voice search test sets containing rare words. For the rescoring setup, we learn a small neural module to generate per-token fusion weights in a data-dependent manner. This model achieves the same rescoring WER as regular MWER-trained model, but without the need for sweeping fusion weights.", "paper_url": "http://arxiv.org/abs/2204.07553v1", "pdf_url": "http://arxiv.org/pdf/2204.07553v1", "repo_url": null}, "2204.08426": {"publish_time": "2022-04-18", "title": "CHAI: A CHatbot AI for Task-Oriented Dialogue with Offline Reinforcement Learning", "author": "Siddharth Verma et.al.", "abstract": "Conventionally, generation of natural language for dialogue agents may be viewed as a statistical learning problem: determine the patterns in human-provided data and generate appropriate responses with similar statistical properties. However, dialogue can also be regarded as a goal directed process, where speakers attempt to accomplish a specific task. Reinforcement learning (RL) algorithms are designed specifically for solving such goal-directed problems, but the most direct way to apply RL -- through trial-and-error learning in human conversations, -- is costly. In this paper, we study how offline reinforcement learning can instead be used to train dialogue agents entirely using static datasets collected from human speakers. Our experiments show that recently developed offline RL methods can be combined with language models to yield realistic dialogue agents that better accomplish task goals.", "paper_url": "http://arxiv.org/abs/2204.08426v1", "pdf_url": "http://arxiv.org/pdf/2204.08426v1", "repo_url": null}, "2204.08415": {"publish_time": "2022-04-18", "title": "Exploring Dimensionality Reduction Techniques in Multilingual Transformers", "author": "\u00c1lvaro Huertas-Garc\u00eda et.al.", "abstract": "Both in scientific literature and in industry,, Semantic and context-aware Natural Language Processing-based solutions have been gaining importance in recent years. The possibilities and performance shown by these models when dealing with complex Language Understanding tasks is unquestionable, from conversational agents to the fight against disinformation in social networks. In addition, considerable attention is also being paid to developing multilingual models to tackle the language bottleneck. The growing need to provide more complex models implementing all these features has been accompanied by an increase in their size, without being conservative in the number of dimensions required. This paper aims to give a comprehensive account of the impact of a wide variety of dimensional reduction techniques on the performance of different state-of-the-art multilingual Siamese Transformers, including unsupervised dimensional reduction techniques such as linear and nonlinear feature extraction, feature selection, and manifold techniques. In order to evaluate the effects of these techniques, we considered the multilingual extended version of Semantic Textual Similarity Benchmark (mSTSb) and two different baseline approaches, one using the pre-trained version of several models and another using their fine-tuned STS version. The results evidence that it is possible to achieve an average reduction in the number of dimensions of $91.58\\% \\pm 2.59\\%$ and $54.65\\% \\pm 32.20\\%$, respectively. This work has also considered the consequences of dimensionality reduction for visualization purposes. The results of this study will significantly contribute to the understanding of how different tuning approaches affect performance on semantic-aware tasks and how dimensional reduction techniques deal with the high-dimensional embeddings computed for the STS task and their potential for highly demanding NLP tasks", "paper_url": "http://arxiv.org/abs/2204.08415v1", "pdf_url": "http://arxiv.org/pdf/2204.08415v1", "repo_url": null}, "2204.08409": {"publish_time": "2022-04-18", "title": "Caption Feature Space Regularization for Audio Captioning", "author": "Yiming Zhang et.al.", "abstract": "Audio captioning aims at describing the content of audio clips with human language. Due to the ambiguity of audio, different people may perceive the same audio differently, resulting in caption disparities (i.e., one audio may correlate to several captions with diverse semantics). For that, general audio captioning models achieve the one-to-many training by randomly selecting a correlated caption as the ground truth for each audio. However, it leads to a significant variation in the optimization directions and weakens the model stability. To eliminate this negative effect, in this paper, we propose a two-stage framework for audio captioning: (i) in the first stage, via the contrastive learning, we construct a proxy feature space to reduce the distances between captions correlated to the same audio, and (ii) in the second stage, the proxy feature space is utilized as additional supervision to encourage the model to be optimized in the direction that benefits all the correlated captions. We conducted extensive experiments on two datasets using four commonly used encoder and decoder architectures. Experimental results demonstrate the effectiveness of the proposed method. The code is available at https://github.com/PRIS-CV/Caption-Feature-Space-Regularization.", "paper_url": "http://arxiv.org/abs/2204.08409v1", "pdf_url": "http://arxiv.org/pdf/2204.08409v1", "repo_url": "https://github.com/pris-cv/caption-feature-space-regularization"}, "2204.08405": {"publish_time": "2022-04-18", "title": "Zero-shot Entity and Tweet Characterization with Designed Conditional Prompts and Contexts", "author": "Sharath Srivatsa et.al.", "abstract": "Online news and social media have been the de facto mediums to disseminate information globally from the beginning of the last decade. However, bias in content and purpose of intentions are not regulated, and managing bias is the responsibility of content consumers. In this regard, understanding the stances and biases of news sources towards specific entities becomes important. To address this problem, we use pretrained language models, which have been shown to bring about good results with no task-specific training or few-shot training. In this work, we approach the problem of characterizing Named Entities and Tweets as an open-ended text classification and open-ended fact probing problem.We evaluate the zero-shot language model capabilities of Generative Pretrained Transformer 2 (GPT-2) to characterize Entities and Tweets subjectively with human psychology-inspired and logical conditional prefixes and contexts. First, we fine-tune the GPT-2 model on a sufficiently large news corpus and evaluate subjective characterization of popular entities in the corpus by priming with prefixes. Second, we fine-tune GPT-2 with a Tweets corpus from a few popular hashtags and evaluate characterizing tweets by priming the language model with prefixes, questions, and contextual synopsis prompts. Entity characterization results were positive across measures and human evaluation.", "paper_url": "http://arxiv.org/abs/2204.08405v1", "pdf_url": "http://arxiv.org/pdf/2204.08405v1", "repo_url": null}, "2204.08401": {"publish_time": "2022-04-18", "title": "TranS: Transition-based Knowledge Graph Embedding with Synthetic Relation Representation", "author": "Xuanyu Zhang et.al.", "abstract": "Knowledge graph embedding (KGE) aims to learn continuous vectors of relations and entities in knowledge graph. Recently, transition-based KGE methods have achieved promising performance, where the single relation vector learns to translate head entity to tail entity. However, this scoring pattern is not suitable for complex scenarios where the same entity pair has different relations. Previous models usually focus on the improvement of entity representation for 1-to-N, N-to-1 and N-to-N relations, but ignore the single relation vector. In this paper, we propose a novel transition-based method, TranS, for knowledge graph embedding. The single relation vector in traditional scoring patterns is replaced with synthetic relation representation, which can solve these issues effectively and efficiently. Experiments on a large knowledge graph dataset, ogbl-wikikg2, show that our model achieves state-of-the-art results.", "paper_url": "http://arxiv.org/abs/2204.08401v1", "pdf_url": "http://arxiv.org/pdf/2204.08401v1", "repo_url": null}, "2204.09028": {"publish_time": "2022-04-19", "title": "On the Locality of Attention in Direct Speech Translation", "author": "Belen Alastruey et.al.", "abstract": "Transformers have achieved state-of-the-art results across multiple NLP tasks. However, the self-attention mechanism complexity scales quadratically with the sequence length, creating an obstacle for tasks involving long sequences, like in the speech domain. In this paper, we discuss the usefulness of self-attention for Direct Speech Translation. First, we analyze the layer-wise token contributions in the self-attention of the encoder, unveiling local diagonal patterns. To prove that some attention weights are avoidable, we propose to substitute the standard self-attention with a local efficient one, setting the amount of context used based on the results of the analysis. With this approach, our model matches the baseline performance, and improves the efficiency by skipping the computation of those weights that standard attention discards.", "paper_url": "http://arxiv.org/abs/2204.09028v1", "pdf_url": "http://arxiv.org/pdf/2204.09028v1", "repo_url": null}, "2204.08997": {"publish_time": "2022-04-19", "title": "A Benchmark for Automatic Medical Consultation System: Frameworks, Tasks and Datasets", "author": "Wei Chen et.al.", "abstract": "In recent years, interest has arisen in using machine learning to improve the efficiency of automatic medical consultation and enhance patient experience. In this paper, we propose two frameworks to support automatic medical consultation, namely doctor-patient dialogue understanding and task-oriented interaction. A new large medical dialogue dataset with multi-level fine-grained annotations is introduced and five independent tasks are established, including named entity recognition, dialogue act classification, symptom label inference, medical report generation and diagnosis-oriented dialogue policy. We report a set of benchmark results for each task, which shows the usability of the dataset and sets a baseline for future studies.", "paper_url": "http://arxiv.org/abs/2204.08997v1", "pdf_url": "http://arxiv.org/pdf/2204.08997v1", "repo_url": "https://github.com/lemuria-wchen/imcs21"}, "2204.08975": {"publish_time": "2022-04-19", "title": "Detecting Text Formality: A Study of Text Classification Approaches", "author": "Daryna Dementieva et.al.", "abstract": "Formality is an important characteristic of text documents. The automatic detection of the formality level of a text is potentially beneficial for various natural language processing tasks, such as retrieval of texts with a desired formality level, integration in language learning and document editing platforms, or evaluating the desired conversation tone by chatbots. Recently two large-scale datasets were introduced for multiple languages featuring formality annotation. However, they were primarily used for the training of style transfer models. However, detection text formality on its own may also be a useful application. This work proposes the first systematic study of formality detection methods based on current (and more classic) machine learning methods and delivers the best-performing models for public usage. We conducted three types of experiments -- monolingual, multilingual, and cross-lingual. The study shows the overcome of BiLSTM-based models over transformer-based ones for the formality classification task. We release formality detection models for several languages yielding state of the art results and possessing tested cross-lingual capabilities.", "paper_url": "http://arxiv.org/abs/2204.08975v1", "pdf_url": "http://arxiv.org/pdf/2204.08975v1", "repo_url": null}, "2204.08960": {"publish_time": "2022-04-19", "title": "Building Odia Shallow Parser", "author": "Pruthwik Mishra et.al.", "abstract": "Shallow parsing is an essential task for many NLP applications like machine translation, summarization, sentiment analysis, aspect identification and many more. Quality annotated corpora is critical for building accurate shallow parsers. Many Indian languages are resource poor with respect to the availability of corpora in general. So, this paper is an attempt towards creating quality corpora for shallow parsers. The contribution of this paper is two folds: creation pos and chunk annotated corpora for Odia and development of baseline systems for pos tagging and chunking in Odia.", "paper_url": "http://arxiv.org/abs/2204.08960v1", "pdf_url": "http://arxiv.org/pdf/2204.08960v1", "repo_url": "https://github.com/pruthwik/odia-chunker"}, "2204.08952": {"publish_time": "2022-04-19", "title": "Retrieval Enhanced Data Augmentation for Question Answering on Privacy Policies", "author": "Md Rizwan Parvez et.al.", "abstract": "Prior studies in privacy policies frame the question answering (QA) tasks as identifying the most relevant text segment or a list of sentences from the policy document for a user query. However, annotating such a dataset is challenging as it requires specific domain expertise (e.g., law academics). Even if we manage a small-scale one, a bottleneck that remains is that the labeled data are heavily imbalanced (only a few segments are relevant) --limiting the gain in this domain. Therefore, in this paper, we develop a novel data augmentation framework based on ensembling retriever models that captures the relevant text segments from unlabeled policy documents and expand the positive examples in the training set. In addition, to improve the diversity and quality of the augmented data, we leverage multiple pre-trained language models (LMs) and cascaded them with noise reduction oracles. Using our augmented data on the PrivacyQA benchmark, we elevate the existing baseline by a large margin (10\\% F1) and achieve a new state-of-the-art F1 score of 50\\%. Our ablation studies provide further insights into the effectiveness of our approach.", "paper_url": "http://arxiv.org/abs/2204.08952v1", "pdf_url": "http://arxiv.org/pdf/2204.08952v1", "repo_url": null}, "2204.09667": {"publish_time": "2022-04-20", "title": "Sim-2-Sim Transfer for Vision-and-Language Navigation in Continuous Environments", "author": "Jacob Krantz et.al.", "abstract": "Recent work in Vision-and-Language Navigation (VLN) has presented two environmental paradigms with differing realism -- the standard VLN setting built on topological environments where navigation is abstracted away, and the VLN-CE setting where agents must navigate continuous 3D environments using low-level actions. Despite sharing the high-level task and even the underlying instruction-path data, performance on VLN-CE lags behind VLN significantly. In this work, we explore this gap by transferring an agent from the abstract environment of VLN to the continuous environment of VLN-CE. We find that this sim-2-sim transfer is highly effective, improving over the prior state of the art in VLN-CE by +12% success rate. While this demonstrates the potential for this direction, the transfer does not fully retain the original performance of the agent in the abstract setting. We present a sequence of experiments to identify what differences result in performance degradation, providing clear directions for further improvement.", "paper_url": "http://arxiv.org/abs/2204.09667v1", "pdf_url": "http://arxiv.org/pdf/2204.09667v1", "repo_url": null}, "2204.09606": {"publish_time": "2022-04-20", "title": "Detecting Unintended Memorization in Language-Model-Fused ASR", "author": "W. Ronny Huang et.al.", "abstract": "End-to-end (E2E) models are often being accompanied by language models (LMs) via shallow fusion for boosting their overall quality as well as recognition of rare words. At the same time, several prior works show that LMs are susceptible to unintentionally memorizing rare or unique sequences in the training data. In this work, we design a framework for detecting memorization of random textual sequences (which we call canaries) in the LM training data when one has only black-box (query) access to LM-fused speech recognizer, as opposed to direct access to the LM. On a production-grade Conformer RNN-T E2E model fused with a Transformer LM, we show that detecting memorization of singly-occurring canaries from the LM training data of 300M examples is possible. Motivated to protect privacy, we also show that such memorization gets significantly reduced by per-example gradient-clipped LM training without compromising overall quality.", "paper_url": "http://arxiv.org/abs/2204.09606v1", "pdf_url": "http://arxiv.org/pdf/2204.09606v1", "repo_url": null}, "2204.09565": {"publish_time": "2022-04-20", "title": "On the Ethical Considerations of Text Simplification", "author": "Sian Gooding et.al.", "abstract": "This paper outlines the ethical implications of text simplification within the framework of assistive systems. We argue that a distinction should be made between the technologies that perform text simplification and the realisation of these in assistive technologies. When using the latter as a motivation for research, it is important that the subsequent ethical implications be carefully considered. We provide guidelines for the framing of text simplification independently of assistive systems, as well as suggesting directions for future research and discussion based on the concerns raised.", "paper_url": "http://arxiv.org/abs/2204.09565v1", "pdf_url": "http://arxiv.org/pdf/2204.09565v1", "repo_url": null}, "2204.09519": {"publish_time": "2022-04-20", "title": "A Survey on Neural Abstractive Summarization Methods and Factual Consistency of Summarization", "author": "Meng Cao et.al.", "abstract": "Automatic summarization is the process of shortening a set of textual data computationally, to create a subset (a summary) that represents the most important pieces of information in the original text. Existing summarization methods can be roughly divided into two types: extractive and abstractive. An extractive summarizer explicitly selects text snippets (words, phrases, sentences, etc.) from the source document, while an abstractive summarizer generates novel text snippets to convey the most salient concepts prevalent in the source.", "paper_url": "http://arxiv.org/abs/2204.09519v1", "pdf_url": "http://arxiv.org/pdf/2204.09519v1", "repo_url": null}, "2204.09484": {"publish_time": "2022-04-20", "title": "Generalizing to the Future: Mitigating Entity Bias in Fake News Detection", "author": "Yongchun Zhu et.al.", "abstract": "The wide dissemination of fake news is increasingly threatening both individuals and society. Fake news detection aims to train a model on the past news and detect fake news of the future. Though great efforts have been made, existing fake news detection methods overlooked the unintended entity bias in the real-world data, which seriously influences models' generalization ability to future data. For example, 97\\% of news pieces in 2010-2017 containing the entity `Donald Trump' are real in our data, but the percentage falls down to merely 33\\% in 2018. This would lead the model trained on the former set to hardly generalize to the latter, as it tends to predict news pieces about `Donald Trump' as real for lower training loss. In this paper, we propose an entity debiasing framework (\\textbf{ENDEF}) which generalizes fake news detection models to the future data by mitigating entity bias from a cause-effect perspective. Based on the causal graph among entities, news contents, and news veracity, we separately model the contribution of each cause (entities and contents) during training. In the inference stage, we remove the direct effect of the entities to mitigate entity bias. Extensive offline experiments on the English and Chinese datasets demonstrate that the proposed framework can largely improve the performance of base fake news detectors, and online tests verify its superiority in practice. To the best of our knowledge, this is the first work to explicitly improve the generalization ability of fake news detection models to the future data. The code has been released at https://github.com/ICTMCG/ENDEF-SIGIR2022.", "paper_url": "http://arxiv.org/abs/2204.09484v1", "pdf_url": "http://arxiv.org/pdf/2204.09484v1", "repo_url": "https://github.com/ictmcg/endef-sigir2022"}, "2204.10298": {"publish_time": "2022-04-21", "title": "DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings", "author": "Yung-Sung Chuang et.al.", "abstract": "We propose DiffCSE, an unsupervised contrastive learning framework for learning sentence embeddings. DiffCSE learns sentence embeddings that are sensitive to the difference between the original sentence and an edited sentence, where the edited sentence is obtained by stochastically masking out the original sentence and then sampling from a masked language model. We show that DiffSCE is an instance of equivariant contrastive learning (Dangovski et al., 2021), which generalizes contrastive learning and learns representations that are insensitive to certain types of augmentations and sensitive to other \"harmful\" types of augmentations. Our experiments show that DiffCSE achieves state-of-the-art results among unsupervised sentence representation learning methods, outperforming unsupervised SimCSE by 2.3 absolute points on semantic textual similarity tasks.", "paper_url": "http://arxiv.org/abs/2204.10298v1", "pdf_url": "http://arxiv.org/pdf/2204.10298v1", "repo_url": "https://github.com/voidism/diffcse"}, "2204.10245": {"publish_time": "2022-04-21", "title": "SpaceE: Knowledge Graph Embedding by Relational Linear Transformation in the Entity Space", "author": "Jinxing Yu et.al.", "abstract": "Translation distance based knowledge graph embedding (KGE) methods, such as TransE and RotatE, model the relation in knowledge graphs as translation or rotation in the vector space. Both translation and rotation are injective; that is, the translation or rotation of different vectors results in different results. In knowledge graphs, different entities may have a relation with the same entity; for example, many actors starred in one movie. Such a non-injective relation pattern cannot be well modeled by the translation or rotation operations in existing translation distance based KGE methods. To tackle the challenge, we propose a translation distance-based KGE method called SpaceE to model relations as linear transformations. The proposed SpaceE embeds both entities and relations in knowledge graphs as matrices and SpaceE naturally models non-injective relations with singular linear transformations. We theoretically demonstrate that SpaceE is a fully expressive model with the ability to infer multiple desired relation patterns, including symmetry, skew-symmetry, inversion, Abelian composition, and non-Abelian composition. Experimental results on link prediction datasets illustrate that SpaceE substantially outperforms many previous translation distance based knowledge graph embedding methods, especially on datasets with many non-injective relations. The code is available based on the PaddlePaddle deep learning platform https://www.paddlepaddle.org.cn.", "paper_url": "http://arxiv.org/abs/2204.10245v1", "pdf_url": "http://arxiv.org/pdf/2204.10245v1", "repo_url": null}, "2204.10230": {"publish_time": "2022-04-21", "title": "Cross-Lingual Query-Based Summarization of Crisis-Related Social Media: An Abstractive Approach Using Transformers", "author": "Fedor Vitiugin et.al.", "abstract": "Relevant and timely information collected from social media during crises can be an invaluable resource for emergency management. However, extracting this information remains a challenging task, particularly when dealing with social media postings in multiple languages. This work proposes a cross-lingual method for retrieving and summarizing crisis-relevant information from social media postings. We describe a uniform way of expressing various information needs through structured queries and a way of creating summaries answering those information needs. The method is based on multilingual transformers embeddings. Queries are written in one of the languages supported by the embeddings, and the extracted sentences can be in any of the other languages supported. Abstractive summaries are created by transformers. The evaluation, done by crowdsourcing evaluators and emergency management experts, and carried out on collections extracted from Twitter during five large-scale disasters spanning ten languages, shows the flexibility of our approach. The generated summaries are regarded as more focused, structured, and coherent than existing state-of-the-art methods, and experts compare them favorably against summaries created by existing, state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2204.10230v1", "pdf_url": "http://arxiv.org/pdf/2204.10230v1", "repo_url": "https://github.com/vitiugin/cliqs-cm"}, "2204.10216": {"publish_time": "2022-04-21", "title": "Re-Examining System-Level Correlations of Automatic Summarization Evaluation Metrics", "author": "Daniel Deutsch et.al.", "abstract": "How reliably an automatic summarization evaluation metric replicates human judgments of summary quality is quantified by system-level correlations. We identify two ways in which the definition of the system-level correlation is inconsistent with how metrics are used to evaluate systems in practice and propose changes to rectify this disconnect. First, we calculate the system score for an automatic metric using the full test set instead of the subset of summaries judged by humans, which is currently standard practice. We demonstrate how this small change leads to more precise estimates of system-level correlations. Second, we propose to calculate correlations only on pairs of systems that are separated by small differences in automatic scores which are commonly observed in practice. This allows us to demonstrate that our best estimate of the correlation of ROUGE to human judgments is near 0 in realistic scenarios. The results from the analyses point to the need to collect more high-quality human judgments and to improve automatic metrics when differences in system scores are small.", "paper_url": "http://arxiv.org/abs/2204.10216v1", "pdf_url": "http://arxiv.org/pdf/2204.10216v1", "repo_url": null}, "2204.10206": {"publish_time": "2022-04-21", "title": "Benchmarking Answer Verification Methods for Question Answering-Based Summarization Evaluation Metrics", "author": "Daniel Deutsch et.al.", "abstract": "Question answering-based summarization evaluation metrics must automatically determine whether the QA model's prediction is correct or not, a task known as answer verification. In this work, we benchmark the lexical answer verification methods which have been used by current QA-based metrics as well as two more sophisticated text comparison methods, BERTScore and LERC. We find that LERC out-performs the other methods in some settings while remaining statistically indistinguishable from lexical overlap in others. However, our experiments reveal that improved verification performance does not necessarily translate to overall QA-based metric quality: In some scenarios, using a worse verification method -- or using none at all -- has comparable performance to using the best verification method, a result that we attribute to properties of the datasets.", "paper_url": "http://arxiv.org/abs/2204.10206v1", "pdf_url": "http://arxiv.org/pdf/2204.10206v1", "repo_url": null}, "2204.10849": {"publish_time": "2022-04-22", "title": "Metric Learning and Adaptive Boundary for Out-of-Domain Detection", "author": "Petr Lorenc et.al.", "abstract": "Conversational agents are usually designed for closed-world environments. Unfortunately, users can behave unexpectedly. Based on the open-world environment, we often encounter the situation that the training and test data are sampled from different distributions. Then, data from different distributions are called out-of-domain (OOD). A robust conversational agent needs to react to these OOD utterances adequately. Thus, the importance of robust OOD detection is emphasized. Unfortunately, collecting OOD data is a challenging task. We have designed an OOD detection algorithm independent of OOD data that outperforms a wide range of current state-of-the-art algorithms on publicly available datasets. Our algorithm is based on a simple but efficient approach of combining metric learning with adaptive decision boundary. Furthermore, compared to other algorithms, we have found that our proposed algorithm has significantly improved OOD performance in a scenario with a lower number of classes while preserving the accuracy for in-domain (IND) classes.", "paper_url": "http://arxiv.org/abs/2204.10849v1", "pdf_url": "http://arxiv.org/pdf/2204.10849v1", "repo_url": "https://github.com/tgargiani/adaptive-boundary"}, "2204.10841": {"publish_time": "2022-04-22", "title": "Detecting early signs of depression in the conversational domain: The role of transfer learning in low-resource scenarios", "author": "Petr Lorenc et.al.", "abstract": "The high prevalence of depression in society has given rise to the need for new digital tools to assist in its early detection. To this end, existing research has mainly focused on detecting depression in the domain of social media, where there is a sufficient amount of data. However, with the rise of conversational agents like Siri or Alexa, the conversational domain is becoming more critical. Unfortunately, there is a lack of data in the conversational domain. We perform a study focusing on domain adaptation from social media to the conversational domain. Our approach mainly exploits the linguistic information preserved in the vector representation of text. We describe transfer learning techniques to classify users who suffer from early signs of depression with high recall. We achieve state-of-the-art results on a commonly used conversational dataset, and we highlight how the method can easily be used in conversational agents. We publicly release all source code.", "paper_url": "http://arxiv.org/abs/2204.10841v1", "pdf_url": "http://arxiv.org/pdf/2204.10841v1", "repo_url": "https://github.com/petrlorenc/mental-health"}, "2204.10825": {"publish_time": "2022-04-22", "title": "Meet Your Favorite Character: Open-domain Chatbot Mimicking Fictional Characters with only a Few Utterances", "author": "Seungju Han et.al.", "abstract": "In this paper, we consider mimicking fictional characters as a promising direction for building engaging conversation models. To this end, we present a new practical task where only a few utterances of each fictional character are available to generate responses mimicking them. Furthermore, we propose a new method named Pseudo Dialog Prompting (PDP) that generates responses by leveraging the power of large-scale language models with prompts containing the target character's utterances. To better reflect the style of the character, PDP builds the prompts in the form of dialog that includes the character's utterances as dialog history. Since only utterances of the characters are available in the proposed task, PDP matches each utterance with an appropriate pseudo-context from a predefined set of context candidates using a retrieval model. Through human and automatic evaluation, we show that PDP generates responses that better reflect the style of fictional characters than baseline methods.", "paper_url": "http://arxiv.org/abs/2204.10825v1", "pdf_url": "http://arxiv.org/pdf/2204.10825v1", "repo_url": null}, "2204.10815": {"publish_time": "2022-04-22", "title": "A Vocabulary-Free Multilingual Neural Tokenizer for End-to-End Task Learning", "author": "Md Mofijul Islam et.al.", "abstract": "Subword tokenization is a commonly used input pre-processing step in most recent NLP models. However, it limits the models' ability to leverage end-to-end task learning. Its frequency-based vocabulary creation compromises tokenization in low-resource languages, leading models to produce suboptimal representations. Additionally, the dependency on a fixed vocabulary limits the subword models' adaptability across languages and domains. In this work, we propose a vocabulary-free neural tokenizer by distilling segmentation information from heuristic-based subword tokenization. We pre-train our character-based tokenizer by processing unique words from multilingual corpus, thereby extensively increasing word diversity across languages. Unlike the predefined and fixed vocabularies in subword methods, our tokenizer allows end-to-end task learning, resulting in optimal task-specific tokenization. The experimental results show that replacing the subword tokenizer with our neural tokenizer consistently improves performance on multilingual (NLI) and code-switching (sentiment analysis) tasks, with larger gains in low-resource languages. Additionally, our neural tokenizer exhibits a robust performance on downstream tasks when adversarial noise is present (typos and misspelling), further increasing the initial improvements over statistical subword tokenizers.", "paper_url": "http://arxiv.org/abs/2204.10815v1", "pdf_url": "http://arxiv.org/pdf/2204.10815v1", "repo_url": null}, "2204.10810": {"publish_time": "2022-04-22", "title": "Learning to Scaffold: Optimizing Model Explanations for Teaching", "author": "Patrick Fernandes et.al.", "abstract": "Modern machine learning models are opaque, and as a result there is a burgeoning academic subfield on methods that explain these models' behavior. However, what is the precise goal of providing such explanations, and how can we demonstrate that explanations achieve this goal? Some research argues that explanations should help teach a student (either human or machine) to simulate the model being explained, and that the quality of explanations can be measured by the simulation accuracy of students on unexplained examples. In this work, leveraging meta-learning techniques, we extend this idea to improve the quality of the explanations themselves, specifically by optimizing explanations such that student models more effectively learn to simulate the original model. We train models on three natural language processing and computer vision tasks, and find that students trained with explanations extracted with our framework are able to simulate the teacher significantly more effectively than ones produced with previous methods. Through human annotations and a user study, we further find that these learned explanations more closely align with how humans would explain the required decisions in these tasks. Our code is available at https://github.com/coderpat/learning-scaffold", "paper_url": "http://arxiv.org/abs/2204.10810v1", "pdf_url": "http://arxiv.org/pdf/2204.10810v1", "repo_url": "https://github.com/coderpat/learning-scaffold"}, "2204.11817": {"publish_time": "2022-04-25", "title": "Translation between Molecules and Natural Language", "author": "Carl Edwards et.al.", "abstract": "Joint representations between images and text have been deeply investigated in the literature. In computer vision, the benefits of incorporating natural language have become clear for enabling semantic-level control of images. In this work, we present $\\textbf{MolT5}-$a self-supervised learning framework for pretraining models on a vast amount of unlabeled natural language text and molecule strings. $\\textbf{MolT5}$ allows for new, useful, and challenging analogs of traditional vision-language tasks, such as molecule captioning and text-based de novo molecule generation (altogether: translation between molecules and language), which we explore for the first time. Furthermore, since $\\textbf{MolT5}$ pretrains models on single-modal data, it helps overcome the chemistry domain shortcoming of data scarcity. Additionally, we consider several metrics, including a new cross-modal embedding-based metric, to evaluate the tasks of molecule captioning and text-based molecule generation. By interfacing molecules with natural language, we enable a higher semantic level of control over molecule discovery and understanding--a critical task for scientific domains such as drug discovery and material design. Our results show that $\\textbf{MolT5}$-based models are able to generate outputs, both molecule and text, which in many cases are high quality and match the input modality. On molecule generation, our best model achieves 30% exact matching test accuracy (i.e., it generates the correct structure for about one-third of the captions in our held-out test set).", "paper_url": "http://arxiv.org/abs/2204.11817v1", "pdf_url": "http://arxiv.org/pdf/2204.11817v1", "repo_url": "https://github.com/blender-nlp/MolT5"}, "2204.11790": {"publish_time": "2022-04-25", "title": "Can Rationalization Improve Robustness?", "author": "Howard Chen et.al.", "abstract": "A growing line of work has investigated the development of neural NLP models that can produce rationales--subsets of input that can explain their model predictions. In this paper, we ask whether such rationale models can also provide robustness to adversarial attacks in addition to their interpretable nature. Since these models need to first generate rationales (\"rationalizer\") before making predictions (\"predictor\"), they have the potential to ignore noise or adversarially added text by simply masking it out of the generated rationale. To this end, we systematically generate various types of 'AddText' attacks for both token and sentence-level rationalization tasks, and perform an extensive empirical evaluation of state-of-the-art rationale models across five different tasks. Our experiments reveal that the rationale models show the promise to improve robustness, while they struggle in certain scenarios--when the rationalizer is sensitive to positional bias or lexical choices of attack text. Further, leveraging human rationale as supervision does not always translate to better performance. Our study is a first step towards exploring the interplay between interpretability and robustness in the rationalize-then-predict framework.", "paper_url": "http://arxiv.org/abs/2204.11790v1", "pdf_url": "http://arxiv.org/pdf/2204.11790v1", "repo_url": "https://github.com/princeton-nlp/rationale-robustness"}, "2204.11786": {"publish_time": "2022-04-25", "title": "Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications", "author": "Han Cai et.al.", "abstract": "Deep neural networks (DNNs) have achieved unprecedented success in the field of artificial intelligence (AI), including computer vision, natural language processing and speech recognition. However, their superior performance comes at the considerable cost of computational complexity, which greatly hinders their applications in many resource-constrained devices, such as mobile phones and Internet of Things (IoT) devices. Therefore, methods and techniques that are able to lift the efficiency bottleneck while preserving the high accuracy of DNNs are in great demand in order to enable numerous edge AI applications. This paper provides an overview of efficient deep learning methods, systems and applications. We start from introducing popular model compression methods, including pruning, factorization, quantization as well as compact model design. To reduce the large design cost of these manual solutions, we discuss the AutoML framework for each of them, such as neural architecture search (NAS) and automated pruning and quantization. We then cover efficient on-device training to enable user customization based on the local data on mobile devices. Apart from general acceleration techniques, we also showcase several task-specific accelerations for point cloud, video and natural language processing by exploiting their spatial sparsity and temporal/token redundancy. Finally, to support all these algorithmic advancements, we introduce the efficient deep learning system design from both software and hardware perspectives.", "paper_url": "http://arxiv.org/abs/2204.11786v1", "pdf_url": "http://arxiv.org/pdf/2204.11786v1", "repo_url": null}, "2204.11742": {"publish_time": "2022-04-25", "title": "Discovering changes in birthing narratives during COVID-19", "author": "Daphna Spira et.al.", "abstract": "We investigate whether, and if so how, birthing narratives written by new parents on Reddit changed during COVID-19. Our results indicate that the presence of family members significantly decreased and themes related to induced labor significantly increased in the narratives during COVID-19. Our work builds upon recent research that analyze how new parents use Reddit to describe their birthing experiences.", "paper_url": "http://arxiv.org/abs/2204.11742v1", "pdf_url": "http://arxiv.org/pdf/2204.11742v1", "repo_url": null}, "2204.11714": {"publish_time": "2022-04-25", "title": "The Causal News Corpus: Annotating Causal Relations in Event Sentences from News", "author": "Fiona Anting Tan et.al.", "abstract": "Despite the importance of understanding causality, corpora addressing causal relations are limited. There is a discrepancy between existing annotation guidelines of event causality and conventional causality corpora that focus more on linguistics. Many guidelines restrict themselves to include only explicit relations or clause-based arguments. Therefore, we propose an annotation schema for event causality that addresses these concerns. We annotated 3,559 event sentences from protest event news with labels on whether it contains causal relations or not. Our corpus is known as the Causal News Corpus (CNC). A neural network built upon a state-of-the-art pre-trained language model performed well with 81.20% F1 score on test set, and 83.46% in 5-folds cross-validation. CNC is transferable across two external corpora: CausalTimeBank (CTB) and Penn Discourse Treebank (PDTB). Leveraging each of these external datasets for training, we achieved up to approximately 64% F1 on the CNC test set without additional fine-tuning. CNC also served as an effective training and pre-training dataset for the two external corpora. Lastly, we demonstrate the difficulty of our task to the layman in a crowd-sourced annotation exercise. Our annotated corpus is publicly available, providing a valuable resource for causal text mining researchers.", "paper_url": "http://arxiv.org/abs/2204.11714v1", "pdf_url": "http://arxiv.org/pdf/2204.11714v1", "repo_url": "https://github.com/tanfiona/causalnewscorpus"}, "2204.12481": {"publish_time": "2022-04-26", "title": "From Hyperbolic Geometry Back to Word Embeddings", "author": "Sultan Nurmukhamedov et.al.", "abstract": "We choose random points in the hyperbolic disc and claim that these points are already word representations. However, it is yet to be uncovered which point corresponds to which word of the human language of interest. This correspondence can be approximately established using a pointwise mutual information between words and recent alignment techniques.", "paper_url": "http://arxiv.org/abs/2204.12481v1", "pdf_url": "http://arxiv.org/pdf/2204.12481v1", "repo_url": "https://github.com/soltustik/rhg"}, "2204.12456": {"publish_time": "2022-04-26", "title": "Event Detection Explorer: An Interactive Tool for Event Detection Exploration", "author": "Wenlong Zhang et.al.", "abstract": "Event Detection (ED) is an important task in natural language processing. In the past few years, many datasets have been introduced for advancing ED machine learning models. However, most of these datasets are under-explored because not many tools are available for people to study events, trigger words, and event mention instances systematically and efficiently. In this paper, we present an interactive and easy-to-use tool, namely ED Explorer, for ED dataset and model exploration. ED Explorer consists of an interactive web application, an API, and an NLP toolkit, which can help both domain experts and non-experts to better understand the ED task. We use ED Explorer to analyze a recent proposed large-scale ED datasets (referred to as MAVEN), and discover several underlying problems, including sparsity, label bias, label imbalance, and debatable annotations, which provide us with directions to improve the MAVEN dataset. The ED Explorer can be publicly accessed through http://edx.leafnlp.org/. The demonstration video is available here https://www.youtube.com/watch?v=6QPnxPwxg50.", "paper_url": "http://arxiv.org/abs/2204.12456v1", "pdf_url": "http://arxiv.org/pdf/2204.12456v1", "repo_url": null}, "2204.12421": {"publish_time": "2022-04-26", "title": "Disambiguation of morpho-syntactic features of African American English -- the case of habitual be", "author": "Harrison Santiago et.al.", "abstract": "Recent research has highlighted that natural language processing (NLP) systems exhibit a bias against African American speakers. The bias errors are often caused by poor representation of linguistic features unique to African American English (AAE), due to the relatively low probability of occurrence of many such features in training data. We present a workflow to overcome such bias in the case of habitual \"be\". Habitual \"be\" is isomorphic, and therefore ambiguous, with other forms of \"be\" found in both AAE and other varieties of English. This creates a clear challenge for bias in NLP technologies. To overcome the scarcity, we employ a combination of rule-based filters and data augmentation that generate a corpus balanced between habitual and non-habitual instances. With this balanced corpus, we train unbiased machine learning classifiers, as demonstrated on a corpus of AAE transcribed texts, achieving .65 F$_1$ score disambiguating habitual \"be\".", "paper_url": "http://arxiv.org/abs/2204.12421v1", "pdf_url": "http://arxiv.org/pdf/2204.12421v1", "repo_url": null}, "2204.12386": {"publish_time": "2022-04-26", "title": "Learning Meta Word Embeddings by Unsupervised Weighted Concatenation of Source Embeddings", "author": "Danushka Bollegala et.al.", "abstract": "Given multiple source word embeddings learnt using diverse algorithms and lexical resources, meta word embedding learning methods attempt to learn more accurate and wide-coverage word embeddings.   Prior work on meta-embedding has repeatedly discovered that simple vector concatenation of the source embeddings to be a competitive baseline.   However, it remains unclear as to why and when simple vector concatenation can produce accurate meta-embeddings.   We show that weighted concatenation can be seen as a spectrum matching operation between each source embedding and the meta-embedding, minimising the pairwise inner-product loss.   Following this theoretical analysis, we propose two \\emph{unsupervised} methods to learn the optimal concatenation weights for creating meta-embeddings from a given set of source embeddings.   Experimental results on multiple benchmark datasets show that the proposed weighted concatenated meta-embedding methods outperform previously proposed meta-embedding learning methods.", "paper_url": "http://arxiv.org/abs/2204.12386v1", "pdf_url": "http://arxiv.org/pdf/2204.12386v1", "repo_url": null}, "2204.12316": {"publish_time": "2022-04-26", "title": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective", "author": "Edoardo Manino et.al.", "abstract": "Metamorphic testing has recently been used to check the safety of neural NLP models. Its main advantage is that it does not rely on a ground truth to generate test cases. However, existing studies are mostly concerned with robustness-like metamorphic relations, limiting the scope of linguistic properties they can test. We propose three new classes of metamorphic relations, which address the properties of systematicity, compositionality and transitivity. Unlike robustness, our relations are defined over multiple source inputs, thus increasing the number of test cases that we can produce by a polynomial factor. With them, we test the internal consistency of state-of-the-art NLP models, and show that they do not always behave according to their expected linguistic properties. Lastly, we introduce a novel graphical notation that efficiently summarises the inner structure of metamorphic relations.", "paper_url": "http://arxiv.org/abs/2204.12316v1", "pdf_url": "http://arxiv.org/pdf/2204.12316v1", "repo_url": null}, "2204.13097": {"publish_time": "2022-04-27", "title": "Learning to Borrow -- Relation Representation for Without-Mention Entity-Pairs for Knowledge Graph Completion", "author": "Huda Hakami et.al.", "abstract": "Prior work on integrating text corpora with knowledge graphs (KGs) to improve Knowledge Graph Embedding (KGE) have obtained good performance for entities that co-occur in sentences in text corpora. Such sentences (textual mentions of entity-pairs) are represented as Lexicalised Dependency Paths (LDPs) between two entities. However, it is not possible to represent relations between entities that do not co-occur in a single sentence using LDPs. In this paper, we propose and evaluate several methods to address this problem, where we borrow LDPs from the entity pairs that co-occur in sentences in the corpus (i.e. with mention entity pairs) to represent entity pairs that do not co-occur in any sentence in the corpus (i.e. without mention entity pairs). We propose a supervised borrowing method, SuperBorrow, that learns to score the suitability of an LDP to represent a without-mention entity pair using pre-trained entity embeddings and contextualised LDP representations. Experimental results show that SuperBorrow improves the link prediction performance of multiple widely-used prior KGE methods such as TransE, DistMult, ComplEx and RotatE.", "paper_url": "http://arxiv.org/abs/2204.13097v1", "pdf_url": "http://arxiv.org/pdf/2204.13097v1", "repo_url": "https://github.com/huda-hakami/learning-to-borrow-for-kgs"}, "2204.13074": {"publish_time": "2022-04-27", "title": "Towards Teachable Reasoning Systems", "author": "Bhavana Dalvi et.al.", "abstract": "Our goal is a teachable reasoning system for question-answering (QA), where a user can interact with faithful answer explanations, and correct errors so that the system improves over time. Our approach is three-fold: First, generated chains of reasoning show how answers are implied by the system's own internal beliefs. Second, users can interact with the explanations to identify erroneous model beliefs and provide corrections. Third, we augment the model with a dynamic memory of such corrections. Retrievals from memory are used as additional context for QA, to help avoid previous mistakes in similar new situations - a novel type of memory-based continuous learning. To our knowledge, this is the first system to generate chains that are both faithful (the answer follows from the reasoning) and truthful (the chain reflects the system's own beliefs, as ascertained by self-querying). In evaluation, users judge that a majority (65%+) of generated chains clearly show how an answer follows from a set of facts - substantially better than a high-performance baseline. We also find that using simulated feedback, our system (called EntailmentWriter) continually improves with time, requiring feedback on only 25% of training examples to reach within 1% of the upper-bound (feedback on all examples). We observe a similar trend with real users. This suggests new opportunities for using language models in an interactive setting where users can inspect, debug, correct, and improve a system's performance over time.", "paper_url": "http://arxiv.org/abs/2204.13074v1", "pdf_url": "http://arxiv.org/pdf/2204.13074v1", "repo_url": null}, "2204.13032": {"publish_time": "2022-04-27", "title": "TimeBERT: Enhancing Pre-Trained Language Representations with Temporal Information", "author": "Jiexin Wang et.al.", "abstract": "Time is an important aspect of text documents, which has been widely exploited in natural language processing and has strong influence, for example, in temporal information retrieval, where the temporal information of queries or documents need to be identified for relevance estimation. Event-related tasks like event ordering, which aims to order events by their occurrence time, also need to determine the temporal information of events. In this work, we investigate methods for incorporating temporal information during pre-training, to further improve the performance on time-related tasks. Compared with BERT which utilizes synchronic document collections (BooksCorpus and English Wikipedia) as the training corpora, we use long-span temporal news collection for building word representations, since temporal information constitutes one of the most significant features of news articles. We then introduce TimeBERT, a novel language representation model trained on a temporal collection of news articles via two new pre-training tasks, which harness two distinct temporal signals to construct time-aware language representation. The experimental results show that TimeBERT consistently outperforms BERT and other existing pre-trained models, with substantial gains on different downstream NLP tasks or applications for which time is of importance.", "paper_url": "http://arxiv.org/abs/2204.13032v1", "pdf_url": "http://arxiv.org/pdf/2204.13032v1", "repo_url": null}, "2204.13031": {"publish_time": "2022-04-27", "title": "DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation", "author": "Wei Chen et.al.", "abstract": "Dialog response generation in open domain is an important research topic where the main challenge is to generate relevant and diverse responses. In this paper, we propose a new dialog pre-training framework called DialogVED, which introduces continuous latent variables into the enhanced encoder-decoder pre-training framework to increase the relevance and diversity of responses. With the help of a large dialog corpus (Reddit), we pre-train the model using the following 4 tasks, used in training language models (LMs) and Variational Autoencoders (VAEs) literature: 1) masked language model; 2) response generation; 3) bag-of-words prediction; and 4) KL divergence reduction. We also add additional parameters to model the turn structure in dialogs to improve the performance of the pre-trained model. We conduct experiments on PersonaChat, DailyDialog, and DSTC7-AVSD benchmarks for response generation. Experimental results show that our model achieves the new state-of-the-art results on all these datasets.", "paper_url": "http://arxiv.org/abs/2204.13031v1", "pdf_url": "http://arxiv.org/pdf/2204.13031v1", "repo_url": "https://github.com/lemuria-wchen/DialogVED"}, "2204.13021": {"publish_time": "2022-04-27", "title": "NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue", "author": "I\u00f1igo Casanueva et.al.", "abstract": "We present NLU++, a novel dataset for natural language understanding (NLU) in task-oriented dialogue (ToD) systems, with the aim to provide a much more challenging evaluation environment for dialogue NLU models, up to date with the current application and industry requirements. NLU++ is divided into two domains (BANKING and HOTELS) and brings several crucial improvements over current commonly used NLU datasets. \\textbf{1)} NLU++ provides fine-grained domain ontologies with a large set of challenging \\textit{multi-intent} sentences, introducing and validating the idea of \\textit{intent modules} that can be combined into complex intents that convey complex user goals, combined with finer-grained and thus more challenging slot sets. \\textbf{2)} The ontology is divided into \\textit{domain-specific} and \\textit{generic} (i.e., domain-universal) intent modules that overlap across domains, promoting cross-domain reusability of annotated examples. \\textbf{3)} The dataset design has been inspired by the problems observed in industrial ToD systems, and \\textbf{4)} it has been collected, filtered and carefully annotated by dialogue NLU experts, yielding high-quality annotated data. Finally, we benchmark a series of current state-of-the-art NLU models on NLU++; the results demonstrate the challenging nature of the dataset, especially in low-data regimes, the validity of `intent modularisation', and call for further research on ToD NLU.", "paper_url": "http://arxiv.org/abs/2204.13021v1", "pdf_url": "http://arxiv.org/pdf/2204.13021v1", "repo_url": null}, "2204.13692": {"publish_time": "2022-04-28", "title": "NMTScore: A Multilingual Analysis of Translation-based Text Similarity Measures", "author": "Jannis Vamvas et.al.", "abstract": "Being able to rank the similarity of short text segments is an interesting bonus feature of neural machine translation. Translation-based similarity measures include direct and pivot translation probability, as well as translation cross-likelihood, which has not been studied so far. We analyze these measures in the common framework of multilingual NMT, releasing the NMTScore library (available at https://github.com/ZurichNLP/nmtscore). Compared to baselines such as sentence embeddings, translation-based measures prove competitive in paraphrase identification and are more robust against adversarial or multilingual input, especially if proper normalization is applied. When used for reference-based evaluation of data-to-text generation in 2 tasks and 17 languages, translation-based measures show a relatively high correlation to human judgments.", "paper_url": "http://arxiv.org/abs/2204.13692v1", "pdf_url": "http://arxiv.org/pdf/2204.13692v1", "repo_url": "https://github.com/zurichnlp/nmtscore"}, "2204.13638": {"publish_time": "2022-04-28", "title": "Russian Texts Detoxification with Levenshtein Editing", "author": "Ilya Gusev et.al.", "abstract": "Text detoxification is a style transfer task of creating neutral versions of toxic texts. In this paper, we use the concept of text editing to build a two-step tagging-based detoxification model using a parallel corpus of Russian texts. With this model, we achieved the best style transfer accuracy among all models in the RUSSE Detox shared task, surpassing larger sequence-to-sequence models.", "paper_url": "http://arxiv.org/abs/2204.13638v1", "pdf_url": "http://arxiv.org/pdf/2204.13638v1", "repo_url": "https://github.com/ilyagusev/rudetox"}, "2204.13604": {"publish_time": "2022-04-28", "title": "MeSHup: A Corpus for Full Text Biomedical Document Indexing", "author": "Xindi Wang et.al.", "abstract": "Medical Subject Heading (MeSH) indexing refers to the problem of assigning a given biomedical document with the most relevant labels from an extremely large set of MeSH terms. Currently, the vast number of biomedical articles in the PubMed database are manually annotated by human curators, which is time consuming and costly; therefore, a computational system that can assist the indexing is highly valuable. When developing supervised MeSH indexing systems, the availability of a large-scale annotated text corpus is desirable. A publicly available, large corpus that permits robust evaluation and comparison of various systems is important to the research community. We release a large scale annotated MeSH indexing corpus, MeSHup, which contains 1,342,667 full text articles in English, together with the associated MeSH labels and metadata, authors, and publication venues that are collected from the MEDLINE database. We train an end-to-end model that combines features from documents and their associated labels on our corpus and report the new baseline.", "paper_url": "http://arxiv.org/abs/2204.13604v1", "pdf_url": "http://arxiv.org/pdf/2204.13604v1", "repo_url": null}, "2204.13569": {"publish_time": "2022-04-28", "title": "Life is not Always Depressing: Exploring the Happy Moments of People Diagnosed with Depression", "author": "Ana-Maria Bucur et.al.", "abstract": "In this work, we explore the relationship between depression and manifestations of happiness in social media. While the majority of works surrounding depression focus on symptoms, psychological research shows that there is a strong link between seeking happiness and being diagnosed with depression. We make use of Positive-Unlabeled learning paradigm to automatically extract happy moments from social media posts of both controls and users diagnosed with depression, and qualitatively analyze them with linguistic tools such as LIWC and keyness information. We show that the life of depressed individuals is not always bleak, with positive events related to friends and family being more noteworthy to their lives compared to the more mundane happy events reported by control users.", "paper_url": "http://arxiv.org/abs/2204.13569v1", "pdf_url": "http://arxiv.org/pdf/2204.13569v1", "repo_url": null}, "2204.13535": {"publish_time": "2022-04-28", "title": "Machine Learning for Violence Risk Assessment Using Dutch Clinical Notes", "author": "Pablo Mosteiro et.al.", "abstract": "Violence risk assessment in psychiatric institutions enables interventions to avoid violence incidents. Clinical notes written by practitioners and available in electronic health records are valuable resources capturing unique information, but are seldom used to their full potential. We explore conventional and deep machine learning methods to assess violence risk in psychiatric patients using practitioner notes. The performance of our best models is comparable to the currently used questionnaire-based method, with an area under the Receiver Operating Characteristic curve of approximately 0.8. We find that the deep-learning model BERTje performs worse than conventional machine learning methods. We also evaluate our data and our classifiers to understand the performance of our models better. This is particularly important for the applicability of evaluated classifiers to new data, and is also of great interest to practitioners, due to the increased availability of new data in electronic format.", "paper_url": "http://arxiv.org/abs/2204.13535v1", "pdf_url": "http://arxiv.org/pdf/2204.13535v1", "repo_url": null}, "2204.14272": {"publish_time": "2022-04-29", "title": "End-to-end Spoken Conversational Question Answering: Task, Dataset and Model", "author": "Chenyu You et.al.", "abstract": "In spoken question answering, the systems are designed to answer questions from contiguous text spans within the related speech transcripts. However, the most natural way that human seek or test their knowledge is via human conversations. Therefore, we propose a new Spoken Conversational Question Answering task (SCQA), aiming at enabling the systems to model complex dialogue flows given the speech documents. In this task, our main objective is to build the system to deal with conversational questions based on the audio recordings, and to explore the plausibility of providing more cues from different modalities with systems in information gathering. To this end, instead of directly adopting automatically generated speech transcripts with highly noisy data, we propose a novel unified data distillation approach, DDNet, which effectively ingests cross-modal information to achieve fine-grained representations of the speech and language modalities. Moreover, we propose a simple and novel mechanism, termed Dual Attention, by encouraging better alignments between audio and text to ease the process of knowledge transfer. To evaluate the capacity of SCQA systems in a dialogue-style interaction, we assemble a Spoken Conversational Question Answering (Spoken-CoQA) dataset with more than 40k question-answer pairs from 4k conversations. The performance of the existing state-of-the-art methods significantly degrade on our dataset, hence demonstrating the necessity of cross-modal information integration. Our experimental results demonstrate that our proposed method achieves superior performance in spoken conversational question answering tasks.", "paper_url": "http://arxiv.org/abs/2204.14272v1", "pdf_url": "http://arxiv.org/pdf/2204.14272v1", "repo_url": null}, "2204.14268": {"publish_time": "2022-04-29", "title": "How Robust is Neural Machine Translation to Language Imbalance in Multilingual Tokenizer Training?", "author": "Shiyue Zhang et.al.", "abstract": "A multilingual tokenizer is a fundamental component of multilingual neural machine translation. It is trained from a multilingual corpus. Since a skewed data distribution is considered to be harmful, a sampling strategy is usually used to balance languages in the corpus. However, few works have systematically answered how language imbalance in tokenizer training affects downstream performance. In this work, we analyze how translation performance changes as the data ratios among languages vary in the tokenizer training corpus. We find that while relatively better performance is often observed when languages are more equally sampled, the downstream performance is more robust to language imbalance than we usually expected. Two features, UNK rate and closeness to the character level, can warn of poor downstream performance before performing the task. We also distinguish language sampling for tokenizer training from sampling for model training and show that the model is more sensitive to the latter.", "paper_url": "http://arxiv.org/abs/2204.14268v1", "pdf_url": "http://arxiv.org/pdf/2204.14268v1", "repo_url": null}, "2204.14264": {"publish_time": "2022-04-29", "title": "Polyglot Prompt: Multilingual Multitask PrompTraining", "author": "Jinlan Fu et.al.", "abstract": "This paper aims for a potential architectural breakthrough for multilingual learning and asks: could different tasks from different languages be modeled in a monolithic framework (without any task/language-specific module)? The benefit of achieving this is not only that systems trained on low resources scenario can be assisted by more other languages and tasks, but opening new doors for future multilingual research. We approach this goal by developing a learning framework Polyglot Prompt, where prompting methods are introduced to learn a unified semantic space for different languages and tasks after proper multilingual prompt engineering. Experimentally, we perform a comprehensive evaluation on 6 tasks (topic classification, sentiment classification, named entity recognition, question answering, natural language inference, summarization), 24 datasets, and 49 languages, which shows the efficacy of multilingual multitask prompting training and suggests several interesting observations. e.g., English prompts are polyglots since directly applying them to task samples in other languages could result in a better improvement. We also present an interpretable multilingual evaluation methodology and show how the proposed framework, multilingual multitask prompt training, works. We release all datasets prompted in the best setting and will release our code soon.", "paper_url": "http://arxiv.org/abs/2204.14264v1", "pdf_url": "http://arxiv.org/pdf/2204.14264v1", "repo_url": null}, "2204.14256": {"publish_time": "2022-04-29", "title": "Handling and Presenting Harmful Text", "author": "Leon Derczynski et.al.", "abstract": "Textual data can pose a risk of serious harm. These harms can be categorised along three axes: (1) the harm type (e.g. misinformation, hate speech or racial stereotypes) (2) whether it is \\textit{elicited} as a feature of the research design from directly studying harmful content (e.g. training a hate speech classifier or auditing unfiltered large-scale datasets) versus \\textit{spuriously} invoked from working on unrelated problems (e.g. language generation or part of speech tagging) but with datasets that nonetheless contain harmful content, and (3) who it affects, from the humans (mis)represented in the data to those handling or labelling the data to readers and reviewers of publications produced from the data. It is an unsolved problem in NLP as to how textual harms should be handled, presented, and discussed; but, stopping work on content which poses a risk of harm is untenable. Accordingly, we provide practical advice and introduce \\textsc{HarmCheck}, a resource for reflecting on research into textual harms. We hope our work encourages ethical, responsible, and respectful research in the NLP community.", "paper_url": "http://arxiv.org/abs/2204.14256v1", "pdf_url": "http://arxiv.org/pdf/2204.14256v1", "repo_url": null}, "2204.14243": {"publish_time": "2022-04-29", "title": "Training Naturalized Semantic Parsers with Very Little Data", "author": "Subendhu Rongali et.al.", "abstract": "Semantic parsing is an important NLP problem, particularly for voice assistants such as Alexa and Google Assistant. State-of-the-art (SOTA) semantic parsers are seq2seq architectures based on large language models that have been pretrained on vast amounts of text. To better leverage that pretraining, recent work has explored a reformulation of semantic parsing whereby the output sequences are themselves natural language sentences, but in a controlled fragment of natural language. This approach delivers strong results, particularly for few-shot semantic parsing, which is of key importance in practice and the focus of our paper. We push this line of work forward by introducing an automated methodology that delivers very significant additional improvements by utilizing modest amounts of unannotated data, which is typically easy to obtain. Our method is based on a novel synthesis of four techniques: joint training with auxiliary unsupervised tasks; constrained decoding; self-training; and paraphrasing. We show that this method delivers new SOTA few-shot performance on the Overnight dataset, particularly in very low-resource settings, and very compelling few-shot results on a new semantic parsing dataset.", "paper_url": "http://arxiv.org/abs/2204.14243v1", "pdf_url": "http://arxiv.org/pdf/2204.14243v1", "repo_url": null}, "2205.01086": {"publish_time": "2022-05-02", "title": "Wav2Seq: Pre-training Speech-to-Text Encoder-Decoder Models Using Pseudo Languages", "author": "Felix Wu et.al.", "abstract": "We introduce Wav2Seq, the first self-supervised approach to pre-train both parts of encoder-decoder models for speech data. We induce a pseudo language as a compact discrete representation, and formulate a self-supervised pseudo speech recognition task -- transcribing audio inputs into pseudo subword sequences. This process stands on its own, or can be applied as low-cost second-stage pre-training. We experiment with automatic speech recognition (ASR), spoken named entity recognition, and speech-to-text translation. We set new state-of-the-art results for end-to-end spoken named entity recognition, and show consistent improvements on 20 language pairs for speech-to-text translation, even when competing methods use additional text data for training. Finally, on ASR, our approach enables encoder-decoder methods to benefit from pre-training for all parts of the network, and shows comparable performance to highly optimized recent methods.", "paper_url": "http://arxiv.org/abs/2205.01086v1", "pdf_url": "http://arxiv.org/pdf/2205.01086v1", "repo_url": null}, "2205.01068": {"publish_time": "2022-05-02", "title": "OPT: Open Pre-trained Transformer Language Models", "author": "Susan Zhang et.al.", "abstract": "Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.", "paper_url": "http://arxiv.org/abs/2205.01068v1", "pdf_url": "http://arxiv.org/pdf/2205.01068v1", "repo_url": "https://github.com/facebookresearch/metaseq"}, "2205.01005": {"publish_time": "2022-05-02", "title": "What Factors Should Paper-Reviewer Assignments Rely On? Community Perspectives on Issues and Ideals in Conference Peer-Review", "author": "Terne Sasha Thorn Jakobsen et.al.", "abstract": "Both scientific progress and individual researcher careers depend on the quality of peer review, which in turn depends on paper-reviewer matching. Surprisingly, this problem has been mostly approached as an automated recommendation problem rather than as a matter where different stakeholders (area chairs, reviewers, authors) have accumulated experience worth taking into account. We present the results of the first survey of the NLP community, identifying common issues and perspectives on what factors should be considered by paper-reviewer matching systems. This study contributes actionable recommendations for improving future NLP conferences, and desiderata for interpretable peer review assignments.", "paper_url": "http://arxiv.org/abs/2205.01005v1", "pdf_url": "http://arxiv.org/pdf/2205.01005v1", "repo_url": null}, "2205.00978": {"publish_time": "2022-05-02", "title": "Quality-Aware Decoding for Neural Machine Translation", "author": "Patrick Fernandes et.al.", "abstract": "Despite the progress in machine translation quality estimation and evaluation in the last years, decoding in neural machine translation (NMT) is mostly oblivious to this and centers around finding the most probable translation according to the model (MAP decoding), approximated with beam search. In this paper, we bring together these two lines of research and propose quality-aware decoding for NMT, by leveraging recent breakthroughs in reference-free and reference-based MT evaluation through various inference methods like $N$-best reranking and minimum Bayes risk decoding. We perform an extensive comparison of various possible candidate generation and ranking methods across four datasets and two model classes and find that quality-aware decoding consistently outperforms MAP-based decoding according both to state-of-the-art automatic metrics (COMET and BLEURT) and to human assessments. Our code is available at https://github.com/deep-spin/qaware-decode.", "paper_url": "http://arxiv.org/abs/2205.00978v1", "pdf_url": "http://arxiv.org/pdf/2205.00978v1", "repo_url": "https://github.com/deep-spin/qaware-decode"}, "2205.00965": {"publish_time": "2022-05-02", "title": "State-of-the-art in Open-domain Conversational AI: A Survey", "author": "Tosin Adewumi et.al.", "abstract": "We survey SoTA open-domain conversational AI models with the purpose of presenting the prevailing challenges that still exist to spur future research. In addition, we provide statistics on the gender of conversational AI in order to guide the ethics discussion surrounding the issue. Open-domain conversational AI are known to have several challenges, including bland responses and performance degradation when prompted with figurative language, among others. First, we provide some background by discussing some topics of interest in conversational AI. We then discuss the method applied to the two investigations carried out that make up this study. The first investigation involves a search for recent SoTA open-domain conversational AI models while the second involves the search for 100 conversational AI to assess their gender. Results of the survey show that progress has been made with recent SoTA conversational AI, but there are still persistent challenges that need to be solved, and the female gender is more common than the male for conversational AI. One main take-away is that hybrid models of conversational AI offer more advantages than any single architecture. The key contributions of this survey are 1) the identification of prevailing challenges in SoTA open-domain conversational AI, 2) the unusual discussion about open-domain conversational AI for low-resource languages, and 3) the discussion about the ethics surrounding the gender of conversational AI.", "paper_url": "http://arxiv.org/abs/2205.00965v1", "pdf_url": "http://arxiv.org/pdf/2205.00965v1", "repo_url": null}, "2205.01663": {"publish_time": "2022-05-03", "title": "Adversarial Training for High-Stakes Reliability", "author": "Daniel M. Ziegler et.al.", "abstract": "In the future, powerful AI systems may be deployed in high-stakes settings, where a single failure could be catastrophic. One technique for improving AI safety in high-stakes settings is adversarial training, which uses an adversary to generate examples to train on in order to achieve better worst-case performance.   In this work, we used a language generation task as a testbed for achieving high reliability through adversarial training. We created a series of adversarial training techniques -- including a tool that assists human adversaries -- to find and eliminate failures in a classifier that filters text completions suggested by a generator. In our simple \"avoid injuries\" task, we determined that we can set very conservative classifier thresholds without significantly impacting the quality of the filtered outputs. With our chosen thresholds, filtering with our baseline classifier decreases the rate of unsafe completions from about 2.4% to 0.003% on in-distribution data, which is near the limit of our ability to measure. We found that adversarial training significantly increased robustness to the adversarial attacks that we trained on, without affecting in-distribution performance. We hope to see further work in the high-stakes reliability setting, including more powerful tools for enhancing human adversaries and better ways to measure high levels of reliability, until we can confidently rule out the possibility of catastrophic deployment-time failures of powerful models.", "paper_url": "http://arxiv.org/abs/2205.01663v1", "pdf_url": "http://arxiv.org/pdf/2205.01663v1", "repo_url": null}, "2205.01620": {"publish_time": "2022-05-03", "title": "OmniKnight: Multilingual Neural Machine Translation with Language-Specific Self-Distillation", "author": "Yichong Huang et.al.", "abstract": "Although all-in-one-model multilingual neural machine translation (MNMT) has achieved remarkable progress in recent years, its selected best overall checkpoint fails to achieve the best performance simultaneously in all language pairs. It is because that the best checkpoints for each individual language pair (i.e., language-specific best checkpoints) scatter in different epochs. In this paper, we present a novel training strategy dubbed Language-Specific Self-Distillation (LSSD) for bridging the gap between language-specific best checkpoints and the overall best checkpoint. In detail, we regard each language-specific best checkpoint as a teacher to distill the overall best checkpoint. Moreover, we systematically explore three variants of our LSSD, which perform distillation statically, selectively, and adaptively. Experimental results on two widely-used benchmarks show that LSSD obtains consistent improvements towards all language pairs and achieves the state-of-the-art", "paper_url": "http://arxiv.org/abs/2205.01620v1", "pdf_url": "http://arxiv.org/pdf/2205.01620v1", "repo_url": null}, "2205.01603": {"publish_time": "2022-05-03", "title": "CTM -- A Model for Large-Scale Multi-View Tweet Topic Classification", "author": "Vivek Kulkarni et.al.", "abstract": "Automatically associating social media posts with topics is an important prerequisite for effective search and recommendation on many social media platforms. However, topic classification of such posts is quite challenging because of (a) a large topic space (b) short text with weak topical cues, and (c) multiple topic associations per post. In contrast to most prior work which only focuses on post classification into a small number of topics ($10$-$20$), we consider the task of large-scale topic classification in the context of Twitter where the topic space is $10$ times larger with potentially multiple topic associations per Tweet. We address the challenges above by proposing a novel neural model, CTM that (a) supports a large topic space of $300$ topics and (b) takes a holistic approach to tweet content modeling -- leveraging multi-modal content, author context, and deeper semantic cues in the Tweet. Our method offers an effective way to classify Tweets into topics at scale by yielding superior performance to other approaches (a relative lift of $\\mathbf{20}\\%$ in median average precision score) and has been successfully deployed in production at Twitter.", "paper_url": "http://arxiv.org/abs/2205.01603v1", "pdf_url": "http://arxiv.org/pdf/2205.01603v1", "repo_url": null}, "2205.01600": {"publish_time": "2022-05-03", "title": "A Comparison of Approaches for Imbalanced Classification Problems in the Context of Retrieving Relevant Documents for an Analysis", "author": "Sandra Wankm\u00fcller et.al.", "abstract": "One of the first steps in many text-based social science studies is to retrieve documents that are relevant for the analysis from large corpora of otherwise irrelevant documents. The conventional approach in social science to address this retrieval task is to apply a set of keywords and to consider those documents to be relevant that contain at least one of the keywords. But the application of incomplete keyword lists risks drawing biased inferences. More complex and costly methods such as query expansion techniques, topic model-based classification rules, and active as well as passive supervised learning could have the potential to more accurately separate relevant from irrelevant documents and thereby reduce the potential size of bias. Yet, whether applying these more expensive approaches increases retrieval performance compared to keyword lists at all, and if so, by how much, is unclear as a comparison of these approaches is lacking. This study closes this gap by comparing these methods across three retrieval tasks associated with a data set of German tweets (Linder, 2017), the Social Bias Inference Corpus (SBIC) (Sap et al., 2020), and the Reuters-21578 corpus (Lewis, 1997). Results show that query expansion techniques and topic model-based classification rules in most studied settings tend to decrease rather than increase retrieval performance. Active supervised learning, however, if applied on a not too small set of labeled training instances (e.g. 1,000 documents), reaches a substantially higher retrieval performance than keyword lists.", "paper_url": "http://arxiv.org/abs/2205.01600v1", "pdf_url": "http://arxiv.org/pdf/2205.01600v1", "repo_url": null}, "2205.01588": {"publish_time": "2022-05-03", "title": "SparCAssist: A Model Risk Assessment Assistant Based on Sparse Generated Counterfactuals", "author": "Zijian Zhang et.al.", "abstract": "We introduce SparcAssist, a general-purpose risk assessment tool for the machine learning models trained for language tasks. It evaluates models' risk by inspecting their behavior on counterfactuals, namely out-of-distribution instances generated based on the given data instance. The counterfactuals are generated by replacing tokens in rational subsequences identified by ExPred, while the replacements are retrieved using HotFlip or Masked-Language-Model-based algorithms. The main purpose of our system is to help the human annotators to assess the model's risk on deployment. The counterfactual instances generated during the assessment are the by-product and can be used to train more robust NLP models in the future.", "paper_url": "http://arxiv.org/abs/2205.01588v1", "pdf_url": "http://arxiv.org/pdf/2205.01588v1", "repo_url": null}, "2205.02225": {"publish_time": "2022-05-04", "title": "HiURE: Hierarchical Exemplar Contrastive Learning for Unsupervised Relation Extraction", "author": "Shuliang Liu et.al.", "abstract": "Unsupervised relation extraction aims to extract the relationship between entities from natural language sentences without prior information on relational scope or distribution. Existing works either utilize self-supervised schemes to refine relational feature signals by iteratively leveraging adaptive clustering and classification that provoke gradual drift problems, or adopt instance-wise contrastive learning which unreasonably pushes apart those sentence pairs that are semantically similar. To overcome these defects, we propose a novel contrastive learning framework named HiURE, which has the capability to derive hierarchical signals from relational feature space using cross hierarchy attention and effectively optimize relation representation of sentences under exemplar-wise contrastive learning. Experimental results on two public datasets demonstrate the advanced effectiveness and robustness of HiURE on unsupervised relation extraction when compared with state-of-the-art models.", "paper_url": "http://arxiv.org/abs/2205.02225v1", "pdf_url": "http://arxiv.org/pdf/2205.02225v1", "repo_url": null}, "2205.02223": {"publish_time": "2022-05-04", "title": "Semi-supervised learning approaches for predicting South African political sentiment for local government elections", "author": "Mashadi Ledwaba et.al.", "abstract": "This study aims to understand the South African political context by analysing the sentiments shared on Twitter during the local government elections. An emphasis on the analysis was placed on understanding the discussions led around four predominant political parties ANC, DA, EFF and ActionSA. A semi-supervised approach by means of a graph-based technique to label the vast accessible Twitter data for the classification of tweets into negative and positive sentiment was used. The tweets expressing negative sentiment were further analysed through latent topic extraction to uncover hidden topics of concern associated with each of the political parties. Our findings demonstrated that the general sentiment across South African Twitter users is negative towards all four predominant parties with the worst negative sentiment among users projected towards the current ruling party, ANC, relating to concerns cantered around corruption, incompetence and loadshedding.", "paper_url": "http://arxiv.org/abs/2205.02223v1", "pdf_url": "http://arxiv.org/pdf/2205.02223v1", "repo_url": null}, "2205.02211": {"publish_time": "2022-05-04", "title": "User-Centric Gender Rewriting", "author": "Bashar Alhafni et.al.", "abstract": "In this paper, we define the task of gender rewriting in contexts involving two users (I and/or You) - first and second grammatical persons with independent grammatical gender preferences. We focus on Arabic, a gender-marking morphologically rich language. We develop a multi-step system that combines the positive aspects of both rule-based and neural rewriting models. Our results successfully demonstrate the viability of this approach on a recently created corpus for Arabic gender rewriting, achieving 88.42 M2 F0.5 on a blind test set. Our proposed system improves over previous work on the first-person-only version of this task, by 3.05 absolute increase in M2 F0.5. We demonstrate a use case of our gender rewriting system by using it to post-edit the output of a commercial MT system to provide personalized outputs based on the users' grammatical gender preferences. We make our code, data, and models publicly available.", "paper_url": "http://arxiv.org/abs/2205.02211v1", "pdf_url": "http://arxiv.org/pdf/2205.02211v1", "repo_url": "https://github.com/camel-lab/gender-rewriting"}, "2205.02182": {"publish_time": "2022-05-04", "title": "Reproducibility Beyond the Research Community: Experience from NLP Beginners", "author": "Shane Storks et.al.", "abstract": "As NLP research attracts public attention and excitement, it becomes increasingly important for it to be accessible to a broad audience. As the research community works to democratize NLP, it remains unclear whether beginners to the field can easily apply the latest developments. To understand their needs, we conducted a study with 93 students in an introductory NLP course, where students reproduced results of recent NLP papers. Surprisingly, our results suggest that their technical skill (i.e., programming experience) has limited impact on their effort spent completing the exercise. Instead, we find accessibility efforts by research authors to be key to a successful experience, including thorough documentation and easy access to required models and datasets.", "paper_url": "http://arxiv.org/abs/2205.02182v1", "pdf_url": "http://arxiv.org/pdf/2205.02182v1", "repo_url": null}, "2205.02172": {"publish_time": "2022-05-04", "title": "Using virtual edges to extract keywords from texts modeled as complex networks", "author": "Jorge A. V. Tohalino et.al.", "abstract": "Detecting keywords in texts is important for many text mining applications. Graph-based methods have been commonly used to automatically find the key concepts in texts, however, relevant information provided by embeddings has not been widely used to enrich the graph structure. Here we modeled texts co-occurrence networks, where nodes are words and edges are established either by contextual or semantical similarity. We compared two embedding approaches -- Word2vec and BERT -- to check whether edges created via word embeddings can improve the quality of the keyword extraction method. We found that, in fact, the use of virtual edges can improve the discriminability of co-occurrence networks. The best performance was obtained when we considered low percentages of addition of virtual (embedding) edges. A comparative analysis of structural and dynamical network metrics revealed the degree, PageRank, and accessibility are the metrics displaying the best performance in the model enriched with virtual edges.", "paper_url": "http://arxiv.org/abs/2205.02172v1", "pdf_url": "http://arxiv.org/pdf/2205.02172v1", "repo_url": null}, "2205.02832": {"publish_time": "2022-05-05", "title": "Entity Cloze By Date: What LMs Know About Unseen Entities", "author": "Yasumasa Onoe et.al.", "abstract": "Language models (LMs) are typically trained once on a large-scale corpus and used for years without being updated. However, in a dynamic world, new entities constantly arise. We propose a framework to analyze what LMs can infer about new entities that did not exist when the LMs were pretrained. We derive a dataset of entities indexed by their origination date and paired with their English Wikipedia articles, from which we can find sentences about each entity. We evaluate LMs' perplexity on masked spans within these sentences. We show that models more informed about the entities, such as those with access to a textual definition of them, achieve lower perplexity on this benchmark. Our experimental results demonstrate that making inferences about new entities remains difficult for LMs. Given its wide coverage on entity knowledge and temporal indexing, our dataset can be used to evaluate LMs and techniques designed to modify or extend their knowledge. Our automatic data collection pipeline can be easily used to continually update our benchmark.", "paper_url": "http://arxiv.org/abs/2205.02832v1", "pdf_url": "http://arxiv.org/pdf/2205.02832v1", "repo_url": null}, "2205.02795": {"publish_time": "2022-05-05", "title": "Diversifying Neural Dialogue Generation via Negative Distillation", "author": "Yiwei Li et.al.", "abstract": "Generative dialogue models suffer badly from the generic response problem, limiting their applications to a few toy scenarios. Recently, an interesting approach, namely negative training, has been proposed to alleviate this problem by reminding the model not to generate high-frequency responses during training. However, its performance is hindered by two issues, ignoring low-frequency but generic responses and bringing low-frequency but meaningless responses. In this paper, we propose a novel negative training paradigm, called negative distillation, to keep the model away from the undesirable generic responses while avoiding the above problems. First, we introduce a negative teacher model that can produce query-wise generic responses, and then the student model is required to maximize the distance with multi-level negative knowledge. Empirical results show that our method outperforms previous negative training methods significantly.", "paper_url": "http://arxiv.org/abs/2205.02795v1", "pdf_url": "http://arxiv.org/pdf/2205.02795v1", "repo_url": null}, "2205.02728": {"publish_time": "2022-05-05", "title": "CATs are Fuzzy PETs: A Corpus and Analysis of Potentially Euphemistic Terms", "author": "Martha Gavidia et.al.", "abstract": "Euphemisms have not received much attention in natural language processing, despite being an important element of polite and figurative language. Euphemisms prove to be a difficult topic, not only because they are subject to language change, but also because humans may not agree on what is a euphemism and what is not. Nevertheless, the first step to tackling the issue is to collect and analyze examples of euphemisms. We present a corpus of potentially euphemistic terms (PETs) along with example texts from the GloWbE corpus. Additionally, we present a subcorpus of texts where these PETs are not being used euphemistically, which may be useful for future applications. We also discuss the results of multiple analyses run on the corpus. Firstly, we find that sentiment analysis on the euphemistic texts supports that PETs generally decrease negative and offensive sentiment. Secondly, we observe cases of disagreement in an annotation task, where humans are asked to label PETs as euphemistic or not in a subset of our corpus text examples. We attribute the disagreement to a variety of potential reasons, including if the PET was a commonly accepted term (CAT).", "paper_url": "http://arxiv.org/abs/2205.02728v1", "pdf_url": "http://arxiv.org/pdf/2205.02728v1", "repo_url": null}, "2205.02724": {"publish_time": "2022-05-05", "title": "Implicit N-grams Induced by Recurrence", "author": "Xiaobing Sun et.al.", "abstract": "Although self-attention based models such as Transformers have achieved remarkable successes on natural language processing (NLP) tasks, recent studies reveal that they have limitations on modeling sequential transformations (Hahn, 2020), which may prompt re-examinations of recurrent neural networks (RNNs) that demonstrated impressive results on handling sequential data. Despite many prior attempts to interpret RNNs, their internal mechanisms have not been fully understood, and the question on how exactly they capture sequential features remains largely unclear. In this work, we present a study that shows there actually exist some explainable components that reside within the hidden states, which are reminiscent of the classical n-grams features. We evaluated such extracted explainable features from trained RNNs on downstream sentiment analysis tasks and found they could be used to model interesting linguistic phenomena such as negation and intensification. Furthermore, we examined the efficacy of using such n-gram components alone as encoders on tasks such as sentiment analysis and language modeling, revealing they could be playing important roles in contributing to the overall performance of RNNs. We hope our findings could add interpretability to RNN architectures, and also provide inspirations for proposing new architectures for sequential data.", "paper_url": "http://arxiv.org/abs/2205.02724v1", "pdf_url": "http://arxiv.org/pdf/2205.02724v1", "repo_url": "https://github.com/richardsun-voyager/inibr"}, "2205.02694": {"publish_time": "2022-05-05", "title": "Quantifying Language Variation Acoustically with Few Resources", "author": "Martijn Bartelds et.al.", "abstract": "Deep acoustic models represent linguistic information based on massive amounts of data. Unfortunately, for regional languages and dialects such resources are mostly not available. However, deep acoustic models might have learned linguistic information that transfers to low-resource languages. In this study, we evaluate whether this is the case through the task of distinguishing low-resource (Dutch) regional varieties. By extracting embeddings from the hidden layers of various wav2vec 2.0 models (including new models which are pre-trained and/or fine-tuned on Dutch) and using dynamic time warping, we compute pairwise pronunciation differences averaged over 10 words for over 100 individual dialects from four (regional) languages. We then cluster the resulting difference matrix in four groups and compare these to a gold standard, and a partitioning on the basis of comparing phonetic transcriptions. Our results show that acoustic models outperform the (traditional) transcription-based approach without requiring phonetic transcriptions, with the best performance achieved by the multilingual XLSR-53 model fine-tuned on Dutch. On the basis of only six seconds of speech, the resulting clustering closely matches the gold standard.", "paper_url": "http://arxiv.org/abs/2205.02694v1", "pdf_url": "http://arxiv.org/pdf/2205.02694v1", "repo_url": "https://github.com/bartelds/language-variation"}, "2205.03403": {"publish_time": "2022-05-06", "title": "A Data Cartography based MixUp for Pre-trained Language Models", "author": "Seo Yeon Park et.al.", "abstract": "MixUp is a data augmentation strategy where additional samples are generated during training by combining random pairs of training samples and their labels. However, selecting random pairs is not potentially an optimal choice. In this work, we propose TDMixUp, a novel MixUp strategy that leverages Training Dynamics and allows more informative samples to be combined for generating new data samples. Our proposed TDMixUp first measures confidence, variability, (Swayamdipta et al., 2020), and Area Under the Margin (AUM) (Pleiss et al., 2020) to identify the characteristics of training samples (e.g., as easy-to-learn or ambiguous samples), and then interpolates these characterized samples. We empirically validate that our method not only achieves competitive performance using a smaller subset of the training data compared with strong baselines, but also yields lower expected calibration error on the pre-trained language model, BERT, on both in-domain and out-of-domain settings in a wide range of NLP tasks. We publicly release our code.", "paper_url": "http://arxiv.org/abs/2205.03403v1", "pdf_url": "http://arxiv.org/pdf/2205.03403v1", "repo_url": "https://github.com/seoyeon-p/tdmixup"}, "2205.03401": {"publish_time": "2022-05-06", "title": "The Unreliability of Explanations in Few-Shot In-Context Learning", "author": "Xi Ye et.al.", "abstract": "How can prompting a large language model like GPT-3 with explanations improve in-context learning? We focus specifically on two NLP tasks that involve reasoning over text, namely question answering and natural language inference. Including explanations in the prompt and having the model generate them does not consistently improve performance in the settings we study, contrary to recent results on symbolic reasoning tasks (Nye et al., 2021; Wei et al., 2022). Despite careful prompting, explanations generated by GPT-3 may not even be factually grounded in the input, even on simple tasks with straightforward extractive explanations. However, these flawed explanations can still be useful as a way to verify GPT-3's predictions post-hoc. Through analysis in three settings, we show that explanations judged as good by humans--those that are logically consistent with the input and the prediction--usually indicate more accurate predictions. Following these observations, we present a framework for calibrating model predictions based on the reliability of the explanations. Our framework trains calibrators using automatically extracted scores that approximately assess the reliability of explanations, which helps improve performance across three different datasets.", "paper_url": "http://arxiv.org/abs/2205.03401v1", "pdf_url": "http://arxiv.org/pdf/2205.03401v1", "repo_url": null}, "2205.03369": {"publish_time": "2022-05-06", "title": "Quantifying Synthesis and Fusion and their Impact on Machine Translation", "author": "Arturo Oncevay et.al.", "abstract": "Theoretical work in morphological typology offers the possibility of measuring morphological diversity on a continuous scale. However, literature in Natural Language Processing (NLP) typically labels a whole language with a strict type of morphology, e.g. fusional or agglutinative. In this work, we propose to reduce the rigidity of such claims, by quantifying morphological typology at the word and segment level. We consider Payne (2017)'s approach to classify morphology using two indices: synthesis (e.g. analytic to polysynthetic) and fusion (agglutinative to fusional). For computing synthesis, we test unsupervised and supervised morphological segmentation methods for English, German and Turkish, whereas for fusion, we propose a semi-automatic method using Spanish as a case study. Then, we analyse the relationship between machine translation quality and the degree of synthesis and fusion at word (nouns and verbs for English-Turkish, and verbs in English-Spanish) and segment level (previous language pairs plus English-German in both directions). We complement the word-level analysis with human evaluation, and overall, we observe a consistent impact of both indexes on machine translation quality.", "paper_url": "http://arxiv.org/abs/2205.03369v1", "pdf_url": "http://arxiv.org/pdf/2205.03369v1", "repo_url": null}, "2205.03314": {"publish_time": "2022-05-06", "title": "Example-Based Machine Translation from Text to a Hierarchical Representation of Sign Language", "author": "\u00c9lise Bertin-Lem\u00e9e et.al.", "abstract": "This article presents an original method for Text-to-Sign Translation. It compensates data scarcity using a domain-specific parallel corpus of alignments between text and hierarchical formal descriptions of Sign Language videos in AZee. Based on the detection of similarities present in the source text, the proposed algorithm recursively exploits matches and substitutions of aligned segments to build multiple candidate translations for a novel statement. This helps preserving Sign Language structures as much as possible before falling back on literal translations too quickly, in a generative way. The resulting translations are in the form of AZee expressions, designed to be used as input to avatar synthesis systems. We present a test set tailored to showcase its potential for expressiveness and generation of idiomatic target language, and observed limitations. This work finally opens prospects on how to evaluate translation and linguistic aspects, such as accuracy and grammatical fluency.", "paper_url": "http://arxiv.org/abs/2205.03314v1", "pdf_url": "http://arxiv.org/pdf/2205.03314v1", "repo_url": null}, "2205.03313": {"publish_time": "2022-05-06", "title": "Combining Humor and Sarcasm for Improving Political Parody Detection", "author": "Xiao Ao et.al.", "abstract": "Parody is a figurative device used for mimicking entities for comedic or critical purposes. Parody is intentionally humorous and often involves sarcasm. This paper explores jointly modelling these figurative tropes with the goal of improving performance of political parody detection in tweets. To this end, we present a multi-encoder model that combines three parallel encoders to enrich parody-specific representations with humor and sarcasm information. Experiments on a publicly available data set of political parody tweets demonstrate that our approach outperforms previous state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2205.03313v1", "pdf_url": "http://arxiv.org/pdf/2205.03313v1", "repo_url": "https://github.com/iamoscar1/multi_encoder_model_for_political_parody_prediction"}, "2205.04438": {"publish_time": "2022-05-09", "title": "BLINK with Elasticsearch for Efficient Entity Linking in Business Conversations", "author": "Md Tahmid Rahman Laskar et.al.", "abstract": "An Entity Linking system aligns the textual mentions of entities in a text to their corresponding entries in a knowledge base. However, deploying a neural entity linking system for efficient real-time inference in production environments is a challenging task. In this work, we present a neural entity linking system that connects the product and organization type entities in business conversations to their corresponding Wikipedia and Wikidata entries. The proposed system leverages Elasticsearch to ensure inference efficiency when deployed in a resource limited cloud machine, and obtains significant improvements in terms of inference speed and memory consumption while retaining high accuracy.", "paper_url": "http://arxiv.org/abs/2205.04438v1", "pdf_url": "http://arxiv.org/pdf/2205.04438v1", "repo_url": null}, "2205.04421": {"publish_time": "2022-05-09", "title": "NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality", "author": "Xu Tan et.al.", "abstract": "Text to speech (TTS) has made rapid progress in both academia and industry in recent years. Some questions naturally arise that whether a TTS system can achieve human-level quality, how to define/judge human-level quality and how to achieve it. In this paper, we answer these questions by first defining human-level quality based on statistical significance of measurement and describing the guidelines to judge it, and then proposing a TTS system called NaturalSpeech that achieves human-level quality on a benchmark dataset. Specifically, we leverage a variational autoencoder (VAE) for end-to-end text to waveform generation, with several key designs to enhance the capacity of prior from text and reduce the complexity of posterior from speech, including phoneme pre-training, differentiable duration modeling, bidirectional prior/posterior modeling, and memory mechanism in VAE. Experiment evaluations on popular LJSpeech dataset show that our proposed NaturalSpeech achieves -0.01 CMOS (comparative mean opinion score) to human recordings on sentence level, with Wilcoxon signed rank test at p-level p>>0.05, which demonstrates no statistically significant difference from human recordings for the first time on this dataset.", "paper_url": "http://arxiv.org/abs/2205.04421v1", "pdf_url": "http://arxiv.org/pdf/2205.04421v1", "repo_url": null}, "2205.04404": {"publish_time": "2022-05-09", "title": "TeamX@DravidianLangTech-ACL2022: A Comparative Analysis for Troll-Based Meme Classification", "author": "Rabindra Nath Nandi et.al.", "abstract": "The spread of fake news, propaganda, misinformation, disinformation, and harmful content online raised concerns among social media platforms, government agencies, policymakers, and society as a whole. This is because such harmful or abusive content leads to several consequences to people such as physical, emotional, relational, and financial. Among different harmful content \\textit{trolling-based} online content is one of them, where the idea is to post a message that is provocative, offensive, or menacing with an intent to mislead the audience. The content can be textual, visual, a combination of both, or a meme. In this study, we provide a comparative analysis of troll-based memes classification using the textual, visual, and multimodal content. We report several interesting findings in terms of code-mixed text, multimodal setting, and combining an additional dataset, which shows improvements over the majority baseline.", "paper_url": "http://arxiv.org/abs/2205.04404v1", "pdf_url": "http://arxiv.org/pdf/2205.04404v1", "repo_url": null}, "2205.04402": {"publish_time": "2022-05-09", "title": "Detecting the Role of an Entity in Harmful Memes: Techniques and Their Limitations", "author": "Rabindra Nath Nandi et.al.", "abstract": "Harmful or abusive online content has been increasing over time, raising concerns for social media platforms, government agencies, and policymakers. Such harmful or abusive content can have major negative impact on society, e.g., cyberbullying can lead to suicides, rumors about COVID-19 can cause vaccine hesitance, promotion of fake cures for COVID-19 can cause health harms and deaths. The content that is posted and shared online can be textual, visual, or a combination of both, e.g., in a meme. Here, we describe our experiments in detecting the roles of the entities (hero, villain, victim) in harmful memes, which is part of the CONSTRAINT-2022 shared task, as well as our system for the task. We further provide a comparative analysis of different experimental settings (i.e., unimodal, multimodal, attention, and augmentation). For reproducibility, we make our experimental code publicly available. \\url{https://github.com/robi56/harmful_memes_block_fusion}", "paper_url": "http://arxiv.org/abs/2205.04402v1", "pdf_url": "http://arxiv.org/pdf/2205.04402v1", "repo_url": "https://github.com/robi56/harmful_memes_block_fusion"}, "2205.04376": {"publish_time": "2022-05-09", "title": "EigenNoise: A Contrastive Prior to Warm-Start Representations", "author": "Hunter Scott Heidenreich et.al.", "abstract": "In this work, we present a naive initialization scheme for word vectors based on a dense, independent co-occurrence model and provide preliminary results that suggest it is competitive and warrants further investigation. Specifically, we demonstrate through information-theoretic minimum description length (MDL) probing that our model, EigenNoise, can approach the performance of empirically trained GloVe despite the lack of any pre-training data (in the case of EigenNoise). We present these preliminary results with interest to set the stage for further investigations into how this competitive initialization works without pre-training data, as well as to invite the exploration of more intelligent initialization schemes informed by the theory of harmonic linguistic structure. Our application of this theory likewise contributes a novel (and effective) interpretation of recent discoveries which have elucidated the underlying distributional information that linguistic representations capture from data and contrast distributions.", "paper_url": "http://arxiv.org/abs/2205.04376v1", "pdf_url": "http://arxiv.org/pdf/2205.04376v1", "repo_url": null}, "2205.05071": {"publish_time": "2022-05-10", "title": "Towards Climate Awareness in NLP Research", "author": "Daniel Hershcovich et.al.", "abstract": "The climate impact of AI, and NLP research in particular, has become a serious issue given the enormous amount of energy that is increasingly being used for training and running computational models. Consequently, increasing focus is placed on efficient NLP. However, this important initiative lacks simple guidelines that would allow for systematic climate reporting of NLP research. We argue that this deficiency is one of the reasons why very few publications in NLP report key figures that would allow a more thorough examination of environmental impact. As a remedy, we propose a climate performance model card with the primary purpose of being practically usable with only limited information about experiments and the underlying computer hardware. We describe why this step is essential to increase awareness about the environmental impact of NLP research and, thereby, paving the way for more thorough discussions.", "paper_url": "http://arxiv.org/abs/2205.05071v1", "pdf_url": "http://arxiv.org/pdf/2205.05071v1", "repo_url": null}, "2205.05050": {"publish_time": "2022-05-10", "title": "White-box Testing of NLP models with Mask Neuron Coverage", "author": "Arshdeep Sekhon et.al.", "abstract": "Recent literature has seen growing interest in using black-box strategies like CheckList for testing the behavior of NLP models. Research on white-box testing has developed a number of methods for evaluating how thoroughly the internal behavior of deep models is tested, but they are not applicable to NLP models. We propose a set of white-box testing methods that are customized for transformer-based NLP models. These include Mask Neuron Coverage (MNCOVER) that measures how thoroughly the attention layers in models are exercised during testing. We show that MNCOVER can refine testing suites generated by CheckList by substantially reduce them in size, for more than 60\\% on average, while retaining failing tests -- thereby concentrating the fault detection power of the test suite. Further we show how MNCOVER can be used to guide CheckList input generation, evaluate alternative NLP testing methods, and drive data augmentation to improve accuracy.", "paper_url": "http://arxiv.org/abs/2205.05050v1", "pdf_url": "http://arxiv.org/pdf/2205.05050v1", "repo_url": null}, "2205.05019": {"publish_time": "2022-05-10", "title": "Learning to Answer Visual Questions from Web Videos", "author": "Antoine Yang et.al.", "abstract": "Recent methods for visual question answering rely on large-scale annotated datasets. Manual annotation of questions and answers for videos, however, is tedious, expensive and prevents scalability. In this work, we propose to avoid manual annotation and generate a large-scale training dataset for video question answering making use of automatic cross-modal supervision. We leverage a question generation transformer trained on text data and use it to generate question-answer pairs from transcribed video narrations. Given narrated videos, we then automatically generate the HowToVQA69M dataset with 69M video-question-answer triplets. To handle the open vocabulary of diverse answers in this dataset, we propose a training procedure based on a contrastive loss between a video-question multi-modal transformer and an answer transformer. We introduce the zero-shot VideoQA task and the VideoQA feature probe evaluation setting and show excellent results, in particular for rare answers. Furthermore, our method achieves competitive results on MSRVTT-QA, ActivityNet-QA, MSVD-QA and How2QA datasets. We also show that our VideoQA dataset generation approach generalizes to another source of web video and text data. We use our method to generate the \\webdataname{} dataset from the WebVid dataset, i.e., videos with alt-text annotations, and show its benefits for training VideoQA models. Finally, for a detailed evaluation we introduce \\smalldatasetname{}, a new VideoQA dataset with reduced language bias and high-quality manual annotations. Code, datasets and trained models are available at https://antoyang.github.io/just-ask.html", "paper_url": "http://arxiv.org/abs/2205.05019v1", "pdf_url": "http://arxiv.org/pdf/2205.05019v1", "repo_url": "https://github.com/antoyang/just-ask"}, "2205.04980": {"publish_time": "2022-05-10", "title": "ALLSH: Active Learning Guided by Local Sensitivity and Hardness", "author": "Shujian Zhang et.al.", "abstract": "Active learning, which effectively collects informative unlabeled data for annotation, reduces the demand for labeled data. In this work, we propose to retrieve unlabeled samples with a local sensitivity and hardness-aware acquisition function. The proposed method generates data copies through local perturbations and selects data points whose predictive likelihoods diverge the most from their copies. We further empower our acquisition function by injecting the select-worst case perturbation. Our method achieves consistent gains over the commonly used active learning strategies in various classification tasks. Furthermore, we observe consistent improvements over the baselines on the study of prompt selection in prompt-based few-shot learning. These experiments demonstrate that our acquisition guided by local sensitivity and hardness can be effective and beneficial for many NLP tasks.", "paper_url": "http://arxiv.org/abs/2205.04980v1", "pdf_url": "http://arxiv.org/pdf/2205.04980v1", "repo_url": null}, "2205.04820": {"publish_time": "2022-05-10", "title": "Bridging the prosody GAP: Genetic Algorithm with People to efficiently sample emotional prosody", "author": "Pol van Rijn et.al.", "abstract": "The human voice effectively communicates a range of emotions with nuanced variations in acoustics. Existing emotional speech corpora are limited in that they are either (a) highly curated to induce specific emotions with predefined categories that may not capture the full extent of emotional experiences, or (b) entangled in their semantic and prosodic cues, limiting the ability to study these cues separately. To overcome this challenge, we propose a new approach called 'Genetic Algorithm with People' (GAP), which integrates human decision and production into a genetic algorithm. In our design, we allow creators and raters to jointly optimize the emotional prosody over generations. We demonstrate that GAP can efficiently sample from the emotional speech space and capture a broad range of emotions, and show comparable results to state-of-the-art emotional speech corpora. GAP is language-independent and supports large crowd-sourcing, thus can support future large-scale cross-cultural research.", "paper_url": "http://arxiv.org/abs/2205.04820v1", "pdf_url": "http://arxiv.org/pdf/2205.04820v1", "repo_url": null}, "2205.05666": {"publish_time": "2022-05-11", "title": "Identifying concept libraries from language about object structure", "author": "Catherine Wong et.al.", "abstract": "Our understanding of the visual world goes beyond naming objects, encompassing our ability to parse objects into meaningful parts, attributes, and relations. In this work, we leverage natural language descriptions for a diverse set of 2K procedurally generated objects to identify the parts people use and the principles leading these parts to be favored over others. We formalize our problem as search over a space of program libraries that contain different part concepts, using tools from machine translation to evaluate how well programs expressed in each library align to human language. By combining naturalistic language at scale with structured program representations, we discover a fundamental information-theoretic tradeoff governing the part concepts people name: people favor a lexicon that allows concise descriptions of each object, while also minimizing the size of the lexicon itself.", "paper_url": "http://arxiv.org/abs/2205.05666v1", "pdf_url": "http://arxiv.org/pdf/2205.05666v1", "repo_url": null}, "2205.05656": {"publish_time": "2022-05-11", "title": "Ontology-Based and Weakly Supervised Rare Disease Phenotyping from Clinical Notes", "author": "Hang Dong et.al.", "abstract": "Computational text phenotyping is the practice of identifying patients with certain disorders and traits from clinical notes. Rare diseases are challenging to be identified due to few cases available for machine learning and the need for data annotation from domain experts. We propose a method using ontologies and weak supervision, with recent pre-trained contextual representations from Bi-directional Transformers (e.g. BERT). The ontology-based framework includes two steps: (i) Text-to-UMLS, extracting phenotypes by contextually linking mentions to concepts in Unified Medical Language System (UMLS), with a Named Entity Recognition and Linking (NER+L) tool, SemEHR, and weak supervision with customised rules and contextual mention representation; (ii) UMLS-to-ORDO, matching UMLS concepts to rare diseases in Orphanet Rare Disease Ontology (ORDO). The weakly supervised approach is proposed to learn a phenotype confirmation model to improve Text-to-UMLS linking, without annotated data from domain experts. We evaluated the approach on three clinical datasets of discharge summaries and radiology reports from two institutions in the US and the UK. Our best weakly supervised method achieved 81.4% precision and 91.4% recall on extracting rare disease UMLS phenotypes from MIMIC-III discharge summaries. The overall pipeline processing clinical notes can surface rare disease cases, mostly uncaptured in structured data (manually assigned ICD codes). Results on radiology reports from MIMIC-III and NHS Tayside were consistent with the discharge summaries. We discuss the usefulness of the weak supervision approach and propose directions for future studies.", "paper_url": "http://arxiv.org/abs/2205.05656v1", "pdf_url": "http://arxiv.org/pdf/2205.05656v1", "repo_url": null}, "2205.05646": {"publish_time": "2022-05-11", "title": "Aggregating Pairwise Semantic Differences for Few-Shot Claim Veracity Classification", "author": "Xia Zeng et.al.", "abstract": "As part of an automated fact-checking pipeline, the claim veracity classification task consists in determining if a claim is supported by an associated piece of evidence. The complexity of gathering labelled claim-evidence pairs leads to a scarcity of datasets, particularly when dealing with new domains. In this paper, we introduce SEED, a novel vector-based method to few-shot claim veracity classification that aggregates pairwise semantic differences for claim-evidence pairs. We build on the hypothesis that we can simulate class representative vectors that capture average semantic differences for claim-evidence pairs in a class, which can then be used for classification of new instances. We compare the performance of our method with competitive baselines including fine-tuned BERT/RoBERTa models, as well as the state-of-the-art few-shot veracity classification method that leverages language model perplexity. Experiments conducted on the FEVER and SCIFACT datasets show consistent improvements over competitive baselines in few-shot settings. Our code is available.", "paper_url": "http://arxiv.org/abs/2205.05646v1", "pdf_url": "http://arxiv.org/pdf/2205.05646v1", "repo_url": null}, "2205.05638": {"publish_time": "2022-05-11", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning", "author": "Haokun Liu et.al.", "abstract": "Few-shot in-context learning (ICL) enables pre-trained language models to perform a previously-unseen task without any gradient-based training by feeding a small number of training examples as part of the input. ICL incurs substantial computational, memory, and storage costs because it involves processing all of the training examples every time a prediction is made. Parameter-efficient fine-tuning (e.g. adapter modules, prompt tuning, sparse update methods, etc.) offers an alternative paradigm where a small set of parameters are trained to enable a model to perform the new task. In this paper, we rigorously compare few-shot ICL and parameter-efficient fine-tuning and demonstrate that the latter offers better accuracy as well as dramatically lower computational costs. Along the way, we introduce a new parameter-efficient fine-tuning method called (IA)$^3$ that scales activations by learned vectors, attaining stronger performance while only introducing a relatively tiny amount of new parameters. We also propose a simple recipe based on the T0 model called T-Few that can be applied to new tasks without task-specific tuning or modifications. We validate the effectiveness of T-Few on completely unseen tasks by applying it to the RAFT benchmark, attaining super-human performance for the first time and outperforming the state-of-the-art by 6% absolute. All of the code used in our experiments is publicly available.", "paper_url": "http://arxiv.org/abs/2205.05638v1", "pdf_url": "http://arxiv.org/pdf/2205.05638v1", "repo_url": null}, "2205.05593": {"publish_time": "2022-05-11", "title": "Identifying Moments of Change from Longitudinal User Text", "author": "Adam Tsakalidis et.al.", "abstract": "Identifying changes in individuals' behaviour and mood, as observed via content shared on online platforms, is increasingly gaining importance. Most research to-date on this topic focuses on either: (a) identifying individuals at risk or with a certain mental health condition given a batch of posts or (b) providing equivalent labels at the post level. A disadvantage of such work is the lack of a strong temporal component and the inability to make longitudinal assessments following an individual's trajectory and allowing timely interventions. Here we define a new task, that of identifying moments of change in individuals on the basis of their shared content online. The changes we consider are sudden shifts in mood (switches) or gradual mood progression (escalations). We have created detailed guidelines for capturing moments of change and a corpus of 500 manually annotated user timelines (18.7K posts). We have developed a variety of baseline models drawing inspiration from related tasks and show that the best performance is obtained through context aware sequential modelling. We also introduce new metrics for capturing rare events in temporal windows.", "paper_url": "http://arxiv.org/abs/2205.05593v1", "pdf_url": "http://arxiv.org/pdf/2205.05593v1", "repo_url": null}, "2205.06266": {"publish_time": "2022-05-12", "title": "Lifting the Curse of Multilinguality by Pre-training Modular Transformers", "author": "Jonas Pfeiffer et.al.", "abstract": "Multilingual pre-trained models are known to suffer from the curse of multilinguality, which causes per-language performance to drop as they cover more languages. We address this issue by introducing language-specific modules, which allows us to grow the total capacity of the model, while keeping the total number of trainable parameters per language constant. In contrast with prior work that learns language-specific components post-hoc, we pre-train the modules of our Cross-lingual Modular (X-Mod) models from the start. Our experiments on natural language inference, named entity recognition and question answering show that our approach not only mitigates the negative interference between languages, but also enables positive transfer, resulting in improved monolingual and cross-lingual performance. Furthermore, our approach enables adding languages post-hoc with no measurable drop in performance, no longer limiting the model usage to the set of pre-trained languages.", "paper_url": "http://arxiv.org/abs/2205.06266v1", "pdf_url": "http://arxiv.org/pdf/2205.06266v1", "repo_url": null}, "2205.06262": {"publish_time": "2022-05-12", "title": "FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue", "author": "Alon Albalak et.al.", "abstract": "Task transfer, transferring knowledge contained in related tasks, holds the promise of reducing the quantity of labeled data required to fine-tune language models. Dialogue understanding encompasses many diverse tasks, yet task transfer has not been thoroughly studied in conversational AI. This work explores conversational task transfer by introducing FETA: a benchmark for few-sample task transfer in open-domain dialogue. FETA contains two underlying sets of conversations upon which there are 10 and 7 tasks annotated, enabling the study of intra-dataset task transfer; task transfer without domain adaptation. We utilize three popular language models and three learning algorithms to analyze the transferability between 132 source-target task pairs and create a baseline for future work. We run experiments in the single- and multi-source settings and report valuable findings, e.g., most performance trends are model-specific, and span extraction and multiple-choice tasks benefit the most from task transfer. In addition to task transfer, FETA can be a valuable resource for future research into the efficiency and generalizability of pre-training datasets and model architectures, as well as for learning settings such as continual and multitask learning.", "paper_url": "http://arxiv.org/abs/2205.06262v1", "pdf_url": "http://arxiv.org/pdf/2205.06262v1", "repo_url": "https://github.com/alon-albalak/tlidb"}, "2205.06253": {"publish_time": "2022-05-12", "title": "What's in a Caption? Dataset-Specific Linguistic Diversity and Its Effect on Visual Description Models and Metrics", "author": "David M. Chan et.al.", "abstract": "While there have been significant gains in the field of automated video description, the generalization performance of automated description models to novel domains remains a major barrier to using these systems in the real world. Most visual description methods are known to capture and exploit patterns in the training data leading to evaluation metric increases, but what are those patterns? In this work, we examine several popular visual description datasets, and capture, analyze, and understand the dataset-specific linguistic patterns that models exploit but do not generalize to new domains. At the token level, sample level, and dataset level, we find that caption diversity is a major driving factor behind the generation of generic and uninformative captions. We further show that state-of-the-art models even outperform held-out ground truth captions on modern metrics, and that this effect is an artifact of linguistic diversity in datasets. Understanding this linguistic diversity is key to building strong captioning models, we recommend several methods and approaches for maintaining diversity in the collection of new data, and dealing with the consequences of limited diversity when using current models and metrics.", "paper_url": "http://arxiv.org/abs/2205.06253v1", "pdf_url": "http://arxiv.org/pdf/2205.06253v1", "repo_url": "https://github.com/cannylab/vdtk"}, "2205.06207": {"publish_time": "2022-05-12", "title": "CiteSum: Citation Text-guided Scientific Extreme Summarization and Low-resource Domain Adaptation", "author": "Yuning Mao et.al.", "abstract": "Scientific extreme summarization (TLDR) aims to form ultra-short summaries of scientific papers. Previous efforts on curating scientific TLDR datasets failed to scale up due to the heavy human annotation and domain expertise required. In this paper, we propose a simple yet effective approach to automatically extracting TLDR summaries for scientific papers from their citation texts. Based on the proposed approach, we create a new benchmark CiteSum without human annotation, which is around 30 times larger than the previous human-curated dataset SciTLDR. We conduct a comprehensive analysis of CiteSum, examining its data characteristics and establishing strong baselines. We further demonstrate the usefulness of CiteSum by adapting models pre-trained on CiteSum (named CITES) to new tasks and domains with limited supervision. For scientific extreme summarization, CITES outperforms most fully-supervised methods on SciTLDR without any fine-tuning and obtains state-of-the-art results with only 128 examples. For news extreme summarization, CITES achieves significant gains on XSum over its base model (not pre-trained on CiteSum), e.g., +7.2 ROUGE-1 zero-shot performance and state-of-the-art few-shot performance. For news headline generation, CITES performs the best among unsupervised and zero-shot methods on Gigaword.", "paper_url": "http://arxiv.org/abs/2205.06207v1", "pdf_url": "http://arxiv.org/pdf/2205.06207v1", "repo_url": "https://github.com/morningmoni/citesum"}, "2205.06203": {"publish_time": "2022-05-12", "title": "Predicting Human Psychometric Properties Using Computational Language Models", "author": "Antonio Laverghetta Jr. et.al.", "abstract": "Transformer-based language models (LMs) continue to achieve state-of-the-art performance on natural language processing (NLP) benchmarks, including tasks designed to mimic human-inspired \"commonsense\" competencies. To better understand the degree to which LMs can be said to have certain linguistic reasoning skills, researchers are beginning to adapt the tools and concepts from psychometrics. But to what extent can benefits flow in the other direction? In other words, can LMs be of use in predicting the psychometric properties of test items, when those items are given to human participants? If so, the benefit for psychometric practitioners is enormous, as it can reduce the need for multiple rounds of empirical testing. We gather responses from numerous human participants and LMs (transformer- and non-transformer-based) on a broad diagnostic test of linguistic competencies. We then use the human responses to calculate standard psychometric properties of the items in the diagnostic test, using the human responses and the LM responses separately. We then determine how well these two sets of predictions correlate. We find that transformer-based LMs predict the human psychometric data consistently well across most categories, suggesting that they can be used to gather human-like psychometric data without the need for extensive human trials.", "paper_url": "http://arxiv.org/abs/2205.06203v1", "pdf_url": "http://arxiv.org/pdf/2205.06203v1", "repo_url": null}, "2205.06756": {"publish_time": "2022-05-13", "title": "Interlock-Free Multi-Aspect Rationalization for Text Classification", "author": "Shuangqi Li et.al.", "abstract": "Explanation is important for text classification tasks. One prevalent type of explanation is rationales, which are text snippets of input text that suffice to yield the prediction and are meaningful to humans. A lot of research on rationalization has been based on the selective rationalization framework, which has recently been shown to be problematic due to the interlocking dynamics. In this paper, we show that we address the interlocking problem in the multi-aspect setting, where we aim to generate multiple rationales for multiple outputs. More specifically, we propose a multi-stage training method incorporating an additional self-supervised contrastive loss that helps to generate more semantically diverse rationales. Empirical results on the beer review dataset show that our method improves significantly the rationalization performance.", "paper_url": "http://arxiv.org/abs/2205.06756v1", "pdf_url": "http://arxiv.org/pdf/2205.06756v1", "repo_url": null}, "2205.06755": {"publish_time": "2022-05-13", "title": "Who Are We Talking About? Handling Person Names in Speech Translation", "author": "Marco Gaido et.al.", "abstract": "Recent work has shown that systems for speech translation (ST) -- similarly to automatic speech recognition (ASR) -- poorly handle person names. This shortcoming does not only lead to errors that can seriously distort the meaning of the input, but also hinders the adoption of such systems in application scenarios (like computer-assisted interpreting) where the translation of named entities, like person names, is crucial. In this paper, we first analyse the outputs of ASR/ST systems to identify the reasons of failures in person name transcription/translation. Besides the frequency in the training data, we pinpoint the nationality of the referred person as a key factor. We then mitigate the problem by creating multilingual models, and further improve our ST systems by forcing them to jointly generate transcripts and translations, prioritising the former over the latter. Overall, our solutions result in a relative improvement in token-level person name accuracy by 47.8% on average for three language pairs (en->es,fr,it).", "paper_url": "http://arxiv.org/abs/2205.06755v1", "pdf_url": "http://arxiv.org/pdf/2205.06755v1", "repo_url": null}, "2205.06740": {"publish_time": "2022-05-13", "title": "An empirical study of CTC based models for OCR of Indian languages", "author": "Minesh Mathew et.al.", "abstract": "Recognition of text on word or line images, without the need for sub-word segmentation has become the mainstream of research and development of text recognition for Indian languages. Modelling unsegmented sequences using Connectionist Temporal Classification (CTC) is the most commonly used approach for segmentation-free OCR. In this work we present a comprehensive empirical study of various neural network models that uses CTC for transcribing step-wise predictions in the neural network output to a Unicode sequence. The study is conducted for 13 Indian languages, using an internal dataset that has around 1000 pages per language. We study the choice of line vs word as the recognition unit, and use of synthetic data to train the models. We compare our models with popular publicly available OCR tools for end-to-end document image recognition. Our end-to-end pipeline that employ our recognition models and existing text segmentation tools outperform these public OCR tools for 8 out of the 13 languages. We also introduce a new public dataset called Mozhi for word and line recognition in Indian language. The dataset contains more than 1.2 million annotated word images (120 thousand text lines) across 13 Indian languages. Our code, trained models and the Mozhi dataset will be made available at http://cvit.iiit.ac.in/research/projects/cvit-projects/", "paper_url": "http://arxiv.org/abs/2205.06740v1", "pdf_url": "http://arxiv.org/pdf/2205.06740v1", "repo_url": null}, "2205.06733": {"publish_time": "2022-05-13", "title": "Improving the Numerical Reasoning Skills of Pretrained Language Models", "author": "Dominic Petrak et.al.", "abstract": "State-of-the-art pretrained language models tend to perform below their capabilities when applied out-of-the-box on tasks that require reasoning over numbers. Recent work sees two main reasons for this: (1) popular tokenisation algorithms are optimized for common words, and therefore have limited expressiveness for numbers, and (2) common pretraining objectives do not target numerical reasoning or understanding numbers at all. Recent approaches usually address them separately and mostly by proposing architectural changes or pretraining models from scratch. In this paper, we propose a new extended pretraining approach called reasoning-aware pretraining to jointly address both shortcomings without requiring architectural changes or pretraining from scratch. Using contrastive learning, our approach incorporates an alternative number representation into an already pretrained model, while improving its numerical reasoning skills by training on a novel pretraining objective called inferable number prediction task. We evaluate our approach on three different tasks that require numerical reasoning, including (a) reading comprehension in the DROP dataset, (b) inference-on-tables in the InfoTabs dataset, and (c) table-to-text generation in WikiBio and SciGen datasets. Our results on DROP and InfoTabs show that our approach improves the accuracy by 9.6 and 33.9 points on these datasets, respectively. Our human evaluation on SciGen and WikiBio shows that our approach improves the factual correctness on all datasets.", "paper_url": "http://arxiv.org/abs/2205.06733v1", "pdf_url": "http://arxiv.org/pdf/2205.06733v1", "repo_url": "https://github.com/ukplab/emnlp2022-reasoning-aware-pretraining"}, "2205.06703": {"publish_time": "2022-05-13", "title": "MuCPAD: A Multi-Domain Chinese Predicate-Argument Dataset", "author": "Yahui Liu et.al.", "abstract": "During the past decade, neural network models have made tremendous progress on in-domain semantic role labeling (SRL). However, performance drops dramatically under the out-of-domain setting. In order to facilitate research on cross-domain SRL, this paper presents MuCPAD, a multi-domain Chinese predicate-argument dataset, which consists of 30,897 sentences and 92,051 predicates from six different domains. MuCPAD exhibits three important features. 1) Based on a frame-free annotation methodology, we avoid writing complex frames for new predicates. 2) We explicitly annotate omitted core arguments to recover more complete semantic structure, considering that omission of content words is ubiquitous in multi-domain Chinese texts. 3) We compile 53 pages of annotation guidelines and adopt strict double annotation for improving data quality. This paper describes in detail the annotation methodology and annotation process of MuCPAD, and presents in-depth data analysis. We also give benchmark results on cross-domain SRL based on MuCPAD.", "paper_url": "http://arxiv.org/abs/2205.06703v1", "pdf_url": "http://arxiv.org/pdf/2205.06703v1", "repo_url": "https://github.com/suda-la/mucpad"}, "2205.07830": {"publish_time": "2022-05-16", "title": "FactPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization", "author": "David Wan et.al.", "abstract": "We present FactPEGASUS, an abstractive summarization model that addresses the problem of factuality during pre-training and fine-tuning: (1) We augment the sentence selection strategy of PEGASUS's (Zhang et al., 2020) pre-training objective to create pseudo-summaries that are both important and factual; (2) We introduce three complementary components for fine-tuning. The corrector removes hallucinations present in the reference summary, the contrastor uses contrastive learning to better differentiate nonfactual summaries from factual ones, and the connector bridges the gap between the pre-training and fine-tuning for better transfer of knowledge. Experiments on three downstream tasks demonstrate that FactPEGASUS substantially improves factuality evaluated by multiple automatic metrics and humans. Our thorough analysis suggests that FactPEGASUS is more factual than using the original pre-training objective in zero-shot and few-shot settings, retains factual behavior more robustly than strong baselines, and does not rely entirely on becoming more extractive to improve factuality. Our code and data are publicly available at: https://github.com/meetdavidwan/factpegasus", "paper_url": "http://arxiv.org/abs/2205.07830v1", "pdf_url": "http://arxiv.org/pdf/2205.07830v1", "repo_url": null}, "2205.07811": {"publish_time": "2022-05-16", "title": "Natural Language Specifications in Proof Assistants", "author": "Colin S. Gordon et.al.", "abstract": "Interactive proof assistants are computer programs carefully constructed to check a human-designed proof of a mathematical claim with high confidence in the implementation. However, this only validates truth of a formal claim, which may have been mistranslated from a claim made in natural language. This is especially problematic when using proof assistants to formally verify the correctness of software with respect to a natural language specification. The translation from informal to formal remains a challenging, time-consuming process that is difficult to audit for correctness. This paper argues that it is possible to build support for natural language specifications within existing proof assistants, in a way that complements the principles used to establish trust and auditability in proof assistants themselves.", "paper_url": "http://arxiv.org/abs/2205.07811v1", "pdf_url": "http://arxiv.org/pdf/2205.07811v1", "repo_url": null}, "2205.07795": {"publish_time": "2022-05-16", "title": "Referring Expressions with Rational Speech Act Framework: A Probabilistic Approach", "author": "Hieu Le et.al.", "abstract": "This paper focuses on a referring expression generation (REG) task in which the aim is to pick out an object in a complex visual scene. One common theoretical approach to this problem is to model the task as a two-agent cooperative scheme in which a `speaker' agent would generate the expression that best describes a targeted area and a `listener' agent would identify the target. Several recent REG systems have used deep learning approaches to represent the speaker/listener agents. The Rational Speech Act framework (RSA), a Bayesian approach to pragmatics that can predict human linguistic behavior quite accurately, has been shown to generate high quality and explainable expressions on toy datasets involving simple visual scenes. Its application to large scale problems, however, remains largely unexplored. This paper applies a combination of the probabilistic RSA framework and deep learning approaches to larger datasets involving complex visual scenes in a multi-step process with the aim of generating better-explained expressions. We carry out experiments on the RefCOCO and RefCOCO+ datasets and compare our approach with other end-to-end deep learning approaches as well as a variation of RSA to highlight our key contribution. Experimental results show that while achieving lower accuracy than SOTA deep learning methods, our approach outperforms similar RSA approach in human comprehension and has an advantage over end-to-end deep learning under limited data scenario. Lastly, we provide a detailed analysis on the expression generation process with concrete examples, thus providing a systematic view on error types and deficiencies in the generation process and identifying possible areas for future improvements.", "paper_url": "http://arxiv.org/abs/2205.07795v1", "pdf_url": "http://arxiv.org/pdf/2205.07795v1", "repo_url": null}, "2205.07750": {"publish_time": "2022-05-16", "title": "What company do words keep? Revisiting the distributional semantics of J.R. Firth & Zellig Harris", "author": "Mikael Brunila et.al.", "abstract": "The power of word embeddings is attributed to the linguistic theory that similar words will appear in similar contexts. This idea is specifically invoked by noting that \"you shall know a word by the company it keeps,\" a quote from British linguist J.R. Firth who, along with his American colleague Zellig Harris, is often credited with the invention of \"distributional semantics.\" While both Firth and Harris are cited in all major NLP textbooks and many foundational papers, the content and differences between their theories is seldom discussed. Engaging in a close reading of their work, we discover two distinct and in many ways divergent theories of meaning. One focuses exclusively on the internal workings of linguistic forms, while the other invites us to consider words in new company - not just with other linguistic elements, but also in a broader cultural and situational context. Contrasting these theories from the perspective of current debates in NLP, we discover in Firth a figure who could guide the field towards a more culturally grounded notion of semantics. We consider how an expanded notion of \"context\" might be modeled in practice through two different strategies: comparative stratification and syntagmatic extension", "paper_url": "http://arxiv.org/abs/2205.07750v1", "pdf_url": "http://arxiv.org/pdf/2205.07750v1", "repo_url": null}, "2205.07743": {"publish_time": "2022-05-16", "title": "Strong Equivalence of TAG and CCG", "author": "Andreas Maletti et.al.", "abstract": "Tree-adjoining grammar (TAG) and combinatory categorial grammar (CCG) are two well-established mildly context-sensitive grammar formalisms that are known to have the same expressive power on strings (i.e., generate the same class of string languages). It is demonstrated that their expressive power on trees also essentially coincides. In fact, CCG without lexicon entries for the empty string and only first-order rules of degree at most 2 are sufficient for its full expressive power.", "paper_url": "http://arxiv.org/abs/2205.07743v1", "pdf_url": "http://arxiv.org/pdf/2205.07743v1", "repo_url": null}, "2205.08533": {"publish_time": "2022-05-17", "title": "Consistent Human Evaluation of Machine Translation across Language Pairs", "author": "Daniel Licht et.al.", "abstract": "Obtaining meaningful quality scores for machine translation systems through human evaluation remains a challenge given the high variability between human evaluators, partly due to subjective expectations for translation quality for different language pairs. We propose a new metric called XSTS that is more focused on semantic equivalence and a cross-lingual calibration method that enables more consistent assessment. We demonstrate the effectiveness of these novel contributions in large scale evaluation studies across up to 14 language pairs, with translation both into and out of English.", "paper_url": "http://arxiv.org/abs/2205.08533v1", "pdf_url": "http://arxiv.org/pdf/2205.08533v1", "repo_url": null}, "2205.08514": {"publish_time": "2022-05-17", "title": "Recovering Private Text in Federated Learning of Language Models", "author": "Samyak Gupta et.al.", "abstract": "Federated learning allows distributed users to collaboratively train a model while keeping each user's data private. Recently, a growing body of work has demonstrated that an eavesdropping attacker can effectively recover image data from gradients transmitted during federated learning. However, little progress has been made in recovering text data. In this paper, we present a novel attack method FILM for federated learning of language models -- for the first time, we show the feasibility of recovering text from large batch sizes of up to 128 sentences. Different from image-recovery methods which are optimized to match gradients, we take a distinct approach that first identifies a set of words from gradients and then directly reconstructs sentences based on beam search and a prior-based reordering strategy. The key insight of our attack is to leverage either prior knowledge in pre-trained language models or memorization during training. Despite its simplicity, we demonstrate that FILM can work well with several large-scale datasets -- it can extract single sentences with high fidelity even for large batch sizes and recover multiple sentences from the batch successfully if the attack is applied iteratively. We hope our results can motivate future work in developing stronger attacks as well as new defense methods for training language models in federated learning. Our code is publicly available at https://github.com/Princeton-SysML/FILM.", "paper_url": "http://arxiv.org/abs/2205.08514v1", "pdf_url": "http://arxiv.org/pdf/2205.08514v1", "repo_url": null}, "2205.08497": {"publish_time": "2022-05-17", "title": "Feature Aggregation in Zero-Shot Cross-Lingual Transfer Using Multilingual BERT", "author": "Beiduo Chen et.al.", "abstract": "Multilingual BERT (mBERT), a language model pre-trained on large multilingual corpora, has impressive zero-shot cross-lingual transfer capabilities and performs surprisingly well on zero-shot POS tagging and Named Entity Recognition (NER), as well as on cross-lingual model transfer. At present, the mainstream methods to solve the cross-lingual downstream tasks are always using the last transformer layer's output of mBERT as the representation of linguistic information. In this work, we explore the complementary property of lower layers to the last transformer layer of mBERT. A feature aggregation module based on an attention mechanism is proposed to fuse the information contained in different layers of mBERT. The experiments are conducted on four zero-shot cross-lingual transfer datasets, and the proposed method obtains performance improvements on key multilingual benchmark tasks XNLI (+1.5 %), PAWS-X (+2.4 %), NER (+1.2 F1), and POS (+1.5 F1). Through the analysis of the experimental results, we prove that the layers before the last layer of mBERT can provide extra useful information for cross-lingual downstream tasks and explore the interpretability of mBERT empirically.", "paper_url": "http://arxiv.org/abs/2205.08497v1", "pdf_url": "http://arxiv.org/pdf/2205.08497v1", "repo_url": null}, "2205.08478": {"publish_time": "2022-05-17", "title": "An Evaluation Framework for Legal Document Summarization", "author": "Ankan Mullick et.al.", "abstract": "A law practitioner has to go through numerous lengthy legal case proceedings for their practices of various categories, such as land dispute, corruption, etc. Hence, it is important to summarize these documents, and ensure that summaries contain phrases with intent matching the category of the case. To the best of our knowledge, there is no evaluation metric that evaluates a summary based on its intent. We propose an automated intent-based summarization metric, which shows a better agreement with human evaluation as compared to other automated metrics like BLEU, ROUGE-L etc. in terms of human satisfaction. We also curate a dataset by annotating intent phrases in legal documents, and show a proof of concept as to how this system can be automated. Additionally, all the code and data to generate reproducible results is available on Github.", "paper_url": "http://arxiv.org/abs/2205.08478v1", "pdf_url": "http://arxiv.org/pdf/2205.08478v1", "repo_url": "https://github.com/manavkapadnis/legalevaluation_lrec2022"}, "2205.08288": {"publish_time": "2022-05-17", "title": "Measuring Alignment Bias in Neural Seq2Seq Semantic Parsers", "author": "Davide Locatelli et.al.", "abstract": "Prior to deep learning the semantic parsing community has been interested in understanding and modeling the range of possible word alignments between natural language sentences and their corresponding meaning representations. Sequence-to-sequence models changed the research landscape suggesting that we no longer need to worry about alignments since they can be learned automatically by means of an attention mechanism. More recently, researchers have started to question such premise. In this work we investigate whether seq2seq models can handle both simple and complex alignments. To answer this question we augment the popular Geo semantic parsing dataset with alignment annotations and create Geo-Aligned. We then study the performance of standard seq2seq models on the examples that can be aligned monotonically versus examples that require more complex alignments. Our empirical study shows that performance is significantly better over monotonic alignments.", "paper_url": "http://arxiv.org/abs/2205.08288v1", "pdf_url": "http://arxiv.org/pdf/2205.08288v1", "repo_url": null}, "2205.09073": {"publish_time": "2022-05-18", "title": "Dialog Inpainting: Turning Documents into Dialogs", "author": "Zhuyun Dai et.al.", "abstract": "Many important questions (e.g. \"How to eat healthier?\") require conversation to establish context and explore in depth. However, conversational question answering (ConvQA) systems have long been stymied by scarce training data that is expensive to collect. To address this problem, we propose a new technique for synthetically generating diverse and high-quality dialog data: dialog inpainting. Our approach takes the text of any document and transforms it into a two-person dialog between the writer and an imagined reader: we treat sentences from the article as utterances spoken by the writer, and then use a dialog inpainter to predict what the imagined reader asked or said in between each of the writer's utterances. By applying this approach to passages from Wikipedia and the web, we produce WikiDialog and WebDialog, two datasets totalling 19 million diverse information-seeking dialogs -- 1,000x larger than the largest existing ConvQA dataset. Furthermore, human raters judge the answer adequacy and conversationality of WikiDialog to be as good or better than existing manually-collected datasets. Using our inpainted data to pre-train ConvQA retrieval systems, we significantly advance state-of-the-art across three benchmarks (QReCC, OR-QuAC, TREC CAsT) yielding up to 40% relative gains on standard evaluation metrics.", "paper_url": "http://arxiv.org/abs/2205.09073v1", "pdf_url": "http://arxiv.org/pdf/2205.09073v1", "repo_url": null}, "2205.09067": {"publish_time": "2022-05-18", "title": "Automatic Rule Induction for Efficient Semi-Supervised Learning", "author": "Reid Pryzant et.al.", "abstract": "Semi-supervised learning has shown promise in allowing NLP models to generalize from small amounts of labeled data. Meanwhile, pretrained transformer models act as black-box correlation engines that are difficult to explain and sometimes behave unreliably. In this paper, we propose tackling both of these challenges via Automatic Rule Induction (ARI), a simple and general-purpose framework for the automatic discovery and integration of symbolic rules into pretrained transformer models. First, we extract weak symbolic rules from low-capacity machine learning models trained on small amounts of labeled data. Next, we use an attention mechanism to integrate these rules into high-capacity pretrained transformer models. Last, the rule-augmented system becomes part of a self-training framework to boost supervision signal on unlabeled data. These steps can be layered beneath a variety of existing weak supervision and semi-supervised NLP algorithms in order to improve performance and interpretability. Experiments across nine sequence classification and relation extraction tasks suggest that ARI can improve state-of-the-art methods with no manual effort and minimal computational overhead.", "paper_url": "http://arxiv.org/abs/2205.09067v1", "pdf_url": "http://arxiv.org/pdf/2205.09067v1", "repo_url": null}, "2205.09058": {"publish_time": "2022-05-18", "title": "Minimising Biasing Word Errors for Contextual ASR with the Tree-Constrained Pointer Generator", "author": "Guangzhi Sun et.al.", "abstract": "Contextual knowledge is essential for reducing speech recognition errors on high-valued long-tail words. This paper proposes a novel tree-constrained pointer generator (TCPGen) component that enables end-to-end ASR models to bias towards a list of long-tail words obtained using external contextual information. With only a small overhead in memory use and computation cost, TCPGen can structure thousands of biasing words efficiently into a symbolic prefix-tree and creates a neural shortcut between the tree and the final ASR output to facilitate the recognition of the biasing words. To enhance TCPGen, we further propose a novel minimum biasing word error (MBWE) loss that directly optimises biasing word errors during training, along with a biasing-word-driven language model discounting (BLMD) method during the test. All contextual ASR systems were evaluated on the public Librispeech audiobook corpus and the data from the dialogue state tracking challenges (DSTC) with the biasing lists extracted from the dialogue-system ontology. Consistent word error rate (WER) reductions were achieved with TCPGen, which were particularly significant on the biasing words with around 40\\% relative reductions in the recognition error rates. MBWE and BLMD further improved the effectiveness of TCPGen and achieved more significant WER reductions on the biasing words. TCPGen also achieved zero-shot learning of words not in the audio training set with large WER reductions on the out-of-vocabulary words in the biasing list.", "paper_url": "http://arxiv.org/abs/2205.09058v1", "pdf_url": "http://arxiv.org/pdf/2205.09058v1", "repo_url": null}, "2205.08993": {"publish_time": "2022-05-18", "title": "Leveraging Pseudo-labeled Data to Improve Direct Speech-to-Speech Translation", "author": "Qianqian Dong et.al.", "abstract": "Direct Speech-to-speech translation (S2ST) has drawn more and more attention recently. The task is very challenging due to data scarcity and complex speech-to-speech mapping. In this paper, we report our recent achievements in S2ST. Firstly, we build a S2ST Transformer baseline which outperforms the original Translatotron. Secondly, we utilize the external data by pseudo-labeling and obtain a new state-of-the-art result on the Fisher English-to-Spanish test set. Indeed, we exploit the pseudo data with a combination of popular techniques which are not trivial when applied to S2ST. Moreover, we evaluate our approach on both syntactically similar (Spanish-English) and distant (English-Chinese) language pairs. Our implementation is available at https://github.com/fengpeng-yue/speech-to-speech-translation.", "paper_url": "http://arxiv.org/abs/2205.08993v1", "pdf_url": "http://arxiv.org/pdf/2205.08993v1", "repo_url": "https://github.com/fengpeng-yue/speech-to-speech-translation"}, "2205.08943": {"publish_time": "2022-05-18", "title": "CREATER: CTR-driven Advertising Text Generation with Controlled Pre-Training and Contrastive Fine-Tuning", "author": "Penghui Wei et.al.", "abstract": "This paper focuses on automatically generating the text of an ad, and the goal is that the generated text can capture user interest for achieving higher click-through rate (CTR). We propose CREATER, a CTR-driven advertising text generation approach, to generate ad texts based on high-quality user reviews. To incorporate CTR objective, our model learns from online A/B test data with contrastive learning, which encourages the model to generate ad texts that obtain higher CTR. To alleviate the low-resource issue, we design a customized self-supervised objective reducing the gap between pre-training and fine-tuning. Experiments on industrial datasets show that CREATER significantly outperforms current approaches. It has been deployed online in a leading advertising platform and brings uplift on core online metrics.", "paper_url": "http://arxiv.org/abs/2205.08943v1", "pdf_url": "http://arxiv.org/pdf/2205.08943v1", "repo_url": null}, "2205.09732": {"publish_time": "2022-05-19", "title": "Enhancing Slot Tagging with Intent Features for Task Oriented Natural Language Understanding using BERT", "author": "Shruthi Hariharan et.al.", "abstract": "Recent joint intent detection and slot tagging models have seen improved performance when compared to individual models. In many real-world datasets, the slot labels and values have a strong correlation with their intent labels. In such cases, the intent label information may act as a useful feature to the slot tagging model. In this paper, we examine the effect of leveraging intent label features through 3 techniques in the slot tagging task of joint intent and slot detection models. We evaluate our techniques on benchmark spoken language datasets SNIPS and ATIS, as well as over a large private Bixby dataset and observe an improved slot-tagging performance over state-of-the-art models.", "paper_url": "http://arxiv.org/abs/2205.09732v1", "pdf_url": "http://arxiv.org/pdf/2205.09732v1", "repo_url": null}, "2205.09726": {"publish_time": "2022-05-19", "title": "RankGen: Improving Text Generation with Large Ranking Models", "author": "Kalpesh Krishna et.al.", "abstract": "Given an input sequence (or prefix), modern language models often assign high probabilities to output sequences that are repetitive, incoherent, or irrelevant to the prefix; as such, model-generated text also contains such artifacts. To address these issues, we present RankGen, an encoder model (1.2B parameters) that scores model generations given a prefix. RankGen can be flexibly incorporated as a scoring function in beam search and used to decode from any pretrained language model. We train RankGen using large-scale contrastive learning to map a prefix close to the ground-truth sequence that follows it and far away from two types of negatives: (1) random sequences from the same document as the prefix, and, which discourage topically-similar but irrelevant generations; (2) sequences generated from a large language model conditioned on the prefix, which discourage repetition and hallucination. Experiments across four different language models (345M-11B parameters) and two domains show that RankGen significantly outperforms decoding algorithms like nucleus, top-k, and typical sampling on both automatic metrics (85.0 vs 77.3 MAUVE) as well as human evaluations with English writers (74.5% human preference over nucleus sampling). Analysis reveals that RankGen outputs are more relevant to the prefix and improve continuity and coherence compared to baselines. We open source our model checkpoints, code, and human preferences with detailed explanations for future research.", "paper_url": "http://arxiv.org/abs/2205.09726v1", "pdf_url": "http://arxiv.org/pdf/2205.09726v1", "repo_url": "https://github.com/martiansideofthemoon/rankgen"}, "2205.09712": {"publish_time": "2022-05-19", "title": "Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning", "author": "Antonia Creswell et.al.", "abstract": "Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 50 tasks that probe different aspects of logical reasoning. We show that language models tend to perform fairly well at single step inference or entailment tasks, but struggle to chain together multiple reasoning steps to solve more complex problems. In light of this, we propose a Selection-Inference (SI) framework that exploits pre-trained LLMs as general processing modules, and alternates between selection and inference to generate a series of interpretable, casual reasoning steps leading to the final answer. We show that a 7B parameter LLM used within the SI framework in a 5-shot generalisation setting, with no fine-tuning, yields a performance improvement of over 100% compared to an equivalent vanilla baseline on a suite of 10 logical reasoning tasks. The same model in the same setting even outperforms a significantly larger 280B parameter baseline on the same suite of tasks. Moreover, answers produced by the SI framework are accompanied by a causal natural-language-based reasoning trace, which has important implications for the safety and trustworthiness of the system.", "paper_url": "http://arxiv.org/abs/2205.09712v1", "pdf_url": "http://arxiv.org/pdf/2205.09712v1", "repo_url": null}, "2205.09710": {"publish_time": "2022-05-19", "title": "Voxel-informed Language Grounding", "author": "Rodolfo Corona et.al.", "abstract": "Natural language applied to natural 2D images describes a fundamentally 3D world. We present the Voxel-informed Language Grounder (VLG), a language grounding model that leverages 3D geometric information in the form of voxel maps derived from the visual input using a volumetric reconstruction model. We show that VLG significantly improves grounding accuracy on SNARE, an object reference game task. At the time of writing, VLG holds the top place on the SNARE leaderboard, achieving SOTA results with a 2.0% absolute improvement.", "paper_url": "http://arxiv.org/abs/2205.09710v1", "pdf_url": "http://arxiv.org/pdf/2205.09710v1", "repo_url": null}, "2205.09709": {"publish_time": "2022-05-19", "title": "Bi-LSTM Scoring Based Similarity Measurement with Agglomerative Hierarchical Clustering (AHC) for Speaker Diarization", "author": "Siddharth S. Nijhawan et.al.", "abstract": "Majority of speech signals across different scenarios are never available with well-defined audio segments containing only a single speaker. A typical conversation between two speakers consists of segments where their voices overlap, interrupt each other or halt their speech in between multiple sentences. Recent advancements in diarization technology leverage neural network-based approaches to improvise multiple subsystems of speaker diarization system comprising of extracting segment-wise embedding features and detecting changes in the speaker during conversation. However, to identify speaker through clustering, models depend on methodologies like PLDA to generate similarity measure between two extracted segments from a given conversational audio. Since these algorithms ignore the temporal structure of conversations, they tend to achieve a higher Diarization Error Rate (DER), thus leading to misdetections both in terms of speaker and change identification. Therefore, to compare similarity of two speech segments both independently and sequentially, we propose a Bi-directional Long Short-term Memory network for estimating the elements present in the similarity matrix. Once the similarity matrix is generated, Agglomerative Hierarchical Clustering (AHC) is applied to further identify speaker segments based on thresholding. To evaluate the performance, Diarization Error Rate (DER%) metric is used. The proposed model achieves a low DER of 34.80% on a test set of audio samples derived from ICSI Meeting Corpus as compared to traditional PLDA based similarity measurement mechanism which achieved a DER of 39.90%.", "paper_url": "http://arxiv.org/abs/2205.09709v1", "pdf_url": "http://arxiv.org/pdf/2205.09709v1", "repo_url": null}, "2205.10350": {"publish_time": "2022-05-20", "title": "Lossless Acceleration for Seq2seq Generation with Aggressive Decoding", "author": "Tao Ge et.al.", "abstract": "We study lossless acceleration for seq2seq generation with a novel decoding algorithm -- Aggressive Decoding. Unlike the previous efforts (e.g., non-autoregressive decoding) speeding up seq2seq generation at the cost of quality loss, our approach aims to yield the identical (or better) generation compared with autoregressive decoding but in a significant speedup, achieved by innovative cooperation of aggressive decoding and verification that are both efficient due to parallel computing.   We propose two Aggressive Decoding paradigms for 2 kinds of seq2seq tasks: 1) For the seq2seq tasks whose inputs and outputs are highly similar (e.g., Grammatical Error Correction), we propose Input-guided Aggressive Decoding (IAD) that aggressively copies from the input sentence as drafted decoded tokens to verify in parallel; 2) For other general seq2seq tasks (e.g., Machine Translation), we propose Generalized Aggressive Decoding (GAD) that first employs an additional non-autoregressive decoding model for aggressive decoding and then verifies in parallel in the autoregressive manner.   We test Aggressive Decoding on the most popular 6-layer Transformer model on GPU in multiple seq2seq tasks: 1) For IAD, we show that it can introduce a 7x-9x speedup for the Transformer in Grammatical Error Correction and Text Simplification tasks with the identical results as greedy decoding; 2) For GAD, we observe a 3x-5x speedup with the identical or even better quality in two important seq2seq tasks: Machine Translation and Abstractive Summarization. Moreover, Aggressive Decoding can benefit even more from stronger computing devices that are better at parallel computing. Given the lossless quality as well as significant and promising speedup, we believe Aggressive Decoding may potentially evolve into a de facto standard for efficient and lossless seq2seq generation in the near future.", "paper_url": "http://arxiv.org/abs/2205.10350v1", "pdf_url": "http://arxiv.org/pdf/2205.10350v1", "repo_url": "https://github.com/microsoft/unilm"}, "2205.10312": {"publish_time": "2022-05-20", "title": "ClusterEA: Scalable Entity Alignment with Stochastic Training and Normalized Mini-batch Similarities", "author": "Yunjun Gao et.al.", "abstract": "Entity alignment (EA) aims at finding equivalent entities in different knowledge graphs (KGs). Embedding-based approaches have dominated the EA task in recent years. Those methods face problems that come from the geometric properties of embedding vectors, including hubness and isolation. To solve these geometric problems, many normalization approaches have been adopted to EA. However, the increasing scale of KGs renders it is hard for EA models to adopt the normalization processes, thus limiting their usage in real-world applications. To tackle this challenge, we present ClusterEA, a general framework that is capable of scaling up EA models and enhancing their results by leveraging normalization methods on mini-batches with a high entity equivalent rate. ClusterEA contains three components to align entities between large-scale KGs, including stochastic training, ClusterSampler, and SparseFusion. It first trains a large-scale Siamese GNN for EA in a stochastic fashion to produce entity embeddings. Based on the embeddings, a novel ClusterSampler strategy is proposed for sampling highly overlapped mini-batches. Finally, ClusterEA incorporates SparseFusion, which normalizes local and global similarity and then fuses all similarity matrices to obtain the final similarity matrix. Extensive experiments with real-life datasets on EA benchmarks offer insight into the proposed framework, and suggest that it is capable of outperforming the state-of-the-art scalable EA framework by up to 8 times in terms of Hits@1.", "paper_url": "http://arxiv.org/abs/2205.10312v1", "pdf_url": "http://arxiv.org/pdf/2205.10312v1", "repo_url": "https://github.com/joker-xii/clusterea"}, "2205.10282": {"publish_time": "2022-05-20", "title": "Heterformer: A Transformer Architecture for Node Representation Learning on Heterogeneous Text-Rich Networks", "author": "Bowen Jin et.al.", "abstract": "We study node representation learning on heterogeneous text-rich networks, where nodes and edges are multi-typed and some types of nodes are associated with text information. Although recent studies on graph neural networks (GNNs) and pretrained language models (PLMs) have demonstrated their power in encoding network and text signals, respectively, less focus has been given to delicately coupling these two types of models on heterogeneous text-rich networks. Specifically, existing GNNs rarely model text in each node in a contextualized way; existing PLMs can hardly be applied to characterize graph structures due to their sequence architecture. In this paper, we propose Heterformer, a Heterogeneous GNN-nested transformer that blends GNNs and PLMs into a unified model. Different from previous \"cascaded architectures\" that directly add GNN layers upon a PLM, our Heterformer alternately stacks two modules - a graph-attention-based neighbor aggregation module and a transformer-based text and neighbor joint encoding module - to facilitate thorough mutual enhancement between network and text signals. Meanwhile, Heterformer is capable of characterizing network heterogeneity and nodes without text information. Comprehensive experiments on three large-scale datasets from different domains demonstrate the superiority of Heterformer over state-of-the-art baselines in link prediction, transductive/inductive node classification, node clustering, and semantics-based retrieval.", "paper_url": "http://arxiv.org/abs/2205.10282v1", "pdf_url": "http://arxiv.org/pdf/2205.10282v1", "repo_url": null}, "2205.10192": {"publish_time": "2022-05-20", "title": "On the Trade-off between Redundancy and Local Coherence in Summarization", "author": "Ronald Cardenas et.al.", "abstract": "Extractive summarization systems are known to produce poorly coherent and, if not accounted for, highly redundant text. In this work, we tackle the problem of summary redundancy in unsupervised extractive summarization of long, highly-redundant documents. For this, we leverage a psycholinguistic theory of human reading comprehension which directly models local coherence and redundancy. Implementing this theory, our system operates at the proposition level and exploits properties of human memory representations to rank similarly content units that are coherent and non-redundant, hence encouraging the extraction of less redundant final summaries. Because of the impact of the summary length on automatic measures, we control for it by formulating content selection as an optimization problem with soft constraints in the budget of information retrieved. Using summarization of scientific articles as a case study, extensive experiments demonstrate that the proposed systems extract consistently less redundant summaries across increasing levels of document redundancy, whilst maintaining comparable performance (in terms of relevancy and local coherence) against strong unsupervised baselines according to automated evaluations.", "paper_url": "http://arxiv.org/abs/2205.10192v1", "pdf_url": "http://arxiv.org/pdf/2205.10192v1", "repo_url": null}, "2205.10189": {"publish_time": "2022-05-20", "title": "Progressive Class Semantic Matching for Semi-supervised Text Classification", "author": "Hai-Ming Xu et.al.", "abstract": "Semi-supervised learning is a promising way to reduce the annotation cost for text-classification. Combining with pre-trained language models (PLMs), e.g., BERT, recent semi-supervised learning methods achieved impressive performance. In this work, we further investigate the marriage between semi-supervised learning and a pre-trained language model. Unlike existing approaches that utilize PLMs only for model parameter initialization, we explore the inherent topic matching capability inside PLMs for building a more powerful semi-supervised learning approach. Specifically, we propose a joint semi-supervised learning process that can progressively build a standard $K$-way classifier and a matching network for the input text and the Class Semantic Representation (CSR). The CSR will be initialized from the given labeled sentences and progressively updated through the training process. By means of extensive experiments, we show that our method can not only bring remarkable improvement to baselines, but also overall be more stable, and achieves state-of-the-art performance in semi-supervised text classification.", "paper_url": "http://arxiv.org/abs/2205.10189v1", "pdf_url": "http://arxiv.org/pdf/2205.10189v1", "repo_url": "https://github.com/heimingx/pcm"}, "2205.11509": {"publish_time": "2022-05-23", "title": "Information Propagation by Composited Labels in Natural Language Processing", "author": "Takeshi Inagaki et.al.", "abstract": "In natural language processing (NLP), labeling on regions of text, such as words, sentences and paragraphs, is a basic task. In this paper, label is defined as map between mention of entity in a region on text and context of entity in a broader region on text containing the mention. This definition naturally introduces linkage of entities induced from inclusion relation of regions, and connected entities form a graph representing information flow defined by map. It also enables calculation of information loss through map using entropy, and entropy lost is regarded as distance between two entities over a path on graph.", "paper_url": "http://arxiv.org/abs/2205.11509v1", "pdf_url": "http://arxiv.org/pdf/2205.11509v1", "repo_url": null}, "2205.11505": {"publish_time": "2022-05-23", "title": "What Makes Data-to-Text Generation Hard for Pretrained Language Models?", "author": "Moniba Keymanesh et.al.", "abstract": "Expressing natural language descriptions of structured facts or relations -- data-to-text generation (D2T) -- increases the accessibility of structured knowledge repositories. Previous work shows that pre-trained language models(PLMs) perform remarkably well on this task after fine-tuning on a significant amount of task-specific training data. On the other hand, while auto-regressive PLMs can generalize from a few task examples, their efficacy at D2T is largely unexplored. Furthermore, we have an incomplete understanding of the limits of PLMs on D2T.   In this work, we conduct an empirical study of both fine-tuned and auto-regressive PLMs on the DART multi-domain D2T dataset. We consider their performance as a function of the amount of task-specific data and how these data are incorporated into the models: zero and few-shot learning, and fine-tuning of model weights. In addition, we probe the limits of PLMs by measuring performance on subsets of the evaluation data: novel predicates and abstractive test examples. To improve the performance on these subsets, we investigate two techniques: providing predicate descriptions in the context and re-ranking generated candidates by information reflected in the source. Finally, we conduct a human evaluation of model errors and show that D2T generation tasks would benefit from datasets with more careful manual curation.", "paper_url": "http://arxiv.org/abs/2205.11505v1", "pdf_url": "http://arxiv.org/pdf/2205.11505v1", "repo_url": null}, "2205.11503": {"publish_time": "2022-05-23", "title": "Prompt-and-Rerank: A Method for Zero-Shot and Few-Shot Arbitrary Textual Style Transfer with Small Language Models", "author": "Mirac Suzgun et.al.", "abstract": "We propose a method for arbitrary textual style transfer (TST)--the task of transforming a text into any given style--utilizing general-purpose pre-trained language models. Our method, Prompt-and-Rerank, is based on a mathematical formulation of the TST task, decomposing it into three constituent components: textual similarity, target style strength, and fluency. Specifically, our method first uses zero-shot or few-shot prompting to obtain a set of candidate generations in the target style, and then re-ranks these candidates according to a combination of the three components above. Empirically, our method enables small pre-trained language models to perform on par with state-of-the-art large-scale models while consuming two orders of magnitude less compute and memory. Finally, we conduct a systematic investigation of the effect of model size and prompt design (e.g., prompt paraphrasing and delimiter-pair choice) on style transfer quality across seven diverse textual style transfer datasets.", "paper_url": "http://arxiv.org/abs/2205.11503v1", "pdf_url": "http://arxiv.org/pdf/2205.11503v1", "repo_url": null}, "2205.11502": {"publish_time": "2022-05-23", "title": "On the Paradox of Learning to Reason from Data", "author": "Honghua Zhang et.al.", "abstract": "Logical reasoning is needed in a wide range of NLP tasks. Can a BERT model be trained end-to-end to solve logical reasoning problems presented in natural language? We attempt to answer this question in a confined problem space where there exists a set of parameters that perfectly simulates logical reasoning. We make observations that seem to contradict each other: BERT attains near-perfect accuracy on in-distribution test examples while failing to generalize to other data distributions over the exact same problem space. Our study provides an explanation for this paradox: instead of learning to emulate the correct reasoning function, BERT has in fact learned statistical features that inherently exist in logical reasoning problems. We also show that it is infeasible to jointly remove statistical features from data, illustrating the difficulty of learning to reason in general. Our result naturally extends to other neural models and unveils the fundamental difference between learning to reason and learning to achieve high performance on NLP benchmarks using statistical features.", "paper_url": "http://arxiv.org/abs/2205.11502v1", "pdf_url": "http://arxiv.org/pdf/2205.11502v1", "repo_url": null}, "2205.11501": {"publish_time": "2022-05-23", "title": "VQA-GNN: Reasoning with Multimodal Semantic Graph for Visual Question Answering", "author": "Yanan Wang et.al.", "abstract": "Visual understanding requires seamless integration between recognition and reasoning: beyond image-level recognition (e.g., detecting objects), systems must perform concept-level reasoning (e.g., inferring the context of objects and intents of people). However, existing methods only model the image-level features, and do not ground them and reason with background concepts such as knowledge graphs (KGs). In this work, we propose a novel visual question answering method, VQA-GNN, which unifies the image-level information and conceptual knowledge to perform joint reasoning of the scene. Specifically, given a question-image pair, we build a scene graph from the image, retrieve a relevant linguistic subgraph from ConceptNet and visual subgraph from VisualGenome, and unify these three graphs and the question into one joint graph, multimodal semantic graph. Our VQA-GNN then learns to aggregate messages and reason across different modalities captured by the multimodal semantic graph. In the evaluation on the VCR task, our method outperforms the previous scene graph-based Trans-VL models by over 4%, and VQA-GNN-Large, our model that fuses a Trans-VL further improves the state of the art by 2%, attaining the top of the VCR leaderboard at the time of submission. This result suggests the efficacy of our model in performing conceptual reasoning beyond image-level recognition for visual understanding. Finally, we demonstrate that our model is the first work to provide interpretability across visual and textual knowledge domains for the VQA task.", "paper_url": "http://arxiv.org/abs/2205.11501v1", "pdf_url": "http://arxiv.org/pdf/2205.11501v1", "repo_url": null}, "2205.12259": {"publish_time": "2022-05-24", "title": "Policy Compliance Detection via Expression Tree Inference", "author": "Neema Kotonya et.al.", "abstract": "Policy Compliance Detection (PCD) is a task we encounter when reasoning over texts, e.g. legal frameworks. Previous work to address PCD relies heavily on modeling the task as a special case of Recognizing Textual Entailment. Entailment is applicable to the problem of PCD, however viewing the policy as a single proposition, as opposed to multiple interlinked propositions, yields poor performance and lacks explainability. To address this challenge, more recent proposals for PCD have argued for decomposing policies into expression trees consisting of questions connected with logic operators. Question answering is used to obtain answers to these questions with respect to a scenario. Finally, the expression tree is evaluated in order to arrive at an overall solution. However, this work assumes expression trees are provided by experts, thus limiting its applicability to new policies. In this work, we learn how to infer expression trees automatically from policy texts. We ensure the validity of the inferred trees by introducing constrained decoding using a finite state automaton to ensure the generation of valid trees. We determine through automatic evaluation that 63% of the expression trees generated by our constrained generation model are logically equivalent to gold trees. Human evaluation shows that 88% of trees generated by our model are correct.", "paper_url": "http://arxiv.org/abs/2205.12259v1", "pdf_url": "http://arxiv.org/pdf/2205.12259v1", "repo_url": null}, "2205.12258": {"publish_time": "2022-05-24", "title": "History Compression via Language Models in Reinforcement Learning", "author": "Fabian Paischer et.al.", "abstract": "In a partially observable Markov decision process (POMDP), an agent typically uses a representation of the past to approximate the underlying MDP. We propose to utilize a frozen Pretrained Language Transformer (PLT) for history representation and compression to improve sample efficiency. To avoid training of the Transformer, we introduce FrozenHopfield, which automatically associates observations with original token embeddings. To form these associations, a modern Hopfield network stores the original token embeddings, which are retrieved by queries that are obtained by a random but fixed projection of observations. Our new method, HELM, enables actor-critic network architectures that contain a pretrained language Transformer for history representation as a memory module. Since a representation of the past need not be learned, HELM is much more sample efficient than competitors. On Minigrid and Procgen environments HELM achieves new state-of-the-art results. Our code is available at https://github.com/ml-jku/helm.", "paper_url": "http://arxiv.org/abs/2205.12258v1", "pdf_url": "http://arxiv.org/pdf/2205.12258v1", "repo_url": null}, "2205.12255": {"publish_time": "2022-05-24", "title": "TALM: Tool Augmented Language Models", "author": "Aaron Parisi et.al.", "abstract": "Transformer based language models (LMs) demonstrate increasing performance with scale across a wide variety of tasks. Scale alone however cannot enable models to solve tasks that require access to ephemeral, changing, or private data that was unavailable at training time. Many useful tasks may also benefit from LMs being able to access APIs that read or modify state. In this work, we present Tool Augmented Language Models (TALM), combining a text-only approach to augment language models with non-differentiable tools, and an iterative \"self-play\" technique to bootstrap performance starting from few tool demonstrations. TALM exhibits strong performance on both a knowledge-heavy QA task and a reasoning oriented math task with simple tools. At a given model scale, TALM significantly outperforms non-augmented LMs. We further demonstrate that TALM successfully performs out-of-distribution inferences on both QA and math tasks, where non-augmented LMs fail. Our results suggest that Tool Augmented Language Models are a promising direction to enrich LMs' capabilities, with less dependence on scale.", "paper_url": "http://arxiv.org/abs/2205.12255v1", "pdf_url": "http://arxiv.org/pdf/2205.12255v1", "repo_url": null}, "2205.12254": {"publish_time": "2022-05-24", "title": "Interpretation Quality Score for Measuring the Quality of interpretability methods", "author": "Yuansheng Xie et.al.", "abstract": "Machine learning (ML) models have been applied to a wide range of natural language processing (NLP) tasks in recent years. In addition to making accurate decisions, the necessity of understanding how models make their decisions has become apparent in many applications. To that end, many interpretability methods that help explain the decision processes of ML models have been developed. Yet, there currently exists no widely-accepted metric to evaluate the quality of explanations generated by these methods. As a result, there currently is no standard way of measuring to what degree an interpretability method achieves an intended objective. Moreover, there is no accepted standard of performance by which we can compare and rank the current existing interpretability methods. In this paper, we propose a novel metric for quantifying the quality of explanations generated by interpretability methods. We compute the metric on three NLP tasks using six interpretability methods and present our results.", "paper_url": "http://arxiv.org/abs/2205.12254v1", "pdf_url": "http://arxiv.org/pdf/2205.12254v1", "repo_url": null}, "2205.12253": {"publish_time": "2022-05-24", "title": "Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing", "author": "Linlu Qiu et.al.", "abstract": "Despite their strong performance on many tasks, pre-trained language models have been shown to struggle on out-of-distribution compositional generalization. Meanwhile, recent work has shown considerable improvements on many NLP tasks from model scaling. Can scaling up model size also improve compositional generalization in semantic parsing? We evaluate encoder-decoder models up to 11B parameters and decoder-only models up to 540B parameters, and compare model scaling curves for three different methods for transfer learning: fine-tuning all parameters, prompt tuning, and in-context learning. We observe that fine-tuning generally has flat or negative scaling curves on out-of-distribution compositional generalization in semantic parsing evaluations. In-context learning has positive scaling curves, but is generally outperformed by much smaller fine-tuned models. Prompt-tuning can outperform fine-tuning, suggesting further potential improvements from scaling as it exhibits a more positive scaling curve. Additionally, we identify several error trends that vary with model scale. For example, larger models are generally better at modeling the syntax of the output space, but are also more prone to certain types of overfitting. Overall, our study highlights limitations of current techniques for effectively leveraging model scale for compositional generalization, while our analysis also suggests promising directions for future work.", "paper_url": "http://arxiv.org/abs/2205.12253v1", "pdf_url": "http://arxiv.org/pdf/2205.12253v1", "repo_url": null}, "2205.12914": {"publish_time": "2022-05-25", "title": "New Intent Discovery with Pre-training and Contrastive Learning", "author": "Yuwei Zhang et.al.", "abstract": "New intent discovery aims to uncover novel intent categories from user utterances to expand the set of supported intent classes. It is a critical task for the development and service expansion of a practical dialogue system. Despite its importance, this problem remains under-explored in the literature. Existing approaches typically rely on a large amount of labeled utterances and employ pseudo-labeling methods for representation learning and clustering, which are label-intensive, inefficient, and inaccurate. In this paper, we provide new solutions to two important research questions for new intent discovery: (1) how to learn semantic utterance representations and (2) how to better cluster utterances. Particularly, we first propose a multi-task pre-training strategy to leverage rich unlabeled data along with external labeled data for representation learning. Then, we design a new contrastive loss to exploit self-supervisory signals in unlabeled data for clustering. Extensive experiments on three intent recognition benchmarks demonstrate the high effectiveness of our proposed method, which outperforms state-of-the-art methods by a large margin in both unsupervised and semi-supervised scenarios. The source code will be available at \\url{https://github.com/zhang-yu-wei/MTP-CLNN}.", "paper_url": "http://arxiv.org/abs/2205.12914v1", "pdf_url": "http://arxiv.org/pdf/2205.12914v1", "repo_url": "https://github.com/zhang-yu-wei/mtp-clnn"}, "2205.12910": {"publish_time": "2022-05-25", "title": "NaturalProver: Grounded Mathematical Proof Generation with Language Models", "author": "Sean Welleck et.al.", "abstract": "Theorem proving in natural mathematical language - the mixture of symbolic and natural language used by humans - plays a central role in mathematical advances and education, and tests aspects of reasoning that are core to intelligence. Yet it has remained underexplored with modern generative models. We study large-scale language models on two new generation tasks: suggesting the next step in a mathematical proof, and full proof generation. Naively applying language models to these problems yields proofs riddled with hallucinations and logical incoherence. We develop NaturalProver, a language model that generates proofs by conditioning on background references (e.g. theorems and definitions that are either retrieved or human-provided), and optionally enforces their presence with constrained decoding. On theorems from the NaturalProofs benchmark, NaturalProver improves the quality of next-step suggestions and generated proofs over fine-tuned GPT-3, according to human evaluations from university-level mathematics students. NaturalProver is capable of proving some theorems that require short (2-6 step) proofs, and providing next-step suggestions that are rated as correct and useful over 40% of the time, which is to our knowledge the first demonstration of these capabilities using neural language models.", "paper_url": "http://arxiv.org/abs/2205.12910v1", "pdf_url": "http://arxiv.org/pdf/2205.12910v1", "repo_url": null}, "2205.12898": {"publish_time": "2022-05-25", "title": "Reasoning over Logically Interacted Conditions for Question Answering", "author": "Haitian Sun et.al.", "abstract": "Some questions have multiple answers that are not equally correct, i.e. answers are different under different conditions. Conditions are used to distinguish answers as well as to provide additional information to support them. In this paper, we study a more challenging task where answers are constrained by a list of conditions that logically interact, which requires performing logical reasoning over the conditions to determine the correctness of the answers. Even more challenging, we only provide evidences for a subset of the conditions, so some questions may not have deterministic answers. In such cases, models are asked to find probable answers and identify conditions that need to be satisfied to make the answers correct. We propose a new model, TReasoner, for this challenging reasoning task. TReasoner consists of an entailment module, a reasoning module, and a generation module (if the answers are free-form text spans). TReasoner achieves state-of-the-art performance on two benchmark conditional QA datasets, outperforming the previous state-of-the-art by 3-10 points.", "paper_url": "http://arxiv.org/abs/2205.12898v1", "pdf_url": "http://arxiv.org/pdf/2205.12898v1", "repo_url": null}, "2205.12870": {"publish_time": "2022-05-25", "title": "Open-Domain Sign Language Translation Learned from Online Video", "author": "Bowen Shi et.al.", "abstract": "Existing work on sign language translation--that is, translation from sign language videos into sentences in a written language--has focused mainly on (1) data collected in a controlled environment or (2) data in a specific domain, which limits the applicability to real-world settings. In this paper, we introduce OpenASL, a large-scale ASL-English dataset collected from online video sites (e.g., YouTube). OpenASL contains 288 hours of ASL videos in various domains (news, VLOGs, etc.) from over 200 signers and is the largest publicly available ASL translation dataset to date. To tackle the challenges of sign language translation in realistic settings and without glosses, we propose a set of techniques including sign search as a pretext task for pre-training and fusion of mouthing and handshape features. The proposed techniques produce consistent and large improvements in translation quality, over baseline models based on prior work. Our data, code and model will be publicly available at https://github.com/chevalierNoir/OpenASL", "paper_url": "http://arxiv.org/abs/2205.12870v1", "pdf_url": "http://arxiv.org/pdf/2205.12870v1", "repo_url": null}, "2205.12854": {"publish_time": "2022-05-25", "title": "Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors", "author": "Liyan Tang et.al.", "abstract": "The propensity of abstractive summarization systems to make factual errors has been the subject of significant study, including work on models to detect factual errors and annotation of errors in current systems' outputs. However, the ever-evolving nature of summarization systems, error detectors, and annotated benchmarks make factuality evaluation a moving target; it is hard to get a clear picture of how techniques compare. In this work, we collect labeled factuality errors from across nine datasets of annotated summary outputs and stratify them in a new way, focusing on what kind of base summarization model was used. To support finer-grained analysis, we unify the labeled error types into a single taxonomy and project each of the datasets' errors into this shared labeled space. We then contrast five state-of-the-art error detection methods on this benchmark. Our findings show that benchmarks built on modern summary outputs (those from pre-trained models) show significantly different results than benchmarks using pre-Transformer models. Furthermore, no one factuality technique is superior in all settings or for all error types, suggesting that system developers should take care to choose the right system for their task at hand.", "paper_url": "http://arxiv.org/abs/2205.12854v1", "pdf_url": "http://arxiv.org/pdf/2205.12854v1", "repo_url": "https://github.com/liyan06/aggrefact"}, "2205.13530": {"publish_time": "2022-05-26", "title": "Semantic Parsing of Interpage Relations", "author": "Mehmet Arif Demirta\u015f et.al.", "abstract": "Page-level analysis of documents has been a topic of interest in digitization efforts, and multimodal approaches have been applied to both classification and page stream segmentation. In this work, we focus on capturing finer semantic relations between pages of a multi-page document. To this end, we formalize the task as semantic parsing of interpage relations and we propose an end-to-end approach for interpage dependency extraction, inspired by the dependency parsing literature. We further design a multi-task training approach to jointly optimize for page embeddings to be used in segmentation, classification, and parsing of the page dependencies using textual and visual features extracted from the pages. Moreover, we also combine the features from two modalities to obtain multimodal page embeddings. To the best of our knowledge, this is the first study to extract rich semantic interpage relations from multi-page documents. Our experimental results show that the proposed method increased LAS by 41 percentage points for semantic parsing, increased accuracy by 33 percentage points for page stream segmentation, and 45 percentage points for page classification over a naive baseline.", "paper_url": "http://arxiv.org/abs/2205.13530v1", "pdf_url": "http://arxiv.org/pdf/2205.13530v1", "repo_url": null}, "2205.13434": {"publish_time": "2022-05-26", "title": "Jointly Learning Span Extraction and Sequence Labeling for Information Extraction from Business Documents", "author": "Nguyen Hong Son et.al.", "abstract": "This paper introduces a new information extraction model for business documents. Different from prior studies which only base on span extraction or sequence labeling, the model takes into account advantage of both span extraction and sequence labeling. The combination allows the model to deal with long documents with sparse information (the small amount of extracted information). The model is trained end-to-end to jointly optimize the two tasks in a unified manner. Experimental results on four business datasets in English and Japanese show that the model achieves promising results and is significantly faster than the normal span-based extraction method. The code is also available.", "paper_url": "http://arxiv.org/abs/2205.13434v1", "pdf_url": "http://arxiv.org/pdf/2205.13434v1", "repo_url": null}, "2205.13401": {"publish_time": "2022-05-26", "title": "Your Transformer May Not be as Powerful as You Expect", "author": "Shengjie Luo et.al.", "abstract": "Relative Positional Encoding (RPE), which encodes the relative distance between any pair of tokens, is one of the most successful modifications to the original Transformer. As far as we know, theoretical understanding of the RPE-based Transformers is largely unexplored. In this work, we mathematically analyze the power of RPE-based Transformers regarding whether the model is capable of approximating any continuous sequence-to-sequence functions. One may naturally assume the answer is in the affirmative -- RPE-based Transformers are universal function approximators. However, we present a negative result by showing there exist continuous sequence-to-sequence functions that RPE-based Transformers cannot approximate no matter how deep and wide the neural network is. One key reason lies in that most RPEs are placed in the softmax attention that always generates a right stochastic matrix. This restricts the network from capturing positional information in the RPEs and limits its capacity. To overcome the problem and make the model more powerful, we first present sufficient conditions for RPE-based Transformers to achieve universal function approximation. With the theoretical guidance, we develop a novel attention module, called Universal RPE-based (URPE) Attention, which satisfies the conditions. Therefore, the corresponding URPE-based Transformers become universal function approximators. Extensive experiments covering typical architectures and tasks demonstrate that our model is parameter-efficient and can achieve superior performance to strong baselines in a wide range of applications.", "paper_url": "http://arxiv.org/abs/2205.13401v1", "pdf_url": "http://arxiv.org/pdf/2205.13401v1", "repo_url": null}, "2205.13357": {"publish_time": "2022-05-26", "title": "The Document Vectors Using Cosine Similarity Revisited", "author": "Zhang Bingyu et.al.", "abstract": "The current state-of-the-art test accuracy (97.42\\%) on the IMDB movie reviews dataset was reported by \\citet{thongtan-phienthrakul-2019-sentiment} and achieved by the logistic regression classifier trained on the Document Vectors using Cosine Similarity (DV-ngrams-cosine) proposed in their paper and the Bag-of-N-grams (BON) vectors scaled by Naive Bayesian weights. While large pre-trained Transformer-based models have shown SOTA results across many datasets and tasks, the aforementioned model has not been surpassed by them, despite being much simpler and pre-trained on the IMDB dataset only.   In this paper, we describe an error in the evaluation procedure of this model, which was found when we were trying to analyze its excellent performance on the IMDB dataset. We further show that the previously reported test accuracy of 97.42\\% is invalid and should be corrected to 93.68\\%. We also analyze the model performance with different amounts of training data (subsets of the IMDB dataset) and compare it to the Transformer-based RoBERTa model. The results show that while RoBERTa has a clear advantage for larger training sets, the DV-ngrams-cosine performs better than RoBERTa when the labelled training set is very small (10 or 20 documents). Finally, we introduce a sub-sampling scheme based on Naive Bayesian weights for the training process of the DV-ngrams-cosine, which leads to faster training and better quality.", "paper_url": "http://arxiv.org/abs/2205.13357v1", "pdf_url": "http://arxiv.org/pdf/2205.13357v1", "repo_url": "https://github.com/bgzh/dv_cosine_revisited"}, "2205.13346": {"publish_time": "2022-05-26", "title": "Keywords and Instances: A Hierarchical Contrastive Learning Framework Unifying Hybrid Granularities for Text Generation", "author": "Mingzhe Li et.al.", "abstract": "Contrastive learning has achieved impressive success in generation tasks to militate the \"exposure bias\" problem and discriminatively exploit the different quality of references. Existing works mostly focus on contrastive learning on the instance-level without discriminating the contribution of each word, while keywords are the gist of the text and dominant the constrained mapping relationships. Hence, in this work, we propose a hierarchical contrastive learning mechanism, which can unify hybrid granularities semantic meaning in the input text. Concretely, we first propose a keyword graph via contrastive correlations of positive-negative pairs to iteratively polish the keyword representations. Then, we construct intra-contrasts within instance-level and keyword-level, where we assume words are sampled nodes from a sentence distribution. Finally, to bridge the gap between independent contrast levels and tackle the common contrast vanishing problem, we propose an inter-contrast mechanism that measures the discrepancy between contrastive keyword nodes respectively to the instance distribution. Experiments demonstrate that our model outperforms competitive baselines on paraphrasing, dialogue generation, and storytelling tasks.", "paper_url": "http://arxiv.org/abs/2205.13346v1", "pdf_url": "http://arxiv.org/pdf/2205.13346v1", "repo_url": null}, "2205.14140": {"publish_time": "2022-05-27", "title": "CEBaB: Estimating the Causal Effects of Real-World Concepts on NLP Model Behavior", "author": "Eldar David Abraham et.al.", "abstract": "The increasing size and complexity of modern ML systems has improved their predictive capabilities but made their behavior harder to explain. Many techniques for model explanation have been developed in response, but we lack clear criteria for assessing these techniques. In this paper, we cast model explanation as the causal inference problem of estimating causal effects of real-world concepts on the output behavior of ML models given actual input data. We introduce CEBaB, a new benchmark dataset for assessing concept-based explanation methods in Natural Language Processing (NLP). CEBaB consists of short restaurant reviews with human-generated counterfactual reviews in which an aspect (food, noise, ambiance, service) of the dining experience was modified. Original and counterfactual reviews are annotated with multiply-validated sentiment ratings at the aspect-level and review-level. The rich structure of CEBaB allows us to go beyond input features to study the effects of abstract, real-world concepts on model behavior. We use CEBaB to compare the quality of a range of concept-based explanation methods covering different assumptions and conceptions of the problem, and we seek to establish natural metrics for comparative assessments of these methods.", "paper_url": "http://arxiv.org/abs/2205.14140v1", "pdf_url": "http://arxiv.org/pdf/2205.14140v1", "repo_url": null}, "2205.14086": {"publish_time": "2022-05-27", "title": "Patching Leaks in the Charformer for Efficient Character-Level Generation", "author": "Lukas Edman et.al.", "abstract": "Character-based representations have important advantages over subword-based ones for morphologically rich languages. They come with increased robustness to noisy input and do not need a separate tokenization step. However, they also have a crucial disadvantage: they notably increase the length of text sequences. The GBST method from Charformer groups (aka downsamples) characters to solve this, but allows information to leak when applied to a Transformer decoder. We solve this information leak issue, thereby enabling character grouping in the decoder. We show that Charformer downsampling has no apparent benefits in NMT over previous downsampling methods in terms of translation quality, however it can be trained roughly 30% faster. Promising performance on English--Turkish translation indicate the potential of character-level models for morphologically-rich languages.", "paper_url": "http://arxiv.org/abs/2205.14086v1", "pdf_url": "http://arxiv.org/pdf/2205.14086v1", "repo_url": "https://github.com/leukas/patchinggbst"}, "2205.14084": {"publish_time": "2022-05-27", "title": "UAlberta at SemEval 2022 Task 2: Leveraging Glosses and Translations for Multilingual Idiomaticity Detection", "author": "Bradley Hauer et.al.", "abstract": "We describe the University of Alberta systems for the SemEval-2022 Task 2 on multilingual idiomaticity detection. Working under the assumption that idiomatic expressions are noncompositional, our first method integrates information on the meanings of the individual words of an expression into a binary classifier. Further hypothesizing that literal and idiomatic expressions translate differently, our second method translates an expression in context, and uses a lexical knowledge base to determine if the translation is literal. Our approaches are grounded in linguistic phenomena, and leverage existing sources of lexical knowledge. Our results offer support for both approaches, particularly the former.", "paper_url": "http://arxiv.org/abs/2205.14084v1", "pdf_url": "http://arxiv.org/pdf/2205.14084v1", "repo_url": null}, "2205.14036": {"publish_time": "2022-05-27", "title": "StereoKG: Data-Driven Knowledge Graph Construction for Cultural Knowledge and Stereotypes", "author": "Awantee Deshpande et.al.", "abstract": "Analyzing ethnic or religious bias is important for improving fairness, accountability, and transparency of natural language processing models. However, many techniques rely on human-compiled lists of bias terms, which are expensive to create and are limited in coverage. In this study, we present a fully data-driven pipeline for generating a knowledge graph (KG) of cultural knowledge and stereotypes. Our resulting KG covers 5 religious groups and 5 nationalities and can easily be extended to include more entities. Our human evaluation shows that the majority (59.2%) of non-singleton entries are coherent and complete stereotypes. We further show that performing intermediate masked language model training on the verbalized KG leads to a higher level of cultural awareness in the model and has the potential to increase classification performance on knowledge-crucial samples on a related task, i.e., hate speech detection.", "paper_url": "http://arxiv.org/abs/2205.14036v1", "pdf_url": "http://arxiv.org/pdf/2205.14036v1", "repo_url": "https://github.com/uds-lsv/stereokg"}, "2205.14014": {"publish_time": "2022-05-27", "title": "What Dense Graph Do You Need for Self-Attention?", "author": "Yuxing Wang et.al.", "abstract": "Transformers have made progress in miscellaneous tasks, but suffer from quadratic computational and memory complexities. Recent works propose sparse Transformers with attention on sparse graphs to reduce complexity and remain strong performance. While effective, the crucial parts of how dense a graph needs to be to perform well are not fully explored. In this paper, we propose Normalized Information Payload (NIP), a graph scoring function measuring information transfer on graph, which provides an analysis tool for trade-offs between performance and complexity. Guided by this theoretical analysis, we present Hypercube Transformer, a sparse Transformer that models token interactions in a hypercube and shows comparable or even better results with vanilla Transformer while yielding $O(N\\log N)$ complexity with sequence length $N$. Experiments on tasks requiring various sequence lengths lay validation for our graph function well.", "paper_url": "http://arxiv.org/abs/2205.14014v1", "pdf_url": "http://arxiv.org/pdf/2205.14014v1", "repo_url": "https://github.com/yxzwang/normalized-information-payload"}, "2205.15301": {"publish_time": "2022-05-30", "title": "Can Transformer be Too Compositional? Analysing Idiom Processing in Neural Machine Translation", "author": "Verna Dankers et.al.", "abstract": "Unlike literal expressions, idioms' meanings do not directly follow from their parts, posing a challenge for neural machine translation (NMT). NMT models are often unable to translate idioms accurately and over-generate compositional, literal translations. In this work, we investigate whether the non-compositionality of idioms is reflected in the mechanics of the dominant NMT model, Transformer, by analysing the hidden states and attention patterns for models with English as source language and one of seven European languages as target language. When Transformer emits a non-literal translation - i.e. identifies the expression as idiomatic - the encoder processes idioms more strongly as single lexical units compared to literal expressions. This manifests in idioms' parts being grouped through attention and in reduced interaction between idioms and their context. In the decoder's cross-attention, figurative inputs result in reduced attention on source-side tokens. These results suggest that Transformer's tendency to process idioms as compositional expressions contributes to literal translations of idioms.", "paper_url": "http://arxiv.org/abs/2205.15301v1", "pdf_url": "http://arxiv.org/pdf/2205.15301v1", "repo_url": null}, "2205.15281": {"publish_time": "2022-05-30", "title": "Learning Open Domain Multi-hop Search Using Reinforcement Learning", "author": "Enrique Noriega-Atala et.al.", "abstract": "We propose a method to teach an automated agent to learn how to search for multi-hop paths of relations between entities in an open domain. The method learns a policy for directing existing information retrieval and machine reading resources to focus on relevant regions of a corpus. The approach formulates the learning problem as a Markov decision process with a state representation that encodes the dynamics of the search process and a reward structure that minimizes the number of documents that must be processed while still finding multi-hop paths. We implement the method in an actor-critic reinforcement learning algorithm and evaluate it on a dataset of search problems derived from a subset of English Wikipedia. The algorithm finds a family of policies that succeeds in extracting the desired information while processing fewer documents compared to several baseline heuristic algorithms.", "paper_url": "http://arxiv.org/abs/2205.15281v1", "pdf_url": "http://arxiv.org/pdf/2205.15281v1", "repo_url": null}, "2205.15237": {"publish_time": "2022-05-30", "title": "VLUE: A Multi-Task Benchmark for Evaluating Vision-Language Models", "author": "Wangchunshu Zhou et.al.", "abstract": "Recent advances in vision-language pre-training (VLP) have demonstrated impressive performance in a range of vision-language (VL) tasks. However, there exist several challenges for measuring the community's progress in building general multi-modal intelligence. First, most of the downstream VL datasets are annotated using raw images that are already seen during pre-training, which may result in an overestimation of current VLP models' generalization ability. Second, recent VLP work mainly focuses on absolute performance but overlooks the efficiency-performance trade-off, which is also an important indicator for measuring progress.   To this end, we introduce the Vision-Language Understanding Evaluation (VLUE) benchmark, a multi-task multi-dimension benchmark for evaluating the generalization capabilities and the efficiency-performance trade-off (``Pareto SOTA'') of VLP models. We demonstrate that there is a sizable generalization gap for all VLP models when testing on out-of-distribution test sets annotated on images from a more diverse distribution that spreads across cultures. Moreover, we find that measuring the efficiency-performance trade-off of VLP models leads to complementary insights for several design choices of VLP. We release the VLUE benchmark to promote research on building vision-language models that generalize well to more diverse images and concepts unseen during pre-training, and are practical in terms of efficiency-performance trade-off.", "paper_url": "http://arxiv.org/abs/2205.15237v1", "pdf_url": "http://arxiv.org/pdf/2205.15237v1", "repo_url": "https://github.com/michaelzhouwang/vlue"}, "2205.15231": {"publish_time": "2022-05-30", "title": "A Survey in Mathematical Language Processing", "author": "Jordan Meadows et.al.", "abstract": "Informal mathematical text underpins real-world quantitative reasoning and communication. Developing sophisticated methods of retrieval and abstraction from this dual modality is crucial in the pursuit of the vision of automating discovery in quantitative science and mathematics. We track the development of informal mathematical language processing approaches across five strategic sub-areas in recent years, highlighting the prevailing successful methodological elements along with existing limitations.", "paper_url": "http://arxiv.org/abs/2205.15231v1", "pdf_url": "http://arxiv.org/pdf/2205.15231v1", "repo_url": null}, "2205.15223": {"publish_time": "2022-05-30", "title": "Prompting ELECTRA: Few-Shot Learning with Discriminative Pre-Trained Models", "author": "Mengzhou Xia et.al.", "abstract": "Pre-trained masked language models successfully perform few-shot learning by formulating downstream tasks as text infilling. However, as a strong alternative in full-shot settings, discriminative pre-trained models like ELECTRA do not fit into the paradigm. In this work, we adapt prompt-based few-shot learning to ELECTRA and show that it outperforms masked language models in a wide range of tasks. ELECTRA is pre-trained to distinguish if a token is generated or original. We naturally extend that to prompt-based few-shot learning by training to score the originality of the target options without introducing new parameters. Our method can be easily adapted to tasks involving multi-token predictions without extra computation overhead. Analysis shows that ELECTRA learns distributions that align better with downstream tasks.", "paper_url": "http://arxiv.org/abs/2205.15223v1", "pdf_url": "http://arxiv.org/pdf/2205.15223v1", "repo_url": null}, "2205.16005": {"publish_time": "2022-05-31", "title": "Neural Retriever and Go Beyond: A Thesis Proposal", "author": "Man Luo et.al.", "abstract": "Information Retriever (IR) aims to find the relevant documents (e.g. snippets, passages, and articles) to a given query at large scale. IR plays an important role in many tasks such as open domain question answering and dialogue systems, where external knowledge is needed. In the past, searching algorithms based on term matching have been widely used. Recently, neural-based algorithms (termed as neural retrievers) have gained more attention which can mitigate the limitations of traditional methods. Regardless of the success achieved by neural retrievers, they still face many challenges, e.g. suffering from a small amount of training data and failing to answer simple entity-centric questions. Furthermore, most of the existing neural retrievers are developed for pure-text query. This prevents them from handling multi-modality queries (i.e. the query is composed of textual description and images). This proposal has two goals. First, we introduce methods to address the abovementioned issues of neural retrievers from three angles, new model architectures, IR-oriented pretraining tasks, and generating large scale training data. Second, we identify the future research direction and propose potential corresponding solution.", "paper_url": "http://arxiv.org/abs/2205.16005v1", "pdf_url": "http://arxiv.org/pdf/2205.16005v1", "repo_url": null}, "2205.16001": {"publish_time": "2022-05-31", "title": "Cluster-based Evaluation of Automatically Generated Text", "author": "Tiago Pimentel et.al.", "abstract": "While probabilistic language generators have improved dramatically over the last few years, the automatic evaluation metrics used to assess them have not kept pace with this progress. In the domain of language generation, a good metric must correlate highly with human judgements. Yet, with few exceptions, there is a lack of such metrics in the literature. In this work, we analyse the general paradigm of language generator evaluation. We first discuss the computational and qualitative issues with using automatic evaluation metrics that operate on probability distributions over strings, the backbone of most language generators. We then propose the use of distributions over clusters instead, where we cluster strings based on their text embeddings (obtained from a pretrained language model). While we find the biases introduced by this substitution to be quite strong, we observe that, empirically, this methodology leads to metric estimators with higher correlation with human judgements, while simultaneously reducing estimator variance. We finish the paper with a probing analysis, which leads us to conclude that -- by encoding syntactic- and coherence-level features of text, while ignoring surface-level features -- these clusters may simply be better equipped to evaluate state-of-the-art language models.", "paper_url": "http://arxiv.org/abs/2205.16001v1", "pdf_url": "http://arxiv.org/pdf/2205.16001v1", "repo_url": null}, "2205.15960": {"publish_time": "2022-05-31", "title": "NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages", "author": "Genta Indra Winata et.al.", "abstract": "Natural language processing (NLP) has a significant impact on society via technologies such as machine translation and search engines. Despite its success, NLP technology is only widely available for high-resource languages such as English and Chinese, while it remains inaccessible to many languages due to the unavailability of data resources and benchmarks. In this work, we focus on developing resources for languages in Indonesia. Despite being the second most linguistically diverse country, most languages in Indonesia are categorized as endangered and some are even extinct. We develop the first-ever parallel resource for 10 low-resource languages in Indonesia. Our resource includes datasets, a multi-task benchmark, and lexicons, as well as a parallel Indonesian-English dataset. We provide extensive analyses and describe the challenges when creating such resources. We hope that our work can spark NLP research on Indonesian and other underrepresented languages.", "paper_url": "http://arxiv.org/abs/2205.15960v1", "pdf_url": "http://arxiv.org/pdf/2205.15960v1", "repo_url": "https://github.com/indonlp/nusax"}, "2205.15952": {"publish_time": "2022-05-31", "title": "Knowledge Graph -- Deep Learning: A Case Study in Question Answering in Aviation Safety Domain", "author": "Ankush Agarwal et.al.", "abstract": "In the commercial aviation domain, there are a large number of documents, like, accident reports (NTSB, ASRS) and regulatory directives (ADs). There is a need for a system to access these diverse repositories efficiently in order to service needs in the aviation industry, like maintenance, compliance, and safety. In this paper, we propose a Knowledge Graph (KG) guided Deep Learning (DL) based Question Answering (QA) system for aviation safety. We construct a Knowledge Graph from Aircraft Accident reports and contribute this resource to the community of researchers. The efficacy of this resource is tested and proved by the aforesaid QA system. Natural Language Queries constructed from the documents mentioned above are converted into SPARQL (the interface language of the RDF graph database) queries and answered. On the DL side, we have two different QA models: (i) BERT QA which is a pipeline of Passage Retrieval (Sentence-BERT based) and Question Answering (BERT based), and (ii) the recently released GPT-3. We evaluate our system on a set of queries created from the accident reports. Our combined QA system achieves 9.3% increase in accuracy over GPT-3 and 40.3% increase over BERT QA. Thus, we infer that KG-DL performs better than either singly.", "paper_url": "http://arxiv.org/abs/2205.15952v1", "pdf_url": "http://arxiv.org/pdf/2205.15952v1", "repo_url": null}, "2205.15951": {"publish_time": "2022-05-31", "title": "Hollywood Identity Bias Dataset: A Context Oriented Bias Analysis of Movie Dialogues", "author": "Sandhya Singh et.al.", "abstract": "Movies reflect society and also hold power to transform opinions. Social biases and stereotypes present in movies can cause extensive damage due to their reach. These biases are not always found to be the need of storyline but can creep in as the author's bias. Movie production houses would prefer to ascertain that the bias present in a script is the story's demand. Today, when deep learning models can give human-level accuracy in multiple tasks, having an AI solution to identify the biases present in the script at the writing stage can help them avoid the inconvenience of stalled release, lawsuits, etc. Since AI solutions are data intensive and there exists no domain specific data to address the problem of biases in scripts, we introduce a new dataset of movie scripts that are annotated for identity bias. The dataset contains dialogue turns annotated for (i) bias labels for seven categories, viz., gender, race/ethnicity, religion, age, occupation, LGBTQ, and other, which contains biases like body shaming, personality bias, etc. (ii) labels for sensitivity, stereotype, sentiment, emotion, emotion intensity, (iii) all labels annotated with context awareness, (iv) target groups and reason for bias labels and (v) expert-driven group-validation process for high quality annotations. We also report various baseline performances for bias identification and category detection on our dataset.", "paper_url": "http://arxiv.org/abs/2205.15951v1", "pdf_url": "http://arxiv.org/pdf/2205.15951v1", "repo_url": null}, "2206.00621": {"publish_time": "2022-06-01", "title": "Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training", "author": "Yan Zeng et.al.", "abstract": "In this paper, we introduce Cross-View Language Modeling, a simple and effective language model pre-training framework that unifies cross-lingual cross-modal pre-training with shared architectures and objectives. Our approach is motivated by a key observation that cross-lingual and cross-modal pre-training share the same goal of aligning two different views of the same object into a common semantic space. To this end, the cross-view language modeling framework considers both multi-modal data (i.e., image-caption pairs) and multi-lingual data (i.e., parallel sentence pairs) as two different views of the same object, and trains the model to align the two views by maximizing the mutual information between them with conditional masked language modeling and contrastive learning. We pre-train CCLM, a Cross-lingual Cross-modal Language Model, with the cross-view language modeling framework. Empirical results on IGLUE, a multi-lingual multi-modal benchmark, and two multi-lingual image-text retrieval datasets show that while conceptually simpler, CCLM significantly outperforms the prior state-of-the-art with an average absolute improvement of over 10%. Notably, CCLM is the first multi-lingual multi-modal model that surpasses the translate-test performance of representative English vision-language models by zero-shot cross-lingual transfer.", "paper_url": "http://arxiv.org/abs/2206.00621v1", "pdf_url": "http://arxiv.org/pdf/2206.00621v1", "repo_url": null}, "2206.00564": {"publish_time": "2022-06-01", "title": "Exploring Diversity in Back Translation for Low-Resource Machine Translation", "author": "Laurie Burchell et.al.", "abstract": "Back translation is one of the most widely used methods for improving the performance of neural machine translation systems. Recent research has sought to enhance the effectiveness of this method by increasing the 'diversity' of the generated translations. We argue that the definitions and metrics used to quantify 'diversity' in previous work have been insufficient. This work puts forward a more nuanced framework for understanding diversity in training data, splitting it into lexical diversity and syntactic diversity. We present novel metrics for measuring these different aspects of diversity and carry out empirical analysis into the effect of these types of diversity on final neural machine translation model performance for low-resource English$\\leftrightarrow$Turkish and mid-resource English$\\leftrightarrow$Icelandic. Our findings show that generating back translation using nucleus sampling results in higher final model performance, and that this method of generation has high levels of both lexical and syntactic diversity. We also find evidence that lexical diversity is more important than syntactic for back translation performance.", "paper_url": "http://arxiv.org/abs/2206.00564v1", "pdf_url": "http://arxiv.org/pdf/2206.00564v1", "repo_url": "https://github.com/laurieburchell/exploring-diversity-bt"}, "2206.00524": {"publish_time": "2022-06-01", "title": "Vietnamese Hate and Offensive Detection using PhoBERT-CNN and Social Media Streaming Data", "author": "Khanh Q. Tran et.al.", "abstract": "Society needs to develop a system to detect hate and offense to build a healthy and safe environment. However, current research in this field still faces four major shortcomings, including deficient pre-processing techniques, indifference to data imbalance issues, modest performance models, and lacking practical applications. This paper focused on developing an intelligent system capable of addressing these shortcomings. Firstly, we proposed an efficient pre-processing technique to clean comments collected from Vietnamese social media. Secondly, a novel hate speech detection (HSD) model, which is the combination of a pre-trained PhoBERT model and a Text-CNN model, was proposed for solving tasks in Vietnamese. Thirdly, EDA techniques are applied to deal with imbalanced data to improve the performance of classification models. Besides, various experiments were conducted as baselines to compare and investigate the proposed model's performance against state-of-the-art methods. The experiment results show that the proposed PhoBERT-CNN model outperforms SOTA methods and achieves an F1-score of 67,46% and 98,45% on two benchmark datasets, ViHSD and HSD-VLSP, respectively. Finally, we also built a streaming HSD application to demonstrate the practicality of our proposed system.", "paper_url": "http://arxiv.org/abs/2206.00524v1", "pdf_url": "http://arxiv.org/pdf/2206.00524v1", "repo_url": "https://github.com/khanhtran0412/visomecens"}, "2206.00437": {"publish_time": "2022-06-01", "title": "What a Creole Wants, What a Creole Needs", "author": "Heather Lent et.al.", "abstract": "In recent years, the natural language processing (NLP) community has given increased attention to the disparity of efforts directed towards high-resource languages over low-resource ones. Efforts to remedy this delta often begin with translations of existing English datasets into other languages. However, this approach ignores that different language communities have different needs. We consider a group of low-resource languages, Creole languages. Creoles are both largely absent from the NLP literature, and also often ignored by society at large due to stigma, despite these languages having sizable and vibrant communities. We demonstrate, through conversations with Creole experts and surveys of Creole-speaking communities, how the things needed from language technology can change dramatically from one language to another, even when the languages are considered to be very similar to each other, as with Creoles. We discuss the prominent themes arising from these conversations, and ultimately demonstrate that useful language technology cannot be built without involving the relevant community.", "paper_url": "http://arxiv.org/abs/2206.00437v1", "pdf_url": "http://arxiv.org/pdf/2206.00437v1", "repo_url": null}, "2206.00372": {"publish_time": "2022-06-01", "title": "BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate Speech in Different Social Contexts", "author": "Nauros Romim et.al.", "abstract": "Social media platforms and online streaming services have spawned a new breed of Hate Speech (HS). Due to the massive amount of user-generated content on these sites, modern machine learning techniques are found to be feasible and cost-effective to tackle this problem. However, linguistically diverse datasets covering different social contexts in which offensive language is typically used are required to train generalizable models. In this paper, we identify the shortcomings of existing Bangla HS datasets and introduce a large manually labeled dataset BD-SHS that includes HS in different social contexts. The labeling criteria were prepared following a hierarchical annotation process, which is the first of its kind in Bangla HS to the best of our knowledge. The dataset includes more than 50,200 offensive comments crawled from online social networking sites and is at least 60% larger than any existing Bangla HS datasets. We present the benchmark result of our dataset by training different NLP models resulting in the best one achieving an F1-score of 91.0%. In our experiments, we found that a word embedding trained exclusively using 1.47 million comments from social media and streaming sites consistently resulted in better modeling of HS detection in comparison to other pre-trained embeddings. Our dataset and all accompanying codes is publicly available at github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media", "paper_url": "http://arxiv.org/abs/2206.00372v1", "pdf_url": "http://arxiv.org/pdf/2206.00372v1", "repo_url": null}, "2206.01201": {"publish_time": "2022-06-02", "title": "REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering", "author": "Yuanze Lin et.al.", "abstract": "This paper revisits visual representation in knowledge-based visual question answering (VQA) and demonstrates that using regional information in a better way can significantly improve the performance. While visual representation is extensively studied in traditional VQA, it is under-explored in knowledge-based VQA even though these two tasks share the common spirit, i.e., rely on visual input to answer the question. Specifically, we observe that in most state-of-the-art knowledge-based VQA methods: 1) visual features are extracted either from the whole image or in a sliding window manner for retrieving knowledge, and the important relationship within/among object regions is neglected; 2) visual features are not well utilized in the final answering model, which is counter-intuitive to some extent. Based on these observations, we propose a new knowledge-based VQA method REVIVE, which tries to utilize the explicit information of object regions not only in the knowledge retrieval stage but also in the answering model. The key motivation is that object regions and inherent relationships are important for knowledge-based VQA. We perform extensive experiments on the standard OK-VQA dataset and achieve new state-of-the-art performance, i.e., 58.0% accuracy, surpassing previous state-of-the-art method by a large margin (+3.6%). We also conduct detailed analysis and show the necessity of regional information in different framework components for knowledge-based VQA.", "paper_url": "http://arxiv.org/abs/2206.01201v1", "pdf_url": "http://arxiv.org/pdf/2206.01201v1", "repo_url": null}, "2206.01137": {"publish_time": "2022-06-02", "title": "Finding the Right Recipe for Low Resource Domain Adaptation in Neural Machine Translation", "author": "Virginia Adams et.al.", "abstract": "General translation models often still struggle to generate accurate translations in specialized domains. To guide machine translation practitioners and characterize the effectiveness of domain adaptation methods under different data availability scenarios, we conduct an in-depth empirical exploration of monolingual and parallel data approaches to domain adaptation of pre-trained, third-party, NMT models in settings where architecture change is impractical. We compare data centric adaptation methods in isolation and combination. We study method effectiveness in very low resource (8k parallel examples) and moderately low resource (46k parallel examples) conditions and propose an ensemble approach to alleviate reductions in original domain translation quality. Our work includes three domains: consumer electronic, clinical, and biomedical and spans four language pairs - Zh-En, Ja-En, Es-En, and Ru-En. We also make concrete recommendations for achieving high in-domain performance and release our consumer electronic and medical domain datasets for all languages and make our code publicly available.", "paper_url": "http://arxiv.org/abs/2206.01137v1", "pdf_url": "http://arxiv.org/pdf/2206.01137v1", "repo_url": null}, "2206.01134": {"publish_time": "2022-06-02", "title": "Vygotskian Autotelic Artificial Intelligence: Language and Culture Internalization for Human-Like AI", "author": "C\u00e9dric Colas et.al.", "abstract": "Building autonomous artificial agents able to grow open-ended repertoires of skills is one of the fundamental goals of AI. To that end, a promising developmental approach recommends the design of intrinsically motivated agents that learn new skills by generating and pursuing their own goals - autotelic agents. However, existing algorithms still show serious limitations in terms of goal diversity, exploration, generalization or skill composition. This perspective calls for the immersion of autotelic agents into rich socio-cultural worlds. We focus on language especially, and how its structure and content may support the development of new cognitive functions in artificial agents, just like it does in humans. Indeed, most of our skills could not be learned in isolation. Formal education teaches us to reason systematically, books teach us history, and YouTube might teach us how to cook. Crucially, our values, traditions, norms and most of our goals are cultural in essence. This knowledge, and some argue, some of our cognitive functions such as abstraction, compositional imagination or relational thinking, are formed through linguistic and cultural interactions. Inspired by the work of Vygotsky, we suggest the design of Vygotskian autotelic agents able to interact with others and, more importantly, able to internalize these interactions to transform them into cognitive tools supporting the development of new cognitive functions. This perspective paper proposes a new AI paradigm in the quest for artificial lifelong skill discovery. It justifies the approach by uncovering examples of new artificial cognitive functions emerging from interactions between language and embodiment in recent works at the intersection of deep reinforcement learning and natural language processing. Looking forward, it highlights future opportunities and challenges for Vygotskian Autotelic AI research.", "paper_url": "http://arxiv.org/abs/2206.01134v1", "pdf_url": "http://arxiv.org/pdf/2206.01134v1", "repo_url": null}, "2206.01127": {"publish_time": "2022-06-02", "title": "VL-BEiT: Generative Vision-Language Pretraining", "author": "Hangbo Bao et.al.", "abstract": "We introduce a vision-language foundation model called VL-BEiT, which is a bidirectional multimodal Transformer learned by generative pretraining. Our minimalist solution conducts masked prediction on both monomodal and multimodal data with a shared Transformer. Specifically, we perform masked vision-language modeling on image-text pairs, masked language modeling on texts, and masked image modeling on images. VL-BEiT is learned from scratch with one unified pretraining task, one shared backbone, and one-stage training. Our method is conceptually simple and empirically effective. Experimental results show that VL-BEiT obtains strong results on various vision-language benchmarks, such as visual question answering, visual reasoning, and image-text retrieval. Moreover, our method learns transferable visual features, achieving competitive performance on image classification, and semantic segmentation.", "paper_url": "http://arxiv.org/abs/2206.01127v1", "pdf_url": "http://arxiv.org/pdf/2206.01127v1", "repo_url": null}, "2206.00962": {"publish_time": "2022-06-02", "title": "Transfer Language Selection for Zero-Shot Cross-Lingual Abusive Language Detection", "author": "Juuso Eronen et.al.", "abstract": "We study the selection of transfer languages for automatic abusive language detection. Instead of preparing a dataset for every language, we demonstrate the effectiveness of cross-lingual transfer learning for zero-shot abusive language detection. This way we can use existing data from higher-resource languages to build better detection systems for low-resource languages. Our datasets are from seven different languages from three language families. We measure the distance between the languages using several language similarity measures, especially by quantifying the World Atlas of Language Structures. We show that there is a correlation between linguistic similarity and classifier performance. This discovery allows us to choose an optimal transfer language for zero shot abusive language detection.", "paper_url": "http://arxiv.org/abs/2206.00962v1", "pdf_url": "http://arxiv.org/pdf/2206.00962v1", "repo_url": null}, "2206.01720": {"publish_time": "2022-06-03", "title": "Revisiting the \"Video\" in Video-Language Understanding", "author": "Shyamal Buch et.al.", "abstract": "What makes a video task uniquely suited for videos, beyond what can be understood from a single image? Building on recent progress in self-supervised image-language models, we revisit this question in the context of video and language tasks. We propose the atemporal probe (ATP), a new model for video-language analysis which provides a stronger bound on the baseline accuracy of multimodal models constrained by image-level understanding. By applying this model to standard discriminative video and language tasks, such as video question answering and text-to-video retrieval, we characterize the limitations and potential of current video-language benchmarks. We find that understanding of event temporality is often not necessary to achieve strong or state-of-the-art performance, even compared with recent large-scale video-language models and in contexts intended to benchmark deeper video-level understanding. We also demonstrate how ATP can improve both video-language dataset and model design. We describe a technique for leveraging ATP to better disentangle dataset subsets with a higher concentration of temporally challenging data, improving benchmarking efficacy for causal and temporal understanding. Further, we show that effectively integrating ATP into full video-level temporal models can improve efficiency and state-of-the-art accuracy.", "paper_url": "http://arxiv.org/abs/2206.01720v1", "pdf_url": "http://arxiv.org/pdf/2206.01720v1", "repo_url": null}, "2206.01718": {"publish_time": "2022-06-03", "title": "A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge", "author": "Dustin Schwenk et.al.", "abstract": "The Visual Question Answering (VQA) task aspires to provide a meaningful testbed for the development of AI models that can jointly reason over visual and natural language inputs. Despite a proliferation of VQA datasets, this goal is hindered by a set of common limitations. These include a reliance on relatively simplistic questions that are repetitive in both concepts and linguistic structure, little world knowledge needed outside of the paired image, and limited reasoning required to arrive at the correct answer. We introduce A-OKVQA, a crowdsourced dataset composed of a diverse set of about 25K questions requiring a broad base of commonsense and world knowledge to answer. In contrast to the existing knowledge-based VQA datasets, the questions generally cannot be answered by simply querying a knowledge base, and instead require some form of commonsense reasoning about the scene depicted in the image. We demonstrate the potential of this new dataset through a detailed analysis of its contents and baseline performance measurements over a variety of state-of-the-art vision-language models. Project page: http://a-okvqa.allenai.org/", "paper_url": "http://arxiv.org/abs/2206.01718v1", "pdf_url": "http://arxiv.org/pdf/2206.01718v1", "repo_url": null}, "2206.01691": {"publish_time": "2022-06-03", "title": "Measuring Gender Bias in Word Embeddings of Gendered Languages Requires Disentangling Grammatical Gender Signals", "author": "Shiva Omrani Sabbaghi et.al.", "abstract": "Does the grammatical gender of a language interfere when measuring the semantic gender information captured by its word embeddings? A number of anomalous gender bias measurements in the embeddings of gendered languages suggest this possibility. We demonstrate that word embeddings learn the association between a noun and its grammatical gender in grammatically gendered languages, which can skew social gender bias measurements. Consequently, word embedding post-processing methods are introduced to quantify, disentangle, and evaluate grammatical gender signals. The evaluation is performed on five gendered languages from the Germanic, Romance, and Slavic branches of the Indo-European language family. Our method reduces the strength of grammatical gender signals, which is measured in terms of effect size (Cohen's d), by a significant average of d = 1.3 for French, German, and Italian, and d = 0.56 for Polish and Spanish. Once grammatical gender is disentangled, the association between over 90% of 10,000 inanimate nouns and their assigned grammatical gender weakens, and cross-lingual bias results from the Word Embedding Association Test (WEAT) become more congruent with country-level implicit bias measurements. The results further suggest that disentangling grammatical gender signals from word embeddings may lead to improvement in semantic machine learning tasks.", "paper_url": "http://arxiv.org/abs/2206.01691v1", "pdf_url": "http://arxiv.org/pdf/2206.01691v1", "repo_url": "https://github.com/shivaomrani/gg_disentangling"}, "2206.01685": {"publish_time": "2022-06-03", "title": "Toward a realistic model of speech processing in the brain with self-supervised learning", "author": "Juliette Millet et.al.", "abstract": "Several deep neural networks have recently been shown to generate activations similar to those of the brain in response to the same input. These algorithms, however, remain largely implausible: they require (1) extraordinarily large amounts of data, (2) unobtainable supervised labels, (3) textual rather than raw sensory input, and / or (4) implausibly large memory (e.g. thousands of contextual words). These elements highlight the need to identify algorithms that, under these limitations, would suffice to account for both behavioral and brain responses. Focusing on the issue of speech processing, we here hypothesize that self-supervised algorithms trained on the raw waveform constitute a promising candidate. Specifically, we compare a recent self-supervised architecture, Wav2Vec 2.0, to the brain activity of 412 English, French, and Mandarin individuals recorded with functional Magnetic Resonance Imaging (fMRI), while they listened to ~1h of audio books. Our results are four-fold. First, we show that this algorithm learns brain-like representations with as little as 600 hours of unlabelled speech -- a quantity comparable to what infants can be exposed to during language acquisition. Second, its functional hierarchy aligns with the cortical hierarchy of speech processing. Third, different training regimes reveal a functional specialization akin to the cortex: Wav2Vec 2.0 learns sound-generic, speech-specific and language-specific representations similar to those of the prefrontal and temporal cortices. Fourth, we confirm the similarity of this specialization with the behavior of 386 additional participants. These elements, resulting from the largest neuroimaging benchmark to date, show how self-supervised learning can account for a rich organization of speech processing in the brain, and thus delineate a path to identify the laws of language acquisition which shape the human brain.", "paper_url": "http://arxiv.org/abs/2206.01685v1", "pdf_url": "http://arxiv.org/pdf/2206.01685v1", "repo_url": null}, "2206.01677": {"publish_time": "2022-06-03", "title": "ArgRewrite V.2: an Annotated Argumentative Revisions Corpus", "author": "Omid Kashefi et.al.", "abstract": "Analyzing how humans revise their writings is an interesting research question, not only from an educational perspective but also in terms of artificial intelligence. Better understanding of this process could facilitate many NLP applications, from intelligent tutoring systems to supportive and collaborative writing environments. Developing these applications, however, requires revision corpora, which are not widely available. In this work, we present ArgRewrite V.2, a corpus of annotated argumentative revisions, collected from two cycles of revisions to argumentative essays about self-driving cars. Annotations are provided at different levels of purpose granularity (coarse and fine) and scope (sentential and subsentential). In addition, the corpus includes the revision goal given to each writer, essay scores, annotation verification, pre- and post-study surveys collected from participants as meta-data. The variety of revision unit scope and purpose granularity levels in ArgRewrite, along with the inclusion of new types of meta-data, can make it a useful resource for research and applications that involve revision analysis. We demonstrate some potential applications of ArgRewrite V.2 in the development of automatic revision purpose predictors, as a training source and benchmark.", "paper_url": "http://arxiv.org/abs/2206.01677v1", "pdf_url": "http://arxiv.org/pdf/2206.01677v1", "repo_url": null}, "2206.02737": {"publish_time": "2022-06-06", "title": "Investigating the use of Paraphrase Generation for Question Reformulation in the FRANK QA system", "author": "Nick Ferguson et.al.", "abstract": "We present a study into the ability of paraphrase generation methods to increase the variety of natural language questions that the FRANK Question Answering system can answer. We first evaluate paraphrase generation methods on the LC-QuAD 2.0 dataset using both automatic metrics and human judgement, and discuss their correlation. Error analysis on the dataset is also performed using both automatic and manual approaches, and we discuss how paraphrase generation and evaluation is affected by data points which contain error. We then simulate an implementation of the best performing paraphrase generation method (an English-French backtranslation) into FRANK in order to test our original hypothesis, using a small challenge dataset. Our two main conclusions are that cleaning of LC-QuAD 2.0 is required as the errors present can affect evaluation; and that, due to limitations of FRANK's parser, paraphrase generation is not a method which we can rely on to improve the variety of natural language questions that FRANK can answer.", "paper_url": "http://arxiv.org/abs/2206.02737v1", "pdf_url": "http://arxiv.org/pdf/2206.02737v1", "repo_url": null}, "2206.02712": {"publish_time": "2022-06-06", "title": "Curriculum-Based Self-Training Makes Better Few-Shot Learners for Data-to-Text Generation", "author": "Pei Ke et.al.", "abstract": "Despite the success of text-to-text pre-trained models in various natural language generation (NLG) tasks, the generation performance is largely restricted by the number of labeled data in downstream tasks, particularly in data-to-text generation tasks. Existing works mostly utilize abundant unlabeled structured data to conduct unsupervised pre-training for task adaption, which fail to model the complex relationship between source structured data and target texts. Thus, we introduce self-training as a better few-shot learner than task-adaptive pre-training, which explicitly captures this relationship via pseudo-labeled data generated by the pre-trained model. To alleviate the side-effect of low-quality pseudo-labeled data during self-training, we propose a novel method called Curriculum-Based Self-Training (CBST) to effectively leverage unlabeled data in a rearranged order determined by the difficulty of text generation. Experimental results show that our method can outperform fine-tuning and task-adaptive pre-training methods, and achieve state-of-the-art performance in the few-shot setting of data-to-text generation.", "paper_url": "http://arxiv.org/abs/2206.02712v1", "pdf_url": "http://arxiv.org/pdf/2206.02712v1", "repo_url": null}, "2206.02696": {"publish_time": "2022-06-06", "title": "Learning to Ask Like a Physician", "author": "Eric Lehman et.al.", "abstract": "Existing question answering (QA) datasets derived from electronic health records (EHR) are artificially generated and consequently fail to capture realistic physician information needs. We present Discharge Summary Clinical Questions (DiSCQ), a newly curated question dataset composed of 2,000+ questions paired with the snippets of text (triggers) that prompted each question. The questions are generated by medical experts from 100+ MIMIC-III discharge summaries. We analyze this dataset to characterize the types of information sought by medical experts. We also train baseline models for trigger detection and question generation (QG), paired with unsupervised answer retrieval over EHRs. Our baseline model is able to generate high quality questions in over 62% of cases when prompted with human selected triggers. We release this dataset (and all code to reproduce baseline model results) to facilitate further research into realistic clinical QA and QG: https://github.com/elehman16/discq.", "paper_url": "http://arxiv.org/abs/2206.02696v1", "pdf_url": "http://arxiv.org/pdf/2206.02696v1", "repo_url": null}, "2206.02608": {"publish_time": "2022-06-06", "title": "What do tokens know about their characters and how do they know it?", "author": "Ayush Kaushal et.al.", "abstract": "Pre-trained language models (PLMs) that use subword tokenization schemes can succeed at a variety of language tasks that require character-level information, despite lacking explicit access to the character composition of tokens. Here, studying a range of models (e.g., GPT- J, BERT, RoBERTa, GloVe), we probe what word pieces encode about character-level information by training classifiers to predict the presence or absence of a particular alphabetical character in a token, based on its embedding (e.g., probing whether the model embedding for \"cat\" encodes that it contains the character \"a\"). We find that these models robustly encode character-level information and, in general, larger models perform better at the task. We show that these results generalize to characters from non-Latin alphabets (Arabic, Devanagari, and Cyrillic). Then, through a series of experiments and analyses, we investigate the mechanisms through which PLMs acquire English-language character information during training and argue that this knowledge is acquired through multiple phenomena, including a systematic relationship between particular characters and particular parts of speech, as well as natural variability in the tokenization of related strings.", "paper_url": "http://arxiv.org/abs/2206.02608v1", "pdf_url": "http://arxiv.org/pdf/2206.02608v1", "repo_url": "https://github.com/ayushk4/character-probing-pytorch"}, "2206.02512": {"publish_time": "2022-06-06", "title": "UTTS: Unsupervised TTS with Conditional Disentangled Sequential Variational Auto-encoder", "author": "Jiachen Lian et.al.", "abstract": "In this paper, we propose a novel unsupervised text-to-speech (UTTS) framework which does not require text-audio pairs for the TTS acoustic modeling (AM). UTTS is a multi-speaker speech synthesizer developed from the perspective of disentangled speech representation learning. The framework offers a flexible choice of a speaker's duration model, timbre feature (identity) and content for TTS inference. We leverage recent advancements in self-supervised speech representation learning as well as speech synthesis front-end techniques for the system development. Specifically, we utilize a lexicon to map input text to the phoneme sequence, which is expanded to the frame-level forced alignment (FA) with a speaker-dependent duration model. Then, we develop an alignment mapping module that converts the FA to the unsupervised alignment (UA). Finally, a Conditional Disentangled Sequential Variational Auto-encoder (C-DSVAE), serving as the self-supervised TTS AM, takes the predicted UA and a target speaker embedding to generate the mel spectrogram, which is ultimately converted to waveform with a neural vocoder. We show how our method enables speech synthesis without using a paired TTS corpus. Experiments demonstrate that UTTS can synthesize speech of high naturalness and intelligibility measured by human and objective evaluations.", "paper_url": "http://arxiv.org/abs/2206.02512v1", "pdf_url": "http://arxiv.org/pdf/2206.02512v1", "repo_url": null}, "2206.03428": {"publish_time": "2022-06-07", "title": "Revealing Single Frame Bias for Video-and-Language Learning", "author": "Jie Lei et.al.", "abstract": "Training an effective video-and-language model intuitively requires multiple frames as model inputs. However, it is unclear whether using multiple frames is beneficial to downstream tasks, and if yes, whether the performance gain is worth the drastically-increased computation and memory costs resulting from using more frames. In this work, we explore single-frame models for video-and-language learning. On a diverse set of video-and-language tasks (including text-to-video retrieval and video question answering), we show the surprising result that, with large-scale pre-training and a proper frame ensemble strategy at inference time, a single-frame trained model that does not consider temporal information can achieve better performance than existing methods that use multiple frames for training. This result reveals the existence of a strong \"static appearance bias\" in popular video-and-language datasets. Therefore, to allow for a more comprehensive evaluation of video-and-language models, we propose two new retrieval tasks based on existing fine-grained action recognition datasets that encourage temporal modeling. Our code is available at https://github.com/jayleicn/singularity", "paper_url": "http://arxiv.org/abs/2206.03428v1", "pdf_url": "http://arxiv.org/pdf/2206.03428v1", "repo_url": "https://github.com/jayleicn/singularity"}, "2206.03400": {"publish_time": "2022-06-07", "title": "The Influence of Dataset Partitioning on Dysfluency Detection Systems", "author": "Sebastian P. Bayerl et.al.", "abstract": "This paper empirically investigates the influence of different data splits and splitting strategies on the performance of dysfluency detection systems. For this, we perform experiments using wav2vec 2.0 models with a classification head as well as support vector machines (SVM) in conjunction with the features extracted from the wav2vec 2.0 model to detect dysfluencies. We train and evaluate the systems with different non-speaker-exclusive and speaker-exclusive splits of the Stuttering Events in Podcasts (SEP-28k) dataset to shed some light on the variability of results w.r.t. to the partition method used. Furthermore, we show that the SEP-28k dataset is dominated by only a few speakers, making it difficult to evaluate. To remedy this problem, we created SEP-28k-Extended (SEP-28k-E), containing semi-automatically generated speaker and gender information for the SEP-28k corpus, and suggest different data splits, each useful for evaluating other aspects of methods for dysfluency detection.", "paper_url": "http://arxiv.org/abs/2206.03400v1", "pdf_url": "http://arxiv.org/pdf/2206.03400v1", "repo_url": "https://github.com/th-nuernberg/ml-stuttering-events-dataset-extended"}, "2206.03390": {"publish_time": "2022-06-07", "title": "Gender Bias in Word Embeddings: A Comprehensive Analysis of Frequency, Syntax, and Semantics", "author": "Aylin Caliskan et.al.", "abstract": "The statistical regularities in language corpora encode well-known social biases into word embeddings. Here, we focus on gender to provide a comprehensive analysis of group-based biases in widely-used static English word embeddings trained on internet corpora (GloVe 2014, fastText 2017). Using the Single-Category Word Embedding Association Test, we demonstrate the widespread prevalence of gender biases that also show differences in: (1) frequencies of words associated with men versus women; (b) part-of-speech tags in gender-associated words; (c) semantic categories in gender-associated words; and (d) valence, arousal, and dominance in gender-associated words.   First, in terms of word frequency: we find that, of the 1,000 most frequent words in the vocabulary, 77% are more associated with men than women, providing direct evidence of a masculine default in the everyday language of the English-speaking world. Second, turning to parts-of-speech: the top male-associated words are typically verbs (e.g., fight, overpower) while the top female-associated words are typically adjectives and adverbs (e.g., giving, emotionally). Gender biases in embeddings also permeate parts-of-speech. Third, for semantic categories: bottom-up, cluster analyses of the top 1,000 words associated with each gender. The top male-associated concepts include roles and domains of big tech, engineering, religion, sports, and violence; in contrast, the top female-associated concepts are less focused on roles, including, instead, female-specific slurs and sexual content, as well as appearance and kitchen terms. Fourth, using human ratings of word valence, arousal, and dominance from a ~20,000 word lexicon, we find that male-associated words are higher on arousal and dominance, while female-associated words are higher on valence.", "paper_url": "http://arxiv.org/abs/2206.03390v1", "pdf_url": "http://arxiv.org/pdf/2206.03390v1", "repo_url": null}, "2206.03382": {"publish_time": "2022-06-07", "title": "Tutel: Adaptive Mixture-of-Experts at Scale", "author": "Changho Hwang et.al.", "abstract": "In recent years, Mixture-of-Experts (MoE) has emerged as a promising technique for deep learning that can scale the model capacity to trillion-plus parameters while reducing the computing cost via sparse computation. While MoE opens a new frontier of exceedingly large models, its implementation over thousands of GPUs has been limited due to mismatch between the dynamic nature of MoE and static parallelism/pipelining of the system. We present Tutel, a highly scalable stack design and implementation for MoE with dynamically adaptive parallelism and pipelining. Tutel delivers adaptive parallelism switching and adaptive pipelining at runtime, which achieves up to 1.74x and 2.00x single MoE layer speedup, respectively. We also propose a novel two-dimensional hierarchical algorithm for MoE communication speedup that outperforms the previous state-of-the-art up to 20.7x over 2,048 GPUs. Aggregating all techniques, Tutel finally delivers 4.96x and 5.75x speedup of a single MoE layer on 16 GPUs and 2,048 GPUs, respectively, over Fairseq: Meta's Facebook AI Research Sequence-to-Sequence Toolkit (Tutel is now partially adopted by Fairseq). Tutel source code is available in public: https://github.com/microsoft/tutel . Our evaluation shows that Tutel efficiently and effectively runs a real-world MoE-based model named SwinV2-MoE, built upon Swin Transformer V2, a state-of-the-art computer vision architecture. On efficiency, Tutel accelerates SwinV2-MoE, achieving up to 1.55x and 2.11x speedup in training and inference over Fairseq, respectively. On effectiveness, the SwinV2-MoE model achieves superior accuracy in both pre-training and down-stream computer vision tasks such as COCO object detection than the counterpart dense model, indicating the readiness of Tutel for end-to-end real-world model training and inference. SwinV2-MoE is open sourced in https://github.com/microsoft/Swin-Transformer .", "paper_url": "http://arxiv.org/abs/2206.03382v1", "pdf_url": "http://arxiv.org/pdf/2206.03382v1", "repo_url": "https://github.com/microsoft/Swin-Transformer"}, "2206.03377": {"publish_time": "2022-06-07", "title": "RAAT: Relation-Augmented Attention Transformer for Relation Modeling in Document-Level Event Extraction", "author": "Yuan Liang et.al.", "abstract": "In document-level event extraction (DEE) task, event arguments always scatter across sentences (across-sentence issue) and multiple events may lie in one document (multi-event issue). In this paper, we argue that the relation information of event arguments is of great significance for addressing the above two issues, and propose a new DEE framework which can model the relation dependencies, called Relation-augmented Document-level Event Extraction (ReDEE). More specifically, this framework features a novel and tailored transformer, named as Relation-augmented Attention Transformer (RAAT). RAAT is scalable to capture multi-scale and multi-amount argument relations. To further leverage relation information, we introduce a separate event relation prediction task and adopt multi-task learning method to explicitly enhance event extraction performance. Extensive experiments demonstrate the effectiveness of the proposed method, which can achieve state-of-the-art performance on two public datasets. Our code is available at https://github. com/TencentYoutuResearch/RAAT.", "paper_url": "http://arxiv.org/abs/2206.03377v1", "pdf_url": "http://arxiv.org/pdf/2206.03377v1", "repo_url": null}, "2206.04045": {"publish_time": "2022-06-08", "title": "STable: Table Generation Framework for Encoder-Decoder Models", "author": "Micha\u0142 Pietruszka et.al.", "abstract": "The output structure of database-like tables, consisting of values structured in horizontal rows and vertical columns identifiable by name, can cover a wide range of NLP tasks. Following this constatation, we propose a framework for text-to-table neural models applicable to problems such as extraction of line items, joint entity and relation extraction, or knowledge base population. The permutation-based decoder of our proposal is a generalized sequential method that comprehends information from all cells in the table. The training maximizes the expected log-likelihood for a table's content across all random permutations of the factorization order. During the content inference, we exploit the model's ability to generate cells in any order by searching over possible orderings to maximize the model's confidence and avoid substantial error accumulation, which other sequential models are prone to. Experiments demonstrate a high practical value of the framework, which establishes state-of-the-art results on several challenging datasets, outperforming previous solutions by up to 15%.", "paper_url": "http://arxiv.org/abs/2206.04045v1", "pdf_url": "http://arxiv.org/pdf/2206.04045v1", "repo_url": null}, "2206.04039": {"publish_time": "2022-06-08", "title": "Resolving the Human Subjects Status of Machine Learning's Crowdworkers", "author": "Divyansh Kaushik et.al.", "abstract": "In recent years, machine learning (ML) has come to rely more heavily on crowdworkers, both for building bigger datasets and for addressing research questions requiring human interaction or judgment. Owing to the diverse tasks performed by crowdworkers, and the myriad ways the resulting datasets are used, it can be difficult to determine when these individuals are best thought of as workers, versus as human subjects. These difficulties are compounded by conflicting policies, with some institutions and researchers treating all ML crowdwork as human subjects research, and other institutions holding that ML crowdworkers rarely constitute human subjects. Additionally, few ML papers involving crowdwork mention IRB oversight, raising the prospect that many might not be in compliance with ethical and regulatory requirements. In this paper, we focus on research in natural language processing to investigate the appropriate designation of crowdsourcing studies and the unique challenges that ML research poses for research oversight. Crucially, under the U.S. Common Rule, these judgments hinge on determinations of \"aboutness\", both whom (or what) the collected data is about and whom (or what) the analysis is about. We highlight two challenges posed by ML: (1) the same set of workers can serve multiple roles and provide many sorts of information; and (2) compared to the life sciences and social sciences, ML research tends to embrace a dynamic workflow, where research questions are seldom stated ex ante and data sharing opens the door for future studies to ask questions about different targets from the original study. In particular, our analysis exposes a potential loophole in the Common Rule, where researchers can elude research ethics oversight by splitting data collection and analysis into distinct studies. We offer several policy recommendations to address these concerns.", "paper_url": "http://arxiv.org/abs/2206.04039v1", "pdf_url": "http://arxiv.org/pdf/2206.04039v1", "repo_url": null}, "2206.04007": {"publish_time": "2022-06-08", "title": "Proactively Reducing the Hate Intensity of Online Posts via Hate Speech Normalization", "author": "Sarah Masud et.al.", "abstract": "Curbing online hate speech has become the need of the hour; however, a blanket ban on such activities is infeasible for several geopolitical and cultural reasons. To reduce the severity of the problem, in this paper, we introduce a novel task, hate speech normalization, that aims to weaken the intensity of hatred exhibited by an online post. The intention of hate speech normalization is not to support hate but instead to provide the users with a stepping stone towards non-hate while giving online platforms more time to monitor any improvement in the user's behavior.   To this end, we manually curated a parallel corpus - hate texts and their normalized counterparts (a normalized text is less hateful and more benign). We introduce NACL, a simple yet efficient hate speech normalization model that operates in three stages - first, it measures the hate intensity of the original sample; second, it identifies the hate span(s) within it; and finally, it reduces hate intensity by paraphrasing the hate spans. We perform extensive experiments to measure the efficacy of NACL via three-way evaluation (intrinsic, extrinsic, and human-study). We observe that NACL outperforms six baselines - NACL yields a score of 0.1365 RMSE for the intensity prediction, 0.622 F1-score in the span identification, and 82.27 BLEU and 80.05 perplexity for the normalized text generation. We further show the generalizability of NACL across other platforms (Reddit, Facebook, Gab). An interactive prototype of NACL was put together for the user study. Further, the tool is being deployed in a real-world setting at Wipro AI as a part of its mission to tackle harmful content on online platforms.", "paper_url": "http://arxiv.org/abs/2206.04007v1", "pdf_url": "http://arxiv.org/pdf/2206.04007v1", "repo_url": null}, "2206.03945": {"publish_time": "2022-06-08", "title": "Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models", "author": "Esma Balkir et.al.", "abstract": "Motivations for methods in explainable artificial intelligence (XAI) often include detecting, quantifying and mitigating bias, and contributing to making machine learning models fairer. However, exactly how an XAI method can help in combating biases is often left unspecified. In this paper, we briefly review trends in explainability and fairness in NLP research, identify the current practices in which explainability methods are applied to detect and mitigate bias, and investigate the barriers preventing XAI methods from being used more widely in tackling fairness issues.", "paper_url": "http://arxiv.org/abs/2206.03945v1", "pdf_url": "http://arxiv.org/pdf/2206.03945v1", "repo_url": null}, "2206.03931": {"publish_time": "2022-06-08", "title": "Few-shot Prompting Toward Controllable Response Generation", "author": "Hsuan Su et.al.", "abstract": "Much literature has shown that prompt-based learning is an efficient method to make use of the large pre-trained language model. Recent works also exhibit the possibility of steering a chatbot's output by plugging in an appropriate prompt. Gradient-based methods are often used to perturb the prompts. However, some language models are not even available to the public. In this work, we first explored the combination of prompting and reinforcement learning (RL) to steer models' generation without accessing any of the models' parameters. Second, to reduce the training effort and enhance the generalizability to the unseen task, we apply multi-task learning to make the model learn to generalize to new tasks better. The experiment results show that our proposed method can successfully control several state-of-the-art (SOTA) dialogue models without accessing their parameters. Furthermore, the model demonstrates the strong ability to quickly adapt to an unseen task in fewer steps than the baseline model.", "paper_url": "http://arxiv.org/abs/2206.03931v1", "pdf_url": "http://arxiv.org/pdf/2206.03931v1", "repo_url": null}, "2206.04659": {"publish_time": "2022-06-09", "title": "Jewelry Shop Conversational Chatbot", "author": "Safa Zaid et.al.", "abstract": "Since the advent of chatbots in the commercial sector, they have been widely employed in the customer service department. Typically, these commercial chatbots are retrieval-based, so they are unable to respond to queries absent in the provided dataset. On the contrary, generative chatbots try to create the most appropriate response, but are mostly unable to create a smooth flow in the customer-bot dialog. Since the client has few options left for continuing after receiving a response, the dialog becomes short. Through our work, we try to maximize the intelligence of a simple conversational agent so it can answer unseen queries, and generate follow-up questions or remarks. We have built a chatbot for a jewelry shop that finds the underlying objective of the customer's query by finding similarity of the input to patterns in the corpus. Our system features an audio input interface for clients, so they may speak to it in natural language. After converting the audio to text, we trained the model to extract the intent of the query, to find an appropriate response and to speak to the client in a natural human voice. To gauge the system's performance, we used performance metrics such as Recall, Precision and F1 score.", "paper_url": "http://arxiv.org/abs/2206.04659v1", "pdf_url": "http://arxiv.org/pdf/2206.04659v1", "repo_url": null}, "2206.04658": {"publish_time": "2022-06-09", "title": "BigVGAN: A Universal Neural Vocoder with Large-Scale Training", "author": "Sang-gil Lee et.al.", "abstract": "Despite recent progress in generative adversarial network(GAN)-based vocoders, where the model generates raw waveform conditioned on mel spectrogram, it is still challenging to synthesize high-fidelity audio for numerous speakers across varied recording environments. In this work, we present BigVGAN, a universal vocoder that generalizes well under various unseen conditions in zero-shot setting. We introduce periodic nonlinearities and anti-aliased representation into the generator, which brings the desired inductive bias for waveform synthesis and significantly improves audio quality. Based on our improved generator and the state-of-the-art discriminators, we train our GAN vocoder at the largest scale up to 112M parameters, which is unprecedented in the literature. In particular, we identify and address the training instabilities specific to such scale, while maintaining high-fidelity output without over-regularization. Our BigVGAN achieves the state-of-the-art zero-shot performance for various out-of-distribution scenarios, including new speakers, novel languages, singing voices, music and instrumental audio in unseen (even noisy) recording environments. We will release our code and model at: https://github.com/NVIDIA/BigVGAN", "paper_url": "http://arxiv.org/abs/2206.04658v1", "pdf_url": "http://arxiv.org/pdf/2206.04658v1", "repo_url": "https://github.com/nvidia/bigvgan"}, "2206.04624": {"publish_time": "2022-06-09", "title": "Factuality Enhanced Language Models for Open-Ended Text Generation", "author": "Nayeon Lee et.al.", "abstract": "Pretrained language models (LMs) are susceptible to generate text with nonfactual information. In this work, we measure and improve the factual accuracy of large-scale LMs for open-ended text generation. We design the FactualityPrompts test set and metrics to measure the factuality of LM generations. Based on that, we study the factual accuracy of LMs with parameter sizes ranging from 126M to 530B. Interestingly, we find that larger LMs are more factual than smaller ones, although a previous study suggests that larger LMs can be less truthful in terms of misconceptions. In addition, popular sampling algorithms (e.g., top-p) in open-ended text generation can harm the factuality due to the \"uniform randomness\" introduced at every sampling step. We propose the factual-nucleus sampling algorithm that dynamically adapts the randomness to improve the factuality of generation while maintaining quality. Furthermore, we analyze the inefficiencies of the standard training method in learning correct associations between entities from factual text corpus (e.g., Wikipedia). We propose a factuality-enhanced training method that uses TopicPrefix for better awareness of facts and sentence completion as the training objective, which can vastly reduce the factual errors.", "paper_url": "http://arxiv.org/abs/2206.04624v1", "pdf_url": "http://arxiv.org/pdf/2206.04624v1", "repo_url": null}, "2206.04615": {"publish_time": "2022-06-09", "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models", "author": "Aarohi Srivastava et.al.", "abstract": "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.", "paper_url": "http://arxiv.org/abs/2206.04615v1", "pdf_url": "http://arxiv.org/pdf/2206.04615v1", "repo_url": "https://github.com/google/BIG-bench"}, "2206.04591": {"publish_time": "2022-06-09", "title": "Privacy Leakage in Text Classification: A Data Extraction Approach", "author": "Adel Elmahdy et.al.", "abstract": "Recent work has demonstrated the successful extraction of training data from generative language models. However, it is not evident whether such extraction is feasible in text classification models since the training objective is to predict the class label as opposed to next-word prediction. This poses an interesting challenge and raises an important question regarding the privacy of training data in text classification settings. Therefore, we study the potential privacy leakage in the text classification domain by investigating the problem of unintended memorization of training data that is not pertinent to the learning task. We propose an algorithm to extract missing tokens of a partial text by exploiting the likelihood of the class label provided by the model. We test the effectiveness of our algorithm by inserting canaries into the training set and attempting to extract tokens in these canaries post-training. In our experiments, we demonstrate that successful extraction is possible to some extent. This can also be used as an auditing strategy to assess any potential unauthorized use of personal data without consent.", "paper_url": "http://arxiv.org/abs/2206.04591v1", "pdf_url": "http://arxiv.org/pdf/2206.04591v1", "repo_url": null}, "2206.05238": {"publish_time": "2022-06-10", "title": "Dimensional Modeling of Emotions in Text with Appraisal Theories: Corpus Creation, Annotation Reliability, and Prediction", "author": "Enrica Troiano et.al.", "abstract": "The most prominent tasks in emotion analysis are to assign emotions to texts and to understand how emotions manifest in language. An important observation for natural language processing is that emotions can be communicated implicitly by referring to events alone, appealing to an empathetic, intersubjective understanding of events, even without explicitly mentioning an emotion name. In psychology, the class of emotion theories known as appraisal theories aims at explaining the link between events and emotions. Appraisals can be formalized as variables that measure a cognitive evaluation by people living through an event that they consider relevant. They include the assessment if an event is novel, if the person considers themselves to be responsible, if it is in line with the own goals, and many others. Such appraisals explain which emotions are developed based on an event, e.g., that a novel situation can induce surprise or one with uncertain consequences could evoke fear. We analyze the suitability of appraisal theories for emotion analysis in text with the goal of understanding if appraisal concepts can reliably be reconstructed by annotators, if they can be predicted by text classifiers, and if appraisal concepts help to identify emotion categories. To achieve that, we compile a corpus by asking people to textually describe events that triggered particular emotions and to disclose their appraisals. Then, we ask readers to reconstruct emotions and appraisals from the text. This setup allows us to measure if emotions and appraisals can be recovered purely from text and provides a human baseline to judge model's performance measures. Our comparison of text classification methods to human annotators shows that both can reliably detect emotions and appraisals with similar performance. We further show that appraisal concepts improve the categorization of emotions in text.", "paper_url": "http://arxiv.org/abs/2206.05238v1", "pdf_url": "http://arxiv.org/pdf/2206.05238v1", "repo_url": null}, "2206.05224": {"publish_time": "2022-06-10", "title": "A Multi-Task Benchmark for Korean Legal Language Understanding and Judgement Prediction", "author": "Wonseok Hwang et.al.", "abstract": "The recent advances of deep learning have dramatically changed how machine learning, especially in the domain of natural language processing, can be applied to legal domain. However, this shift to the data-driven approaches calls for larger and more diverse datasets, which are nevertheless still small in number, especially in non-English languages. Here we present the first large-scale benchmark of Korean legal AI datasets, LBox Open, that consists of one legal corpus, two classification tasks, two legal judgement prediction (LJP) tasks, and one summarization task. The legal corpus consists of 150k Korean precedents (264M tokens), of which 63k are sentenced in last 4 years and 96k are from the first and the second level courts in which factual issues are reviewed. The two classification tasks are case names (10k) and statutes (3k) prediction from the factual description of individual cases. The LJP tasks consist of (1) 11k criminal examples where the model is asked to predict fine amount, imprisonment with labor, and imprisonment without labor ranges for the given facts, and (2) 5k civil examples where the inputs are facts and claim for relief and outputs are the degrees of claim acceptance. The summarization task consists of the Supreme Court precedents and the corresponding summaries. We also release LCube, the first Korean legal language model trained on the legal corpus from this study. Given the uniqueness of the Law of South Korea and the diversity of the legal tasks covered in this work, we believe that LBox Open contributes to the multilinguality of global legal research. LBox Open and LCube will be publicly available.", "paper_url": "http://arxiv.org/abs/2206.05224v1", "pdf_url": "http://arxiv.org/pdf/2206.05224v1", "repo_url": "https://github.com/lbox-kr/lbox-open"}, "2206.05195": {"publish_time": "2022-06-10", "title": "Nominal Metaphor Generation with Multitask Learning", "author": "Yucheng Li et.al.", "abstract": "Nominal metaphors are frequently used in human language and have been shown to be effective in persuading, expressing emotion, and stimulating interest. This paper tackles the problem of Chinese Nominal Metaphor (NM) generation. We introduce a novel multitask framework, which jointly optimizes three tasks: NM identification, NM component identification, and NM generation. The metaphor identification module is able to perform a self-training procedure, which discovers novel metaphors from a large-scale unlabeled corpus for NM generation. The NM component identification module emphasizes components during training and conditions the generation on these NM components for more coherent results. To train the NM identification and component identification modules, we construct an annotated corpus consisting of 6.3k sentences that contain diverse metaphorical patterns. Automatic metrics show that our method can produce diverse metaphors with good readability, where 92\\% of them are novel metaphorical comparisons. Human evaluation shows our model significantly outperforms baselines on consistency and creativity.", "paper_url": "http://arxiv.org/abs/2206.05195v1", "pdf_url": "http://arxiv.org/pdf/2206.05195v1", "repo_url": null}, "2206.05154": {"publish_time": "2022-06-10", "title": "Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning", "author": "Aditi Chaudhary et.al.", "abstract": "One of the challenges of language teaching is how to organize the rules regarding syntax, semantics, or phonology of the language in a meaningful manner. This not only requires pedagogical skills, but also requires a deep understanding of that language. While comprehensive materials to develop such curricula are available in English and some broadly spoken languages, for many other languages, teachers need to manually create them in response to their students' needs. This process is challenging because i) it requires that such experts be accessible and have the necessary resources, and ii) even if there are such experts, describing all the intricacies of a language is time-consuming and prone to omission. In this article, we present an automatic framework that aims to facilitate this process by automatically discovering and visualizing descriptions of different aspects of grammar. Specifically, we extract descriptions from a natural text corpus that answer questions about morphosyntax (learning of word order, agreement, case marking, or word formation) and semantics (learning of vocabulary) and show illustrative examples. We apply this method for teaching the Indian languages, Kannada and Marathi, which, unlike English, do not have well-developed pedagogical resources and, therefore, are likely to benefit from this exercise. To assess the perceived utility of the extracted material, we enlist the help of language educators from schools in North America who teach these languages to perform a manual evaluation. Overall, teachers find the materials to be interesting as a reference material for their own lesson preparation or even for learner evaluation.", "paper_url": "http://arxiv.org/abs/2206.05154v1", "pdf_url": "http://arxiv.org/pdf/2206.05154v1", "repo_url": null}, "2206.05123": {"publish_time": "2022-06-10", "title": "REKnow: Enhanced Knowledge for Joint Entity and Relation Extraction", "author": "Sheng Zhang et.al.", "abstract": "Relation extraction is an important but challenging task that aims to extract all hidden relational facts from the text. With the development of deep language models, relation extraction methods have achieved good performance on various benchmarks. However, we observe two shortcomings of previous methods: first, there is no unified framework that works well under various relation extraction settings; second, effectively utilizing external knowledge as background information is absent. In this work, we propose a knowledge-enhanced generative model to mitigate these two issues. Our generative model is a unified framework to sequentially generate relational triplets under various relation extraction settings and explicitly utilizes relevant knowledge from Knowledge Graph (KG) to resolve ambiguities. Our model achieves superior performance on multiple benchmarks and settings, including WebNLG, NYT10, and TACRED.", "paper_url": "http://arxiv.org/abs/2206.05123v1", "pdf_url": "http://arxiv.org/pdf/2206.05123v1", "repo_url": null}, "2206.06336": {"publish_time": "2022-06-13", "title": "Language Models are General-Purpose Interfaces", "author": "Yaru Hao et.al.", "abstract": "Foundation models have received much attention due to their effectiveness across a broad range of downstream applications. Though there is a big convergence in terms of architecture, most pretrained models are typically still developed for specific tasks or modalities. In this work, we propose to use language models as a general-purpose interface to various foundation models. A collection of pretrained encoders perceive diverse modalities (such as vision, and language), and they dock with a language model that plays the role of a universal task layer. We propose a semi-causal language modeling objective to jointly pretrain the interface and the modular encoders. We subsume the advantages and capabilities from both causal and non-causal modeling, thereby combining the best of two worlds. Specifically, the proposed method not only inherits the capabilities of in-context learning and open-ended generation from causal language modeling, but also is conducive to finetuning because of the bidirectional encoders. More importantly, our approach seamlessly unlocks the combinations of the above capabilities, e.g., enabling in-context learning or instruction following with finetuned encoders. Experimental results across various language-only and vision-language benchmarks show that our model outperforms or is competitive with specialized models on finetuning, zero-shot generalization, and few-shot learning.", "paper_url": "http://arxiv.org/abs/2206.06336v1", "pdf_url": "http://arxiv.org/pdf/2206.06336v1", "repo_url": null}, "2206.06315": {"publish_time": "2022-06-13", "title": "JiuZhang: A Chinese Pre-trained Language Model for Mathematical Problem Understanding", "author": "Wayne Xin Zhao et.al.", "abstract": "This paper aims to advance the mathematical intelligence of machines by presenting the first Chinese mathematical pre-trained language model~(PLM) for effectively understanding and representing mathematical problems. Unlike other standard NLP tasks, mathematical texts are difficult to understand, since they involve mathematical terminology, symbols and formulas in the problem statement. Typically, it requires complex mathematical logic and background knowledge for solving mathematical problems.   Considering the complex nature of mathematical texts, we design a novel curriculum pre-training approach for improving the learning of mathematical PLMs, consisting of both basic and advanced courses. Specially, we first perform token-level pre-training based on a position-biased masking strategy, and then design logic-based pre-training tasks that aim to recover the shuffled sentences and formulas, respectively. Finally, we introduce a more difficult pre-training task that enforces the PLM to detect and correct the errors in its generated solutions. We conduct extensive experiments on offline evaluation (including nine math-related tasks) and online $A/B$ test. Experimental results demonstrate the effectiveness of our approach compared with a number of competitive baselines. Our code is available at: \\textcolor{blue}{\\url{https://github.com/RUCAIBox/JiuZhang}}.", "paper_url": "http://arxiv.org/abs/2206.06315v1", "pdf_url": "http://arxiv.org/pdf/2206.06315v1", "repo_url": null}, "2206.06308": {"publish_time": "2022-06-13", "title": "Knowledge Graph Construction and Its Application in Automatic Radiology Report Generation from Radiologist's Dictation", "author": "Kaveri Kale et.al.", "abstract": "Conventionally, the radiologist prepares the diagnosis notes and shares them with the transcriptionist. Then the transcriptionist prepares a preliminary formatted report referring to the notes, and finally, the radiologist reviews the report, corrects the errors, and signs off. This workflow causes significant delays and errors in the report. In current research work, we focus on applications of NLP techniques like Information Extraction (IE) and domain-specific Knowledge Graph (KG) to automatically generate radiology reports from radiologist's dictation. This paper focuses on KG construction for each organ by extracting information from an existing large corpus of free-text radiology reports. We develop an information extraction pipeline that combines rule-based, pattern-based, and dictionary-based techniques with lexical-semantic features to extract entities and relations. Missing information in short dictation can be accessed from the KGs to generate pathological descriptions and hence the radiology report. Generated pathological descriptions evaluated using semantic similarity metrics, which shows 97% similarity with gold standard pathological descriptions. Also, our analysis shows that our IE module is performing better than the OpenIE tool for the radiology domain. Furthermore, we include a manual qualitative analysis from radiologists, which shows that 80-85% of the generated reports are correctly written, and the remaining are partially correct.", "paper_url": "http://arxiv.org/abs/2206.06308v1", "pdf_url": "http://arxiv.org/pdf/2206.06308v1", "repo_url": null}, "2206.06294": {"publish_time": "2022-06-13", "title": "Introducing Proof Tree Automata and Proof Tree Graphs", "author": "Valentin D. Richard et.al.", "abstract": "In structural proof theory, designing and working on large calculi make it difficult to get intuitions about each rule individually and as part of a whole system. We introduce two novel tools to help working on calculi using the approach of graph theory and automata theory. The first tool is a Proof Tree Automaton (PTA): a tree automaton which language is the derivation language of a calculus. The second tool is a graphical representation of a calculus called Proof Tree Graph (PTG). In this directed hypergraph, vertices are sets of terms (e.g. sequents) and hyperarcs are rules. We explore properties of PTA and PTGs and how they relate to each other. We show that we can decompose a PTA as a partial map from a calculus to a traditional tree automaton. We formulate that statement in the theory of refinement systems. Finally, we compare our framework to proof nets and string diagrams.", "paper_url": "http://arxiv.org/abs/2206.06294v1", "pdf_url": "http://arxiv.org/pdf/2206.06294v1", "repo_url": null}, "2206.06238": {"publish_time": "2022-06-13", "title": "Indian Legal Text Summarization: A Text Normalisation-based Approach", "author": "Satyajit Ghosh et.al.", "abstract": "In the Indian court system, pending cases have long been a problem. There are more than 4 crore cases outstanding. Manually summarising hundreds of documents is a time-consuming and tedious task for legal stakeholders. Many state-of-the-art models for text summarization have emerged as machine learning has progressed. Domain-independent models don't do well with legal texts, and fine-tuning those models for the Indian Legal System is problematic due to a lack of publicly available datasets. To improve the performance of domain-independent models, the authors have proposed a methodology for normalising legal texts in the Indian context. The authors experimented with two state-of-the-art domain-independent models for legal text summarization, namely BART and PEGASUS. BART and PEGASUS are put through their paces in terms of extractive and abstractive summarization to understand the effectiveness of the text normalisation approach. Summarised texts are evaluated by domain experts on multiple parameters and using ROUGE metrics. It shows the proposed text normalisation approach is effective in legal texts with domain-independent models.", "paper_url": "http://arxiv.org/abs/2206.06238v1", "pdf_url": "http://arxiv.org/pdf/2206.06238v1", "repo_url": "https://github.com/satyajit1910/ilds"}, "2206.07043": {"publish_time": "2022-06-14", "title": "Text Generation with Text-Editing Models", "author": "Eric Malmi et.al.", "abstract": "Text-editing models have recently become a prominent alternative to seq2seq models for monolingual text-generation tasks such as grammatical error correction, simplification, and style transfer. These tasks share a common trait - they exhibit a large amount of textual overlap between the source and target texts. Text-editing models take advantage of this observation and learn to generate the output by predicting edit operations applied to the source sequence. In contrast, seq2seq models generate outputs word-by-word from scratch thus making them slow at inference time. Text-editing models provide several benefits over seq2seq models including faster inference speed, higher sample efficiency, and better control and interpretability of the outputs. This tutorial provides a comprehensive overview of text-editing models and current state-of-the-art approaches, and analyzes their pros and cons. We discuss challenges related to productionization and how these models can be used to mitigate hallucination and bias, both pressing challenges in the field of text generation.", "paper_url": "http://arxiv.org/abs/2206.07043v1", "pdf_url": "http://arxiv.org/pdf/2206.07043v1", "repo_url": null}, "2206.07026": {"publish_time": "2022-06-14", "title": "Computational linguistics and Natural Language Processing", "author": "Saturnino Luz et.al.", "abstract": "This chapter provides an introduction to computational linguistics methods, with focus on their applications to the practice and study of translation. It covers computational models, methods and tools for collection, storage, indexing and analysis of linguistic data in the context of translation, and discusses the main methodological issues and challenges in this field. While an exhaustive review of existing computational linguistics methods and tools is beyond the scope of this chapter, we describe the most representative approaches, and illustrate them with descriptions of typical applications.", "paper_url": "http://arxiv.org/abs/2206.07026v1", "pdf_url": "http://arxiv.org/pdf/2206.07026v1", "repo_url": null}, "2206.07023": {"publish_time": "2022-06-14", "title": "SBERT studies Meaning Representations: Decomposing Sentence Embeddings into Explainable AMR Meaning Features", "author": "Juri Opitz et.al.", "abstract": "Metrics for graph-based meaning representations (e.g., Abstract Meaning Representation, AMR) can help us uncover key semantic aspects in which two sentences are similar to each other. However, such metrics tend to be slow, rely on parsers, and do not reach state-of-the-art performance when rating sentence similarity. On the other hand, models based on large-pretrained language models, such as S(entence)BERT, show high correlation to human similarity ratings, but lack interpretability.   In this paper, we aim at the best of these two worlds, by creating similarity metrics that are highly effective, while also providing an interpretable rationale for their rating. Our approach works in two steps: We first select AMR graph metrics that measure meaning similarity of sentences with respect to key semantic facets, such as, i.a., semantic roles, negation, or quantification. Second, we employ these metrics to induce Semantically Structured Sentence BERT embeddings (S$^3$BERT), which are composed of different meaning aspects captured in different sub-spaces. In our experimental studies, we show that our approach offers a valuable balance between performance and interpretability.", "paper_url": "http://arxiv.org/abs/2206.07023v1", "pdf_url": "http://arxiv.org/pdf/2206.07023v1", "repo_url": null}, "2206.06992": {"publish_time": "2022-06-14", "title": "An Experimental Investigation of Part-Of-Speech Taggers for Vietnamese", "author": "Tuan-Phong Nguyen et.al.", "abstract": "Part-of-speech (POS) tagging plays an important role in Natural Language Processing (NLP). Its applications can be found in many NLP tasks such as named entity recognition, syntactic parsing, dependency parsing and text chunking. In the investigation conducted in this paper, we utilize the technologies of two widely-used toolkits, ClearNLP and Stanford POS Tagger, as well as develop two new POS taggers for Vietnamese, then compare them to three well-known Vietnamese taggers, namely JVnTagger, vnTagger and RDRPOSTagger. We make a systematic comparison to find out the tagger having the best performance. We also design a new feature set to measure the performance of the statistical taggers. Our new taggers built from Stanford Tagger and ClearNLP with the new feature set can outperform all other current Vietnamese taggers in term of tagging accuracy. Moreover, we also analyze the affection of some features to the performance of statistical taggers. Lastly, the experimental results also reveal that the transformation-based tagger, RDRPOSTagger, can run significantly faster than any other statistical tagger.", "paper_url": "http://arxiv.org/abs/2206.06992v1", "pdf_url": "http://arxiv.org/pdf/2206.06992v1", "repo_url": null}, "2206.06952": {"publish_time": "2022-06-14", "title": "FETILDA: An Effective Framework For Fin-tuned Embeddings For Long Financial Text Documents", "author": "Bolun \"Namir\" Xia et.al.", "abstract": "Unstructured data, especially text, continues to grow rapidly in various domains. In particular, in the financial sphere, there is a wealth of accumulated unstructured financial data, such as the textual disclosure documents that companies submit on a regular basis to regulatory agencies, such as the Securities and Exchange Commission (SEC). These documents are typically very long and tend to contain valuable soft information about a company's performance. It is therefore of great interest to learn predictive models from these long textual documents, especially for forecasting numerical key performance indicators (KPIs). Whereas there has been a great progress in pre-trained language models (LMs) that learn from tremendously large corpora of textual data, they still struggle in terms of effective representations for long documents. Our work fills this critical need, namely how to develop better models to extract useful information from long textual documents and learn effective features that can leverage the soft financial and risk information for text regression (prediction) tasks. In this paper, we propose and implement a deep learning framework that splits long documents into chunks and utilizes pre-trained LMs to process and aggregate the chunks into vector representations, followed by self-attention to extract valuable document-level features. We evaluate our model on a collection of 10-K public disclosure reports from US banks, and another dataset of reports submitted by US companies. Overall, our framework outperforms strong baseline methods for textual modeling as well as a baseline regression model using only numerical data. Our work provides better insights into how utilizing pre-trained domain-specific and fine-tuned long-input LMs in representing long documents can improve the quality of representation of textual data, and therefore, help in improving predictive analyses.", "paper_url": "http://arxiv.org/abs/2206.06952v1", "pdf_url": "http://arxiv.org/pdf/2206.06952v1", "repo_url": null}, "2206.07699": {"publish_time": "2022-06-15", "title": "Prefix Language Models are Unified Modal Learners", "author": "Shizhe Diao et.al.", "abstract": "With the success of vision-language pre-training, we have witnessed the state-of-the-art has been pushed on multi-modal understanding and generation. However, the current pre-training paradigm is either incapable of targeting all modalities at once (e.g., text generation and image generation), or requires multi-fold well-designed tasks which significantly limits the scalability. We demonstrate that a unified modal model could be learned with a prefix language modeling objective upon text and image sequences. Thanks to the simple but powerful pre-training paradigm, our proposed model, DaVinci, is simple to train, scalable to huge data, and adaptable to a variety of downstream tasks across modalities (language / vision / vision+language), types (understanding / generation) and settings (e.g., zero-shot, fine-tuning, linear evaluation) with a single unified architecture. DaVinci achieves the competitive performance on a wide range of 26 understanding / generation tasks, and outperforms previous unified vision-language models on most tasks, including ImageNet classification (+1.6%), VQAv2 (+1.4%), COCO caption generation (BLEU@4 +1.1%, CIDEr +1.5%) and COCO image generation (IS +0.9%, FID -1.0%), at the comparable model and data scale. Furthermore, we offer a well-defined benchmark for future research by reporting the performance on different scales of the pre-training dataset on a heterogeneous and wide distribution coverage. Our results establish new, stronger baselines for future comparisons at different data scales and shed light on the difficulties of comparing VLP models more generally.", "paper_url": "http://arxiv.org/abs/2206.07699v1", "pdf_url": "http://arxiv.org/pdf/2206.07699v1", "repo_url": "https://github.com/shizhediao/davinci"}, "2206.07694": {"publish_time": "2022-06-15", "title": "DIRECTOR: Generator-Classifiers For Supervised Language Modeling", "author": "Kushal Arora et.al.", "abstract": "Current language models achieve low perplexity but their resulting generations still suffer from toxic responses, repetitiveness and contradictions. The standard language modeling setup fails to address these issues. In this paper, we introduce a new architecture, {\\sc Director}, that consists of a unified generator-classifier with both a language modeling and a classification head for each output token. Training is conducted jointly using both standard language modeling data, and data labeled with desirable and undesirable sequences. Experiments in several settings show that the model has competitive training and decoding speed compared to standard language models while yielding superior results, alleviating known issues while maintaining generation quality. It also outperforms existing model guiding approaches in terms of both accuracy and efficiency.", "paper_url": "http://arxiv.org/abs/2206.07694v1", "pdf_url": "http://arxiv.org/pdf/2206.07694v1", "repo_url": null}, "2206.07682": {"publish_time": "2022-06-15", "title": "Emergent Abilities of Large Language Models", "author": "Jason Wei et.al.", "abstract": "Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence implies that additional scaling could further expand the range of capabilities of language models.", "paper_url": "http://arxiv.org/abs/2206.07682v1", "pdf_url": "http://arxiv.org/pdf/2206.07682v1", "repo_url": null}, "2206.07669": {"publish_time": "2022-06-15", "title": "A Unified Sequence Interface for Vision Tasks", "author": "Ting Chen et.al.", "abstract": "While language tasks are naturally expressed in a single, unified, modeling framework, i.e., generating sequences of tokens, this has not been the case in computer vision. As a result, there is a proliferation of distinct architectures and loss functions for different vision tasks. In this work we show that a diverse set of \"core\" computer vision tasks can also be unified if formulated in terms of a shared pixel-to-sequence interface. We focus on four tasks, namely, object detection, instance segmentation, keypoint detection, and image captioning, all with diverse types of outputs, e.g., bounding boxes or dense masks. Despite that, by formulating the output of each task as a sequence of discrete tokens with a unified interface, we show that one can train a neural network with a single model architecture and loss function on all these tasks, with no task-specific customization. To solve a specific task, we use a short prompt as task description, and the sequence output adapts to the prompt so it can produce task-specific output. We show that such a model can achieve competitive performance compared to well-established task-specific models.", "paper_url": "http://arxiv.org/abs/2206.07669v1", "pdf_url": "http://arxiv.org/pdf/2206.07669v1", "repo_url": null}, "2206.07666": {"publish_time": "2022-06-15", "title": "Transformer-based Automatic Speech Recognition of Formal and Colloquial Czech in MALACH Project", "author": "Jan Lehe\u010dka et.al.", "abstract": "Czech is a very specific language due to its large differences between the formal and the colloquial form of speech. While the formal (written) form is used mainly in official documents, literature, and public speeches, the colloquial (spoken) form is used widely among people in casual speeches. This gap introduces serious problems for ASR systems, especially when training or evaluating ASR models on datasets containing a lot of colloquial speech, such as the MALACH project. In this paper, we are addressing this problem in the light of a new paradigm in end-to-end ASR systems -- recently introduced self-supervised audio Transformers. Specifically, we are investigating the influence of colloquial speech on the performance of Wav2Vec 2.0 models and their ability to transcribe colloquial speech directly into formal transcripts. We are presenting results with both formal and colloquial forms in the training transcripts, language models, and evaluation transcripts.", "paper_url": "http://arxiv.org/abs/2206.07666v1", "pdf_url": "http://arxiv.org/pdf/2206.07666v1", "repo_url": null}, "2206.08349": {"publish_time": "2022-06-16", "title": "Know your audience: specializing grounded language models with the game of Dixit", "author": "Aaditya K. Singh et.al.", "abstract": "Effective communication requires adapting to the idiosyncratic common ground shared with each communicative partner. We study a particularly challenging instantiation of this problem: the popular game Dixit. We formulate a round of Dixit as a multi-agent image reference game where a (trained) speaker model is rewarded for describing a target image such that one (pretrained) listener model can correctly identify it from a pool of distractors, but another listener cannot. To adapt to this setting, the speaker must exploit differences in the common ground it shares with the different listeners. We show that finetuning an attention-based adapter between a CLIP vision encoder and a large language model in this contrastive, multi-agent setting gives rise to context-dependent natural language specialization from rewards only, without direct supervision. In a series of controlled experiments, we show that the speaker can adapt according to the idiosyncratic strengths and weaknesses of various pairs of different listeners. Furthermore, we show zero-shot transfer of the speaker's specialization to unseen real-world data. Our experiments offer a step towards adaptive communication in complex multi-partner settings and highlight the interesting research challenges posed by games like Dixit. We hope that our work will inspire creative new approaches to adapting pretrained models.", "paper_url": "http://arxiv.org/abs/2206.08349v1", "pdf_url": "http://arxiv.org/pdf/2206.08349v1", "repo_url": null}, "2206.08325": {"publish_time": "2022-06-16", "title": "Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models", "author": "Maribeth Rauh et.al.", "abstract": "Large language models produce human-like text that drive a growing number of applications. However, recent literature and, increasingly, real world observations, have demonstrated that these models can generate language that is toxic, biased, untruthful or otherwise harmful. Though work to evaluate language model harms is under way, translating foresight about which harms may arise into rigorous benchmarks is not straightforward. To facilitate this translation, we outline six ways of characterizing harmful text which merit explicit consideration when designing new benchmarks. We then use these characteristics as a lens to identify trends and gaps in existing benchmarks. Finally, we apply them in a case study of the Perspective API, a toxicity classifier that is widely used in harm benchmarks. Our characteristics provide one piece of the bridge that translates between foresight and effective evaluation.", "paper_url": "http://arxiv.org/abs/2206.08325v1", "pdf_url": "http://arxiv.org/pdf/2206.08325v1", "repo_url": null}, "2206.08317": {"publish_time": "2022-06-16", "title": "Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition", "author": "Zhifu Gao et.al.", "abstract": "Transformers have recently dominated the ASR field. Although able to yield good performance, they involve an autoregressive (AR) decoder to generate tokens one by one, which is computationally inefficient. To speed up inference, non-autoregressive (NAR) methods, e.g. single-step NAR, were designed, to enable parallel generation. However, due to an independence assumption within the output tokens, performance of single-step NAR is inferior to that of AR models, especially with a large-scale corpus. There are two challenges to improving single-step NAR: Firstly to accurately predict the number of output tokens and extract hidden variables; secondly, to enhance modeling of interdependence between output tokens. To tackle both challenges, we propose a fast and accurate parallel transformer, termed Paraformer. This utilizes a continuous integrate-and-fire based predictor to predict the number of tokens and generate hidden variables. A glancing language model (GLM) sampler then generates semantic embeddings to enhance the NAR decoder's ability to model context interdependence. Finally, we design a strategy to generate negative samples for minimum word error rate training to further improve performance. Experiments using the public AISHELL-1, AISHELL-2 benchmark, and an industrial-level 20,000 hour task demonstrate that the proposed Paraformer can attain comparable performance to the state-of-the-art AR transformer, with more than 10x speedup.", "paper_url": "http://arxiv.org/abs/2206.08317v1", "pdf_url": "http://arxiv.org/pdf/2206.08317v1", "repo_url": null}, "2206.08288": {"publish_time": "2022-06-16", "title": "Balancing Cost and Quality: An Exploration of Human-in-the-loop Frameworks for Automated Short Answer Scoring", "author": "Hiroaki Funayama et.al.", "abstract": "Short answer scoring (SAS) is the task of grading short text written by a learner. In recent years, deep-learning-based approaches have substantially improved the performance of SAS models, but how to guarantee high-quality predictions still remains a critical issue when applying such models to the education field. Towards guaranteeing high-quality predictions, we present the first study of exploring the use of human-in-the-loop framework for minimizing the grading cost while guaranteeing the grading quality by allowing a SAS model to share the grading task with a human grader. Specifically, by introducing a confidence estimation method for indicating the reliability of the model predictions, one can guarantee the scoring quality by utilizing only predictions with high reliability for the scoring results and casting predictions with low reliability to human graders. In our experiments, we investigate the feasibility of the proposed framework using multiple confidence estimation methods and multiple SAS datasets. We find that our human-in-the-loop framework allows automatic scoring models and human graders to achieve the target scoring quality.", "paper_url": "http://arxiv.org/abs/2206.08288v1", "pdf_url": "http://arxiv.org/pdf/2206.08288v1", "repo_url": null}, "2206.08263": {"publish_time": "2022-06-16", "title": "'John ate 5 apples' != 'John ate some apples': Self-Supervised Paraphrase Quality Detection for Algebraic Word Problems", "author": "Rishabh Gupta et.al.", "abstract": "This paper introduces the novel task of scoring paraphrases for Algebraic Word Problems (AWP) and presents a self-supervised method for doing so. In the current online pedagogical setting, paraphrasing these problems is helpful for academicians to generate multiple syntactically diverse questions for assessments. It also helps induce variation to ensure that the student has understood the problem instead of just memorizing it or using unfair means to solve it. The current state-of-the-art paraphrase generation models often cannot effectively paraphrase word problems, losing a critical piece of information (such as numbers or units) which renders the question unsolvable. There is a need for paraphrase scoring methods in the context of AWP to enable the training of good paraphrasers. Thus, we propose ParaQD, a self-supervised paraphrase quality detection method using novel data augmentations that can learn latent representations to separate a high-quality paraphrase of an algebraic question from a poor one by a wide margin. Through extensive experimentation, we demonstrate that our method outperforms existing state-of-the-art self-supervised methods by up to 32% while also demonstrating impressive zero-shot performance.", "paper_url": "http://arxiv.org/abs/2206.08263v1", "pdf_url": "http://arxiv.org/pdf/2206.08263v1", "repo_url": "https://github.com/ads-ai/paraqd"}, "2206.08910": {"publish_time": "2022-06-17", "title": "niksss at HinglishEval: Language-agnostic BERT-based Contextual Embeddings with Catboost for Quality Evaluation of the Low-Resource Synthetically Generated Code-Mixed Hinglish Text", "author": "Nikhil Singh et.al.", "abstract": "This paper describes the system description for the HinglishEval challenge at INLG 2022. The goal of this task was to investigate the factors influencing the quality of the code-mixed text generation system. The task was divided into two subtasks, quality rating prediction and annotators disagreement prediction of the synthetic Hinglish dataset. We attempted to solve these tasks using sentence-level embeddings, which are obtained from mean pooling the contextualized word embeddings for all input tokens in our text. We experimented with various classifiers on top of the embeddings produced for respective tasks. Our best-performing system ranked 1st on subtask B and 3rd on subtask A.", "paper_url": "http://arxiv.org/abs/2206.08910v1", "pdf_url": "http://arxiv.org/pdf/2206.08910v1", "repo_url": "https://github.com/nikhilbyte/hinglish-qeval"}, "2206.08853": {"publish_time": "2022-06-17", "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge", "author": "Linxi Fan et.al.", "abstract": "Autonomous agents have made great strides in specialist domains like Atari games and Go. However, they typically learn tabula rasa in isolated environments with limited and manually conceived objectives, thus failing to generalize across a wide spectrum of tasks and capabilities. Inspired by how humans continually learn and adapt in the open world, we advocate a trinity of ingredients for building generalist agents: 1) an environment that supports a multitude of tasks and goals, 2) a large-scale database of multimodal knowledge, and 3) a flexible and scalable agent architecture. We introduce MineDojo, a new framework built on the popular Minecraft game that features a simulation suite with thousands of diverse open-ended tasks and an internet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and forum discussions. Using MineDojo's data, we propose a novel agent learning algorithm that leverages large pre-trained video-language models as a learned reward function. Our agent is able to solve a variety of open-ended tasks specified in free-form language without any manually designed dense shaping reward. We open-source the simulation suite and knowledge bases (https://minedojo.org) to promote research towards the goal of generally capable embodied agents.", "paper_url": "http://arxiv.org/abs/2206.08853v1", "pdf_url": "http://arxiv.org/pdf/2206.08853v1", "repo_url": "https://github.com/MineDojo/MineDojo"}, "2206.08835": {"publish_time": "2022-06-17", "title": "What can Speech and Language Tell us About the Working Alliance in Psychotherapy", "author": "Sebastian P. Bayerl et.al.", "abstract": "We are interested in the problem of conversational analysis and its application to the health domain. Cognitive Behavioral Therapy is a structured approach in psychotherapy, allowing the therapist to help the patient to identify and modify the malicious thoughts, behavior, or actions. This cooperative effort can be evaluated using the Working Alliance Inventory Observer-rated Shortened - a 12 items inventory covering task, goal, and relationship - which has a relevant influence on therapeutic outcomes. In this work, we investigate the relation between this alliance inventory and the spoken conversations (sessions) between the patient and the psychotherapist. We have delivered eight weeks of e-therapy, collected their audio and video call sessions, and manually transcribed them. The spoken conversations have been annotated and evaluated with WAI ratings by professional therapists. We have investigated speech and language features and their association with WAI items. The feature types include turn dynamics, lexical entrainment, and conversational descriptors extracted from the speech and language signals. Our findings provide strong evidence that a subset of these features are strong indicators of working alliance. To the best of our knowledge, this is the first and a novel study to exploit speech and language for characterising working alliance.", "paper_url": "http://arxiv.org/abs/2206.08835v1", "pdf_url": "http://arxiv.org/pdf/2206.08835v1", "repo_url": null}, "2206.08823": {"publish_time": "2022-06-17", "title": "Language with Vision: a Study on Grounded Word and Sentence Embeddings", "author": "Hassan Shahmohammadi et.al.", "abstract": "Language grounding to vision is an active field of research aiming to enrich text-based representations of word meanings by leveraging perceptual knowledge from vision. Despite many attempts at language grounding, it is still unclear how to effectively inject visual knowledge into the word embeddings of a language in such a way that a proper balance of textual and visual knowledge is maintained. Some common concerns are the following. Is visual grounding beneficial for abstract words or is its contribution only limited to concrete words? What is the optimal way of bridging the gap between text and vision? How much do we gain by visually grounding textual embeddings? The present study addresses these questions by proposing a simple yet very effective grounding approach for pre-trained word embeddings. Our model aligns textual embeddings with vision while largely preserving the distributional statistics that characterize word use in text corpora. By applying a learned alignment, we are able to generate visually grounded embeddings for unseen words, including abstract words. A series of evaluations on word similarity benchmarks shows that visual grounding is beneficial not only for concrete words, but also for abstract words. We also show that our method for visual grounding offers advantages for contextualized embeddings, but only when these are trained on corpora of relatively modest size. Code and grounded embeddings for English are available at https://github.com/Hazel1994/Visually_Grounded_Word_Embeddings_2.", "paper_url": "http://arxiv.org/abs/2206.08823v1", "pdf_url": "http://arxiv.org/pdf/2206.08823v1", "repo_url": "https://github.com/hazel1994/visually_grounded_word_embeddings_2"}, "2206.08790": {"publish_time": "2022-06-17", "title": "Self-supervised speech unit discovery from articulatory and acoustic features using VQ-VAE", "author": "Marc-Antoine Georges et.al.", "abstract": "The human perception system is often assumed to recruit motor knowledge when processing auditory speech inputs. Using articulatory modeling and deep learning, this study examines how this articulatory information can be used for discovering speech units in a self-supervised setting. We used vector-quantized variational autoencoders (VQ-VAE) to learn discrete representations from articulatory and acoustic speech data. In line with the zero-resource paradigm, an ABX test was then used to investigate how the extracted representations encode phonetically relevant properties. Experiments were conducted on three different corpora in English and French. We found that articulatory information rather organises the latent representations in terms of place of articulation whereas the speech acoustics mainly structure the latent space in terms of manner of articulation. We show that an optimal fusion of the two modalities can lead to a joint representation of these phonetic dimensions more accurate than each modality considered individually. Since articulatory information is usually not available in a practical situation, we finally investigate the benefit it provides when inferred from the speech acoustics in a self-supervised manner.", "paper_url": "http://arxiv.org/abs/2206.08790v1", "pdf_url": "http://arxiv.org/pdf/2206.08790v1", "repo_url": null}, "2206.10559": {"publish_time": "2022-06-21", "title": "Low Resource Pipeline for Spoken Language Understanding via Weak Supervision", "author": "Ayush Kumar et.al.", "abstract": "In Weak Supervised Learning (WSL), a model is trained over noisy labels obtained from semantic rules and task-specific pre-trained models. Rules offer limited generalization over tasks and require significant manual efforts while pre-trained models are available only for limited tasks. In this work, we propose to utilize prompt-based methods as weak sources to obtain the noisy labels on unannotated data. We show that task-agnostic prompts are generalizable and can be used to obtain noisy labels for different Spoken Language Understanding (SLU) tasks such as sentiment classification, disfluency detection and emotion classification. These prompts could additionally be updated to add task-specific contexts, thus providing flexibility to design task-specific prompts. We demonstrate that prompt-based methods generate reliable labels for the above SLU tasks and thus can be used as a universal weak source to train a weak-supervised model (WSM) in absence of labeled data. Our proposed WSL pipeline trained over prompt-based weak source outperforms other competitive low-resource benchmarks on zero and few-shot learning by more than 4% on Macro-F1 on all of the three benchmark SLU datasets. The proposed method also outperforms a conventional rule based WSL pipeline by more than 5% on Macro-F1.", "paper_url": "http://arxiv.org/abs/2206.10559v1", "pdf_url": "http://arxiv.org/pdf/2206.10559v1", "repo_url": null}, "2206.10498": {"publish_time": "2022-06-21", "title": "Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)", "author": "Karthik Valmeekam et.al.", "abstract": "The recent advances in large language models (LLMs) have transformed the field of natural language processing (NLP). From GPT-3 to PaLM, the state-of-the-art performance on natural language tasks is being pushed forward with every new large language model. Along with natural language abilities, there has been a significant interest in understanding whether such models, trained on enormous amounts of data, exhibit reasoning capabilities. Hence there has been interest in developing benchmarks for various reasoning tasks and the preliminary results from testing LLMs over such benchmarks seem mostly positive. However, the current benchmarks are relatively simplistic and the performance over these benchmarks cannot be used as an evidence to support, many a times outlandish, claims being made about LLMs' reasoning capabilities. As of right now, these benchmarks only represent a very limited set of simple reasoning tasks and we need to look at more sophisticated reasoning problems if we are to measure the true limits of such LLM-based systems. With this motivation, we propose an extensible assessment framework to test the abilities of LLMs on a central aspect of human intelligence, which is reasoning about actions and change. We provide multiple test cases that are more involved than any of the previously established reasoning benchmarks and each test case evaluates a certain aspect of reasoning about actions and change. Initial evaluation results on the base version of GPT-3 (Davinci), showcase subpar performance on these benchmarks.", "paper_url": "http://arxiv.org/abs/2206.10498v1", "pdf_url": "http://arxiv.org/pdf/2206.10498v1", "repo_url": null}, "2206.10471": {"publish_time": "2022-06-21", "title": "Twitter conversations predict the daily confirmed COVID-19 cases", "author": "Rabindra Lamsala et.al.", "abstract": "As of writing this paper, COVID-19 (Coronavirus disease 2019) has spread to more than 220 countries and territories. Following the outbreak, the pandemic's seriousness has made people more active on social media, especially on the microblogging platforms such as Twitter and Weibo. The pandemic-specific discourse has remained on-trend on these platforms for months now. Previous studies have confirmed the contributions of such socially generated conversations towards situational awareness of crisis events. The early forecasts of cases are essential to authorities to estimate the requirements of resources needed to cope with the outgrowths of the virus. Therefore, this study attempts to incorporate the public discourse in the design of forecasting models particularly targeted for the steep-hill region of an ongoing wave. We propose a sentiment-involved topic-based methodology for designing multiple time series from publicly available COVID-19 related Twitter conversations. As a use case, we implement the proposed methodology on Australian COVID-19 daily cases and Twitter conversations generated within the country. Experimental results: (i) show the presence of latent social media variables that Granger-cause the daily COVID-19 confirmed cases, and (ii) confirm that those variables offer additional prediction capability to forecasting models. Further, the results show that the inclusion of social media variables for modeling introduces 48.83--51.38% improvements on RMSE over the baseline models. We also release the large-scale COVID-19 specific geotagged global tweets dataset, MegaGeoCOV, to the public anticipating that the geotagged data of this scale would aid in understanding the conversational dynamics of the pandemic through other spatial and temporal contexts.", "paper_url": "http://arxiv.org/abs/2206.10471v1", "pdf_url": "http://arxiv.org/pdf/2206.10471v1", "repo_url": null}, "2206.10461": {"publish_time": "2022-06-21", "title": "An Automatic and Efficient BERT Pruning for Edge AI Systems", "author": "Shaoyi Huang et.al.", "abstract": "With the yearning for deep learning democratization, there are increasing demands to implement Transformer-based natural language processing (NLP) models on resource-constrained devices for low-latency and high accuracy. Existing BERT pruning methods require domain experts to heuristically handcraft hyperparameters to strike a balance among model size, latency, and accuracy. In this work, we propose AE-BERT, an automatic and efficient BERT pruning framework with efficient evaluation to select a \"good\" sub-network candidate (with high accuracy) given the overall pruning ratio constraints. Our proposed method requires no human experts experience and achieves a better accuracy performance on many NLP tasks. Our experimental results on General Language Understanding Evaluation (GLUE) benchmark show that AE-BERT outperforms the state-of-the-art (SOTA) hand-crafted pruning methods on BERT$_{\\mathrm{BASE}}$. On QNLI and RTE, we obtain 75\\% and 42.8\\% more overall pruning ratio while achieving higher accuracy. On MRPC, we obtain a 4.6 higher score than the SOTA at the same overall pruning ratio of 0.5. On STS-B, we can achieve a 40\\% higher pruning ratio with a very small loss in Spearman correlation compared to SOTA hand-crafted pruning methods. Experimental results also show that after model compression, the inference time of a single BERT$_{\\mathrm{BASE}}$ encoder on Xilinx Alveo U200 FPGA board has a 1.83$\\times$ speedup compared to Intel(R) Xeon(R) Gold 5218 (2.30GHz) CPU, which shows the reasonableness of deploying the proposed method generated subnets of BERT$_{\\mathrm{BASE}}$ model on computation restricted devices.", "paper_url": "http://arxiv.org/abs/2206.10461v1", "pdf_url": "http://arxiv.org/pdf/2206.10461v1", "repo_url": null}, "2206.10429": {"publish_time": "2022-06-21", "title": "Plug and Play Counterfactual Text Generation for Model Robustness", "author": "Nishtha Madaan et.al.", "abstract": "Generating counterfactual test-cases is an important backbone for testing NLP models and making them as robust and reliable as traditional software. In generating the test-cases, a desired property is the ability to control the test-case generation in a flexible manner to test for a large variety of failure cases and to explain and repair them in a targeted manner. In this direction, significant progress has been made in the prior works by manually writing rules for generating controlled counterfactuals. However, this approach requires heavy manual supervision and lacks the flexibility to easily introduce new controls. Motivated by the impressive flexibility of the plug-and-play approach of PPLM, we propose bringing the framework of plug-and-play to counterfactual test case generation task. We introduce CASPer, a plug-and-play counterfactual generation framework to generate test cases that satisfy goal attributes on demand. Our plug-and-play model can steer the test case generation process given any attribute model without requiring attribute-specific training of the model. In experiments, we show that CASPer effectively generates counterfactual text that follow the steering provided by an attribute model while also being fluent, diverse and preserving the original content. We also show that the generated counterfactuals from CASPer can be used for augmenting the training data and thereby fixing and making the test model more robust.", "paper_url": "http://arxiv.org/abs/2206.10429v1", "pdf_url": "http://arxiv.org/pdf/2206.10429v1", "repo_url": null}, "2206.11249": {"publish_time": "2022-06-22", "title": "GEMv2: Multilingual NLG Benchmarking in a Single Line of Code", "author": "Sebastian Gehrmann et.al.", "abstract": "Evaluation in machine learning is usually informed by past choices, for example which datasets or metrics to use. This standardization enables the comparison on equal footing using leaderboards, but the evaluation choices become sub-optimal as better alternatives arise. This problem is especially pertinent in natural language generation which requires ever-improving suites of datasets, metrics, and human evaluation to make definitive claims. To make following best model evaluation practices easier, we introduce GEMv2. The new version of the Generation, Evaluation, and Metrics Benchmark introduces a modular infrastructure for dataset, model, and metric developers to benefit from each others work. GEMv2 supports 40 documented datasets in 51 languages. Models for all datasets can be evaluated online and our interactive data card creation and rendering tools make it easier to add new datasets to the living benchmark.", "paper_url": "http://arxiv.org/abs/2206.11249v1", "pdf_url": "http://arxiv.org/pdf/2206.11249v1", "repo_url": null}, "2206.11219": {"publish_time": "2022-06-22", "title": "Understanding the Properties of Generated Corpora", "author": "Naama Zwerdling et.al.", "abstract": "Models for text generation have become focal for many research tasks and especially for the generation of sentence corpora. However, understanding the properties of an automatically generated text corpus remains challenging. We propose a set of tools that examine the properties of generated text corpora. Applying these tools on various generated corpora allowed us to gain new insights into the properties of the generative models. As part of our characterization process, we found remarkable differences in the corpora generated by two leading generative technologies.", "paper_url": "http://arxiv.org/abs/2206.11219v1", "pdf_url": "http://arxiv.org/pdf/2206.11219v1", "repo_url": null}, "2206.11218": {"publish_time": "2022-06-22", "title": "Hierarchical Context Tagging for Utterance Rewriting", "author": "Lisa Jin et.al.", "abstract": "Utterance rewriting aims to recover coreferences and omitted information from the latest turn of a multi-turn dialogue. Recently, methods that tag rather than linearly generate sequences have proven stronger in both in- and out-of-domain rewriting settings. This is due to a tagger's smaller search space as it can only copy tokens from the dialogue context. However, these methods may suffer from low coverage when phrases that must be added to a source utterance cannot be covered by a single context span. This can occur in languages like English that introduce tokens such as prepositions into the rewrite for grammaticality. We propose a hierarchical context tagger (HCT) that mitigates this issue by predicting slotted rules (e.g., \"besides_\") whose slots are later filled with context spans. HCT (i) tags the source string with token-level edit actions and slotted rules and (ii) fills in the resulting rule slots with spans from the dialogue context. This rule tagging allows HCT to add out-of-context tokens and multiple spans at once; we further cluster the rules to truncate the long tail of the rule distribution. Experiments on several benchmarks show that HCT can outperform state-of-the-art rewriting systems by ~2 BLEU points.", "paper_url": "http://arxiv.org/abs/2206.11218v1", "pdf_url": "http://arxiv.org/pdf/2206.11218v1", "repo_url": "https://github.com/lisjin/hct"}, "2206.11212": {"publish_time": "2022-06-22", "title": "VisFIS: Visual Feature Importance Supervision with Right-for-the-Right-Reason Objectives", "author": "Zhuofan Ying et.al.", "abstract": "Many past works aim to improve visual reasoning in models by supervising feature importance (estimated by model explanation techniques) with human annotations such as highlights of important image regions. However, recent work has shown that performance gains from feature importance (FI) supervision for Visual Question Answering (VQA) tasks persist even with random supervision, suggesting that these methods do not meaningfully align model FI with human FI. In this paper, we show that model FI supervision can meaningfully improve VQA model accuracy as well as performance on several Right-for-the-Right-Reason (RRR) metrics by optimizing for four key model objectives: (1) accurate predictions given limited but sufficient information (Sufficiency); (2) max-entropy predictions given no important information (Uncertainty); (3) invariance of predictions to changes in unimportant features (Invariance); and (4) alignment between model FI explanations and human FI explanations (Plausibility). Our best performing method, Visual Feature Importance Supervision (VisFIS), outperforms strong baselines on benchmark VQA datasets in terms of both in-distribution and out-of-distribution accuracy. While past work suggests that the mechanism for improved accuracy is through improved explanation plausibility, we show that this relationship depends crucially on explanation faithfulness (whether explanations truly represent the model's internal reasoning). Predictions are more accurate when explanations are plausible and faithful, and not when they are plausible but not faithful. Lastly, we show that, surprisingly, RRR metrics are not predictive of out-of-distribution model accuracy when controlling for a model's in-distribution accuracy, which calls into question the value of these metrics for evaluating model reasoning. All supporting code is available at https://github.com/zfying/visfis", "paper_url": "http://arxiv.org/abs/2206.11212v1", "pdf_url": "http://arxiv.org/pdf/2206.11212v1", "repo_url": "https://github.com/zfying/visfis"}, "2206.11184": {"publish_time": "2022-06-22", "title": "Towards Unsupervised Content Disentanglement in Sentence Representations via Syntactic Roles", "author": "Ghazi Felhi et.al.", "abstract": "Linking neural representations to linguistic factors is crucial in order to build and analyze NLP models interpretable by humans. Among these factors, syntactic roles (e.g. subjects, direct objects,$\\dots$) and their realizations are essential markers since they can be understood as a decomposition of predicative structures and thus the meaning of sentences. Starting from a deep probabilistic generative model with attention, we measure the interaction between latent variables and realizations of syntactic roles and show that it is possible to obtain, without supervision, representations of sentences where different syntactic roles correspond to clearly identified different latent variables. The probabilistic model we propose is an Attention-Driven Variational Autoencoder (ADVAE). Drawing inspiration from Transformer-based machine translation models, ADVAEs enable the analysis of the interactions between latent variables and input tokens through attention. We also develop an evaluation protocol to measure disentanglement with regard to the realizations of syntactic roles. This protocol is based on attention maxima for the encoder and on latent variable perturbations for the decoder. Our experiments on raw English text from the SNLI dataset show that $\\textit{i)}$ disentanglement of syntactic roles can be induced without supervision, $\\textit{ii)}$ ADVAE separates syntactic roles better than classical sequence VAEs and Transformer VAEs, $\\textit{iii)}$ realizations of syntactic roles can be separately modified in sentences by mere intervention on the associated latent variables. Our work constitutes a first step towards unsupervised controllable content generation. The code for our work is publicly available.", "paper_url": "http://arxiv.org/abs/2206.11184v1", "pdf_url": "http://arxiv.org/pdf/2206.11184v1", "repo_url": null}, "2206.11719": {"publish_time": "2022-06-23", "title": "AST-Probe: Recovering abstract syntax trees from hidden representations of pre-trained language models", "author": "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez et.al.", "abstract": "The objective of pre-trained language models is to learn contextual representations of textual data. Pre-trained language models have become mainstream in natural language processing and code modeling. Using probes, a technique to study the linguistic properties of hidden vector spaces, previous works have shown that these pre-trained language models encode simple linguistic properties in their hidden representations. However, none of the previous work assessed whether these models encode the whole grammatical structure of a programming language. In this paper, we prove the existence of a \\textit{syntactic subspace}, lying in the hidden representations of pre-trained language models, which contain the syntactic information of the programming language. We show that this subspace can be extracted from the models' representations and define a novel probing method, the AST-Probe, that enables recovering the whole abstract syntax tree (AST) of an input code snippet. In our experimentations, we show that this syntactic subspace exists in five state-of-the-art pre-trained language models. In addition, we highlight that the middle layers of the models are the ones that encode most of the AST information. Finally, we estimate the optimal size of this syntactic subspace and show that its dimension is substantially lower than those of the models' representation spaces. This suggests that pre-trained language models use a small part of their representation spaces to encode syntactic information of the programming languages.", "paper_url": "http://arxiv.org/abs/2206.11719v1", "pdf_url": "http://arxiv.org/pdf/2206.11719v1", "repo_url": null}, "2206.11706": {"publish_time": "2022-06-23", "title": "A Temporal Extension of Latent Dirichlet Allocation for Unsupervised Acoustic Unit Discovery", "author": "Werner van der Merwe et.al.", "abstract": "Latent Dirichlet allocation (LDA) is widely used for unsupervised topic modelling on sets of documents. No temporal information is used in the model. However, there is often a relationship between the corresponding topics of consecutive tokens. In this paper, we present an extension to LDA that uses a Markov chain to model temporal information. We use this new model for acoustic unit discovery from speech. As input tokens, the model takes a discretised encoding of speech from a vector quantised (VQ) neural network with 512 codes. The goal is then to map these 512 VQ codes to 50 phone-like units (topics) in order to more closely resemble true phones. In contrast to the base LDA, which only considers how VQ codes co-occur within utterances (documents), the Markov chain LDA additionally captures how consecutive codes follow one another. This extension leads to an increase in cluster quality and phone segmentation results compared to the base LDA. Compared to a recent vector quantised neural network approach that also learns 50 units, the extended LDA model performs better in phone segmentation but worse in mutual information.", "paper_url": "http://arxiv.org/abs/2206.11706v1", "pdf_url": "http://arxiv.org/pdf/2206.11706v1", "repo_url": null}, "2206.11684": {"publish_time": "2022-06-23", "title": "Theory-Grounded Measurement of U.S. Social Stereotypes in English Language Models", "author": "Yang Trista Cao et.al.", "abstract": "NLP models trained on text have been shown to reproduce human stereotypes, which can magnify harms to marginalized groups when systems are deployed at scale. We adapt the Agency-Belief-Communion (ABC) stereotype model of Koch et al. (2016) from social psychology as a framework for the systematic study and discovery of stereotypic group-trait associations in language models (LMs). We introduce the sensitivity test (SeT) for measuring stereotypical associations from language models. To evaluate SeT and other measures using the ABC model, we collect group-trait judgments from U.S.-based subjects to compare with English LM stereotypes. Finally, we extend this framework to measure LM stereotyping of intersectional identities.", "paper_url": "http://arxiv.org/abs/2206.11684v1", "pdf_url": "http://arxiv.org/pdf/2206.11684v1", "repo_url": "https://github.com/tristacao/u.s_stereotypes"}, "2206.11612": {"publish_time": "2022-06-23", "title": "Constructing Cross-lingual Consumer Health Vocabulary with Word-Embedding from Comparable User Generated Content", "author": "Chia-Hsuan Chang et.al.", "abstract": "The online health community (OHC) is the primary channel for laypeople to share health information. To analyze the health consumer-generated content (HCGC) from the OHCs, identifying the colloquial medical expressions used by laypeople is a critical challenge. The open-access and collaborative consumer health vocabulary (OAC CHV) is the controlled vocabulary for addressing such a challenge. Nevertheless, OAC CHV is only available in English, limiting the applicability to other languages. This research aims to propose a cross-lingual automatic term recognition framework for extending the English OAC CHV into a cross-lingual one. Our framework requires an English HCGC corpus and a non-English (i.e., Chinese in this study) HCGC corpus as inputs. Two monolingual word vector spaces are determined using skip-gram algorithm so that each space encodes common word associations from laypeople within a language. Based on isometry assumption, the framework align two monolingual spaces into a bilingual word vector space, where we employ cosine similarity as a metric for identifying semantically similar words across languages. In the experiments, our framework demonstrates that it can effectively retrieve similar medical terms, including colloquial expressions, across languages and further facilitate compilation of cross-lingual CHV.", "paper_url": "http://arxiv.org/abs/2206.11612v1", "pdf_url": "http://arxiv.org/pdf/2206.11612v1", "repo_url": null}, "2206.11569": {"publish_time": "2022-06-23", "title": "Mining Error Templates for Grammatical Error Correction", "author": "Yue Zhang et.al.", "abstract": "Some grammatical error correction (GEC) systems incorporate hand-crafted rules and achieve positive results. However, manually defining rules is time-consuming and laborious. In view of this, we propose a method to mine error templates for GEC automatically. An error template is a regular expression aiming at identifying text errors. We use the web crawler to acquire such error templates from the Internet. For each template, we further select the corresponding corrective action by using the language model perplexity as a criterion. We have accumulated 1,119 error templates for Chinese GEC based on this method. Experimental results on the newly proposed CTC-2021 Chinese GEC benchmark show that combing our error templates can effectively improve the performance of a strong GEC system, especially on two error types with very little training data. Our error templates are available at \\url{https://github.com/HillZhang1999/gec_error_template}.", "paper_url": "http://arxiv.org/abs/2206.11569v1", "pdf_url": "http://arxiv.org/pdf/2206.11569v1", "repo_url": "https://github.com/hillzhang1999/gec_error_template"}, "2206.12388": {"publish_time": "2022-06-24", "title": "QAGAN: Adversarial Approach To Learning Domain Invariant Language Features", "author": "Shubham Shrivastava et.al.", "abstract": "Training models that are robust to data domain shift has gained an increasing interest both in academia and industry. Question-Answering language models, being one of the typical problem in Natural Language Processing (NLP) research, has received much success with the advent of large transformer models. However, existing approaches mostly work under the assumption that data is drawn from same distribution during training and testing which is unrealistic and non-scalable in the wild.   In this paper, we explore adversarial training approach towards learning domain-invariant features so that language models can generalize well to out-of-domain datasets. We also inspect various other ways to boost our model performance including data augmentation by paraphrasing sentences, conditioning end of answer span prediction on the start word, and carefully designed annealing function. Our initial results show that in combination with these methods, we are able to achieve $15.2\\%$ improvement in EM score and $5.6\\%$ boost in F1 score on out-of-domain validation dataset over the baseline. We also dissect our model outputs and visualize the model hidden-states by projecting them onto a lower-dimensional space, and discover that our specific adversarial training approach indeed encourages the model to learn domain invariant embedding and bring them closer in the multi-dimensional space.", "paper_url": "http://arxiv.org/abs/2206.12388v1", "pdf_url": "http://arxiv.org/pdf/2206.12388v1", "repo_url": "https://github.com/towardsautonomy/qagan"}, "2206.12368": {"publish_time": "2022-06-24", "title": "Using BERT Embeddings to Model Word Importance in Conversational Transcripts for Deaf and Hard of Hearing Users", "author": "Akhter Al Amin et.al.", "abstract": "Deaf and hard of hearing individuals regularly rely on captioning while watching live TV. Live TV captioning is evaluated by regulatory agencies using various caption evaluation metrics. However, caption evaluation metrics are often not informed by preferences of DHH users or how meaningful the captions are. There is a need to construct caption evaluation metrics that take the relative importance of words in a transcript into account. We conducted correlation analysis between two types of word embeddings and human-annotated labeled word-importance scores in existing corpus. We found that normalized contextualized word embeddings generated using BERT correlated better with manually annotated importance scores than word2vec-based word embeddings. We make available a pairing of word embeddings and their human-annotated importance scores. We also provide proof-of-concept utility by training word importance models, achieving an F1-score of 0.57 in the 6-class word importance classification task.", "paper_url": "http://arxiv.org/abs/2206.12368v1", "pdf_url": "http://arxiv.org/pdf/2206.12368v1", "repo_url": null}, "2206.12294": {"publish_time": "2022-06-24", "title": "Learning Rhetorical Structure Theory-based descriptions of observed behaviour", "author": "Luis Botelho et.al.", "abstract": "In a previous paper, we have proposed a set of concepts, axiom schemata and algorithms that can be used by agents to learn to describe their behaviour, goals, capabilities, and environment. The current paper proposes a new set of concepts, axiom schemata and algorithms that allow the agent to learn new descriptions of an observed behaviour (e.g., perplexing actions), of its actor (e.g., undesired propositions or actions), and of its environment (e.g., incompatible propositions). Each learned description (e.g., a certain action prevents another action from being performed in the future) is represented by a relationship between entities (either propositions or actions) and is learned by the agent, just by observation, using domain-independent axiom schemata and or learning algorithms. The relations used by agents to represent the descriptions they learn were inspired on the Theory of Rhetorical Structure (RST). The main contribution of the paper is the relation family Although, inspired on the RST relation Concession. The accurate definition of the relations of the family Although involves a set of deontic concepts whose definition and corresponding algorithms are presented. The relations of the family Although, once extracted from the agent's observations, express surprise at the observed behaviour and, in certain circumstances, present a justification for it.   The paper shows results of the presented proposals in a demonstration scenario, using implemented software.", "paper_url": "http://arxiv.org/abs/2206.12294v1", "pdf_url": "http://arxiv.org/pdf/2206.12294v1", "repo_url": null}, "2206.12293": {"publish_time": "2022-06-24", "title": "Text and author-level political inference using heterogeneous knowledge representations", "author": "Samuel Caetano da Silva et.al.", "abstract": "The inference of politically-charged information from text data is a popular research topic in Natural Language Processing (NLP) at both text- and author-level. In recent years, studies of this kind have been implemented with the aid of representations from transformers such as BERT. Despite considerable success, however, we may ask whether results may be improved even further by combining transformed-based models with additional knowledge representations. To shed light on this issue, the present work describes a series of experiments to compare alternative model configurations for political inference from text in both English and Portuguese languages. Results suggest that certain text representations - in particular, the combined use of BERT pre-trained language models with a syntactic dependency model - may outperform the alternatives across multiple experimental settings, making a potentially strong case for further research in the use of heterogeneous text representations in these and possibly other NLP tasks.", "paper_url": "http://arxiv.org/abs/2206.12293v1", "pdf_url": "http://arxiv.org/pdf/2206.12293v1", "repo_url": null}, "2206.12284": {"publish_time": "2022-06-24", "title": "Robustness of Explanation Methods for NLP Models", "author": "Shriya Atmakuri et.al.", "abstract": "Explanation methods have emerged as an important tool to highlight the features responsible for the predictions of neural networks. There is mounting evidence that many explanation methods are rather unreliable and susceptible to malicious manipulations. In this paper, we particularly aim to understand the robustness of explanation methods in the context of text modality. We provide initial insights and results towards devising a successful adversarial attack against text explanations. To our knowledge, this is the first attempt to evaluate the adversarial robustness of an explanation method. Our experiments show the explanation method can be largely disturbed for up to 86% of the tested samples with small changes in the input sentence and its semantics.", "paper_url": "http://arxiv.org/abs/2206.12284v1", "pdf_url": "http://arxiv.org/pdf/2206.12284v1", "repo_url": null}, "2206.13425": {"publish_time": "2022-06-27", "title": "Simplifying Semantic Annotations of SMCalFlow", "author": "Joram Meron et.al.", "abstract": "SMCalFlow is a large corpus of semantically detailed annotations of task-oriented natural dialogues. The annotations use a dataflow approach, in which the annotations are programs which represent user requests. Despite the availability, size and richness of this annotated corpus, it has seen only very limited use in dialogue systems research work, at least in part due to the difficulty in understanding and using the annotations. To address these difficulties, this paper suggests a simplification of the SMCalFlow annotations, as well as releases code needed to inspect the execution of the annotated dataflow programs, which should allow researchers of dialogue systems an easy entry point to experiment with various dataflow based implementations and annotations.", "paper_url": "http://arxiv.org/abs/2206.13425v1", "pdf_url": "http://arxiv.org/pdf/2206.13425v1", "repo_url": "https://github.com/telepathylabsai/OpenDF"}, "2206.13415": {"publish_time": "2022-06-27", "title": "Is the Language Familiarity Effect gradual? A computational modelling approach", "author": "Maureen de Seyssel et.al.", "abstract": "According to the Language Familiarity Effect (LFE), people are better at discriminating between speakers of their native language. Although this cognitive effect was largely studied in the literature, experiments have only been conducted on a limited number of language pairs and their results only show the presence of the effect without yielding a gradual measure that may vary across language pairs. In this work, we show that the computational model of LFE introduced by Thorburn, Feldmand and Schatz (2019) can address these two limitations. In a first experiment, we attest to this model's capacity to obtain a gradual measure of the LFE by replicating behavioural findings on native and accented speech. In a second experiment, we evaluate LFE on a large number of language pairs, including many which have never been tested on humans. We show that the effect is replicated across a wide array of languages, providing further evidence of its universality. Building on the gradual measure of LFE, we also show that languages belonging to the same family yield smaller scores, supporting the idea of an effect of language distance on LFE.", "paper_url": "http://arxiv.org/abs/2206.13415v1", "pdf_url": "http://arxiv.org/pdf/2206.13415v1", "repo_url": null}, "2206.13289": {"publish_time": "2022-06-27", "title": "Analyzing Encoded Concepts in Transformer Language Models", "author": "Hassan Sajjad et.al.", "abstract": "We propose a novel framework ConceptX, to analyze how latent concepts are encoded in representations learned within pre-trained language models. It uses clustering to discover the encoded concepts and explains them by aligning with a large set of human-defined concepts. Our analysis on seven transformer language models reveal interesting insights: i) the latent space within the learned representations overlap with different linguistic concepts to a varying degree, ii) the lower layers in the model are dominated by lexical concepts (e.g., affixation), whereas the core-linguistic concepts (e.g., morphological or syntactic relations) are better represented in the middle and higher layers, iii) some encoded concepts are multi-faceted and cannot be adequately explained using the existing human-defined concepts.", "paper_url": "http://arxiv.org/abs/2206.13289v1", "pdf_url": "http://arxiv.org/pdf/2206.13289v1", "repo_url": null}, "2206.13288": {"publish_time": "2022-06-27", "title": "Linguistic Correlation Analysis: Discovering Salient Neurons in deepNLP models", "author": "Nadir Durrani et.al.", "abstract": "While a lot of work has been done in understanding representations learned within deep NLP models and what knowledge they capture, little attention has been paid towards individual neurons. We present a technique called as Linguistic Correlation Analysis to extract salient neurons in the model, with respect to any extrinsic property - with the goal of understanding how such a knowledge is preserved within neurons. We carry out a fine-grained analysis to answer the following questions: (i) can we identify subsets of neurons in the network that capture specific linguistic properties? (ii) how localized or distributed neurons are across the network? iii) how redundantly is the information preserved? iv) how fine-tuning pre-trained models towards downstream NLP tasks, impacts the learned linguistic knowledge? iv) how do architectures vary in learning different linguistic properties? Our data-driven, quantitative analysis illuminates interesting findings: (i) we found small subsets of neurons that can predict different linguistic tasks, ii) with neurons capturing basic lexical information (such as suffixation) localized in lower most layers, iii) while those learning complex concepts (such as syntactic role) predominantly in middle and higher layers, iii) that salient linguistic neurons are relocated from higher to lower layers during transfer learning, as the network preserve the higher layers for task specific information, iv) we found interesting differences across pre-trained models, with respect to how linguistic information is preserved within, and v) we found that concept exhibit similar neuron distribution across different languages in the multilingual transformer models. Our code is publicly available as part of the NeuroX toolkit.", "paper_url": "http://arxiv.org/abs/2206.13288v1", "pdf_url": "http://arxiv.org/pdf/2206.13288v1", "repo_url": null}, "2206.13284": {"publish_time": "2022-06-27", "title": "Which one is more toxic? Findings from Jigsaw Rate Severity of Toxic Comments", "author": "Millon Madhur Das et.al.", "abstract": "The proliferation of online hate speech has necessitated the creation of algorithms which can detect toxicity. Most of the past research focuses on this detection as a classification task, but assigning an absolute toxicity label is often tricky. Hence, few of the past works transform the same task into a regression. This paper shows the comparative evaluation of different transformers and traditional machine learning models on a recently released toxicity severity measurement dataset by Jigsaw. We further demonstrate the issues with the model predictions using explainability analysis.", "paper_url": "http://arxiv.org/abs/2206.13284v1", "pdf_url": "http://arxiv.org/pdf/2206.13284v1", "repo_url": null}, "2206.14181": {"publish_time": "2022-06-28", "title": "The NLP Sandbox: an efficient model-to-data system to enable federated and unbiased evaluation of clinical NLP models", "author": "Yao Yan et.al.", "abstract": "Objective The evaluation of natural language processing (NLP) models for clinical text de-identification relies on the availability of clinical notes, which is often restricted due to privacy concerns. The NLP Sandbox is an approach for alleviating the lack of data and evaluation frameworks for NLP models by adopting a federated, model-to-data approach. This enables unbiased federated model evaluation without the need for sharing sensitive data from multiple institutions. Materials and Methods We leveraged the Synapse collaborative framework, containerization software, and OpenAPI generator to build the NLP Sandbox (nlpsandbox.io). We evaluated two state-of-the-art NLP de-identification focused annotation models, Philter and NeuroNER, using data from three institutions. We further validated model performance using data from an external validation site. Results We demonstrated the usefulness of the NLP Sandbox through de-identification clinical model evaluation. The external developer was able to incorporate their model into the NLP Sandbox template and provide user experience feedback. Discussion We demonstrated the feasibility of using the NLP Sandbox to conduct a multi-site evaluation of clinical text de-identification models without the sharing of data. Standardized model and data schemas enable smooth model transfer and implementation. To generalize the NLP Sandbox, work is required on the part of data owners and model developers to develop suitable and standardized schemas and to adapt their data or model to fit the schemas. Conclusions The NLP Sandbox lowers the barrier to utilizing clinical data for NLP model evaluation and facilitates federated, multi-site, unbiased evaluation of NLP models.", "paper_url": "http://arxiv.org/abs/2206.14181v1", "pdf_url": "http://arxiv.org/pdf/2206.14181v1", "repo_url": null}, "2206.14169": {"publish_time": "2022-06-28", "title": "Creation and Analysis of an International Corpus of Privacy Laws", "author": "Sonu Gupta et.al.", "abstract": "The landscape of privacy laws and regulations around the world is complex and ever-changing. National and super-national laws, agreements, decrees, and other government-issued rules form a patchwork that companies must follow to operate internationally. To examine the status and evolution of this patchwork, we introduce the Government Privacy Instructions Corpus, or GPI Corpus, of 1,043 privacy laws, regulations, and guidelines, covering 182 jurisdictions. This corpus enables a large-scale quantitative and qualitative examination of legal foci on privacy. We examine the temporal distribution of when GPIs were created and illustrate the dramatic increase in privacy legislation over the past 50 years, although a finer-grained examination reveals that the rate of increase varies depending on the personal data types that GPIs address. Our exploration also demonstrates that most privacy laws respectively address relatively few personal data types, showing that comprehensive privacy legislation remains rare. Additionally, topic modeling results show the prevalence of common themes in GPIs, such as finance, healthcare, and telecommunications. Finally, we release the corpus to the research community to promote further study.", "paper_url": "http://arxiv.org/abs/2206.14169v1", "pdf_url": "http://arxiv.org/pdf/2206.14169v1", "repo_url": null}, "2206.14125": {"publish_time": "2022-06-28", "title": "Simplifying Dataflow Dialogue Design", "author": "Joram Meron et.al.", "abstract": "In \\citep{andreas2020task-oriented}, a dataflow (DF) based dialogue system was introduced, showing clear advantages compared to many commonly used current systems. This was accompanied by the release of SMCalFlow, a practically relevant, manually annotated dataset, more detailed and much larger than any comparable dialogue dataset. Despite these remarkable contributions, the community has not shown further interest in this direction. What are the reasons for this lack of interest? And how can the community be encouraged to engage in research in this direction?   One explanation may be the perception that this approach is too complex - both the the annotation and the system. This paper argues that this perception is wrong: 1) Suggestions for a simplified format for the annotation of the dataset are presented, 2) An implementation of the DF execution engine is released\\footnote{https://github.com/telepathylabsai/OpenDF}, which can serve as a sandbox allowing researchers to easily implement, and experiment with, new DF dialogue designs. The hope is that these contributions will help engage more practitioners in exploring new ideas and designs for DF based dialogue systems.", "paper_url": "http://arxiv.org/abs/2206.14125v1", "pdf_url": "http://arxiv.org/pdf/2206.14125v1", "repo_url": "https://github.com/telepathylabsai/OpenDF"}, "2206.14089": {"publish_time": "2022-06-28", "title": "Placing (Historical) Facts on a Timeline: A Classification cum Coref Resolution Approach", "author": "Sayantan Adak et.al.", "abstract": "A timeline provides one of the most effective ways to visualize the important historical facts that occurred over a period of time, presenting the insights that may not be so apparent from reading the equivalent information in textual form. By leveraging generative adversarial learning for important sentence classification and by assimilating knowledge based tags for improving the performance of event coreference resolution we introduce a two staged system for event timeline generation from multiple (historical) text documents. We demonstrate our results on two manually annotated historical text documents. Our results can be extremely helpful for historians, in advancing research in history and in understanding the socio-political landscape of a country as reflected in the writings of famous personas.", "paper_url": "http://arxiv.org/abs/2206.14089v1", "pdf_url": "http://arxiv.org/pdf/2206.14089v1", "repo_url": null}, "2206.14055": {"publish_time": "2022-06-28", "title": "Towards Lexical Gender Inference: A Scalable Methodology using Online Databases", "author": "Marion Bartl et.al.", "abstract": "This paper presents a new method for automatically detecting words with lexical gender in large-scale language datasets. Currently, the evaluation of gender bias in natural language processing relies on manually compiled lexicons of gendered expressions, such as pronouns ('he', 'she', etc.) and nouns with lexical gender ('mother', 'boyfriend', 'policewoman', etc.). However, manual compilation of such lists can lead to static information if they are not periodically updated and often involve value judgments by individual annotators and researchers. Moreover, terms not included in the list fall out of the range of analysis. To address these issues, we devised a scalable, dictionary-based method to automatically detect lexical gender that can provide a dynamic, up-to-date analysis with high coverage. Our approach reaches over 80% accuracy in determining the lexical gender of nouns retrieved randomly from a Wikipedia sample and when testing on a list of gendered words used in previous research.", "paper_url": "http://arxiv.org/abs/2206.14055v1", "pdf_url": "http://arxiv.org/pdf/2206.14055v1", "repo_url": null}, "2206.14796": {"publish_time": "2022-06-29", "title": "On the Robustness of Dialogue History Representation in Conversational Question Answering: A Comprehensive Study and a New Prompt-based Method", "author": "Zorik Gekhman et.al.", "abstract": "Most works on modeling the conversation history in Conversational Question Answering (CQA) report a single main result on a common CQA benchmark. While existing models show impressive results on CQA leaderboards, it remains unclear whether they are robust to shifts in setting (sometimes to more realistic ones), training data size (e.g. from large to small sets) and domain. In this work, we design and conduct the first large-scale robustness study of history modeling approaches for CQA. We find that high benchmark scores do not necessarily translate to strong robustness, and that various methods can perform extremely differently under different settings. Equipped with the insights from our study, we design a novel prompt-based history modeling approach, and demonstrate its strong robustness across various settings. Our approach is inspired by existing methods that highlight historic answers in the passage. However, instead of highlighting by modifying the passage token embeddings, we add textual prompts directly in the passage text. Our approach is simple, easy-to-plug into practically any model, and highly effective, thus we recommend it as a starting point for future model developers. We also hope that our study and insights will raise awareness to the importance of robustness-focused evaluation, in addition to obtaining high leaderboard scores, leading to better CQA systems.", "paper_url": "http://arxiv.org/abs/2206.14796v1", "pdf_url": "http://arxiv.org/pdf/2206.14796v1", "repo_url": "https://github.com/zorikg/marcqap"}, "2206.14774": {"publish_time": "2022-06-29", "title": "TweetNLP: Cutting-Edge Natural Language Processing for Social Media", "author": "Jose Camacho-Collados et.al.", "abstract": "In this paper we present TweetNLP, an integrated platform for Natural Language Processing (NLP) in social media. TweetNLP supports a diverse set of NLP tasks, including generic focus areas such as sentiment analysis and named entity recognition, as well as social media-specific tasks such as emoji prediction and offensive language identification. Task-specific systems are powered by reasonably-sized Transformer-based language models specialized on social media text (in particular, Twitter) which can be run without the need for dedicated hardware or cloud services. The main contributions of TweetNLP are: (1) an integrated Python library for a modern toolkit supporting social media analysis using our various task-specific models adapted to the social domain; (2) an interactive online demo for codeless experimentation using our models; and (3) a tutorial covering a wide variety of typical social media applications.", "paper_url": "http://arxiv.org/abs/2206.14774v1", "pdf_url": "http://arxiv.org/pdf/2206.14774v1", "repo_url": null}, "2206.14729": {"publish_time": "2022-06-29", "title": "longhorns at DADC 2022: How many linguists does it take to fool a Question Answering model? A systematic approach to adversarial attacks", "author": "Venelin Kovatchev et.al.", "abstract": "Developing methods to adversarially challenge NLP systems is a promising avenue for improving both model performance and interpretability. Here, we describe the approach of the team \"longhorns\" on Task 1 of the The First Workshop on Dynamic Adversarial Data Collection (DADC), which asked teams to manually fool a model on an Extractive Question Answering task. Our team finished first, with a model error rate of 62%. We advocate for a systematic, linguistically informed approach to formulating adversarial questions, and we describe the results of our pilot experiments, as well as our official submission.", "paper_url": "http://arxiv.org/abs/2206.14729v1", "pdf_url": "http://arxiv.org/pdf/2206.14729v1", "repo_url": null}, "2206.14719": {"publish_time": "2022-06-29", "title": "Trial2Vec: Zero-Shot Clinical Trial Document Similarity Search using Self-Supervision", "author": "Zifeng Wang et.al.", "abstract": "Clinical trials are essential for drug development but are extremely expensive and time-consuming to conduct. It is beneficial to study similar historical trials when designing a clinical trial. However, lengthy trial documents and lack of labeled data make trial similarity search difficult. We propose a zero-shot clinical trial retrieval method, Trial2Vec, which learns through self-supervision without annotating similar clinical trials. Specifically, the meta-structure of trial documents (e.g., title, eligibility criteria, target disease) along with clinical knowledge (e.g., UMLS knowledge base https://www.nlm.nih.gov/research/umls/index.html) are leveraged to automatically generate contrastive samples. Besides, Trial2Vec encodes trial documents considering meta-structure thus producing compact embeddings aggregating multi-aspect information from the whole document. We show that our method yields medically interpretable embeddings by visualization and it gets a 15% average improvement over the best baselines on precision/recall for trial retrieval, which is evaluated on our labeled 1600 trial pairs. In addition, we prove the pre-trained embeddings benefit the downstream trial outcome prediction task over 240k trials.", "paper_url": "http://arxiv.org/abs/2206.14719v1", "pdf_url": "http://arxiv.org/pdf/2206.14719v1", "repo_url": null}, "2206.14716": {"publish_time": "2022-06-29", "title": "Improving Deliberation by Text-Only and Semi-Supervised Training", "author": "Ke Hu et.al.", "abstract": "Text-only and semi-supervised training based on audio-only data has gained popularity recently due to the wide availability of unlabeled text and speech data. In this work, we propose incorporating text-only and semi-supervised training into an attention-based deliberation model. By incorporating text-only data in training a bidirectional encoder representation from transformer (BERT) for the deliberation text encoder, and large-scale text-to-speech and audio-only utterances using joint acoustic and text decoder (JATD) and semi-supervised training, we achieved 4%-12% WER reduction for various tasks compared to the baseline deliberation. Compared to a state-of-the-art language model (LM) rescoring method, the deliberation model reduces the Google Voice Search WER by 11% relative. We show that the deliberation model also achieves a positive human side-by-side evaluation compared to the state-of-the-art LM rescorer with reasonable endpointer latencies.", "paper_url": "http://arxiv.org/abs/2206.14716v1", "pdf_url": "http://arxiv.org/pdf/2206.14716v1", "repo_url": null}, "2206.15474": {"publish_time": "2022-06-30", "title": "Forecasting Future World Events with Neural Networks", "author": "Andy Zou et.al.", "abstract": "Forecasting future world events is a challenging but valuable task. Forecasts of climate, geopolitical conflict, pandemics and economic indicators help shape policy and decision making. In these domains, the judgment of expert humans contributes to the best forecasts. Given advances in language modeling, can these forecasts be automated? To this end, we introduce Autocast, a dataset containing thousands of forecasting questions and an accompanying news corpus. Questions are taken from forecasting tournaments, ensuring high quality, real-world importance, and diversity. The news corpus is organized by date, allowing us to precisely simulate the conditions under which humans made past forecasts (avoiding leakage from the future). Motivated by the difficulty of forecasting numbers across orders of magnitude (e.g. global cases of COVID-19 in 2022), we also curate IntervalQA, a dataset of numerical questions and metrics for calibration. We test language models on our forecasting task and find that performance is far below a human expert baseline. However, performance improves with increased model size and incorporation of relevant information from the news corpus. In sum, Autocast poses a novel challenge for large language models and improved performance could bring large practical benefits.", "paper_url": "http://arxiv.org/abs/2206.15474v1", "pdf_url": "http://arxiv.org/pdf/2206.15474v1", "repo_url": "https://github.com/andyzoujm/autocast"}, "2206.15462": {"publish_time": "2022-06-30", "title": "Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations", "author": "Ziyan Yang et.al.", "abstract": "We propose a margin-based loss for vision-language model pretraining that encourages gradient-based explanations that are consistent with region-level annotations. We refer to this objective as Attention Mask Consistency (AMC) and demonstrate that it produces superior visual grounding performance compared to models that rely instead on region-level annotations for explicitly training an object detector such as Faster R-CNN. AMC works by encouraging gradient-based explanation masks that focus their attention scores mostly within annotated regions of interest for images that contain such annotations. Particularly, a model trained with AMC on top of standard vision-language modeling objectives obtains a state-of-the-art accuracy of 86.59% in the Flickr30k visual grounding benchmark, an absolute improvement of 5.48% when compared to the best previous model. Our approach also performs exceedingly well on established benchmarks for referring expression comprehension and offers the added benefit by design of gradient-based explanations that better align with human annotations.", "paper_url": "http://arxiv.org/abs/2206.15462v1", "pdf_url": "http://arxiv.org/pdf/2206.15462v1", "repo_url": null}, "2206.15455": {"publish_time": "2022-06-30", "title": "Hate Speech Criteria: A Modular Approach to Task-Specific Hate Speech Definitions", "author": "Urja Khurana et.al.", "abstract": "\\textbf{Offensive Content Warning}: This paper contains offensive language only for providing examples that clarify this research and do not reflect the authors' opinions. Please be aware that these examples are offensive and may cause you distress.   The subjectivity of recognizing \\textit{hate speech} makes it a complex task. This is also reflected by different and incomplete definitions in NLP. We present \\textit{hate speech} criteria, developed with perspectives from law and social science, with the aim of helping researchers create more precise definitions and annotation guidelines on five aspects: (1) target groups, (2) dominance, (3) perpetrator characteristics, (4) type of negative group reference, and the (5) type of potential consequences/effects. Definitions can be structured so that they cover a more broad or more narrow phenomenon. As such, conscious choices can be made on specifying criteria or leaving them open. We argue that the goal and exact task developers have in mind should determine how the scope of \\textit{hate speech} is defined. We provide an overview of the properties of English datasets from \\url{hatespeechdata.com} that may help select the most suitable dataset for a specific scenario.", "paper_url": "http://arxiv.org/abs/2206.15455v1", "pdf_url": "http://arxiv.org/pdf/2206.15455v1", "repo_url": null}, "2206.15381": {"publish_time": "2022-06-30", "title": "Visual grounding of abstract and concrete words: A response to G\u00fcnther et al. (2020)", "author": "Hassan Shahmohammadi et.al.", "abstract": "Current computational models capturing words' meaning mostly rely on textual corpora. While these approaches have been successful over the last decades, their lack of grounding in the real world is still an ongoing problem. In this paper, we focus on visual grounding of word embeddings and target two important questions. First, how can language benefit from vision in the process of visual grounding? And second, is there a link between visual grounding and abstract concepts? We investigate these questions by proposing a simple yet effective approach where language benefits from vision specifically with respect to the modeling of both concrete and abstract words. Our model aligns word embeddings with their corresponding visual representation without deteriorating the knowledge captured by textual distributional information. We apply our model to a behavioral experiment reported by G\\\"unther et al. (2020), which addresses the plausibility of having visual mental representations for abstract words. Our evaluation results show that: (1) It is possible to predict human behaviour to a large degree using purely textual embeddings. (2) Our grounded embeddings model human behavior better compared to their textual counterparts. (3) Abstract concepts benefit from visual grounding implicitly through their connections to concrete concepts, rather than from having corresponding visual representations.", "paper_url": "http://arxiv.org/abs/2206.15381v1", "pdf_url": "http://arxiv.org/pdf/2206.15381v1", "repo_url": null}, "2206.15359": {"publish_time": "2022-06-30", "title": "Two-Stage Classifier for COVID-19 Misinformation Detection Using BERT: a Study on Indonesian Tweets", "author": "Douglas Raevan Faisal et.al.", "abstract": "The COVID-19 pandemic has caused globally significant impacts since the beginning of 2020. This brought a lot of confusion to society, especially due to the spread of misinformation through social media. Although there were already several studies related to the detection of misinformation in social media data, most studies focused on the English dataset. Research on COVID-19 misinformation detection in Indonesia is still scarce. Therefore, through this research, we collect and annotate datasets for Indonesian and build prediction models for detecting COVID-19 misinformation by considering the tweet's relevance. The dataset construction is carried out by a team of annotators who labeled the relevance and misinformation of the tweet data. In this study, we propose the two-stage classifier model using IndoBERT pre-trained language model for the Tweet misinformation detection task. We also experiment with several other baseline models for text classification. The experimental results show that the combination of the BERT sequence classifier for relevance prediction and Bi-LSTM for misinformation detection outperformed other machine learning models with an accuracy of 87.02%. Overall, the BERT utilization contributes to the higher performance of most prediction models. We release a high-quality COVID-19 misinformation Tweet corpus in the Indonesian language, indicated by the high inter-annotator agreement.", "paper_url": "http://arxiv.org/abs/2206.15359v1", "pdf_url": "http://arxiv.org/pdf/2206.15359v1", "repo_url": "https://github.com/douglasraevan/covid19-indonesian-misinformation-tweets"}, "2207.00560": {"publish_time": "2022-07-01", "title": "Is neural language acquisition similar to natural? A chronological probing study", "author": "Ekaterina Voloshina et.al.", "abstract": "The probing methodology allows one to obtain a partial representation of linguistic phenomena stored in the inner layers of the neural network, using external classifiers and statistical analysis. Pre-trained transformer-based language models are widely used both for natural language understanding (NLU) and natural language generation (NLG) tasks making them most commonly used for downstream applications. However, little analysis was carried out, whether the models were pre-trained enough or contained knowledge correlated with linguistic theory. We are presenting the chronological probing study of transformer English models such as MultiBERT and T5. We sequentially compare the information about the language learned by the models in the process of training on corpora. The results show that 1) linguistic information is acquired in the early stages of training 2) both language models demonstrate capabilities to capture various features from various levels of language, including morphology, syntax, and even discourse, while they also can inconsistently fail on tasks that are perceived as easy. We also introduce the open-source framework for chronological probing research, compatible with other transformer-based models. https://github.com/EkaterinaVoloshina/chronological_probing", "paper_url": "http://arxiv.org/abs/2207.00560v1", "pdf_url": "http://arxiv.org/pdf/2207.00560v1", "repo_url": "https://github.com/ekaterinavoloshina/chronological_probing"}, "2207.00555": {"publish_time": "2022-07-01", "title": "FitHuBERT: Going Thinner and Deeper for Knowledge Distillation of Speech Self-Supervised Learning", "author": "Yeonghyeon Lee et.al.", "abstract": "Large-scale speech self-supervised learning (SSL) has emerged to the main field of speech processing, however, the problem of computational cost arising from its vast size makes a high entry barrier to academia. In addition, existing distillation techniques of speech SSL models compress the model by reducing layers, which induces performance degradation in linguistic pattern recognition tasks such as phoneme recognition (PR). In this paper, we propose FitHuBERT, which makes thinner in dimension throughout almost all model components and deeper in layer compared to prior speech SSL distillation works. Moreover, we employ a time-reduction layer to speed up inference time and propose a method of hint-based distillation for less performance degradation. Our method reduces the model to 23.8% in size and 35.9% in inference time compared to HuBERT. Also, we achieve 12.1% word error rate and 13.3% phoneme error rate on the SUPERB benchmark which is superior than prior work.", "paper_url": "http://arxiv.org/abs/2207.00555v1", "pdf_url": "http://arxiv.org/pdf/2207.00555v1", "repo_url": "https://github.com/glory20h/FitHuBERT"}, "2207.00552": {"publish_time": "2022-07-01", "title": "Reduce Indonesian Vocabularies with an Indonesian Sub-word Separator", "author": "Mukhlis Amien et.al.", "abstract": "Indonesian is an agglutinative language since it has a compounding process of word-formation. Therefore, the translation model of this language requires a mechanism that is even lower than the word level, referred to as the sub-word level. This compounding process leads to a rare word problem since the number of vocabulary explodes. We propose a strategy to address the unique word problem of the neural machine translation (NMT) system, which uses Indonesian as a pair language. Our approach uses a rule-based method to transform a word into its roots and accompanied affixes to retain its meaning and context. Using a rule-based algorithm has more advantages: it does not require corpus data but only applies the standard Indonesian rules. Our experiments confirm that this method is practical. It reduces the number of vocabulary significantly up to 57\\%, and on the English to Indonesian translation, this strategy provides an improvement of up to 5 BLEU points over a similar NMT system that does not use this technique.", "paper_url": "http://arxiv.org/abs/2207.00552v1", "pdf_url": "http://arxiv.org/pdf/2207.00552v1", "repo_url": null}, "2207.00489": {"publish_time": "2022-07-01", "title": "Panning for gold: Lessons learned from the platform-agnostic automated detection of political content in textual data", "author": "Mykola Makhortykh et.al.", "abstract": "The growing availability of data about online information behaviour enables new possibilities for political communication research. However, the volume and variety of these data makes them difficult to analyse and prompts the need for developing automated content approaches relying on a broad range of natural language processing techniques (e.g. machine learning- or neural network-based ones). In this paper, we discuss how these techniques can be used to detect political content across different platforms. Using three validation datasets, which include a variety of political and non-political textual documents from online platforms, we systematically compare the performance of three groups of detection techniques relying on dictionaries, supervised machine learning, or neural networks. We also examine the impact of different modes of data preprocessing (e.g. stemming and stopword removal) on the low-cost implementations of these techniques using a large set (n = 66) of detection models. Our results show the limited impact of preprocessing on model performance, with the best results for less noisy data being achieved by neural network- and machine-learning-based models, in contrast to the more robust performance of dictionary-based models on noisy data.", "paper_url": "http://arxiv.org/abs/2207.00489v1", "pdf_url": "http://arxiv.org/pdf/2207.00489v1", "repo_url": null}, "2207.00473": {"publish_time": "2022-07-01", "title": "Assessing the Effects of Hyperparameters on Knowledge Graph Embedding Quality", "author": "Oliver Lloyd et.al.", "abstract": "Embedding knowledge graphs into low-dimensional spaces is a popular method for applying approaches, such as link prediction or node classification, to these databases. This embedding process is very costly in terms of both computational time and space. Part of the reason for this is the optimisation of hyperparameters, which involves repeatedly sampling, by random, guided, or brute-force selection, from a large hyperparameter space and testing the resulting embeddings for their quality. However, not all hyperparameters in this search space will be equally important. In fact, with prior knowledge of the relative importance of the hyperparameters, some could be eliminated from the search altogether without significantly impacting the overall quality of the outputted embeddings. To this end, we ran a Sobol sensitivity analysis to evaluate the effects of tuning different hyperparameters on the variance of embedding quality. This was achieved by performing thousands of embedding trials, each time measuring the quality of embeddings produced by different hyperparameter configurations. We regressed the embedding quality on those hyperparameter configurations, using this model to generate Sobol sensitivity indices for each of the hyperparameters. By evaluating the correlation between Sobol indices, we find substantial variability in the hyperparameter sensitivities between knowledge graphs with differing dataset characteristics as the probable cause of these inconsistencies. As an additional contribution of this work we identify several relations in the UMLS knowledge graph that may cause data leakage via inverse relations, and derive and present UMLS-43, a leakage-robust variant of that graph.", "paper_url": "http://arxiv.org/abs/2207.00473v1", "pdf_url": "http://arxiv.org/pdf/2207.00473v1", "repo_url": null}, "2207.01547": {"publish_time": "2022-07-04", "title": "Unify and Conquer: How Phonetic Feature Representation Affects Polyglot Text-To-Speech (TTS)", "author": "Ariadna Sanchez et.al.", "abstract": "An essential design decision for multilingual Neural Text-To-Speech (NTTS) systems is how to represent input linguistic features within the model. Looking at the wide variety of approaches in the literature, two main paradigms emerge, unified and separate representations. The former uses a shared set of phonetic tokens across languages, whereas the latter uses unique phonetic tokens for each language. In this paper, we conduct a comprehensive study comparing multilingual NTTS systems models trained with both representations. Our results reveal that the unified approach consistently achieves better cross-lingual synthesis with respect to both naturalness and accent. Separate representations tend to have an order of magnitude more tokens than unified ones, which may affect model capacity. For this reason, we carry out an ablation study to understand the interaction of the representation type with the size of the token embedding. We find that the difference between the two paradigms only emerges above a certain threshold embedding size. This study provides strong evidence that unified representations should be the preferred paradigm when building multilingual NTTS systems.", "paper_url": "http://arxiv.org/abs/2207.01547v1", "pdf_url": "http://arxiv.org/pdf/2207.01547v1", "repo_url": null}, "2207.01528": {"publish_time": "2022-07-04", "title": "VEM$^2$L: A Plug-and-play Framework for Fusing Text and Structure Knowledge on Sparse Knowledge Graph Completion", "author": "Tao He et.al.", "abstract": "Knowledge Graph Completion has been widely studied recently to complete missing elements within triples via mainly modeling graph structural features, but performs sensitive to the sparsity of graph structure. Relevant texts like entity names and descriptions, acting as another expression form for Knowledge Graphs (KGs), are expected to solve this challenge. Several methods have been proposed to utilize both structure and text messages with two encoders, but only achieved limited improvements due to the failure to balance weights between them. And reserving both structural and textual encoders during inference also suffers from heavily overwhelmed parameters. Motivated by Knowledge Distillation, we view knowledge as mappings from input to output probabilities and propose a plug-and-play framework VEM2L over sparse KGs to fuse knowledge extracted from text and structure messages into a unity. Specifically, we partition knowledge acquired by models into two nonoverlapping parts: one part is relevant to the fitting capacity upon training triples, which could be fused by motivating two encoders to learn from each other on training sets; the other reflects the generalization ability upon unobserved queries. And correspondingly, we propose a new fusion strategy proved by Variational EM algorithm to fuse the generalization ability of models, during which we also apply graph densification operations to further alleviate the sparse graph problem. By combining these two fusion methods, we propose VEM2L framework finally. Both detailed theoretical evidence, as well as quantitative and qualitative experiments, demonstrates the effectiveness and efficiency of our proposed framework.", "paper_url": "http://arxiv.org/abs/2207.01528v1", "pdf_url": "http://arxiv.org/pdf/2207.01528v1", "repo_url": null}, "2207.01507": {"publish_time": "2022-07-04", "title": "Mix and Match: An Empirical Study on Training Corpus Composition for Polyglot Text-To-Speech (TTS)", "author": "Ziyao Zhang et.al.", "abstract": "Training multilingual Neural Text-To-Speech (NTTS) models using only monolingual corpora has emerged as a popular way for building voice cloning based Polyglot NTTS systems. In order to train these models, it is essential to understand how the composition of the training corpora affects the quality of multilingual speech synthesis. In this context, it is common to hear questions such as \"Would including more Spanish data help my Italian synthesis, given the closeness of both languages?\". Unfortunately, we found existing literature on the topic lacking in completeness in this regard. In the present work, we conduct an extensive ablation study aimed at understanding how various factors of the training corpora, such as language family affiliation, gender composition, and the number of speakers, contribute to the quality of Polyglot synthesis. Our findings include the observation that female speaker data are preferred in most scenarios, and that it is not always beneficial to have more speakers from the target language variant in the training corpus. The findings herein are informative for the process of data procurement and corpora building.", "paper_url": "http://arxiv.org/abs/2207.01507v1", "pdf_url": "http://arxiv.org/pdf/2207.01507v1", "repo_url": null}, "2207.01454": {"publish_time": "2022-07-04", "title": "GlowVC: Mel-spectrogram space disentangling model for language-independent text-free voice conversion", "author": "Magdalena Proszewska et.al.", "abstract": "In this paper, we propose GlowVC: a multilingual multi-speaker flow-based model for language-independent text-free voice conversion. We build on Glow-TTS, which provides an architecture that enables use of linguistic features during training without the necessity of using them for VC inference. We consider two versions of our model: GlowVC-conditional and GlowVC-explicit. GlowVC-conditional models the distribution of mel-spectrograms with speaker-conditioned flow and disentangles the mel-spectrogram space into content- and pitch-relevant dimensions, while GlowVC-explicit models the explicit distribution with unconditioned flow and disentangles said space into content-, pitch- and speaker-relevant dimensions. We evaluate our models in terms of intelligibility, speaker similarity and naturalness for intra- and cross-lingual conversion in seen and unseen languages. GlowVC models greatly outperform AutoVC baseline in terms of intelligibility, while achieving just as high speaker similarity in intra-lingual VC, and slightly worse in the cross-lingual setting. Moreover, we demonstrate that GlowVC-explicit surpasses both GlowVC-conditional and AutoVC in terms of naturalness.", "paper_url": "http://arxiv.org/abs/2207.01454v1", "pdf_url": "http://arxiv.org/pdf/2207.01454v1", "repo_url": null}, "2207.01450": {"publish_time": "2022-07-04", "title": "Discourse-Aware Graph Networks for Textual Logical Reasoning", "author": "Yinya Huang et.al.", "abstract": "Textual logical reasoning, especially question answering (QA) tasks with logical reasoning, requires awareness of particular logical structures. The passage-level logical relations represent entailment or contradiction between propositional units (e.g., a concluding sentence). However, such structures are unexplored as current QA systems focus on entity-based relations. In this work, we propose logic structural-constraint modeling to solve the logical reasoning QA and introduce discourse-aware graph networks (DAGNs). The networks perform two procedures: (1) logic graph construction that leverages in-line discourse connectives as well as generic logic theories, (2) logic representation learning by graph networks that produces structural logic features. This pipeline is applied to a general encoder, whose fundamental features are joined with the high-level logic features for answer prediction. Experiments on three textual logical reasoning datasets demonstrate the reasonability of the logical structures built in DAGNs and the effectiveness of the learned logic features. Moreover, zero-shot transfer results show the features' generality to unseen logical texts.", "paper_url": "http://arxiv.org/abs/2207.01450v1", "pdf_url": "http://arxiv.org/pdf/2207.01450v1", "repo_url": null}, "2207.02185": {"publish_time": "2022-07-05", "title": "CLEAR: Improving Vision-Language Navigation with Cross-Lingual, Environment-Agnostic Representations", "author": "Jialu Li et.al.", "abstract": "Vision-and-Language Navigation (VLN) tasks require an agent to navigate through the environment based on language instructions. In this paper, we aim to solve two key challenges in this task: utilizing multilingual instructions for improved instruction-path grounding and navigating through new environments that are unseen during training. To address these challenges, we propose CLEAR: Cross-Lingual and Environment-Agnostic Representations. First, our agent learns a shared and visually-aligned cross-lingual language representation for the three languages (English, Hindi and Telugu) in the Room-Across-Room dataset. Our language representation learning is guided by text pairs that are aligned by visual information. Second, our agent learns an environment-agnostic visual representation by maximizing the similarity between semantically-aligned image pairs (with constraints on object-matching) from different environments. Our environment agnostic visual representation can mitigate the environment bias induced by low-level visual information. Empirically, on the Room-Across-Room dataset, we show that our multilingual agent gets large improvements in all metrics over the strong baseline model when generalizing to unseen environments with the cross-lingual language representation and the environment-agnostic visual representation. Furthermore, we show that our learned language and visual representations can be successfully transferred to the Room-to-Room and Cooperative Vision-and-Dialogue Navigation task, and present detailed qualitative and quantitative generalization and grounding analysis. Our code is available at https://github.com/jialuli-luka/CLEAR", "paper_url": "http://arxiv.org/abs/2207.02185v1", "pdf_url": "http://arxiv.org/pdf/2207.02185v1", "repo_url": "https://github.com/jialuli-luka/clear"}, "2207.02160": {"publish_time": "2022-07-05", "title": "A Comprehensive Review of Visual-Textual Sentiment Analysis from Social Media Networks", "author": "Israa Khalaf Salman Al-Tameemi et.al.", "abstract": "Social media networks have become a significant aspect of people's lives, serving as a platform for their ideas, opinions and emotions. Consequently, automated sentiment analysis (SA) is critical for recognising people's feelings in ways that other information sources cannot. The analysis of these feelings revealed various applications, including brand evaluations, YouTube film reviews and healthcare applications. As social media continues to develop, people post a massive amount of information in different forms, including text, photos, audio and video. Thus, traditional SA algorithms have become limited, as they do not consider the expressiveness of other modalities. By including such characteristics from various material sources, these multimodal data streams provide new opportunities for optimising the expected results beyond text-based SA. Our study focuses on the forefront field of multimodal SA, which examines visual and textual data posted on social media networks. Many people are more likely to utilise this information to express themselves on these platforms. To serve as a resource for academics in this rapidly growing field, we introduce a comprehensive overview of textual and visual SA, including data pre-processing, feature extraction techniques, sentiment benchmark datasets, and the efficacy of multiple classification methodologies suited to each field. We also provide a brief introduction of the most frequently utilised data fusion strategies and a summary of existing research on visual-textual SA. Finally, we highlight the most significant challenges and investigate several important sentiment applications.", "paper_url": "http://arxiv.org/abs/2207.02160v1", "pdf_url": "http://arxiv.org/pdf/2207.02160v1", "repo_url": null}, "2207.02104": {"publish_time": "2022-07-05", "title": "A cross-corpus study on speech emotion recognition", "author": "Rosanna Milner et.al.", "abstract": "For speech emotion datasets, it has been difficult to acquire large quantities of reliable data and acted emotions may be over the top compared to less expressive emotions displayed in everyday life. Lately, larger datasets with natural emotions have been created. Instead of ignoring smaller, acted datasets, this study investigates whether information learnt from acted emotions is useful for detecting natural emotions. Cross-corpus research has mostly considered cross-lingual and even cross-age datasets, and difficulties arise from different methods of annotating emotions causing a drop in performance. To be consistent, four adult English datasets covering acted, elicited and natural emotions are considered. A state-of-the-art model is proposed to accurately investigate the degradation of performance. The system involves a bi-directional LSTM with an attention mechanism to classify emotions across datasets. Experiments study the effects of training models in a cross-corpus and multi-domain fashion and results show the transfer of information is not successful. Out-of-domain models, followed by adapting to the missing dataset, and domain adversarial training (DAT) are shown to be more suitable to generalising to emotions across datasets. This shows positive information transfer from acted datasets to those with more natural emotions and the benefits from training on different corpora.", "paper_url": "http://arxiv.org/abs/2207.02104v1", "pdf_url": "http://arxiv.org/pdf/2207.02104v1", "repo_url": null}, "2207.02098": {"publish_time": "2022-07-05", "title": "Neural Networks and the Chomsky Hierarchy", "author": "Gr\u00e9goire Del\u00e9tang et.al.", "abstract": "Reliable generalization lies at the heart of safe ML and AI. However, understanding when and how neural networks generalize remains one of the most important unsolved problems in the field. In this work, we conduct an extensive empirical study (2200 models, 16 tasks) to investigate whether insights from the theory of computation can predict the limits of neural network generalization in practice. We demonstrate that grouping tasks according to the Chomsky hierarchy allows us to forecast whether certain architectures will be able to generalize to out-of-distribution inputs. This includes negative results where even extensive amounts of data and training time never led to any non-trivial generalization, despite models having sufficient capacity to perfectly fit the training data. Our results show that, for our subset of tasks, RNNs and Transformers fail to generalize on non-regular tasks, LSTMs can solve regular and counter-language tasks, and only networks augmented with structured memory (such as a stack or memory tape) can successfully generalize on context-free and context-sensitive tasks.", "paper_url": "http://arxiv.org/abs/2207.02098v1", "pdf_url": "http://arxiv.org/pdf/2207.02098v1", "repo_url": "https://github.com/deepmind/neural_networks_chomsky_hierarchy"}, "2207.02008": {"publish_time": "2022-07-05", "title": "Block-SCL: Blocking Matters for Supervised Contrastive Learning in Product Matching", "author": "Mario Almagro et.al.", "abstract": "Product matching is a fundamental step for the global understanding of consumer behavior in e-commerce. In practice, product matching refers to the task of deciding if two product offers from different data sources (e.g. retailers) represent the same product. Standard pipelines use a previous stage called blocking, where for a given product offer a set of potential matching candidates are retrieved based on similar characteristics (e.g. same brand, category, flavor, etc.). From these similar product candidates, those that are not a match can be considered hard negatives. We present Block-SCL, a strategy that uses the blocking output to make the most of Supervised Contrastive Learning (SCL). Concretely, Block-SCL builds enriched batches using the hard-negatives samples obtained in the blocking stage. These batches provide a strong training signal leading the model to learn more meaningful sentence embeddings for product matching. Experimental results in several public datasets demonstrate that Block-SCL achieves state-of-the-art results despite only using short product titles as input, no data augmentation, and a lighter transformer backbone than competing methods.", "paper_url": "http://arxiv.org/abs/2207.02008v1", "pdf_url": "http://arxiv.org/pdf/2207.02008v1", "repo_url": null}, "2207.02824": {"publish_time": "2022-07-06", "title": "Strong Heuristics for Named Entity Linking", "author": "Marko \u010culjak et.al.", "abstract": "Named entity linking (NEL) in news is a challenging endeavour due to the frequency of unseen and emerging entities, which necessitates the use of unsupervised or zero-shot methods. However, such methods tend to come with caveats, such as no integration of suitable knowledge bases (like Wikidata) for emerging entities, a lack of scalability, and poor interpretability. Here, we consider person disambiguation in Quotebank, a massive corpus of speaker-attributed quotations from the news, and investigate the suitability of intuitive, lightweight, and scalable heuristics for NEL in web-scale corpora. Our best performing heuristic disambiguates 94% and 63% of the mentions on Quotebank and the AIDA-CoNLL benchmark, respectively. Additionally, the proposed heuristics compare favourably to the state-of-the-art unsupervised and zero-shot methods, Eigenthemes and mGENRE, respectively, thereby serving as strong baselines for unsupervised and zero-shot entity linking.", "paper_url": "http://arxiv.org/abs/2207.02824v1", "pdf_url": "http://arxiv.org/pdf/2207.02824v1", "repo_url": "https://github.com/epfl-dlab/nelight"}, "2207.02802": {"publish_time": "2022-07-06", "title": "Rethinking the Value of Gazetteer in Chinese Named Entity Recognition", "author": "Qianglong Chen et.al.", "abstract": "Gazetteer is widely used in Chinese named entity recognition (NER) to enhance span boundary detection and type classification. However, to further understand the generalizability and effectiveness of gazetteers, the NLP community still lacks a systematic analysis of the gazetteer-enhanced NER model. In this paper, we first re-examine the effectiveness several common practices of the gazetteer-enhanced NER models and carry out a series of detailed analysis to evaluate the relationship between the model performance and the gazetteer characteristics, which can guide us to build a more suitable gazetteer. The findings of this paper are as follows: (1) the gazetteer has improved the most situations where the dataset is difficult to learn well for the conventional NER model. (2) the performance of model greatly benefits from the high-quality pre-trained lexeme embeddings. (3) a good gazetteer should cover more entities that can be matched in both the training set and testing set.", "paper_url": "http://arxiv.org/abs/2207.02802v1", "pdf_url": "http://arxiv.org/pdf/2207.02802v1", "repo_url": "https://github.com/knowledgeresearch/kaner"}, "2207.02663": {"publish_time": "2022-07-06", "title": "Kaggle Competition: Cantonese Audio-Visual Speech Recognition for In-car Commands", "author": "Wenliang Dai et.al.", "abstract": "With the rise of deep learning and intelligent vehicles, the smart assistant has become an essential in-car component to facilitate driving and provide extra functionalities. In-car smart assistants should be able to process general as well as car-related commands and perform corresponding actions, which eases driving and improves safety. However, in this research field, most datasets are in major languages, such as English and Chinese. There is a huge data scarcity issue for low-resource languages, hindering the development of research and applications for broader communities. Therefore, it is crucial to have more benchmarks to raise awareness and motivate the research in low-resource languages. To mitigate this problem, we collect a new dataset, namely Cantonese In-car Audio-Visual Speech Recognition (CI-AVSR), for in-car speech recognition in the Cantonese language with video and audio data. Together with it, we propose Cantonese Audio-Visual Speech Recognition for In-car Commands as a new challenge for the community to tackle low-resource speech recognition under in-car scenarios.", "paper_url": "http://arxiv.org/abs/2207.02663v1", "pdf_url": "http://arxiv.org/pdf/2207.02663v1", "repo_url": null}, "2207.02657": {"publish_time": "2022-07-06", "title": "A Challenge on Semi-Supervised and Reinforced Task-Oriented Dialog Systems", "author": "Zhijian Ou et.al.", "abstract": "A challenge on Semi-Supervised and Reinforced Task-Oriented Dialog Systems, Co-located with EMNLP2022 SereTOD Workshop.", "paper_url": "http://arxiv.org/abs/2207.02657v1", "pdf_url": "http://arxiv.org/pdf/2207.02657v1", "repo_url": null}, "2207.02624": {"publish_time": "2022-07-06", "title": "Knowing Earlier what Right Means to You: A Comprehensive VQA Dataset for Grounding Relative Directions via Multi-Task Learning", "author": "Kyra Ahrens et.al.", "abstract": "Spatial reasoning poses a particular challenge for intelligent agents and is at the same time a prerequisite for their successful interaction and communication in the physical world. One such reasoning task is to describe the position of a target object with respect to the intrinsic orientation of some reference object via relative directions. In this paper, we introduce GRiD-A-3D, a novel diagnostic visual question-answering (VQA) dataset based on abstract objects. Our dataset allows for a fine-grained analysis of end-to-end VQA models' capabilities to ground relative directions. At the same time, model training requires considerably fewer computational resources compared with existing datasets, yet yields a comparable or even higher performance. Along with the new dataset, we provide a thorough evaluation based on two widely known end-to-end VQA architectures trained on GRiD-A-3D. We demonstrate that within a few epochs, the subtasks required to reason over relative directions, such as recognizing and locating objects in a scene and estimating their intrinsic orientations, are learned in the order in which relative directions are intuitively processed.", "paper_url": "http://arxiv.org/abs/2207.02624v1", "pdf_url": "http://arxiv.org/pdf/2207.02624v1", "repo_url": null}, "2207.03477": {"publish_time": "2022-07-07", "title": "VeriDark: A Large-Scale Benchmark for Authorship Verification on the Dark Web", "author": "Andrei Manolache et.al.", "abstract": "The DarkWeb represents a hotbed for illicit activity, where users communicate on different market forums in order to exchange goods and services. Law enforcement agencies benefit from forensic tools that perform authorship analysis, in order to identify and profile users based on their textual content. However, authorship analysis has been traditionally studied using corpora featuring literary texts such as fragments from novels or fan fiction, which may not be suitable in a cybercrime context. Moreover, the few works that employ authorship analysis tools for cybercrime prevention usually employ ad-hoc experimental setups and datasets. To address these issues, we release VeriDark: a benchmark comprised of three large scale authorship verification datasets and one authorship identification dataset obtained from user activity from either Dark Web related Reddit communities or popular illicit Dark Web market forums. We evaluate competitive NLP baselines on the three datasets and perform an analysis of the predictions to better understand the limitations of such approaches. We make the datasets and baselines publicly available at https://github.com/bit-ml/VeriDark", "paper_url": "http://arxiv.org/abs/2207.03477v1", "pdf_url": "http://arxiv.org/pdf/2207.03477v1", "repo_url": "https://github.com/bit-ml/veridark"}, "2207.03422": {"publish_time": "2022-07-07", "title": "AsNER -- Annotated Dataset and Baseline for Assamese Named Entity recognition", "author": "Dhrubajyoti Pathak et.al.", "abstract": "We present the AsNER, a named entity annotation dataset for low resource Assamese language with a baseline Assamese NER model. The dataset contains about 99k tokens comprised of text from the speech of the Prime Minister of India and Assamese play. It also contains person names, location names and addresses. The proposed NER dataset is likely to be a significant resource for deep neural based Assamese language processing. We benchmark the dataset by training NER models and evaluating using state-of-the-art architectures for supervised named entity recognition (NER) such as Fasttext, BERT, XLM-R, FLAIR, MuRIL etc. We implement several baseline approaches with state-of-the-art sequence tagging Bi-LSTM-CRF architecture. The highest F1-score among all baselines achieves an accuracy of 80.69% when using MuRIL as a word embedding method. The annotated dataset and the top performing model are made publicly available.", "paper_url": "http://arxiv.org/abs/2207.03422v1", "pdf_url": "http://arxiv.org/pdf/2207.03422v1", "repo_url": null}, "2207.03392": {"publish_time": "2022-07-07", "title": "Bayesian Modeling of Language-Evoked Event-Related Potentials", "author": "Davide Turco et.al.", "abstract": "Bayesian hierarchical models are well-suited to analyzing the often noisy data from electroencephalography experiments in cognitive neuroscience: these models provide an intuitive framework to account for structures and correlations in the data, and they allow a straightforward handling of uncertainty. In a typical neurolinguistic experiment, event-related potentials show only very small effect sizes and frequentist approaches to data analysis fail to establish the significance of some of these effects. Here, we present a Bayesian approach to analyzing event-related potentials using as an example data from an experiment which relates word surprisal and neural response. Our model is able to estimate the effect of word surprisal on most components of the event-related potential and provides a richer description of the data. The Bayesian framework also allows easier comparison between estimates based on surprisal values calculated using different language models.", "paper_url": "http://arxiv.org/abs/2207.03392v1", "pdf_url": "http://arxiv.org/pdf/2207.03392v1", "repo_url": "https://github.com/davideturco/bayeserps"}, "2207.03391": {"publish_time": "2022-07-07", "title": "Non-Linear Pairwise Language Mappings for Low-Resource Multilingual Acoustic Model Fusion", "author": "Muhammad Umar Farooq et.al.", "abstract": "Multilingual speech recognition has drawn significant attention as an effective way to compensate data scarcity for low-resource languages. End-to-end (e2e) modelling is preferred over conventional hybrid systems, mainly because of no lexicon requirement. However, hybrid DNN-HMMs still outperform e2e models in limited data scenarios. Furthermore, the problem of manual lexicon creation has been alleviated by publicly available trained models of grapheme-to-phoneme (G2P) and text to IPA transliteration for a lot of languages. In this paper, a novel approach of hybrid DNN-HMM acoustic models fusion is proposed in a multilingual setup for the low-resource languages. Posterior distributions from different monolingual acoustic models, against a target language speech signal, are fused together. A separate regression neural network is trained for each source-target language pair to transform posteriors from source acoustic model to the target language. These networks require very limited data as compared to the ASR training. Posterior fusion yields a relative gain of 14.65% and 6.5% when compared with multilingual and monolingual baselines respectively. Cross-lingual model fusion shows that the comparable results can be achieved without using posteriors from the language dependent ASR.", "paper_url": "http://arxiv.org/abs/2207.03391v1", "pdf_url": "http://arxiv.org/pdf/2207.03391v1", "repo_url": null}, "2207.03390": {"publish_time": "2022-07-07", "title": "Investigating the Impact of Cross-lingual Acoustic-Phonetic Similarities on Multilingual Speech Recognition", "author": "Muhammad Umar Farooq et.al.", "abstract": "Multilingual automatic speech recognition (ASR) systems mostly benefit low resource languages but suffer degradation in performance across several languages relative to their monolingual counterparts. Limited studies have focused on understanding the languages behaviour in the multilingual speech recognition setups. In this paper, a novel data-driven approach is proposed to investigate the cross-lingual acoustic-phonetic similarities. This technique measures the similarities between posterior distributions from various monolingual acoustic models against a target speech signal. Deep neural networks are trained as mapping networks to transform the distributions from different acoustic models into a directly comparable form. The analysis observes that the languages closeness can not be truly estimated by the volume of overlapping phonemes set. Entropy analysis of the proposed mapping networks exhibits that a language with lesser overlap can be more amenable to cross-lingual transfer, and hence more beneficial in the multilingual setup. Finally, the proposed posterior transformation approach is leveraged to fuse monolingual models for a target language. A relative improvement of ~8% over monolingual counterpart is achieved.", "paper_url": "http://arxiv.org/abs/2207.03390v1", "pdf_url": "http://arxiv.org/pdf/2207.03390v1", "repo_url": null}}}, "Reinforcement Learning": {"Reinforcement Learning": {"2202.12884": {"publish_time": "2022-02-25", "title": "Learning to Identify Perceptual Bugs in 3D Video Games", "author": "Benedict Wilkins et.al.", "abstract": "Automated Bug Detection (ABD) in video games is composed of two distinct but complementary problems: automated game exploration and bug identification. Automated game exploration has received much recent attention, spurred on by developments in fields such as reinforcement learning. The complementary problem of identifying the bugs present in a player's experience has for the most part relied on the manual specification of rules. Although it is widely recognised that many bugs of interest cannot be identified with such methods, little progress has been made in this direction. In this work we show that it is possible to identify a range of perceptual bugs using learning-based methods by making use of only the rendered game screen as seen by the player. To support our work, we have developed World of Bugs (WOB) an open platform for testing ABD methods in 3D game environments.", "paper_url": "http://arxiv.org/abs/2202.12884v1", "pdf_url": "http://arxiv.org/pdf/2202.12884v1", "repo_url": null}, "2202.12872": {"publish_time": "2022-02-25", "title": "AutoFR: Automated Filter Rule Generation for Adblocking", "author": "Hieu Le et.al.", "abstract": "Adblocking relies on filter lists, which are manually curated and maintained by a small community of filter list authors. This manual process is laborious and does not scale well to a large number of sites and over time. We introduce AutoFR, a reinforcement learning framework to fully automate the process of filter rule creation and evaluation. We design an algorithm based on multi-arm bandits to generate filter rules while controlling the trade-off between blocking ads and avoiding breakage. We test our implementation of AutoFR on thousands of sites in terms of efficiency and effectiveness. AutoFR is efficient: it takes only a few minutes to generate filter rules for a site. AutoFR is also effective: it generates filter rules that can block 86% of the ads, as compared to 87% by EasyList while achieving comparable visual breakage. The filter rules generated by AutoFR generalize well to new and unseen sites. We envision AutoFR to assist the adblocking community in automated filter rule generation at scale.", "paper_url": "http://arxiv.org/abs/2202.12872v1", "pdf_url": "http://arxiv.org/pdf/2202.12872v1", "repo_url": null}, "2202.12866": {"publish_time": "2022-02-25", "title": "Learning to Schedule Heuristics for the Simultaneous Stochastic Optimization of Mining Complexes", "author": "Yassine Yaakoubi et.al.", "abstract": "The simultaneous stochastic optimization of mining complexes (SSOMC) is a large-scale stochastic combinatorial optimization problem that simultaneously manages the extraction of materials from multiple mines and their processing using interconnected facilities to generate a set of final products, while taking into account material supply (geological) uncertainty to manage the associated risk. Although simulated annealing has been shown to outperform comparing methods for solving the SSOMC, early performance might dominate recent performance in that a combination of the heuristics' performance is used to determine which perturbations to apply. This work proposes a data-driven framework for heuristic scheduling in a fully self-managed hyper-heuristic to solve the SSOMC. The proposed learn-to-perturb (L2P) hyper-heuristic is a multi-neighborhood simulated annealing algorithm. The L2P selects the heuristic (perturbation) to be applied in a self-adaptive manner using reinforcement learning to efficiently explore which local search is best suited for a particular search point. Several state-of-the-art agents have been incorporated into L2P to better adapt the search and guide it towards better solutions. By learning from data describing the performance of the heuristics, a problem-specific ordering of heuristics that collectively finds better solutions faster is obtained. L2P is tested on several real-world mining complexes, with an emphasis on efficiency, robustness, and generalization capacity. Results show a reduction in the number of iterations by 30-50% and in the computational time by 30-45%.", "paper_url": "http://arxiv.org/abs/2202.12866v1", "pdf_url": "http://arxiv.org/pdf/2202.12866v1", "repo_url": null}, "2202.12861": {"publish_time": "2022-02-25", "title": "Hierarchical Control for Multi-Agent Autonomous Racing", "author": "Rishabh Saumil Thakkar et.al.", "abstract": "We develop a hierarchical controller for multi-agent autonomous racing. A high-level planner approximates the race as a discrete game with simplified dynamics that encodes the complex safety and fairness rules seen in real-life racing and calculates a series of target waypoints. The low-level controller takes the resulting waypoints as a reference trajectory and computes high-resolution control inputs by solving a simplified formulation of a multi-agent racing game. We consider two approaches for the low-level planner to construct two hierarchical controllers. One approach uses multi-agent reinforcement learning (MARL), and the other solves a linear-quadratic Nash game (LQNG) to produce control inputs. We test the controllers against three baselines: an end-to-end MARL controller, a MARL controller tracking a fixed racing line, and an LQNG controller tracking a fixed racing line. Quantitative results show that the proposed hierarchical methods outperform their respective baseline methods in terms of head-to-head race wins and abiding by the rules. The hierarchical controller using MARL for low-level control consistently outperformed all other methods by winning over 88\\% of head-to-head races and more consistently adhered to the complex racing rules. Qualitatively, we observe the proposed controllers mimicking actions performed by expert human drivers such as shielding/blocking, overtaking, and long-term planning for delayed advantages. We show that hierarchical planning for game-theoretic reasoning produces competitive behavior even when challenged with complex rules and constraints.", "paper_url": "http://arxiv.org/abs/2202.12861v1", "pdf_url": "http://arxiv.org/pdf/2202.12861v1", "repo_url": "https://github.com/ribsthakkar/HierarchicalKarting"}, "2202.12847": {"publish_time": "2022-02-25", "title": "Building a 3-Player Mahjong AI using Deep Reinforcement Learning", "author": "Xiangyu Zhao et.al.", "abstract": "Mahjong is a popular multi-player imperfect-information game developed in China in the late 19th-century, with some very challenging features for AI research. Sanma, being a 3-player variant of the Japanese Riichi Mahjong, possesses unique characteristics including fewer tiles and, consequently, a more aggressive playing style. It is thus challenging and of great research interest in its own right, but has not yet been explored. In this paper, we present Meowjong, an AI for Sanma using deep reinforcement learning. We define an informative and compact 2-dimensional data structure for encoding the observable information in a Sanma game. We pre-train 5 convolutional neural networks (CNNs) for Sanma's 5 actions -- discard, Pon, Kan, Kita and Riichi, and enhance the major action's model, namely the discard model, via self-play reinforcement learning using the Monte Carlo policy gradient method. Meowjong's models achieve test accuracies comparable with AIs for 4-player Mahjong through supervised learning, and gain a significant further enhancement from reinforcement learning. Being the first ever AI in Sanma, we claim that Meowjong stands as a state-of-the-art in this game.", "paper_url": "http://arxiv.org/abs/2202.12847v1", "pdf_url": "http://arxiv.org/pdf/2202.12847v1", "repo_url": null}, "2202.13914": {"publish_time": "2022-02-28", "title": "Combining Modular Skills in Multitask Learning", "author": "Edoardo M. Ponti et.al.", "abstract": "A modular design encourages neural models to disentangle and recombine different facets of knowledge to generalise more systematically to new tasks. In this work, we assume that each task is associated with a subset of latent discrete skills from a (potentially small) inventory. In turn, skills correspond to parameter-efficient (sparse / low-rank) model parameterisations. By jointly learning these and a task-skill allocation matrix, the network for each task is instantiated as the average of the parameters of active skills. To favour non-trivial soft partitions of skills across tasks, we experiment with a series of inductive biases, such as an Indian Buffet Process prior and a two-speed learning rate. We evaluate our latent-skill model on two main settings: 1) multitask reinforcement learning for grounded instruction following on 8 levels of the BabyAI platform; and 2) few-shot adaptation of pre-trained text-to-text generative models on CrossFit, a benchmark comprising 160 NLP tasks. We find that the modular design of a network significantly increases sample efficiency in reinforcement learning and few-shot generalisation in supervised learning, compared to baselines with fully shared, task-specific, or conditionally generated parameters where knowledge is entangled across tasks. In addition, we show how discrete skills help interpretability, as they yield an explicit hierarchy of tasks.", "paper_url": "http://arxiv.org/abs/2202.13914v1", "pdf_url": "http://arxiv.org/pdf/2202.13914v1", "repo_url": null}, "2202.13890": {"publish_time": "2022-02-28", "title": "Pessimistic Q-Learning for Offline Reinforcement Learning: Towards Optimal Sample Complexity", "author": "Laixi Shi et.al.", "abstract": "Offline or batch reinforcement learning seeks to learn a near-optimal policy using history data without active exploration of the environment. To counter the insufficient coverage and sample scarcity of many offline datasets, the principle of pessimism has been recently introduced to mitigate high bias of the estimated values. While pessimistic variants of model-based algorithms (e.g., value iteration with lower confidence bounds) have been theoretically investigated, their model-free counterparts -- which do not require explicit model estimation -- have not been adequately studied, especially in terms of sample efficiency. To address this inadequacy, we study a pessimistic variant of Q-learning in the context of finite-horizon Markov decision processes, and characterize its sample complexity under the single-policy concentrability assumption which does not require the full coverage of the state-action space. In addition, a variance-reduced pessimistic Q-learning algorithm is proposed to achieve near-optimal sample complexity. Altogether, this work highlights the efficiency of model-free algorithms in offline RL when used in conjunction with pessimism and variance reduction.", "paper_url": "http://arxiv.org/abs/2202.13890v1", "pdf_url": "http://arxiv.org/pdf/2202.13890v1", "repo_url": null}, "2202.13887": {"publish_time": "2022-02-28", "title": "Probing the Robustness of Trained Metrics for Conversational Dialogue Systems", "author": "Jan Deriu et.al.", "abstract": "This paper introduces an adversarial method to stress-test trained metrics to evaluate conversational dialogue systems. The method leverages Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics. We apply our method to test recently proposed trained metrics. We find that they all are susceptible to giving high scores to responses generated by relatively simple and obviously flawed strategies that our method converges on. For instance, simply copying parts of the conversation context to form a response yields competitive scores or even outperforms responses written by humans.", "paper_url": "http://arxiv.org/abs/2202.13887v1", "pdf_url": "http://arxiv.org/pdf/2202.13887v1", "repo_url": null}, "2202.13863": {"publish_time": "2022-02-28", "title": "Provably Efficient Convergence of Primal-Dual Actor-Critic with Nonlinear Function Approximation", "author": "Jing Dong et.al.", "abstract": "We study the convergence of the actor-critic algorithm with nonlinear function approximation under a nonconvex-nonconcave primal-dual formulation. Stochastic gradient descent ascent is applied with an adaptive proximal term for robust learning rates. We show the first efficient convergence result with primal-dual actor-critic with a convergence rate of $\\mathcal{O}\\left(\\sqrt{\\frac{\\ln \\left(N d G^2 \\right)}{N}}\\right)$ under Markovian sampling, where $G$ is the element-wise maximum of the gradient, $N$ is the number of iterations, and $d$ is the dimension of the gradient. Our result is presented with only the Polyak-\\L{}ojasiewicz condition for the dual variables, which is easy to verify and applicable to a wide range of reinforcement learning (RL) scenarios. The algorithm and analysis are general enough to be applied to other RL settings, like multi-agent RL. Empirical results on OpenAI Gym continuous control tasks corroborate our theoretical findings.", "paper_url": "http://arxiv.org/abs/2202.13863v1", "pdf_url": "http://arxiv.org/pdf/2202.13863v1", "repo_url": null}, "2202.13706": {"publish_time": "2022-02-28", "title": "Monkey Business: Reinforcement learning meets neighborhood search for Virtual Network Embedding", "author": "Maxime Elkael et.al.", "abstract": "In this article, we consider the Virtual Network Embedding (VNE) problem for 5G networks slicing. This problem requires to allocate multiple Virtual Networks (VN) on a substrate virtualized physical network while maximizing among others, resource utilization, maximum number of placed VNs and network operator's benefit. We solve the online version of the problem where slices arrive over time. Inspired by the Nested Rollout Policy Adaptation (NRPA) algorithm, a variant of the well known Monte Carlo Tree Search (MCTS) that learns how to perform good simulations over time, we propose a new algorithm that we call Neighborhood Enhanced Policy Adaptation (NEPA). The key feature of our algorithm is to observe NRPA cannot exploit knowledge acquired in one branch of the state tree for another one which starts differently. NEPA learns by combining NRPA with Neighbordhood Search in a frugal manner which improves only promising solutions while keeping the running time low. We call this technique a monkey business because it comes down to jumping from one interesting branch to the other, similar to how monkeys jump from tree to tree instead of going down everytime. NEPA achieves better results in terms of acceptance ratio and revenue-to-cost ratio compared to other state-of-the-art algorithms, both on real and synthetic topologies.", "paper_url": "http://arxiv.org/abs/2202.13706v1", "pdf_url": "http://arxiv.org/pdf/2202.13706v1", "repo_url": null}, "2203.00669": {"publish_time": "2022-03-01", "title": "AI Planning Annotation for Sample Efficient Reinforcement Learning", "author": "Junkyu Lee et.al.", "abstract": "AI planning and Reinforcement Learning (RL) both solve sequential decision-making problems under the different formulations. AI Planning requires operator models, but then allows efficient plan generation. RL requires no operator model, instead learns a policy to guide an agent to high reward states. Planning can be brittle in the face of noise whereas RL is more tolerant. However, RL requires a large number of training examples to learn the policy. In this work, we aim to bring AI planning and RL closer by showing that a suitably defined planning model can be used to improve the efficiency of RL. Specifically, we show that the options in the hierarchical RL can be derived from a planning task and integrate planning and RL algorithms for training option policy functions. Our experiments demonstrate an improved sample efficiency on a variety of RL environments over the previous state-of-the-art.", "paper_url": "http://arxiv.org/abs/2203.00669v1", "pdf_url": "http://arxiv.org/pdf/2203.00669v1", "repo_url": null}, "2203.00636": {"publish_time": "2022-03-01", "title": "Distributional Reinforcement Learning for Scheduling of (Bio)chemical Production Processes", "author": "Max Mowbray et.al.", "abstract": "Reinforcement Learning (RL) has recently received significant attention from the process systems engineering and control communities. Recent works have investigated the application of RL to identify optimal scheduling decision in the presence of uncertainty. In this work, we present a RL methodology to address precedence and disjunctive constraints as commonly imposed on production scheduling problems. This work naturally enables the optimization of risk-sensitive formulations such as the conditional value-at-risk (CVaR), which are essential in realistic scheduling processes. The proposed strategy is investigated thoroughly in a single-stage, parallel batch production environment, and benchmarked against mixed integer linear programming (MILP) strategies. We show that the policy identified by our approach is able to account for plant uncertainties in online decision-making, with expected performance comparable to existing MILP methods. Additionally, the framework gains the benefits of optimizing for risk-sensitive measures, and identifies decisions orders of magnitude faster than the most efficient optimization approaches. This promises to mitigate practical issues and ease in handling realizations of process uncertainty in the paradigm of online production scheduling.", "paper_url": "http://arxiv.org/abs/2203.00636v1", "pdf_url": "http://arxiv.org/pdf/2203.00636v1", "repo_url": null}, "2203.00543": {"publish_time": "2022-03-01", "title": "On the Generalization of Representations in Reinforcement Learning", "author": "Charline Le Lan et.al.", "abstract": "In reinforcement learning, state representations are used to tractably deal with large problem spaces. State representations serve both to approximate the value function with few parameters, but also to generalize to newly encountered states. Their features may be learned implicitly (as part of a neural network) or explicitly (for example, the successor representation of \\citet{dayan1993improving}). While the approximation properties of representations are reasonably well-understood, a precise characterization of how and when these representations generalize is lacking. In this work, we address this gap and provide an informative bound on the generalization error arising from a specific state representation. This bound is based on the notion of effective dimension which measures the degree to which knowing the value at one state informs the value at other states. Our bound applies to any state representation and quantifies the natural tension between representations that generalize well and those that approximate well. We complement our theoretical results with an empirical survey of classic representation learning methods from the literature and results on the Arcade Learning Environment, and find that the generalization behaviour of learned representations is well-explained by their effective dimension.", "paper_url": "http://arxiv.org/abs/2203.00543v1", "pdf_url": "http://arxiv.org/pdf/2203.00543v1", "repo_url": null}, "2203.00494": {"publish_time": "2022-03-01", "title": "DreamingV2: Reinforcement Learning with Discrete World Models without Reconstruction", "author": "Masashi Okada et.al.", "abstract": "The present paper proposes a novel reinforcement learning method with world models, DreamingV2, a collaborative extension of DreamerV2 and Dreaming. DreamerV2 is a cutting-edge model-based reinforcement learning from pixels that uses discrete world models to represent latent states with categorical variables. Dreaming is also a form of reinforcement learning from pixels that attempts to avoid the autoencoding process in general world model training by involving a reconstruction-free contrastive learning objective. The proposed DreamingV2 is a novel approach of adopting both the discrete representation of DreamingV2 and the reconstruction-free objective of Dreaming. Compared to DreamerV2 and other recent model-based methods without reconstruction, DreamingV2 achieves the best scores on five simulated challenging 3D robot arm tasks. We believe that DreamingV2 will be a reliable solution for robot learning since its discrete representation is suitable to describe discontinuous environments, and the reconstruction-free fashion well manages complex vision observations.", "paper_url": "http://arxiv.org/abs/2203.00494v1", "pdf_url": "http://arxiv.org/pdf/2203.00494v1", "repo_url": null}, "2203.00397": {"publish_time": "2022-03-01", "title": "A Theory of Abstraction in Reinforcement Learning", "author": "David Abel et.al.", "abstract": "Reinforcement learning defines the problem facing agents that learn to make good decisions through action and observation alone. To be effective problem solvers, such agents must efficiently explore vast worlds, assign credit from delayed feedback, and generalize to new experiences, all while making use of limited data, computational resources, and perceptual bandwidth. Abstraction is essential to all of these endeavors. Through abstraction, agents can form concise models of their environment that support the many practices required of a rational, adaptive decision maker. In this dissertation, I present a theory of abstraction in reinforcement learning. I first offer three desiderata for functions that carry out the process of abstraction: they should 1) preserve representation of near-optimal behavior, 2) be learned and constructed efficiently, and 3) lower planning or learning time. I then present a suite of new algorithms and analysis that clarify how agents can learn to abstract according to these desiderata. Collectively, these results provide a partial path toward the discovery and use of abstraction that minimizes the complexity of effective reinforcement learning.", "paper_url": "http://arxiv.org/abs/2203.00397v1", "pdf_url": "http://arxiv.org/pdf/2203.00397v1", "repo_url": null}, "2203.01302": {"publish_time": "2022-03-02", "title": "Evolving Curricula with Regret-Based Environment Design", "author": "Jack Parker-Holder et.al.", "abstract": "It remains a significant challenge to train generally capable agents with reinforcement learning (RL). A promising avenue for improving the robustness of RL agents is through the use of curricula. One such class of methods frames environment design as a game between a student and a teacher, using regret-based objectives to produce environment instantiations (or levels) at the frontier of the student agent's capabilities. These methods benefit from their generality, with theoretical guarantees at equilibrium, yet they often struggle to find effective levels in challenging design spaces. By contrast, evolutionary approaches seek to incrementally alter environment complexity, resulting in potentially open-ended learning, but often rely on domain-specific heuristics and vast amounts of computational resources. In this paper we propose to harness the power of evolution in a principled, regret-based curriculum. Our approach, which we call Adversarially Compounding Complexity by Editing Levels (ACCEL), seeks to constantly produce levels at the frontier of an agent's capabilities, resulting in curricula that start simple but become increasingly complex. ACCEL maintains the theoretical benefits of prior regret-based methods, while providing significant empirical gains in a diverse set of environments. An interactive version of the paper is available at accelagent.github.io.", "paper_url": "http://arxiv.org/abs/2203.01302v1", "pdf_url": "http://arxiv.org/pdf/2203.01302v1", "repo_url": null}, "2203.01298": {"publish_time": "2022-03-02", "title": "Pareto Frontier Approximation Network (PA-Net) to Solve Bi-objective TSP", "author": "Ishaan Mehta et.al.", "abstract": "Travelling salesperson problem (TSP) is a classic resource allocation problem used to find an optimal order of doing a set of tasks while minimizing (or maximizing) an associated objective function. It is widely used in robotics for applications such as planning, scheduling etc. In this work, we solve TSP for two objectives using reinforcement learning. Often in multi objective optimization problems, the associated objective functions can be conflicting in nature. In such cases, the optimality is defined in terms of Pareto optimality. A set of these Pareto Optimal solutions in the objective space form a Pareto front (or frontier). Each solution has its own trade off. } In this work, we present PA-Net, a network that generates good approximations of the Pareto front for the bi-objective travelling salesperson problem (BTSP). Firstly, BTSP is converted into a constrained optimization problem. We then train our network to solve this constrained problem using the Lagrangian relaxation and policy gradient. With PA-Net we are able to generate good quality Pareto fronts with fast inference times. Finally, we present the application of PA-Net to find optimal visiting order in a robotic navigation task/coverage planning.", "paper_url": "http://arxiv.org/abs/2203.01298v1", "pdf_url": "http://arxiv.org/pdf/2203.01298v1", "repo_url": null}, "2203.01292": {"publish_time": "2022-03-02", "title": "Andes_gym: A Versatile Environment for Deep Reinforcement Learning in Power Systems", "author": "Hantao Cui et.al.", "abstract": "This paper presents Andes_gym, a versatile and high-performance reinforcement learning environment for power system studies. The environment leverages the modeling and simulation capability of ANDES and the reinforcement learning (RL) environment OpenAI Gym to enable the prototyping and demonstration of RL algorithms for power systems. The architecture of the proposed software tool is elaborated to provide the observation and action interfaces for RL algorithms. An example is shown to rapidly prototype a load-frequency control algorithm based on RL trained by available algorithms. The proposed environment is highly generalized by supporting all the power system dynamic models available in ANDES and numerous RL algorithms available for OpenAI Gym.", "paper_url": "http://arxiv.org/abs/2203.01292v1", "pdf_url": "http://arxiv.org/pdf/2203.01292v1", "repo_url": null}, "2203.01190": {"publish_time": "2022-03-02", "title": "Model-free Neural Lyapunov Control for Safe Robot Navigation", "author": "Zikang Xiong et.al.", "abstract": "Model-free Deep Reinforcement Learning (DRL) controllers have demonstrated promising results on various challenging non-linear control tasks. While a model-free DRL algorithm can solve unknown dynamics and high-dimensional problems, it lacks safety assurance. Although safety constraints can be encoded as part of a reward function, there still exists a large gap between an RL controller trained with this modified reward and a safe controller. In contrast, instead of implicitly encoding safety constraints with rewards, we explicitly co-learn a Twin Neural Lyapunov Function (TNLF) with the control policy in the DRL training loop and use the learned TNLF to build a runtime monitor. Combined with the path generated from a planner, the monitor chooses appropriate waypoints that guide the learned controller to provide collision-free control trajectories. Our approach inherits the scalability advantages from DRL while enhancing safety guarantees. Our experimental evaluation demonstrates the effectiveness of our approach compared to DRL with augmented rewards and constrained DRL methods over a range of high-dimensional safety-sensitive navigation tasks.", "paper_url": "http://arxiv.org/abs/2203.01190v1", "pdf_url": "http://arxiv.org/pdf/2203.01190v1", "repo_url": null}, "2203.01148": {"publish_time": "2022-03-02", "title": "Reactive Stepping for Humanoid Robots using Reinforcement Learning: Application to Standing Push Recovery on the Exoskeleton Atalante", "author": "Alexis Duburcq et.al.", "abstract": "State-of-the-art reinforcement learning is now able to learn versatile locomotion, balancing and push-recovery capabilities for bipedal robots in simulation. Yet, the reality gap has mostly been overlooked and the simulated results hardly transfer to real hardware. Either it is unsuccessful in practice because the physics is over-simplified and hardware limitations are ignored, or regularity is not guaranteed and unexpected hazardous motions can occur. This paper presents a reinforcement learning framework capable of learning robust standing push recovery for bipedal robots with a smooth out-of-the-box transfer to reality, requiring only instantaneous proprioceptive observations. By combining original termination conditions and policy smoothness conditioning, we achieve stable learning, sim-to-real transfer and safety using a policy without memory nor observation history. Reward shaping is then used to give insights into how to keep balance. We demonstrate its performance in reality on the lower-limb medical exoskeleton Atalante.", "paper_url": "http://arxiv.org/abs/2203.01148v1", "pdf_url": "http://arxiv.org/pdf/2203.01148v1", "repo_url": null}, "2203.01889": {"publish_time": "2022-03-03", "title": "Quantum Reinforcement Learning via Policy Iteration", "author": "El Amine Cherrat et.al.", "abstract": "Quantum computing has shown the potential to substantially speed up machine learning applications, in particular for supervised and unsupervised learning. Reinforcement learning, on the other hand, has become essential for solving many decision making problems and policy iteration methods remain the foundation of such approaches. In this paper, we provide a general framework for performing quantum reinforcement learning via policy iteration. We validate our framework by designing and analyzing: \\emph{quantum policy evaluation} methods for infinite horizon discounted problems by building quantum states that approximately encode the value function of a policy $\\pi$; and \\emph{quantum policy improvement} methods by post-processing measurement outcomes on these quantum states. Last, we study the theoretical and experimental performance of our quantum algorithms on two environments from OpenAI's Gym.", "paper_url": "http://arxiv.org/abs/2203.01889v1", "pdf_url": "http://arxiv.org/pdf/2203.01889v1", "repo_url": null}, "2203.01855": {"publish_time": "2022-03-03", "title": "Reasoning about Counterfactuals to Improve Human Inverse Reinforcement Learning", "author": "Michael S. Lee et.al.", "abstract": "To collaborate well with robots, we must be able to understand their decision making. Humans naturally infer other agents' beliefs and desires by reasoning about their observable behavior in a way that resembles inverse reinforcement learning (IRL). Thus, robots can convey their beliefs and desires by providing demonstrations that are informative for a human's IRL. An informative demonstration is one that differs strongly from the learner's expectations of what the robot will do given their current understanding of the robot's decision making. However, standard IRL does not model the learner's existing expectations, and thus cannot do this counterfactual reasoning. We propose to incorporate the learner's current understanding of the robot's decision making into our model of human IRL, so that our robot can select demonstrations that maximize the human's understanding. We also propose a novel measure for estimating the difficulty for a human to predict instances of a robot's behavior in unseen environments. A user study finds that our test difficulty measure correlates well with human performance and confidence. Interestingly, considering human beliefs and counterfactuals when selecting demonstrations decreases human performance on easy tests, but increases performance on difficult tests, providing insight on how to best utilize such models.", "paper_url": "http://arxiv.org/abs/2203.01855v1", "pdf_url": "http://arxiv.org/pdf/2203.01855v1", "repo_url": null}, "2203.01821": {"publish_time": "2022-03-03", "title": "Socially Aware Robot Crowd Navigation with Interaction Graphs and Human Trajectory Prediction", "author": "Shuijing Liu et.al.", "abstract": "We study the problem of safe and socially aware robot navigation in dense and interactive human crowds. Previous works use simplified methods to model the personal spaces of pedestrians and ignore the social compliance of the robot behaviors. In this paper, we provide a more accurate representation of personal zones of walking pedestrians with their future trajectories. The predicted personal zones are incorporated into a reinforcement learning framework to prevent the robot from intruding into the personal zones. To learn socially aware navigation policies, we propose a novel recurrent graph neural network with attention mechanisms to capture the interactions among agents through space and time. We demonstrate that our method enables the robot to achieve good navigation performance and non-invasiveness in challenging crowd navigation scenarios. We successfully transfer the policy learned in the simulator to a real-world TurtleBot 2i.", "paper_url": "http://arxiv.org/abs/2203.01821v1", "pdf_url": "http://arxiv.org/pdf/2203.01821v1", "repo_url": null}, "2203.01758": {"publish_time": "2022-03-03", "title": "On Practical Reinforcement Learning: Provable Robustness, Scalability, and Statistical Efficiency", "author": "Thanh Nguyen-Tang et.al.", "abstract": "This thesis rigorously studies fundamental reinforcement learning (RL) methods in modern practical considerations, including robust RL, distributional RL, and offline RL with neural function approximation. The thesis first prepares the readers with an overall overview of RL and key technical background in statistics and optimization. In each of the settings, the thesis motivates the problems to be studied, reviews the current literature, provides computationally efficient algorithms with provable efficiency guarantees, and concludes with future research directions. The thesis makes fundamental contributions to the three settings above, both algorithmically, theoretically, and empirically, while staying relevant to practical considerations.", "paper_url": "http://arxiv.org/abs/2203.01758v1", "pdf_url": "http://arxiv.org/pdf/2203.01758v1", "repo_url": "https://github.com/thanhnguyentang/drbqo"}, "2203.01735": {"publish_time": "2022-03-03", "title": "Modality-Adaptive Mixup and Invariant Decomposition for RGB-Infrared Person Re-Identification", "author": "Zhipeng Huang et.al.", "abstract": "RGB-infrared person re-identification is an emerging cross-modality re-identification task, which is very challenging due to significant modality discrepancy between RGB and infrared images. In this work, we propose a novel modality-adaptive mixup and invariant decomposition (MID) approach for RGB-infrared person re-identification towards learning modality-invariant and discriminative representations. MID designs a modality-adaptive mixup scheme to generate suitable mixed modality images between RGB and infrared images for mitigating the inherent modality discrepancy at the pixel-level. It formulates modality mixup procedure as Markov decision process, where an actor-critic agent learns dynamical and local linear interpolation policy between different regions of cross-modality images under a deep reinforcement learning framework. Such policy guarantees modality-invariance in a more continuous latent space and avoids manifold intrusion by the corrupted mixed modality samples. Moreover, to further counter modality discrepancy and enforce invariant visual semantics at the feature-level, MID employs modality-adaptive convolution decomposition to disassemble a regular convolution layer into modality-specific basis layers and a modality-shared coefficient layer. Extensive experimental results on two challenging benchmarks demonstrate superior performance of MID over state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2203.01735v1", "pdf_url": "http://arxiv.org/pdf/2203.01735v1", "repo_url": null}, "2203.02481": {"publish_time": "2022-03-04", "title": "AutoDIME: Automatic Design of Interesting Multi-Agent Environments", "author": "Ingmar Kanitscheider et.al.", "abstract": "Designing a distribution of environments in which RL agents can learn interesting and useful skills is a challenging and poorly understood task, for multi-agent environments the difficulties are only exacerbated. One approach is to train a second RL agent, called a teacher, who samples environments that are conducive for the learning of student agents. However, most previous proposals for teacher rewards do not generalize straightforwardly to the multi-agent setting. We examine a set of intrinsic teacher rewards derived from prediction problems that can be applied in multi-agent settings and evaluate them in Mujoco tasks such as multi-agent Hide and Seek as well as a diagnostic single-agent maze task. Of the intrinsic rewards considered we found value disagreement to be most consistent across tasks, leading to faster and more reliable emergence of advanced skills in Hide and Seek and the maze task. Another candidate intrinsic reward considered, value prediction error, also worked well in Hide and Seek but was susceptible to noisy-TV style distractions in stochastic environments. Policy disagreement performed well in the maze task but did not speed up learning in Hide and Seek. Our results suggest that intrinsic teacher rewards, and in particular value disagreement, are a promising approach for automating both single and multi-agent environment design.", "paper_url": "http://arxiv.org/abs/2203.02481v1", "pdf_url": "http://arxiv.org/pdf/2203.02481v1", "repo_url": null}, "2203.02389": {"publish_time": "2022-03-04", "title": "Learning Goal-Oriented Non-Prehensile Pushing in Cluttered Scenes", "author": "Nils Dengler et.al.", "abstract": "Pushing objects through cluttered scenes is a challenging task, especially when the objects to be pushed have initially unknown dynamics and touching other entities has to be avoided to reduce the risk of damage. In this paper, we approach this problem by applying deep reinforcement learning to generate pushing actions for a robotic manipulator acting on a planar surface where objects have to be pushed to goal locations while avoiding other items in the same workspace. With the latent space learned from a depth image of the scene and other observations of the environment, such as contact information between the end effector and the object as well as distance to the goal, our framework is able to learn contact-rich pushing actions that avoid collisions with other objects. As the experimental results with a six degrees of freedom robotic arm show, our system is able to successfully push objects from start to end positions while avoiding nearby objects. Furthermore, we evaluate our learned policy in comparison to a state-of-the-art pushing controller for mobile robots and show that our agent performs better in terms of success rate, collisions with other objects, and continuous object contact in various scenarios.", "paper_url": "http://arxiv.org/abs/2203.02389v1", "pdf_url": "http://arxiv.org/pdf/2203.02389v1", "repo_url": null}, "2203.02381": {"publish_time": "2022-03-04", "title": "Where to Look Next: Learning Viewpoint Recommendations for Informative Trajectory Planning", "author": "Max Lodel et.al.", "abstract": "Search missions require motion planning and navigation methods for information gathering that continuously replan based on new observations of the robot's surroundings. Current methods for information gathering, such as Monte Carlo Tree Search, are capable of reasoning over long horizons, but they are computationally expensive. An alternative for fast online execution is to train, offline, an information gathering policy, which indirectly reasons about the information value of new observations. However, these policies lack safety guarantees and do not account for the robot dynamics. To overcome these limitations we train an information-aware policy via deep reinforcement learning, that guides a receding-horizon trajectory optimization planner. In particular, the policy continuously recommends a reference viewpoint to the local planner, such that the resulting dynamically feasible and collision-free trajectories lead to observations that maximize the information gain and reduce the uncertainty about the environment. In simulation tests in previously unseen environments, our method consistently outperforms greedy next-best-view policies and achieves competitive performance compared to Monte Carlo Tree Search, in terms of information gains and coverage time, with a reduction in execution time by three orders of magnitude.", "paper_url": "http://arxiv.org/abs/2203.02381v1", "pdf_url": "http://arxiv.org/pdf/2203.02381v1", "repo_url": null}, "2203.02230": {"publish_time": "2022-03-04", "title": "Cloud-Edge Training Architecture for Sim-to-Real Deep Reinforcement Learning", "author": "Hongpeng Cao et.al.", "abstract": "Deep reinforcement learning (DRL) is a promising approach to solve complex control tasks by learning policies through interactions with the environment. However, the training of DRL policies requires large amounts of training experiences, making it impractical to learn the policy directly on physical systems. Sim-to-real approaches leverage simulations to pretrain DRL policies and then deploy them in the real world. Unfortunately, the direct real-world deployment of pretrained policies usually suffers from performance deterioration due to the different dynamics, known as the reality gap. Recent sim-to-real methods, such as domain randomization and domain adaptation, focus on improving the robustness of the pretrained agents. Nevertheless, the simulation-trained policies often need to be tuned with real-world data to reach optimal performance, which is challenging due to the high cost of real-world samples.   This work proposes a distributed cloud-edge architecture to train DRL agents in the real world in real-time. In the architecture, the inference and training are assigned to the edge and cloud, separating the real-time control loop from the computationally expensive training loop. To overcome the reality gap, our architecture exploits sim-to-real transfer strategies to continue the training of simulation-pretrained agents on a physical system. We demonstrate its applicability on a physical inverted-pendulum control system, analyzing critical parameters. The real-world experiments show that our architecture can adapt the pretrained DRL agents to unseen dynamics consistently and efficiently.", "paper_url": "http://arxiv.org/abs/2203.02230v1", "pdf_url": "http://arxiv.org/pdf/2203.02230v1", "repo_url": null}, "2203.02201": {"publish_time": "2022-03-04", "title": "Neural Simulated Annealing", "author": "Alvaro H. C. Correia et.al.", "abstract": "Simulated annealing (SA) is a stochastic global optimisation technique applicable to a wide range of discrete and continuous variable problems. Despite its simplicity, the development of an effective SA optimiser for a given problem hinges on a handful of carefully handpicked components; namely, neighbour proposal distribution and temperature annealing schedule. In this work, we view SA from a reinforcement learning perspective and frame the proposal distribution as a policy, which can be optimised for higher solution quality given a fixed computational budget. We demonstrate that this Neural SA with such a learnt proposal distribution, parametrised by small equivariant neural networks, outperforms SA baselines on a number of problems: Rosenbrock's function, the Knapsack problem, the Bin Packing problem, and the Travelling Salesperson problem. We also show that Neural SA scales well to large problems - generalising to significantly larger problems than the ones seen during training - while achieving comparable performance to popular off-the-shelf solvers and other machine learning methods in terms of solution quality and wall-clock time.", "paper_url": "http://arxiv.org/abs/2203.02201v1", "pdf_url": "http://arxiv.org/pdf/2203.02201v1", "repo_url": null}, "2203.03535": {"publish_time": "2022-03-07", "title": "Influencing Long-Term Behavior in Multiagent Reinforcement Learning", "author": "Dong-Ki Kim et.al.", "abstract": "The main challenge of multiagent reinforcement learning is the difficulty of learning useful policies in the presence of other simultaneously learning agents whose changing behaviors jointly affect the environment's transition and reward dynamics. An effective approach that has recently emerged for addressing this non-stationarity is for each agent to anticipate the learning of other interacting agents and influence the evolution of their future policies towards desirable behavior for its own benefit. Unfortunately, all previous approaches for achieving this suffer from myopic evaluation, considering only a few or a finite number of updates to the policies of other agents. In this paper, we propose a principled framework for considering the limiting policies of other agents as the time approaches infinity. Specifically, we develop a new optimization objective that maximizes each agent's average reward by directly accounting for the impact of its behavior on the limiting set of policies that other agents will take on. Thanks to our farsighted evaluation, we demonstrate better long-term performance than state-of-the-art baselines in various domains, including the full spectrum of general-sum, competitive, and cooperative settings.", "paper_url": "http://arxiv.org/abs/2203.03535v1", "pdf_url": "http://arxiv.org/pdf/2203.03535v1", "repo_url": null}, "2203.03480": {"publish_time": "2022-03-07", "title": "Reinforcement Learning for Location-Aware Scheduling", "author": "Stelios Stavroulakis et.al.", "abstract": "Recent techniques in dynamical scheduling and resource management have found applications in warehouse environments due to their ability to organize and prioritize tasks in a higher temporal resolution. The rise of deep reinforcement learning, as a learning paradigm, has enabled decentralized agent populations to discover complex coordination strategies. However, training multiple agents simultaneously introduce many obstacles in training as observation and action spaces become exponentially large. In our work, we experimentally quantify how various aspects of the warehouse environment (e.g., floor plan complexity, information about agents' live location, level of task parallelizability) affect performance and execution priority. To achieve efficiency, we propose a compact representation of the state and action space for location-aware multi-agent systems, wherein each agent has knowledge of only self and task coordinates, hence only partial observability of the underlying Markov Decision Process. Finally, we show how agents trained in certain environments maintain performance in completely unseen settings and also correlate performance degradation with floor plan geometry.", "paper_url": "http://arxiv.org/abs/2203.03480v1", "pdf_url": "http://arxiv.org/pdf/2203.03480v1", "repo_url": null}, "2203.03457": {"publish_time": "2022-03-07", "title": "Graph Neural Networks for Image Classification and Reinforcement Learning using Graph representations", "author": "Naman Goyal et.al.", "abstract": "In this paper, we will evaluate the performance of graph neural networks in two distinct domains: computer vision and reinforcement learning. In the computer vision section, we seek to learn whether a novel non-redundant representation for images as graphs can improve performance over trivial pixel to node mapping on a graph-level prediction graph, specifically image classification. For the reinforcement learning section, we seek to learn if explicitly modeling solving a Rubik's cube as a graph problem can improve performance over a standard model-free technique with no inductive bias.", "paper_url": "http://arxiv.org/abs/2203.03457v1", "pdf_url": "http://arxiv.org/pdf/2203.03457v1", "repo_url": null}, "2203.03451": {"publish_time": "2022-03-07", "title": "Safety Verification of Autonomous Systems: A Multi-Fidelity Reinforcement Learning Approach", "author": "Jared J. Beard et.al.", "abstract": "As autonomous and semi-autonomous agents become more integrated with society, validation of their safety is increasingly important. The scenarios under which they are used, however, can be quite complicated; as such, formal verification may be impossible. To this end, simulation-based safety verification is being used more frequently to understand failure scenarios for the most complex problems. Recent approaches, such as adaptive stress testing (AST), use reinforcement learning, making them prone to excessive exploitation of known failures, limiting coverage of the space of failures. To overcome this, the work below defines a class of Markov decision processes, the knowledge MDP, which captures information about the learned model to reason over. More specifically, by leveraging, the \"knows what it knows\" (KWIK) framework, the learner estimates its knowledge (model estimates and confidence, as well as assumptions) about the underlying system. This formulation is vetted through MF-KWIK-AST which extends bidirectional learning in multiple fidelities (MF) of simulators to the safety verification problem. The knowledge MDP formulation is applied to detect convergence of the model, penalizing this behavior to encourage further exploration. Results are evaluated in a grid world, training an adversary to intercept a system under test. Monte Carlo trials compare the relative sample efficiency of MF-KWIK-AST to learning with a single-fidelity simulator, as well as demonstrate the utility of incorporating knowledge about learned models into the decision making process.", "paper_url": "http://arxiv.org/abs/2203.03451v1", "pdf_url": "http://arxiv.org/pdf/2203.03451v1", "repo_url": null}, "2203.03417": {"publish_time": "2022-03-07", "title": "Scalable multi-agent reinforcement learning for distributed control of residential energy flexibility", "author": "Flora Charbonnier et.al.", "abstract": "This paper proposes a novel scalable type of multi-agent reinforcement learning-based coordination for distributed residential energy. Cooperating agents learn to control the flexibility offered by electric vehicles, space heating and flexible loads in a partially observable stochastic environment. In the standard independent Q-learning approach, the coordination performance of agents under partial observability drops at scale in stochastic environments. Here, the novel combination of learning from off-line convex optimisations on historical data and isolating marginal contributions to total rewards in reward signals increases stability and performance at scale. Using fixed-size Q-tables, prosumers are able to assess their marginal impact on total system objectives without sharing personal data either with each other or with a central coordinator. Case studies are used to assess the fitness of different combinations of exploration sources, reward definitions, and multi-agent learning frameworks. It is demonstrated that the proposed strategies create value at individual and system levels thanks to reductions in the costs of energy imports, losses, distribution network congestion, battery depreciation and greenhouse gas emissions.", "paper_url": "http://arxiv.org/abs/2203.03417v1", "pdf_url": "http://arxiv.org/pdf/2203.03417v1", "repo_url": null}, "2203.04272": {"publish_time": "2022-03-08", "title": "Policy-Based Bayesian Experimental Design for Non-Differentiable Implicit Models", "author": "Vincent Lim et.al.", "abstract": "For applications in healthcare, physics, energy, robotics, and many other fields, designing maximally informative experiments is valuable, particularly when experiments are expensive, time-consuming, or pose safety hazards. While existing approaches can sequentially design experiments based on prior observation history, many of these methods do not extend to implicit models, where simulation is possible but computing the likelihood is intractable. Furthermore, they often require either significant online computation during deployment or a differentiable simulation system. We introduce Reinforcement Learning for Deep Adaptive Design (RL-DAD), a method for simulation-based optimal experimental design for non-differentiable implicit models. RL-DAD extends prior work in policy-based Bayesian Optimal Experimental Design (BOED) by reformulating it as a Markov Decision Process with a reward function based on likelihood-free information lower bounds, which is used to learn a policy via deep reinforcement learning. The learned design policy maps prior histories to experiment designs offline and can be quickly deployed during online execution. We evaluate RL-DAD and find that it performs competitively with baselines on three benchmarks.", "paper_url": "http://arxiv.org/abs/2203.04272v1", "pdf_url": "http://arxiv.org/pdf/2203.04272v1", "repo_url": null}, "2203.04271": {"publish_time": "2022-03-08", "title": "Gradient Ascent Pulse Engineering with Feedback", "author": "Riccardo Porotti et.al.", "abstract": "Efficient approaches to quantum control and feedback are essential for quantum technologies, from sensing to quantum computation. Pure control tasks have been successfully solved using optimization techniques, including methods like gradient-ascent pulse engineering (GRAPE) , relying on a differentiable model of the quantum dynamics. For feedback tasks, such methods are not directly applicable, since the aim is to discover strategies conditioned on measurement outcomes. There, model-free reinforcement learning (RL) has recently proven a powerful new ansatz. What is missing is a way to combine the best of both approaches for scenarios that go beyond weak measurements. In this work, we introduce feedback-GRAPE, which borrows concepts from model-free RL to incorporate the response to strong stochastic (discrete or continuous) measurements, while still performing direct gradient ascent through the quantum dynamics. We illustrate its power on a Jaynes-Cummings model with feedback, where it yields interpretable feedback strategies for state preparation and stabilization in the presence of noise. This approach could be employed for discovering strategies in a wide range of feedback tasks, from calibration of multi-qubit devices to linear-optics quantum computation strategies, quantum-enhanced sensing with adaptive measurements, and quantum error correction.", "paper_url": "http://arxiv.org/abs/2203.04271v1", "pdf_url": "http://arxiv.org/pdf/2203.04271v1", "repo_url": null}, "2203.04236": {"publish_time": "2022-03-08", "title": "A Sharp Characterization of Linear Estimators for Offline Policy Evaluation", "author": "Juan C. Perdomo et.al.", "abstract": "Offline policy evaluation is a fundamental statistical problem in reinforcement learning that involves estimating the value function of some decision-making policy given data collected by a potentially different policy. In order to tackle problems with complex, high-dimensional observations, there has been significant interest from theoreticians and practitioners alike in understanding the possibility of function approximation in reinforcement learning. Despite significant study, a sharp characterization of when we might expect offline policy evaluation to be tractable, even in the simplest setting of linear function approximation, has so far remained elusive, with a surprising number of strong negative results recently appearing in the literature.   In this work, we identify simple control-theoretic and linear-algebraic conditions that are necessary and sufficient for classical methods, in particular Fitted Q-iteration (FQI) and least squares temporal difference learning (LSTD), to succeed at offline policy evaluation. Using this characterization, we establish a precise hierarchy of regimes under which these estimators succeed. We prove that LSTD works under strictly weaker conditions than FQI. Furthermore, we establish that if a problem is not solvable via LSTD, then it cannot be solved by a broad class of linear estimators, even in the limit of infinite data. Taken together, our results provide a complete picture of the behavior of linear estimators for offline policy evaluation (OPE), unify previously disparate analyses of canonical algorithms, and provide significantly sharper notions of the underlying statistical complexity of OPE.", "paper_url": "http://arxiv.org/abs/2203.04236v1", "pdf_url": "http://arxiv.org/pdf/2203.04236v1", "repo_url": null}, "2203.04227": {"publish_time": "2022-03-08", "title": "Learning based Age of Information Minimization in UAV-relayed IoT Networks", "author": "Biplav Choudhury et.al.", "abstract": "Unmanned Aerial Vehicles (UAVs) are used as aerial base-stations to relay time-sensitive packets from IoT devices to the nearby terrestrial base-station (TBS). Scheduling of packets in such UAV-relayed IoT-networks to ensure fresh (or up-to-date) IoT devices' packets at the TBS is a challenging problem as it involves two simultaneous steps of (i) sampling of packets generated at IoT devices by the UAVs [hop-1] and (ii) updating of sampled packets from UAVs to the TBS [hop-2]. To address this, we propose Age-of-Information (AoI) scheduling algorithms for two-hop UAV-relayed IoT-networks. First, we propose a low-complexity AoI scheduler, termed, MAF-MAD that employs Maximum AoI First (MAF) policy for sampling of IoT devices at UAV (hop-1) and Maximum AoI Difference (MAD) policy for updating sampled packets from UAV to the TBS (hop-2). We prove that MAF-MAD is the optimal AoI scheduler under ideal conditions (lossless wireless channels and generate-at-will traffic-generation at IoT devices). On the contrary, for general conditions (lossy channel conditions and varying periodic traffic-generation at IoT devices), a deep reinforcement learning algorithm, namely, Proximal Policy Optimization (PPO)-based scheduler is proposed. Simulation results show that the proposed PPO-based scheduler outperforms other schedulers like MAF-MAD, MAF, and round-robin in all considered general scenarios.", "paper_url": "http://arxiv.org/abs/2203.04227v1", "pdf_url": "http://arxiv.org/pdf/2203.04227v1", "repo_url": null}, "2203.04172": {"publish_time": "2022-03-08", "title": "Distributed Control using Reinforcement Learning with Temporal-Logic-Based Reward Shaping", "author": "Ningyuan Zhang et.al.", "abstract": "We present a computational framework for synthesis of distributed control strategies for a heterogeneous team of robots in a partially observable environment. The goal is to cooperatively satisfy specifications given as Truncated Linear Temporal Logic (TLTL) formulas. Our approach formulates the synthesis problem as a stochastic game and employs a policy graph method to find a control strategy with memory for each agent. We construct the stochastic game on the product between the team transition system and a finite state automaton (FSA) that tracks the satisfaction of the TLTL formula. We use the quantitative semantics of TLTL as the reward of the game, and further reshape it using the FSA to guide and accelerate the learning process. Simulation results demonstrate the efficacy of the proposed solution under demanding task specifications and the effectiveness of reward shaping in significantly accelerating the speed of learning.", "paper_url": "http://arxiv.org/abs/2203.04172v1", "pdf_url": "http://arxiv.org/pdf/2203.04172v1", "repo_url": null}, "2203.04927": {"publish_time": "2022-03-09", "title": "Investigation of Factorized Optical Flows as Mid-Level Representations", "author": "Hsuan-Kung Yang et.al.", "abstract": "In this paper, we introduce a new concept of incorporating factorized flow maps as mid-level representations, for bridging the perception and the control modules in modular learning based robotic frameworks. To investigate the advantages of factorized flow maps and examine their interplay with the other types of mid-level representations, we further develop a configurable framework, along with four different environments that contain both static and dynamic objects, for analyzing the impacts of factorized optical flow maps on the performance of deep reinforcement learning agents. Based on this framework, we report our experimental results on various scenarios, and offer a set of analyses to justify our hypothesis. Finally, we validate flow factorization in real world scenarios.", "paper_url": "http://arxiv.org/abs/2203.04927v1", "pdf_url": "http://arxiv.org/pdf/2203.04927v1", "repo_url": null}, "2203.04923": {"publish_time": "2022-03-09", "title": "On-Robot Policy Learning with $\\mathrm{O}(2)$-Equivariant SAC", "author": "Dian Wang et.al.", "abstract": "Recently, equivariant neural network models have been shown to be useful in improving sample efficiency for tasks in computer vision and reinforcement learning. This paper explores this idea in the context of on-robot policy learning where a policy must be learned entirely on a physical robotic system without reference to a model, a simulator, or an offline dataset. We focus on applications of $\\mathrm{SO}(2)$-Equivariant SAC to robotic manipulation and explore a number of variations of the algorithm. Ultimately, we demonstrate the ability to learn several non-trivial manipulation tasks completely through on-robot experiences in less than an hour or two of wall clock time.", "paper_url": "http://arxiv.org/abs/2203.04923v1", "pdf_url": "http://arxiv.org/pdf/2203.04923v1", "repo_url": null}, "2203.04857": {"publish_time": "2022-03-09", "title": "Neuro-symbolic Natural Logic with Introspective Revision for Natural Language Inference", "author": "Yufei Feng et.al.", "abstract": "We introduce a neuro-symbolic natural logic framework based on reinforcement learning with introspective revision. The model samples and rewards specific reasoning paths through policy gradient, in which the introspective revision algorithm modifies intermediate symbolic reasoning steps to discover reward-earning operations as well as leverages external knowledge to alleviate spurious reasoning and training inefficiency. The framework is supported by properly designed local relation models to avoid input entangling, which helps ensure the interpretability of the proof paths. The proposed model has built-in interpretability and shows superior capability in monotonicity inference, systematic generalization, and interpretability, compared to previous models on the existing datasets.", "paper_url": "http://arxiv.org/abs/2203.04857v1", "pdf_url": "http://arxiv.org/pdf/2203.04857v1", "repo_url": null}, "2203.04791": {"publish_time": "2022-03-09", "title": "Dimensionality Reduction and Prioritized Exploration for Policy Search", "author": "Marius Memmel et.al.", "abstract": "Black-box policy optimization is a class of reinforcement learning algorithms that explores and updates the policies at the parameter level. This class of algorithms is widely applied in robotics with movement primitives or non-differentiable policies. Furthermore, these approaches are particularly relevant where exploration at the action level could cause actuator damage or other safety issues. However, Black-box optimization does not scale well with the increasing dimensionality of the policy, leading to high demand for samples, which are expensive to obtain in real-world systems. In many practical applications, policy parameters do not contribute equally to the return. Identifying the most relevant parameters allows to narrow down the exploration and speed up the learning. Furthermore, updating only the effective parameters requires fewer samples, improving the scalability of the method. We present a novel method to prioritize the exploration of effective parameters and cope with full covariance matrix updates. Our algorithm learns faster than recent approaches and requires fewer samples to achieve state-of-the-art results. To select the effective parameters, we consider both the Pearson correlation coefficient and the Mutual Information. We showcase the capabilities of our approach on the Relative Entropy Policy Search algorithm in several simulated environments, including robotics simulations. Code is available at https://git.ias.informatik.tu-darmstadt.de/ias\\_code/aistats2022/dr-creps}{git.ias.informatik.tu-darmstadt.de/ias\\_code/aistats2022/dr-creps.", "paper_url": "http://arxiv.org/abs/2203.04791v1", "pdf_url": "http://arxiv.org/pdf/2203.04791v1", "repo_url": null}, "2203.04700": {"publish_time": "2022-03-09", "title": "Multi-robot Cooperative Pursuit via Potential Field-Enhanced Reinforcement Learning", "author": "Zheng Zhang et.al.", "abstract": "It is of great challenge, though promising, to coordinate collective robots for hunting an evader in a decentralized manner purely in light of local observations. In this paper, this challenge is addressed by a novel hybrid cooperative pursuit algorithm that combines reinforcement learning with the artificial potential field method. In the proposed algorithm, decentralized deep reinforcement learning is employed to learn cooperative pursuit policies that are adaptive to dynamic environments. The artificial potential field method is integrated into the learning process as predefined rules to improve the data efficiency and generalization ability. It is shown by numerical simulations that the proposed hybrid design outperforms the pursuit policies either learned from vanilla reinforcement learning or designed by the potential field method. Furthermore, experiments are conducted by transferring the learned pursuit policies into real-world mobile robots. Experimental results demonstrate the feasibility and potential of the proposed algorithm in learning multiple cooperative pursuit strategies.", "paper_url": "http://arxiv.org/abs/2203.04700v1", "pdf_url": "http://arxiv.org/pdf/2203.04700v1", "repo_url": null}, "2203.05449": {"publish_time": "2022-03-10", "title": "Artificial Intelligence in Vehicular Wireless Networks: A Case Study Using ns-3", "author": "Matteo Drago et.al.", "abstract": "Artificial intelligence (AI) techniques have emerged as a powerful approach to make wireless networks more efficient and adaptable. In this paper we present an ns-3 simulation framework, able to implement AI algorithms for the optimization of wireless networks. Our pipeline consists of: (i) a new geometry-based mobility-dependent channel model for V2X; (ii) all the layers of a 5G-NR-compliant protocol stack, based on the ns3-mmwave module; (iii) a new application to simulate V2X data transmission, and (iv) a new intelligent entity for the control of the network via AI. Thanks to its flexible and modular design, researchers can use this tool to implement, train, and evaluate their own algorithms in a realistic and controlled environment. We test the behavior of our framework in a Predictive Quality of Service (PQoS) scenario, where AI functionalities are implemented using Reinforcement Learning (RL), and demonstrate that it promotes better network optimization compared to baseline solutions that do not implement AI.", "paper_url": "http://arxiv.org/abs/2203.05449v1", "pdf_url": "http://arxiv.org/pdf/2203.05449v1", "repo_url": null}, "2203.05434": {"publish_time": "2022-03-10", "title": "Near-optimal Deep Reinforcement Learning Policies from Data for Zone Temperature Control", "author": "Loris Di Natale et.al.", "abstract": "Replacing poorly performing existing controllers with smarter solutions will decrease the energy intensity of the building sector. Recently, controllers based on Deep Reinforcement Learning (DRL) have been shown to be more effective than conventional baselines. However, since the optimal solution is usually unknown, it is still unclear if DRL agents are attaining near-optimal performance in general or if there is still a large gap to bridge.   In this paper, we investigate the performance of DRL agents compared to the theoretically optimal solution. To that end, we leverage Physically Consistent Neural Networks (PCNNs) as simulation environments, for which optimal control inputs are easy to compute. Furthermore, PCNNs solely rely on data to be trained, avoiding the difficult physics-based modeling phase, while retaining physical consistency. Our results hint that DRL agents not only clearly outperform conventional rule-based controllers, they furthermore attain near-optimal performance.", "paper_url": "http://arxiv.org/abs/2203.05434v1", "pdf_url": "http://arxiv.org/pdf/2203.05434v1", "repo_url": null}, "2203.05360": {"publish_time": "2022-03-10", "title": "Deep Residual Reinforcement Learning based Autonomous Blimp Control", "author": "Yu Tang Liu et.al.", "abstract": "Blimps are well suited to perform long-duration aerial tasks as they are energy efficient, relatively silent and safe. To address the blimp navigation and control task, in previous work we developed a hardware and software-in-the-loop framework and a PID-based controller for large blimps in the presence of wind disturbance. However, blimps have a deformable structure and their dynamics are inherently non-linear and time-delayed, making PID controllers difficult to tune. Thus, often resulting in large tracking errors. Moreover, the buoyancy of a blimp is constantly changing due to variations in ambient temperature and pressure. To address these issues, in this paper we present a learning-based framework based on deep residual reinforcement learning (DRRL), for the blimp control task. Within this framework, we first employ a PID controller to provide baseline performance. Subsequently, the DRRL agent learns to modify the PID decisions by interaction with the environment. We demonstrate in simulation that DRRL agent consistently improves the PID performance. Through rigorous simulation experiments, we show that the agent is robust to changes in wind speed and buoyancy. In real-world experiments, we demonstrate that the agent, trained only in simulation, is sufficiently robust to control an actual blimp in windy conditions. We openly provide the source code of our approach at https://github.com/ robot-perception-group/AutonomousBlimpDRL.", "paper_url": "http://arxiv.org/abs/2203.05360v1", "pdf_url": "http://arxiv.org/pdf/2203.05360v1", "repo_url": "https://github.com/robot-perception-group/autonomousblimpdrl"}, "2203.05285": {"publish_time": "2022-03-10", "title": "API: Boosting Multi-Agent Reinforcement Learning via Agent-Permutation-Invariant Networks", "author": "Xiaotian Hao et.al.", "abstract": "Multi-agent reinforcement learning suffers from poor sample efficiency due to the exponential growth of the state-action space. Considering a homogeneous multiagent system, a global state consisting of $m$ homogeneous components has $m!$ differently ordered representations, thus designing functions satisfying permutation invariant (PI) can reduce the state space by a factor of $\\frac{1}{m!}$. However, mainstream MARL algorithms ignore this property and learn over the original state space. To achieve PI, previous works including data augmentation based methods and embedding-sharing architecture based methods, suffer from training instability and limited model capacity. In this work, we propose two novel designs to achieve PI, while avoiding the above limitations. The first design permutes the same but differently ordered inputs back to the same order and the downstream networks only need to learn function mapping over fixed-ordering inputs instead of all permutations, which is much easier to train. The second design applies a hypernetwork to generate customized embedding for each component, which has higher representational capacity than the previous embedding-sharing method. Empirical results on the SMAC benchmark show that the proposed method achieves 100% win-rates in almost all hard and super-hard scenarios (never achieved before), and superior sample-efficiency than the state-of-the-art baselines by up to 400%.", "paper_url": "http://arxiv.org/abs/2203.05285v1", "pdf_url": "http://arxiv.org/pdf/2203.05285v1", "repo_url": "https://github.com/tju-drl-lab/api-marl"}, "2203.05194": {"publish_time": "2022-03-10", "title": "Learning Torque Control for Quadrupedal Locomotion", "author": "Shuxiao Chen et.al.", "abstract": "Reinforcement learning (RL) is a promising tool for developing controllers for quadrupedal locomotion. The design of most learning-based locomotion controllers adopts the joint position-based paradigm, wherein a low-frequency RL policy outputs target joint positions that are then tracked by a high-frequency proportional-derivative (PD) controller that outputs joint torques. However, the low frequency of such a policy hinders the advancement of highly dynamic locomotion behaviors. Moreover, determining the PD gains for optimal tracking performance is laborious and dependent on the task at hand. In this paper, we introduce a learning torque control framework for quadrupedal locomotion, which trains an RL policy that directly predicts joint torques at a high frequency, thus circumventing the use of PD controllers. We validate the proposed framework with extensive experiments where the robot is able to both traverse various terrains and resist external pushes, given user-specified commands. To our knowledge, this is the first attempt of learning torque control for quadrupedal locomotion with an end-to-end single neural network that has led to successful real-world experiments among recent research on learning-based quadrupedal locomotion which is mostly position-based.", "paper_url": "http://arxiv.org/abs/2203.05194v1", "pdf_url": "http://arxiv.org/pdf/2203.05194v1", "repo_url": null}, "2203.06173": {"publish_time": "2022-03-11", "title": "Masked Visual Pre-training for Motor Control", "author": "Tete Xiao et.al.", "abstract": "This paper shows that self-supervised visual pre-training from real-world images is effective for learning motor control tasks from pixels. We first train the visual representations by masked modeling of natural images. We then freeze the visual encoder and train neural network controllers on top with reinforcement learning. We do not perform any task-specific fine-tuning of the encoder; the same visual representations are used for all motor control tasks. To the best of our knowledge, this is the first self-supervised model to exploit real-world images at scale for motor control. To accelerate progress in learning from pixels, we contribute a benchmark suite of hand-designed tasks varying in movements, scenes, and robots. Without relying on labels, state-estimation, or expert demonstrations, we consistently outperform supervised encoders by up to 80% absolute success rate, sometimes even matching the oracle state performance. We also find that in-the-wild images, e.g., from YouTube or Egocentric videos, lead to better visual representations for various manipulation tasks than ImageNet images.", "paper_url": "http://arxiv.org/abs/2203.06173v1", "pdf_url": "http://arxiv.org/pdf/2203.06173v1", "repo_url": null}, "2203.06053": {"publish_time": "2022-03-11", "title": "A Machine Learning Approach for Prosumer Management in Intraday Electricity Markets", "author": "Saeed Mohammadi et.al.", "abstract": "Prosumer operators are dealing with extensive challenges to participate in short-term electricity markets while taking uncertainties into account. Challenges such as variation in demand, solar energy, wind power, and electricity prices as well as faster response time in intraday electricity markets. Machine learning approaches could resolve these challenges due to their ability to continuous learning of complex relations and providing a real-time response. Such approaches are applicable with presence of the high performance computing and big data. To tackle these challenges, a Markov decision process is proposed and solved with a reinforcement learning algorithm with proper observations and actions employing tabular Q-learning. Trained agent converges to a policy which is similar to the global optimal solution. It increases the prosumer's profit by 13.39% compared to the well-known stochastic optimization approach.", "paper_url": "http://arxiv.org/abs/2203.06053v1", "pdf_url": "http://arxiv.org/pdf/2203.06053v1", "repo_url": null}, "2203.05985": {"publish_time": "2022-03-11", "title": "Graph Neural Networks for Relational Inductive Bias in Vision-based Deep Reinforcement Learning of Robot Control", "author": "Marco Oliva et.al.", "abstract": "State-of-the-art reinforcement learning algorithms predominantly learn a policy from either a numerical state vector or images. Both approaches generally do not take structural knowledge of the task into account, which is especially prevalent in robotic applications and can benefit learning if exploited. This work introduces a neural network architecture that combines relational inductive bias and visual feedback to learn an efficient position control policy for robotic manipulation. We derive a graph representation that models the physical structure of the manipulator and combines the robot's internal state with a low-dimensional description of the visual scene generated by an image encoding network. On this basis, a graph neural network trained with reinforcement learning predicts joint velocities to control the robot. We further introduce an asymmetric approach of training the image encoder separately from the policy using supervised learning. Experimental results demonstrate that, for a 2-DoF planar robot in a geometrically simplistic 2D environment, a learned representation of the visual scene can replace access to the explicit coordinates of the reaching target without compromising on the quality and sample efficiency of the policy. We further show the ability of the model to improve sample efficiency for a 6-DoF robot arm in a visually realistic 3D environment.", "paper_url": "http://arxiv.org/abs/2203.05985v1", "pdf_url": "http://arxiv.org/pdf/2203.05985v1", "repo_url": null}, "2203.05804": {"publish_time": "2022-03-11", "title": "Near-optimal Offline Reinforcement Learning with Linear Representation: Leveraging Variance Information with Pessimism", "author": "Ming Yin et.al.", "abstract": "Offline reinforcement learning, which seeks to utilize offline/historical data to optimize sequential decision-making strategies, has gained surging prominence in recent studies. Due to the advantage that appropriate function approximators can help mitigate the sample complexity burden in modern reinforcement learning problems, existing endeavors usually enforce powerful function representation models (e.g. neural networks) to learn the optimal policies. However, a precise understanding of the statistical limits with function representations, remains elusive, even when such a representation is linear.   Towards this goal, we study the statistical limits of offline reinforcement learning with linear model representations. To derive the tight offline learning bound, we design the variance-aware pessimistic value iteration (VAPVI), which adopts the conditional variance information of the value function for time-inhomogeneous episodic linear Markov decision processes (MDPs). VAPVI leverages estimated variances of the value functions to reweight the Bellman residuals in the least-square pessimistic value iteration and provides improved offline learning bounds over the best-known existing results (whereas the Bellman residuals are equally weighted by design). More importantly, our learning bounds are expressed in terms of system quantities, which provide natural instance-dependent characterizations that previous results are short of. We hope our results draw a clearer picture of what offline learning should look like when linear representations are provided.", "paper_url": "http://arxiv.org/abs/2203.05804v1", "pdf_url": "http://arxiv.org/pdf/2203.05804v1", "repo_url": null}, "2203.05775": {"publish_time": "2022-03-11", "title": "Physics-informed Reinforcement Learning for Perception and Reasoning about Fluids", "author": "Beatriz Moya et.al.", "abstract": "Learning and reasoning about physical phenomena is still a challenge in robotics development, and computational sciences play a capital role in the search for accurate methods able to provide explanations for past events and rigorous forecasts of future situations. We propose a physics-informed reinforcement learning strategy for fluid perception and reasoning from observations. As a model problem, we take the sloshing phenomena of different fluids contained in a glass. Starting from full-field and high-resolution synthetic data for a particular fluid, we develop a method for the tracking (perception) and analysis (reasoning) of any previously unseen liquid whose free surface is observed with a commodity camera. This approach demonstrates the importance of physics and knowledge not only in data-driven (grey box) modeling but also in the correction for real physics adaptation in low data regimes and partial observations of the dynamics. The method here presented is extensible to other domains such as the development of cognitive digital twins, able to learn from observation of phenomena for which they have not been trained explicitly.", "paper_url": "http://arxiv.org/abs/2203.05775v1", "pdf_url": "http://arxiv.org/pdf/2203.05775v1", "repo_url": "https://github.com/beatrizmoya/rlfluidperception"}, "2203.07368": {"publish_time": "2022-03-14", "title": "The Efficacy of Pessimism in Asynchronous Q-Learning", "author": "Yuling Yan et.al.", "abstract": "This paper is concerned with the asynchronous form of Q-learning, which applies a stochastic approximation scheme to Markovian data samples. Motivated by the recent advances in offline reinforcement learning, we develop an algorithmic framework that incorporates the principle of pessimism into asynchronous Q-learning, which penalizes infrequently-visited state-action pairs based on suitable lower confidence bounds (LCBs). This framework leads to, among other things, improved sample efficiency and enhanced adaptivity in the presence of near-expert data. Our approach permits the observed data in some important scenarios to cover only partial state-action space, which is in stark contrast to prior theory that requires uniform coverage of all state-action pairs. When coupled with the idea of variance reduction, asynchronous Q-learning with LCB penalization achieves near-optimal sample complexity, provided that the target accuracy level is small enough. In comparison, prior works were suboptimal in terms of the dependency on the effective horizon even when i.i.d. sampling is permitted. Our results deliver the first theoretical support for the use of pessimism principle in the presence of Markovian non-i.i.d. data.", "paper_url": "http://arxiv.org/abs/2203.07368v1", "pdf_url": "http://arxiv.org/pdf/2203.07368v1", "repo_url": null}, "2203.07322": {"publish_time": "2022-03-14", "title": "Efficient Model-based Multi-agent Reinforcement Learning via Optimistic Equilibrium Computation", "author": "Pier Giuseppe Sessa et.al.", "abstract": "We consider model-based multi-agent reinforcement learning, where the environment transition model is unknown and can only be learned via expensive interactions with the environment. We propose H-MARL (Hallucinated Multi-Agent Reinforcement Learning), a novel sample-efficient algorithm that can efficiently balance exploration, i.e., learning about the environment, and exploitation, i.e., achieve good equilibrium performance in the underlying general-sum Markov game. H-MARL builds high-probability confidence intervals around the unknown transition model and sequentially updates them based on newly observed data. Using these, it constructs an optimistic hallucinated game for the agents for which equilibrium policies are computed at each round. We consider general statistical models (e.g., Gaussian processes, deep ensembles, etc.) and policy classes (e.g., deep neural networks), and theoretically analyze our approach by bounding the agents' dynamic regret. Moreover, we provide a convergence rate to the equilibria of the underlying Markov game. We demonstrate our approach experimentally on an autonomous driving simulation benchmark. H-MARL learns successful equilibrium policies after a few interactions with the environment and can significantly improve the performance compared to non-exploratory methods.", "paper_url": "http://arxiv.org/abs/2203.07322v1", "pdf_url": "http://arxiv.org/pdf/2203.07322v1", "repo_url": null}, "2203.07276": {"publish_time": "2022-03-14", "title": "FRL-FI: Transient Fault Analysis for Federated Reinforcement Learning-Based Navigation Systems", "author": "Zishen Wan et.al.", "abstract": "Swarm intelligence is being increasingly deployed in autonomous systems, such as drones and unmanned vehicles. Federated reinforcement learning (FRL), a key swarm intelligence paradigm where agents interact with their own environments and cooperatively learn a consensus policy while preserving privacy, has recently shown potential advantages and gained popularity. However, transient faults are increasing in the hardware system with continuous technology node scaling and can pose threats to FRL systems. Meanwhile, conventional redundancy-based protection methods are challenging to deploy on resource-constrained edge applications. In this paper, we experimentally evaluate the fault tolerance of FRL navigation systems at various scales with respect to fault models, fault locations, learning algorithms, layer types, communication intervals, and data types at both training and inference stages. We further propose two cost-effective fault detection and recovery techniques that can achieve up to 3.3x improvement in resilience with <2.7% overhead in FRL systems.", "paper_url": "http://arxiv.org/abs/2203.07276v1", "pdf_url": "http://arxiv.org/pdf/2203.07276v1", "repo_url": null}, "2203.07263": {"publish_time": "2022-03-14", "title": "Logical shadow tomography: Efficient estimation of error-mitigated observables", "author": "Hong-Ye Hu et.al.", "abstract": "We introduce a technique to estimate error-mitigated expectation values on noisy quantum computers. Our technique performs shadow tomography on a logical state to produce a memory-efficient classical reconstruction of the noisy density matrix. Using efficient classical post-processing, one can mitigate errors by projecting a general nonlinear function of the noisy density matrix into the codespace. The subspace expansion and virtual distillation can be viewed as special cases of the new framekwork. We show our method is favorable in the quantum and classical resources overhead. Relative to subspace expansion which requires $O\\left(2^{N} \\right)$ samples to estimate a logical Pauli observable with $[[N, k]]$ error correction code, our technique requires only $O\\left(4^{k} \\right)$ samples. Relative to virtual distillation, our technique can compute powers of the density matrix without additional copies of quantum states or quantum memory. We present numerical evidence using logical states encoded with up to sixty physical qubits and show fast convergence to error-free expectation values with only $10^5$ samples under 1% depolarizing noise.", "paper_url": "http://arxiv.org/abs/2203.07263v1", "pdf_url": "http://arxiv.org/pdf/2203.07263v1", "repo_url": null}, "2203.07196": {"publish_time": "2022-03-14", "title": "Optimising low-Reynolds-number predation via optimal control and reinforcement learning", "author": "Guangpu Zhu et.al.", "abstract": "We seek the best stroke sequences of a finite-size swimming predator chasing a non-motile point or finite--size prey at low Reynolds number. We use optimal control to seek the globally-optimal solutions for the former and RL for general situations. The predator is represented by a squirmer model that can translate forward and laterally, rotate and generate a stresslet flow. We identify the predator's best squirming sequences to achieve the time-optimal (TO) and efficiency-optimal (EO) predation. For a point prey, the TO squirmer executing translational motions favours a two-fold L-shaped trajectory that enables it to exploit the disturbance flow for accelerated predation; using a stresslet mode significantly expedites the EO predation, allowing the predator to catch the prey faster yet with lower energy consumption and higher predatory efficiency; the predator can harness its stresslet disturbance flow to suck the prey towards itself; compared to a translating predator, its compeer combining translation and rotation is less time--efficient, and the latter occasionally achieves the TO predation via retreating in order to advance. We also adopt RL to reproduce the globally-optimal predatory strategy of chasing a point prey, qualitatively capturing the crucial two--fold attribute of TO path. Using a numerically emulated RL environment, we explore the dependence of the optimal predatory path on the size of prey. Our results might provide useful information that help design synthetic microswimmers such as \\textit{in vivo} medical micro-robots capable of capturing and approaching objects in viscous flows.", "paper_url": "http://arxiv.org/abs/2203.07196v1", "pdf_url": "http://arxiv.org/pdf/2203.07196v1", "repo_url": null}, "2203.08098": {"publish_time": "2022-03-15", "title": "RB2: Robotic Manipulation Benchmarking with a Twist", "author": "Sudeep Dasari et.al.", "abstract": "Benchmarks offer a scientific way to compare algorithms using objective performance metrics. Good benchmarks have two features: (a) they should be widely useful for many research groups; (b) and they should produce reproducible findings. In robotic manipulation research, there is a trade-off between reproducibility and broad accessibility. If the benchmark is kept restrictive (fixed hardware, objects), the numbers are reproducible but the setup becomes less general. On the other hand, a benchmark could be a loose set of protocols (e.g. object sets) but the underlying variation in setups make the results non-reproducible. In this paper, we re-imagine benchmarking for robotic manipulation as state-of-the-art algorithmic implementations, alongside the usual set of tasks and experimental protocols. The added baseline implementations will provide a way to easily recreate SOTA numbers in a new local robotic setup, thus providing credible relative rankings between existing approaches and new work. However, these local rankings could vary between different setups. To resolve this issue, we build a mechanism for pooling experimental data between labs, and thus we establish a single global ranking for existing (and proposed) SOTA algorithms. Our benchmark, called Ranking-Based Robotics Benchmark (RB2), is evaluated on tasks that are inspired from clinically validated Southampton Hand Assessment Procedures. Our benchmark was run across two different labs and reveals several surprising findings. For example, extremely simple baselines like open-loop behavior cloning, outperform more complicated models (e.g. closed loop, RNN, Offline-RL, etc.) that are preferred by the field. We hope our fellow researchers will use RB2 to improve their research's quality and rigor.", "paper_url": "http://arxiv.org/abs/2203.08098v1", "pdf_url": "http://arxiv.org/pdf/2203.08098v1", "repo_url": null}, "2203.07889": {"publish_time": "2022-03-15", "title": "Comparing two samples through stochastic dominance: a graphical approach", "author": "Etor Arza et.al.", "abstract": "Non-deterministic measurements are common in real-world scenarios: the performance of a stochastic optimization algorithm or the total reward of a reinforcement learning agent in a chaotic environment are just two examples in which unpredictable outcomes are common. These measures can be modeled as random variables and compared among each other via their expected values or more sophisticated tools such as null hypothesis statistical tests. In this paper, we propose an alternative framework to visually compare two samples according to their estimated cumulative distribution functions. First, we introduce a dominance measure for two random variables that quantifies the proportion in which the cumulative distribution function of one of the random variables scholastically dominates the other one. Then, we present a graphical method that decomposes in quantiles i) the proposed dominance measure and ii) the probability that one of the random variables takes lower values than the other. With illustrative purposes, we re-evaluate the experimentation of an already published work with the proposed methodology and we show that additional conclusions (missed by the rest of the methods) can be inferred. Additionally, the software package RVCompare was created as a convenient way of applying and experimenting with the proposed framework.", "paper_url": "http://arxiv.org/abs/2203.07889v1", "pdf_url": "http://arxiv.org/pdf/2203.07889v1", "repo_url": "https://github.com/etorarza/supplementarypaperrvcompare"}, "2203.07709": {"publish_time": "2022-03-15", "title": "Adaptive Environment Modeling Based Reinforcement Learning for Collision Avoidance in Complex Scenes", "author": "Shuaijun Wang et.al.", "abstract": "The major challenges of collision avoidance for robot navigation in crowded scenes lie in accurate environment modeling, fast perceptions, and trustworthy motion planning policies. This paper presents a novel adaptive environment model based collision avoidance reinforcement learning (i.e., AEMCARL) framework for an unmanned robot to achieve collision-free motions in challenging navigation scenarios. The novelty of this work is threefold: (1) developing a hierarchical network of gated-recurrent-unit (GRU) for environment modeling; (2) developing an adaptive perception mechanism with an attention module; (3) developing an adaptive reward function for the reinforcement learning (RL) framework to jointly train the environment model, perception function and motion planning policy. The proposed method is tested with the Gym-Gazebo simulator and a group of robots (Husky and Turtlebot) under various crowded scenes. Both simulation and experimental results have demonstrated the superior performance of the proposed method over baseline methods.", "paper_url": "http://arxiv.org/abs/2203.07709v1", "pdf_url": "http://arxiv.org/pdf/2203.07709v1", "repo_url": "https://github.com/sjwang2015/aemcarl"}, "2203.07676": {"publish_time": "2022-03-15", "title": "An Introduction to Multi-Agent Reinforcement Learning and Review of its Application to Autonomous Mobility", "author": "Lukas M. Schmidt et.al.", "abstract": "Many scenarios in mobility and traffic involve multiple different agents that need to cooperate to find a joint solution. Recent advances in behavioral planning use Reinforcement Learning to find effective and performant behavior strategies. However, as autonomous vehicles and vehicle-to-X communications become more mature, solutions that only utilize single, independent agents leave potential performance gains on the road. Multi-Agent Reinforcement Learning (MARL) is a research field that aims to find optimal solutions for multiple agents that interact with each other. This work aims to give an overview of the field to researchers in autonomous mobility. We first explain MARL and introduce important concepts. Then, we discuss the central paradigms that underlie MARL algorithms, and give an overview of state-of-the-art methods and ideas in each paradigm. With this background, we survey applications of MARL in autonomous mobility scenarios and give an overview of existing scenarios and implementations.", "paper_url": "http://arxiv.org/abs/2203.07676v1", "pdf_url": "http://arxiv.org/pdf/2203.07676v1", "repo_url": null}, "2203.07632": {"publish_time": "2022-03-15", "title": "Graph Representation Learning for Popularity Prediction Problem: A Survey", "author": "Tiantian Chen et.al.", "abstract": "The online social platforms, like Twitter, Facebook, LinkedIn and WeChat, have grown really fast in last decade and have been one of the most effective platforms for people to communicate and share information with each other. Due to the \"word of mouth\" effects, information usually can spread rapidly on these social media platforms. Therefore, it is important to study the mechanisms driving the information diffusion and quantify the consequence of information spread. A lot of efforts have been focused on this problem to help us better understand and achieve higher performance in viral marketing and advertising. On the other hand, the development of neural networks has blossomed in the last few years, leading to a large number of graph representation learning (GRL) models. Compared to traditional models, GRL methods are often shown to be more effective. In this paper, we present a comprehensive review for existing works using GRL methods for popularity prediction problem, and categorize related literatures into two big classes, according to their mainly used model and techniques: embedding-based methods and deep learning methods. Deep learning method is further classified into six small classes: convolutional neural networks, graph convolutional networks, graph attention networks, graph neural networks, recurrent neural networks, and reinforcement learning. We compare the performance of these different models and discuss their strengths and limitations. Finally, we outline the challenges and future chances for popularity prediction problem.", "paper_url": "http://arxiv.org/abs/2203.07632v1", "pdf_url": "http://arxiv.org/pdf/2203.07632v1", "repo_url": null}, "2203.08553": {"publish_time": "2022-03-16", "title": "PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration", "author": "Pengyi Li et.al.", "abstract": "Learning to collaborate is critical in multi-agent reinforcement learning (MARL). A number of previous works promote collaboration by maximizing the correlation of agents' behaviors, which is typically characterised by mutual information (MI) in different forms. However, in this paper, we reveal that strong correlation can emerge from sub-optimal collaborative behaviors, and simply maximizing the MI can, surprisingly, hinder the learning towards better collaboration. To address this issue, we propose a novel MARL framework, called Progressive Mutual Information Collaboration (PMIC), for more effective MI-driven collaboration. In PMIC, we use a new collaboration criterion measured by the MI between global states and joint actions. Based on the criterion, the key idea of PMIC is maximizing the MI associated with superior collaborative behaviors and minimizing the MI associated with inferior ones. The two MI objectives play complementary roles by facilitating learning towards better collaborations while avoiding falling into sub-optimal ones. Specifically, PMIC stores and progressively maintains sets of superior and inferior interaction experiences, from which dual MI neural estimators are established. Experiments on a wide range of MARL benchmarks show the superior performance of PMIC compared with other algorithms.", "paper_url": "http://arxiv.org/abs/2203.08553v1", "pdf_url": "http://arxiv.org/pdf/2203.08553v1", "repo_url": null}, "2203.08542": {"publish_time": "2022-03-16", "title": "Lazy-MDPs: Towards Interpretable Reinforcement Learning by Learning When to Act", "author": "Alexis Jacq et.al.", "abstract": "Traditionally, Reinforcement Learning (RL) aims at deciding how to act optimally for an artificial agent. We argue that deciding when to act is equally important. As humans, we drift from default, instinctive or memorized behaviors to focused, thought-out behaviors when required by the situation. To enhance RL agents with this aptitude, we propose to augment the standard Markov Decision Process and make a new mode of action available: being lazy, which defers decision-making to a default policy. In addition, we penalize non-lazy actions in order to encourage minimal effort and have agents focus on critical decisions only. We name the resulting formalism lazy-MDPs. We study the theoretical properties of lazy-MDPs, expressing value functions and characterizing optimal solutions. Then we empirically demonstrate that policies learned in lazy-MDPs generally come with a form of interpretability: by construction, they show us the states where the agent takes control over the default policy. We deem those states and corresponding actions important since they explain the difference in performance between the default and the new, lazy policy. With suboptimal policies as default (pretrained or random), we observe that agents are able to get competitive performance in Atari games while only taking control in a limited subset of states.", "paper_url": "http://arxiv.org/abs/2203.08542v1", "pdf_url": "http://arxiv.org/pdf/2203.08542v1", "repo_url": null}, "2203.08454": {"publish_time": "2022-03-16", "title": "Coach-assisted Multi-Agent Reinforcement Learning Framework for Unexpected Crashed Agents", "author": "Jian Zhao et.al.", "abstract": "Multi-agent reinforcement learning is difficult to be applied in practice, which is partially due to the gap between the simulated and real-world scenarios. One reason for the gap is that the simulated systems always assume that the agents can work normally all the time, while in practice, one or more agents may unexpectedly \"crash\" during the coordination process due to inevitable hardware or software failures. Such crashes will destroy the cooperation among agents, leading to performance degradation. In this work, we present a formal formulation of a cooperative multi-agent reinforcement learning system with unexpected crashes. To enhance the robustness of the system to crashes, we propose a coach-assisted multi-agent reinforcement learning framework, which introduces a virtual coach agent to adjust the crash rate during training. We design three coaching strategies and the re-sampling strategy for our coach agent. To the best of our knowledge, this work is the first to study the unexpected crashes in the multi-agent system. Extensive experiments on grid-world and StarCraft II micromanagement tasks demonstrate the efficacy of adaptive strategy compared with the fixed crash rate strategy and curriculum learning strategy. The ablation study further illustrates the effectiveness of our re-sampling strategy.", "paper_url": "http://arxiv.org/abs/2203.08454v1", "pdf_url": "http://arxiv.org/pdf/2203.08454v1", "repo_url": null}, "2203.08412": {"publish_time": "2022-03-16", "title": "CTDS: Centralized Teacher with Decentralized Student for Multi-Agent Reinforcement Learning", "author": "Jian Zhao et.al.", "abstract": "Due to the partial observability and communication constraints in many multi-agent reinforcement learning (MARL) tasks, centralized training with decentralized execution (CTDE) has become one of the most widely used MARL paradigms. In CTDE, centralized information is dedicated to learning the allocation of the team reward with a mixing network, while the learning of individual Q-values is usually based on local observations. The insufficient utility of global observation will degrade performance in challenging environments. To this end, this work proposes a novel Centralized Teacher with Decentralized Student (CTDS) framework, which consists of a teacher model and a student model. Specifically, the teacher model allocates the team reward by learning individual Q-values conditioned on global observation, while the student model utilizes the partial observations to approximate the Q-values estimated by the teacher model. In this way, CTDS balances the full utilization of global observation during training and the feasibility of decentralized execution for online inference. Our CTDS framework is generic which is ready to be applied upon existing CTDE methods to boost their performance. We conduct experiments on a challenging set of StarCraft II micromanagement tasks to test the effectiveness of our method and the results show that CTDS outperforms the existing value-based MARL methods.", "paper_url": "http://arxiv.org/abs/2203.08412v1", "pdf_url": "http://arxiv.org/pdf/2203.08412v1", "repo_url": null}, "2203.08409": {"publish_time": "2022-03-16", "title": "How to Learn from Risk: Explicit Risk-Utility Reinforcement Learning for Efficient and Safe Driving Strategies", "author": "Lukas M. Schmidt et.al.", "abstract": "Autonomous driving has the potential to revolutionize mobility and is hence an active area of research. In practice, the behavior of autonomous vehicles must be acceptable, i.e., efficient, safe, and interpretable. While vanilla reinforcement learning (RL) finds performant behavioral strategies, they are often unsafe and uninterpretable. Safety is introduced through Safe RL approaches, but they still mostly remain uninterpretable as the learned behaviour is jointly optimized for safety and performance without modeling them separately. Interpretable machine learning is rarely applied to RL. This paper proposes SafeDQN, which allows to make the behavior of autonomous vehicles safe and interpretable while still being efficient. SafeDQN offers an understandable, semantic trade-off between the expected risk and the utility of actions while being algorithmically transparent. We show that SafeDQN finds interpretable and safe driving policies for a variety of scenarios and demonstrate how state-of-the-art saliency techniques can help to assess both risk and utility.", "paper_url": "http://arxiv.org/abs/2203.08409v1", "pdf_url": "http://arxiv.org/pdf/2203.08409v1", "repo_url": null}, "2203.09498": {"publish_time": "2022-03-17", "title": "The Frost Hollow Experiments: Pavlovian Signalling as a Path to Coordination and Communication Between Agents", "author": "Patrick M. Pilarski et.al.", "abstract": "Learned communication between agents is a powerful tool when approaching decision-making problems that are hard to overcome by any single agent in isolation. However, continual coordination and communication learning between machine agents or human-machine partnerships remains a challenging open problem. As a stepping stone toward solving the continual communication learning problem, in this paper we contribute a multi-faceted study into what we term Pavlovian signalling -- a process by which learned, temporally extended predictions made by one agent inform decision-making by another agent with different perceptual access to their shared environment. We seek to establish how different temporal processes and representational choices impact Pavlovian signalling between learning agents. To do so, we introduce a partially observable decision-making domain we call the Frost Hollow. In this domain a prediction learning agent and a reinforcement learning agent are coupled into a two-part decision-making system that seeks to acquire sparse reward while avoiding time-conditional hazards. We evaluate two domain variations: 1) machine prediction and control learning in a linear walk, and 2) a prediction learning machine interacting with a human participant in a virtual reality environment. Our results showcase the speed of learning for Pavlovian signalling, the impact that different temporal representations do (and do not) have on agent-agent coordination, and how temporal aliasing impacts agent-agent and human-agent interactions differently. As a main contribution, we establish Pavlovian signalling as a natural bridge between fixed signalling paradigms and fully adaptive communication learning. Our results therefore point to an actionable, constructivist path towards continual communication learning between reinforcement learning agents, with potential impact in a range of real-world settings.", "paper_url": "http://arxiv.org/abs/2203.09498v1", "pdf_url": "http://arxiv.org/pdf/2203.09498v1", "repo_url": null}, "2203.09365": {"publish_time": "2022-03-17", "title": "Semi-Markov Offline Reinforcement Learning for Healthcare", "author": "Mehdi Fatemi et.al.", "abstract": "Reinforcement learning (RL) tasks are typically framed as Markov Decision Processes (MDPs), assuming that decisions are made at fixed time intervals. However, many applications of great importance, including healthcare, do not satisfy this assumption, yet they are commonly modelled as MDPs after an artificial reshaping of the data. In addition, most healthcare (and similar) problems are offline by nature, allowing for only retrospective studies. To address both challenges, we begin by discussing the Semi-MDP (SMDP) framework, which formally handles actions of variable timings. We next present a formal way to apply SMDP modifications to nearly any given value-based offline RL method. We use this theory to introduce three SMDP-based offline RL algorithms, namely, SDQN, SDDQN, and SBCQ. We then experimentally demonstrate that these SMDP-based algorithms learn the optimal policy in these variable-time environments, whereas un-directed modifications of MDP modelling lead to sub-optimal policies. Finally, we apply our new algorithms to a real-world offline dataset pertaining to warfarin dosing for stroke prevention and demonstrate similar results.", "paper_url": "http://arxiv.org/abs/2203.09365v1", "pdf_url": "http://arxiv.org/pdf/2203.09365v1", "repo_url": null}, "2203.09251": {"publish_time": "2022-03-17", "title": "Near Instance-Optimal PAC Reinforcement Learning for Deterministic MDPs", "author": "Andrea Tirinzoni et.al.", "abstract": "In probably approximately correct (PAC) reinforcement learning (RL), an agent is required to identify an $\\epsilon$-optimal policy with probability $1-\\delta$. While minimax optimal algorithms exist for this problem, its instance-dependent complexity remains elusive in episodic Markov decision processes (MDPs). In this paper, we propose the first (nearly) matching upper and lower bounds on the sample complexity of PAC RL in deterministic episodic MDPs with finite state and action spaces. In particular, our bounds feature a new notion of sub-optimality gap for state-action pairs that we call the deterministic return gap. While our instance-dependent lower bound is written as a linear program, our algorithms are very simple and do not require solving such an optimization problem during learning. Their design and analyses employ novel ideas, including graph-theoretical concepts such as minimum flows and maximum cuts, which we believe to shed new light on this problem.", "paper_url": "http://arxiv.org/abs/2203.09251v1", "pdf_url": "http://arxiv.org/pdf/2203.09251v1", "repo_url": null}, "2203.08975": {"publish_time": "2022-03-16", "title": "A Survey of Multi-Agent Reinforcement Learning with Communication", "author": "Changxi Zhu et.al.", "abstract": "Communication is an effective mechanism for coordinating the behavior of multiple agents. In the field of multi-agent reinforcement learning, agents can improve the overall learning performance and achieve their objectives by communication. Moreover, agents can communicate various types of messages, either to all agents or to specific agent groups, and through specific channels. With the growing body of research work in MARL with communication (Comm-MARL), there is lack of a systematic and structural approach to distinguish and classify existing Comm-MARL systems. In this paper, we survey recent works in the Comm-MARL field and consider various aspects of communication that can play a role in the design and development of multi-agent reinforcement learning systems. With these aspects in mind, we propose several dimensions along which Comm-MARL systems can be analyzed, developed, and compared.", "paper_url": "http://arxiv.org/abs/2203.08975v1", "pdf_url": "http://arxiv.org/pdf/2203.08975v1", "repo_url": null}, "2203.08949": {"publish_time": "2022-03-16", "title": "Latent-Variable Advantage-Weighted Policy Optimization for Offline RL", "author": "Xi Chen et.al.", "abstract": "Offline reinforcement learning methods hold the promise of learning policies from pre-collected datasets without the need to query the environment for new transitions. This setting is particularly well-suited for continuous control robotic applications for which online data collection based on trial-and-error is costly and potentially unsafe. In practice, offline datasets are often heterogeneous, i.e., collected in a variety of scenarios, such as data from several human demonstrators or from policies that act with different purposes. Unfortunately, such datasets can exacerbate the distribution shift between the behavior policy underlying the data and the optimal policy to be learned, leading to poor performance. To address this challenge, we propose to leverage latent-variable policies that can represent a broader class of policy distributions, leading to better adherence to the training data distribution while maximizing reward via a policy over the latent variable. As we empirically show on a range of simulated locomotion, navigation, and manipulation tasks, our method referred to as latent-variable advantage-weighted policy optimization (LAPO), improves the average performance of the next best-performing offline reinforcement learning methods by 49% on heterogeneous datasets, and by 8% on datasets with narrow and biased distributions.", "paper_url": "http://arxiv.org/abs/2203.08949v1", "pdf_url": "http://arxiv.org/pdf/2203.08949v1", "repo_url": null}, "2203.10050": {"publish_time": "2022-03-18", "title": "SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning", "author": "Jongjin Park et.al.", "abstract": "Preference-based reinforcement learning (RL) has shown potential for teaching agents to perform the target tasks without a costly, pre-defined reward function by learning the reward with a supervisor's preference between the two agent behaviors. However, preference-based learning often requires a large amount of human feedback, making it difficult to apply this approach to various applications. This data-efficiency problem, on the other hand, has been typically addressed by using unlabeled samples or data augmentation techniques in the context of supervised learning. Motivated by the recent success of these approaches, we present SURF, a semi-supervised reward learning framework that utilizes a large amount of unlabeled samples with data augmentation. In order to leverage unlabeled samples for reward learning, we infer pseudo-labels of the unlabeled samples based on the confidence of the preference predictor. To further improve the label-efficiency of reward learning, we introduce a new data augmentation that temporally crops consecutive subsequences from the original behaviors. Our experiments demonstrate that our approach significantly improves the feedback-efficiency of the state-of-the-art preference-based method on a variety of locomotion and robotic manipulation tasks.", "paper_url": "http://arxiv.org/abs/2203.10050v1", "pdf_url": "http://arxiv.org/pdf/2203.10050v1", "repo_url": null}, "2203.10045": {"publish_time": "2022-03-18", "title": "Risk-Sensitive Bayesian Games for Multi-Agent Reinforcement Learning under Policy Uncertainty", "author": "Hannes Eriksson et.al.", "abstract": "In stochastic games with incomplete information, the uncertainty is evoked by the lack of knowledge about a player's own and the other players' types, i.e. the utility function and the policy space, and also the inherent stochasticity of different players' interactions. In existing literature, the risk in stochastic games has been studied in terms of the inherent uncertainty evoked by the variability of transitions and actions. In this work, we instead focus on the risk associated with the \\textit{uncertainty over types}. We contrast this with the multi-agent reinforcement learning framework where the other agents have fixed stationary policies and investigate risk-sensitiveness due to the uncertainty about the other agents' adaptive policies. We propose risk-sensitive versions of existing algorithms proposed for risk-neutral stochastic games, such as Iterated Best Response (IBR), Fictitious Play (FP) and a general multi-objective gradient approach using dual ascent (DAPG). Our experimental analysis shows that risk-sensitive DAPG performs better than competing algorithms for both social welfare and general-sum stochastic games.", "paper_url": "http://arxiv.org/abs/2203.10045v1", "pdf_url": "http://arxiv.org/pdf/2203.10045v1", "repo_url": null}, "2203.10033": {"publish_time": "2022-03-18", "title": "Skill-based Multi-objective Reinforcement Learning of Industrial Robot Tasks with Planning and Knowledge Integration", "author": "Matthias Mayr et.al.", "abstract": "In modern industrial settings with small batch sizes it should be easy to set up a robot system for a new task. Strategies exist, e.g. the use of skills, but when it comes to handling forces and torques, these systems often fall short. We introduce an approach that provides a combination of task-level planning with targeted learning of scenario-specific parameters for skill-based systems. We propose the following pipeline: (1) the user provides a task goal in the planning language PDDL, (2) a plan (i.e., a sequence of skills) is generated and the learnable parameters of the skills are automatically identified. An operator then chooses (3) reward functions and hyperparameters for the learning process. Two aspects of our methodology are critical: (a) learning is tightly integrated with a knowledge framework to support symbolic planning and to provide priors for learning, (b) using multi-objective optimization. This can help to balance key performance indicators (KPIs) such as safety and task performance since they can often affect each other. We adopt a multi-objective Bayesian optimization approach and learn entirely in simulation. We demonstrate the efficacy and versatility of our approach by learning skill parameters for two different contact-rich tasks. We show their successful execution on a real 7-DOF KUKA-iiwa manipulator and outperform the manual parameterization by human robot operators.", "paper_url": "http://arxiv.org/abs/2203.10033v1", "pdf_url": "http://arxiv.org/pdf/2203.10033v1", "repo_url": null}, "2203.09844": {"publish_time": "2022-03-18", "title": "Reinforcement Learning Approach to Clear Paths of Robots in Elevator Environment", "author": "Wanli Ma et.al.", "abstract": "Efficiently using the space of an elevator for a service robot is very necessary, due to the need for reducing the amount of time caused by waiting for the next elevator. To solve this, we propose a hybrid approach that combines reinforcement learning (RL) with voice interaction for robot navigation in the scene of entering the elevator. RL provides robots with a high exploration ability to find a new clear path to enter the elevator compared to the traditional navigation methods such as Optimal Reciprocal Collision Avoidance (ORCA). The proposed method allows the robot to take an active clear path action towards the elevator whilst a crowd of people stands at the entrance of the elevator wherein there are still lots of space. This is done by embedding a clear path action (beep) into the RL framework, and the proposed navigation policy leads the robot to finish tasks efficiently and safely. Our model approach provides a great improvement in the success rate and reward of entering the elevator compared to state-of-the-art ORCA and RL navigation policy without beep.", "paper_url": "http://arxiv.org/abs/2203.09844v1", "pdf_url": "http://arxiv.org/pdf/2203.09844v1", "repo_url": null}, "2203.09809": {"publish_time": "2022-03-18", "title": "Proximal Policy Optimization with Adaptive Threshold for Symmetric Relative Density Ratio", "author": "Taisuke Kobayashi et.al.", "abstract": "Deep reinforcement learning (DRL) is one of the promising approaches for introducing robots into complicated environments. The recent remarkable progress of DRL stands on regularization of policy, which allows the policy to improve stably and efficiently. A popular method, so-called proximal policy optimization (PPO), and its variants constrain density ratio of the latest and baseline policies when the density ratio exceeds a given threshold. This threshold can be designed relatively intuitively, and in fact its recommended value range has been suggested. However, the density ratio is asymmetric for its center, and the possible error scale from its center, which should be close to the threshold, would depend on how the baseline policy is given. In order to maximize the values of regularization of policy, this paper proposes a new PPO derived using relative Pearson (RPE) divergence, therefore so-called PPO-RPE, to design the threshold adaptively. In PPO-RPE, the relative density ratio, which can be formed with symmetry, replaces the raw density ratio. Thanks to this symmetry, its error scale from center can easily be estimated, hence, the threshold can be adapted for the estimated error scale. From three simple benchmark simulations, the importance of algorithm-dependent threshold design is revealed. By simulating additional four locomotion tasks, it is verified that the proposed method statistically contributes to task accomplishment by appropriately restricting the policy updates.", "paper_url": "http://arxiv.org/abs/2203.09809v1", "pdf_url": "http://arxiv.org/pdf/2203.09809v1", "repo_url": null}, "2203.11176": {"publish_time": "2022-03-21", "title": "One After Another: Learning Incremental Skills for a Changing World", "author": "Nur Muhammad Shafiullah et.al.", "abstract": "Reward-free, unsupervised discovery of skills is an attractive alternative to the bottleneck of hand-designing rewards in environments where task supervision is scarce or expensive. However, current skill pre-training methods, like many RL techniques, make a fundamental assumption - stationary environments during training. Traditional methods learn all their skills simultaneously, which makes it difficult for them to both quickly adapt to changes in the environment, and to not forget earlier skills after such adaptation. On the other hand, in an evolving or expanding environment, skill learning must be able to adapt fast to new environment situations while not forgetting previously learned skills. These two conditions make it difficult for classic skill discovery to do well in an evolving environment. In this work, we propose a new framework for skill discovery, where skills are learned one after another in an incremental fashion. This framework allows newly learned skills to adapt to new environment or agent dynamics, while the fixed old skills ensure the agent doesn't forget a learned skill. We demonstrate experimentally that in both evolving and static environments, incremental skills significantly outperform current state-of-the-art skill discovery methods on both skill quality and the ability to solve downstream tasks. Videos for learned skills and code are made public on https://notmahi.github.io/disk", "paper_url": "http://arxiv.org/abs/2203.11176v1", "pdf_url": "http://arxiv.org/pdf/2203.11176v1", "repo_url": null}, "2203.11147": {"publish_time": "2022-03-21", "title": "Teaching language models to support answers with verified quotes", "author": "Jacob Menick et.al.", "abstract": "Recent large language models often answer factual questions correctly. But users can't trust any given claim a model makes without fact-checking, because language models can hallucinate convincing nonsense. In this work we use reinforcement learning from human preferences (RLHP) to train \"open-book\" QA models that generate answers whilst also citing specific evidence for their claims, which aids in the appraisal of correctness. Supporting evidence is drawn from multiple documents found via a search engine, or from a single user-provided document. Our 280 billion parameter model, GopherCite, is able to produce answers with high quality supporting evidence and abstain from answering when unsure. We measure the performance of GopherCite by conducting human evaluation of answers to questions in a subset of the NaturalQuestions and ELI5 datasets. The model's response is found to be high-quality 80\\% of the time on this Natural Questions subset, and 67\\% of the time on the ELI5 subset. Abstaining from the third of questions for which it is most unsure improves performance to 90\\% and 80\\% respectively, approaching human baselines. However, analysis on the adversarial TruthfulQA dataset shows why citation is only one part of an overall strategy for safety and trustworthiness: not all claims supported by evidence are true.", "paper_url": "http://arxiv.org/abs/2203.11147v1", "pdf_url": "http://arxiv.org/pdf/2203.11147v1", "repo_url": null}, "2203.10949": {"publish_time": "2022-03-21", "title": "Optimizing Trajectories for Highway Driving with Offline Reinforcement Learning", "author": "Branka Mirchevska et.al.", "abstract": "Implementing an autonomous vehicle that is able to output feasible, smooth and efficient trajectories is a long-standing challenge. Several approaches have been considered, roughly falling under two categories: rule-based and learning-based approaches. The rule-based approaches, while guaranteeing safety and feasibility, fall short when it comes to long-term planning and generalization. The learning-based approaches are able to account for long-term planning and generalization to unseen situations, but may fail to achieve smoothness, safety and the feasibility which rule-based approaches ensure. Hence, combining the two approaches is an evident step towards yielding the best compromise out of both. We propose a Reinforcement Learning-based approach, which learns target trajectory parameters for fully autonomous driving on highways. The trained agent outputs continuous trajectory parameters based on which a feasible polynomial-based trajectory is generated and executed. We compare the performance of our agent against four other highway driving agents. The experiments are conducted in the Sumo simulator, taking into consideration various realistic, dynamically changing highway scenarios, including surrounding vehicles with different driver behaviors. We demonstrate that our offline trained agent, with randomly collected data, learns to drive smoothly, achieving velocities as close as possible to the desired velocity, while outperforming the other agents. Code, training data and details available at: https://nrgit.informatik.uni-freiburg. de/branka.mirchevska/offline-rl-tp.", "paper_url": "http://arxiv.org/abs/2203.10949v1", "pdf_url": "http://arxiv.org/pdf/2203.10949v1", "repo_url": null}, "2203.10905": {"publish_time": "2022-03-21", "title": "Self-Imitation Learning from Demonstrations", "author": "Georgiy Pshikhachev et.al.", "abstract": "Despite the numerous breakthroughs achieved with Reinforcement Learning (RL), solving environments with sparse rewards remains a challenging task that requires sophisticated exploration. Learning from Demonstrations (LfD) remedies this issue by guiding the agent's exploration towards states experienced by an expert. Naturally, the benefits of this approach hinge on the quality of demonstrations, which are rarely optimal in realistic scenarios. Modern LfD algorithms require meticulous tuning of hyperparameters that control the influence of demonstrations and, as we show in the paper, struggle with learning from suboptimal demonstrations. To address these issues, we extend Self-Imitation Learning (SIL), a recent RL algorithm that exploits the agent's past good experience, to the LfD setup by initializing its replay buffer with demonstrations. We denote our algorithm as SIL from Demonstrations (SILfD). We empirically show that SILfD can learn from demonstrations that are noisy or far from optimal and can automatically adjust the influence of demonstrations throughout the training without additional hyperparameters or handcrafted schedules. We also find SILfD superior to the existing state-of-the-art LfD algorithms in sparse environments, especially when demonstrations are highly suboptimal.", "paper_url": "http://arxiv.org/abs/2203.10905v1", "pdf_url": "http://arxiv.org/pdf/2203.10905v1", "repo_url": null}, "2203.10844": {"publish_time": "2022-03-21", "title": "Lean Evolutionary Reinforcement Learning by Multitasking with Importance Sampling", "author": "Nick Zhang et.al.", "abstract": "Studies have shown evolution strategies (ES) to be a promising approach for reinforcement learning (RL) with deep neural networks. However, the issue of high sample complexity persists in applications of ES to deep RL. In this paper, we address the shortcoming of today's methods via a novel neuroevolutionary multitasking (NuEMT) algorithm, designed to transfer information from a set of auxiliary tasks (of short episode length) to the target (full length) RL task at hand. The artificially generated auxiliary tasks allow an agent to update and quickly evaluate policies on shorter time horizons. The evolved skills are then transferred to guide the longer and harder task towards an optimal policy. We demonstrate that the NuEMT algorithm achieves data-lean evolutionary RL, reducing expensive agent-environment interaction data requirements. Our key algorithmic contribution in this setting is to introduce, for the first time, a multitask information transfer mechanism based on the statistical importance sampling technique. In addition, an adaptive resource allocation strategy is utilized to assign computational resources to auxiliary tasks based on their gleaned usefulness. Experiments on a range of continuous control tasks from the OpenAI Gym confirm that our proposed algorithm is efficient compared to recent ES baselines.", "paper_url": "http://arxiv.org/abs/2203.10844v1", "pdf_url": "http://arxiv.org/pdf/2203.10844v1", "repo_url": null}, "2203.11889": {"publish_time": "2022-03-22", "title": "Insights From the NeurIPS 2021 NetHack Challenge", "author": "Eric Hambro et.al.", "abstract": "In this report, we summarize the takeaways from the first NeurIPS 2021 NetHack Challenge. Participants were tasked with developing a program or agent that can win (i.e., 'ascend' in) the popular dungeon-crawler game of NetHack by interacting with the NetHack Learning Environment (NLE), a scalable, procedurally generated, and challenging Gym environment for reinforcement learning (RL). The challenge showcased community-driven progress in AI with many diverse approaches significantly beating the previously best results on NetHack. Furthermore, it served as a direct comparison between neural (e.g., deep RL) and symbolic AI, as well as hybrid systems, demonstrating that on NetHack symbolic bots currently outperform deep RL by a large margin. Lastly, no agent got close to winning the game, illustrating NetHack's suitability as a long-term benchmark for AI research.", "paper_url": "http://arxiv.org/abs/2203.11889v1", "pdf_url": "http://arxiv.org/pdf/2203.11889v1", "repo_url": null}, "2203.11842": {"publish_time": "2022-03-22", "title": "X-MEN: Guaranteed XOR-Maximum Entropy Constrained Inverse Reinforcement Learning", "author": "Fan Ding et.al.", "abstract": "Inverse Reinforcement Learning (IRL) is a powerful way of learning from demonstrations. In this paper, we address IRL problems with the availability of prior knowledge that optimal policies will never violate certain constraints. Conventional approaches ignoring these constraints need many demonstrations to converge. We propose XOR-Maximum Entropy Constrained Inverse Reinforcement Learning (X-MEN), which is guaranteed to converge to the optimal policy in linear rate w.r.t. the number of learning iterations. X-MEN embeds XOR-sampling -- a provable sampling approach that transforms the #P complete sampling problem into queries to NP oracles -- into the framework of maximum entropy IRL. X-MEN also guarantees the learned policy will never generate trajectories that violate constraints. Empirical results in navigation demonstrate that X-MEN converges faster to the optimal policies compared to baseline approaches and always generates trajectories that satisfy multi-state combinatorial constraints.", "paper_url": "http://arxiv.org/abs/2203.11842v1", "pdf_url": "http://arxiv.org/pdf/2203.11842v1", "repo_url": null}, "2203.11758": {"publish_time": "2022-03-22", "title": "Linear convergence of a policy gradient method for finite horizon continuous time stochastic control problems", "author": "Christoph Reisinger et.al.", "abstract": "Despite its popularity in the reinforcement learning community, a provably convergent policy gradient method for general continuous space-time stochastic control problems has been elusive. This paper closes the gap by proposing a proximal gradient algorithm for feedback controls of finite-time horizon stochastic control problems. The state dynamics are continuous time nonlinear diffusions with controlled drift and possibly degenerate noise, and the objectives are nonconvex in the state and nonsmooth in the control. We prove under suitable conditions that the algorithm converges linearly to a stationary point of the control problem, and is stable with respect to policy updates by approximate gradient steps. The convergence result justifies the recent reinforcement learning heuristics that adding entropy regularization to the optimization objective accelerates the convergence of policy gradient methods. The proof exploits careful regularity estimates of backward stochastic differential equations.", "paper_url": "http://arxiv.org/abs/2203.11758v1", "pdf_url": "http://arxiv.org/pdf/2203.11758v1", "repo_url": null}, "2203.11658": {"publish_time": "2022-03-22", "title": "A Decentralised Multi-Agent Reinforcement Learning Approach for the Same-Day Delivery Problem", "author": "Elvin Ngu et.al.", "abstract": "Same-Day Delivery services are becoming increasingly popular in recent years. These have been usually modelled by previous studies as a certain class of Dynamic Vehicle Routing Problem (DVRP) where goods must be delivered from a depot to a set of customers in the same day that the orders were placed. Adaptive exact solution methods for DVRPs can become intractable even for small problem instances. In this paper, we formulate the SDDP as a Markov Decision Process (MDP) and solve it using a parameter-sharing Deep Q-Network, which corresponds to a decentralised Multi-Agent Reinforcement Learning (MARL) approach. For this, we create a multi-agent grid-based SDD environment, consisting of multiple vehicles, a central depot and dynamic order generation. In addition, we introduce zone-specific order generation and reward probabilities. We compare the performance of our proposed MARL approach against a Mixed Inter Programming (MIP) solution. Results show that our proposed MARL framework performs on par with MIP-based policy when the number of orders is relatively low. For problem instances with higher order arrival rates, computational results show that the MARL approach underperforms the MIP by up to 30%. The performance gap between both methods becomes smaller when zone-specific parameters are employed. The gap is reduced from 30% to 3% for a 5x5 grid scenario with 30 orders. Execution time results indicate that the MARL approach is, on average, 65 times faster than the MIP-based policy, and therefore may be more advantageous for real-time control, at least for small-sized instances.", "paper_url": "http://arxiv.org/abs/2203.11658v1", "pdf_url": "http://arxiv.org/pdf/2203.11658v1", "repo_url": null}, "2203.11656": {"publish_time": "2022-03-22", "title": "Is Vanilla Policy Gradient Overlooked? Analyzing Deep Reinforcement Learning for Hanabi", "author": "Bram Grooten et.al.", "abstract": "In pursuit of enhanced multi-agent collaboration, we analyze several on-policy deep reinforcement learning algorithms in the recently published Hanabi benchmark. Our research suggests a perhaps counter-intuitive finding, where Proximal Policy Optimization (PPO) is outperformed by Vanilla Policy Gradient over multiple random seeds in a simplified environment of the multi-agent cooperative card game. In our analysis of this behavior we look into Hanabi-specific metrics and hypothesize a reason for PPO's plateau. In addition, we provide proofs for the maximum length of a perfect game (71 turns) and any game (89 turns). Our code can be found at: https://github.com/bramgrooten/DeepRL-for-Hanabi", "paper_url": "http://arxiv.org/abs/2203.11656v1", "pdf_url": "http://arxiv.org/pdf/2203.11656v1", "repo_url": "https://github.com/bramgrooten/deeprl-for-hanabi"}, "2203.12592": {"publish_time": "2022-03-23", "title": "Your Policy Regularizer is Secretly an Adversary", "author": "Rob Brekelmans et.al.", "abstract": "Policy regularization methods such as maximum entropy regularization are widely used in reinforcement learning to improve the robustness of a learned policy. In this paper, we show how this robustness arises from hedging against worst-case perturbations of the reward function, which are chosen from a limited set by an imagined adversary. Using convex duality, we characterize this robust set of adversarial reward perturbations under KL- and {\\alpha}-divergence regularization, which includes Shannon and Tsallis entropy regularization as special cases. Importantly, generalization guarantees can be given within this robust set. We provide detailed discussion of the worst-case reward perturbations, and present intuitive empirical examples to illustrate this robustness and its relationship with generalization. Finally, we discuss how our analysis complements and extends previous results on adversarial reward robustness and path consistency optimality conditions.", "paper_url": "http://arxiv.org/abs/2203.12592v1", "pdf_url": "http://arxiv.org/pdf/2203.12592v1", "repo_url": null}, "2203.12315": {"publish_time": "2022-03-23", "title": "Resource allocation optimization using artificial intelligence methods in various computing paradigms: A Review", "author": "Javad Hassannataj Joloudari et.al.", "abstract": "With the advent of smart devices, the demand for various computational paradigms such as the Internet of Things, fog, and cloud computing has increased. However, effective resource allocation remains challenging in these paradigms. This paper presents a comprehensive literature review on the application of artificial intelligence (AI) methods such as deep learning (DL) and machine learning (ML) for resource allocation optimization in computational paradigms. To the best of our knowledge, there are no existing reviews on AI-based resource allocation approaches in different computational paradigms. The reviewed ML-based approaches are categorized as supervised and reinforcement learning (RL). Moreover, DL-based approaches and their combination with RL are surveyed. The review ends with a discussion on open research directions and a conclusion.", "paper_url": "http://arxiv.org/abs/2203.12315v1", "pdf_url": "http://arxiv.org/pdf/2203.12315v1", "repo_url": null}, "2203.12299": {"publish_time": "2022-03-23", "title": "NavDreams: Towards Camera-Only RL Navigation Among Humans", "author": "Daniel Dugas et.al.", "abstract": "Autonomously navigating a robot in everyday crowded spaces requires solving complex perception and planning challenges. When using only monocular image sensor data as input, classical two-dimensional planning approaches cannot be used. While images present a significant challenge when it comes to perception and planning, they also allow capturing potentially important details, such as complex geometry, body movement, and other visual cues. In order to successfully solve the navigation task from only images, algorithms must be able to model the scene and its dynamics using only this channel of information. We investigate whether the world model concept, which has shown state-of-the-art results for modeling and learning policies in Atari games as well as promising results in 2D LiDAR-based crowd navigation, can also be applied to the camera-based navigation problem. To this end, we create simulated environments where a robot must navigate past static and moving humans without colliding in order to reach its goal. We find that state-of-the-art methods are able to achieve success in solving the navigation problem, and can generate dream-like predictions of future image-sequences which show consistent geometry and moving persons. We are also able to show that policy performance in our high-fidelity sim2real simulation scenario transfers to the real world by testing the policy on a real robot. We make our simulator, models and experiments available at https://github.com/danieldugas/NavDreams.", "paper_url": "http://arxiv.org/abs/2203.12299v1", "pdf_url": "http://arxiv.org/pdf/2203.12299v1", "repo_url": "https://github.com/danieldugas/navdreams"}, "2203.12133": {"publish_time": "2022-03-23", "title": "Congestion-aware motion planning game with Markov decision process dynamics", "author": "Sarah H. Q. Li et.al.", "abstract": "To model a competitive multi-agent motion planning scenario for heterogeneous players with distinct dynamics and objectives, we propose a novel atomic congestion game framework with Markov decision process (MDP) dynamics. We assume that all players share the state-action space but have unique costs and transition dynamics. Each player's cost is a function of the joint state-action density, and thus is implicitly coupled to the opponents' policies. With proper cost design, the resulting Nash equilibrium avoids congesting the state-action space and each player optimally achieves its individual objective with respect to the presence of its opponents. For a class of player cost functions, we demonstrate equivalence between players' Q-value functions and the KKT point of a potential minimization problem, and derive sufficient conditions for the existence of a unique Nash equilibrium. Finally, we outline a learning algorithm for finding the Nash equilibrium that extends single-agent MDP/reinforcement learning algorithms and has linear complexity in the number of players. Throughout the paper, we provide examples for multi-agent motion planning, accumulating in a multi-robot warehouse demonstration, in which robots autonomously retrieve and deliver packages while avoiding collisions.", "paper_url": "http://arxiv.org/abs/2203.12133v1", "pdf_url": "http://arxiv.org/pdf/2203.12133v1", "repo_url": null}, "2203.12117": {"publish_time": "2022-03-23", "title": "NovGrid: A Flexible Grid World for Evaluating Agent Response to Novelty", "author": "Jonathan Balloch et.al.", "abstract": "A robust body of reinforcement learning techniques have been developed to solve complex sequential decision making problems. However, these methods assume that train and evaluation tasks come from similarly or identically distributed environments. This assumption does not hold in real life where small novel changes to the environment can make a previously learned policy fail or introduce simpler solutions that might never be found. To that end we explore the concept of {\\em novelty}, defined in this work as the sudden change to the mechanics or properties of environment. We provide an ontology of for novelties most relevant to sequential decision making, which distinguishes between novelties that affect objects versus actions, unary properties versus non-unary relations, and the distribution of solutions to a task. We introduce NovGrid, a novelty generation framework built on MiniGrid, acting as a toolkit for rapidly developing and evaluating novelty-adaptation-enabled reinforcement learning techniques. Along with the core NovGrid we provide exemplar novelties aligned with our ontology and instantiate them as novelty templates that can be applied to many MiniGrid-compliant environments. Finally, we present a set of metrics built into our framework for the evaluation of novelty-adaptation-enabled machine-learning techniques, and show characteristics of a baseline RL model using these metrics.", "paper_url": "http://arxiv.org/abs/2203.12117v1", "pdf_url": "http://arxiv.org/pdf/2203.12117v1", "repo_url": null}, "2203.13251": {"publish_time": "2022-03-24", "title": "Dexterous Imitation Made Easy: A Learning-Based Framework for Efficient Dexterous Manipulation", "author": "Sridhar Pandian Arunachalam et.al.", "abstract": "Optimizing behaviors for dexterous manipulation has been a longstanding challenge in robotics, with a variety of methods from model-based control to model-free reinforcement learning having been previously explored in literature. Perhaps one of the most powerful techniques to learn complex manipulation strategies is imitation learning. However, collecting and learning from demonstrations in dexterous manipulation is quite challenging. The complex, high-dimensional action-space involved with multi-finger control often leads to poor sample efficiency of learning-based methods. In this work, we propose 'Dexterous Imitation Made Easy' (DIME) a new imitation learning framework for dexterous manipulation. DIME only requires a single RGB camera to observe a human operator and teleoperate our robotic hand. Once demonstrations are collected, DIME employs standard imitation learning methods to train dexterous manipulation policies. On both simulation and real robot benchmarks we demonstrate that DIME can be used to solve complex, in-hand manipulation tasks such as 'flipping', 'spinning', and 'rotating' objects with the Allegro hand. Our framework along with pre-collected demonstrations is publicly available at https://nyu-robot-learning.github.io/dime.", "paper_url": "http://arxiv.org/abs/2203.13251v1", "pdf_url": "http://arxiv.org/pdf/2203.13251v1", "repo_url": null}, "2203.13055": {"publish_time": "2022-03-24", "title": "Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory", "author": "Li Siyao et.al.", "abstract": "Driving 3D characters to dance following a piece of music is highly challenging due to the spatial constraints applied to poses by choreography norms. In addition, the generated dance sequence also needs to maintain temporal coherency with different music genres. To tackle these challenges, we propose a novel music-to-dance framework, Bailando, with two powerful components: 1) a choreographic memory that learns to summarize meaningful dancing units from 3D pose sequence to a quantized codebook, 2) an actor-critic Generative Pre-trained Transformer (GPT) that composes these units to a fluent dance coherent to the music. With the learned choreographic memory, dance generation is realized on the quantized units that meet high choreography standards, such that the generated dancing sequences are confined within the spatial constraints. To achieve synchronized alignment between diverse motion tempos and music beats, we introduce an actor-critic-based reinforcement learning scheme to the GPT with a newly-designed beat-align reward function. Extensive experiments on the standard benchmark demonstrate that our proposed framework achieves state-of-the-art performance both qualitatively and quantitatively. Notably, the learned choreographic memory is shown to discover human-interpretable dancing-style poses in an unsupervised manner.", "paper_url": "http://arxiv.org/abs/2203.13055v1", "pdf_url": "http://arxiv.org/pdf/2203.13055v1", "repo_url": "https://github.com/lisiyao21/bailando"}, "2203.12980": {"publish_time": "2022-03-24", "title": "MERLIN -- Malware Evasion with Reinforcement LearnINg", "author": "Tony Quertier et.al.", "abstract": "In addition to signature-based and heuristics-based detection techniques, Machine learning (ML) is being widely used to generalize to new never-before-seen malicious software (malware). However, it has been demonstrated that ML models can be fooled by tricking the classifier into returning the incorrect label. These studies usually rely on a prediction score that is fragile to gradient-based attacks for instance. In the context of a more realistic situation where an attacker has very little information about the outputs of a malware detection engine, modest evasion rates are achieved. In this paper, we propose a method using Reinforcement Learning with DQN and REINFORCE algorithms to challenge two state-of-the-art Machine Learning based detection engines (MalConv \\& EMBER) and a commercial AV classified by Gartner as a leader in 2021. Our stateful method combines several actions modifying a Windows Portable Execution (PE) file without breaking its functionalities. Our method also identifies which actions perform better and compiles a detailed vulnerability report to help mitigate the evasion. We demonstrate that REINFORCE achieves very good evasion rates even on a commercial AV with low provided information.", "paper_url": "http://arxiv.org/abs/2203.12980v1", "pdf_url": "http://arxiv.org/pdf/2203.12980v1", "repo_url": null}, "2203.12961": {"publish_time": "2022-03-24", "title": "Multilevel Bayesin Deep Neural Networks", "author": "Neil K. Chada et.al.", "abstract": "In this article we consider Bayesian inference associated to deep neural networks (DNNs) and in particular, trace-class neural network (TNN) priors which were proposed by Sell et al. [39]. Such priors were developed as more robust alternatives to classical architectures in the context of inference problems. For this work we develop multilevel Monte Carlo (MLMC) methods for such models. MLMC is a popular variance reduction technique, with particular applications in Bayesian statistics and uncertainty quantification. We show how a particular advanced MLMC method that was introduced in [4] can be applied to Bayesian inference from DNNs and establish mathematically, that the computational cost to achieve a particular mean square error, associated to posterior expectation computation, can be reduced by several orders, versus more conventional techniques. To verify such results we provide numerous numerical experiments on model problems arising in machine learning. These include Bayesian regression, as well as Bayesian classification and reinforcement learning.", "paper_url": "http://arxiv.org/abs/2203.12961v1", "pdf_url": "http://arxiv.org/pdf/2203.12961v1", "repo_url": null}, "2203.12922": {"publish_time": "2022-03-24", "title": "Horizon-Free Reinforcement Learning in Polynomial Time: the Power of Stationary Policies", "author": "Zihan Zhang et.al.", "abstract": "This paper gives the first polynomial-time algorithm for tabular Markov Decision Processes (MDP) that enjoys a regret bound \\emph{independent on the planning horizon}. Specifically, we consider tabular MDP with $S$ states, $A$ actions, a planning horizon $H$, total reward bounded by $1$, and the agent plays for $K$ episodes. We design an algorithm that achieves an $O\\left(\\mathrm{poly}(S,A,\\log K)\\sqrt{K}\\right)$ regret in contrast to existing bounds which either has an additional $\\mathrm{polylog}(H)$ dependency~\\citep{zhang2020reinforcement} or has an exponential dependency on $S$~\\citep{li2021settling}. Our result relies on a sequence of new structural lemmas establishing the approximation power, stability, and concentration property of stationary policies, which can have applications in other problems related to Markov chains.", "paper_url": "http://arxiv.org/abs/2203.12922v1", "pdf_url": "http://arxiv.org/pdf/2203.12922v1", "repo_url": null}, "2203.13599": {"publish_time": "2022-03-25", "title": "Learning Relational Rules from Rewards", "author": "Guillermo Puebla et.al.", "abstract": "Humans perceive the world in terms of objects and relations between them. In fact, for any given pair of objects, there is a myriad of relations that apply to them. How does the cognitive system learn which relations are useful to characterize the task at hand? And how can it use these representations to build a relational policy to interact effectively with the environment? In this paper we proposed that this problem can be understood through the lens of a sub-field of symbolic machine learning called relational reinforcement learning (RRL). To demonstrate the potential of our approach, we build a simple model of relational policy learning based on a function approximator developed in RRL. We trained and tested our model in three Atari games that required to consider an increasingly number of potential relations: Breakout, Pong and Demon Attack. In each game, our model was able to select adequate relational representations and build a relational policy incrementally. We discuss the relationship between our model with models of relational and analogical reasoning, as well as its limitations and future directions of research.", "paper_url": "http://arxiv.org/abs/2203.13599v1", "pdf_url": "http://arxiv.org/pdf/2203.13599v1", "repo_url": "https://github.com/guillermopuebla/rrl"}, "2203.13573": {"publish_time": "2022-03-25", "title": "Unsupervised Learning of Temporal Abstractions with Slot-based Transformers", "author": "Anand Gopalakrishnan et.al.", "abstract": "The discovery of reusable sub-routines simplifies decision-making and planning in complex reinforcement learning problems. Previous approaches propose to learn such temporal abstractions in a purely unsupervised fashion through observing state-action trajectories gathered from executing a policy. However, a current limitation is that they process each trajectory in an entirely sequential manner, which prevents them from revising earlier decisions about sub-routine boundary points in light of new incoming information. In this work we propose SloTTAr, a fully parallel approach that integrates sequence processing Transformers with a Slot Attention module and adaptive computation for learning about the number of such sub-routines in an unsupervised fashion. We demonstrate how SloTTAr is capable of outperforming strong baselines in terms of boundary point discovery, even for sequences containing variable amounts of sub-routines, while being up to 7x faster to train on existing benchmarks.", "paper_url": "http://arxiv.org/abs/2203.13573v1", "pdf_url": "http://arxiv.org/pdf/2203.13573v1", "repo_url": null}, "2203.13572": {"publish_time": "2022-03-25", "title": "A Visual Navigation Perspective for Category-Level Object Pose Estimation", "author": "Jiaxin Guo et.al.", "abstract": "This paper studies category-level object pose estimation based on a single monocular image. Recent advances in pose-aware generative models have paved the way for addressing this challenging task using analysis-by-synthesis. The idea is to sequentially update a set of latent variables, e.g., pose, shape, and appearance, of the generative model until the generated image best agrees with the observation. However, convergence and efficiency are two challenges of this inference procedure. In this paper, we take a deeper look at the inference of analysis-by-synthesis from the perspective of visual navigation, and investigate what is a good navigation policy for this specific task. We evaluate three different strategies, including gradient descent, reinforcement learning and imitation learning, via thorough comparisons in terms of convergence, robustness and efficiency. Moreover, we show that a simple hybrid approach leads to an effective and efficient solution. We further compare these strategies to state-of-the-art methods, and demonstrate superior performance on synthetic and real-world datasets leveraging off-the-shelf pose-aware generative models.", "paper_url": "http://arxiv.org/abs/2203.13572v1", "pdf_url": "http://arxiv.org/pdf/2203.13572v1", "repo_url": null}, "2203.13563": {"publish_time": "2022-03-25", "title": "An Intelligent End-to-End Neural Architecture Search Framework for Electricity Forecasting Model Development", "author": "Jin Yang et.al.", "abstract": "Recent years have witnessed an exponential growth in developing deep learning (DL) models for the time-series electricity forecasting in power systems. However, most of the proposed models are designed based on the designers' inherent knowledge and experience without elaborating on the suitability of the proposed neural architectures. Moreover, these models cannot be self-adjusted to the dynamically changing data patterns due to an inflexible design of their structures. Even though several latest studies have considered application of the neural architecture search (NAS) technique for obtaining a network with an optimized structure in the electricity forecasting sector, their training process is quite time-consuming, computationally expensive and not intelligent, indicating that the NAS application in electricity forecasting area is still at an infancy phase. In this research study, we propose an intelligent automated architecture search (IAAS) framework for the development of time-series electricity forecasting models. The proposed framework contains two primary components, i.e., network function-preserving transformation operation and reinforcement learning (RL)-based network transformation control. In the first component, we introduce a theoretical function-preserving transformation of recurrent neural networks (RNN) to the literature for capturing the hidden temporal patterns within the time-series data. In the second component, we develop three RL-based transformation actors and a net pool to intelligently and effectively search a high-quality neural architecture. After conducting comprehensive experiments on two publicly-available electricity load datasets and two wind power datasets, we demonstrate that the proposed IAAS framework significantly outperforms the ten existing models or methods in terms of forecasting accuracy and stability.", "paper_url": "http://arxiv.org/abs/2203.13563v1", "pdf_url": "http://arxiv.org/pdf/2203.13563v1", "repo_url": null}, "2203.13424": {"publish_time": "2022-03-25", "title": "Dealing with Sparse Rewards Using Graph Neural Networks", "author": "Matvey Gerasyov et.al.", "abstract": "Deep reinforcement learning in partially observable environments is a difficult task in itself, and can be further complicated by a sparse reward signal. Most tasks involving navigation in three-dimensional environments provide the agent with extremely limited information. Typically, the agent receives a visual observation input from the environment and is rewarded once at the end of the episode. A good reward function could substantially improve the convergence of reinforcement learning algorithms for such tasks. The classic approach to increase the density of the reward signal is to augment it with supplementary rewards. This technique is called the reward shaping. In this study, we propose two modifications of one of the recent reward shaping methods based on graph convolutional networks: the first involving advanced aggregation functions, and the second utilizing the attention mechanism. We empirically validate the effectiveness of our solutions for the task of navigation in a 3D environment with sparse rewards. For the solution featuring attention mechanism, we are also able to show that the learned attention is concentrated on edges corresponding to important transitions in 3D environment.", "paper_url": "http://arxiv.org/abs/2203.13424v1", "pdf_url": "http://arxiv.org/pdf/2203.13424v1", "repo_url": null}, "2203.14908": {"publish_time": "2022-03-28", "title": "Heterogeneous Random Laser with Switching Activity Visualized by Replica Symmetry Breaking Maps", "author": "Loredana M. Massaro et.al.", "abstract": "In the past decade, complex networks of light emitters are proposed as novel platforms for photonic circuits and lab-on-chip active devices. Lasing networks made by connected multiple gain components and graphs of nanoscale random lasers (RLs) obtained from complex meshes of polymeric nanofibers are successful prototypes. However, in the reported research, mainly collective emission from a whole network of resonators is investigated, and only in a few cases, the emission from single points showing, although homogeneous and broad, spatial emission. In all cases, simultaneous activation of the miniaturized lasers is observed. Here, differently, we realize heterogeneous random lasers made of ribbon-like and highly porous fibers with evident RL action from separated micrometric domains that alternatively switch on and off by tuning the pumping light intensity. We visualize this novel effect by building for the first time replica symmetry breaking (RSB) maps of the emitting fibers with 2 {\\mu}m spatial resolution. In addition, we calculate the spatial correlations of the laser regions showing clearly an average extension of 50 {\\mu}m. The observed blinking effect is due to mode interaction along light guiding fibers and opens new avenues in the fabrication of flexible photonic networks with specific and adaptable activity.", "paper_url": "http://arxiv.org/abs/2203.14908v1", "pdf_url": "http://arxiv.org/pdf/2203.14908v1", "repo_url": null}, "2203.14817": {"publish_time": "2022-03-28", "title": "Sketching without Worrying: Noise-Tolerant Sketch-Based Image Retrieval", "author": "Ayan Kumar Bhunia et.al.", "abstract": "Sketching enables many exciting applications, notably, image retrieval. The fear-to-sketch problem (i.e., \"I can't sketch\") has however proven to be fatal for its widespread adoption. This paper tackles this \"fear\" head on, and for the first time, proposes an auxiliary module for existing retrieval models that predominantly lets the users sketch without having to worry. We first conducted a pilot study that revealed the secret lies in the existence of noisy strokes, but not so much of the \"I can't sketch\". We consequently design a stroke subset selector that {detects noisy strokes, leaving only those} which make a positive contribution towards successful retrieval. Our Reinforcement Learning based formulation quantifies the importance of each stroke present in a given subset, based on the extent to which that stroke contributes to retrieval. When combined with pre-trained retrieval models as a pre-processing module, we achieve a significant gain of 8%-10% over standard baselines and in turn report new state-of-the-art performance. Last but not least, we demonstrate the selector once trained, can also be used in a plug-and-play manner to empower various sketch applications in ways that were not previously possible.", "paper_url": "http://arxiv.org/abs/2203.14817v1", "pdf_url": "http://arxiv.org/pdf/2203.14817v1", "repo_url": "https://github.com/ayankumarbhunia/stroke_subset_selector-for-fgsbir"}, "2203.14794": {"publish_time": "2022-03-28", "title": "Limited Parameter Denoising for Low-dose X-ray Computed Tomography Using Deep Reinforcement Learning", "author": "Mayank Patwari et.al.", "abstract": "The use of deep learning has successfully solved several problems in the field of medical imaging. Deep learning has been applied to the CT denoising problem successfully. However, the use of deep learning requires large amounts of data to train deep convolutional networks (CNNs). Moreover, due to large parameter count, such deep CNNs may cause unexpected results. In this study, we introduce a novel CT denoising framework, which has interpretable behaviour, and provides useful results with limited data. We employ bilateral filtering in both the projection and volume domains to remove noise. To account for non-stationary noise, we tune the $\\sigma$ parameters of the volume for every projection view, and for every volume pixel. The tuning is carried out by two deep CNNs. Due to impracticality of labelling, the two deep CNNs are trained via a Deep-Q reinforcement learning task. The reward for the task is generated by using a custom reward function represented by a neural network. Our experiments were carried out on abdominal scans for the Mayo Clinic TCIA dataset, and the AAPM Low Dose CT Grand Challenge. Our denoising framework has excellent denoising performance increasing the PSNR from 28.53 to 28.93, and increasing the SSIM from 0.8952 to 0.9204. We outperform several state-of-the-art deep CNNs, which have several orders of magnitude higher number of parameters (p-value (PSNR) = 0.000, p-value (SSIM) = 0.000). Our method does not introduce any blurring, which is introduced by MSE loss based methods, or any deep learning artifacts, which are introduced by WGAN based models. Our ablation studies show that parameter tuning and using our reward network results in the best possible results.", "paper_url": "http://arxiv.org/abs/2203.14794v1", "pdf_url": "http://arxiv.org/pdf/2203.14794v1", "repo_url": null}, "2203.14790": {"publish_time": "2022-03-28", "title": "5G Routing Interfered Environment", "author": "Barak Gahtan et.al.", "abstract": "5G is the next-generation cellular network technology, with the goal of meeting the critical demand for bandwidth required to accommodate a high density of users. It employs flexible architectures to accommodate the high density \\cite{7390965}. 5G is enabled by mmWave communication, which operates at frequencies ranging from 30 to 300 GHz. This paper discusses the creation of a python-based environment known as the 5G Routing Interfered Environment (5GRIE). The environment can run different algorithms to route packets with source and destination pairs using a formulated interference model. Deep Reinforcement Learning algorithms that use Stable-Baselines 3 \\cite{Raffin_Stable_Baselines3_2020}, as well as heuristic-based algorithms like random or greedy, can be run on it. Profitable is an algorithm that is provided.", "paper_url": "http://arxiv.org/abs/2203.14790v1", "pdf_url": "http://arxiv.org/pdf/2203.14790v1", "repo_url": "https://github.com/BarakGahtan/5GRIE"}, "2203.14749": {"publish_time": "2022-03-28", "title": "Adaptive Risk Tendency: Nano Drone Navigation in Cluttered Environments with Distributional Reinforcement Learning", "author": "Cheng Liu et.al.", "abstract": "Enabling robots with the capability of assessing risk and making risk-aware decisions is widely considered a key step toward ensuring robustness for robots operating under uncertainty. In this paper, we consider the specific case of a nano drone robot learning to navigate an apriori unknown environment while avoiding obstacles under partial observability. We present a distributional reinforcement learning framework in order to learn adaptive risk tendency policies. Specifically, we propose to use tail conditional variance of the learnt action-value distribution as an uncertainty measurement, and use a exponentially weighted average forecasting algorithm to automatically adapt the risk-tendency at run-time based on the observed uncertainty in the environment. We show our algorithm can adjust its risk-sensitivity on the fly both in simulation and real-world experiments and achieving better performance than risk-neutral policy or risk-averse policies. Code and real-world experiment video can be found in this repository: \\url{https://github.com/tudelft/risk-sensitive-rl.git}", "paper_url": "http://arxiv.org/abs/2203.14749v1", "pdf_url": "http://arxiv.org/pdf/2203.14749v1", "repo_url": "https://github.com/tudelft/risk-sensitive-rl"}, "2203.15778": {"publish_time": "2022-03-29", "title": "Text-Driven Video Acceleration: A Weakly-Supervised Reinforcement Learning Method", "author": "Washington Ramos et.al.", "abstract": "The growth of videos in our digital age and the users' limited time raise the demand for processing untrimmed videos to produce shorter versions conveying the same information. Despite the remarkable progress that summarization methods have made, most of them can only select a few frames or skims, creating visual gaps and breaking the video context. This paper presents a novel weakly-supervised methodology based on a reinforcement learning formulation to accelerate instructional videos using text. A novel joint reward function guides our agent to select which frames to remove and reduce the input video to a target length without creating gaps in the final video. We also propose the Extended Visually-guided Document Attention Network (VDAN+), which can generate a highly discriminative embedding space to represent both textual and visual data. Our experiments show that our method achieves the best performance in Precision, Recall, and F1 Score against the baselines while effectively controlling the video's output length. Visit https://www.verlab.dcc.ufmg.br/semantic-hyperlapse/tpami2022/ for code and extra results.", "paper_url": "http://arxiv.org/abs/2203.15778v1", "pdf_url": "http://arxiv.org/pdf/2203.15778v1", "repo_url": null}, "2203.15755": {"publish_time": "2022-03-29", "title": "Demonstration-Bootstrapped Autonomous Practicing via Multi-Task Reinforcement Learning", "author": "Abhishek Gupta et.al.", "abstract": "Reinforcement learning systems have the potential to enable continuous improvement in unstructured environments, leveraging data collected autonomously. However, in practice these systems require significant amounts of instrumentation or human intervention to learn in the real world. In this work, we propose a system for reinforcement learning that leverages multi-task reinforcement learning bootstrapped with prior data to enable continuous autonomous practicing, minimizing the number of resets needed while being able to learn temporally extended behaviors. We show how appropriately provided prior data can help bootstrap both low-level multi-task policies and strategies for sequencing these tasks one after another to enable learning with minimal resets. This mechanism enables our robotic system to practice with minimal human intervention at training time while being able to solve long horizon tasks at test time. We show the efficacy of the proposed system on a challenging kitchen manipulation task both in simulation and in the real world, demonstrating the ability to practice autonomously in order to solve temporally extended problems.", "paper_url": "http://arxiv.org/abs/2203.15755v1", "pdf_url": "http://arxiv.org/pdf/2203.15755v1", "repo_url": null}, "2203.15722": {"publish_time": "2022-03-29", "title": "Transformer Network-based Reinforcement Learning Method for Power Distribution Network (PDN) Optimization of High Bandwidth Memory (HBM)", "author": "Hyunwook Park et.al.", "abstract": "In this article, for the first time, we propose a transformer network-based reinforcement learning (RL) method for power distribution network (PDN) optimization of high bandwidth memory (HBM). The proposed method can provide an optimal decoupling capacitor (decap) design to maximize the reduction of PDN self- and transfer impedance seen at multiple ports. An attention-based transformer network is implemented to directly parameterize decap optimization policy. The optimality performance is significantly improved since the attention mechanism has powerful expression to explore massive combinatorial space for decap assignments. Moreover, it can capture sequential relationships between the decap assignments. The computing time for optimization is dramatically reduced due to the reusable network on positions of probing ports and decap assignment candidates. This is because the transformer network has a context embedding process to capture meta-features including probing ports positions. In addition, the network is trained with randomly generated data sets. Therefore, without additional training, the trained network can solve new decap optimization problems. The computing time for training and data cost are critically decreased due to the scalability of the network. Thanks to its shared weight property, the network can adapt to a larger scale of problems without additional training. For verification, we compare the results with conventional genetic algorithm (GA), random search (RS), and all the previous RL-based methods. As a result, the proposed method outperforms in all the following aspects: optimality performance, computing time, and data efficiency.", "paper_url": "http://arxiv.org/abs/2203.15722v1", "pdf_url": "http://arxiv.org/pdf/2203.15722v1", "repo_url": null}, "2203.15625": {"publish_time": "2022-03-29", "title": "PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and Hallucination under Self-supervision", "author": "Kehong Gong et.al.", "abstract": "Existing self-supervised 3D human pose estimation schemes have largely relied on weak supervisions like consistency loss to guide the learning, which, inevitably, leads to inferior results in real-world scenarios with unseen poses. In this paper, we propose a novel self-supervised approach that allows us to explicitly generate 2D-3D pose pairs for augmenting supervision, through a self-enhancing dual-loop learning framework. This is made possible via introducing a reinforcement-learning-based imitator, which is learned jointly with a pose estimator alongside a pose hallucinator; the three components form two loops during the training process, complementing and strengthening one another. Specifically, the pose estimator transforms an input 2D pose sequence to a low-fidelity 3D output, which is then enhanced by the imitator that enforces physical constraints. The refined 3D poses are subsequently fed to the hallucinator for producing even more diverse data, which are, in turn, strengthened by the imitator and further utilized to train the pose estimator. Such a co-evolution scheme, in practice, enables training a pose estimator on self-generated motion data without relying on any given 3D data. Extensive experiments across various benchmarks demonstrate that our approach yields encouraging results significantly outperforming the state of the art and, in some cases, even on par with results of fully-supervised methods. Notably, it achieves 89.1% 3D PCK on MPI-INF-3DHP under self-supervised cross-dataset evaluation setup, improving upon the previous best self-supervised methods by 8.6%. Code can be found at: https://github.com/Garfield-kh/PoseTriplet", "paper_url": "http://arxiv.org/abs/2203.15625v1", "pdf_url": "http://arxiv.org/pdf/2203.15625v1", "repo_url": null}, "2203.15426": {"publish_time": "2022-03-29", "title": "On Reinforcement Learning, Effect Handlers, and the State Monad", "author": "Ugo Dal Lago et.al.", "abstract": "We study the algebraic effects and handlers as a way to support decision-making abstractions in functional programs, whereas a user can ask a learning algorithm to resolve choices without implementing the underlying selection mechanism, and give a feedback by way of rewards. Differently from some recently proposed approach to the problem based on the selection monad [Abadi and Plotkin, LICS 2021], we express the underlying intelligence as a reinforcement learning algorithm implemented as a set of handlers for some of these algebraic operations, including those for choices and rewards. We show how we can in practice use algebraic operations and handlers -- as available in the programming language EFF -- to clearly separate the learning algorithm from its environment, thus allowing for a good level of modularity. We then show how the host language can be taken as a lambda-calculus with handlers, this way showing what the essential linguistic features are. We conclude by hinting at how type and effect systems could ensure safety properties, at the same time pointing at some directions for further work.", "paper_url": "http://arxiv.org/abs/2203.15426v1", "pdf_url": "http://arxiv.org/pdf/2203.15426v1", "repo_url": null}, "2203.16464": {"publish_time": "2022-03-30", "title": "Towards Interpretable Deep Reinforcement Learning Models via Inverse Reinforcement Learning", "author": "Yuansheng Xie et.al.", "abstract": "Artificial intelligence, particularly through recent advancements in deep learning, has achieved exceptional performances in many tasks in fields such as natural language processing and computer vision. In addition to desirable evaluation metrics, a high level of interpretability is often required for these models to be reliably utilized. Therefore, explanations that offer insight into the process by which a model maps its inputs onto its outputs are much sought-after. Unfortunately, current black box nature of machine learning models is still an unresolved issue and this very nature prevents researchers from learning and providing explicative descriptions for a model's behavior and final predictions. In this work, we propose a novel framework utilizing Adversarial Inverse Reinforcement Learning that can provide global explanations for decisions made by a Reinforcement Learning model and capture intuitive tendencies that the model follows by summarizing the model's decision-making process.", "paper_url": "http://arxiv.org/abs/2203.16464v1", "pdf_url": "http://arxiv.org/pdf/2203.16464v1", "repo_url": null}, "2203.16319": {"publish_time": "2022-03-30", "title": "Multi-Robot Active Mapping via Neural Bipartite Graph Matching", "author": "Kai Ye et.al.", "abstract": "We study the problem of multi-robot active mapping, which aims for complete scene map construction in minimum time steps. The key to this problem lies in the goal position estimation to enable more efficient robot movements. Previous approaches either choose the frontier as the goal position via a myopic solution that hinders the time efficiency, or maximize the long-term value via reinforcement learning to directly regress the goal position, but does not guarantee the complete map construction. In this paper, we propose a novel algorithm, namely NeuralCoMapping, which takes advantage of both approaches. We reduce the problem to bipartite graph matching, which establishes the node correspondences between two graphs, denoting robots and frontiers. We introduce a multiplex graph neural network (mGNN) that learns the neural distance to fill the affinity matrix for more effective graph matching. We optimize the mGNN with a differentiable linear assignment layer by maximizing the long-term values that favor time efficiency and map completeness via reinforcement learning. We compare our algorithm with several state-of-the-art multi-robot active mapping approaches and adapted reinforcement-learning baselines. Experimental results demonstrate the superior performance and exceptional generalization ability of our algorithm on various indoor scenes and unseen number of robots, when only trained with 9 indoor scenes.", "paper_url": "http://arxiv.org/abs/2203.16319v1", "pdf_url": "http://arxiv.org/pdf/2203.16319v1", "repo_url": null}, "2203.16289": {"publish_time": "2022-03-30", "title": "One-Step Two-Critic Deep Reinforcement Learning for Inverter-based Volt-Var Control in Active Distribution Networks", "author": "Qiong Liu et.al.", "abstract": "A one-step two-critic deep reinforcement learning (OSTC-DRL) approach for inverter-based volt-var control (IB-VVC) in active distribution networks is proposed in this paper. Firstly, considering IB-VVC can be formulated as a single-period optimization problem, we formulate the IB-VVC as a one-step Markov decision process rather than the standard Markov decision process, which simplifies the DRL learning task. Then we design the one-step actor-critic DRL scheme which is a simplified version of recent DRL algorithms, and it avoids the issue of Q value overestimation successfully. Furthermore, considering two objectives of VVC: minimizing power loss and eliminating voltage violation, we utilize two critics to approximate the rewards of two objectives separately. It simplifies the approximation tasks of each critic, and avoids the interaction effect between two objectives in the learning process of critic. The OSTC-DRL approach integrates the one-step actor-critic DRL scheme and the two-critic technology. Based on the OSTC-DRL, we design two centralized DRL algorithms. Further, we extend the OSTC-DRL to multi-agent OSTC-DRL for decentralized IB-VVC and design two multi-agent DRL algorithms. Simulations demonstrate that the proposed OSTC-DRL has a faster convergence rate and a better control performance, and the multi-agent OSTC-DRL works well for decentralized IB-VVC problems.", "paper_url": "http://arxiv.org/abs/2203.16289v1", "pdf_url": "http://arxiv.org/pdf/2203.16289v1", "repo_url": null}, "2203.16275": {"publish_time": "2022-03-30", "title": "Reinforcement Learning Guided by Provable Normative Compliance", "author": "Emery Neufeld et.al.", "abstract": "Reinforcement learning (RL) has shown promise as a tool for engineering safe, ethical, or legal behaviour in autonomous agents. Its use typically relies on assigning punishments to state-action pairs that constitute unsafe or unethical choices. Despite this assignment being a crucial step in this approach, however, there has been limited discussion on generalizing the process of selecting punishments and deciding where to apply them. In this paper, we adopt an approach that leverages an existing framework -- the normative supervisor of (Neufeld et al., 2021) -- during training. This normative supervisor is used to dynamically translate states and the applicable normative system into defeasible deontic logic theories, feed these theories to a theorem prover, and use the conclusions derived to decide whether or not to assign a punishment to the agent. We use multi-objective RL (MORL) to balance the ethical objective of avoiding violations with a non-ethical objective; we will demonstrate that our approach works for a multiplicity of MORL techniques, and show that it is effective regardless of the magnitude of the punishment we assign.", "paper_url": "http://arxiv.org/abs/2203.16275v1", "pdf_url": "http://arxiv.org/pdf/2203.16275v1", "repo_url": null}, "2203.16199": {"publish_time": "2022-03-30", "title": "Momentum transport properties of a hot and dense QCD matter in a weak magnetic field", "author": "Shubhalaxmi Rath et.al.", "abstract": "We have studied the momentum transport properties of a hot and dense QCD matter in a weak magnetic field by determining the shear ($\\eta$) and bulk ($\\zeta$) viscosities in the relaxation time approximation of kinetic theory. The dependence of $\\eta$ and $\\zeta$ on the temperature has been explored in the presence of weak magnetic field ($B$-field) and finite chemical potential ($\\mu$). It is observed that both shear and bulk viscosities get decreased in the presence of a weak magnetic field, whereas the finite chemical potential increases these viscosities, specifically at low temperatures. This study is important to understand the sound attenuation through the Prandtl number (Pl), the nature of the flow through the Reynolds number (Rl), the fluidity and location of transition point of the matter through the ratios $\\eta/s$ and $\\zeta/s$ ($s$ is the entropy density), respectively. The Prandtl number gets increased in the weak magnetic field, whereas the finite chemical potential reduces its magnitude as compared to the counterpart in the absence of $B$-field and $\\mu$. However, Pl still remains larger than unity, indicating that the energy dissipation due to the sound attenuation is mostly governed by the momentum diffusion. It is noticed that the weak magnetic field makes the Reynolds number larger, whereas the chemical potential makes it smaller than that in the absence of $B$-field and $\\mu$. We have observed that the ratio $\\eta/s$ gets decreased in the weak magnetic field regime, whereas the finite chemical potential increases its value, but the ratio $\\zeta/s$ is found to be decreased by both weak magnetic field and finite chemical potential.", "paper_url": "http://arxiv.org/abs/2203.16199v1", "pdf_url": "http://arxiv.org/pdf/2203.16199v1", "repo_url": null}, "2203.17275": {"publish_time": "2022-03-31", "title": "DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools", "author": "Xingyu Lin et.al.", "abstract": "We consider the problem of sequential robotic manipulation of deformable objects using tools. Previous works have shown that differentiable physics simulators provide gradients to the environment state and help trajectory optimization to converge orders of magnitude faster than model-free reinforcement learning algorithms for deformable object manipulation. However, such gradient-based trajectory optimization typically requires access to the full simulator states and can only solve short-horizon, single-skill tasks due to local optima. In this work, we propose a novel framework, named DiffSkill, that uses a differentiable physics simulator for skill abstraction to solve long-horizon deformable object manipulation tasks from sensory observations. In particular, we first obtain short-horizon skills using individual tools from a gradient-based optimizer, using the full state information in a differentiable simulator; we then learn a neural skill abstractor from the demonstration trajectories which takes RGBD images as input. Finally, we plan over the skills by finding the intermediate goals and then solve long-horizon tasks. We show the advantages of our method in a new set of sequential deformable object manipulation tasks compared to previous reinforcement learning algorithms and compared to the trajectory optimizer.", "paper_url": "http://arxiv.org/abs/2203.17275v1", "pdf_url": "http://arxiv.org/pdf/2203.17275v1", "repo_url": null}, "2203.17193": {"publish_time": "2022-03-31", "title": "Learning from many trajectories", "author": "Stephen Tu et.al.", "abstract": "We initiate a study of supervised learning from many independent sequences (\"trajectories\") of non-independent covariates, reflecting tasks in sequence modeling, control, and reinforcement learning. Conceptually, our multi-trajectory setup sits between two traditional settings in statistical learning theory: learning from independent examples and learning from a single auto-correlated sequence. Our conditions for efficient learning generalize the former setting--trajectories must be non-degenerate in ways that extend standard requirements for independent examples. They do not require that trajectories be ergodic, long, nor strictly stable.   For linear least-squares regression, given $n$-dimensional examples produced by $m$ trajectories, each of length $T$, we observe a notable change in statistical efficiency as the number of trajectories increases from a few (namely $m \\lesssim n$) to many (namely $m \\gtrsim n$). Specifically, we establish that the worst-case error rate this problem is $\\Theta(n / m T)$ whenever $m \\gtrsim n$. Meanwhile, when $m \\lesssim n$, we establish a (sharp) lower bound of $\\Omega(n^2 / m^2 T)$ on the worst-case error rate, realized by a simple, marginally unstable linear dynamical system. A key upshot is that, in domains where trajectories regularly reset, the error rate eventually behaves as if all of the examples were independent altogether, drawn from their marginals. As a corollary of our analysis, we also improve guarantees for the linear system identification problem.", "paper_url": "http://arxiv.org/abs/2203.17193v1", "pdf_url": "http://arxiv.org/pdf/2203.17193v1", "repo_url": null}, "2203.17128": {"publish_time": "2022-03-31", "title": "Neural Q-learning for solving elliptic PDEs", "author": "Samuel N. Cohen et.al.", "abstract": "Solving high-dimensional partial differential equations (PDEs) is a major challenge in scientific computing. We develop a new numerical method for solving elliptic-type PDEs by adapting the Q-learning algorithm in reinforcement learning. Our \"Q-PDE\" algorithm is mesh-free and therefore has the potential to overcome the curse of dimensionality. Using a neural tangent kernel (NTK) approach, we prove that the neural network approximator for the PDE solution, trained with the Q-PDE algorithm, converges to the trajectory of an infinite-dimensional ordinary differential equation (ODE) as the number of hidden units $\\rightarrow \\infty$. For monotone PDE (i.e. those given by monotone operators, which may be nonlinear), despite the lack of a spectral gap in the NTK, we then prove that the limit neural network, which satisfies the infinite-dimensional ODE, converges in $L^2$ to the PDE solution as the training time $\\rightarrow \\infty$. More generally, we can prove that any fixed point of the wide-network limit for the Q-PDE algorithm is a solution of the PDE (not necessarily under the monotone condition). The numerical performance of the Q-PDE algorithm is studied for several elliptic PDEs.", "paper_url": "http://arxiv.org/abs/2203.17128v1", "pdf_url": "http://arxiv.org/pdf/2203.17128v1", "repo_url": null}, "2203.17106": {"publish_time": "2022-03-31", "title": "A Cooperative Optimal Control Framework for Connected and Automated Vehicles in Mixed Traffic Using Social Value Orientation", "author": "Viet-Anh Le et.al.", "abstract": "In this paper, we develop a socially cooperative optimal control framework for connected and automated vehicles (CAVs) in mixed traffic using social value orientation (SVO). In our approach, we formulate the interaction between a CAV and a human-driven vehicle (HDV) as a simultaneous game to facilitate the derivation of a Nash equilibrium. In the imposed game, each vehicle minimizes a weighted sum of its egoistic objective and a cooperative objective. The SVO angles are used to quantify preferences of the vehicles toward the egoistic and cooperative objectives which lead to an appropriate design of weighting factors in a multi-objective optimal control problem. We prove that by solving the proposed optimal control problem, a Nash equilibrium can be obtained. To estimate the SVO angle of the HDV, we develop a receding horizon estimation based on maximum entropy inverse reinforcement learning. The effectiveness of the proposed approach is demonstrated by numerical simulations at a highway on-ramp merging scenario.", "paper_url": "http://arxiv.org/abs/2203.17106v1", "pdf_url": "http://arxiv.org/pdf/2203.17106v1", "repo_url": null}, "2203.16942": {"publish_time": "2022-03-31", "title": "Sequential Recommendation with User Evolving Preference Decomposition", "author": "Weiqi Shao et.al.", "abstract": "Modeling user sequential behaviors has recently attracted increasing attention in the recommendation domain. Existing methods mostly assume coherent preference in the same sequence. However, user personalities are volatile and easily changed, and there can be multiple mixed preferences underlying user behaviors. To solve this problem, in this paper, we propose a novel sequential recommender model via decomposing and modeling user independent preferences. To achieve this goal, we highlight three practical challenges considering the inconsistent, evolving and uneven nature of the user behavior, which are seldom noticed by the previous work. For overcoming these challenges in a unified framework, we introduce a reinforcement learning module to simulate the evolution of user preference. More specifically, the action aims to allocate each item into a sub-sequence or create a new one according to how the previous items are decomposed as well as the time interval between successive behaviors. The reward is associated with the final loss of the learning objective, aiming to generate sub-sequences which can better fit the training data. We conduct extensive experiments based on six real-world datasets across different domains. Compared with the state-of-the-art methods, empirical studies manifest that our model can on average improve the performance by about 8.21%, 10.08%, 10.32%, and 9.82% on the metrics of Precision, Recall, NDCG and MRR, respectively.", "paper_url": "http://arxiv.org/abs/2203.16942v1", "pdf_url": "http://arxiv.org/pdf/2203.16942v1", "repo_url": null}, "2204.00565": {"publish_time": "2022-04-01", "title": "What makes useful auxiliary tasks in reinforcement learning: investigating the effect of the target policy", "author": "Banafsheh Rafiee et.al.", "abstract": "Auxiliary tasks have been argued to be useful for representation learning in reinforcement learning. Although many auxiliary tasks have been empirically shown to be effective for accelerating learning on the main task, it is not yet clear what makes useful auxiliary tasks. Some of the most promising results are on the pixel control, reward prediction, and the next state prediction auxiliary tasks; however, the empirical results are mixed, showing substantial improvements in some cases and marginal improvements in others. Careful investigations of how auxiliary tasks help the learning of the main task is necessary. In this paper, we take a step studying the effect of the target policies on the usefulness of the auxiliary tasks formulated as general value functions. General value functions consist of three core elements: 1) policy 2) cumulant 3) continuation function. Our focus on the role of the target policy of the auxiliary tasks is motivated by the fact that the target policy determines the behavior about which the agent wants to make a prediction and the state-action distribution that the agent is trained on, which further affects the main task learning. Our study provides insights about questions such as: Does a greedy policy result in bigger improvement gains compared to other policies? Is it best to set the auxiliary task policy to be the same as the main task policy? Does the choice of the target policy have a substantial effect on the achieved performance gain or simple strategies for setting the policy, such as using a uniformly random policy, work as well? Our empirical results suggest that: 1) Auxiliary tasks with the greedy policy tend to be useful. 2) Most policies, including a uniformly random policy, tend to improve over the baseline. 3) Surprisingly, the main task policy tends to be less useful compared to other policies.", "paper_url": "http://arxiv.org/abs/2204.00565v1", "pdf_url": "http://arxiv.org/pdf/2204.00565v1", "repo_url": null}, "2204.00377": {"publish_time": "2022-04-01", "title": "Deep Page-Level Interest Network in Reinforcement Learning for Ads Allocation", "author": "Guogang Liao et.al.", "abstract": "A mixed list of ads and organic items is usually displayed in feed and how to allocate the limited slots to maximize the overall revenue is a key problem. Meanwhile, modeling user preference with historical behavior is essential in recommendation and advertising (e.g., CTR prediction and ads allocation). Most previous works for user behavior modeling only model user's historical point-level positive feedback (i.e., click), which neglect the page-level information of feedback and other types of feedback. To this end, we propose Deep Page-level Interest Network (DPIN) to model the page-level user preference and exploit multiple types of feedback. Specifically, we introduce four different types of page-level feedback as input, and capture user preference for item arrangement under different receptive fields through the multi-channel interaction module. Through extensive offline and online experiments on Meituan food delivery platform, we demonstrate that DPIN can effectively model the page-level user preference and increase the revenue for the platform.", "paper_url": "http://arxiv.org/abs/2204.00377v1", "pdf_url": "http://arxiv.org/pdf/2204.00377v1", "repo_url": null}, "2204.00308": {"publish_time": "2022-04-01", "title": "Model-agnostic Counterfactual Synthesis Policy for Interactive Recommendation", "author": "Siyu Wang et.al.", "abstract": "Interactive recommendation is able to learn from the interactive processes between users and systems to confront the dynamic interests of users. Recent advances have convinced that the ability of reinforcement learning to handle the dynamic process can be effectively applied in the interactive recommendation. However, the sparsity of interactive data may hamper the performance of the system. We propose to train a Model-agnostic Counterfactual Synthesis Policy to generate counterfactual data and address the data sparsity problem by modelling from observation and counterfactual distribution. The proposed policy can identify and replace the trivial components for any state in the training process with other agents, which can be deployed in any RL-based algorithm. The experimental results demonstrate the effectiveness and generality of our proposed policy.", "paper_url": "http://arxiv.org/abs/2204.00308v1", "pdf_url": "http://arxiv.org/pdf/2204.00308v1", "repo_url": null}, "2204.00306": {"publish_time": "2022-04-01", "title": "Building Decision Forest via Deep Reinforcement Learning", "author": "Guixuan Wen et.al.", "abstract": "Ensemble learning methods whose base classifier is a decision tree usually belong to the bagging or boosting. However, no previous work has ever built the ensemble classifier by maximizing long-term returns to the best of our knowledge. This paper proposes a decision forest building method called MA-H-SAC-DF for binary classification via deep reinforcement learning. First, the building process is modeled as a decentralized partial observable Markov decision process, and a set of cooperative agents jointly constructs all base classifiers. Second, the global state and local observations are defined based on informations of the parent node and the current location. Last, the state-of-the-art deep reinforcement method Hybrid SAC is extended to a multi-agent system under the CTDE architecture to find an optimal decision forest building policy. The experiments indicate that MA-H-SAC-DF has the same performance as random forest, Adaboost, and GBDT on balanced datasets and outperforms them on imbalanced datasets.", "paper_url": "http://arxiv.org/abs/2204.00306v1", "pdf_url": "http://arxiv.org/pdf/2204.00306v1", "repo_url": null}, "2204.00302": {"publish_time": "2022-04-01", "title": "Actual Causality and Responsibility Attribution in Decentralized Partially Observable Markov Decision Processes", "author": "Stelios Triantafyllou et.al.", "abstract": "Actual causality and a closely related concept of responsibility attribution are central to accountable decision making. Actual causality focuses on specific outcomes and aims to identify decisions (actions) that were critical in realizing an outcome of interest. Responsibility attribution is complementary and aims to identify the extent to which decision makers (agents) are responsible for this outcome. In this paper, we study these concepts under a widely used framework for multi-agent sequential decision making under uncertainty: decentralized partially observable Markov decision processes (Dec-POMDPs). Following recent works in RL that show correspondence between POMDPs and Structural Causal Models (SCMs), we first establish a connection between Dec-POMDPs and SCMs. This connection enables us to utilize a language for describing actual causality from prior work and study existing definitions of actual causality in Dec-POMDPs. Given that some of the well-known definitions may lead to counter-intuitive actual causes, we introduce a novel definition that more explicitly accounts for causal dependencies between agents' actions. We then turn to responsibility attribution based on actual causality, where we argue that in ascribing responsibility to an agent it is important to consider both the number of actual causes in which the agent participates, as well as its ability to manipulate its own degree of responsibility. Motivated by these arguments we introduce a family of responsibility attribution methods that extends prior work, while accounting for the aforementioned considerations. Finally, through a simulation-based experiment, we compare different definitions of actual causality and responsibility attribution methods. The empirical results demonstrate the qualitative difference between the considered definitions of actual causality and their impact on attributed responsibility.", "paper_url": "http://arxiv.org/abs/2204.00302v1", "pdf_url": "http://arxiv.org/pdf/2204.00302v1", "repo_url": null}, "2204.01597": {"publish_time": "2022-04-04", "title": "Optimising Energy Efficiency in UAV-Assisted Networks using Deep Reinforcement Learning", "author": "Babatunji Omoniwa et.al.", "abstract": "In this letter, we study the energy efficiency (EE) optimisation of unmanned aerial vehicles (UAVs) providing wireless coverage to static and mobile ground users. Recent multi-agent reinforcement learning approaches optimise the system's EE using a 2D trajectory design, neglecting interference from nearby UAV cells. We aim to maximise the system's EE by jointly optimising each UAV's 3D trajectory, number of connected users, and the energy consumed, while accounting for interference. Thus, we propose a cooperative Multi-Agent Decentralised Double Deep Q-Network (MAD-DDQN) approach. Our approach outperforms existing baselines in terms of EE by as much as 55 -- 80%.", "paper_url": "http://arxiv.org/abs/2204.01597v1", "pdf_url": "http://arxiv.org/pdf/2204.01597v1", "repo_url": null}, "2204.01464": {"publish_time": "2022-04-04", "title": "Value Gradient weighted Model-Based Reinforcement Learning", "author": "Claas Voelcker et.al.", "abstract": "Model-based reinforcement learning (MBRL) is a sample efficient technique to obtain control policies, yet unavoidable modeling errors often lead performance deterioration. The model in MBRL is often solely fitted to reconstruct dynamics, state observations in particular, while the impact of model error on the policy is not captured by the training objective. This leads to a mismatch between the intended goal of MBRL, enabling good policy and value learning, and the target of the loss function employed in practice, future state prediction. Naive intuition would suggest that value-aware model learning would fix this problem and, indeed, several solutions to this objective mismatch problem have been proposed based on theoretical analysis. However, they tend to be inferior in practice to commonly used maximum likelihood (MLE) based approaches. In this paper we propose the Value-gradient weighted Model Learning (VaGraM), a novel method for value-aware model learning which improves the performance of MBRL in challenging settings, such as small model capacity and the presence of distracting state dimensions. We analyze both MLE and value-aware approaches and demonstrate how they fail to account for exploration and the behavior of function approximation when learning value-aware models and highlight the additional goals that must be met to stabilize optimization in the deep learning setting. We verify our analysis by showing that our loss function is able to achieve high returns on the Mujoco benchmark suite while being more robust than maximum likelihood based approaches.", "paper_url": "http://arxiv.org/abs/2204.01464v1", "pdf_url": "http://arxiv.org/pdf/2204.01464v1", "repo_url": null}, "2204.01437": {"publish_time": "2022-04-04", "title": "Disentangling Abstraction from Statistical Pattern Matching in Human and Machine Learning", "author": "Sreejan Kumar et.al.", "abstract": "The ability to acquire abstract knowledge is a hallmark of human intelligence and is believed by many to be one of the core differences between humans and neural network models. Agents can be endowed with an inductive bias towards abstraction through meta-learning, where they are trained on a distribution of tasks that share some abstract structure that can be learned and applied. However, because neural networks are hard to interpret, it can be difficult to tell whether agents have learned the underlying abstraction, or alternatively statistical patterns that are characteristic of that abstraction. In this work, we compare the performance of humans and agents in a meta-reinforcement learning paradigm in which tasks are generated from abstract rules. We define a novel methodology for building \"task metamers\" that closely match the statistics of the abstract tasks but use a different underlying generative process, and evaluate performance on both abstract and metamer tasks. In our first set of experiments, we found that humans perform better at abstract tasks than metamer tasks whereas a widely-used meta-reinforcement learning agent performs worse on the abstract tasks than the matched metamers. In a second set of experiments, we base the tasks on abstractions derived directly from empirically identified human priors. We utilize the same procedure to generate corresponding metamer tasks, and see the same double dissociation between humans and agents. This work provides a foundation for characterizing differences between humans and machine learning that can be used in future work towards developing machines with human-like behavior.", "paper_url": "http://arxiv.org/abs/2204.01437v1", "pdf_url": "http://arxiv.org/pdf/2204.01437v1", "repo_url": "https://github.com/sreejank/Abstract_Neural_Metamers"}, "2204.01409": {"publish_time": "2022-04-04", "title": "Safe Controller for Output Feedback Linear Systems using Model-Based Reinforcement Learning", "author": "S M Nahid Mahmud et.al.", "abstract": "The objective of this research is to enable safety-critical systems to simultaneously learn and execute optimal control policies in a safe manner to achieve complex autonomy. Learning optimal policies via trial and error, i.e., traditional reinforcement learning, is difficult to implement in safety-critical systems, particularly when task restarts are unavailable. Safe model-based reinforcement learning techniques based on a barrier transformation have recently been developed to address this problem. However, these methods rely on full state feedback, limiting their usability in a real-world environment. In this work, an output-feedback safe model-based reinforcement learning technique based on a novel barrier-aware dynamic state estimator has been designed to address this issue. The developed approach facilitates simultaneous learning and execution of safe control policies for safety-critical linear systems. Simulation results indicate that barrier transformation is an effective approach to achieve online reinforcement learning in safety-critical systems using output feedback.", "paper_url": "http://arxiv.org/abs/2204.01409v1", "pdf_url": "http://arxiv.org/pdf/2204.01409v1", "repo_url": null}, "2204.01266": {"publish_time": "2022-04-04", "title": "CIRS: Bursting Filter Bubbles by Counterfactual Interactive Recommender System", "author": "Chongming Gao et.al.", "abstract": "While personalization increases the utility of recommender systems, it also brings the issue of filter bubbles. E.g., if the system keeps exposing and recommending the items that the user is interested in, it may also make the user feel bored and less satisfied. Existing work studies filter bubbles in static recommendation, where the effect of overexposure is hard to capture. In contrast, we believe it is more meaningful to study the issue in interactive recommendation and optimize long-term user satisfaction. Nevertheless, it is unrealistic to train the model online due to the high cost. As such, we have to leverage offline training data and disentangle the causal effect on user satisfaction.   To achieve this goal, we propose a counterfactual interactive recommender system (CIRS) that augments offline reinforcement learning (offline RL) with causal inference. The basic idea is to first learn a causal user model on historical data to capture the overexposure effect of items on user satisfaction. It then uses the learned causal user model to help the planning of the RL policy. To conduct evaluation offline, we innovatively create an authentic RL environment (KuaiEnv) based on a real-world fully observed user rating dataset. The experiments show the effectiveness of CIRS in bursting filter bubbles and achieving long-term success in interactive recommendation. The implementation of CIRS is available via https://github.com/chongminggao/CIRS-codes.", "paper_url": "http://arxiv.org/abs/2204.01266v1", "pdf_url": "http://arxiv.org/pdf/2204.01266v1", "repo_url": "https://github.com/chongminggao/cirs-codes"}, "2204.02395": {"publish_time": "2022-04-05", "title": "A Piecewise Learning Framework for Control of Unknown Nonlinear Systems with Stability Guarantees", "author": "Milad Farsi et.al.", "abstract": "We propose a piecewise learning framework for controlling nonlinear systems with unknown dynamics. While model-based reinforcement learning techniques in terms of some basis functions are well known in the literature, when it comes to more complex dynamics, only a local approximation of the model can be obtained using a limited number of bases. The complexity of the identifier and the controller can be considerably high if obtaining an approximation over a larger domain is desired. To overcome this limitation, we propose a general piecewise nonlinear framework where each piece is responsible for locally learning and controlling over some region of the domain. We obtain rigorous uncertainty bounds for the learned piecewise models. The piecewise affine (PWA) model is then studied as a special case, for which we propose an optimization-based verification technique for stability analysis of the closed-loop system. Accordingly, given a time-discretization of the learned {PWA} system, we iteratively search for a common piecewise Lyapunov function in a set of positive definite functions, where a non-monotonic convergence is allowed. This Lyapunov candidate is verified on the uncertain system to either provide a certificate for stability or find a counter-example when it fails. This counter-example is added to a set of samples to facilitate the further learning of a Lyapunov function. We demonstrate the results on two examples and show that the proposed approach yields a less conservative region of attraction (ROA) compared with alternative state-of-the-art approaches. Moreover, we provide the runtime results to demonstrate potentials of the proposed framework in real-world implementations.", "paper_url": "http://arxiv.org/abs/2204.02395v1", "pdf_url": "http://arxiv.org/pdf/2204.02395v1", "repo_url": null}, "2204.02393": {"publish_time": "2022-04-05", "title": "Action-Conditioned Contrastive Policy Pretraining", "author": "Qihang Zhang et.al.", "abstract": "Deep visuomotor policy learning achieves promising results in control tasks such as robotic manipulation and autonomous driving, where the action is generated from the visual input by the neural policy. However, it requires a huge number of online interactions with the training environment, which limits its real-world application. Compared to the popular unsupervised feature learning for visual recognition, feature pretraining for visuomotor control tasks is much less explored. In this work, we aim to pretrain policy representations for driving tasks using hours-long uncurated YouTube videos. A new contrastive policy pretraining method is developed to learn action-conditioned features from video frames with action pseudo labels. Experiments show that the resulting action-conditioned features bring substantial improvements to the downstream reinforcement learning and imitation learning tasks, outperforming the weights pretrained from previous unsupervised learning methods. Code and models will be made publicly available.", "paper_url": "http://arxiv.org/abs/2204.02393v1", "pdf_url": "http://arxiv.org/pdf/2204.02393v1", "repo_url": null}, "2204.02390": {"publish_time": "2022-04-05", "title": "Learning Pneumatic Non-Prehensile Manipulation with a Mobile Blower", "author": "Jimmy Wu et.al.", "abstract": "We investigate pneumatic non-prehensile manipulation (i.e., blowing) as a means of efficiently moving scattered objects into a target receptacle. Due to the chaotic nature of aerodynamic forces, a blowing controller must (i) continually adapt to unexpected changes from its actions, (ii) maintain fine-grained control, since the slightest misstep can result in large unintended consequences (e.g., scatter objects already in a pile), and (iii) infer long-range plans (e.g., move the robot to strategic blowing locations). We tackle these challenges in the context of deep reinforcement learning, introducing a multi-frequency version of the spatial action maps framework. This allows for efficient learning of vision-based policies that effectively combine high-level planning and low-level closed-loop control for dynamic mobile manipulation. Experiments show that our system learns efficient behaviors for the task, demonstrating in particular that blowing achieves better downstream performance than pushing, and that our policies improve performance over baselines. Moreover, we show that our system naturally encourages emergent specialization between the different subpolicies spanning low-level fine-grained control and high-level planning. On a real mobile robot equipped with a miniature air blower, we show that our simulation-trained policies transfer well to a real environment and can generalize to novel objects.", "paper_url": "http://arxiv.org/abs/2204.02390v1", "pdf_url": "http://arxiv.org/pdf/2204.02390v1", "repo_url": null}, "2204.02372": {"publish_time": "2022-04-05", "title": "Jump-Start Reinforcement Learning", "author": "Ikechukwu Uchendu et.al.", "abstract": "Reinforcement learning (RL) provides a theoretical framework for continuously improving an agent's behavior via trial and error. However, efficiently learning policies from scratch can be very difficult, particularly for tasks with exploration challenges. In such settings, it might be desirable to initialize RL with an existing policy, offline data, or demonstrations. However, naively performing such initialization in RL often works poorly, especially for value-based methods. In this paper, we present a meta algorithm that can use offline data, demonstrations, or a pre-existing policy to initialize an RL policy, and is compatible with any RL approach. In particular, we propose Jump-Start Reinforcement Learning (JSRL), an algorithm that employs two policies to solve tasks: a guide-policy, and an exploration-policy. By using the guide-policy to form a curriculum of starting states for the exploration-policy, we are able to efficiently improve performance on a set of simulated robotic tasks. We show via experiments that JSRL is able to significantly outperform existing imitation and reinforcement learning algorithms, particularly in the small-data regime. In addition, we provide an upper bound on the sample complexity of JSRL and show that with the help of a guide-policy, one can improve the sample complexity for non-optimism exploration methods from exponential in horizon to polynomial.", "paper_url": "http://arxiv.org/abs/2204.02372v1", "pdf_url": "http://arxiv.org/pdf/2204.02372v1", "repo_url": null}, "2204.02320": {"publish_time": "2022-04-05", "title": "Learning Generalizable Dexterous Manipulation from Human Grasp Affordance", "author": "Yueh-Hua Wu et.al.", "abstract": "Dexterous manipulation with a multi-finger hand is one of the most challenging problems in robotics. While recent progress in imitation learning has largely improved the sample efficiency compared to Reinforcement Learning, the learned policy can hardly generalize to manipulate novel objects, given limited expert demonstrations. In this paper, we propose to learn dexterous manipulation using large-scale demonstrations with diverse 3D objects in a category, which are generated from a human grasp affordance model. This generalizes the policy to novel object instances within the same category. To train the policy, we propose a novel imitation learning objective jointly with a geometric representation learning objective using our demonstrations. By experimenting with relocating diverse objects in simulation, we show that our approach outperforms baselines with a large margin when manipulating novel objects. We also ablate the importance on 3D object representation learning for manipulation. We include videos, code, and additional information on the project website - https://kristery.github.io/ILAD/ .", "paper_url": "http://arxiv.org/abs/2204.02320v1", "pdf_url": "http://arxiv.org/pdf/2204.02320v1", "repo_url": null}, "2204.02877": {"publish_time": "2022-04-06", "title": "PAnDR: Fast Adaptation to New Environments from Offline Experiences via Decoupling Policy and Environment Representations", "author": "Tong Sang et.al.", "abstract": "Deep Reinforcement Learning (DRL) has been a promising solution to many complex decision-making problems. Nevertheless, the notorious weakness in generalization among environments prevent widespread application of DRL agents in real-world scenarios. Although advances have been made recently, most prior works assume sufficient online interaction on training environments, which can be costly in practical cases. To this end, we focus on an \\textit{offline-training-online-adaptation} setting, in which the agent first learns from offline experiences collected in environments with different dynamics and then performs online policy adaptation in environments with new dynamics. In this paper, we propose Policy Adaptation with Decoupled Representations (PAnDR) for fast policy adaptation. In offline training phase, the environment representation and policy representation are learned through contrastive learning and policy recovery, respectively. The representations are further refined by mutual information optimization to make them more decoupled and complete. With learned representations, a Policy-Dynamics Value Function (PDVF) (Raileanu et al., 2020) network is trained to approximate the values for different combinations of policies and environments. In online adaptation phase, with the environment context inferred from few experiences collected in new environments, the policy is optimized by gradient ascent with respect to the PDVF. Our experiments show that PAnDR outperforms existing algorithms in several representative policy adaptation problems.", "paper_url": "http://arxiv.org/abs/2204.02877v1", "pdf_url": "http://arxiv.org/pdf/2204.02877v1", "repo_url": null}, "2204.02737": {"publish_time": "2022-04-06", "title": "Adversarial Learning to Reason in an Arbitrary Logic", "author": "Stanis\u0142aw J. Purga\u0142 et.al.", "abstract": "Existing approaches to learning to prove theorems focus on particular logics and datasets. In this work, we propose Monte-Carlo simulations guided by reinforcement learning that can work in an arbitrarily specified logic, without any human knowledge or set of problems. Since the algorithm does not need any training dataset, it is able to learn to work with any logical foundation, even when there is no body of proofs or even conjectures available. We practically demonstrate the feasibility of the approach in multiple logical systems. The approach is stronger than training on randomly generated data but weaker than the approaches trained on tailored axiom and conjecture sets. It however allows us to apply machine learning to automated theorem proving for many logics, where no such attempts have been tried to date, such as intuitionistic logic or linear logic.", "paper_url": "http://arxiv.org/abs/2204.02737v1", "pdf_url": "http://arxiv.org/pdf/2204.02737v1", "repo_url": null}, "2204.02654": {"publish_time": "2022-04-06", "title": "Adversarial Analysis of the Differentially-Private Federated Learning in Cyber-Physical Critical Infrastructures", "author": "Md Tamjid Hossain et.al.", "abstract": "Differential privacy (DP) is considered to be an effective privacy-preservation method to secure the promising distributed machine learning (ML) paradigm-federated learning (FL) from privacy attacks (e.g., membership inference attack). Nevertheless, while the DP mechanism greatly alleviates privacy concerns, recent studies have shown that it can be exploited to conduct security attacks (e.g., false data injection attacks). To address such attacks on FL-based applications in critical infrastructures, in this paper, we perform the first systematic study on the DP-exploited poisoning attacks from an adversarial point of view. We demonstrate that the DP method, despite providing a level of privacy guarantee, can effectively open a new poisoning attack vector for the adversary. Our theoretical analysis and empirical evaluation of a smart grid dataset show the FL performance degradation (sub-optimal model generation) scenario due to the differential noise-exploited selective model poisoning attacks. As a countermeasure, we propose a reinforcement learning-based differential privacy level selection (rDP) process. The rDP process utilizes the differential privacy parameters (privacy loss, information leakage probability, etc.) and the losses to intelligently generate an optimal privacy level for the nodes. The evaluation shows the accumulated reward and errors of the proposed technique converge to an optimal privacy policy.", "paper_url": "http://arxiv.org/abs/2204.02654v1", "pdf_url": "http://arxiv.org/pdf/2204.02654v1", "repo_url": null}, "2204.02634": {"publish_time": "2022-04-06", "title": "Federated Reinforcement Learning with Environment Heterogeneity", "author": "Hao Jin et.al.", "abstract": "We study a Federated Reinforcement Learning (FedRL) problem in which $n$ agents collaboratively learn a single policy without sharing the trajectories they collected during agent-environment interaction. We stress the constraint of environment heterogeneity, which means $n$ environments corresponding to these $n$ agents have different state transitions. To obtain a value function or a policy function which optimizes the overall performance in all environments, we propose two federated RL algorithms, \\texttt{QAvg} and \\texttt{PAvg}. We theoretically prove that these algorithms converge to suboptimal solutions, while such suboptimality depends on how heterogeneous these $n$ environments are. Moreover, we propose a heuristic that achieves personalization by embedding the $n$ environments into $n$ vectors. The personalization heuristic not only improves the training but also allows for better generalization to new environments.", "paper_url": "http://arxiv.org/abs/2204.02634v1", "pdf_url": "http://arxiv.org/pdf/2204.02634v1", "repo_url": "https://github.com/pengyang7881187/fedrl"}, "2204.02558": {"publish_time": "2022-04-06", "title": "DouZero+: Improving DouDizhu AI by Opponent Modeling and Coach-guided Learning", "author": "Youpeng Zhao et.al.", "abstract": "Recent years have witnessed the great breakthrough of deep reinforcement learning (DRL) in various perfect and imperfect information games. Among these games, DouDizhu, a popular card game in China, is very challenging due to the imperfect information, large state space, elements of collaboration and a massive number of possible moves from turn to turn. Recently, a DouDizhu AI system called DouZero has been proposed. Trained using traditional Monte Carlo method with deep neural networks and self-play procedure without the abstraction of human prior knowledge, DouZero has outperformed all the existing DouDizhu AI programs. In this work, we propose to enhance DouZero by introducing opponent modeling into DouZero. Besides, we propose a novel coach network to further boost the performance of DouZero and accelerate its training process. With the integration of the above two techniques into DouZero, our DouDizhu AI system achieves better performance and ranks top in the Botzone leaderboard among more than 400 AI agents, including DouZero.", "paper_url": "http://arxiv.org/abs/2204.02558v1", "pdf_url": "http://arxiv.org/pdf/2204.02558v1", "repo_url": null}, "2204.03597": {"publish_time": "2022-04-07", "title": "Imitating, Fast and Slow: Robust learning from demonstrations via decision-time planning", "author": "Carl Qi et.al.", "abstract": "The goal of imitation learning is to mimic expert behavior from demonstrations, without access to an explicit reward signal. A popular class of approach infers the (unknown) reward function via inverse reinforcement learning (IRL) followed by maximizing this reward function via reinforcement learning (RL). The policies learned via these approaches are however very brittle in practice and deteriorate quickly even with small test-time perturbations due to compounding errors. We propose Imitation with Planning at Test-time (IMPLANT), a new meta-algorithm for imitation learning that utilizes decision-time planning to correct for compounding errors of any base imitation policy. In contrast to existing approaches, we retain both the imitation policy and the rewards model at decision-time, thereby benefiting from the learning signal of the two components. Empirically, we demonstrate that IMPLANT significantly outperforms benchmark imitation learning approaches on standard control environments and excels at zero-shot generalization when subject to challenging perturbations in test-time dynamics.", "paper_url": "http://arxiv.org/abs/2204.03597v1", "pdf_url": "http://arxiv.org/pdf/2204.03597v1", "repo_url": null}, "2204.03525": {"publish_time": "2022-04-07", "title": "Temporal Alignment for History Representation in Reinforcement Learning", "author": "Aleksandr Ermolov et.al.", "abstract": "Environments in Reinforcement Learning are usually only partially observable. To address this problem, a possible solution is to provide the agent with information about the past. However, providing complete observations of numerous steps can be excessive. Inspired by human memory, we propose to represent history with only important changes in the environment and, in our approach, to obtain automatically this representation using self-supervision. Our method (TempAl) aligns temporally-close frames, revealing a general, slowly varying state of the environment. This procedure is based on contrastive loss, which pulls embeddings of nearby observations to each other while pushing away other samples from the batch. It can be interpreted as a metric that captures the temporal relations of observations. We propose to combine both common instantaneous and our history representation and we evaluate TempAl on all available Atari games from the Arcade Learning Environment. TempAl surpasses the instantaneous-only baseline in 35 environments out of 49. The source code of the method and of all the experiments is available at https://github.com/htdt/tempal.", "paper_url": "http://arxiv.org/abs/2204.03525v1", "pdf_url": "http://arxiv.org/pdf/2204.03525v1", "repo_url": "https://github.com/htdt/tempal"}, "2204.03516": {"publish_time": "2022-04-07", "title": "Distributed Reinforcement Learning for Robot Teams: A Review", "author": "Yutong Wang et.al.", "abstract": "Purpose of review: Recent advances in sensing, actuation, and computation have opened the door to multi-robot systems consisting of hundreds/thousands of robots, with promising applications to automated manufacturing, disaster relief, harvesting, last-mile delivery, port/airport operations, or search and rescue. The community has leveraged model-free multi-agent reinforcement learning (MARL) to devise efficient, scalable controllers for multi-robot systems (MRS). This review aims to provide an analysis of the state-of-the-art in distributed MARL for multi-robot cooperation.   Recent findings: Decentralized MRS face fundamental challenges, such as non-stationarity and partial observability. Building upon the \"centralized training, decentralized execution\" paradigm, recent MARL approaches include independent learning, centralized critic, value decomposition, and communication learning approaches. Cooperative behaviors are demonstrated through AI benchmarks and fundamental real-world robotic capabilities such as multi-robot motion/path planning.   Summary: This survey reports the challenges surrounding decentralized model-free MARL for multi-robot cooperation and existing classes of approaches. We present benchmarks and robotic applications along with a discussion on current open avenues for research.", "paper_url": "http://arxiv.org/abs/2204.03516v1", "pdf_url": "http://arxiv.org/pdf/2204.03516v1", "repo_url": null}, "2204.03514": {"publish_time": "2022-04-07", "title": "Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale", "author": "Ram Ramrakhya et.al.", "abstract": "We present a large-scale study of imitating human demonstrations on tasks that require a virtual robot to search for objects in new environments -- (1) ObjectGoal Navigation (e.g. 'find & go to a chair') and (2) Pick&Place (e.g. 'find mug, pick mug, find counter, place mug on counter'). First, we develop a virtual teleoperation data-collection infrastructure -- connecting Habitat simulator running in a web browser to Amazon Mechanical Turk, allowing remote users to teleoperate virtual robots, safely and at scale. We collect 80k demonstrations for ObjectNav and 12k demonstrations for Pick&Place, which is an order of magnitude larger than existing human demonstration datasets in simulation or on real robots.   Second, we attempt to answer the question -- how does large-scale imitation learning (IL) (which hasn't been hitherto possible) compare to reinforcement learning (RL) (which is the status quo)? On ObjectNav, we find that IL (with no bells or whistles) using 70k human demonstrations outperforms RL using 240k agent-gathered trajectories. The IL-trained agent demonstrates efficient object-search behavior -- it peeks into rooms, checks corners for small objects, turns in place to get a panoramic view -- none of these are exhibited as prominently by the RL agent, and to induce these behaviors via RL would require tedious reward engineering. Finally, accuracy vs. training data size plots show promising scaling behavior, suggesting that simply collecting more demonstrations is likely to advance the state of art further. On Pick&Place, the comparison is starker -- IL agents achieve ${\\sim}$18% success on episodes with new object-receptacle locations when trained with 9.5k human demonstrations, while RL agents fail to get beyond 0%. Overall, our work provides compelling evidence for investing in large-scale imitation learning.   Project page: https://ram81.github.io/projects/habitat-web.", "paper_url": "http://arxiv.org/abs/2204.03514v1", "pdf_url": "http://arxiv.org/pdf/2204.03514v1", "repo_url": null}, "2204.03487": {"publish_time": "2022-04-07", "title": "Optimizing the Long-Term Behaviour of Deep Reinforcement Learning for Pushing and Grasping", "author": "Rodrigo Chau et.al.", "abstract": "We investigate the \"Visual Pushing for Grasping\" (VPG) system by Zeng et al. and the \"Hourglass\" system by Ewerton et al., an evolution of the former. The focus of our work is the investigation of the capabilities of both systems to learn long-term rewards and policies. Zeng et al. original task only needs a limited amount of foresight. Ewerton et al. attain their best performance using an agent which only takes the most immediate action under consideration. We are interested in the ability of their models and training algorithms to accurately predict long-term Q-Values. To evaluate this ability, we design a new bin sorting task and reward function. Our task requires agents to accurately estimate future rewards and therefore use high discount factors in their Q-Value calculation. We investigate the behaviour of an adaptation of the VPG training algorithm on our task. We show that this adaptation can not accurately predict the required long-term action sequences. In addition to the limitations identified by Ewerton et al., it suffers from the known Deep Q-Learning problem of overestimated Q-Values. In an effort to solve our task, we turn to the Hourglass models and combine them with the Double Q-Learning approach. We show that this approach enables the models to accurately predict long-term action sequences when trained with large discount factors. Our results show that the Double Q-Learning technique is essential for training with very high discount factors, as the models Q-Value predictions diverge otherwise. We also experiment with different approaches for discount factor scheduling, loss calculation and exploration procedures. Our results show that the latter factors do not visibly influence the model's performance for our task.", "paper_url": "http://arxiv.org/abs/2204.03487v1", "pdf_url": "http://arxiv.org/pdf/2204.03487v1", "repo_url": null}, "2204.04198": {"publish_time": "2022-04-08", "title": "Modern applications of machine learning in quantum sciences", "author": "Anna Dawid et.al.", "abstract": "In these Lecture Notes, we provide a comprehensive introduction to the most recent advances in the application of machine learning methods in quantum sciences. We cover the use of deep learning and kernel methods in supervised, unsupervised, and reinforcement learning algorithms for phase classification, representation of many-body quantum states, quantum feedback control, and quantum circuits optimization. Moreover, we introduce and discuss more specialized topics such as differentiable programming, generative models, statistical approach to machine learning, and quantum machine learning.", "paper_url": "http://arxiv.org/abs/2204.04198v1", "pdf_url": "http://arxiv.org/pdf/2204.04198v1", "repo_url": null}, "2204.04157": {"publish_time": "2022-04-08", "title": "Custom Sine Waves Are Enough for Imitation Learning of Bipedal Gaits with Different Styles", "author": "Qi Wu et.al.", "abstract": "Not until recently, robust bipedal locomotion has been achieved through reinforcement learning. However, existing implementations rely heavily on insights and efforts from human experts, which is costly for the iterative design of robot systems. Also, styles of the learned motion are strictly limited to that of the reference. In this paper, we propose a new way to learn bipedal locomotion from a simple sine wave as the reference for foot heights. With the naive human insight that the two feet should be lifted up alternatively and periodically, we experimentally demonstrate on the Cassie robot that, a simple reward function is able to make the robot learn to walk end-to-end and efficiently without any explicit knowledge of the model. With custom sine waves, the learned gait pattern can also have customized styles. Codes will be released at github.com/WooQi57/sin-cassie-rl.", "paper_url": "http://arxiv.org/abs/2204.04157v1", "pdf_url": "http://arxiv.org/pdf/2204.04157v1", "repo_url": null}, "2204.03991": {"publish_time": "2022-04-08", "title": "The Complexity of Markov Equilibrium in Stochastic Games", "author": "Constantinos Daskalakis et.al.", "abstract": "We show that computing approximate stationary Markov coarse correlated equilibria (CCE) in general-sum stochastic games is computationally intractable, even when there are two players, the game is turn-based, the discount factor is an absolute constant, and the approximation is an absolute constant. Our intractability results stand in sharp contrast to normal-form games where exact CCEs are efficiently computable. A fortiori, our results imply that there are no efficient algorithms for learning stationary Markov CCE policies in multi-agent reinforcement learning (MARL), even when the interaction is two-player and turn-based, and both the discount factor and the desired approximation of the learned policies is an absolute constant. In turn, these results stand in sharp contrast to single-agent reinforcement learning (RL) where near-optimal stationary Markov policies can be efficiently learned. Complementing our intractability results for stationary Markov CCEs, we provide a decentralized algorithm (assuming shared randomness among players) for learning a nonstationary Markov CCE policy with polynomial time and sample complexity in all problem parameters. Previous work for learning Markov CCE policies all required exponential time and sample complexity in the number of players.", "paper_url": "http://arxiv.org/abs/2204.03991v1", "pdf_url": "http://arxiv.org/pdf/2204.03991v1", "repo_url": null}, "2204.03973": {"publish_time": "2022-04-08", "title": "Gradient dynamics in reinforcement learning", "author": "Riccardo Fabbricatore et.al.", "abstract": "Despite the success achieved by the analysis of supervised learning algorithms in the framework of statistical mechanics, reinforcement learning has remained largely untouched. Here we move towards closing the gap by analyzing the dynamics of the policy gradient algorithm. For a convex problem, we show that it obeys a drift-diffusion motion with coeffcients tuned by learning rate. Furthermore, we propose a mapping between a non-convex reinforcement learning problem and a disordered system. This mapping enables us to show how the learning rate acts as an effective temperature and thus is capable of smoothing rough landscapes, corroborating what is displayed by the drift-diffusive description and paving the way for physics-inspired algorithmic optimization based on annealing procedures in disordered systems.", "paper_url": "http://arxiv.org/abs/2204.03973v1", "pdf_url": "http://arxiv.org/pdf/2204.03973v1", "repo_url": null}, "2204.03897": {"publish_time": "2022-04-08", "title": "Sim-to-Real Learning of Robust Compliant Bipedal Locomotion on Torque Sensor-Less Gear-Driven Humanoid", "author": "Shimpei Masuda et.al.", "abstract": "In deep reinforcement learning, sim-to-real is the mainstream method as it needs a large number of trials, however, it is challenging to transfer trained policy due to reality gap. In particular, it is known that the characteristics of actuators in leg robots have a considerable influence on the reality gap, and this is also noticeable in high reduction ratio gears. Therefore, we propose a new simulation model of high reduction ratio gears to reduce the reality gap. The instability of the bipedal locomotion causes the sim-to-real transfer to fail catastrophically, making system identification of the physical parameters of the simulation difficult. Thus, we also propose a system identification method that utilizes the failure experience. The realistic simulations obtained by these improvements allow the robot to perform compliant bipedal locomotion by reinforcement learning. The effectiveness of the method is verified using a actual biped robot, ROBOTIS-OP3, and the sim-to-real transferred policy archived to stabilize the robot under severe disturbances and walk on uneven terrain without force and torque sensors.", "paper_url": "http://arxiv.org/abs/2204.03897v1", "pdf_url": "http://arxiv.org/pdf/2204.03897v1", "repo_url": null}, "2204.05275": {"publish_time": "2022-04-11", "title": "Settling the Sample Complexity of Model-Based Offline Reinforcement Learning", "author": "Gen Li et.al.", "abstract": "This paper is concerned with offline reinforcement learning (RL), which learns using pre-collected data without further exploration. Effective offline RL would be able to accommodate distribution shift and limited data coverage. However, prior algorithms or analyses either suffer from suboptimal sample complexities or incur high burn-in cost to reach sample optimality, thus posing an impediment to efficient offline RL in sample-starved applications.   We demonstrate that the model-based (or \"plug-in\") approach achieves minimax-optimal sample complexity without burn-in cost for tabular Markov decision processes (MDPs). Concretely, consider a finite-horizon (resp. $\\gamma$-discounted infinite-horizon) MDP with $S$ states and horizon $H$ (resp. effective horizon $\\frac{1}{1-\\gamma}$), and suppose the distribution shift of data is reflected by some single-policy clipped concentrability coefficient $C^{\\star}_{\\text{clipped}}$. We prove that model-based offline RL yields $\\varepsilon$-accuracy with a sample complexity of \\[ \\begin{cases} \\frac{H^{4}SC_{\\text{clipped}}^{\\star}}{\\varepsilon^{2}} & (\\text{finite-horizon MDPs}) \\frac{SC_{\\text{clipped}}^{\\star}}{(1-\\gamma)^{3}\\varepsilon^{2}} & (\\text{infinite-horizon MDPs}) \\end{cases} \\] up to log factor, which is minimax optimal for the entire $\\varepsilon$-range. Our algorithms are \"pessimistic\" variants of value iteration with Bernstein-style penalties, and do not require sophisticated variance reduction.", "paper_url": "http://arxiv.org/abs/2204.05275v1", "pdf_url": "http://arxiv.org/pdf/2204.05275v1", "repo_url": null}, "2204.05263": {"publish_time": "2022-04-11", "title": "Maximum entropy optimal density control of discrete-time linear systems and Schr\u00f6dinger bridges", "author": "Kaito Ito et.al.", "abstract": "We consider an entropy-regularized version of optimal density control of deterministic discrete-time linear systems. Entropy regularization, or a maximum entropy (MaxEnt) method for optimal control has attracted much attention especially in reinforcement learning due to its many advantages such as a natural exploration strategy. Despite the merits, high-entropy control policies introduce probabilistic uncertainty into systems, which severely limits the applicability of MaxEnt optimal control to safety-critical systems. To remedy this situation, we impose a Gaussian density constraint at a specified time on the MaxEnt optimal control to directly control state uncertainty. Specifically, we derive the explicit form of the MaxEnt optimal density control. In addition, we also consider the case where a density constraint is replaced by a fixed point constraint. Then, we characterize the associated state process as a pinned process, which is a generalization of the Brownian bridge to linear systems. Finally, we reveal that the MaxEnt optimal density control induces the so-called Schr\\\"odinger bridge associated to a discrete-time linear system.", "paper_url": "http://arxiv.org/abs/2204.05263v1", "pdf_url": "http://arxiv.org/pdf/2204.05263v1", "repo_url": null}, "2204.05196": {"publish_time": "2022-04-11", "title": "Automatically Learning Fallback Strategies with Model-Free Reinforcement Learning in Safety-Critical Driving Scenarios", "author": "Ugo Lecerf et.al.", "abstract": "When learning to behave in a stochastic environment where safety is critical, such as driving a vehicle in traffic, it is natural for human drivers to plan fallback strategies as a backup to use if ever there is an unexpected change in the environment. Knowing to expect the unexpected, and planning for such outcomes, increases our capability for being robust to unseen scenarios and may help prevent catastrophic failures. Control of Autonomous Vehicles (AVs) has a particular interest in knowing when and how to use fallback strategies in the interest of safety. Due to imperfect information available to an AV about its environment, it is important to have alternate strategies at the ready which might not have been deduced from the original training data distribution.   In this paper we present a principled approach for a model-free Reinforcement Learning (RL) agent to capture multiple modes of behaviour in an environment. We introduce an extra pseudo-reward term to the reward model, to encourage exploration to areas of state-space different from areas privileged by the optimal policy. We base this reward term on a distance metric between the trajectories of agents, in order to force policies to focus on different areas of state-space than the initial exploring agent. Throughout the paper, we refer to this particular training paradigm as learning fallback strategies.   We apply this method to an autonomous driving scenario, and show that we are able to learn useful policies that would have otherwise been missed out on during training, and unavailable to use when executing the control algorithm.", "paper_url": "http://arxiv.org/abs/2204.05196v1", "pdf_url": "http://arxiv.org/pdf/2204.05196v1", "repo_url": null}, "2204.05036": {"publish_time": "2022-04-11", "title": "Pareto Conditioned Networks", "author": "Mathieu Reymond et.al.", "abstract": "In multi-objective optimization, learning all the policies that reach Pareto-efficient solutions is an expensive process. The set of optimal policies can grow exponentially with the number of objectives, and recovering all solutions requires an exhaustive exploration of the entire state space. We propose Pareto Conditioned Networks (PCN), a method that uses a single neural network to encompass all non-dominated policies. PCN associates every past transition with its episode's return. It trains the network such that, when conditioned on this same return, it should reenact said transition. In doing so we transform the optimization problem into a classification problem. We recover a concrete policy by conditioning the network on the desired Pareto-efficient solution. Our method is stable as it learns in a supervised fashion, thus avoiding moving target issues. Moreover, by using a single network, PCN scales efficiently with the number of objectives. Finally, it makes minimal assumptions on the shape of the Pareto front, which makes it suitable to a wider range of problems than previous state-of-the-art multi-objective reinforcement learning algorithms.", "paper_url": "http://arxiv.org/abs/2204.05036v1", "pdf_url": "http://arxiv.org/pdf/2204.05036v1", "repo_url": null}, "2204.05027": {"publish_time": "2022-04-11", "title": "Exploring the Pareto front of multi-objective COVID-19 mitigation policies using reinforcement learning", "author": "Mathieu Reymond et.al.", "abstract": "Infectious disease outbreaks can have a disruptive impact on public health and societal processes. As decision making in the context of epidemic mitigation is hard, reinforcement learning provides a methodology to automatically learn prevention strategies in combination with complex epidemic models. Current research focuses on optimizing policies w.r.t. a single objective, such as the pathogen's attack rate. However, as the mitigation of epidemics involves distinct, and possibly conflicting criteria (i.a., prevalence, mortality, morbidity, cost), a multi-objective approach is warranted to learn balanced policies. To lift this decision-making process to real-world epidemic models, we apply deep multi-objective reinforcement learning and build upon a state-of-the-art algorithm, Pareto Conditioned Networks (PCN), to learn a set of solutions that approximates the Pareto front of the decision problem. We consider the first wave of the Belgian COVID-19 epidemic, which was mitigated by a lockdown, and study different deconfinement strategies, aiming to minimize both COVID-19 cases (i.e., infections and hospitalizations) and the societal burden that is induced by the applied mitigation measures. We contribute a multi-objective Markov decision process that encapsulates the stochastic compartment model that was used to inform policy makers during the COVID-19 epidemic. As these social mitigation measures are implemented in a continuous action space that modulates the contact matrix of the age-structured epidemic model, we extend PCN to this setting. We evaluate the solution returned by PCN, and observe that it correctly learns to reduce the social burden whenever the hospitalization rates are sufficiently low. In this work, we thus show that multi-objective reinforcement learning is attainable in complex epidemiological models and provides essential insights to balance complex mitigation policies.", "paper_url": "http://arxiv.org/abs/2204.05027v1", "pdf_url": "http://arxiv.org/pdf/2204.05027v1", "repo_url": null}, "2204.05951": {"publish_time": "2022-04-12", "title": "RL-CoSeg : A Novel Image Co-Segmentation Algorithm with Deep Reinforcement Learning", "author": "Xin Duan et.al.", "abstract": "This paper proposes an automatic image co-segmentation algorithm based on deep reinforcement learning (RL). Existing co-segmentation tasks mainly rely on deep learning methods, and the obtained foreground edges are often rough. In order to obtain more precise foreground edges, we use deep RL to solve this problem and achieve the finer segmentation. To our best knowledge, this is the first work to apply RL methods to co-segmentation. We define the problem as a Markov Decision Process (MDP) and optimize it by RL with asynchronous advantage actor-critic (A3C). The RL image co-segmentation network uses the correlation between images to segment common and salient objects from a set of related images. In order to achieve automatic segmentation, our RL-CoSeg method eliminates user's hints. For the image co-segmentation problem, we propose a collaborative RL algorithm based on the A3C model. We propose a Siamese RL co-segmentation network structure to obtain the co-attention of images for co-segmentation. We improve the self-attention for automatic RL algorithm to obtain long-distance dependence and enlarge the receptive field. The image feature information obtained by self-attention can be used to supplement the deleted user's hints and help to obtain more accurate actions. Experimental results have shown that our method can improve the performance effectively on both coarse and fine initial segmentations, and it achieves the state-of-the-art performance on Internet dataset, iCoseg dataset and MLMR-COS dataset.", "paper_url": "http://arxiv.org/abs/2204.05951v1", "pdf_url": "http://arxiv.org/pdf/2204.05951v1", "repo_url": null}, "2204.05928": {"publish_time": "2022-04-12", "title": "Dynamic Dialogue Policy Transformer for Continual Reinforcement Learning", "author": "Christian Geishauser et.al.", "abstract": "Continual learning is one of the key components of human learning and a necessary requirement of artificial intelligence. As dialogue can potentially span infinitely many topics and tasks, a task-oriented dialogue system must have the capability to continually learn, dynamically adapting to new challenges while preserving the knowledge it already acquired. Despite the importance, continual reinforcement learning of the dialogue policy has remained largely unaddressed. The lack of a framework with training protocols, baseline models and suitable metrics, has so far hindered research in this direction. In this work we fill precisely this gap, enabling research in dialogue policy optimisation to go from static to dynamic learning. We provide a continual learning algorithm, baseline architectures and metrics for assessing continual learning models. Moreover, we propose the dynamic dialogue policy transformer (DDPT), a novel dynamic architecture that can integrate new knowledge seamlessly, is capable of handling large state spaces and obtains significant zero-shot performance when being exposed to unseen domains, without any growth in network parameter size.", "paper_url": "http://arxiv.org/abs/2204.05928v1", "pdf_url": "http://arxiv.org/pdf/2204.05928v1", "repo_url": null}, "2204.05862": {"publish_time": "2022-04-12", "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback", "author": "Yuntao Bai et.al.", "abstract": "We apply preference modeling and reinforcement learning from human feedback (RLHF) to finetune language models to act as helpful and harmless assistants. We find this alignment training improves performance on almost all NLP evaluations, and is fully compatible with training for specialized skills such as python coding and summarization. We explore an iterated online mode of training, where preference models and RL policies are updated on a weekly cadence with fresh human feedback data, efficiently improving our datasets and models. Finally, we investigate the robustness of RLHF training, and identify a roughly linear relation between the RL reward and the square root of the KL divergence between the policy and its initialization. Alongside our main results, we perform peripheral analyses on calibration, competing objectives, and the use of OOD detection, compare our models with human writers, and provide samples from our models using prompts appearing in recent related work.", "paper_url": "http://arxiv.org/abs/2204.05862v1", "pdf_url": "http://arxiv.org/pdf/2204.05862v1", "repo_url": "https://github.com/anthropics/hh-rlhf"}, "2204.05669": {"publish_time": "2022-04-12", "title": "An Analysis of Discretization Methods for Communication Learning with Multi-Agent Reinforcement Learning", "author": "Astrid Vanneste et.al.", "abstract": "Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as two methods that have not been used for communication learning before. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. Our results show that none of the methods is best in all environments. The best choice in discretization method greatly depends on the environment. However, the discretize regularize unit (DRU), straight through DRU and the straight through gumbel softmax show the most consistent results across all the tested environments. Therefore, these methods prove to be the best choice for general use while the straight through estimator and the gumbel softmax may provide better results in specific environments but fail completely in others.", "paper_url": "http://arxiv.org/abs/2204.05669v1", "pdf_url": "http://arxiv.org/pdf/2204.05669v1", "repo_url": null}, "2204.05627": {"publish_time": "2022-04-12", "title": "Proximal Policy Optimization Learning based Control of Congested Freeway Traffic", "author": "Shurong Mo et.al.", "abstract": "This study proposes a delay-compensated feedback controller based on proximal policy optimization (PPO) reinforcement learning to stabilize traffic flow in the congested regime by manipulating the time-gap of adaptive cruise control-equipped (ACC-equipped) vehicles.The traffic dynamics on a freeway segment are governed by an Aw-Rascle-Zhang (ARZ) model, consisting of $2\\times 2$ nonlinear first-order partial differential equations (PDEs).Inspired by the backstepping delay compensator [18] but different from whose complex segmented control scheme, the PPO control is composed of three feedbacks, namely the current traffic flow velocity, the current traffic flow density and previous one step control input. The control gains for the three feedbacks are learned from the interaction between the PPO and the numerical simulator of the traffic system without knowing the system dynamics. Numerical simulation experiments are designed to compare the Lyapunov control, the backstepping control and the PPO control. The results show that for a delay-free system, the PPO control has faster convergence rate and less control effort than the Lyapunov control. For a traffic system with input delay, the performance of the PPO controller is comparable to that of the Backstepping controller, even for the situation that the delay value does not match. However, the PPO is robust to parameter perturbations, while the Backstepping controller cannot stabilize a system where one of the parameters is disturbed by Gaussian noise.", "paper_url": "http://arxiv.org/abs/2204.05627v1", "pdf_url": "http://arxiv.org/pdf/2204.05627v1", "repo_url": null}, "2204.06550": {"publish_time": "2022-04-13", "title": "Improving adaptability to new environments and removing catastrophic forgetting in Reinforcement Learning by using an eco-system of agents", "author": "Olivier Moulin et.al.", "abstract": "Adapting a Reinforcement Learning (RL) agent to an unseen environment is a difficult task due to typical over-fitting on the training environment. RL agents are often capable of solving environments very close to the trained environment, but when environments become substantially different, their performance quickly drops. When agents are retrained on new environments, a second issue arises: there is a risk of catastrophic forgetting, where the performance on previously seen environments is seriously hampered. This paper proposes a novel approach that exploits an ecosystem of agents to address both concerns. Hereby, the (limited) adaptive power of individual agents is harvested to build a highly adaptive ecosystem. This allows to transfer part of the workload from learning to inference. An evaluation of the approach on two distinct distributions of environments shows that our approach outperforms state-of-the-art techniques in terms of adaptability/generalization as well as avoids catastrophic forgetting.", "paper_url": "http://arxiv.org/abs/2204.06550v1", "pdf_url": "http://arxiv.org/pdf/2204.06550v1", "repo_url": null}, "2204.06436": {"publish_time": "2022-04-13", "title": "Label Augmentation with Reinforced Labeling for Weak Supervision", "author": "G\u00fcrkan Solmaz et.al.", "abstract": "Weak supervision (WS) is an alternative to the traditional supervised learning to address the need for ground truth. Data programming is a practical WS approach that allows programmatic labeling data samples using labeling functions (LFs) instead of hand-labeling each data point. However, the existing approach fails to fully exploit the domain knowledge encoded into LFs, especially when the LFs' coverage is low. This is due to the common data programming pipeline that neglects to utilize data features during the generative process. This paper proposes a new approach called reinforced labeling (RL). Given an unlabeled dataset and a set of LFs, RL augments the LFs' outputs to cases not covered by LFs based on similarities among samples. Thus, RL can lead to higher labeling coverage for training an end classifier. The experiments on several domains (classification of YouTube comments, wine quality, and weather prediction) result in considerable gains. The new approach produces significant performance improvement, leading up to +21 points in accuracy and +61 points in F1 scores compared to the state-of-the-art data programming approach.", "paper_url": "http://arxiv.org/abs/2204.06436v1", "pdf_url": "http://arxiv.org/pdf/2204.06436v1", "repo_url": null}, "2204.06407": {"publish_time": "2022-04-13", "title": "Flexible Multiple-Objective Reinforcement Learning for Chip Placement", "author": "Fu-Chieh Chang et.al.", "abstract": "Recently, successful applications of reinforcement learning to chip placement have emerged. Pretrained models are necessary to improve efficiency and effectiveness. Currently, the weights of objective metrics (e.g., wirelength, congestion, and timing) are fixed during pretraining. However, fixed-weighed models cannot generate the diversity of placements required for engineers to accommodate changing requirements as they arise. This paper proposes flexible multiple-objective reinforcement learning (MORL) to support objective functions with inference-time variable weights using just a single pretrained model. Our macro placement results show that MORL can generate the Pareto frontier of multiple objectives effectively.", "paper_url": "http://arxiv.org/abs/2204.06407v1", "pdf_url": "http://arxiv.org/pdf/2204.06407v1", "repo_url": null}, "2204.06355": {"publish_time": "2022-04-13", "title": "Local Feature Swapping for Generalization in Reinforcement Learning", "author": "David Bertoin et.al.", "abstract": "Over the past few years, the acceleration of computing resources and research in deep learning has led to significant practical successes in a range of tasks, including in particular in computer vision. Building on these advances, reinforcement learning has also seen a leap forward with the emergence of agents capable of making decisions directly from visual observations. Despite these successes, the over-parametrization of neural architectures leads to memorization of the data used during training and thus to a lack of generalization. Reinforcement learning agents based on visual inputs also suffer from this phenomenon by erroneously correlating rewards with unrelated visual features such as background elements. To alleviate this problem, we introduce a new regularization technique consisting of channel-consistent local permutations (CLOP) of the feature maps. The proposed permutations induce robustness to spatial correlations and help prevent overfitting behaviors in RL. We demonstrate, on the OpenAI Procgen Benchmark, that RL agents trained with the CLOP method exhibit robustness to visual changes and better generalization properties than agents trained using other state-of-the-art regularization techniques. We also demonstrate the effectiveness of CLOP as a general regularization technique in supervised learning.", "paper_url": "http://arxiv.org/abs/2204.06355v1", "pdf_url": "http://arxiv.org/pdf/2204.06355v1", "repo_url": null}, "2204.06288": {"publish_time": "2022-04-13", "title": "Automated Atomic Silicon Quantum Dot Circuit Design via Deep Reinforcement Learning", "author": "Robert Lupoiu et.al.", "abstract": "Robust automated design tools are crucial for the proliferation of any computing technology. We introduce the first automated design tool for the silicon dangling bond quantum dot computing technology, which is an extremely versatile and flexible single-atom computing circuitry framework. The automated designer is capable of navigating the complex, hyperdimensional design spaces of arbitrarily sized design areas and truth tables by employing a tabula rasa double-deep Q-learning reinforcement learning algorithm. Robust policy convergence is demonstrated for a wide range of two-input, one-output logic circuits and a two-input, two-output half-adder, designed with an order of magnitude fewer SiDBs in several orders of magnitude less time than the only other half-adder demonstrated in the literature. We anticipate that reinforcement learning-based automated design tools will accelerate the development of the SiDB quantum dot computing technology, leading to its eventual adoption in specialized computing hardware.", "paper_url": "http://arxiv.org/abs/2204.06288v1", "pdf_url": "http://arxiv.org/pdf/2204.06288v1", "repo_url": null}, "2204.07137": {"publish_time": "2022-04-14", "title": "Accelerated Policy Learning with Parallel Differentiable Simulation", "author": "Jie Xu et.al.", "abstract": "Deep reinforcement learning can generate complex control policies, but requires large amounts of training data to work effectively. Recent work has attempted to address this issue by leveraging differentiable simulators. However, inherent problems such as local minima and exploding/vanishing numerical gradients prevent these methods from being generally applied to control tasks with complex contact-rich dynamics, such as humanoid locomotion in classical RL benchmarks. In this work we present a high-performance differentiable simulator and a new policy learning algorithm (SHAC) that can effectively leverage simulation gradients, even in the presence of non-smoothness. Our learning algorithm alleviates problems with local minima through a smooth critic function, avoids vanishing/exploding gradients through a truncated learning window, and allows many physical environments to be run in parallel. We evaluate our method on classical RL control tasks, and show substantial improvements in sample efficiency and wall-clock time over state-of-the-art RL and differentiable simulation-based algorithms. In addition, we demonstrate the scalability of our method by applying it to the challenging high-dimensional problem of muscle-actuated locomotion with a large action space, achieving a greater than 17x reduction in training time over the best-performing established RL algorithm.", "paper_url": "http://arxiv.org/abs/2204.07137v1", "pdf_url": "http://arxiv.org/pdf/2204.07137v1", "repo_url": null}, "2204.07134": {"publish_time": "2022-04-14", "title": "Reinforcement Learning Policy Recommendation for Interbank Network Stability", "author": "Alessio Brini et.al.", "abstract": "In this paper we analyze the effect of a policy recommendation on the performances of an artificial interbank market. Financial institutions stipulate lending agreements following a public recommendation and their individual information. The former, modeled by a reinforcement learning optimal policy trying to maximize the long term fitness of the system, gathers information on the economic environment and directs economic actors to create credit relationships based on the optimal choice between a low interest rate or high liquidity supply. The latter, based on the agents' balance sheet, allows to determine the liquidity supply and interest rate that the banks optimally offer on the market. Based on the combination between the public and the private signal, financial institutions create or cut their credit connections over time via a preferential attachment evolving procedure able to generate a dynamic network. Our results show that the emergence of a core-periphery interbank network, combined with a certain level of homogeneity on the size of lenders and borrowers, are essential features to ensure the resilience of the system. Moreover, the reinforcement learning optimal policy recommendation plays a crucial role in mitigating systemic risk with respect to alternative policy instruments.", "paper_url": "http://arxiv.org/abs/2204.07134v1", "pdf_url": "http://arxiv.org/pdf/2204.07134v1", "repo_url": null}, "2204.07011": {"publish_time": "2022-04-14", "title": "Programming Quantum Hardware via Levenberg Marquardt Machine Learning", "author": "James E. Steck et.al.", "abstract": "Significant challenges remain with the development of macroscopic quantum computing, hardware problems of noise, decoherence, and scaling, software problems of error correction, and, most important, algorithm construction. Finding truly quantum algorithms is quite difficult, and many quantum algorithms, like Shor prime factoring or phase estimation, require extremely long circuit depth for any practical application, necessitating error correction. Machine learning can be used as a systematic method to nonalgorithmically program quantum computers. Quantum machine learning enables us to perform computations without breaking down an algorithm into its gate building blocks, eliminating that difficult step and potentially reducing unnecessary complexity. In addition, we have shown that our machine learning approach is robust to both noise and to decoherence, which is ideal for running on inherently noisy NISQ devices which are limited in the number of qubits available for error correction. We demonstrated this using a fundamentally non classical calculation, experimentally estimating the entanglement of an unknown quantum state. Results from this have been successfully ported to the IBM hardware and trained using a powerful hybrid reinforcement learning technique which is a modified Levenberg Marquardt LM method. The LM method is ideally suited to quantum machine learning as it only requires knowledge of the final measured output of the quantum computation, not intermediate quantum states which are generally not accessible. Since it processes all the learning data simultaneously, it also requires significantly fewer hits on the quantum hardware. Machine learning is demonstrated with results from simulations and runs on the IBM Qiskit hardware interface.", "paper_url": "http://arxiv.org/abs/2204.07011v1", "pdf_url": "http://arxiv.org/pdf/2204.07011v1", "repo_url": null}, "2204.06949": {"publish_time": "2022-04-14", "title": "Federated Learning for Vision-based Obstacle Avoidance in the Internet of Robotic Things", "author": "Xianjia Yu et.al.", "abstract": "Deep learning methods have revolutionized mobile robotics, from advanced perception models for an enhanced situational awareness to novel control approaches through reinforcement learning. This paper explores the potential of federated learning for distributed systems of mobile robots enabling collaboration on the Internet of Robotic Things. To demonstrate the effectiveness of such an approach, we deploy wheeled robots in different indoor environments. We analyze the performance of a federated learning approach and compare it to a traditional centralized training process with a priori aggregated data. We show the benefits of collaborative learning across heterogeneous environments and the potential for sim-to-real knowledge transfer. Our results demonstrate significant performance benefits of FL and sim-to-real transfer for vision-based navigation, in addition to the inherent privacy-preserving nature of FL by keeping computation at the edge. This is, to the best of our knowledge, the first work to leverage FL for vision-based navigation that also tests results in real-world settings.", "paper_url": "http://arxiv.org/abs/2204.06949v1", "pdf_url": "http://arxiv.org/pdf/2204.06949v1", "repo_url": null}, "2204.06904": {"publish_time": "2022-04-14", "title": "Efficient and practical quantum compiler towards multi-qubit systems with deep reinforcement learning", "author": "Qiuhao Chen et.al.", "abstract": "Efficient quantum compiling tactics greatly enhance the capability of quantum computers to execute complicated quantum algorithms. Due to its fundamental importance, a plethora of quantum compilers has been designed in past years. However, there are several caveats to current protocols, which are low optimality, high inference time, limited scalability, and lack of universality. To compensate for these defects, here we devise an efficient and practical quantum compiler assisted by advanced deep reinforcement learning (RL) techniques, i.e., data generation, deep Q-learning, and AQ* search. In this way, our protocol is compatible with various quantum machines and can be used to compile multi-qubit operators. We systematically evaluate the performance of our proposal in compiling quantum operators with both inverse-closed and inverse-free universal basis sets. In the task of single-qubit operator compiling, our proposal outperforms other RL-based quantum compilers in the measure of compiling sequence length and inference time. Meanwhile, the output solution is near-optimal, guaranteed by the Solovay-Kitaev theorem. Notably, for the inverse-free universal basis set, the achieved sequence length complexity is comparable with the inverse-based setting and dramatically advances previous methods. These empirical results contribute to improving the inverse-free Solovay-Kitaev theorem. In addition, for the first time, we demonstrate how to leverage RL-based quantum compilers to accomplish two-qubit operator compiling. The achieved results open an avenue for integrating RL with quantum compiling to unify efficiency and practicality and thus facilitate the exploration of quantum advantages.", "paper_url": "http://arxiv.org/abs/2204.06904v1", "pdf_url": "http://arxiv.org/pdf/2204.06904v1", "repo_url": null}, "2204.07543": {"publish_time": "2022-04-15", "title": "CryoRL: Reinforcement Learning Enables Efficient Cryo-EM Data Collection", "author": "Quanfu Fan et.al.", "abstract": "Single-particle cryo-electron microscopy (cryo-EM) has become one of the mainstream structural biology techniques because of its ability to determine high-resolution structures of dynamic bio-molecules. However, cryo-EM data acquisition remains expensive and labor-intensive, requiring substantial expertise. Structural biologists need a more efficient and objective method to collect the best data in a limited time frame. We formulate the cryo-EM data collection task as an optimization problem in this work. The goal is to maximize the total number of good images taken within a specified period. We show that reinforcement learning offers an effective way to plan cryo-EM data collection, successfully navigating heterogenous cryo-EM grids. The approach we developed, cryoRL, demonstrates better performance than average users for data collection under similar settings.", "paper_url": "http://arxiv.org/abs/2204.07543v1", "pdf_url": "http://arxiv.org/pdf/2204.07543v1", "repo_url": null}, "2204.07531": {"publish_time": "2022-04-15", "title": "Understanding Game-Playing Agents with Natural Language Annotations", "author": "Nicholas Tomlin et.al.", "abstract": "We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning. Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations.", "paper_url": "http://arxiv.org/abs/2204.07531v1", "pdf_url": "http://arxiv.org/pdf/2204.07531v1", "repo_url": null}, "2204.07471": {"publish_time": "2022-04-15", "title": "The Importance of Credo in Multiagent Learning", "author": "David Radke et.al.", "abstract": "We propose a model for multi-objective optimization, a credo, for agents in a system that are configured into multiple groups (i.e., teams). Our model of credo regulates how agents optimize their behavior for the component groups they belong to. We evaluate credo in the context of challenging social dilemmas with reinforcement learning agents. Our results indicate that the interests of teammates, or the entire system, are not required to be fully aligned for globally beneficial outcomes. We identify two scenarios without full common interest that achieve high equality and significantly higher mean population rewards compared to when the interests of all agents are aligned.", "paper_url": "http://arxiv.org/abs/2204.07471v1", "pdf_url": "http://arxiv.org/pdf/2204.07471v1", "repo_url": null}, "2204.07417": {"publish_time": "2022-04-15", "title": "Safe Reinforcement Learning Using Black-Box Reachability Analysis", "author": "Mahmoud Selim et.al.", "abstract": "Reinforcement learning (RL) is capable of sophisticated motion planning and control for robots in uncertain environments. However, state-of-the-art deep RL approaches typically lack safety guarantees, especially when the robot and environment models are unknown. To justify widespread deployment, robots must respect safety constraints without sacrificing performance. Thus, we propose a Black-box Reachability-based Safety Layer (BRSL) with three main components: (1) data-driven reachability analysis for a black-box robot model, (2) a trajectory rollout planner that predicts future actions and observations using an ensemble of neural networks trained online, and (3) a differentiable polytope collision check between the reachable set and obstacles that enables correcting unsafe actions. In simulation, BRSL outperforms other state-of-the-art safe RL methods on a Turtlebot 3, a quadrotor, and a trajectory-tracking point mass with an unsafe set adjacent to the area of highest reward.", "paper_url": "http://arxiv.org/abs/2204.07417v1", "pdf_url": "http://arxiv.org/pdf/2204.07417v1", "repo_url": null}, "2204.07404": {"publish_time": "2022-04-15", "title": "Divide & Conquer Imitation Learning", "author": "Alexandre Chenu et.al.", "abstract": "When cast into the Deep Reinforcement Learning framework, many robotics tasks require solving a long horizon and sparse reward problem, where learning algorithms struggle. In such context, Imitation Learning (IL) can be a powerful approach to bootstrap the learning process. However, most IL methods require several expert demonstrations which can be prohibitively difficult to acquire. Only a handful of IL algorithms have shown efficiency in the context of an extreme low expert data regime where a single expert demonstration is available. In this paper, we present a novel algorithm designed to imitate complex robotic tasks from the states of an expert trajectory. Based on a sequential inductive bias, our method divides the complex task into smaller skills. The skills are learned into a goal-conditioned policy that is able to solve each skill individually and chain skills to solve the entire task. We show that our method imitates a non-holonomic navigation task and scales to a complex simulated robotic manipulation task with very high sample efficiency.", "paper_url": "http://arxiv.org/abs/2204.07404v1", "pdf_url": "http://arxiv.org/pdf/2204.07404v1", "repo_url": null}, "2204.08426": {"publish_time": "2022-04-18", "title": "CHAI: A CHatbot AI for Task-Oriented Dialogue with Offline Reinforcement Learning", "author": "Siddharth Verma et.al.", "abstract": "Conventionally, generation of natural language for dialogue agents may be viewed as a statistical learning problem: determine the patterns in human-provided data and generate appropriate responses with similar statistical properties. However, dialogue can also be regarded as a goal directed process, where speakers attempt to accomplish a specific task. Reinforcement learning (RL) algorithms are designed specifically for solving such goal-directed problems, but the most direct way to apply RL -- through trial-and-error learning in human conversations, -- is costly. In this paper, we study how offline reinforcement learning can instead be used to train dialogue agents entirely using static datasets collected from human speakers. Our experiments show that recently developed offline RL methods can be combined with language models to yield realistic dialogue agents that better accomplish task goals.", "paper_url": "http://arxiv.org/abs/2204.08426v1", "pdf_url": "http://arxiv.org/pdf/2204.08426v1", "repo_url": null}, "2204.08367": {"publish_time": "2022-04-18", "title": "Online RIS Configuration Learning for Arbitrary Large Numbers of $1$-Bit Phase Resolution Elements", "author": "Kyriakos Stylianopoulos et.al.", "abstract": "Reinforcement Learning (RL) approaches are lately deployed for orchestrating wireless communications empowered by Reconfigurable Intelligent Surfaces (RISs), leveraging their online optimization capabilities. Most commonly, in RL-based formulations for realistic RISs with low resolution phase-tunable elements, each configuration is modeled as a distinct reflection action, resulting to inefficient exploration due to the exponential nature of the search space. In this paper, we consider RISs with 1-bit phase resolution elements, and model the action of each of them as a binary vector including the feasible reflection coefficients. We then introduce two variations of the well-established Deep Q-Network (DQN) and Deep Deterministic Policy Gradient (DDPG) agents, aiming for effective exploration of the binary action spaces. For the case of DQN, we make use of an efficient approximation of the Q-function, whereas a discretization post-processing step is applied to the output of DDPG. Our simulation results showcase that the proposed techniques greatly outperform the baseline in terms of the rate maximization objective, when large-scale RISs are considered. In addition, when dealing with moderate scale RIS sizes, where the conventional DQN based on configuration-based action spaces is feasible, the performance of the latter technique is similar to the proposed learning approach.", "paper_url": "http://arxiv.org/abs/2204.08367v1", "pdf_url": "http://arxiv.org/pdf/2204.08367v1", "repo_url": null}, "2204.08125": {"publish_time": "2022-04-18", "title": "FedKL: Tackling Data Heterogeneity in Federated Reinforcement Learning by Penalizing KL Divergence", "author": "Zhijie Xie et.al.", "abstract": "As a distributed learning paradigm, Federated Learning (FL) faces the communication bottleneck issue due to many rounds of model synchronization and aggregation. Heterogeneous data further deteriorates the situation by causing slow convergence. Although the impact of data heterogeneity on supervised FL has been widely studied, the related investigation for Federated Reinforcement Learning (FRL) is still in its infancy. In this paper, we first define the type and level of data heterogeneity for policy gradient based FRL systems. By inspecting the connection between the global and local objective functions, we prove that local training can benefit the global objective, if the local update is properly penalized by the total variation (TV) distance between the local and global policies. A necessary condition for the global policy to be learn-able from the local policy is also derived, which is directly related to the heterogeneity level. Based on the theoretical result, a Kullback-Leibler (KL) divergence based penalty is proposed, which, different from the conventional method that penalizes the model divergence in the parameter space, directly constrains the model outputs in the distribution space. By jointly penalizing the divergence of the local policy from the global policy with a global penalty and constraining each iteration of the local training with a local penalty, the proposed method achieves a better trade-off between training speed (step size) and convergence. Experiment results on two popular RL experiment platforms demonstrate the advantage of the proposed algorithm over existing methods in accelerating and stabilizing the training process with heterogeneous data.", "paper_url": "http://arxiv.org/abs/2204.08125v1", "pdf_url": "http://arxiv.org/pdf/2204.08125v1", "repo_url": null}, "2204.08107": {"publish_time": "2022-04-17", "title": "Exploiting Embodied Simulation to Detect Novel Object Classes Through Interaction", "author": "Nikhil Krishnaswamy et.al.", "abstract": "In this paper we present a novel method for a naive agent to detect novel objects it encounters in an interaction. We train a reinforcement learning policy on a stacking task given a known object type, and then observe the results of the agent attempting to stack various other objects based on the same trained policy. By extracting embedding vectors from a convolutional neural net trained over the results of the aforementioned stacking play, we can determine the similarity of a given object to known object types, and determine if the given object is likely dissimilar enough to the known types to be considered a novel class of object. We present the results of this method on two datasets gathered using two different policies and demonstrate what information the agent needs to extract from its environment to make these novelty judgments.", "paper_url": "http://arxiv.org/abs/2204.08107v1", "pdf_url": "http://arxiv.org/pdf/2204.08107v1", "repo_url": null}, "2204.08058": {"publish_time": "2022-04-17", "title": "MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration", "author": "Thomas Hayes et.al.", "abstract": "Multimodal video-audio-text understanding and generation can benefit from datasets that are narrow but rich. The narrowness allows bite-sized challenges that the research community can make progress on. The richness ensures we are making progress along the core challenges. To this end, we present a large-scale video-audio-text dataset MUGEN, collected using the open-sourced platform game CoinRun [11]. We made substantial modifications to make the game richer by introducing audio and enabling new interactions. We trained RL agents with different objectives to navigate the game and interact with 13 objects and characters. This allows us to automatically extract a large collection of diverse videos and associated audio. We sample 375K video clips (3.2s each) and collect text descriptions from human annotators. Each video has additional annotations that are extracted automatically from the game engine, such as accurate semantic maps for each frame and templated textual descriptions. Altogether, MUGEN can help progress research in many tasks in multimodal understanding and generation. We benchmark representative approaches on tasks involving video-audio-text retrieval and generation. Our dataset and code are released at: https://mugen-org.github.io/.", "paper_url": "http://arxiv.org/abs/2204.08058v1", "pdf_url": "http://arxiv.org/pdf/2204.08058v1", "repo_url": null}, "2204.08967": {"publish_time": "2022-04-19", "title": "When Is Partially Observable Reinforcement Learning Not Scary?", "author": "Qinghua Liu et.al.", "abstract": "Applications of Reinforcement Learning (RL), in which agents learn to make a sequence of decisions despite lacking complete information about the latent states of the controlled system, that is, they act under partial observability of the states, are ubiquitous. Partially observable RL can be notoriously difficult -- well-known information-theoretic results show that learning partially observable Markov decision processes (POMDPs) requires an exponential number of samples in the worst case. Yet, this does not rule out the existence of large subclasses of POMDPs over which learning is tractable.   In this paper we identify such a subclass, which we call weakly revealing POMDPs. This family rules out the pathological instances of POMDPs where observations are uninformative to a degree that makes learning hard. We prove that for weakly revealing POMDPs, a simple algorithm combining optimism and Maximum Likelihood Estimation (MLE) is sufficient to guarantee polynomial sample complexity. To the best of our knowledge, this is the first provably sample-efficient result for learning from interactions in overcomplete POMDPs, where the number of latent states can be larger than the number of observations.", "paper_url": "http://arxiv.org/abs/2204.08967v1", "pdf_url": "http://arxiv.org/pdf/2204.08967v1", "repo_url": null}, "2204.08957": {"publish_time": "2022-04-19", "title": "COptiDICE: Offline Constrained Reinforcement Learning via Stationary Distribution Correction Estimation", "author": "Jongmin Lee et.al.", "abstract": "We consider the offline constrained reinforcement learning (RL) problem, in which the agent aims to compute a policy that maximizes expected return while satisfying given cost constraints, learning only from a pre-collected dataset. This problem setting is appealing in many real-world scenarios, where direct interaction with the environment is costly or risky, and where the resulting policy should comply with safety constraints. However, it is challenging to compute a policy that guarantees satisfying the cost constraints in the offline RL setting, since the off-policy evaluation inherently has an estimation error. In this paper, we present an offline constrained RL algorithm that optimizes the policy in the space of the stationary distribution. Our algorithm, COptiDICE, directly estimates the stationary distribution corrections of the optimal policy with respect to returns, while constraining the cost upper bound, with the goal of yielding a cost-conservative policy for actual constraint satisfaction. Experimental results show that COptiDICE attains better policies in terms of constraint satisfaction and return-maximization, outperforming baseline algorithms.", "paper_url": "http://arxiv.org/abs/2204.08957v1", "pdf_url": "http://arxiv.org/pdf/2204.08957v1", "repo_url": null}, "2204.08594": {"publish_time": "2022-04-19", "title": "Multi-UAV Collision Avoidance using Multi-Agent Reinforcement Learning with Counterfactual Credit Assignment", "author": "Shuangyao Huang et.al.", "abstract": "Multi-UAV collision avoidance is a challenging task for UAV swarm applications due to the need of tight cooperation among swarm members for collision-free path planning. Centralized Training with Decentralized Execution (CTDE) in Multi-Agent Reinforcement Learning is a promising method for multi-UAV collision avoidance, in which the key challenge is to effectively learn decentralized policies that can maximize a global reward cooperatively. We propose a new multi-agent critic-actor learning scheme called MACA for UAV swarm collision avoidance. MACA uses a centralized critic to maximize the discounted global reward that considers both safety and energy efficiency, and an actor per UAV to find decentralized policies to avoid collisions. To solve the credit assignment problem in CTDE, we design a counterfactual baseline that marginalizes both an agent's state and action, enabling to evaluate the importance of an agent in the joint observation-action space. To train and evaluate MACA, we design our own simulation environment MACAEnv to closely mimic the realistic behaviors of a UAV swarm. Simulation results show that MACA achieves more than 16% higher average reward than two state-of-the-art MARL algorithms and reduces failure rate by 90% and response time by over 99% compared to a conventional UAV swarm collision avoidance algorithm in all test scenarios.", "paper_url": "http://arxiv.org/abs/2204.08594v1", "pdf_url": "http://arxiv.org/pdf/2204.08594v1", "repo_url": null}, "2204.08585": {"publish_time": "2022-04-18", "title": "INFOrmation Prioritization through EmPOWERment in Visual Model-Based RL", "author": "Homanga Bharadhwaj et.al.", "abstract": "Model-based reinforcement learning (RL) algorithms designed for handling complex visual observations typically learn some sort of latent state representation, either explicitly or implicitly. Standard methods of this sort do not distinguish between functionally relevant aspects of the state and irrelevant distractors, instead aiming to represent all available information equally. We propose a modified objective for model-based RL that, in combination with mutual information maximization, allows us to learn representations and dynamics for visual model-based RL without reconstruction in a way that explicitly prioritizes functionally relevant factors. The key principle behind our design is to integrate a term inspired by variational empowerment into a state-space model based on mutual information. This term prioritizes information that is correlated with action, thus ensuring that functionally relevant factors are captured first. Furthermore, the same empowerment term also promotes faster exploration during the RL process, especially for sparse-reward tasks where the reward signal is insufficient to drive exploration in the early stages of learning. We evaluate the approach on a suite of vision-based robot control tasks with natural video backgrounds, and show that the proposed prioritized information objective outperforms state-of-the-art model based RL approaches with higher sample efficiency and episodic returns. https://sites.google.com/view/information-empowerment", "paper_url": "http://arxiv.org/abs/2204.08585v1", "pdf_url": "http://arxiv.org/pdf/2204.08585v1", "repo_url": null}, "2204.08573": {"publish_time": "2022-04-18", "title": "Training and Evaluation of Deep Policies using Reinforcement Learning and Generative Models", "author": "Ali Ghadirzadeh et.al.", "abstract": "We present a data-efficient framework for solving sequential decision-making problems which exploits the combination of reinforcement learning (RL) and latent variable generative models. The framework, called GenRL, trains deep policies by introducing an action latent variable such that the feed-forward policy search can be divided into two parts: (i) training a sub-policy that outputs a distribution over the action latent variable given a state of the system, and (ii) unsupervised training of a generative model that outputs a sequence of motor actions conditioned on the latent action variable. GenRL enables safe exploration and alleviates the data-inefficiency problem as it exploits prior knowledge about valid sequences of motor actions. Moreover, we provide a set of measures for evaluation of generative models such that we are able to predict the performance of the RL policy training prior to the actual training on a physical robot. We experimentally determine the characteristics of generative models that have most influence on the performance of the final policy training on two robotics tasks: shooting a hockey puck and throwing a basketball. Furthermore, we empirically demonstrate that GenRL is the only method which can safely and efficiently solve the robotics tasks compared to two state-of-the-art RL methods.", "paper_url": "http://arxiv.org/abs/2204.08573v1", "pdf_url": "http://arxiv.org/pdf/2204.08573v1", "repo_url": null}, "2204.09603": {"publish_time": "2022-04-20", "title": "Deep Reinforcement Learning for a Two-Echelon Supply Chain with Seasonal Demand", "author": "Francesco Stranieri et.al.", "abstract": "This paper leverages recent developments in reinforcement learning and deep learning to solve the supply chain inventory management problem, a complex sequential decision-making problem consisting of determining the optimal quantity of products to produce and ship to different warehouses over a given time horizon. A mathematical formulation of the stochastic two-echelon supply chain environment is given, which allows an arbitrary number of warehouses and product types to be managed. Additionally, an open-source library that interfaces with deep reinforcement learning algorithms is developed and made publicly available for solving the inventory management problem. Performances achieved by state-of-the-art deep reinforcement learning algorithms are compared through a rich set of numerical experiments on synthetically generated data. The experimental plan is designed and performed, including different structures, topologies, demands, capacities, and costs of the supply chain. Results show that the PPO algorithm adapts very well to different characteristics of the environment. The VPG algorithm almost always converges to a local maximum, even if it typically achieves an acceptable performance level. Finally, A3C is the fastest algorithm, but just like the VPG, it never achieves the best performance when compared to PPO. In conclusion, numerical experiments show that deep reinforcement learning performs consistently better than standard inventory management strategies, such as the static (s, Q)-policy. Thus, it can be considered a practical and effective option for solving real-world instances of the stochastic two-echelon supply chain problem.", "paper_url": "http://arxiv.org/abs/2204.09603v1", "pdf_url": "http://arxiv.org/pdf/2204.09603v1", "repo_url": "https://github.com/frenkowski/scimai-gym"}, "2204.09602": {"publish_time": "2022-04-20", "title": "Federated Learning for Distributed Energy-Efficient Resource Allocation", "author": "Zelin Ji et.al.", "abstract": "In cellular networks, resource allocation is performed in a centralized way, which brings huge computation complexity to the base station (BS) and high transmission overhead. This paper investigates the distributed resource allocation scheme for cellular networks to maximize the energy efficiency of the system in the uplink transmission, while guaranteeing the quality of service (QoS) for cellular users. Particularly, to cope the fast varying channels in wireless communication environment, we propose a robust federated reinforcement learning (FRL_suc) framework to enable local users to perform distributed resource allocation in items of transmit power and channel assignment by the guidance of the local neural network trained at each user. Analysis and numerical results show that the proposed FRL_suc framework can lower the transmission overhead and offload the computation from the central server to the local users, while outperforming the conventional multi-agent reinforcement learning algorithm in terms of EE, and is more robust to channel variations.", "paper_url": "http://arxiv.org/abs/2204.09602v1", "pdf_url": "http://arxiv.org/pdf/2204.09602v1", "repo_url": null}, "2204.09560": {"publish_time": "2022-04-20", "title": "Understanding and Preventing Capacity Loss in Reinforcement Learning", "author": "Clare Lyle et.al.", "abstract": "The reinforcement learning (RL) problem is rife with sources of non-stationarity, making it a notoriously difficult problem domain for the application of neural networks. We identify a mechanism by which non-stationary prediction targets can prevent learning progress in deep RL agents: \\textit{capacity loss}, whereby networks trained on a sequence of target values lose their ability to quickly update their predictions over time. We demonstrate that capacity loss occurs in a range of RL agents and environments, and is particularly damaging to performance in sparse-reward tasks. We then present a simple regularizer, Initial Feature Regularization (InFeR), that mitigates this phenomenon by regressing a subspace of features towards its value at initialization, leading to significant performance improvements in sparse-reward environments such as Montezuma's Revenge. We conclude that preventing capacity loss is crucial to enable agents to maximally benefit from the learning signals they obtain throughout the entire training trajectory.", "paper_url": "http://arxiv.org/abs/2204.09560v1", "pdf_url": "http://arxiv.org/pdf/2204.09560v1", "repo_url": null}, "2204.09500": {"publish_time": "2022-04-20", "title": "A Reinforcement Learning-based Volt-VAR Control Dataset and Testing Environment", "author": "Yuanqi Gao et.al.", "abstract": "To facilitate the development of reinforcement learning (RL) based power distribution system Volt-VAR control (VVC), this paper introduces a suite of open-source datasets for RL-based VVC algorithm research that is sample efficient, safe, and robust. The dataset consists of two components: 1. a Gym-like VVC testing environment for the IEEE-13, 123, and 8500-bus test feeders and 2. a historical operational dataset for each of the feeders. Potential users of the dataset and testing environment could first train an sample-efficient off-line (batch) RL algorithm on the historical dataset and then evaluate the performance of the trained RL agent on the testing environments. This dataset serves as a useful testbed to conduct RL-based VVC research mimicking the real-world operational challenges faced by electric utilities. Meanwhile, it allows researchers to conduct fair performance comparisons between different algorithms.", "paper_url": "http://arxiv.org/abs/2204.09500v1", "pdf_url": "http://arxiv.org/pdf/2204.09500v1", "repo_url": "https://github.com/yg-smile/rl_vvc_dataset"}, "2204.09424": {"publish_time": "2022-04-20", "title": "SAAC: Safe Reinforcement Learning as an Adversarial Game of Actor-Critics", "author": "Yannis Flet-Berliac et.al.", "abstract": "Although Reinforcement Learning (RL) is effective for sequential decision-making problems under uncertainty, it still fails to thrive in real-world systems where risk or safety is a binding constraint. In this paper, we formulate the RL problem with safety constraints as a non-zero-sum game. While deployed with maximum entropy RL, this formulation leads to a safe adversarially guided soft actor-critic framework, called SAAC. In SAAC, the adversary aims to break the safety constraint while the RL agent aims to maximize the constrained value function given the adversary's policy. The safety constraint on the agent's value function manifests only as a repulsion term between the agent's and the adversary's policies. Unlike previous approaches, SAAC can address different safety criteria such as safe exploration, mean-variance risk sensitivity, and CVaR-like coherent risk sensitivity. We illustrate the design of the adversary for these constraints. Then, in each of these variations, we show the agent differentiates itself from the adversary's unsafe actions in addition to learning to solve the task. Finally, for challenging continuous control tasks, we demonstrate that SAAC achieves faster convergence, better efficiency, and fewer failures to satisfy the safety constraints than risk-averse distributional RL and risk-neutral soft actor-critic algorithms.", "paper_url": "http://arxiv.org/abs/2204.09424v1", "pdf_url": "http://arxiv.org/pdf/2204.09424v1", "repo_url": null}, "2204.10256": {"publish_time": "2022-04-21", "title": "Revisiting Gaussian mixture critic in off-policy reinforcement learning: a sample-based approach", "author": "Bobak Shahriari et.al.", "abstract": "Actor-critic algorithms that make use of distributional policy evaluation have frequently been shown to outperform their non-distributional counterparts on many challenging control tasks. Examples of this behavior include the D4PG and DMPO algorithms as compared to DDPG and MPO, respectively [Barth-Maron et al., 2018; Hoffman et al., 2020]. However, both agents rely on the C51 critic for value estimation.One major drawback of the C51 approach is its requirement of prior knowledge about the minimum andmaximum values a policy can attain as well as the number of bins used, which fixes the resolution ofthe distributional estimate. While the DeepMind control suite of tasks utilizes standardized rewards and episode lengths, thus enabling the entire suite to be solved with a single setting of these hyperparameters, this is often not the case. This paper revisits a natural alternative that removes this requirement, namelya mixture of Gaussians, and a simple sample-based loss function to train it in an off-policy regime. We empirically evaluate its performance on a broad range of continuous control tasks and demonstrate that it eliminates the need for these distributional hyperparameters and achieves state-of-the-art performance on a variety of challenging tasks (e.g. the humanoid, dog, quadruped, and manipulator domains). Finallywe provide an implementation in the Acme agent repository.", "paper_url": "http://arxiv.org/abs/2204.10256v1", "pdf_url": "http://arxiv.org/pdf/2204.10256v1", "repo_url": null}, "2204.10063": {"publish_time": "2022-04-21", "title": "Resilient robot teams: a review integrating decentralised control, change-detection, and learning", "author": "David M. Bossens et.al.", "abstract": "Purpose of review: This paper reviews opportunities and challenges for decentralised control, change-detection, and learning in the context of resilient robot teams.   Recent findings: Exogenous fault detection methods can provide a generic detection or a specific diagnosis with a recovery solution. Robot teams can perform active and distributed sensing for detecting changes in the environment, including identifying and tracking dynamic anomalies, as well as collaboratively mapping dynamic environments. Resilient methods for decentralised control have been developed in learning perception-action-communication loops, multi-agent reinforcement learning, embodied evolution, offline evolution with online adaptation, explicit task allocation, and stigmergy in swarm robotics.   Summary: Remaining challenges for resilient robot teams are integrating change-detection and trial-and-error learning methods, obtaining reliable performance evaluations under constrained evaluation time, improving the safety of resilient robot teams, theoretical results demonstrating rapid adaptation to given environmental perturbations, and designing realistic and compelling case studies.", "paper_url": "http://arxiv.org/abs/2204.10063v1", "pdf_url": "http://arxiv.org/pdf/2204.10063v1", "repo_url": null}, "2204.09839": {"publish_time": "2022-04-21", "title": "6GAN: IPv6 Multi-Pattern Target Generation via Generative Adversarial Nets with Reinforcement Learning", "author": "Tianyu Cui et.al.", "abstract": "Global IPv6 scanning has always been a challenge for researchers because of the limited network speed and computational power. Target generation algorithms are recently proposed to overcome the problem for Internet assessments by predicting a candidate set to scan. However, IPv6 custom address configuration emerges diverse addressing patterns discouraging algorithmic inference. Widespread IPv6 alias could also mislead the algorithm to discover aliased regions rather than valid host targets. In this paper, we introduce 6GAN, a novel architecture built with Generative Adversarial Net (GAN) and reinforcement learning for multi-pattern target generation. 6GAN forces multiple generators to train with a multi-class discriminator and an alias detector to generate non-aliased active targets with different addressing pattern types. The rewards from the discriminator and the alias detector help supervise the address sequence decision-making process. After adversarial training, 6GAN's generators could keep a strong imitating ability for each pattern and 6GAN's discriminator obtains outstanding pattern discrimination ability with a 0.966 accuracy. Experiments indicate that our work outperformed the state-of-the-art target generation algorithms by reaching a higher-quality candidate set.", "paper_url": "http://arxiv.org/abs/2204.09839v1", "pdf_url": "http://arxiv.org/pdf/2204.09839v1", "repo_url": "https://github.com/cuitianyu961030/6gan"}, "2204.09801": {"publish_time": "2022-04-20", "title": "Exact Formulas for Finite-Time Estimation Errors of Decentralized Temporal Difference Learning with Linear Function Approximation", "author": "Xingang Guo et.al.", "abstract": "In this paper, we consider the policy evaluation problem in multi-agent reinforcement learning (MARL) and derive exact closed-form formulas for the finite-time mean-squared estimation errors of decentralized temporal difference (TD) learning with linear function approximation. Our analysis hinges upon the fact that the decentralized TD learning method can be viewed as a Markov jump linear system (MJLS). Then standard MJLS theory can be applied to quantify the mean and covariance matrix of the estimation error of the decentralized TD method at every time step. Various implications of our exact formulas on the algorithm performance are also discussed. An interesting finding is that under a necessary and sufficient stability condition, the mean-squared TD estimation error will converge to an exact limit at a specific exponential rate.", "paper_url": "http://arxiv.org/abs/2204.09801v1", "pdf_url": "http://arxiv.org/pdf/2204.09801v1", "repo_url": null}, "2204.09787": {"publish_time": "2022-04-20", "title": "Sample-Efficient Reinforcement Learning for POMDPs with Linear Function Approximations", "author": "Qi Cai et.al.", "abstract": "Despite the success of reinforcement learning (RL) for Markov decision processes (MDPs) with function approximation, most RL algorithms easily fail if the agent only has partial observations of the state. Such a setting is often modeled as a partially observable Markov decision process (POMDP). Existing sample-efficient algorithms for POMDPs are restricted to the tabular setting where the state and observation spaces are finite. In this paper, we make the first attempt at tackling the tension between function approximation and partial observability. In specific, we focus on a class of undercomplete POMDPs with linear function approximations, which allows the state and observation spaces to be infinite. For such POMDPs, we show that the optimal policy and value function can be characterized by a sequence of finite-memory Bellman operators. We propose an RL algorithm that constructs optimistic estimators of these operators via reproducing kernel Hilbert space (RKHS) embedding. Moreover, we theoretically prove that the proposed algorithm finds an $\\varepsilon$-optimal policy with $\\tilde O (1/\\varepsilon^2)$ episodes of exploration. Also, this sample complexity only depends on the intrinsic dimension of the POMDP polynomially and is independent of the size of the state and observation spaces. To our best knowledge, we develop the first provably sample-efficient algorithm for POMDPs with function approximation.", "paper_url": "http://arxiv.org/abs/2204.09787v1", "pdf_url": "http://arxiv.org/pdf/2204.09787v1", "repo_url": null}, "2204.10817": {"publish_time": "2022-04-22", "title": "Reward Reports for Reinforcement Learning", "author": "Thomas Gilbert et.al.", "abstract": "The desire to build good systems in the face of complex societal effects requires a dynamic approach towards equity and access. Recent approaches to machine learning (ML) documentation have demonstrated the promise of discursive frameworks for deliberation about these complexities. However, these developments have been grounded in a static ML paradigm, leaving the role of feedback and post-deployment performance unexamined. Meanwhile, recent work in reinforcement learning design has shown that the effects of optimization objectives on the resultant system behavior can be wide-ranging and unpredictable. In this paper we sketch a framework for documenting deployed learning systems, which we call Reward Reports. Taking inspiration from various contributions to the technical literature on reinforcement learning, we outline Reward Reports as living documents that track updates to design choices and assumptions behind what a particular automated system is optimizing for. They are intended to track dynamic phenomena arising from system deployment, rather than merely static properties of models or data. After presenting the elements of a Reward Report, we provide three examples: DeepMind's MuZero, MovieLens, and a hypothetical deployment of a Project Flow traffic control policy.", "paper_url": "http://arxiv.org/abs/2204.10817v1", "pdf_url": "http://arxiv.org/pdf/2204.10817v1", "repo_url": null}, "2204.10685": {"publish_time": "2022-04-22", "title": "TASAC: a twin-actor reinforcement learning framework with stochastic policy for batch process control", "author": "Tanuja Joshi et.al.", "abstract": "Due to their complex nonlinear dynamics and batch-to-batch variability, batch processes pose a challenge for process control. Due to the absence of accurate models and resulting plant-model mismatch, these problems become harder to address for advanced model-based control strategies. Reinforcement Learning (RL), wherein an agent learns the policy by directly interacting with the environment, offers a potential alternative in this context. RL frameworks with actor-critic architecture have recently become popular for controlling systems where state and action spaces are continuous. It has been shown that an ensemble of actor and critic networks further helps the agent learn better policies due to the enhanced exploration due to simultaneous policy learning. To this end, the current study proposes a stochastic actor-critic RL algorithm, termed Twin Actor Soft Actor-Critic (TASAC), by incorporating an ensemble of actors for learning, in a maximum entropy framework, for batch process control.", "paper_url": "http://arxiv.org/abs/2204.10685v1", "pdf_url": "http://arxiv.org/pdf/2204.10685v1", "repo_url": null}, "2204.10497": {"publish_time": "2022-04-22", "title": "Transferring ConvNet Features from Passive to Active Robot Self-Localization: The Use of Ego-Centric and World-Centric Views", "author": "Kanya Kurauchi et.al.", "abstract": "The training of a next-best-view (NBV) planner for visual place recognition (VPR) is a fundamentally important task in autonomous robot navigation, for which a typical approach is the use of visual experiences that are collected in the target domain as training data. However, the collection of a wide variety of visual experiences in everyday navigation is costly and prohibitive for real-time robotic applications. We address this issue by employing a novel {\\it domain-invariant} NBV planner. A standard VPR subsystem based on a convolutional neural network (CNN) is assumed to be available, and its domain-invariant state recognition ability is proposed to be transferred to train the domain-invariant NBV planner. Specifically, we divide the visual cues that are available from the CNN model into two types: the output layer cue (OLC) and intermediate layer cue (ILC). The OLC is available at the output layer of the CNN model and aims to estimate the state of the robot (e.g., the robot viewpoint) with respect to the world-centric view coordinate system. The ILC is available within the middle layers of the CNN model as a high-level description of the visual content (e.g., a saliency image) with respect to the ego-centric view. In our framework, the ILC and OLC are mapped to a state vector and subsequently used to train a multiview NBV planner via deep reinforcement learning. Experiments using the public NCLT dataset validate the effectiveness of the proposed method.", "paper_url": "http://arxiv.org/abs/2204.10497v1", "pdf_url": "http://arxiv.org/pdf/2204.10497v1", "repo_url": null}, "2204.10479": {"publish_time": "2022-04-22", "title": "Analysis of Temporal Difference Learning: Linear System Approach", "author": "Donghwan Lee et.al.", "abstract": "The goal of this technical note is to introduce a new finite-time convergence analysis of temporal difference (TD) learning based on stochastic linear system models. TD-learning is a fundamental reinforcement learning (RL) to evaluate a given policy by estimating the corresponding value function for a Markov decision process. While there has been a series of successful works in theoretical analysis of TDlearning, it was not until recently that researchers found some guarantees on its statistical efficiency by developing finite-time error bounds. In this paper, we propose a simple control theoretic finite-time analysis of TD-learning, which exploits linear system models and standard notions in linear system communities. The proposed work provides new simple templets for RL analysis, and additional insights on TD-learning and RL based on ideas in control theory.", "paper_url": "http://arxiv.org/abs/2204.10479v1", "pdf_url": "http://arxiv.org/pdf/2204.10479v1", "repo_url": null}, "2204.10429": {"publish_time": "2022-04-21", "title": "Curriculum Learning for Goal-Oriented Semantic Communications with a Common Language", "author": "Mohammad Karimzadeh Farshbafan et.al.", "abstract": "Goal-oriented semantic communication will be a pillar of next-generation wireless networks. Despite significant recent efforts in this area, most prior works are focused on specific data types (e.g., image or audio), and they ignore the goal and effectiveness aspects of semantic transmissions. In contrast, in this paper, a holistic goal-oriented semantic communication framework is proposed to enable a speaker and a listener to cooperatively execute a set of sequential tasks in a dynamic environment. A common language based on a hierarchical belief set is proposed to enable semantic communications between speaker and listener. The speaker, acting as an observer of the environment, utilizes the beliefs to transmit an initial description of its observation (called event) to the listener. The listener is then able to infer on the transmitted description and complete it by adding related beliefs to the transmitted beliefs of the speaker. As such, the listener reconstructs the observed event based on the completed description, and it then takes appropriate action in the environment based on the reconstructed event. An optimization problem is defined to determine the perfect and abstract description of the events while minimizing the transmission and inference costs with constraints on the task execution time and belief efficiency. Then, a novel bottom-up curriculum learning (CL) framework based on reinforcement learning is proposed to solve the optimization problem and enable the speaker and listener to gradually identify the structure of the belief set and the perfect and abstract description of the events. Simulation results show that the proposed CL method outperforms traditional RL in terms of convergence time, task execution cost and time, reliability, and belief efficiency.", "paper_url": "http://arxiv.org/abs/2204.10429v1", "pdf_url": "http://arxiv.org/pdf/2204.10429v1", "repo_url": null}, "2204.11828": {"publish_time": "2022-04-25", "title": "Skill-based Meta-Reinforcement Learning", "author": "Taewook Nam et.al.", "abstract": "While deep reinforcement learning methods have shown impressive results in robot learning, their sample inefficiency makes the learning of complex, long-horizon behaviors with real robot systems infeasible. To mitigate this issue, meta-reinforcement learning methods aim to enable fast learning on novel tasks by learning how to learn. Yet, the application has been limited to short-horizon tasks with dense rewards. To enable learning long-horizon behaviors, recent works have explored leveraging prior experience in the form of offline datasets without reward or task annotations. While these approaches yield improved sample efficiency, millions of interactions with environments are still required to solve complex tasks. In this work, we devise a method that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to solve unseen target tasks with orders of magnitude fewer environment interactions. Our core idea is to leverage prior experience extracted from offline datasets during meta-learning. Specifically, we propose to (1) extract reusable skills and a skill prior from offline datasets, (2) meta-train a high-level policy that learns to efficiently compose learned skills into long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve an unseen target task. Experimental results on continuous control tasks in navigation and manipulation demonstrate that the proposed method can efficiently solve long-horizon novel target tasks by combining the strengths of meta-learning and the usage of offline datasets, while prior approaches in RL, meta-RL, and multi-task RL require substantially more environment interactions to solve the tasks.", "paper_url": "http://arxiv.org/abs/2204.11828v1", "pdf_url": "http://arxiv.org/pdf/2204.11828v1", "repo_url": null}, "2204.11827": {"publish_time": "2022-04-25", "title": "Task-Induced Representation Learning", "author": "Jun Yamada et.al.", "abstract": "In this work, we evaluate the effectiveness of representation learning approaches for decision making in visually complex environments. Representation learning is essential for effective reinforcement learning (RL) from high-dimensional inputs. Unsupervised representation learning approaches based on reconstruction, prediction or contrastive learning have shown substantial learning efficiency gains. Yet, they have mostly been evaluated in clean laboratory or simulated settings. In contrast, real environments are visually complex and contain substantial amounts of clutter and distractors. Unsupervised representations will learn to model such distractors, potentially impairing the agent's learning efficiency. In contrast, an alternative class of approaches, which we call task-induced representation learning, leverages task information such as rewards or demonstrations from prior tasks to focus on task-relevant parts of the scene and ignore distractors. We investigate the effectiveness of unsupervised and task-induced representation learning approaches on four visually complex environments, from Distracting DMControl to the CARLA driving simulator. For both, RL and imitation learning, we find that representation learning generally improves sample efficiency on unseen tasks even in visually complex scenes and that task-induced representations can double learning efficiency compared to unsupervised alternatives. Code is available at https://clvrai.com/tarp.", "paper_url": "http://arxiv.org/abs/2204.11827v1", "pdf_url": "http://arxiv.org/pdf/2204.11827v1", "repo_url": null}, "2204.11718": {"publish_time": "2022-04-25", "title": "Predicting Real-time Scientific Experiments Using Transformer models and Reinforcement Learning", "author": "Juan Manuel Parrilla-Gutierrez et.al.", "abstract": "Life and physical sciences have always been quick to adopt the latest advances in machine learning to accelerate scientific discovery. Examples of this are cell segmentation or cancer detection. Nevertheless, these exceptional results are based on mining previously created datasets to discover patterns or trends. Recent advances in AI have been demonstrated in real-time scenarios like self-driving cars or playing video games. However, these new techniques have not seen widespread adoption in life or physical sciences because experimentation can be slow. To tackle this limitation, this work aims to adapt generative learning algorithms to model scientific experiments and accelerate their discovery using in-silico simulations. We particularly focused on real-time experiments, aiming to model how they react to user inputs. To achieve this, here we present an encoder-decoder architecture based on the Transformer model to simulate real-time scientific experimentation, predict its future behaviour and manipulate it on a step-by-step basis. As a proof of concept, this architecture was trained to map a set of mechanical inputs to the oscillations generated by a chemical reaction. The model was paired with a Reinforcement Learning controller to show how the simulated chemistry can be manipulated in real-time towards user-defined behaviours. Our results demonstrate how generative learning can model real-time scientific experimentation to track how it changes through time as the user manipulates it, and how the trained models can be paired with optimisation algorithms to discover new phenomena beyond the physical limitations of lab experimentation. This work paves the way towards building surrogate systems where physical experimentation interacts with machine learning on a step-by-step basis.", "paper_url": "http://arxiv.org/abs/2204.11718v1", "pdf_url": "http://arxiv.org/pdf/2204.11718v1", "repo_url": "https://github.com/thephet/SciTransformer"}, "2204.11674": {"publish_time": "2022-04-25", "title": "HyperNCA: Growing Developmental Networks with Neural Cellular Automata", "author": "Elias Najarro et.al.", "abstract": "In contrast to deep reinforcement learning agents, biological neural networks are grown through a self-organized developmental process. Here we propose a new hypernetwork approach to grow artificial neural networks based on neural cellular automata (NCA). Inspired by self-organising systems and information-theoretic approaches to developmental biology, we show that our HyperNCA method can grow neural networks capable of solving common reinforcement learning tasks. Finally, we explore how the same approach can be used to build developmental metamorphosis networks capable of transforming their weights to solve variations of the initial RL task.", "paper_url": "http://arxiv.org/abs/2204.11674v1", "pdf_url": "http://arxiv.org/pdf/2204.11674v1", "repo_url": null}, "2204.11575": {"publish_time": "2022-04-25", "title": "Deep Reinforcement Learning for Orienteering Problems Based on Decomposition", "author": "Wei Liu et.al.", "abstract": "This paper presents a new method for solving an orienteering problem (OP) by breaking it down into two parts: a knapsack problem (KP) and a traveling salesman problem (TSP). A KP solver is responsible for picking nodes, while a TSP solver is responsible for designing the proper path and assisting the KP solver in judging constraint violations. To address constraints, we propose a dual-population coevolutionary algorithm (DPCA) as the KP solver, which simultaneously maintains both feasible and infeasible populations. A dynamic pointer network (DYPN) is introduced as the TSP solver, which takes city locations as inputs and immediately outputs a permutation of nodes. The model, which is trained by reinforcement learning, can capture both the structural and dynamic patterns of the given problem. The model can generalize to other instances with different scales and distributions. Experimental results show that the proposed algorithm can outperform conventional approaches in terms of training, inference, and generalization ability.", "paper_url": "http://arxiv.org/abs/2204.11575v1", "pdf_url": "http://arxiv.org/pdf/2204.11575v1", "repo_url": null}, "2204.12458": {"publish_time": "2022-04-26", "title": "Learning Value Functions from Undirected State-only Experience", "author": "Matthew Chang et.al.", "abstract": "This paper tackles the problem of learning value functions from undirected state-only experience (state transitions without action labels i.e. (s,s',r) tuples). We first theoretically characterize the applicability of Q-learning in this setting. We show that tabular Q-learning in discrete Markov decision processes (MDPs) learns the same value function under any arbitrary refinement of the action space. This theoretical result motivates the design of Latent Action Q-learning or LAQ, an offline RL method that can learn effective value functions from state-only experience. Latent Action Q-learning (LAQ) learns value functions using Q-learning on discrete latent actions obtained through a latent-variable future prediction model. We show that LAQ can recover value functions that have high correlation with value functions learned using ground truth actions. Value functions learned using LAQ lead to sample efficient acquisition of goal-directed behavior, can be used with domain-specific low-level controllers, and facilitate transfer across embodiments. Our experiments in 5 environments ranging from 2D grid world to 3D visual navigation in realistic environments demonstrate the benefits of LAQ over simpler alternatives, imitation learning oracles, and competing methods.", "paper_url": "http://arxiv.org/abs/2204.12458v1", "pdf_url": "http://arxiv.org/pdf/2204.12458v1", "repo_url": null}, "2204.12371": {"publish_time": "2022-04-26", "title": "Social learning spontaneously emerges by searching optimal heuristics with deep reinforcement learning", "author": "Seungwoong Ha et.al.", "abstract": "How have individuals of social animals in nature evolved to learn from each other, and what would be the optimal strategy for such learning in a specific environment? Here, we address both problems by employing a deep reinforcement learning model to optimize the social learning strategies (SLSs) of agents in a cooperative game in a multi-dimensional landscape. Throughout the training for maximizing the overall payoff, we find that the agent spontaneously learns various concepts of social learning, such as copying, focusing on frequent and well-performing neighbors, self-comparison, and the importance of balancing between individual and social learning, without any explicit guidance or prior knowledge about the system. The SLS from a fully trained agent outperforms all of the traditional, baseline SLSs in terms of mean payoff. We demonstrate the superior performance of the reinforcement learning agent in various environments, including temporally changing environments and real social networks, which also verifies the adaptability of our framework to different social settings.", "paper_url": "http://arxiv.org/abs/2204.12371v1", "pdf_url": "http://arxiv.org/pdf/2204.12371v1", "repo_url": null}, "2204.12351": {"publish_time": "2022-04-26", "title": "Reinforcement Learning Generation of 4-Qubits Entangled States", "author": "Sara Giordano et.al.", "abstract": "We have devised an artificial intelligence algorithm with machine reinforcement learning (Q-learning) to construct remarkable entangled states with 4 qubits. This way, the algorithm is able to generate representative states for some of the 49 true SLOCC classes of the four-qubit entanglement states. In particular, it is possible to reach at least one true SLOCC class for each of the nine entanglement families. The quantum circuits synthesized by the algorithm may be useful for the experimental realization of these important classes of entangled states and to draw conclusions about the intrinsic properties of our universe. We introduce a graphical tool called the state-link graph (SLG) to represent the construction of the Quality matrix (Q-matrix) used by the algorithm to build a given objective state belonging to the corresponding entanglement class. This allows us to discover the necessary connections between specific entanglement features and the role of certain quantum gates that the algorithm needs to include in the quantum gate set of actions. The quantum circuits found are optimal by construction with respect to the quantum gate-set chosen. These SLGs make the algorithm simple, intuitive and a useful resource for the automated construction of entangled states with a low number of qubits.", "paper_url": "http://arxiv.org/abs/2204.12351v1", "pdf_url": "http://arxiv.org/pdf/2204.12351v1", "repo_url": null}, "2204.12190": {"publish_time": "2022-04-26", "title": "Multi-Agent Reinforcement Learning for Traffic Signal Control through Universal Communication Method", "author": "Qize Jiang et.al.", "abstract": "How to coordinate the communication among intersections effectively in real complex traffic scenarios with multi-intersection is challenging. Existing approaches only enable the communication in a heuristic manner without considering the content/importance of information to be shared. In this paper, we propose a universal communication form UniComm between intersections. UniComm embeds massive observations collected at one agent into crucial predictions of their impact on its neighbors, which improves the communication efficiency and is universal across existing methods. We also propose a concise network UniLight to make full use of communications enabled by UniComm. Experimental results on real datasets demonstrate that UniComm universally improves the performance of existing state-of-the-art methods, and UniLight significantly outperforms existing methods on a wide range of traffic situations.", "paper_url": "http://arxiv.org/abs/2204.12190v1", "pdf_url": "http://arxiv.org/pdf/2204.12190v1", "repo_url": null}, "2204.12181": {"publish_time": "2022-04-26", "title": "Collaborative Target Search with a Visual Drone Swarm: An Adaptive Curriculum Embedded Multi-stage Reinforcement Learning Approach", "author": "Jiaping Xiao et.al.", "abstract": "Equipping drones with target search capabilities is desirable for applications in disaster management scenarios and smart warehouse delivery systems. Instead of deploying a single drone, an intelligent drone swarm that can collaborate with one another in maneuvering among obstacles will be more effective in accomplishing the target search in a shorter amount of time. In this work, we propose a data-efficient reinforcement learning-based approach, Adaptive Curriculum Embedded Multi-Stage Learning (ACEMSL), to address the challenges of carrying out a collaborative target search with a visual drone swarm, namely the 3D sparse reward space exploration and the collaborative behavior requirement. Specifically, we develop an adaptive embedded curriculum, where the task difficulty level can be adaptively adjusted according to the success rate achieved in training. Meanwhile, with multi-stage learning, ACEMSL allows data-efficient training and individual-team reward allocation for the collaborative drone swarm. The effectiveness and generalization capability of our approach are validated using simulations and actual flight tests.", "paper_url": "http://arxiv.org/abs/2204.12181v1", "pdf_url": "http://arxiv.org/pdf/2204.12181v1", "repo_url": "https://github.com/ntu-uavg/collaborative-target-search-vision-drone-swarm"}, "2204.13070": {"publish_time": "2022-04-27", "title": "Hierarchical Control for Cooperative Teams in Competitive Autonomous Racing", "author": "Rishabh Saumil Thakkar et.al.", "abstract": "We study the problem of autonomous racing amongst teams composed of cooperative agents subject to realistic safety and fairness rules. We develop a hierarchical controller to solve this problem consisting of two levels, extending prior work where bi-level hierarchical control is applied to head-to-head autonomous racing. A high-level planner constructs a discrete game that encodes the complex rules with simplified dynamics to produce a sequence of target waypoints. The low-level controller uses the resulting waypoints as a reference trajectory and computes high-resolution control inputs by solving a simplified racing game with a reduced set of rules. We consider two approaches for the low-level planner: training a multi-agent reinforcement learning (MARL) policy and solving a linear-quadratic Nash game (LQNG) approximation. We test our controllers against three baselines on a simple oval track and a complex track: an end-to-end MARL controller, a MARL controller tracking a fixed racing line, and an LQNG controller tracking a fixed racing line. Quantitative results show that our hierarchical methods outperform their respective baseline methods in terms of race wins, overall team performance, and abiding by the rules. Qualitatively, we observe the hierarchical controllers mimicking actions performed by expert human drivers such as coordinated overtaking moves, defending against multiple opponents, and long-term planning for delayed advantages. We show that hierarchical planning for game-theoretic reasoning produces both cooperative and competitive behavior even when challenged with complex rules and constraints.", "paper_url": "http://arxiv.org/abs/2204.13070v1", "pdf_url": "http://arxiv.org/pdf/2204.13070v1", "repo_url": "https://github.com/ribsthakkar/HierarchicalKarting"}, "2204.13060": {"publish_time": "2022-04-27", "title": "Bisimulation Makes Analogies in Goal-Conditioned Reinforcement Learning", "author": "Philippe Hansen-Estruch et.al.", "abstract": "Building generalizable goal-conditioned agents from rich observations is a key to reinforcement learning (RL) solving real world problems. Traditionally in goal-conditioned RL, an agent is provided with the exact goal they intend to reach. However, it is often not realistic to know the configuration of the goal before performing a task. A more scalable framework would allow us to provide the agent with an example of an analogous task, and have the agent then infer what the goal should be for its current state. We propose a new form of state abstraction called goal-conditioned bisimulation that captures functional equivariance, allowing for the reuse of skills to achieve new goals. We learn this representation using a metric form of this abstraction, and show its ability to generalize to new goals in simulation manipulation tasks. Further, we prove that this learned representation is sufficient not only for goal conditioned tasks, but is amenable to any downstream task described by a state-only reward function. Videos can be found at https://sites.google.com/view/gc-bisimulation.", "paper_url": "http://arxiv.org/abs/2204.13060v1", "pdf_url": "http://arxiv.org/pdf/2204.13060v1", "repo_url": null}, "2204.12948": {"publish_time": "2022-04-27", "title": "Domain Knowledge-Infused Deep Learning for Automated Analog/Radio-Frequency Circuit Parameter Optimization", "author": "Weidong Cao et.al.", "abstract": "The design automation of analog circuits is a longstanding challenge. This paper presents a reinforcement learning method enhanced by graph learning to automate the analog circuit parameter optimization at the pre-layout stage, i.e., finding device parameters to fulfill desired circuit specifications. Unlike all prior methods, our approach is inspired by human experts who rely on domain knowledge of analog circuit design (e.g., circuit topology and couplings between circuit specifications) to tackle the problem. By originally incorporating such key domain knowledge into policy training with a multimodal network, the method best learns the complex relations between circuit parameters and design targets, enabling optimal decisions in the optimization process. Experimental results on exemplary circuits show it achieves human-level design accuracy (99%) 1.5X efficiency of existing best-performing methods. Our method also shows better generalization ability to unseen specifications and optimality in circuit performance optimization. Moreover, it applies to design radio-frequency circuits on emerging semiconductor technologies, breaking the limitations of prior learning methods in designing conventional analog circuits.", "paper_url": "http://arxiv.org/abs/2204.12948v1", "pdf_url": "http://arxiv.org/pdf/2204.12948v1", "repo_url": null}, "2204.12844": {"publish_time": "2022-04-27", "title": "Accelerating Robot Learning of Contact-Rich Manipulations: A Curriculum Learning Study", "author": "Cristian C. Beltran-Hernandez et.al.", "abstract": "The Reinforcement Learning (RL) paradigm has been an essential tool for automating robotic tasks. Despite the advances in RL, it is still not widely adopted in the industry due to the need for an expensive large amount of robot interaction with its environment. Curriculum Learning (CL) has been proposed to expedite learning. However, most research works have been only evaluated in simulated environments, from video games to robotic toy tasks. This paper presents a study for accelerating robot learning of contact-rich manipulation tasks based on Curriculum Learning combined with Domain Randomization (DR). We tackle complex industrial assembly tasks with position-controlled robots, such as insertion tasks. We compare different curricula designs and sampling approaches for DR. Based on this study, we propose a method that significantly outperforms previous work, which uses DR only (No CL is used), with less than a fifth of the training time (samples). Results also show that even when training only in simulation with toy tasks, our method can learn policies that can be transferred to the real-world robot. The learned policies achieved success rates of up to 86\\% on real-world complex industrial insertion tasks (with tolerances of $\\pm 0.01~mm$) not seen during the training.", "paper_url": "http://arxiv.org/abs/2204.12844v1", "pdf_url": "http://arxiv.org/pdf/2204.12844v1", "repo_url": null}, "2204.12791": {"publish_time": "2022-04-27", "title": "Evaluation and Learning in Two-Player Symmetric Games via Best and Better Responses", "author": "Rui Yan et.al.", "abstract": "Artificial intelligence and robotic competitions are accompanied by a class of game paradigms in which each player privately commits a strategy to a game system which simulates the game using the collected joint strategy and then returns payoffs to players. This paper considers the strategy commitment for two-player symmetric games in which the players' strategy spaces are identical and their payoffs are symmetric. First, we introduce two digraph-based metrics at a meta-level for strategy evaluation in two-agent reinforcement learning, grounded on sink equilibrium. The metrics rank the strategies of a single player and determine the set of strategies which are preferred for the private commitment. Then, in order to find the preferred strategies under the metrics, we propose two variants of the classical learning algorithm self-play, called strictly best-response and weakly better-response self-plays. By modeling learning processes as walks over joint-strategy response digraphs, we prove that the learnt strategies by two variants are preferred under two metrics, respectively. The preferred strategies under both two metrics are identified and adjacency matrices induced by one metric and one variant are connected. Finally, simulations are provided to illustrate the results.", "paper_url": "http://arxiv.org/abs/2204.12791v1", "pdf_url": "http://arxiv.org/pdf/2204.12791v1", "repo_url": null}, "2204.13695": {"publish_time": "2022-04-28", "title": "Bilinear value networks", "author": "Zhang-Wei Hong et.al.", "abstract": "The dominant framework for off-policy multi-goal reinforcement learning involves estimating goal conditioned Q-value function. When learning to achieve multiple goals, data efficiency is intimately connected with the generalization of the Q-function to new goals. The de-facto paradigm is to approximate Q(s, a, g) using monolithic neural networks. To improve the generalization of the Q-function, we propose a bilinear decomposition that represents the Q-value via a low-rank approximation in the form of a dot product between two vector fields. The first vector field, f(s, a), captures the environment's local dynamics at the state s; whereas the second component, {\\phi}(s, g), captures the global relationship between the current state and the goal. We show that our bilinear decomposition scheme substantially improves data efficiency, and has superior transfer to out-of-distribution goals compared to prior methods. Empirical evidence is provided on the simulated Fetch robot task-suite and dexterous manipulation with a Shadow hand.", "paper_url": "http://arxiv.org/abs/2204.13695v1", "pdf_url": "http://arxiv.org/pdf/2204.13695v1", "repo_url": null}, "2204.13661": {"publish_time": "2022-04-28", "title": "Toward Compositional Generalization in Object-Oriented World Modeling", "author": "Linfeng Zhao et.al.", "abstract": "Compositional generalization is a critical ability in learning and decision-making. We focus on the setting of reinforcement learning in object-oriented environments to study compositional generalization in world modeling. We (1) formalize the compositional generalization problem with an algebraic approach and (2) study how a world model can achieve that. We introduce a conceptual environment, Object Library, and two instances, and deploy a principled pipeline to measure the generalization ability. Motivated by the formulation, we analyze several methods with exact} or no compositional generalization ability using our framework, and design a differentiable approach, Homomorphic Object-oriented World Model (HOWM), that achieves approximate but more efficient compositional generalization.", "paper_url": "http://arxiv.org/abs/2204.13661v1", "pdf_url": "http://arxiv.org/pdf/2204.13661v1", "repo_url": null}, "2204.13378": {"publish_time": "2022-04-28", "title": "Learning General Inventory Management Policy for Large Supply Chain Network", "author": "Soh Kumabe et.al.", "abstract": "Inventory management in warehouses directly affects profits made by manufacturers. Particularly, large manufacturers produce a very large variety of products that are handled by a significantly large number of retailers. In such a case, the computational complexity of classical inventory management algorithms is inordinately large. In recent years, learning-based approaches have become popular for addressing such problems. However, previous studies have not been managed systems where both the number of products and retailers are large. This study proposes a reinforcement learning-based warehouse inventory management algorithm that can be used for supply chain systems where both the number of products and retailers are large. To solve the computational problem of handling large systems, we provide a means of approximate simulation of the system in the training phase. Our experiments on both real and artificial data demonstrate that our algorithm with approximated simulation can successfully handle large supply chain networks.", "paper_url": "http://arxiv.org/abs/2204.13378v1", "pdf_url": "http://arxiv.org/pdf/2204.13378v1", "repo_url": null}, "2204.13343": {"publish_time": "2022-04-28", "title": "Actor-Critic Scheduling for Path-Aware Air-to-Ground Multipath Multimedia Delivery", "author": "Achilles Machumilane et.al.", "abstract": "Reinforcement Learning (RL) has recently found wide applications in network traffic management and control because some of its variants do not require prior knowledge of network models. In this paper, we present a novel scheduler for real-time multimedia delivery in multipath systems based on an Actor-Critic (AC) RL algorithm. We focus on a challenging scenario of real-time video streaming from an Unmanned Aerial Vehicle (UAV) using multiple wireless paths. The scheduler acting as an RL agent learns in real-time the optimal policy for path selection, path rate allocation and redundancy estimation for flow protection. The scheduler, implemented as a module of the GStreamer framework, can be used in real or simulated settings. The simulation results show that our scheduler can target a very low loss rate at the receiver by dynamically adapting in real-time the scheduling policy to the path conditions without performing training or relying on prior knowledge of network channel models.", "paper_url": "http://arxiv.org/abs/2204.13343v1", "pdf_url": "http://arxiv.org/pdf/2204.13343v1", "repo_url": null}, "2204.13338": {"publish_time": "2022-04-28", "title": "Policy Gradient Stock GAN for Realistic Discrete Order Data Generation in Financial Markets", "author": "Masanori Hirano et.al.", "abstract": "This study proposes a new generative adversarial network (GAN) for generating realistic orders in financial markets. In some previous works, GANs for financial markets generated fake orders in continuous spaces because of GAN architectures' learning limitations. However, in reality, the orders are discrete, such as order prices, which has minimum order price unit, or order types. Thus, we change the generation method to place the generated fake orders into discrete spaces in this study. Because this change disabled the ordinary GAN learning algorithm, this study employed a policy gradient, frequently used in reinforcement learning, for the learning algorithm. Through our experiments, we show that our proposed model outperforms previous models in generated order distribution. As an additional benefit of introducing the policy gradient, the entropy of the generated policy can be used to check GAN's learning status. In the future, higher performance GANs, better evaluation methods, or the applications of our GANs can be addressed.", "paper_url": "http://arxiv.org/abs/2204.13338v1", "pdf_url": "http://arxiv.org/pdf/2204.13338v1", "repo_url": null}, "2204.14173": {"publish_time": "2022-04-29", "title": "Evolutionary Approach to Security Games with Signaling", "author": "Adam \u017bychowski et.al.", "abstract": "Green Security Games have become a popular way to model scenarios involving the protection of natural resources, such as wildlife. Sensors (e.g. drones equipped with cameras) have also begun to play a role in these scenarios by providing real-time information. Incorporating both human and sensor defender resources strategically is the subject of recent work on Security Games with Signaling (SGS). However, current methods to solve SGS do not scale well in terms of time or memory. We therefore propose a novel approach to SGS, which, for the first time in this domain, employs an Evolutionary Computation paradigm: EASGS. EASGS effectively searches the huge SGS solution space via suitable solution encoding in a chromosome and a specially-designed set of operators. The operators include three types of mutations, each focusing on a particular aspect of the SGS solution, optimized crossover and a local coverage improvement scheme (a memetic aspect of EASGS). We also introduce a new set of benchmark games, based on dense or locally-dense graphs that reflect real-world SGS settings. In the majority of 342 test game instances, EASGS outperforms state-of-the-art methods, including a reinforcement learning method, in terms of time scalability, nearly constant memory utilization, and quality of the returned defender's strategies (expected payoffs).", "paper_url": "http://arxiv.org/abs/2204.14173v1", "pdf_url": "http://arxiv.org/pdf/2204.14173v1", "repo_url": null}, "2204.13971": {"publish_time": "2022-04-29", "title": "Cost Effective MLaaS Federation: A Combinatorial Reinforcement Learning Approach", "author": "Shuzhao Xie et.al.", "abstract": "With the advancement of deep learning techniques, major cloud providers and niche machine learning service providers start to offer their cloud-based machine learning tools, also known as machine learning as a service (MLaaS), to the public. According to our measurement, for the same task, these MLaaSes from different providers have varying performance due to the proprietary datasets, models, etc. Federating different MLaaSes together allows us to improve the analytic performance further. However, naively aggregating results from different MLaaSes not only incurs significant momentary cost but also may lead to sub-optimal performance gain due to the introduction of possible false-positive results. In this paper, we propose Armol, a framework to federate the right selection of MLaaS providers to achieve the best possible analytic performance. We first design a word grouping algorithm to unify the output labels across different providers. We then present a deep combinatorial reinforcement learning based-approach to maximize the accuracy while minimizing the cost. The predictions from the selected providers are then aggregated together using carefully chosen ensemble strategies. The real-world trace-driven evaluation further demonstrates that Armol is able to achieve the same accuracy results with $67\\%$ less inference cost.", "paper_url": "http://arxiv.org/abs/2204.13971v1", "pdf_url": "http://arxiv.org/pdf/2204.13971v1", "repo_url": "https://github.com/shuzhaoxie/armol"}, "2204.13906": {"publish_time": "2022-04-29", "title": "Unsupervised Reinforcement Learning for Transferable Manipulation Skill Discovery", "author": "Daesol Cho et.al.", "abstract": "Current reinforcement learning (RL) in robotics often experiences difficulty in generalizing to new downstream tasks due to the innate task-specific training paradigm. To alleviate it, unsupervised RL, a framework that pre-trains the agent in a task-agnostic manner without access to the task-specific reward, leverages active exploration for distilling diverse experience into essential skills or reusable knowledge. For exploiting such benefits also in robotic manipulation, we propose an unsupervised method for transferable manipulation skill discovery that ties structured exploration toward interacting behavior and transferable skill learning. It not only enables the agent to learn interaction behavior, the key aspect of the robotic manipulation learning, without access to the environment reward, but also to generalize to arbitrary downstream manipulation tasks with the learned task-agnostic skills. Through comparative experiments, we show that our approach achieves the most diverse interacting behavior and significantly improves sample efficiency in downstream tasks including the extension to multi-object, multitask problems.", "paper_url": "http://arxiv.org/abs/2204.13906v1", "pdf_url": "http://arxiv.org/pdf/2204.13906v1", "repo_url": null}, "2205.00943": {"publish_time": "2022-05-02", "title": "CCLF: A Contrastive-Curiosity-Driven Learning Framework for Sample-Efficient Reinforcement Learning", "author": "Chenyu Sun et.al.", "abstract": "In reinforcement learning (RL), it is challenging to learn directly from high-dimensional observations, where data augmentation has recently been shown to remedy this via encoding invariances from raw pixels. Nevertheless, we empirically find that not all samples are equally important and hence simply injecting more augmented inputs may instead cause instability in Q-learning. In this paper, we approach this problem systematically by developing a model-agnostic Contrastive-Curiosity-Driven Learning Framework (CCLF), which can fully exploit sample importance and improve learning efficiency in a self-supervised manner. Facilitated by the proposed contrastive curiosity, CCLF is capable of prioritizing the experience replay, selecting the most informative augmented inputs, and more importantly regularizing the Q-function as well as the encoder to concentrate more on under-learned data. Moreover, it encourages the agent to explore with a curiosity-based reward. As a result, the agent can focus on more informative samples and learn representation invariances more efficiently, with significantly reduced augmented inputs. We apply CCLF to several base RL algorithms and evaluate on the DeepMind Control Suite, Atari, and MiniGrid benchmarks, where our approach demonstrates superior sample efficiency and learning performances compared with other state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2205.00943v1", "pdf_url": "http://arxiv.org/pdf/2205.00943v1", "repo_url": "https://github.com/csun001/cclf"}, "2205.00824": {"publish_time": "2022-05-02", "title": "Exploration in Deep Reinforcement Learning: A Survey", "author": "Pawel Ladosz et.al.", "abstract": "This paper reviews exploration techniques in deep reinforcement learning. Exploration techniques are of primary importance when solving sparse reward problems. In sparse reward problems, the reward is rare, which means that the agent will not find the reward often by acting randomly. In such a scenario, it is challenging for reinforcement learning to learn rewards and actions association. Thus more sophisticated exploration methods need to be devised. This review provides a comprehensive overview of existing exploration approaches, which are categorized based on the key contributions as follows reward novel states, reward diverse behaviours, goal-based methods, probabilistic methods, imitation-based methods, safe exploration and random-based methods. Then, the unsolved challenges are discussed to provide valuable future research directions. Finally, the approaches of different categories are compared in terms of complexity, computational effort and overall performance.", "paper_url": "http://arxiv.org/abs/2205.00824v1", "pdf_url": "http://arxiv.org/pdf/2205.00824v1", "repo_url": null}, "2205.00807": {"publish_time": "2022-05-02", "title": "Deep-Attack over the Deep Reinforcement Learning", "author": "Yang Li et.al.", "abstract": "Recent adversarial attack developments have made reinforcement learning more vulnerable, and different approaches exist to deploy attacks against it, where the key is how to choose the right timing of the attack. Some work tries to design an attack evaluation function to select critical points that will be attacked if the value is greater than a certain threshold. This approach makes it difficult to find the right place to deploy an attack without considering the long-term impact. In addition, there is a lack of appropriate indicators of assessment during attacks. To make the attacks more intelligent as well as to remedy the existing problems, we propose the reinforcement learning-based attacking framework by considering the effectiveness and stealthy spontaneously, while we also propose a new metric to evaluate the performance of the attack model in these two aspects. Experimental results show the effectiveness of our proposed model and the goodness of our proposed evaluation metric. Furthermore, we validate the transferability of the model, and also its robustness under the adversarial training.", "paper_url": "http://arxiv.org/abs/2205.00807v1", "pdf_url": "http://arxiv.org/pdf/2205.00807v1", "repo_url": null}, "2205.00772": {"publish_time": "2022-05-02", "title": "Large Neighborhood Search based on Neural Construction Heuristics", "author": "Jonas K. Falkner et.al.", "abstract": "We propose a Large Neighborhood Search (LNS) approach utilizing a learned construction heuristic based on neural networks as repair operator to solve the vehicle routing problem with time windows (VRPTW). Our method uses graph neural networks to encode the problem and auto-regressively decodes a solution and is trained with reinforcement learning on the construction task without requiring any labels for supervision. The neural repair operator is combined with a local search routine, heuristic destruction operators and a selection procedure applied to a small population to arrive at a sophisticated solution approach. The key idea is to use the learned model to re-construct the partially destructed solution and to introduce randomness via the destruction heuristics (or the stochastic policy itself) to effectively explore a large neighborhood.", "paper_url": "http://arxiv.org/abs/2205.00772v1", "pdf_url": "http://arxiv.org/pdf/2205.00772v1", "repo_url": "https://github.com/jokofa/jampr_plus"}, "2205.00579": {"publish_time": "2022-05-01", "title": "Data-driven control of spatiotemporal chaos with reduced-order neural ODE-based models and reinforcement learning", "author": "Kevin Zeng et.al.", "abstract": "Deep reinforcement learning (RL) is a data-driven method capable of discovering complex control strategies for high-dimensional systems, making it promising for flow control applications. In particular, the present work is motivated by the goal of reducing energy dissipation in turbulent flows, and the example considered is the spatiotemporally chaotic dynamics of the Kuramoto-Sivashinsky equation (KSE). A major challenge associated with RL is that substantial training data must be generated by repeatedly interacting with the target system, making it costly when the system is computationally or experimentally expensive. We mitigate this challenge in a data-driven manner by combining dimensionality reduction via an autoencoder with a neural ODE framework to obtain a low-dimensional dynamical model from just a limited data set. We substitute this data-driven reduced-order model (ROM) in place of the true system during RL training to efficiently estimate the optimal policy, which can then be deployed on the true system. For the KSE actuated with localized forcing (\"jets\") at four locations, we demonstrate that we are able to learn a ROM that accurately captures the actuated dynamics as well as the underlying natural dynamics just from snapshots of the KSE experiencing random actuations. Using this ROM and a control objective of minimizing dissipation and power cost, we extract a control policy from it using deep RL. We show that the ROM-based control strategy translates well to the true KSE and highlight that the RL agent discovers and stabilizes an underlying forced equilibrium solution of the KSE system. We show that this forced equilibrium captured in the ROM and discovered through RL is related to an existing known equilibrium solution of the natural KSE.", "paper_url": "http://arxiv.org/abs/2205.00579v1", "pdf_url": "http://arxiv.org/pdf/2205.00579v1", "repo_url": null}, "2205.01435": {"publish_time": "2022-05-03", "title": "RLFlow: Optimising Neural Network Subgraph Transformation with World Models", "author": "Sean Parker et.al.", "abstract": "We explored the use of reinforcement learning (RL) agents that can learn to perform neural network subgraph transformations, without the need of expertly designed heuristics to achieve a high level of performance. Reducing compute requirements of deep learning models is a focus of extensive research and many systems, optimisations and just-in-time (JIT) compilers have been proposed to decrease runtime.   Recent work has aimed to apply reinforcement learning to computer systems with some success, especially using model-free RL techniques. Model-based reinforcement learning methods have seen an increased focus in research as they can be used to learn the transition dynamics of the environment; this can be leveraged to train an agent using the hallucinogenic environment, thereby increasing sample efficiency compared to model-free approaches. Furthermore, when using a world model as a simulated environment, batch rollouts can occur safely in parallel and, especially in systems environments, it overcomes the latency impact of updating system environments that can take orders of magnitude longer to perform an action compared to simple emulators for video games.   We propose a design for a model-based agent which learns to optimise the architecture of neural networks by performing a sequence of subgraph transformations to reduce model runtime. We show our approach can match the performance of state of the art on common convolutional networks and outperform those by up to 5% on transformer-style architectures.", "paper_url": "http://arxiv.org/abs/2205.01435v1", "pdf_url": "http://arxiv.org/pdf/2205.01435v1", "repo_url": null}, "2205.01390": {"publish_time": "2022-05-03", "title": "Cost-Efficient and QoS-Aware User Association and 3D Placement of 6G Aerial Mobile Access Points", "author": "Esteban Catt\u00e9 et.al.", "abstract": "6G networks require a flexible infrastructure to dynamically provide ubiquitous network coverage. Mobile Access Points (MAP) deployment is a promising solution. In this paper, we formulate the joint 3D MAP deployment and user association problem over a dynamic network under interference and mobility constraints. First, we propose an iterative algorithm to optimize the deployment of MAPs. Our solution efficiently and quickly determines the number, position and configuration of MAPs for highly dynamic scenarios. MAPs provide appropriate Quality of Service (QoS) connectivity to mobile ground user in mmwave or sub-6GHz bands and find their optimal positions in a 3D grid. Each MAP also implies an energy cost (e.g. for travel) to be minimized. Once all MAPs deployed, a deep multiagent reinforcement learning algorithm is proposed to associate multiple users to multiple MAPs under interference constraint. Each user acts as an independent agent that operates in a fully distributed architecture and maximizes the network sum-rate.", "paper_url": "http://arxiv.org/abs/2205.01390v1", "pdf_url": "http://arxiv.org/pdf/2205.01390v1", "repo_url": null}, "2205.01356": {"publish_time": "2022-05-03", "title": "Neural Combinatorial Optimization: a New Player in the Field", "author": "Andoni I. Garmendia et.al.", "abstract": "Neural Combinatorial Optimization attempts to learn good heuristics for solving a set of problems using Neural Network models and Reinforcement Learning. Recently, its good performance has encouraged many practitioners to develop neural architectures for a wide variety of combinatorial problems. However, the incorporation of such algorithms in the conventional optimization framework has raised many questions related to their performance and the experimental comparison with other methods such as exact algorithms, heuristics and metaheuristics. This paper presents a critical analysis on the incorporation of algorithms based on neural networks into the classical combinatorial optimization framework. Subsequently, a comprehensive study is carried out to analyse the fundamental aspects of such algorithms, including performance, transferability, computational cost and generalization to larger-sized instances. To that end, we select the Linear Ordering Problem as a case of study, an NP-hard problem, and develop a Neural Combinatorial Optimization model to optimize it. Finally, we discuss how the analysed aspects apply to a general learning framework, and suggest new directions for future work in the area of Neural Combinatorial Optimization algorithms.", "paper_url": "http://arxiv.org/abs/2205.01356v1", "pdf_url": "http://arxiv.org/pdf/2205.01356v1", "repo_url": null}, "2205.01278": {"publish_time": "2022-05-03", "title": "Real-time Cooperative Vehicle Coordination at Unsignalized Road Intersections", "author": "Jiping Luo et.al.", "abstract": "Cooperative coordination at unsignalized road intersections, which aims to improve the driving safety and traffic throughput for connected and automated vehicles, has attracted increasing interests in recent years. However, most existing investigations either suffer from computational complexity or cannot harness the full potential of the road infrastructure. To this end, we first present a dedicated intersection coordination framework, where the involved vehicles hand over their control authorities and follow instructions from a centralized coordinator. Then a unified cooperative trajectory optimization problem will be formulated to maximize the traffic throughput while ensuring the driving safety and long-term stability of the coordination system. To address the key computational challenges in the real-world deployment, we reformulate this non-convex sequential decision problem into a model-free Markov Decision Process (MDP) and tackle it by devising a Twin Delayed Deep Deterministic Policy Gradient (TD3)-based strategy in the deep reinforcement learning (DRL) framework. Simulation and practical experiments show that the proposed strategy could achieve near-optimal performance in sub-static coordination scenarios and significantly improve the traffic throughput in the realistic continuous traffic flow. The most remarkable advantage is that our strategy could reduce the time complexity of computation to milliseconds, and is shown scalable when the road lanes increase.", "paper_url": "http://arxiv.org/abs/2205.01278v1", "pdf_url": "http://arxiv.org/pdf/2205.01278v1", "repo_url": null}, "2205.01235": {"publish_time": "2022-05-02", "title": "Triangular Dropout: Variable Network Width without Retraining", "author": "Edward W. Staley et.al.", "abstract": "One of the most fundamental design choices in neural networks is layer width: it affects the capacity of what a network can learn and determines the complexity of the solution. This latter property is often exploited when introducing information bottlenecks, forcing a network to learn compressed representations. However, such an architecture decision is typically immutable once training begins; switching to a more compressed architecture requires retraining. In this paper we present a new layer design, called Triangular Dropout, which does not have this limitation. After training, the layer can be arbitrarily reduced in width to exchange performance for narrowness. We demonstrate the construction and potential use cases of such a mechanism in three areas. Firstly, we describe the formulation of Triangular Dropout in autoencoders, creating models with selectable compression after training. Secondly, we add Triangular Dropout to VGG19 on ImageNet, creating a powerful network which, without retraining, can be significantly reduced in parameters. Lastly, we explore the application of Triangular Dropout to reinforcement learning (RL) policies on selected control problems.", "paper_url": "http://arxiv.org/abs/2205.01235v1", "pdf_url": "http://arxiv.org/pdf/2205.01235v1", "repo_url": null}, "2205.02108": {"publish_time": "2022-05-04", "title": "Using Deep Reinforcement Learning to solve Optimal Power Flow problem with generator failures", "author": "Muhammad Usman Awais et.al.", "abstract": "Deep Reinforcement Learning (DRL) is being used in many domains. One of the biggest advantages of DRL is that it enables the continuous improvement of a learning agent. Secondly, the DRL framework is robust and flexible enough to be applicable to problems of varying nature and domain. Presented work is evidence of using the DRL technique to solve an Optimal Power Flow (OPF) problem. Two classical algorithms have been presented to solve the OPF problem. The drawbacks of the vanilla DRL application are discussed, and an algorithm is suggested to improve the performance. Secondly, a reward function for the OPF problem is presented that enables the solution of inherent issues in DRL. Reasons for divergence and degeneration in DRL are discussed, and the correct strategy to deal with them with respect to OPF is presented.", "paper_url": "http://arxiv.org/abs/2205.02108v1", "pdf_url": "http://arxiv.org/pdf/2205.02108v1", "repo_url": null}, "2205.02092": {"publish_time": "2022-05-04", "title": "Learning Abstract and Transferable Representations for Planning", "author": "Steven James et.al.", "abstract": "We are concerned with the question of how an agent can acquire its own representations from sensory data. We restrict our focus to learning representations for long-term planning, a class of problems that state-of-the-art learning methods are unable to solve. We propose a framework for autonomously learning state abstractions of an agent's environment, given a set of skills. Importantly, these abstractions are task-independent, and so can be reused to solve new tasks. We demonstrate how an agent can use an existing set of options to acquire representations from ego- and object-centric observations. These abstractions can immediately be reused by the same agent in new environments. We show how to combine these portable representations with problem-specific ones to generate a sound description of a specific task that can be used for abstract planning. Finally, we show how to autonomously construct a multi-level hierarchy consisting of increasingly abstract representations. Since these hierarchies are transferable, higher-order concepts can be reused in new tasks, relieving the agent from relearning them and improving sample efficiency. Our results demonstrate that our approach allows an agent to transfer previous knowledge to new tasks, improving sample efficiency as the number of tasks increases.", "paper_url": "http://arxiv.org/abs/2205.02092v1", "pdf_url": "http://arxiv.org/pdf/2205.02092v1", "repo_url": null}, "2205.02057": {"publish_time": "2022-05-04", "title": "Reinforcement Learning for Improved Random Access in Delay-Constrained Heterogeneous Wireless Networks", "author": "Lei Deng et.al.", "abstract": "In this paper, we for the first time investigate the random access problem for a delay-constrained heterogeneous wireless network. We begin with a simple two-device problem where two devices deliver delay-constrained traffic to an access point (AP) via a common unreliable collision channel. By assuming that one device (called Device 1) adopts ALOHA, we aim to optimize the random access scheme of the other device (called Device 2). The most intriguing part of this problem is that Device 2 does not know the information of Device 1 but needs to maximize the system timely throughput. We first propose a Markov Decision Process (MDP) formulation to derive a model-based upper bound so as to quantify the performance gap of certain random access schemes. We then utilize reinforcement learning (RL) to design an R-learning-based random access scheme, called tiny state-space R-learning random access (TSRA), which is subsequently extended for the tackling of the general multi-device problem. We carry out extensive simulations to show that the proposed TSRA simultaneously achieves higher timely throughput, lower computation complexity, and lower power consumption than the existing baseline--deep-reinforcement learning multiple access (DLMA). This indicates that our proposed TSRA scheme is a promising means for efficient random access over massive mobile devices with limited computation and battery capabilities.", "paper_url": "http://arxiv.org/abs/2205.02057v1", "pdf_url": "http://arxiv.org/pdf/2205.02057v1", "repo_url": null}, "2205.02003": {"publish_time": "2022-05-04", "title": "Multi-subgoal Robot Navigation in Crowds with History Information and Interactions", "author": "Xinyi Yu et.al.", "abstract": "Robot navigation in dynamic environments shared with humans is an important but challenging task, which suffers from performance deterioration as the crowd grows. In this paper, multi-subgoal robot navigation approach based on deep reinforcement learning is proposed, which can reason about more comprehensive relationships among all agents (robot and humans). Specifically, the next position point is planned for the robot by introducing history information and interactions in our work. Firstly, based on subgraph network, the history information of all agents is aggregated before encoding interactions through a graph neural network, so as to improve the ability of the robot to anticipate the future scenarios implicitly. Further consideration, in order to reduce the probability of unreliable next position points, the selection module is designed after policy network in the reinforcement learning framework. In addition, the next position point generated from the selection module satisfied the task requirements better than that obtained directly from the policy network. The experiments demonstrate that our approach outperforms state-of-the-art approaches in terms of both success rate and collision rate, especially in crowded human environments.", "paper_url": "http://arxiv.org/abs/2205.02003v1", "pdf_url": "http://arxiv.org/pdf/2205.02003v1", "repo_url": null}, "2205.01977": {"publish_time": "2022-05-04", "title": "Collision Resolution with Deep Reinforcement Learning for Random Access in Machine-Type Communication", "author": "Muhammad Awais Jadoon et.al.", "abstract": "Grant-free random access (RA) techniques are suitable for machine-type communication (MTC) networks but they need to be adaptive to the MTC traffic, which is different from the human-type communication. Conventional RA protocols such as exponential backoff (EB) schemes for slotted-ALOHA suffer from a high number of collisions and they are not directly applicable to the MTC traffic models. In this work, we propose to use multi-agent deep Q-network (DQN) with parameter sharing to find a single policy applied to all machine-type devices (MTDs) in the network to resolve collisions. Moreover, we consider binary broadcast feedback common to all devices to reduce signalling overhead. We compare the performance of our proposed DQN-RA scheme with EB schemes for up to 500 MTDs and show that the proposed scheme outperforms EB policies and provides a better balance between throughput, delay and collision rate", "paper_url": "http://arxiv.org/abs/2205.01977v1", "pdf_url": "http://arxiv.org/pdf/2205.01977v1", "repo_url": null}, "2205.02824": {"publish_time": "2022-05-05", "title": "Rapid Locomotion via Reinforcement Learning", "author": "Gabriel B Margolis et.al.", "abstract": "Agile maneuvers such as sprinting and high-speed turning in the wild are challenging for legged robots. We present an end-to-end learned controller that achieves record agility for the MIT Mini Cheetah, sustaining speeds up to 3.9 m/s. This system runs and turns fast on natural terrains like grass, ice, and gravel and responds robustly to disturbances. Our controller is a neural network trained in simulation via reinforcement learning and transferred to the real world. The two key components are (i) an adaptive curriculum on velocity commands and (ii) an online system identification strategy for sim-to-real transfer leveraged from prior work. Videos of the robot's behaviors are available at: https://agility.csail.mit.edu/", "paper_url": "http://arxiv.org/abs/2205.02824v1", "pdf_url": "http://arxiv.org/pdf/2205.02824v1", "repo_url": null}, "2205.02818": {"publish_time": "2022-05-05", "title": "Generative methods for sampling transition paths in molecular dynamics", "author": "Tony Leli\u00e8vre et.al.", "abstract": "Molecular systems often remain trapped for long times around some local minimum of the potential energy function, before switching to another one -- a behavior known as metastability. Simulating transition paths linking one metastable state to another one is difficult by direct numerical methods. In view of the promises of machine learning techniques, we explore in this work two approaches to more efficiently generate transition paths: sampling methods based on generative models such as variational autoencoders, and importance sampling methods based on reinforcement learning.", "paper_url": "http://arxiv.org/abs/2205.02818v1", "pdf_url": "http://arxiv.org/pdf/2205.02818v1", "repo_url": null}, "2205.02760": {"publish_time": "2022-05-05", "title": "General sum stochastic games with networked information flows", "author": "Sarah H. Q. Li et.al.", "abstract": "Inspired by applications such as supply chain management, epidemics, and social networks, we formulate a stochastic game model that addresses three key features common across these domains: 1) network-structured player interactions, 2) pair-wise mixed cooperation and competition among players, and 3) limited global information toward individual decision-making. In combination, these features pose significant challenges for black box approaches taken by deep learning-based multi-agent reinforcement learning (MARL) algorithms and deserve more detailed analysis. We formulate a networked stochastic game with pair-wise general sum objectives and asymmetrical information structure, and empirically explore the effects of information availability on the outcomes of different MARL paradigms such as individual learning and centralized learning decentralized execution.", "paper_url": "http://arxiv.org/abs/2205.02760v1", "pdf_url": "http://arxiv.org/pdf/2205.02760v1", "repo_url": null}, "2205.02679": {"publish_time": "2022-05-05", "title": "KnitCity: a machine learning-based, game-theoretical framework for prediction assessment and seismic risk policy design", "author": "Ad\u00e8le Douin et.al.", "abstract": "Knitted fabric exhibits avalanche-like events when deformed: by analogy with eathquakes, we are interested in predicting these \"knitquakes\". However, as in most analogous seismic models, the peculiar statistics of the corresponding time-series severely jeopardize this endeavour, due to the time intermittence and scale-invariance of these events. But more importantly, such predictions are hard to {\\it assess}: depending on the choice of what to predict, the results can be very different and not easily compared. Furthermore, forecasting models may be trained with various generic metrics which ignore some important specificities of the problem at hand, in our case seismic risk. Finally, these models often do not provide a clear strategy regarding the best way to use these predictions in practice. Here we introduce a framework that allows to design, evaluate and compare not only predictors but also decision-making policies: a model seismically active {\\it city} subjected to the crackling dynamics observed in the mechanical response of knitted fabric. We thus proceed to study the population of KnitCity, introducing a policy through which the mayor of the town can decide to either keep people in, which in case of large events cause human loss, or evacuate the city, which costs a daily fee. The policy only relies on past seismic observations. We construct efficient policies using a reinforcement learning environment and various time-series predictors based on artificial neural networks. By inducing a physically motivated metric on the predictors, this mechanism allows quantitative assessment and comparison of their relevance in the decision-making process.", "paper_url": "http://arxiv.org/abs/2205.02679v1", "pdf_url": "http://arxiv.org/pdf/2205.02679v1", "repo_url": null}, "2205.02672": {"publish_time": "2022-05-05", "title": "Multi-Agent Deep Reinforcement Learning in Vehicular OCC", "author": "Amirul Islam et.al.", "abstract": "Optical camera communications (OCC) has emerged as a key enabling technology for the seamless operation of future autonomous vehicles. In this paper, we introduce a spectral efficiency optimization approach in vehicular OCC. Specifically, we aim at optimally adapting the modulation order and the relative speed while respecting bit error rate and latency constraints. As the optimization problem is NP-hard problem, we model the optimization problem as a Markov decision process (MDP) to enable the use of solutions that can be applied online. We then relaxed the constrained problem by employing Lagrange relaxation approach before solving it by multi-agent deep reinforcement learning (DRL). We verify the performance of our proposed scheme through extensive simulations and compare it with various variants of our approach and a random method. The evaluation shows that our system achieves significantly higher sum spectral efficiency compared to schemes under comparison.", "paper_url": "http://arxiv.org/abs/2205.02672v1", "pdf_url": "http://arxiv.org/pdf/2205.02672v1", "repo_url": null}, "2205.03353": {"publish_time": "2022-05-06", "title": "How to Spend Your Robot Time: Bridging Kickstarting and Offline Reinforcement Learning for Vision-based Robotic Manipulation", "author": "Alex X. Lee et.al.", "abstract": "Reinforcement learning (RL) has been shown to be effective at learning control from experience. However, RL typically requires a large amount of online interaction with the environment. This limits its applicability to real-world settings, such as in robotics, where such interaction is expensive. In this work we investigate ways to minimize online interactions in a target task, by reusing a suboptimal policy we might have access to, for example from training on related prior tasks, or in simulation. To this end, we develop two RL algorithms that can speed up training by using not only the action distributions of teacher policies, but also data collected by such policies on the task at hand. We conduct a thorough experimental study of how to use suboptimal teachers on a challenging robotic manipulation benchmark on vision-based stacking with diverse objects. We compare our methods to offline, online, offline-to-online, and kickstarting RL algorithms. By doing so, we find that training on data from both the teacher and student, enables the best performance for limited data budgets. We examine how to best allocate a limited data budget -- on the target task -- between the teacher and the student policy, and report experiments using varying budgets, two teachers with different degrees of suboptimality, and five stacking tasks that require a diverse set of behaviors. Our analysis, both in simulation and in the real world, shows that our approach is the best across data budgets, while standard offline RL from teacher rollouts is surprisingly effective when enough data is given.", "paper_url": "http://arxiv.org/abs/2205.03353v1", "pdf_url": "http://arxiv.org/pdf/2205.03353v1", "repo_url": null}, "2205.03321": {"publish_time": "2022-05-06", "title": "Learning Scalable Policies over Graphs for Multi-Robot Task Allocation using Capsule Attention Networks", "author": "Steve Paul et.al.", "abstract": "This paper presents a novel graph reinforcement learning (RL) architecture to solve multi-robot task allocation (MRTA) problems that involve tasks with deadlines and workload, and robot constraints such as work capacity. While drawing motivation from recent graph learning methods that learn to solve combinatorial optimization (CO) problems such as multi-Traveling Salesman and Vehicle Routing Problems using RL, this paper seeks to provide better performance (compared to non-learning methods) and important scalability (compared to existing learning architectures) for the stated class of MRTA problems. The proposed neural architecture, called Capsule Attention-based Mechanism or CapAM acts as the policy network, and includes three main components: 1) an encoder: a Capsule Network based node embedding model to represent each task as a learnable feature vector; 2) a decoder: an attention-based model to facilitate a sequential output; and 3) context: that encodes the states of the mission and the robots. To train the CapAM model, the policy-gradient method based on REINFORCE is used. When evaluated over unseen scenarios, CapAM demonstrates better task completion performance and $>$10 times faster decision-making compared to standard non-learning based online MRTA methods. CapAM's advantage in generalizability, and scalability to test problems of size larger than those used in training, are also successfully demonstrated in comparison to a popular approach for learning to solve CO problems, namely the purely attention mechanism.", "paper_url": "http://arxiv.org/abs/2205.03321v1", "pdf_url": "http://arxiv.org/pdf/2205.03321v1", "repo_url": null}, "2205.03294": {"publish_time": "2022-05-06", "title": "Vehicle management in a modular production context using Deep Q-Learning", "author": "Lucain Pouget et.al.", "abstract": "We investigate the feasibility of deploying Deep-Q based deep reinforcement learning agents to job-shop scheduling problems in the context of modular production facilities, using discrete event simulations for the environment. These environments are comprised of a source and sink for the parts to be processed, as well as (several) workstations. The agents are trained to schedule automated guided vehicles to transport the parts back and forth between those stations in an optimal fashion. Starting from a very simplistic setup, we increase the complexity of the environment and compare the agents' performances with well established heuristic approaches, such as first-in-first-out based agents, cost tables and a nearest-neighbor approach. We furthermore seek particular configurations of the environments in which the heuristic approaches struggle, to investigate to what degree the Deep-Q agents are affected by these challenges. We find that Deep-Q based agents show comparable performance as the heuristic baselines. Furthermore, our findings suggest that the DRL agents exhibit an increased robustness to noise, as compared to the conventional approaches. Overall, we find that DRL agents constitute a valuable approach for this type of scheduling problems.", "paper_url": "http://arxiv.org/abs/2205.03294v1", "pdf_url": "http://arxiv.org/pdf/2205.03294v1", "repo_url": null}, "2205.03279": {"publish_time": "2022-05-06", "title": "Optimal Control as Variational Inference", "author": "Tom Lefebvre et.al.", "abstract": "In this article we address the stochastic and risk sensitive optimal control problem probabilistically and decompose and solve the probabilistic models using principles from variational inference. We demonstrate how this culminates into two separate probabilistic inference procedures that allow to iteratively infer the deterministic optimal policy. More formally a sequence of belief policies, as a probabilistic proxy for the deterministic optimal policy, is specified through a fixed point iteration with the equilibrium point coinciding with the deterministic solution. These results re-establish the paradigm of Control as Inference, a concept explored and exploited originally by the Reinforcement Learning community anticipating deep rooted connections between optimal estimation and control. Although the Control as Inference paradigm already resulted in the development of several Reinforcement Learning algorithms, until now the underlying mechanism were only partially understood. For that very reason control as inference has not been well received by the control community. By exposing the underlying mechanism we aim to contribute to its general acceptance as a framework superseding optimal control. In order to exhibit its general relevance we discuss parallels with path integral control and discuss a wide range of possible applications.", "paper_url": "http://arxiv.org/abs/2205.03279v1", "pdf_url": "http://arxiv.org/pdf/2205.03279v1", "repo_url": null}, "2205.03243": {"publish_time": "2022-05-06", "title": "Alternating Good-for-MDP Automata", "author": "Ernst Moritz Hahn et.al.", "abstract": "When omega-regular objectives were first proposed in model-free reinforcement learning (RL) for controlling MDPs, deterministic Rabin automata were used in an attempt to provide a direct translation from their transitions to scalar values. While these translations failed, it has turned out that it is possible to repair them by using good-for-MDPs (GFM) B\\\"uchi automata instead. These are nondeterministic B\\\"uchi automata with a restricted type of nondeterminism, albeit not as restricted as in good-for-games automata. Indeed, deterministic Rabin automata have a pretty straightforward translation to such GFM automata, which is bi-linear in the number of states and pairs. Interestingly, the same cannot be said for deterministic Streett automata: a translation to nondeterministic Rabin or B\\\"uchi automata comes at an exponential cost, even without requiring the target automaton to be good-for-MDPs. Do we have to pay more than that to obtain a good-for-MDP automaton? The surprising answer is that we have to pay significantly less when we instead expand the good-for-MDP property to alternating automata: like the nondeterministic GFM automata obtained from deterministic Rabin automata, the alternating good-for-MDP automata we produce from deterministic Streett automata are bi-linear in the the size of the deterministic automaton and its index, and can therefore be exponentially more succinct than minimal nondeterministic B\\\"uchi automata.", "paper_url": "http://arxiv.org/abs/2205.03243v1", "pdf_url": "http://arxiv.org/pdf/2205.03243v1", "repo_url": null}, "2205.04424": {"publish_time": "2022-05-09", "title": "Accelerated Reinforcement Learning for Temporal Logic Control Objectives", "author": "Yiannis Kantaros et.al.", "abstract": "This paper addresses the problem of learning control policies for mobile robots modeled as unknown Markov Decision Processes (MDPs) that are tasked with temporal logic missions, such as sequencing, coverage, or surveillance. The MDP captures uncertainty in the workspace structure and the outcomes of control decisions. The control objective is to synthesize a control policy that maximizes the probability of accomplishing a high-level task, specified as a Linear Temporal Logic (LTL) formula. To address this problem, we propose a novel accelerated model-based reinforcement learning (RL) algorithm for LTL control objectives that is capable of learning control policies significantly faster than related approaches. Its sample-efficiency relies on biasing exploration towards directions that may contribute to task satisfaction. This is accomplished by leveraging an automaton representation of the LTL task as well as a continuously learned MDP model. Finally, we provide extensive comparative experiments that demonstrate the sample efficiency of the proposed method against recent temporal logic RL methods.", "paper_url": "http://arxiv.org/abs/2205.04424v1", "pdf_url": "http://arxiv.org/pdf/2205.04424v1", "repo_url": null}, "2205.04347": {"publish_time": "2022-05-09", "title": "A neural network model for timing control with reinforcement", "author": "Jing Wang et.al.", "abstract": "How do humans and animals perform trial-and-error learning when the space of possibilities is infinite? In a previous study, we used an interval timing production task and discovered an updating strategy in which the agent adjusted the behavioral and neuronal noise for exploration. In the experiment, human subjects proactively generated a series of timed motor outputs. We found that the sequential motor timing varied at two temporal scales: long-term correlation around the target interval due to memory drifts and short-term adjustments of timing variability according to feedback. We have previously described these features of timing variability with an augmented Gaussian process, termed reward sensitive Gaussian process (RSGP). Here we provide a mechanistic model and simulate the process by borrowing the architecture of recurrent neural networks. While recurrent connection provided the long-term serial correlation in motor timing, to facilitate reward-driven short-term variations, we introduced reward-dependent variability in the network connectivity, inspired by the stochastic nature of synaptic transmission in the brain. Our model was able to recursively generate an output sequence incorporating the internal variability and external reinforcement in a Bayesian framework. We show that the model can learn the key features of human behavior. Unlike other neural network models that search for unique network connectivity for the best match between the model prediction and observation, this model can estimate the uncertainty associated with each outcome and thus did a better job in teasing apart adjustable task-relevant variability from unexplained variability. The proposed artificial neural network model parallels the mechanisms of information processing in neural systems and can extend the framework of brain-inspired reinforcement learning in continuous state control.", "paper_url": "http://arxiv.org/abs/2205.04347v1", "pdf_url": "http://arxiv.org/pdf/2205.04347v1", "repo_url": null}, "2205.04134": {"publish_time": "2022-05-09", "title": "Federated Multi-Armed Bandits Under Byzantine Attacks", "author": "Ilker Demirel et.al.", "abstract": "Multi-armed bandits (MAB) is a simple reinforcement learning model where the learner controls the trade-off between exploration versus exploitation to maximize its cumulative reward. Federated multi-armed bandits (FMAB) is a recently emerging framework where a cohort of learners with heterogeneous local models play a MAB game and communicate their aggregated feedback to a parameter server to learn the global feedback model. Federated learning models are vulnerable to adversarial attacks such as model-update attacks or data poisoning. In this work, we study an FMAB problem in the presence of Byzantine clients who can send false model updates that pose a threat to the learning process. We borrow tools from robust statistics and propose a median-of-means-based estimator: Fed-MoM-UCB, to cope with the Byzantine clients. We show that if the Byzantine clients constitute at most half the cohort, it is possible to incur a cumulative regret on the order of ${\\cal O} (\\log T)$ with respect to an unavoidable error margin, including the communication cost between the clients and the parameter server. We analyze the interplay between the algorithm parameters, unavoidable error margin, regret, communication cost, and the arms' suboptimality gaps. We demonstrate Fed-MoM-UCB's effectiveness against the baselines in the presence of Byzantine attacks via experiments.", "paper_url": "http://arxiv.org/abs/2205.04134v1", "pdf_url": "http://arxiv.org/pdf/2205.04134v1", "repo_url": null}, "2205.04023": {"publish_time": "2022-05-09", "title": "A Comparative Tutorial of Bayesian Sequential Design and Reinforcement Learning", "author": "Mauricio Tec et.al.", "abstract": "Reinforcement Learning (RL) is a computational approach to reward-driven learning in sequential decision problems. It implements the discovery of optimal actions by learning from an agent interacting with an environment rather than from supervised data. We contrast and compare RL with traditional sequential design, focusing on simulation-based Bayesian sequential design (BSD). Recently, there has been an increasing interest in RL techniques for healthcare applications. We introduce two related applications as motivating examples. In both applications, the sequential nature of the decisions is restricted to sequential stopping. Rather than a comprehensive survey, the focus of the discussion is on solutions using standard tools for these two relatively simple sequential stopping problems. Both problems are inspired by adaptive clinical trial design. We use examples to explain the terminology and mathematical background that underlie each framework and map one to the other. The implementations and results illustrate the many similarities between RL and BSD. The results motivate the discussion of the potential strengths and limitations of each approach.", "paper_url": "http://arxiv.org/abs/2205.04023v1", "pdf_url": "http://arxiv.org/pdf/2205.04023v1", "repo_url": null}, "2205.04014": {"publish_time": "2022-05-09", "title": "Personalized QoE Enhancement for Adaptive Video Streaming: A Digital Twin-Assisted Scheme", "author": "Xinyu Huang et.al.", "abstract": "In this paper, we present a digital twin (DT)-assisted adaptive video streaming scheme to enhance personalized quality-of-experience (PQoE). Since PQoE models are user-specific and time-varying, existing schemes based on universal and time-invariant PQoE models may suffer from performance degradation. To address this issue, we first propose a DT-assisted PQoE model construction method to obtain accurate user-specific PQoE models. Specifically, user DTs (UDTs) are respectively constructed for individual users, which can acquire and utilize users' data to accurately tune PQoE model parameters in real time. Next, given the obtained PQoE models, we formulate a resource management problem to maximize the overall long-term PQoE by taking the dynamics of user' locations, video content requests, and buffer statuses into account. To solve this problem, a deep reinforcement learning algorithm is developed to jointly determine segment version selection, and communication and computing resource allocation. Simulation results on the real-world dataset demonstrate that the proposed scheme can effectively enhance PQoE compared with benchmark schemes.", "paper_url": "http://arxiv.org/abs/2205.04014v1", "pdf_url": "http://arxiv.org/pdf/2205.04014v1", "repo_url": null}, "2205.05061": {"publish_time": "2022-05-10", "title": "On the Verge of Solving Rocket League using Deep Reinforcement Learning and Sim-to-sim Transfer", "author": "Marco Pleines et.al.", "abstract": "Autonomously trained agents that are supposed to play video games reasonably well rely either on fast simulation speeds or heavy parallelization across thousands of machines running concurrently. This work explores a third way that is established in robotics, namely sim-to-real transfer, or if the game is considered a simulation itself, sim-to-sim transfer. In the case of Rocket League, we demonstrate that single behaviors of goalies and strikers can be successfully learned using Deep Reinforcement Learning in the simulation environment and transferred back to the original game. Although the implemented training simulation is to some extent inaccurate, the goalkeeping agent saves nearly 100% of its faced shots once transferred, while the striking agent scores in about 75% of cases. Therefore, the trained agent is robust enough and able to generalize to the target domain of Rocket League.", "paper_url": "http://arxiv.org/abs/2205.05061v1", "pdf_url": "http://arxiv.org/pdf/2205.05061v1", "repo_url": null}, "2205.05036": {"publish_time": "2022-05-10", "title": "Multi-agent Reinforcement Learning for Dynamic Resource Management in 6G in-X Subnetworks", "author": "Xiao Du et.al.", "abstract": "The 6G network enables a subnetwork-wide evolution, resulting in a \"network of subnetworks\". However, due to the dynamic mobility of wireless subnetworks, the data transmission of intra-subnetwork and inter-subnetwork will inevitably interfere with each other, which poses a great challenge to radio resource management. Moreover, most of the existing approaches require the instantaneous channel gain between subnetworks, which are usually difficult to be collected. To tackle these issues, in this paper we propose a novel effective intelligent radio resource management method using multi-agent deep reinforcement learning (MARL), which only needs the sum of received power, named received signal strength indicator (RSSI), on each channel instead of channel gains. However, to directly separate individual interference from RSSI is an almost impossible thing. To this end, we further propose a novel MARL architecture, named GA-Net, which integrates a hard attention layer to model the importance distribution of inter-subnetwork relationships based on RSSI and exclude the impact of unrelated subnetworks, and employs a graph attention network with a multi-head attention layer to exact the features and calculate their weights that will impact individual throughput. Experimental results prove that our proposed framework significantly outperforms both traditional and MARL-based methods in various aspects.", "paper_url": "http://arxiv.org/abs/2205.05036v1", "pdf_url": "http://arxiv.org/pdf/2205.05036v1", "repo_url": null}, "2205.05029": {"publish_time": "2022-05-10", "title": "Hybrid Reinforcement Learning for STAR-RISs: A Coupled Phase-Shift Model Based Beamformer", "author": "Ruikang Zhong et.al.", "abstract": "A simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted multi-user downlink multiple-input single-output (MISO) communication system is investigated. In contrast to the existing ideal STAR-RIS model assuming an independent transmission and reflection phase-shift control, a practical coupled phase-shift model is considered. Then, a joint active and passive beamforming optimization problem is formulated for minimizing the long-term transmission power consumption, subject to the coupled phase-shift constraint and the minimum data rate constraint. Despite the coupled nature of the phase-shift model, the formulated problem is solved by invoking a hybrid continuous and discrete phase-shift control policy. Inspired by this observation, a pair of hybrid reinforcement learning (RL) algorithms, namely the hybrid deep deterministic policy gradient (hybrid DDPG) algorithm and the joint DDPG & deep-Q network (DDPG-DQN) based algorithm are proposed. The hybrid DDPG algorithm controls the associated high-dimensional continuous and discrete actions by relying on the hybrid action mapping. By contrast, the joint DDPG-DQN algorithm constructs two Markov decision processes (MDPs) relying on an inner and an outer environment, thereby amalgamating the two agents to accomplish a joint hybrid control. Simulation results demonstrate that the STAR-RIS has superiority over other conventional RISs in terms of its energy consumption. Furthermore, both the proposed algorithms outperform the baseline DDPG algorithm, and the joint DDPG-DQN algorithm achieves a superior performance, albeit at an increased computational complexity.", "paper_url": "http://arxiv.org/abs/2205.05029v1", "pdf_url": "http://arxiv.org/pdf/2205.05029v1", "repo_url": null}, "2205.04797": {"publish_time": "2022-05-10", "title": "State Encoders in Reinforcement Learning for Recommendation: A Reproducibility Study", "author": "Jin Huang et.al.", "abstract": "Methods for reinforcement learning for recommendation (RL4Rec) are increasingly receiving attention as they can quickly adapt to user feedback. A typical RL4Rec framework consists of (1) a state encoder to encode the state that stores the users' historical interactions, and (2) an RL method to take actions and observe rewards. Prior work compared four state encoders in an environment where user feedback is simulated based on real-world logged user data. An attention-based state encoder was found to be the optimal choice as it reached the highest performance. However, this finding is limited to the actor-critic method, four state encoders, and evaluation-simulators that do not debias logged user data. In response to these shortcomings, we reproduce and expand on the existing comparison of attention-based state encoders (1) in the publicly available debiased RL4Rec SOFA simulator with (2) a different RL method, (3) more state encoders, and (4) a different dataset. Importantly, our experimental results indicate that existing findings do not generalize to the debiased SOFA simulator generated from a different dataset and a Deep Q-Network (DQN)-based method when compared with more state encoders.", "paper_url": "http://arxiv.org/abs/2205.04797v1", "pdf_url": "http://arxiv.org/pdf/2205.04797v1", "repo_url": "https://github.com/betsyhj/rl4rec"}, "2205.04619": {"publish_time": "2022-05-10", "title": "Risk Aversion In Learning Algorithms and an Application To Recommendation Systems", "author": "Andreas Haupt et.al.", "abstract": "Consider a bandit learning environment. We demonstrate that popular learning algorithms such as Upper Confidence Band (UCB) and $\\varepsilon$-Greedy exhibit risk aversion: when presented with two arms of the same expectation, but different variance, the algorithms tend to not choose the riskier, i.e. higher variance, arm. We prove that $\\varepsilon$-Greedy chooses the risky arm with probability tending to $0$ when faced with a deterministic and a Rademacher-distributed arm. We show experimentally that UCB also shows risk-averse behavior, and that risk aversion is present persistently in early rounds of learning even if the riskier arm has a slightly higher expectation. We calibrate our model to a recommendation system and show that algorithmic risk aversion can decrease consumer surplus and increase homogeneity. We discuss several extensions to other bandit algorithms, reinforcement learning, and investigate the impacts of algorithmic risk aversion for decision theory.", "paper_url": "http://arxiv.org/abs/2205.04619v1", "pdf_url": "http://arxiv.org/pdf/2205.04619v1", "repo_url": null}, "2205.05600": {"publish_time": "2022-05-11", "title": "RLOP: RL Methods in Option Pricing from a Mathematical Perspective", "author": "Ziheng Chen et.al.", "abstract": "Abstract In this work, we build two environments, namely the modified QLBS and RLOP models, from a mathematics perspective which enables RL methods in option pricing through replicating by portfolio. We implement the environment specifications (the source code can be found at https://github.com/owen8877/RLOP), the learning algorithm, and agent parametrization by a neural network. The learned optimal hedging strategy is compared against the BS prediction. The effect of various factors is considered and studied based on how they affect the optimal price and position.", "paper_url": "http://arxiv.org/abs/2205.05600v1", "pdf_url": "http://arxiv.org/pdf/2205.05600v1", "repo_url": null}, "2205.05588": {"publish_time": "2022-05-11", "title": "Characterizing the Action-Generalization Gap in Deep Q-Learning", "author": "Zhiyuan Zhou et.al.", "abstract": "We study the action generalization ability of deep Q-learning in discrete action spaces. Generalization is crucial for efficient reinforcement learning (RL) because it allows agents to use knowledge learned from past experiences on new tasks. But while function approximation provides deep RL agents with a natural way to generalize over state inputs, the same generalization mechanism does not apply to discrete action outputs. And yet, surprisingly, our experiments indicate that Deep Q-Networks (DQN), which use exactly this type of function approximator, are still able to achieve modest action generalization. Our main contribution is twofold: first, we propose a method of evaluating action generalization using expert knowledge of action similarity, and empirically confirm that action generalization leads to faster learning; second, we characterize the action-generalization gap (the difference in learning performance between DQN and the expert) in different domains. We find that DQN can indeed generalize over actions in several simple domains, but that its ability to do so decreases as the action space grows larger.", "paper_url": "http://arxiv.org/abs/2205.05588v1", "pdf_url": "http://arxiv.org/pdf/2205.05588v1", "repo_url": null}, "2205.05569": {"publish_time": "2022-05-11", "title": "Delayed Reinforcement Learning by Imitation", "author": "Pierre Liotet et.al.", "abstract": "When the agent's observations or interactions are delayed, classic reinforcement learning tools usually fail. In this paper, we propose a simple yet new and efficient solution to this problem. We assume that, in the undelayed environment, an efficient policy is known or can be easily learned, but the task may suffer from delays in practice and we thus want to take them into account. We present a novel algorithm, Delayed Imitation with Dataset Aggregation (DIDA), which builds upon imitation learning methods to learn how to act in a delayed environment from undelayed demonstrations. We provide a theoretical analysis of the approach that will guide the practical design of DIDA. These results are also of general interest in the delayed reinforcement learning literature by providing bounds on the performance between delayed and undelayed tasks, under smoothness conditions. We show empirically that DIDA obtains high performances with a remarkable sample efficiency on a variety of tasks, including robotic locomotion, classic control, and trading.", "paper_url": "http://arxiv.org/abs/2205.05569v1", "pdf_url": "http://arxiv.org/pdf/2205.05569v1", "repo_url": null}, "2205.05455": {"publish_time": "2022-05-11", "title": "Finite-Time Analysis of Constant Step-Size Q-Learning : Switching System Approach Revisited", "author": "Donghwna Lee et.al.", "abstract": "This technical note revisits the novel switching system framework in [1] for analyzing the finite-time convergence of Q-learning, where the dynamics of asynchronous Q-learning with a constant step-size is formulated as a discrete-time stochastic switching system model, and a bound on the average iteration is established based on Lyapunov functions. We improve the analysis in the previous paper by replacing the average iteration with the final iteration, which is simpler and more common in the literature. The proposed analysis relies on propagations of the autocorrelation matrix of the state instead of the Lyapunov function analysis. Moreover, we provide comparative analysis of the proposed method and existing approaches, and prove that the proposed approach improves the previous sample complexities in terms of the effective horizon. Besides, the proposed analysis offers additional insights on analysis of Q-learning and reinforcement learning, and complements existing approaches.", "paper_url": "http://arxiv.org/abs/2205.05455v1", "pdf_url": "http://arxiv.org/pdf/2205.05455v1", "repo_url": null}, "2205.05269": {"publish_time": "2022-05-11", "title": "Intelligent Reflecting Surface Configurations for Smart Radio Using Deep Reinforcement Learning", "author": "Wei Wang et.al.", "abstract": "Intelligent reflecting surface (IRS) is envisioned to change the paradigm of wireless communications from \"adapting to wireless channels\" to \"changing wireless channels\". However, current IRS configuration schemes, consisting of sub-channel estimation and passive beamforming in sequence, conform to the conventional model-based design philosophies and are difficult to be realized practically in the complex radio environment. To create the smart radio environment, we propose a model-free design of IRS control that is independent of the sub-channel channel state information (CSI) and requires the minimum interaction between IRS and the wireless communication system. We firstly model the control of IRS as a Markov decision process (MDP) and apply deep reinforcement learning (DRL) to perform real-time coarse phase control of IRS. Then, we apply extremum seeking control (ESC) as the fine phase control of IRS. Finally, by updating the frame structure, we integrate DRL and ESC in the model-free control of IRS to improve its adaptivity to different channel dynamics. Numerical results show the superiority of our proposed joint DRL and ESC scheme and verify its effectiveness in model-free IRS control without sub-channel CSI.", "paper_url": "http://arxiv.org/abs/2205.05269v1", "pdf_url": "http://arxiv.org/pdf/2205.05269v1", "repo_url": null}, "2205.06212": {"publish_time": "2022-05-12", "title": "Contingency-constrained economic dispatch with safe reinforcement learning", "author": "Michael Eichelbeck et.al.", "abstract": "Future power systems will rely heavily on micro grids with a high share of decentralised renewable energy sources and energy storage systems. The high complexity and uncertainty in this context might make conventional power dispatch strategies infeasible. Reinforcement-learning based (RL) controllers can address this challenge, however, cannot themselves provide safety guarantees, preventing their deployment in practice. To overcome this limitation, we propose a formally validated RL controller for economic dispatch. We extend conventional constraints by a time-dependent constraint encoding the islanding contingency. The contingency constraint is computed using set-based backwards reachability analysis and actions of the RL agent are verified through a safety layer. Unsafe actions are projected into the safe action space while leveraging constrained zonotope set representations for computational efficiency. The developed approach is demonstrated on a residential use case using real-world measurements.", "paper_url": "http://arxiv.org/abs/2205.06212v1", "pdf_url": "http://arxiv.org/pdf/2205.06212v1", "repo_url": null}, "2205.06111": {"publish_time": "2022-05-12", "title": "Asking for Knowledge: Training RL Agents to Query External Knowledge Using Language", "author": "Iou-Jen Liu et.al.", "abstract": "To solve difficult tasks, humans ask questions to acquire knowledge from external sources. In contrast, classical reinforcement learning agents lack such an ability and often resort to exploratory behavior. This is exacerbated as few present-day environments support querying for knowledge. In order to study how agents can be taught to query external knowledge via language, we first introduce two new environments: the grid-world-based Q-BabyAI and the text-based Q-TextWorld. In addition to physical interactions, an agent can query an external knowledge source specialized for these environments to gather information. Second, we propose the \"Asking for Knowledge\" (AFK) agent, which learns to generate language commands to query for meaningful knowledge that helps solve the tasks. AFK leverages a non-parametric memory, a pointer mechanism and an episodic exploration bonus to tackle (1) a large query language space, (2) irrelevant information, (3) delayed reward for making meaningful queries. Extensive experiments demonstrate that the AFK agent outperforms recent baselines on the challenging Q-BabyAI and Q-TextWorld environments.", "paper_url": "http://arxiv.org/abs/2205.06111v1", "pdf_url": "http://arxiv.org/pdf/2205.06111v1", "repo_url": null}, "2205.06011": {"publish_time": "2022-05-12", "title": "Mobility-Aware Resource Allocation for mmWave IAB Networks: A Multi-Agent RL Approach", "author": "Bibo Zhang et.al.", "abstract": "MmWaves have been envisioned as a promising direction to provide Gbps wireless access. However, they are susceptible to high path losses and blockages, which directional antennas can only partially mitigate. That makes mmWave networks coverage-limited, thus requiring dense deployments. Integrated access and backhaul (IAB) architectures have emerged as a cost-effective solution for network densification. Resource allocation in mmWave IAB networks must face big challenges to cope with heavy temporal dynamics, such as intermittent links caused by user mobility and blockages from moving obstacles. This makes it extremely difficult to find optimal and adaptive solutions. In this article, exploiting the distributed structure of the problem, we propose a Multi-Agent Reinforcement Learning (MARL) framework to optimize user throughput via flow routing and link scheduling in mmWave IAB networks characterized by user mobility and link outages generated by moving obstacles. The proposed approach implicitly captures the environment dynamics, coordinates the interference, and manages the buffer levels of IAB relay nodes. We design different MARL components, considering full-duplex and half-duplex IAB-nodes. In addition, we provide a communication and coordination scheme for RL agents in an online training framework, addressing the feasibility issues of practical systems. Numerical results show the effectiveness of the proposed approach.", "paper_url": "http://arxiv.org/abs/2205.06011v1", "pdf_url": "http://arxiv.org/pdf/2205.06011v1", "repo_url": null}, "2205.06002": {"publish_time": "2022-05-12", "title": "Learning Generalized Policies Without Supervision Using GNNs", "author": "Simon St\u00e5hlberg et.al.", "abstract": "We consider the problem of learning generalized policies for classical planning domains using graph neural networks from small instances represented in lifted STRIPS. The problem has been considered before but the proposed neural architectures are complex and the results are often mixed. In this work, we use a simple and general GNN architecture and aim at obtaining crisp experimental results and a deeper understanding: either the policy greedy in the learned value function achieves close to 100% generalization over instances larger than those used in training, or the failure must be understood, and possibly fixed, logically. For this, we exploit the relation established between the expressive power of GNNs and the $C_{2}$ fragment of first-order logic (namely, FOL with 2 variables and counting quantifiers). We find for example that domains with general policies that require more expressive features can be solved with GNNs once the states are extended with suitable \"derived atoms\" encoding role compositions and transitive closures that do not fit into $C_{2}$. The work follows the GNN approach for learning optimal general policies in a supervised fashion (Stahlberg, Bonet, Geffner, 2022); but the learned policies are no longer required to be optimal (which expands the scope, as many planning domains do not have general optimal policies) and are learned without supervision. Interestingly, value-based reinforcement learning methods that aim to produce optimal policies, do not always yield policies that generalize, as the goals of optimality and generality are in conflict in domains where optimal planning is NP-hard.", "paper_url": "http://arxiv.org/abs/2205.06002v1", "pdf_url": "http://arxiv.org/pdf/2205.06002v1", "repo_url": null}, "2205.06000": {"publish_time": "2022-05-12", "title": "Accounting for the Sequential Nature of States to Learn Features for Reinforcement Learning", "author": "Nathan Michlo et.al.", "abstract": "In this work, we investigate the properties of data that cause popular representation learning approaches to fail. In particular, we find that in environments where states do not significantly overlap, variational autoencoders (VAEs) fail to learn useful features. We demonstrate this failure in a simple gridworld domain, and then provide a solution in the form of metric learning. However, metric learning requires supervision in the form of a distance function, which is absent in reinforcement learning. To overcome this, we leverage the sequential nature of states in a replay buffer to approximate a distance metric and provide a weak supervision signal, under the assumption that temporally close states are also semantically similar. We modify a VAE with triplet loss and demonstrate that this approach is able to learn useful features for downstream tasks, without additional supervision, in environments where standard VAEs fail.", "paper_url": "http://arxiv.org/abs/2205.06000v1", "pdf_url": "http://arxiv.org/pdf/2205.06000v1", "repo_url": null}, "2205.06800": {"publish_time": "2022-05-13", "title": "Distributed Transmission Control for Wireless Networks using Multi-Agent Reinforcement Learning", "author": "Collin Farquhar et.al.", "abstract": "We examine the problem of transmission control, i.e., when to transmit, in distributed wireless communications networks through the lens of multi-agent reinforcement learning. Most other works using reinforcement learning to control or schedule transmissions use some centralized control mechanism, whereas our approach is fully distributed. Each transmitter node is an independent reinforcement learning agent and does not have direct knowledge of the actions taken by other agents. We consider the case where only a subset of agents can successfully transmit at a time, so each agent must learn to act cooperatively with other agents. An agent may decide to transmit a certain number of steps into the future, but this decision is not communicated to the other agents, so it the task of the individual agents to attempt to transmit at appropriate times. We achieve this collaborative behavior through studying the effects of different actions spaces. We are agnostic to the physical layer, which makes our approach applicable to many types of networks. We submit that approaches similar to ours may be useful in other domains that use multi-agent reinforcement learning with independent agents.", "paper_url": "http://arxiv.org/abs/2205.06800v1", "pdf_url": "http://arxiv.org/pdf/2205.06800v1", "repo_url": null}, "2205.06760": {"publish_time": "2022-05-13", "title": "Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning", "author": "Michael Bradley Johanson et.al.", "abstract": "Advances in artificial intelligence often stem from the development of new environments that abstract real-world situations into a form where research can be done conveniently. This paper contributes such an environment based on ideas inspired by elementary Microeconomics. Agents learn to produce resources in a spatially complex world, trade them with one another, and consume those that they prefer. We show that the emergent production, consumption, and pricing behaviors respond to environmental conditions in the directions predicted by supply and demand shifts in Microeconomics. We also demonstrate settings where the agents' emergent prices for goods vary over space, reflecting the local abundance of goods. After the price disparities emerge, some agents then discover a niche of transporting goods between regions with different prevailing prices -- a profitable strategy because they can buy goods where they are cheap and sell them where they are expensive. Finally, in a series of ablation experiments, we investigate how choices in the environmental rewards, bartering actions, agent architecture, and ability to consume tradable goods can either aid or inhibit the emergence of this economic behavior. This work is part of the environment development branch of a research program that aims to build human-like artificial general intelligence through multi-agent interactions in simulated societies. By exploring which environment features are needed for the basic phenomena of elementary microeconomics to emerge automatically from learning, we arrive at an environment that differs from those studied in prior multi-agent reinforcement learning work along several dimensions. For example, the model incorporates heterogeneous tastes and physical abilities, and agents negotiate with one another as a grounded form of communication.", "paper_url": "http://arxiv.org/abs/2205.06760v1", "pdf_url": "http://arxiv.org/pdf/2205.06760v1", "repo_url": null}, "2205.06750": {"publish_time": "2022-05-13", "title": "Provably Safe Reinforcement Learning: A Theoretical and Experimental Comparison", "author": "Hanna Krasowski et.al.", "abstract": "Ensuring safety of reinforcement learning (RL) algorithms is crucial for many real-world tasks. However, vanilla RL does not guarantee safety for an agent. In recent years, several methods have been proposed to provide safety guarantees for RL. To the best of our knowledge, there is no comprehensive comparison of these provably safe RL methods. We therefore introduce a categorization for existing provably safe RL methods, and present the theoretical foundations for both continuous and discrete action spaces. Additionally, we evaluate provably safe RL on an inverted pendulum. In the experiments, it is shown that indeed only provably safe RL methods guarantee safety.", "paper_url": "http://arxiv.org/abs/2205.06750v1", "pdf_url": "http://arxiv.org/pdf/2205.06750v1", "repo_url": null}, "2205.06595": {"publish_time": "2022-05-13", "title": "Upside-Down Reinforcement Learning Can Diverge in Stochastic Environments With Episodic Resets", "author": "Miroslav \u0160trupl et.al.", "abstract": "Upside-Down Reinforcement Learning (UDRL) is an approach for solving RL problems that does not require value functions and uses only supervised learning, where the targets for given inputs in a dataset do not change over time. Ghosh et al. proved that Goal-Conditional Supervised Learning (GCSL) -- which can be viewed as a simplified version of UDRL -- optimizes a lower bound on goal-reaching performance. This raises expectations that such algorithms may enjoy guaranteed convergence to the optimal policy in arbitrary environments, similar to certain well-known traditional RL algorithms. Here we show that for a specific episodic UDRL algorithm (eUDRL, including GCSL), this is not the case, and give the causes of this limitation. To do so, we first introduce a helpful rewrite of eUDRL as a recursive policy update. This formulation helps to disprove its convergence to the optimal policy for a wide class of stochastic environments. Finally, we provide a concrete example of a very simple environment where eUDRL diverges. Since the primary aim of this paper is to present a negative result, and the best counterexamples are the simplest ones, we restrict all discussions to finite (discrete) environments, ignoring issues of function approximation and limited sample size.", "paper_url": "http://arxiv.org/abs/2205.06595v1", "pdf_url": "http://arxiv.org/pdf/2205.06595v1", "repo_url": "https://github.com/struplm/udrl-gcsl-counterexample"}, "2205.06539": {"publish_time": "2022-05-13", "title": "Reduced modelling and optimal control of epidemiological individual-based models with contact heterogeneity", "author": "C. Court\u00e8s et.al.", "abstract": "Modelling epidemics via classical population-based models suffers from shortcomings that so-called individual-based models are able to overcome, as they are able to take heterogeneity features into account, such as super-spreaders, and describe the dynamics involved in small clusters. In return, such models often involve large graphs which are expensive to simulate and difficult to optimize, both in theory and in practice.   By combining the reinforcement learning philosophy with reduced models, we propose a numerical approach to determine optimal health policies for a stochastic epidemiological graph-model taking into account super-spreaders. More precisely, we introduce a deterministic reduced population-based model involving a neural network, and use it to derive optimal health policies through an optimal control approach. It is meant to faithfully mimic the local dynamics of the original, more complex, graph-model. Roughly speaking, this is achieved by sequentially training the network until an optimal control strategy for the corresponding reduced model manages to equally well contain the epidemic when simulated on the graph-model.   After describing the practical implementation of this approach, we will discuss the range of applicability of the reduced model and to what extent the estimated control strategies could provide useful qualitative information to health authorities.", "paper_url": "http://arxiv.org/abs/2205.06539v1", "pdf_url": "http://arxiv.org/pdf/2205.06539v1", "repo_url": null}, "2205.07802": {"publish_time": "2022-05-16", "title": "The Primacy Bias in Deep Reinforcement Learning", "author": "Evgenii Nikishin et.al.", "abstract": "This work identifies a common flaw of deep reinforcement learning (RL) algorithms: a tendency to rely on early interactions and ignore useful evidence encountered later. Because of training on progressively growing datasets, deep RL agents incur a risk of overfitting to earlier experiences, negatively affecting the rest of the learning process. Inspired by cognitive science, we refer to this effect as the primacy bias. Through a series of experiments, we dissect the algorithmic aspects of deep RL that exacerbate this bias. We then propose a simple yet generally-applicable mechanism that tackles the primacy bias by periodically resetting a part of the agent. We apply this mechanism to algorithms in both discrete (Atari 100k) and continuous action (DeepMind Control Suite) domains, consistently improving their performance.", "paper_url": "http://arxiv.org/abs/2205.07802v1", "pdf_url": "http://arxiv.org/pdf/2205.07802v1", "repo_url": null}, "2205.07730": {"publish_time": "2022-05-16", "title": "A hybrid classical-quantum approach to speed-up Q-learning", "author": "A. Sannia et.al.", "abstract": "We introduce a classical-quantum hybrid approach to computation, allowing for a quadratic performance improvement in the decision process of a learning agent. In particular, a quantum routine is described, which encodes on a quantum register the probability distributions that drive action choices in a reinforcement learning set-up. This routine can be employed by itself in several other contexts where decisions are driven by probabilities. After introducing the algorithm and formally evaluating its performance, in terms of computational complexity and maximum approximation error, we discuss in detail how to exploit it in the Q-learning context.", "paper_url": "http://arxiv.org/abs/2205.07730v1", "pdf_url": "http://arxiv.org/pdf/2205.07730v1", "repo_url": null}, "2205.07704": {"publish_time": "2022-05-16", "title": "From Dirichlet to Rubin: Optimistic Exploration in RL without Bonuses", "author": "Daniil Tiapkin et.al.", "abstract": "We propose the Bayes-UCBVI algorithm for reinforcement learning in tabular, stage-dependent, episodic Markov decision process: a natural extension of the Bayes-UCB algorithm by Kaufmann et al. (2012) for multi-armed bandits. Our method uses the quantile of a Q-value function posterior as upper confidence bound on the optimal Q-value function. For Bayes-UCBVI, we prove a regret bound of order $\\widetilde{O}(\\sqrt{H^3SAT})$ where $H$ is the length of one episode, $S$ is the number of states, $A$ the number of actions, $T$ the number of episodes, that matches the lower-bound of $\\Omega(\\sqrt{H^3SAT})$ up to poly-$\\log$ terms in $H,S,A,T$ for a large enough $T$. To the best of our knowledge, this is the first algorithm that obtains an optimal dependence on the horizon $H$ (and $S$) without the need for an involved Bernstein-like bonus or noise. Crucial to our analysis is a new fine-grained anti-concentration bound for a weighted Dirichlet sum that can be of independent interest. We then explain how Bayes-UCBVI can be easily extended beyond the tabular setting, exhibiting a strong link between our algorithm and Bayesian bootstrap (Rubin, 1981).", "paper_url": "http://arxiv.org/abs/2205.07704v1", "pdf_url": "http://arxiv.org/pdf/2205.07704v1", "repo_url": null}, "2205.07633": {"publish_time": "2022-05-16", "title": "Taming Continuous Posteriors for Latent Variational Dialogue Policies", "author": "Marin Vlastelica et.al.", "abstract": "Utilizing amortized variational inference for latent-action reinforcement learning (RL) has been shown to be an effective approach in Task-oriented Dialogue (ToD) systems for optimizing dialogue success. Until now, categorical posteriors have been argued to be one of the main drivers of performance. In this work we revisit Gaussian variational posteriors for latent-action RL and show that they can yield even better performance than categoricals. We achieve this by simplifying the training procedure and propose ways to regularize the latent dialogue policy to retain good response coherence. Using continuous latent representations our model achieves state of the art dialogue success rate on the MultiWOZ benchmark, and also compares well to categorical latent methods in response coherence.", "paper_url": "http://arxiv.org/abs/2205.07633v1", "pdf_url": "http://arxiv.org/pdf/2205.07633v1", "repo_url": null}, "2205.07626": {"publish_time": "2022-05-16", "title": "Attacking and Defending Deep Reinforcement Learning Policies", "author": "Chao Wang et.al.", "abstract": "Recent studies have shown that deep reinforcement learning (DRL) policies are vulnerable to adversarial attacks, which raise concerns about applications of DRL to safety-critical systems. In this work, we adopt a principled way and study the robustness of DRL policies to adversarial attacks from the perspective of robust optimization. Within the framework of robust optimization, optimal adversarial attacks are given by minimizing the expected return of the policy, and correspondingly a good defense mechanism should be realized by improving the worst-case performance of the policy. Considering that attackers generally have no access to the training environment, we propose a greedy attack algorithm, which tries to minimize the expected return of the policy without interacting with the environment, and a defense algorithm, which performs adversarial training in a max-min form. Experiments on Atari game environments show that our attack algorithm is more effective and leads to worse return of the policy than existing attack algorithms, and our defense algorithm yields policies more robust than existing defense methods to a range of adversarial attacks (including our proposed attack algorithm).", "paper_url": "http://arxiv.org/abs/2205.07626v1", "pdf_url": "http://arxiv.org/pdf/2205.07626v1", "repo_url": null}, "2205.08464": {"publish_time": "2022-05-17", "title": "Robust Losses for Learning Value Functions", "author": "Andrew Patterson et.al.", "abstract": "Most value function learning algorithms in reinforcement learning are based on the mean squared (projected) Bellman error. However, squared errors are known to be sensitive to outliers, both skewing the solution of the objective and resulting in high-magnitude and high-variance gradients. To control these high-magnitude updates, typical strategies in RL involve clipping gradients, clipping rewards, rescaling rewards, or clipping errors. While these strategies appear to be related to robust losses -- like the Huber loss -- they are built on semi-gradient update rules which do not minimize a known loss. In this work, we build on recent insights reformulating squared Bellman errors as a saddlepoint optimization problem and propose a saddlepoint reformulation for a Huber Bellman error and Absolute Bellman error. We start from a formalization of robust losses, then derive sound gradient-based approaches to minimize these losses in both the online off-policy prediction and control settings. We characterize the solutions of the robust losses, providing insight into the problem settings where the robust losses define notably better solutions than the mean squared Bellman error. Finally, we show that the resulting gradient-based algorithms are more stable, for both prediction and control, with less sensitivity to meta-parameters.", "paper_url": "http://arxiv.org/abs/2205.08464v1", "pdf_url": "http://arxiv.org/pdf/2205.08464v1", "repo_url": null}, "2205.08430": {"publish_time": "2022-05-17", "title": "Towards Resilient Access Equality for 6G Serverless p-LEO Satellite Networks", "author": "Lin Shih-Chun et.al.", "abstract": "Low earth orbit (LEO) mega-constellations, integrating government space systems and commercial practices, have emerged as enabling technologies for the sixth generation (6G) networks due to their good merits of global coverage and ubiquitous services for military and civilian use cases. However, convergent LEO-based satellite networking infrastructures still lack leveraging the synergy of space and terrestrial systems. This paper, therefore, extends conventional serverless cloud platforms with serverless edge learning architectures for 6G proliferated LEO (p-LEO) satellite ecosystems and provides a new distributed training design from a networking perspective. The proposed design dynamically orchestrates communications and computation functionalities and resources among heterogeneous physical units to efficiently fulfill multi-agent deep reinforcement learning for service-level agreements. Innovative ecosystem enhancements, including ultrabroadband access, anti-jammed transmissions, resilient networking, and related open challenges, are also investigated for end-to-end connectivity, communications, and learning performance.", "paper_url": "http://arxiv.org/abs/2205.08430v1", "pdf_url": "http://arxiv.org/pdf/2205.08430v1", "repo_url": null}, "2205.08316": {"publish_time": "2022-05-17", "title": "Self-Supervised Learning of Multi-Object Keypoints for Robotic Manipulation", "author": "Jan Ole von Hartz et.al.", "abstract": "In recent years, policy learning methods using either reinforcement or imitation have made significant progress. However, both techniques still suffer from being computationally expensive and requiring large amounts of training data. This problem is especially prevalent in real-world robotic manipulation tasks, where access to ground truth scene features is not available and policies are instead learned from raw camera observations. In this paper, we demonstrate the efficacy of learning image keypoints via the Dense Correspondence pretext task for downstream policy learning. Extending prior work to challenging multi-object scenes, we show that our model can be trained to deal with important problems in representation learning, primarily scale-invariance and occlusion. We evaluate our approach on diverse robot manipulation tasks, compare it to other visual representation learning approaches, and demonstrate its flexibility and effectiveness for sample-efficient policy learning.", "paper_url": "http://arxiv.org/abs/2205.08316v1", "pdf_url": "http://arxiv.org/pdf/2205.08316v1", "repo_url": null}, "2205.08253": {"publish_time": "2022-05-17", "title": "Adaptive Momentum-Based Policy Gradient with Second-Order Information", "author": "Saber Salehkaleybar et.al.", "abstract": "The variance reduced gradient estimators for policy gradient methods has been one of the main focus of research in the reinforcement learning in recent years as they allow acceleration of the estimation process. We propose a variance reduced policy gradient method, called SGDHess-PG, which incorporates second-order information into stochastic gradient descent (SGD) using momentum with an adaptive learning rate. SGDHess-PG algorithm can achieve $\\epsilon$-approximate first-order stationary point with $\\tilde{O}(\\epsilon^{-3})$ number of trajectories, while using a batch size of $O(1)$ at each iteration. Unlike most previous work, our proposed algorithm does not require importance sampling techniques which can compromise the advantage of variance reduction process. Our extensive experimental results show the effectiveness of the proposed algorithm on various control tasks and its advantage over the state of the art in practice.", "paper_url": "http://arxiv.org/abs/2205.08253v1", "pdf_url": "http://arxiv.org/pdf/2205.08253v1", "repo_url": null}, "2205.08221": {"publish_time": "2022-05-17", "title": "Efficient Unsupervised Sentence Compression by Fine-tuning Transformers with Reinforcement Learning", "author": "Demian Gholipour Ghalandari et.al.", "abstract": "Sentence compression reduces the length of text by removing non-essential content while preserving important facts and grammaticality. Unsupervised objective driven methods for sentence compression can be used to create customized models without the need for ground-truth training data, while allowing flexibility in the objective function(s) that are used for learning and inference. Recent unsupervised sentence compression approaches use custom objectives to guide discrete search; however, guided search is expensive at inference time. In this work, we explore the use of reinforcement learning to train effective sentence compression models that are also fast when generating predictions. In particular, we cast the task as binary sequence labelling and fine-tune a pre-trained transformer using a simple policy gradient approach. Our approach outperforms other unsupervised models while also being more efficient at inference time.", "paper_url": "http://arxiv.org/abs/2205.08221v1", "pdf_url": "http://arxiv.org/pdf/2205.08221v1", "repo_url": "https://github.com/complementizer/rl-sentence-compression"}, "2205.09088": {"publish_time": "2022-05-18", "title": "A Birds Eye View on Knowledge Graph Embeddings, Software Libraries, Applications and Challenges", "author": "Satvik Garg et.al.", "abstract": "In recent years, Knowledge Graph (KG) development has attracted significant researches considering the applications in web search, relation prediction, natural language processing, information retrieval, question answering to name a few. However, often KGs are incomplete due to which Knowledge Graph Completion (KGC) has emerged as a sub-domain of research to automatically track down the missing connections in a KG. Numerous strategies have been suggested to work out the KGC dependent on different representation procedures intended to embed triples into a low-dimensional vector space. Given the difficulties related to KGC, researchers around the world are attempting to comprehend the attributes of the problem statement. This study intends to provide an overview of knowledge bases combined with different challenges and their impacts. We discuss existing KGC approaches, including the state-of-the-art Knowledge Graph Embeddings (KGE), not only on static graphs but also for the latest trends such as multimodal, temporal, and uncertain knowledge graphs. In addition, reinforcement learning techniques are reviewed to model complex queries as a link prediction problem. Subsequently, we explored popular software packages for model training and examine open research challenges that can guide future research.", "paper_url": "http://arxiv.org/abs/2205.09088v1", "pdf_url": "http://arxiv.org/pdf/2205.09088v1", "repo_url": null}, "2205.09056": {"publish_time": "2022-05-18", "title": "Slowly Changing Adversarial Bandit Algorithms are Provably Efficient for Discounted MDPs", "author": "Ian A. Kash et.al.", "abstract": "Reinforcement learning (RL) generalizes bandit problems with additional difficulties on longer planning horzion and unknown transition kernel. We show that, under some mild assumptions, \\textbf{any} slowly changing adversarial bandit algorithm enjoys near-optimal regret in adversarial bandits can achieve near-optimal (expected) regret in non-episodic discounted MDPs. The slowly changing property required by our generalization is mild, see e.g. (Even-Dar et al. 2009, Neu et al. 2010), we also show, for example, \\expt~(Auer et al. 2002) is slowly changing and enjoys near-optimal regret in MDPs.", "paper_url": "http://arxiv.org/abs/2205.09056v1", "pdf_url": "http://arxiv.org/pdf/2205.09056v1", "repo_url": null}, "2205.08996": {"publish_time": "2022-05-18", "title": "Optimising cost-effectiveness of pandemic response under partial intervention measures", "author": "Quang Dang Nguyen et.al.", "abstract": "The COVID-19 pandemic created enormous public health and socioeconomic challenges. The health effects of vaccination and non-pharmaceutical interventions (NPIs) were often contrasted with significant social and economic costs. We describe a general framework aimed to derive adaptive cost-effective interventions, adequate for both recent and emerging pandemic threats. We also quantify the net health benefits and propose a reinforcement learning approach to optimise adaptive NPIs. The approach utilises an agent-based model simulating pandemic responses in Australia, and accounts for a heterogeneous population with variable levels of compliance fluctuating over time and across individuals. Our analysis shows that a significant net health benefit may be attained by adaptive NPIs formed by partial social distancing measures, coupled with moderate levels of the society's willingness to pay for health losses. We demonstrate that a socially acceptable balance between health effects and incurred economic costs is achievable over a long term, despite possible early setbacks.", "paper_url": "http://arxiv.org/abs/2205.08996v1", "pdf_url": "http://arxiv.org/pdf/2205.08996v1", "repo_url": null}, "2205.08936": {"publish_time": "2022-05-18", "title": "Market Making via Reinforcement Learning in China Commodity Market", "author": "Junshu Jiang et.al.", "abstract": "Market maker is an important role in financial market. A successful market maker should control inventory risk, adverse selection risk, and provides liquidity to the market. Reinforcement Learning, as an important methodology in control problems, enjoys the advantage of data-driven and less rigid assumption, receive great attentions in market making field since 2018. However, although China Commodity market, which has biggest trading volume on agricultural products, nonferrous metals and some other sectors, the study of applies RL on Market Making in China market is still rare. In this thesis, we try to fill the gap. We develop the Automatic Trading System and verify the feasibility of applying Reinforcement Learning in China Commodity market. Also, we probe the agent behavior by analyzing how it reacts to different environment conditions.", "paper_url": "http://arxiv.org/abs/2205.08936v1", "pdf_url": "http://arxiv.org/pdf/2205.08936v1", "repo_url": null}, "2205.08926": {"publish_time": "2022-05-18", "title": "Generating Explanations from Deep Reinforcement Learning Using Episodic Memory", "author": "Sam Blakeman et.al.", "abstract": "Deep Reinforcement Learning (RL) involves the use of Deep Neural Networks (DNNs) to make sequential decisions in order to maximize reward. For many tasks the resulting sequence of actions produced by a Deep RL policy can be long and difficult to understand for humans. A crucial component of human explanations is selectivity, whereby only key decisions and causes are recounted. Imbuing Deep RL agents with such an ability would make their resulting policies easier to understand from a human perspective and generate a concise set of instructions to aid the learning of future agents. To this end we use a Deep RL agent with an episodic memory system to identify and recount key decisions during policy execution. We show that these decisions form a short, human readable explanation that can also be used to speed up the learning of naive Deep RL agents in an algorithm-independent manner.", "paper_url": "http://arxiv.org/abs/2205.08926v1", "pdf_url": "http://arxiv.org/pdf/2205.08926v1", "repo_url": null}, "2205.09738": {"publish_time": "2022-05-19", "title": "AIGenC: AI generalisation via creativity", "author": "Corina Catarau-Cotutiu et.al.", "abstract": "This paper introduces a computational model of creative problem-solving in deep reinforcement learning agents, inspired by cognitive theories of creativity. The AIGenC model aims at enabling artificial agents to learn, use and generate transferable representations. AIGenC is embedded in a deep learning architecture that includes three main components: concept processing, reflective reasoning, and blending of concepts. The first component extracts objects and affordances from sensory input and encodes them in a concept space, represented as a hierarchical graph structure. Concept representations are stored in a dual memory system. Goal-directed and temporal information acquired by the agent during deep reinforcement learning enriches the representations creating a higher level of abstraction in the concept space. In parallel, a process akin to reflective reasoning detects and recovers from memory concepts relevant to the task according to a matching process that calculates a similarity value between the current state and memory graph structures. Once an interaction is finalised, rewards and temporal information are added to the graph structure, creating a higher abstraction level. If reflective reasoning fails to offer a suitable solution, a blending process comes into place to create new concepts by combining past information. We discuss the model's capability to yield better out-of-distribution generalisation in artificial agents, thus advancing toward artificial general intelligence. To the best of our knowledge, this is the first computational model, beyond mere formal theories, that posits a solution to creative problem solving within a deep learning architecture.", "paper_url": "http://arxiv.org/abs/2205.09738v1", "pdf_url": "http://arxiv.org/pdf/2205.09738v1", "repo_url": null}, "2205.09729": {"publish_time": "2022-05-19", "title": "Reinforcement Learning with Brain-Inspired Modulation can Improve Adaptation to Environmental Changes", "author": "Eric Chalmers et.al.", "abstract": "Developments in reinforcement learning (RL) have allowed algorithms to achieve impressive performance in highly complex, but largely static problems. In contrast, biological learning seems to value efficiency of adaptation to a constantly-changing world. Here we build on a recently-proposed neuronal learning rule that assumes each neuron can optimize its energy balance by predicting its own future activity. That assumption leads to a neuronal learning rule that uses presynaptic input to modulate prediction error. We argue that an analogous RL rule would use action probability to modulate reward prediction error. This modulation makes the agent more sensitive to negative experiences, and more careful in forming preferences. We embed the proposed rule in both tabular and deep-Q-network RL algorithms, and find that it outperforms conventional algorithms in simple, but highly-dynamic tasks. We suggest that the new rule encapsulates a core principle of biological intelligence; an important component for allowing algorithms to adapt to change in a human-like way.", "paper_url": "http://arxiv.org/abs/2205.09729v1", "pdf_url": "http://arxiv.org/pdf/2205.09729v1", "repo_url": "https://github.com/echalmers/modulated_td_error"}, "2205.09705": {"publish_time": "2022-05-19", "title": "Distributed Multi-Agent Deep Reinforcement Learning for Robust Coordination against Noise", "author": "Yoshinari Motokawa et.al.", "abstract": "In multi-agent systems, noise reduction techniques are important for improving the overall system reliability as agents are required to rely on limited environmental information to develop cooperative and coordinated behaviors with the surrounding agents. However, previous studies have often applied centralized noise reduction methods to build robust and versatile coordination in noisy multi-agent environments, while distributed and decentralized autonomous agents are more plausible for real-world application. In this paper, we introduce a \\emph{distributed attentional actor architecture model for a multi-agent system} (DA3-X), using which we demonstrate that agents with DA3-X can selectively learn the noisy environment and behave cooperatively. We experimentally evaluate the effectiveness of DA3-X by comparing learning methods with and without DA3-X and show that agents with DA3-X can achieve better performance than baseline agents. Furthermore, we visualize heatmaps of \\emph{attentional weights} from the DA3-X to analyze how the decision-making process and coordinated behavior are influenced by noise.", "paper_url": "http://arxiv.org/abs/2205.09705v1", "pdf_url": "http://arxiv.org/pdf/2205.09705v1", "repo_url": null}, "2205.09683": {"publish_time": "2022-05-19", "title": "Dexterous Robotic Manipulation using Deep Reinforcement Learning and Knowledge Transfer for Complex Sparse Reward-based Tasks", "author": "Qiang Wang et.al.", "abstract": "This paper describes a deep reinforcement learning (DRL) approach that won Phase 1 of the Real Robot Challenge (RRC) 2021, and then extends this method to a more difficult manipulation task. The RRC consisted of using a TriFinger robot to manipulate a cube along a specified positional trajectory, but with no requirement for the cube to have any specific orientation. We used a relatively simple reward function, a combination of goal-based sparse reward and distance reward, in conjunction with Hindsight Experience Replay (HER) to guide the learning of the DRL agent (Deep Deterministic Policy Gradient (DDPG)). Our approach allowed our agents to acquire dexterous robotic manipulation strategies in simulation. These strategies were then applied to the real robot and outperformed all other competition submissions, including those using more traditional robotic control techniques, in the final evaluation stage of the RRC. Here we extend this method, by modifying the task of Phase 1 of the RRC to require the robot to maintain the cube in a particular orientation, while the cube is moved along the required positional trajectory. The requirement to also orient the cube makes the agent unable to learn the task through blind exploration due to increased problem complexity. To circumvent this issue, we make novel use of a Knowledge Transfer (KT) technique that allows the strategies learned by the agent in the original task (which was agnostic to cube orientation) to be transferred to this task (where orientation matters). KT allowed the agent to learn and perform the extended task in the simulator, which improved the average positional deviation from 0.134 m to 0.02 m, and average orientation deviation from 142{\\deg} to 76{\\deg} during evaluation. This KT concept shows good generalisation properties and could be applied to any actor-critic learning algorithm.", "paper_url": "http://arxiv.org/abs/2205.09683v1", "pdf_url": "http://arxiv.org/pdf/2205.09683v1", "repo_url": null}, "2205.09676": {"publish_time": "2022-05-19", "title": "Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search", "author": "Xiao Wang et.al.", "abstract": "Existing trackers usually select a location or proposal with the maximum score as tracking result for each frame. However, such greedy search scheme maybe not the optimal choice, especially when encountering challenging tracking scenarios like heavy occlusions and fast motion. Since the accumulated errors would make response scores not reliable anymore. In this paper, we propose a novel multi-agent reinforcement learning based beam search strategy (termed BeamTracking) to address this issue. Specifically, we formulate the tracking as a sample selection problem fulfilled by multiple parallel decision-making processes, each of which aims at picking out one sample as their tracking result in each frame. We take the target feature, proposal feature, and its response score as state, and also consider actions predicted by nearby agent, to train multi-agents to select their actions. When all the frames are processed, we select the trajectory with the maximum accumulated score as the tracking result. Extensive experiments on seven popular tracking benchmark datasets validated the effectiveness of the proposed algorithm.", "paper_url": "http://arxiv.org/abs/2205.09676v1", "pdf_url": "http://arxiv.org/pdf/2205.09676v1", "repo_url": null}, "2205.10330": {"publish_time": "2022-05-20", "title": "A Review of Safe Reinforcement Learning: Methods, Theory and Applications", "author": "Shangding Gu et.al.", "abstract": "Reinforcement learning has achieved tremendous success in many complex decision making tasks. When it comes to deploying RL in the real world, safety concerns are usually raised, leading to a growing demand for safe reinforcement learning algorithms, such as in autonomous driving and robotics scenarios. While safety control has a long history, the study of safe RL algorithms is still in the early stages. To establish a good foundation for future research in this thread, in this paper, we provide a review for safe RL from the perspectives of methods, theory and applications. Firstly, we review the progress of safe RL from five dimensions and come up with five problems that are crucial for safe RL being deployed in real-world applications, coined as \"2H3W\". Secondly, we analyze the theory and algorithm progress from the perspectives of answering the \"2H3W\" problems. Then, the sample complexity of safe RL methods is reviewed and discussed, followed by an introduction of the applications and benchmarks of safe RL algorithms. Finally, we open the discussion of the challenging problems in safe RL, hoping to inspire more future research on this thread.   To advance the study of safe RL algorithms, we release a benchmark suite, an open-sourced repository containing the implementations of major safe RL algorithms, along with tutorials at the link: https://github.com/chauncygu/Safe-Reinforcement-Learning-Baselines.git.", "paper_url": "http://arxiv.org/abs/2205.10330v1", "pdf_url": "http://arxiv.org/pdf/2205.10330v1", "repo_url": "https://github.com/chauncygu/safe-reinforcement-learning-baselines"}, "2205.10218": {"publish_time": "2022-05-20", "title": "Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions", "author": "Rui Yang et.al.", "abstract": "Generalization across different environments with the same tasks is critical for successful applications of visual reinforcement learning (RL) in real scenarios. However, visual distractions -- which are common in real scenes -- from high-dimensional observations can be hurtful to the learned representations in visual RL, thus degrading the performance of generalization. To tackle this problem, we propose a novel approach, namely Characteristic Reward Sequence Prediction (CRESP), to extract the task-relevant information by learning reward sequence distributions (RSDs), as the reward signals are task-relevant in RL and invariant to visual distractions. Specifically, to effectively capture the task-relevant information via RSDs, CRESP introduces an auxiliary task -- that is, predicting the characteristic functions of RSDs -- to learn task-relevant representations, because we can well approximate the high-dimensional distributions by leveraging the corresponding characteristic functions. Experiments demonstrate that CRESP significantly improves the performance of generalization on unseen environments, outperforming several state-of-the-arts on DeepMind Control tasks with different visual distractions.", "paper_url": "http://arxiv.org/abs/2205.10218v1", "pdf_url": "http://arxiv.org/pdf/2205.10218v1", "repo_url": null}, "2205.10187": {"publish_time": "2022-05-20", "title": "Adversarial Body Shape Search for Legged Robots", "author": "Takaaki Azakami et.al.", "abstract": "We propose an evolutionary computation method for an adversarial attack on the length and thickness of parts of legged robots by deep reinforcement learning. This attack changes the robot body shape and interferes with walking-we call the attacked body as adversarial body shape. The evolutionary computation method searches adversarial body shape by minimizing the expected cumulative reward earned through walking simulation. To evaluate the effectiveness of the proposed method, we perform experiments with three-legged robots, Walker2d, Ant-v2, and Humanoid-v2 in OpenAI Gym. The experimental results reveal that Walker2d and Ant-v2 are more vulnerable to the attack on the length than the thickness of the body parts, whereas Humanoid-v2 is vulnerable to the attack on both of the length and thickness. We further identify that the adversarial body shapes break left-right symmetry or shift the center of gravity of the legged robots. Finding adversarial body shape can be used to proactively diagnose the vulnerability of legged robot walking.", "paper_url": "http://arxiv.org/abs/2205.10187v1", "pdf_url": "http://arxiv.org/pdf/2205.10187v1", "repo_url": null}, "2205.10175": {"publish_time": "2022-05-20", "title": "Task Relabelling for Multi-task Transfer using Successor Features", "author": "Martin Balla et.al.", "abstract": "Deep Reinforcement Learning has been very successful recently with various works on complex domains. Most works are concerned with learning a single policy that solves the target task, but is fixed in the sense that if the environment changes the agent is unable to adapt to it. Successor Features (SFs) proposes a mechanism that allows learning policies that are not tied to any particular reward function. In this work we investigate how SFs may be pre-trained without observing any reward in a custom environment that features resource collection, traps and crafting. After pre-training we expose the SF agents to various target tasks and see how well they can transfer to new tasks. Transferring is done without any further training on the SF agents, instead just by providing a task vector. For training the SFs we propose a task relabelling method which greatly improves the agent's performance.", "paper_url": "http://arxiv.org/abs/2205.10175v1", "pdf_url": "http://arxiv.org/pdf/2205.10175v1", "repo_url": "https://github.com/martinballa/sf-tr"}, "2205.10106": {"publish_time": "2022-05-20", "title": "LeNSE: Learning To Navigate Subgraph Embeddings for Large-Scale Combinatorial Optimisation", "author": "David Ireland et.al.", "abstract": "Combinatorial Optimisation problems arise in several application domains and are often formulated in terms of graphs. Many of these problems are NP-hard, but exact solutions are not always needed. Several heuristics have been developed to provide near-optimal solutions; however, they do not typically scale well with the size of the graph. We propose a low-complexity approach for identifying a (possibly much smaller) subgraph of the original graph where the heuristics can be run in reasonable time and with a high likelihood of finding a global near-optimal solution. The core component of our approach is LeNSE, a reinforcement learning algorithm that learns how to navigate the space of possible subgraphs using an Euclidean subgraph embedding as its map. To solve CO problems, LeNSE is provided with a discriminative embedding trained using any existing heuristics using only on a small portion of the original graph. When tested on three problems (vertex cover, max-cut and influence maximisation) using real graphs with up to $10$ million edges, LeNSE identifies small subgraphs yielding solutions comparable to those found by running the heuristics on the entire graph, but at a fraction of the total run time.", "paper_url": "http://arxiv.org/abs/2205.10106v1", "pdf_url": "http://arxiv.org/pdf/2205.10106v1", "repo_url": null}, "2205.11507": {"publish_time": "2022-05-23", "title": "Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs", "author": "Dongruo Zhou et.al.", "abstract": "Recent studies have shown that episodic reinforcement learning (RL) is not more difficult than contextual bandits, even with a long planning horizon and unknown state transitions. However, these results are limited to either tabular Markov decision processes (MDPs) or computationally inefficient algorithms for linear mixture MDPs. In this paper, we propose the first computationally efficient horizon-free algorithm for linear mixture MDPs, which achieves the optimal $\\tilde O(d\\sqrt{K} +d^2)$ regret up to logarithmic factors. Our algorithm adapts a weighted least square estimator for the unknown transitional dynamic, where the weight is both \\emph{variance-aware} and \\emph{uncertainty-aware}. When applying our weighted least square estimator to heterogeneous linear bandits, we can obtain an $\\tilde O(d\\sqrt{\\sum_{k=1}^K \\sigma_k^2} +d)$ regret in the first $K$ rounds, where $d$ is the dimension of the context and $\\sigma_k^2$ is the variance of the reward in the $k$-th round. This also improves upon the best-known algorithms in this setting when $\\sigma_k^2$'s are known.", "paper_url": "http://arxiv.org/abs/2205.11507v1", "pdf_url": "http://arxiv.org/pdf/2205.11507v1", "repo_url": null}, "2205.11448": {"publish_time": "2022-05-23", "title": "Data augmentation for efficient learning from parametric experts", "author": "Alexandre Galashov et.al.", "abstract": "We present a simple, yet powerful data-augmentation technique to enable data-efficient learning from parametric experts for reinforcement and imitation learning. We focus on what we call the policy cloning setting, in which we use online or offline queries of an expert or expert policy to inform the behavior of a student policy. This setting arises naturally in a number of problems, for instance as variants of behavior cloning, or as a component of other algorithms such as DAGGER, policy distillation or KL-regularized RL. Our approach, augmented policy cloning (APC), uses synthetic states to induce feedback-sensitivity in a region around sampled trajectories, thus dramatically reducing the environment interactions required for successful cloning of the expert. We achieve highly data-efficient transfer of behavior from an expert to a student policy for high-degrees-of-freedom control problems. We demonstrate the benefit of our method in the context of several existing and widely used algorithms that include policy cloning as a constituent part. Moreover, we highlight the benefits of our approach in two practically relevant settings (a) expert compression, i.e. transfer to a student with fewer parameters; and (b) transfer from privileged experts, i.e. where the expert has a different observation space than the student, usually including access to privileged information.", "paper_url": "http://arxiv.org/abs/2205.11448v1", "pdf_url": "http://arxiv.org/pdf/2205.11448v1", "repo_url": null}, "2205.11428": {"publish_time": "2022-05-23", "title": "Spreading Factor and RSSI for Localization in LoRa Networks: A Deep Reinforcement Learning Approach", "author": "Yaya Etiabi et.al.", "abstract": "Recent advancements in Internet of Things (IoT) technologies have resulted in a tightening of requirements from various applications including localization in LoRa networks. To address the growing demand for LoRaWAN-powered IoT location-based services, accurate localization solutions are more crucial than ever. As such, in this work, we develop an accurate deep neural network based localization framework over a LoRa network by proposing a novel approach that builds the network radio map with the combination of RSSI recordings and the spreading factors (SF) used by LoRa devices during the transmissions. Then, we validate our framework using a publicly available experimental dataset recorded in an urban LoRa network. The performance evaluation shows the prominence of adding the spreading factor as an additional fingerprint, since we can achieve, by our approach, an improvement in localization accuracy by up to 6.67% compared to the state-of-the-art methods which employ uniquely the RSSI fingerprints. Additionally, we provide an analysis of the impact of the SF on the localization performance which reveals that the localization accuracy relies on the SF used for position request. Finally, we propose a deep reinforcement learning based localization system to capture the ever-growing complexity of LoRa networks environment and cope with the scalability issue in LoRa enabled massive IoT, and the results show an improvement of 63.3% in terms of accuracy.", "paper_url": "http://arxiv.org/abs/2205.11428v1", "pdf_url": "http://arxiv.org/pdf/2205.11428v1", "repo_url": null}, "2205.11389": {"publish_time": "2022-05-23", "title": "Fictitious Play in Markov Games with Single Controller", "author": "Muhammed O. Sayin et.al.", "abstract": "Certain but important classes of strategic-form games, including zero-sum and identical-interest games, have the fictitious-play-property (FPP), i.e., beliefs formed in fictitious play dynamics always converge to a Nash equilibrium (NE) in the repeated play of these games. Such convergence results are seen as a (behavioral) justification for the game-theoretical equilibrium analysis. Markov games (MGs), also known as stochastic games, generalize the repeated play of strategic-form games to dynamic multi-state settings with Markovian state transitions. In particular, MGs are standard models for multi-agent reinforcement learning -- a reviving research area in learning and games, and their game-theoretical equilibrium analyses have also been conducted extensively. However, whether certain classes of MGs have the FPP or not (i.e., whether there is a behavioral justification for equilibrium analysis or not) remains largely elusive. In this paper, we study a new variant of fictitious play dynamics for MGs and show its convergence to an NE in n-player identical-interest MGs in which a single player controls the state transitions. Such games are of interest in communications, control, and economics applications. Our result together with the recent results in [Sayin et al. 2020] establishes the FPP of two-player zero-sum MGs and n-player identical-interest MGs with a single controller (standing at two different ends of the MG spectrum from fully competitive to fully cooperative).", "paper_url": "http://arxiv.org/abs/2205.11389v1", "pdf_url": "http://arxiv.org/pdf/2205.11389v1", "repo_url": null}, "2205.11384": {"publish_time": "2022-05-23", "title": "Learning Long-Horizon Robot Exploration Strategies for Multi-Object Search in Continuous Action Spaces", "author": "F. Schmalstieg et.al.", "abstract": "Recent advances in vision-based navigation and exploration have shown impressive capabilities in photorealistic indoor environments. However, these methods still struggle with long-horizon tasks and require large amounts of data to generalize to unseen environments. In this work, we present a novel reinforcement learning approach for multi-object search that combines short-term and long-term reasoning in a single model while avoiding the complexities arising from hierarchical structures. In contrast to existing multi-object search methods that act in granular discrete action spaces, our approach achieves exceptional performance in continuous action spaces. We perform extensive experiments and show that it generalizes to unseen apartment environments with limited data. Furthermore, we demonstrate zero-shot transfer of the learned policies to an office environment in real world experiments.", "paper_url": "http://arxiv.org/abs/2205.11384v1", "pdf_url": "http://arxiv.org/pdf/2205.11384v1", "repo_url": null}, "2205.12258": {"publish_time": "2022-05-24", "title": "History Compression via Language Models in Reinforcement Learning", "author": "Fabian Paischer et.al.", "abstract": "In a partially observable Markov decision process (POMDP), an agent typically uses a representation of the past to approximate the underlying MDP. We propose to utilize a frozen Pretrained Language Transformer (PLT) for history representation and compression to improve sample efficiency. To avoid training of the Transformer, we introduce FrozenHopfield, which automatically associates observations with original token embeddings. To form these associations, a modern Hopfield network stores the original token embeddings, which are retrieved by queries that are obtained by a random but fixed projection of observations. Our new method, HELM, enables actor-critic network architectures that contain a pretrained language Transformer for history representation as a memory module. Since a representation of the past need not be learned, HELM is much more sample efficient than competitors. On Minigrid and Procgen environments HELM achieves new state-of-the-art results. Our code is available at https://github.com/ml-jku/helm.", "paper_url": "http://arxiv.org/abs/2205.12258v1", "pdf_url": "http://arxiv.org/pdf/2205.12258v1", "repo_url": null}, "2205.12184": {"publish_time": "2022-05-24", "title": "Distributional Hamilton-Jacobi-Bellman Equations for Continuous-Time Reinforcement Learning", "author": "Harley Wiltzer et.al.", "abstract": "Continuous-time reinforcement learning offers an appealing formalism for describing control problems in which the passage of time is not naturally divided into discrete increments. Here we consider the problem of predicting the distribution of returns obtained by an agent interacting in a continuous-time, stochastic environment. Accurate return predictions have proven useful for determining optimal policies for risk-sensitive control, learning state representations, multiagent coordination, and more. We begin by establishing the distributional analogue of the Hamilton-Jacobi-Bellman (HJB) equation for It\\^o diffusions and the broader class of Feller-Dynkin processes. We then specialize this equation to the setting in which the return distribution is approximated by $N$ uniformly-weighted particles, a common design choice in distributional algorithms. Our derivation highlights additional terms due to statistical diffusivity which arise from the proper handling of distributions in the continuous-time setting. Based on this, we propose a tractable algorithm for approximately solving the distributional HJB based on a JKO scheme, which can be implemented in an online control algorithm. We demonstrate the effectiveness of such an algorithm in a synthetic control problem.", "paper_url": "http://arxiv.org/abs/2205.12184v1", "pdf_url": "http://arxiv.org/pdf/2205.12184v1", "repo_url": null}, "2205.12128": {"publish_time": "2022-05-24", "title": "Learning to Drive Using Sparse Imitation Reinforcement Learning", "author": "Yuci Han et.al.", "abstract": "In this paper, we propose Sparse Imitation Reinforcement Learning (SIRL), a hybrid end-to-end control policy that combines the sparse expert driving knowledge with reinforcement learning (RL) policy for autonomous driving (AD) task in CARLA simulation environment. The sparse expert is designed based on hand-crafted rules which is suboptimal but provides a risk-averse strategy by enforcing experience for critical scenarios such as pedestrian and vehicle avoidance, and traffic light detection. As it has been demonstrated, training a RL agent from scratch is data-inefficient and time consuming particularly for the urban driving task, due to the complexity of situations stemming from the vast size of state space. Our SIRL strategy provides a solution to solve these problems by fusing the output distribution of the sparse expert policy and the RL policy to generate a composite driving policy. With the guidance of the sparse expert during the early training stage, SIRL strategy accelerates the training process and keeps the RL exploration from causing a catastrophe outcome, and ensures safe exploration. To some extent, the SIRL agent is imitating the driving expert's behavior. At the same time, it continuously gains knowledge during training therefore it keeps making improvement beyond the sparse expert, and can surpass both the sparse expert and a traditional RL agent. We experimentally validate the efficacy of proposed SIRL approach in a complex urban scenario within the CARLA simulator. Besides, we compare the SIRL agent's performance for risk-averse exploration and high learning efficiency with the traditional RL approach. We additionally demonstrate the SIRL agent's generalization ability to transfer the driving skill to unseen environment.", "paper_url": "http://arxiv.org/abs/2205.12128v1", "pdf_url": "http://arxiv.org/pdf/2205.12128v1", "repo_url": null}, "2205.12077": {"publish_time": "2022-05-24", "title": "Sharp Analysis of RLS-based Digital Precoder with Limited PAPR in Massive MIMO", "author": "Xiuxiu Ma et.al.", "abstract": "This paper focuses on the performance analysis of a class of limited peak-to-average power ratio (PAPR) precoders for downlink multi-user massive multiple-input multiple-output (MIMO) systems. Contrary to conventional precoding approaches based on simple linear precoders maximum ratio transmission (MRT) and regularized zero forcing (RZF), the precoders in this paper are obtained by solving a convex optimization problem. To be specific, for the precoders we analyze in this paper, the power of each precoded symbol entry is restricted, which allows them to present a reduced PAPR at each antenna. By using the Convex Gaussian Min-max Theorem (CGMT), we analytically characterize the empirical distribution of the precoded vector and the joint empirical distribution between the distortion and the intended symbol vector. This allows us to study the performance of these precoders in terms of per-antenna power, per-user distortion power, signal to interference and noise ratio, and bit error probability. We show that for this class of precoders, there is an optimal transmit power that maximizes the system performance.", "paper_url": "http://arxiv.org/abs/2205.12077v1", "pdf_url": "http://arxiv.org/pdf/2205.12077v1", "repo_url": null}, "2205.12070": {"publish_time": "2022-05-24", "title": "Deep Reinforcement Learning for Multi-class Imbalanced Training", "author": "Jenny Yang et.al.", "abstract": "With the rapid growth of memory and computing power, datasets are becoming increasingly complex and imbalanced. This is especially severe in the context of clinical data, where there may be one rare event for many cases in the majority class. We introduce an imbalanced classification framework, based on reinforcement learning, for training extremely imbalanced data sets, and extend it for use in multi-class settings. We combine dueling and double deep Q-learning architectures, and formulate a custom reward function and episode-training procedure, specifically with the added capability of handling multi-class imbalanced training. Using real-world clinical case studies, we demonstrate that our proposed framework outperforms current state-of-the-art imbalanced learning methods, achieving more fair and balanced classification, while also significantly improving the prediction of minority classes.", "paper_url": "http://arxiv.org/abs/2205.12070v1", "pdf_url": "http://arxiv.org/pdf/2205.12070v1", "repo_url": null}, "2205.12944": {"publish_time": "2022-05-25", "title": "Learning Mean Field Games: A Survey", "author": "Mathieu Lauri\u00e8re et.al.", "abstract": "Non-cooperative and cooperative games with a very large number of players have many applications but remain generally intractable when the number of players increases. Introduced by Lasry and Lions, and Huang, Caines and Malham\\'e, Mean Field Games (MFGs) rely on a mean-field approximation to allow the number of players to grow to infinity. Traditional methods for solving these games generally rely on solving partial or stochastic differential equations with a full knowledge of the model. Recently, Reinforcement Learning (RL) has appeared promising to solve complex problems. By combining MFGs and RL, we hope to solve games at a very large scale both in terms of population size and environment complexity. In this survey, we review the quickly growing recent literature on RL methods to learn Nash equilibria in MFGs. We first identify the most common settings (static, stationary, and evolutive). We then present a general framework for classical iterative methods (based on best-response computation or policy evaluation) to solve MFGs in an exact way. Building on these algorithms and the connection with Markov Decision Processes, we explain how RL can be used to learn MFG solutions in a model-free way. Last, we present numerical illustrations on a benchmark problem, and conclude with some perspectives.", "paper_url": "http://arxiv.org/abs/2205.12944v1", "pdf_url": "http://arxiv.org/pdf/2205.12944v1", "repo_url": null}, "2205.12888": {"publish_time": "2022-05-25", "title": "Robust Reinforcement Learning on Graphs for Logistics optimization", "author": "Zangir Iklassov et.al.", "abstract": "Logistics optimization nowadays is becoming one of the hottest areas in the AI community. In the past year, significant advancements in the domain were achieved by representing the problem in a form of graph. Another promising area of research was to apply reinforcement learning algorithms to the above task. In our work, we made advantage of using both approaches and apply reinforcement learning on a graph. To do that, we have analyzed the most recent results in both fields and selected SOTA algorithms both from graph neural networks and reinforcement learning. Then, we combined selected models on the problem of AMOD systems optimization for the transportation network of New York city. Our team compared three algorithms - GAT, Pro-CNN and PTDNet - to bring to the fore the important nodes on a graph representation. Finally, we achieved SOTA results on AMOD systems optimization problem employing PTDNet with GNN and training them in reinforcement fashion.   Keywords: Graph Neural Network (GNN), Logistics optimization, Reinforcement Learning", "paper_url": "http://arxiv.org/abs/2205.12888v1", "pdf_url": "http://arxiv.org/pdf/2205.12888v1", "repo_url": null}, "2205.12880": {"publish_time": "2022-05-25", "title": "Trust-based Consensus in Multi-Agent Reinforcement Learning Systems", "author": "Ho Long Fung et.al.", "abstract": "An often neglected issue in multi-agent reinforcement learning (MARL) is the potential presence of unreliable agents in the environment whose deviations from expected behavior can prevent a system from accomplishing its intended tasks. In particular, consensus is a fundamental underpinning problem of cooperative distributed multi-agent systems. Consensus requires different agents, situated in a decentralized communication network, to reach an agreement out of a set of initial proposals that they put forward. Learning-based agents should adopt a protocol that allows them to reach consensus despite having one or more unreliable agents in the system. This paper investigates the problem of unreliable agents in MARL, considering consensus as case study. Echoing established results in the distributed systems literature, our experiments show that even a moderate fraction of such agents can greatly impact the ability of reaching consensus in a networked environment. We propose Reinforcement Learning-based Trusted Consensus (RLTC), a decentralized trust mechanism, in which agents can independently decide which neighbors to communicate with. We empirically demonstrate that our trust mechanism is able to deal with unreliable agents effectively, as evidenced by higher consensus success rates.", "paper_url": "http://arxiv.org/abs/2205.12880v1", "pdf_url": "http://arxiv.org/pdf/2205.12880v1", "repo_url": null}, "2205.12856": {"publish_time": "2022-05-25", "title": "Stochastic Second-Order Methods Provably Beat SGD For Gradient-Dominated Functions", "author": "Saeed Masiha et.al.", "abstract": "We study the performance of Stochastic Cubic Regularized Newton (SCRN) on a class of functions satisfying gradient dominance property which holds in a wide range of applications in machine learning and signal processing. This condition ensures that any first-order stationary point is a global optimum. We prove that SCRN improves the best-known sample complexity of stochastic gradient descent in achieving $\\epsilon$-global optimum by a factor of $\\mathcal{O}(\\epsilon^{-1/2})$. Even under a weak version of gradient dominance property, which is applicable to policy-based reinforcement learning (RL), SCRN achieves the same improvement over stochastic policy gradient methods. Additionally, we show that the sample complexity of SCRN can be improved by a factor of ${\\mathcal{O}}(\\epsilon^{-1/2})$ using a variance reduction method with time-varying batch sizes. Experimental results in various RL settings showcase the remarkable performance of SCRN compared to first-order methods.", "paper_url": "http://arxiv.org/abs/2205.12856v1", "pdf_url": "http://arxiv.org/pdf/2205.12856v1", "repo_url": null}, "2205.12811": {"publish_time": "2022-05-25", "title": "Automatic question generation based on sentence structure analysis using machine learning approach", "author": "Miroslav Bl\u0161t\u00e1k et.al.", "abstract": "Automatic question generation is one of the most challenging tasks of Natural Language Processing. It requires \"bidirectional\" language processing: firstly, the system has to understand the input text (Natural Language Understanding) and it then has to generate questions also in the form of text (Natural Language Generation). In this article, we introduce our framework for generating the factual questions from unstructured text in the English language. It uses a combination of traditional linguistic approaches based on sentence patterns with several machine learning methods. We firstly obtain lexical, syntactic and semantic information from an input text and we then construct a hierarchical set of patterns for each sentence. The set of features is extracted from the patterns and it is then used for automated learning of new transformation rules. Our learning process is totally data-driven because the transformation rules are obtained from a set of initial sentence-question pairs. The advantages of this approach lie in a simple expansion of new transformation rules which allows us to generate various types of questions and also in the continuous improvement of the system by reinforcement learning. The framework also includes a question evaluation module which estimates the quality of generated questions. It serves as a filter for selecting the best questions and eliminating incorrect ones or duplicates. We have performed several experiments to evaluate the correctness of generated questions and we have also compared our system with several state-of-the-art systems. Our results indicate that the quality of generated questions outperforms the state-of-the-art systems and our questions are also comparable to questions created by humans. We have also created and published an interface with all created datasets and evaluated questions, so it is possible to follow up on our work.", "paper_url": "http://arxiv.org/abs/2205.12811v1", "pdf_url": "http://arxiv.org/pdf/2205.12811v1", "repo_url": null}, "2205.13536": {"publish_time": "2022-05-26", "title": "Verifying Learning-Based Robotic Navigation Systems", "author": "Guy Amir et.al.", "abstract": "Deep reinforcement learning (DRL) has become a dominant deep-learning paradigm for various tasks in which complex policies are learned within reactive systems. In parallel, there has recently been significant research on verifying deep neural networks. However, to date, there has been little work demonstrating the use of modern verification tools on real, DRL-controlled systems.   In this case-study paper, we attempt to begin bridging this gap, and focus on the important task of mapless robotic navigation -- a classic robotics problem, in which a robot, usually controlled by a DRL agent, needs to efficiently and safely navigate through an unknown arena towards a desired target. We demonstrate how modern verification engines can be used for effective model selection, i.e., the process of selecting the best available policy for the robot in question from a pool of candidate policies. Specifically, we use verification to detect and rule out policies that may demonstrate suboptimal behavior, such as collisions and infinite loops. We also apply verification to identify models with overly conservative behavior, thus allowing users to choose superior policies that are better at finding an optimal, shorter path to a target.   To validate our work, we conducted extensive experiments on an actual robot, and confirmed that the suboptimal policies detected by our method were indeed flawed. We also compared our verification-driven approach to state-of-the-art gradient attacks, and our results demonstrate that gradient-based methods are inadequate in this setting.   Our work is the first to demonstrate the use of DNN verification backends for recognizing suboptimal DRL policies in real-world robots, and for filtering out unwanted policies. We believe that the methods presented in this work can be applied to a large range of application domains that incorporate deep-learning-based agents.", "paper_url": "http://arxiv.org/abs/2205.13536v1", "pdf_url": "http://arxiv.org/pdf/2205.13536v1", "repo_url": null}, "2205.13528": {"publish_time": "2022-05-26", "title": "TempoRL: Temporal Priors for Exploration in Off-Policy Reinforcement Learning", "author": "Marco Bagatella et.al.", "abstract": "Efficient exploration is a crucial challenge in deep reinforcement learning. Several methods, such as behavioral priors, are able to leverage offline data in order to efficiently accelerate reinforcement learning on complex tasks. However, if the task at hand deviates excessively from the demonstrated task, the effectiveness of such methods is limited. In our work, we propose to learn features from offline data that are shared by a more diverse range of tasks, such as correlation between actions and directedness. Therefore, we introduce state-independent temporal priors, which directly model temporal consistency in demonstrated trajectories, and are capable of driving exploration in complex tasks, even when trained on data collected on simpler tasks. Furthermore, we introduce a novel integration scheme for action priors in off-policy reinforcement learning by dynamically sampling actions from a probabilistic mixture of policy and action prior. We compare our approach against strong baselines and provide empirical evidence that it can accelerate reinforcement learning in long-horizon continuous control tasks under sparse reward settings.", "paper_url": "http://arxiv.org/abs/2205.13528v1", "pdf_url": "http://arxiv.org/pdf/2205.13528v1", "repo_url": null}, "2205.13521": {"publish_time": "2022-05-26", "title": "Discovering Policies with DOMiNO: Diversity Optimization Maintaining Near Optimality", "author": "Tom Zahavy et.al.", "abstract": "Finding different solutions to the same problem is a key aspect of intelligence associated with creativity and adaptation to novel situations. In reinforcement learning, a set of diverse policies can be useful for exploration, transfer, hierarchy, and robustness. We propose DOMiNO, a method for Diversity Optimization Maintaining Near Optimality. We formalize the problem as a Constrained Markov Decision Process where the objective is to find diverse policies, measured by the distance between the state occupancies of the policies in the set, while remaining near-optimal with respect to the extrinsic reward. We demonstrate that the method can discover diverse and meaningful behaviors in various domains, such as different locomotion patterns in the DeepMind Control Suite. We perform extensive analysis of our approach, compare it with other multi-objective baselines, demonstrate that we can control both the quality and the diversity of the set via interpretable hyperparameters, and show that the discovered set is robust to perturbations.", "paper_url": "http://arxiv.org/abs/2205.13521v1", "pdf_url": "http://arxiv.org/pdf/2205.13521v1", "repo_url": null}, "2205.13476": {"publish_time": "2022-05-26", "title": "Embed to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency", "author": "Lingxiao Wang et.al.", "abstract": "Reinforcement learning in partially observed Markov decision processes (POMDPs) faces two challenges. (i) It often takes the full history to predict the future, which induces a sample complexity that scales exponentially with the horizon. (ii) The observation and state spaces are often continuous, which induces a sample complexity that scales exponentially with the extrinsic dimension. Addressing such challenges requires learning a minimal but sufficient representation of the observation and state histories by exploiting the structure of the POMDP.   To this end, we propose a reinforcement learning algorithm named Embed to Control (ETC), which learns the representation at two levels while optimizing the policy.~(i) For each step, ETC learns to represent the state with a low-dimensional feature, which factorizes the transition kernel. (ii) Across multiple steps, ETC learns to represent the full history with a low-dimensional embedding, which assembles the per-step feature. We integrate (i) and (ii) in a unified framework that allows a variety of estimators (including maximum likelihood estimators and generative adversarial networks). For a class of POMDPs with a low-rank structure in the transition kernel, ETC attains an $O(1/\\epsilon^2)$ sample complexity that scales polynomially with the horizon and the intrinsic dimension (that is, the rank). Here $\\epsilon$ is the optimality gap. To our best knowledge, ETC is the first sample-efficient algorithm that bridges representation learning and policy optimization in POMDPs with infinite observation and state spaces.", "paper_url": "http://arxiv.org/abs/2205.13476v1", "pdf_url": "http://arxiv.org/pdf/2205.13476v1", "repo_url": null}, "2205.13441": {"publish_time": "2022-05-26", "title": "Deep Reinforcement Learning with Adaptive Hierarchical Reward for MultiMulti-Phase Multi Multi-Objective Dexterous Manipulation", "author": "Lingfeng Tao et.al.", "abstract": "Dexterous manipulation tasks usually have multiple objectives, and the priorities of these objectives may vary at different phases of a manipulation task. Varying priority makes a robot hardly or even failed to learn an optimal policy with a deep reinforcement learning (DRL) method. To solve this problem, we develop a novel Adaptive Hierarchical Reward Mechanism (AHRM) to guide the DRL agent to learn manipulation tasks with multiple prioritized objectives. The AHRM can determine the objective priorities during the learning process and update the reward hierarchy to adapt to the changing objective priorities at different phases. The proposed method is validated in a multi-objective manipulation task with a JACO robot arm in which the robot needs to manipulate a target with obstacles surrounded. The simulation and physical experiment results show that the proposed method improved robot learning in task performance and learning efficiency.", "paper_url": "http://arxiv.org/abs/2205.13441v1", "pdf_url": "http://arxiv.org/pdf/2205.13441v1", "repo_url": null}, "2205.14105": {"publish_time": "2022-05-27", "title": "Learning to Solve Combinatorial Graph Partitioning Problems via Efficient Exploration", "author": "Thomas D. Barrett et.al.", "abstract": "From logistics to the natural sciences, combinatorial optimisation on graphs underpins numerous real-world applications. Reinforcement learning (RL) has shown particular promise in this setting as it can adapt to specific problem structures and does not require pre-solved instances for these, often NP-hard, problems. However, state-of-the-art (SOTA) approaches typically suffer from severe scalability issues, primarily due to their reliance on expensive graph neural networks (GNNs) at each decision step. We introduce ECORD; a novel RL algorithm that alleviates this expense by restricting the GNN to a single pre-processing step, before entering a fast-acting exploratory phase directed by a recurrent unit. Experimentally, ECORD achieves a new SOTA for RL algorithms on the Maximum Cut problem, whilst also providing orders of magnitude improvement in speed and scalability. Compared to the nearest competitor, ECORD reduces the optimality gap by up to 73% on 500 vertex graphs with a decreased wall-clock time. Moreover, ECORD retains strong performance when generalising to larger graphs with up to 10000 vertices.", "paper_url": "http://arxiv.org/abs/2205.14105v1", "pdf_url": "http://arxiv.org/pdf/2205.14105v1", "repo_url": "https://github.com/tomdbar/ecord"}, "2205.14041": {"publish_time": "2022-05-27", "title": "Double Deep Q Networks for Sensor Management in Space Situational Awareness", "author": "Benedict Oakes et.al.", "abstract": "We present a novel Double Deep Q Network (DDQN) application to a sensor management problem in space situational awareness (SSA). Frequent launches of satellites into Earth orbit pose a significant sensor management challenge, whereby a limited number of sensors are required to detect and track an increasing number of objects. In this paper, we demonstrate the use of reinforcement learning to develop a sensor management policy for SSA. We simulate a controllable Earth-based telescope, which is trained to maximise the number of satellites tracked using an extended Kalman filter. The estimated state covariance matrices for satellites observed under the DDQN policy are greatly reduced compared to those generated by an alternate (random) policy. This work provides the basis for further advancements and motivates the use of reinforcement learning for SSA.", "paper_url": "http://arxiv.org/abs/2205.14041v1", "pdf_url": "http://arxiv.org/pdf/2205.14041v1", "repo_url": null}, "2205.13956": {"publish_time": "2022-05-27", "title": "Guided Exploration of Data Summaries", "author": "Brit Youngmann et.al.", "abstract": "Data summarization is the process of producing interpretable and representative subsets of an input dataset. It is usually performed following a one-shot process with the purpose of finding the best summary. A useful summary contains k individually uniform sets that are collectively diverse to be representative. Uniformity addresses interpretability and diversity addresses representativity. Finding such as summary is a difficult task when data is highly diverse and large. We examine the applicability of Exploratory Data Analysis (EDA) to data summarization and formalize Eda4Sum, the problem of guided exploration of data summaries that seeks to sequentially produce connected summaries with the goal of maximizing their cumulative utility. EdA4Sum generalizes one-shot summarization. We propose to solve it with one of two approaches: (i) Top1Sum which chooses the most useful summary at each step; (ii) RLSum which trains a policy with Deep Reinforcement Learning that rewards an agent for finding a diverse and new collection of uniform sets at each step. We compare these approaches with one-shot summarization and top-performing EDA solutions. We run extensive experiments on three large datasets. Our results demonstrate the superiority of our approaches for summarizing very large data, and the need to provide guidance to domain experts.", "paper_url": "http://arxiv.org/abs/2205.13956v1", "pdf_url": "http://arxiv.org/pdf/2205.13956v1", "repo_url": null}, "2205.13950": {"publish_time": "2022-05-27", "title": "Non-Markovian policies occupancy measures", "author": "Romain Laroche et.al.", "abstract": "A central object of study in Reinforcement Learning (RL) is the Markovian policy, in which an agent's actions are chosen from a memoryless probability distribution, conditioned only on its current state. The family of Markovian policies is broad enough to be interesting, yet simple enough to be amenable to analysis. However, RL often involves more complex policies: ensembles of policies, policies over options, policies updated online, etc. Our main contribution is to prove that the occupancy measure of any non-Markovian policy, i.e., the distribution of transition samples collected with it, can be equivalently generated by a Markovian policy.   This result allows theorems about the Markovian policy class to be directly extended to its non-Markovian counterpart, greatly simplifying proofs, in particular those involving replay buffers and datasets. We provide various examples of such applications to the field of Reinforcement Learning.", "paper_url": "http://arxiv.org/abs/2205.13950v1", "pdf_url": "http://arxiv.org/pdf/2205.13950v1", "repo_url": null}, "2205.13944": {"publish_time": "2022-05-27", "title": "Deep Reinforcement Learning for Distributed and Uncoordinated Cognitive Radios Resource Allocation", "author": "Ankita Tondwalkar et.al.", "abstract": "This paper presents a novel deep reinforcement learning-based resource allocation technique for the multi-agent environment presented by a cognitive radio network where the interactions of the agents during learning may lead to a non-stationary environment. The resource allocation technique presented in this work is distributed, not requiring coordination with other agents. It is shown by considering aspects specific to deep reinforcement learning that the presented algorithm converges in an arbitrarily long time to equilibrium policies in a non-stationary multi-agent environment that results from the uncoordinated dynamic interaction between radios through the shared wireless environment. Simulation results show that the presented technique achieves a faster learning performance compared to an equivalent table-based Q-learning algorithm and is able to find the optimal policy in 99% of cases for a sufficiently long learning time. In addition, simulations show that our DQL approach requires less than half the number of learning steps to achieve the same performance as an equivalent table-based implementation. Moreover, it is shown that the use of a standard single-agent deep reinforcement learning approach may not achieve convergence when used in an uncoordinated interacting multi-radio scenario", "paper_url": "http://arxiv.org/abs/2205.13944v1", "pdf_url": "http://arxiv.org/pdf/2205.13944v1", "repo_url": null}, "2205.15299": {"publish_time": "2022-05-30", "title": "Adapting Rapid Motor Adaptation for Bipedal Robots", "author": "Ashish Kumar et.al.", "abstract": "Recent advances in legged locomotion have enabled quadrupeds to walk on challenging terrains. However, bipedal robots are inherently more unstable and hence it's harder to design walking controllers for them. In this work, we leverage recent advances in rapid adaptation for locomotion control, and extend them to work on bipedal robots. Similar to existing works, we start with a base policy which produces actions while taking as input an estimated extrinsics vector from an adaptation module. This extrinsics vector contains information about the environment and enables the walking controller to rapidly adapt online. However, the extrinsics estimator could be imperfect, which might lead to poor performance of the base policy which expects a perfect estimator. In this paper, we propose A-RMA (Adapting RMA), which additionally adapts the base policy for the imperfect extrinsics estimator by finetuning it using model-free RL. We demonstrate that A-RMA outperforms a number of RL-based baseline controllers and model-based controllers in simulation, and show zero-shot deployment of a single A-RMA policy to enable a bipedal robot, Cassie, to walk in a variety of different scenarios in the real world beyond what it has seen during training. Videos and results at https://ashish-kmr.github.io/a-rma/", "paper_url": "http://arxiv.org/abs/2205.15299v1", "pdf_url": "http://arxiv.org/pdf/2205.15299v1", "repo_url": null}, "2205.15281": {"publish_time": "2022-05-30", "title": "Learning Open Domain Multi-hop Search Using Reinforcement Learning", "author": "Enrique Noriega-Atala et.al.", "abstract": "We propose a method to teach an automated agent to learn how to search for multi-hop paths of relations between entities in an open domain. The method learns a policy for directing existing information retrieval and machine reading resources to focus on relevant regions of a corpus. The approach formulates the learning problem as a Markov decision process with a state representation that encodes the dynamics of the search process and a reward structure that minimizes the number of documents that must be processed while still finding multi-hop paths. We implement the method in an actor-critic reinforcement learning algorithm and evaluate it on a dataset of search problems derived from a subset of English Wikipedia. The algorithm finds a family of policies that succeeds in extracting the desired information while processing fewer documents compared to several baseline heuristic algorithms.", "paper_url": "http://arxiv.org/abs/2205.15281v1", "pdf_url": "http://arxiv.org/pdf/2205.15281v1", "repo_url": null}, "2205.15245": {"publish_time": "2022-05-30", "title": "Residual Q-Networks for Value Function Factorizing in Multi-Agent Reinforcement Learning", "author": "Rafael Pina et.al.", "abstract": "Multi-Agent Reinforcement Learning (MARL) is useful in many problems that require the cooperation and coordination of multiple agents. Learning optimal policies using reinforcement learning in a multi-agent setting can be very difficult as the number of agents increases. Recent solutions such as Value Decomposition Networks (VDN), QMIX, QTRAN and QPLEX adhere to the centralized training and decentralized execution scheme and perform factorization of the joint action-value functions. However, these methods still suffer from increased environmental complexity, and at times fail to converge in a stable manner. We propose a novel concept of Residual Q-Networks (RQNs) for MARL, which learns to transform the individual Q-value trajectories in a way that preserves the Individual-Global-Max criteria (IGM), but is more robust in factorizing action-value functions. The RQN acts as an auxiliary network that accelerates convergence and will become obsolete as the agents reach the training objectives. The performance of the proposed method is compared against several state-of-the-art techniques such as QPLEX, QMIX, QTRAN and VDN, in a range of multi-agent cooperative tasks. The results illustrate that the proposed method, in general, converges faster, with increased stability and shows robust performance in a wider family of environments. The improvements in results are more prominent in environments with severe punishments for non-cooperative behaviours and especially in the absence of complete state information during training time.", "paper_url": "http://arxiv.org/abs/2205.15245v1", "pdf_url": "http://arxiv.org/pdf/2205.15245v1", "repo_url": null}, "2205.15241": {"publish_time": "2022-05-30", "title": "Multi-Game Decision Transformers", "author": "Kuang-Huei Lee et.al.", "abstract": "A longstanding goal of the field of AI is a strategy for compiling diverse experience into a highly capable, generalist agent. In the subfields of vision and language, this was largely achieved by scaling up transformer-based models and training them on large, diverse datasets. Motivated by this progress, we investigate whether the same strategy can be used to produce generalist reinforcement learning agents. Specifically, we show that a single transformer-based model - with a single set of weights - trained purely offline can play a suite of up to 46 Atari games simultaneously at close-to-human performance. When trained and evaluated appropriately, we find that the same trends observed in language and vision hold, including scaling of performance with model size and rapid adaptation to new games via fine-tuning. We compare several approaches in this multi-game setting, such as online and offline RL methods and behavioral cloning, and find that our Multi-Game Decision Transformer models offer the best scalability and performance. We release the pre-trained models and code to encourage further research in this direction. Additional information, videos and code can be seen at: sites.google.com/view/multi-game-transformers", "paper_url": "http://arxiv.org/abs/2205.15241v1", "pdf_url": "http://arxiv.org/pdf/2205.15241v1", "repo_url": null}, "2205.15064": {"publish_time": "2022-05-30", "title": "SEREN: Knowing When to Explore and When to Exploit", "author": "Changmin Yu et.al.", "abstract": "Efficient reinforcement learning (RL) involves a trade-off between \"exploitative\" actions that maximise expected reward and \"explorative'\" ones that sample unvisited states. To encourage exploration, recent approaches proposed adding stochasticity to actions, separating exploration and exploitation phases, or equating reduction in uncertainty with reward. However, these techniques do not necessarily offer entirely systematic approaches making this trade-off. Here we introduce SElective Reinforcement Exploration Network (SEREN) that poses the exploration-exploitation trade-off as a game between an RL agent -- \\exploiter, which purely exploits known rewards, and another RL agent -- \\switcher, which chooses at which states to activate a pure exploration policy that is trained to minimise system uncertainty and override Exploiter. Using a form of policies known as impulse control, \\switcher is able to determine the best set of states to switch to the exploration policy while Exploiter is free to execute its actions everywhere else. We prove that SEREN converges quickly and induces a natural schedule towards pure exploitation. Through extensive empirical studies in both discrete (MiniGrid) and continuous (MuJoCo) control benchmarks, we show that SEREN can be readily combined with existing RL algorithms to yield significant improvement in performance relative to state-of-the-art algorithms.", "paper_url": "http://arxiv.org/abs/2205.15064v1", "pdf_url": "http://arxiv.org/pdf/2205.15064v1", "repo_url": null}, "2205.15967": {"publish_time": "2022-05-31", "title": "You Can't Count on Luck: Why Decision Transformers Fail in Stochastic Environments", "author": "Keiran Paster et.al.", "abstract": "Recently, methods such as Decision Transformer that reduce reinforcement learning to a prediction task and solve it via supervised learning (RvS) have become popular due to their simplicity, robustness to hyperparameters, and strong overall performance on offline RL tasks. However, simply conditioning a probabilistic model on a desired return and taking the predicted action can fail dramatically in stochastic environments since trajectories that result in a return may have only achieved that return due to luck. In this work, we describe the limitations of RvS approaches in stochastic environments and propose a solution. Rather than simply conditioning on the return of a single trajectory as is standard practice, our proposed method, ESPER, learns to cluster trajectories and conditions on average cluster returns, which are independent from environment stochasticity. Doing so allows ESPER to achieve strong alignment between target return and expected performance in real environments. We demonstrate this in several challenging stochastic offline-RL tasks including the challenging puzzle game 2048, and Connect Four playing against a stochastic opponent. In all tested domains, ESPER achieves significantly better alignment between the target return and achieved return than simply conditioning on returns. ESPER also achieves higher maximum performance than even the value-based baselines.", "paper_url": "http://arxiv.org/abs/2205.15967v1", "pdf_url": "http://arxiv.org/pdf/2205.15967v1", "repo_url": null}, "2205.15953": {"publish_time": "2022-05-31", "title": "Timing is Everything: Learning to Act Selectively with Costly Actions and Budgetary Constraints", "author": "David Mguni et.al.", "abstract": "Many real-world settings involve costs for performing actions; transaction costs in financial systems and fuel costs being common examples. In these settings, performing actions at each time step quickly accumulates costs leading to vastly suboptimal outcomes. Additionally, repeatedly acting produces wear and tear and ultimately, damage. Determining when to act is crucial for achieving successful outcomes and yet, the challenge of efficiently learning to behave optimally when actions incur minimally bounded costs remains unresolved. In this paper, we introduce a reinforcement learning (RL) framework named Learnable Impulse Control Reinforcement Algorithm (LICRA), for learning to optimally select both when to act and which actions to take when actions incur costs. At the core of LICRA is a nested structure that combines RL and a form of policy known as impulse control which learns to maximise objectives when actions incur costs. We prove that LICRA, which seamlessly adopts any RL method, converges to policies that optimally select when to perform actions and their optimal magnitudes. We then augment LICRA to handle problems in which the agent can perform at most $k<\\infty$ actions and more generally, faces a budget constraint. We show LICRA learns the optimal value function and ensures budget constraints are satisfied almost surely. We demonstrate empirically LICRA's superior performance against benchmark RL methods in OpenAI gym's Lunar Lander and in Highway environments and a variant of the Merton portfolio problem within finance.", "paper_url": "http://arxiv.org/abs/2205.15953v1", "pdf_url": "http://arxiv.org/pdf/2205.15953v1", "repo_url": null}, "2205.15891": {"publish_time": "2022-05-31", "title": "One Policy is Enough: Parallel Exploration with a Single Policy is Minimax Optimal for Reward-Free Reinforcement Learning", "author": "Pedro Cisneros-Velarde et.al.", "abstract": "While parallelism has been extensively used in Reinforcement Learning (RL), the quantitative effects of parallel exploration are not well understood theoretically. We study the benefits of simple parallel exploration for reward-free RL for linear Markov decision processes (MDPs) and two-player zero-sum Markov games (MGs). In contrast to the existing literature focused on approaches that encourage agents to explore over a diverse set of policies, we show that using a single policy to guide exploration across all agents is sufficient to obtain an almost-linear speedup in all cases compared to their fully sequential counterpart. Further, we show that this simple procedure is minimax optimal up to logarithmic factors in the reward-free setting for both linear MDPs and two-player zero-sum MGs. From a practical perspective, our paper shows that a single policy is sufficient and provably optimal for incorporating parallelism during the exploration phase.", "paper_url": "http://arxiv.org/abs/2205.15891v1", "pdf_url": "http://arxiv.org/pdf/2205.15891v1", "repo_url": null}, "2205.15859": {"publish_time": "2022-05-31", "title": "Learning Generalizable Risk-Sensitive Policies to Coordinate in Decentralized Multi-Agent General-Sum Games", "author": "Ziyi Liu et.al.", "abstract": "While various multi-agent reinforcement learning methods have been proposed in cooperative settings, few works investigate how self-interested learning agents achieve mutual coordination in decentralized general-sum games and generalize pre-trained policies to non-cooperative opponents during execution. In this paper, we present a generalizable and sample efficient algorithm for multi-agent coordination in decentralized general-sum games without any access to other agents' rewards or observations. Specifically, we first learn the distributions over the return of individuals and estimate a dynamic risk-seeking bonus to encourage agents to discover risky coordination strategies. Furthermore, to avoid overfitting opponents' coordination strategies during training, we propose an auxiliary opponent modeling task so that agents can infer their opponents' type and dynamically alter corresponding strategies during execution. Empirically, we show that agents trained via our method can achieve mutual coordination during training and avoid being exploited by non-cooperative opponents during execution, which outperforms other baseline methods and reaches the state-of-the-art.", "paper_url": "http://arxiv.org/abs/2205.15859v1", "pdf_url": "http://arxiv.org/pdf/2205.15859v1", "repo_url": null}, "2205.15827": {"publish_time": "2022-05-31", "title": "Robust Anytime Learning of Markov Decision Processes", "author": "Marnix Suilen et.al.", "abstract": "Markov decision processes (MDPs) are formal models commonly used in sequential decision-making. MDPs capture the stochasticity that may arise, for instance, from imprecise actuators via probabilities in the transition function. However, in data-driven applications, deriving precise probabilities from (limited) data introduces statistical errors that may lead to unexpected or undesirable outcomes. Uncertain MDPs (uMDPs) do not require precise probabilities but instead use so-called uncertainty sets in the transitions, accounting for such limited data. Tools from the formal verification community efficiently compute robust policies that provably adhere to formal specifications, like safety constraints, under the worst-case instance in the uncertainty set. We continuously learn the transition probabilities of an MDP in a robust anytime-learning approach that combines a dedicated Bayesian inference scheme with the computation of robust policies. In particular, our method (1) approximates probabilities as intervals, (2) adapts to new data that may be inconsistent with an intermediate model, and (3) may be stopped at any time to compute a robust policy on the uMDP that faithfully captures the data so far. We show the effectiveness of our approach and compare it to robust policies computed on uMDPs learned by the UCRL2 reinforcement learning algorithm in an experimental evaluation on several benchmarks.", "paper_url": "http://arxiv.org/abs/2205.15827v1", "pdf_url": "http://arxiv.org/pdf/2205.15827v1", "repo_url": null}, "2206.00518": {"publish_time": "2022-06-01", "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement Learning", "author": "Byungchan Ko et.al.", "abstract": "In deep reinforcement learning (RL), data augmentation is widely considered as a tool to induce a set of useful priors about semantic consistency and improve sample efficiency and generalization performance. However, even when the prior is useful for generalization, distilling it to RL agent often interferes with RL training and degenerates sample efficiency. Meanwhile, the agent is forgetful of the prior due to the non-stationary nature of RL. These observations suggest two extreme schedules of distillation: (i) over the entire training; or (ii) only at the end. Hence, we devise a stand-alone network distillation method to inject the consistency prior at any time (even after RL), and a simple yet efficient framework to automatically schedule the distillation. Specifically, the proposed framework first focuses on mastering train environments regardless of generalization by adaptively deciding which {\\it or no} augmentation to be used for the training. After this, we add the distillation to extract the remaining benefits for generalization from all the augmentations, which requires no additional new samples. In our experiments, we demonstrate the utility of the proposed framework, in particular, that considers postponing the augmentation to the end of RL training.", "paper_url": "http://arxiv.org/abs/2206.00518v1", "pdf_url": "http://arxiv.org/pdf/2206.00518v1", "repo_url": null}, "2206.00316": {"publish_time": "2022-06-01", "title": "Model Generation with Provable Coverability for Offline Reinforcement Learning", "author": "Chengxing Jia et.al.", "abstract": "Model-based offline optimization with dynamics-aware policy provides a new perspective for policy learning and out-of-distribution generalization, where the learned policy could adapt to different dynamics enumerated at the training stage. But due to the limitation under the offline setting, the learned model could not mimic real dynamics well enough to support reliable out-of-distribution exploration, which still hinders policy to generalize well. To narrow the gap, previous works roughly ensemble randomly initialized models to better approximate the real dynamics. However, such practice is costly and inefficient, and provides no guarantee on how well the real dynamics could be approximated by the learned models, which we name coverability in this paper. We actively address this issue by generating models with provable ability to cover real dynamics in an efficient and controllable way. To that end, we design a distance metric for dynamic models based on the occupancy of policies under the dynamics, and propose an algorithm to generate models optimizing their coverage for the real dynamics. We give a theoretical analysis on the model generation process and proves that our algorithm could provide enhanced coverability. As a downstream task, we train a dynamics-aware policy with minor or no conservative penalty, and experiments demonstrate that our algorithm outperforms prior offline methods on existing offline RL benchmarks. We also discover that policies learned by our method have better zero-shot transfer performance, implying their better generalization.", "paper_url": "http://arxiv.org/abs/2206.00316v1", "pdf_url": "http://arxiv.org/pdf/2206.00316v1", "repo_url": null}, "2206.00303": {"publish_time": "2022-06-01", "title": "Predecessor Features", "author": "Duncan Bailey et.al.", "abstract": "Any reinforcement learning system must be able to identify which past events contributed to observed outcomes, a problem known as credit assignment. A common solution to this problem is to use an eligibility trace to assign credit to recency-weighted set of experienced events. However, in many realistic tasks, the set of recently experienced events are only one of the many possible action events that could have preceded the current outcome. This suggests that reinforcement learning can be made more efficient by allowing credit assignment to any viable preceding state, rather than only those most recently experienced. Accordingly, we propose \"Predecessor Features\", an algorithm that achieves this richer form of credit assignment. By maintaining a representation that approximates the expected sum of past occupancies, our algorithm allows temporal difference (TD) errors to be propagated accurately to a larger number of predecessor states than conventional methods, greatly improving learning speed. Our algorithm can also be naturally extended from tabular state representation to feature representations allowing for increased performance on a wide range of environments. We demonstrate several use cases for Predecessor Features and contrast its performance with other similar approaches.", "paper_url": "http://arxiv.org/abs/2206.00303v1", "pdf_url": "http://arxiv.org/pdf/2206.00303v1", "repo_url": null}, "2206.00273": {"publish_time": "2022-06-01", "title": "A reinforcement learning-based link quality estimation strategy for RPL and its impact on topology management", "author": "Emilio Ancillotti et.al.", "abstract": "Over the last few years, standardisation efforts are consolidating the role of the Routing Protocol for LowPower and Lossy Networks (RPL) as the standard routing protocol for IPv6 based Wireless Sensor Networks (WSNs). Although many core functionalities are well defined, others are left implementation dependent. Among them, the definition of an efficient link quality estimation (LQE) strategy is of paramount importance, as it influences significantly both the quality of the selected network routes and nodes' energy consumption. In this paper, we present RLProbe, a novel strategy for link quality monitoring in RPL, which accurately measures link quality with minimal overhead and energy waste. To achieve this goal, RLProbe leverages both synchronous and asynchronous monitoring schemes to maintain up-to-date information on link quality and to promptly react to sudden topology changes, e.g. due to mobility. Our solution relies on a reinforcement learning model to drive the monitoring procedures in order to minimise the overhead caused by active probing operations. The performance of the proposed solution is assessed by means of simulations and real experiments. Results demonstrated that RLProbe helps in effectively improving packet loss rates, allowing nodes to promptly react to link quality variations as well as to link failures due to node mobility.", "paper_url": "http://arxiv.org/abs/2206.00273v1", "pdf_url": "http://arxiv.org/pdf/2206.00273v1", "repo_url": null}, "2206.00270": {"publish_time": "2022-06-01", "title": "Provably Efficient Lifelong Reinforcement Learning with Linear Function Approximation", "author": "Sanae Amani et.al.", "abstract": "We study lifelong reinforcement learning (RL) in a regret minimization setting of linear contextual Markov decision process (MDP), where the agent needs to learn a multi-task policy while solving a streaming sequence of tasks. We propose an algorithm, called UCB Lifelong Value Distillation (UCBlvd), that provably achieves sublinear regret for any sequence of tasks, which may be adaptively chosen based on the agent's past behaviors. Remarkably, our algorithm uses only sublinear number of planning calls, which means that the agent eventually learns a policy that is near optimal for multiple tasks (seen or unseen) without the need of deliberate planning. A key to this property is a new structural assumption that enables computation sharing across tasks during exploration. Specifically, for $K$ task episodes of horizon $H$, our algorithm has a regret bound $\\tilde{\\mathcal{O}}(\\sqrt{(d^3+d^\\prime d)H^4K})$ based on $\\mathcal{O}(dH\\log(K))$ number of planning calls, where $d$ and $d^\\prime$ are the feature dimensions of the dynamics and rewards, respectively. This theoretical guarantee implies that our algorithm can enable a lifelong learning agent to accumulate experiences and learn to rapidly solve new tasks.", "paper_url": "http://arxiv.org/abs/2206.00270v1", "pdf_url": "http://arxiv.org/pdf/2206.00270v1", "repo_url": null}, "2206.01192": {"publish_time": "2022-06-02", "title": "Uniqueness and Complexity of Inverse MDP Models", "author": "Marcus Hutter et.al.", "abstract": "What is the action sequence aa'a\" that was likely responsible for reaching state s\"' (from state s) in 3 steps? Addressing such questions is important in causal reasoning and in reinforcement learning. Inverse \"MDP\" models p(aa'a\"|ss\"') can be used to answer them. In the traditional \"forward\" view, transition \"matrix\" p(s'|sa) and policy {\\pi}(a|s) uniquely determine \"everything\": the whole dynamics p(as'a's\"a\"...|s), and with it, the action-conditional state process p(s's\"...|saa'a\"), the multi-step inverse models p(aa'a\"...|ss^i), etc. If the latter is our primary concern, a natural question, analogous to the forward case is to which extent 1-step inverse model p(a|ss') plus policy {\\pi}(a|s) determine the multi-step inverse models or even the whole dynamics. In other words, can forward models be inferred from inverse models or even be side-stepped. This work addresses this question and variations thereof, and also whether there are efficient decision/inference algorithms for this.", "paper_url": "http://arxiv.org/abs/2206.01192v1", "pdf_url": "http://arxiv.org/pdf/2206.01192v1", "repo_url": null}, "2206.01162": {"publish_time": "2022-06-02", "title": "Posterior Coreset Construction with Kernelized Stein Discrepancy for Model-Based Reinforcement Learning", "author": "Souradip Chakraborty et.al.", "abstract": "In this work, we propose a novel ${\\bf K}$ernelized ${\\bf S}$tein Discrepancy-based Posterior Sampling for ${\\bf RL}$ algorithm (named $\\texttt{KSRL}$) which extends model-based RL based upon posterior sampling (PSRL) in several ways: we (i) relax the need for any smoothness or Gaussian assumptions, allowing for complex mixture models; (ii) ensure it is applicable to large-scale training by incorporating a compression step such that the posterior consists of a \\emph{Bayesian coreset} of only statistically significant past state-action pairs; and (iii) develop a novel regret analysis of PSRL based upon integral probability metrics, which, under a smoothness condition on the constructed posterior, can be evaluated in closed form as the kernelized Stein discrepancy (KSD). Consequently, we are able to improve the $\\mathcal{O}(H^{3/2}d\\sqrt{T})$ {regret} of PSRL to $\\mathcal{O}(H^{3/2}\\sqrt{T})$, where $d$ is the input dimension, $H$ is the episode length, and $T$ is the total number of episodes experienced, alleviating a linear dependence on $d$ . Moreover, we theoretically establish a trade-off between regret rate with posterior representational complexity via introducing a compression budget parameter $\\epsilon$ based on KSD, and establish a lower bound on the required complexity for consistency of the model. Experimentally, we observe that this approach is competitive with several state of the art RL methodologies, with substantive improvements in computation time. Experimentally, we observe that this approach is competitive with several state of the art RL methodologies, and can achieve up-to $50\\%$ reduction in wall clock time in some continuous control environments.", "paper_url": "http://arxiv.org/abs/2206.01162v1", "pdf_url": "http://arxiv.org/pdf/2206.01162v1", "repo_url": null}, "2206.01134": {"publish_time": "2022-06-02", "title": "Vygotskian Autotelic Artificial Intelligence: Language and Culture Internalization for Human-Like AI", "author": "C\u00e9dric Colas et.al.", "abstract": "Building autonomous artificial agents able to grow open-ended repertoires of skills is one of the fundamental goals of AI. To that end, a promising developmental approach recommends the design of intrinsically motivated agents that learn new skills by generating and pursuing their own goals - autotelic agents. However, existing algorithms still show serious limitations in terms of goal diversity, exploration, generalization or skill composition. This perspective calls for the immersion of autotelic agents into rich socio-cultural worlds. We focus on language especially, and how its structure and content may support the development of new cognitive functions in artificial agents, just like it does in humans. Indeed, most of our skills could not be learned in isolation. Formal education teaches us to reason systematically, books teach us history, and YouTube might teach us how to cook. Crucially, our values, traditions, norms and most of our goals are cultural in essence. This knowledge, and some argue, some of our cognitive functions such as abstraction, compositional imagination or relational thinking, are formed through linguistic and cultural interactions. Inspired by the work of Vygotsky, we suggest the design of Vygotskian autotelic agents able to interact with others and, more importantly, able to internalize these interactions to transform them into cognitive tools supporting the development of new cognitive functions. This perspective paper proposes a new AI paradigm in the quest for artificial lifelong skill discovery. It justifies the approach by uncovering examples of new artificial cognitive functions emerging from interactions between language and embodiment in recent works at the intersection of deep reinforcement learning and natural language processing. Looking forward, it highlights future opportunities and challenges for Vygotskian Autotelic AI research.", "paper_url": "http://arxiv.org/abs/2206.01134v1", "pdf_url": "http://arxiv.org/pdf/2206.01134v1", "repo_url": null}, "2206.01101": {"publish_time": "2022-06-02", "title": "Weakly Supervised Representation Learning with Sparse Perturbations", "author": "Kartik Ahuja et.al.", "abstract": "The theory of representation learning aims to build methods that provably invert the data generating process with minimal domain knowledge or any source of supervision. Most prior approaches require strong distributional assumptions on the latent variables and weak supervision (auxiliary information such as timestamps) to provide provable identification guarantees. In this work, we show that if one has weak supervision from observations generated by sparse perturbations of the latent variables--e.g. images in a reinforcement learning environment where actions move individual sprites--identification is achievable under unknown continuous latent distributions. We show that if the perturbations are applied only on mutually exclusive blocks of latents, we identify the latents up to those blocks. We also show that if these perturbation blocks overlap, we identify latents up to the smallest blocks shared across perturbations. Consequently, if there are blocks that intersect in one latent variable only, then such latents are identified up to permutation and scaling. We propose a natural estimation procedure based on this theory and illustrate it on low-dimensional synthetic and image-based experiments.", "paper_url": "http://arxiv.org/abs/2206.01101v1", "pdf_url": "http://arxiv.org/pdf/2206.01101v1", "repo_url": "https://github.com/ahujak/wsrl"}, "2206.01085": {"publish_time": "2022-06-02", "title": "Incorporating Explicit Uncertainty Estimates into Deep Offline Reinforcement Learning", "author": "David Brandfonbrener et.al.", "abstract": "Most theoretically motivated work in the offline reinforcement learning setting requires precise uncertainty estimates. This requirement restricts the algorithms derived in that work to the tabular and linear settings where such estimates exist. In this work, we develop a novel method for incorporating scalable uncertainty estimates into an offline reinforcement learning algorithm called deep-SPIBB that extends the SPIBB family of algorithms to environments with larger state and action spaces. We use recent innovations in uncertainty estimation from the deep learning community to get more scalable uncertainty estimates to plug into deep-SPIBB. While these uncertainty estimates do not allow for the same theoretical guarantees as in the tabular case, we argue that the SPIBB mechanism for incorporating uncertainty is more robust and flexible than pessimistic approaches that incorporate the uncertainty as a value function penalty. We bear this out empirically, showing that deep-SPIBB outperforms pessimism based approaches with access to the same uncertainty estimates and performs at least on par with a variety of other strong baselines across several environments and datasets.", "paper_url": "http://arxiv.org/abs/2206.01085v1", "pdf_url": "http://arxiv.org/pdf/2206.01085v1", "repo_url": null}, "2206.01704": {"publish_time": "2022-06-03", "title": "KCRL: Krasovskii-Constrained Reinforcement Learning with Guaranteed Stability in Nonlinear Dynamical Systems", "author": "Sahin Lale et.al.", "abstract": "Learning a dynamical system requires stabilizing the unknown dynamics to avoid state blow-ups. However, current reinforcement learning (RL) methods lack stabilization guarantees, which limits their applicability for the control of safety-critical systems. We propose a model-based RL framework with formal stability guarantees, Krasovskii Constrained RL (KCRL), that adopts Krasovskii's family of Lyapunov functions as a stability constraint. The proposed method learns the system dynamics up to a confidence interval using feature representation, e.g. Random Fourier Features. It then solves a constrained policy optimization problem with a stability constraint based on Krasovskii's method using a primal-dual approach to recover a stabilizing policy. We show that KCRL is guaranteed to learn a stabilizing policy in a finite number of interactions with the underlying unknown system. We also derive the sample complexity upper bound for stabilization of unknown nonlinear dynamical systems via the KCRL framework.", "paper_url": "http://arxiv.org/abs/2206.01704v1", "pdf_url": "http://arxiv.org/pdf/2206.01704v1", "repo_url": null}, "2206.01683": {"publish_time": "2022-06-03", "title": "FishGym: A High-Performance Physics-based Simulation Framework for Underwater Robot Learning", "author": "Wenji Liu et.al.", "abstract": "Bionic underwater robots have demonstrated their superiority in many applications. Yet, training their intelligence for a variety of tasks that mimic the behavior of underwater creatures poses a number of challenges in practice, mainly due to lack of a large amount of available training data as well as the high cost in real physical environment. Alternatively, simulation has been considered as a viable and important tool for acquiring datasets in different environments, but it mostly targeted rigid and soft body systems. There is currently dearth of work for more complex fluid systems interacting with immersed solids that can be efficiently and accurately simulated for robot training purposes. In this paper, we propose a new platform called \"FishGym\", which can be used to train fish-like underwater robots. The framework consists of a robotic fish modeling module using articulated body with skinning, a GPU-based high-performance localized two-way coupled fluid-structure interaction simulation module that handles both finite and infinitely large domains, as well as a reinforcement learning module. We leveraged existing training methods with adaptations to underwater fish-like robots and obtained learned control policies for multiple benchmark tasks. The training results are demonstrated with reasonable motion trajectories, with comparisons and analyses to empirical models as well as known real fish swimming behaviors to highlight the advantages of the proposed platform.", "paper_url": "http://arxiv.org/abs/2206.01683v1", "pdf_url": "http://arxiv.org/pdf/2206.01683v1", "repo_url": null}, "2206.01663": {"publish_time": "2022-06-03", "title": "Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep Reinforcement Learning", "author": "Jiaju Qi et.al.", "abstract": "Nowadays, the application of microgrids (MG) with renewable energy is becoming more and more extensive, which creates a strong need for dynamic energy management. In this paper, deep reinforcement learning (DRL) is applied to learn an optimal policy for making joint energy dispatch (ED) and unit commitment (UC) decisions in an isolated MG, with the aim for reducing the total power generation cost on the premise of ensuring the supply-demand balance. In order to overcome the challenge of discrete-continuous hybrid action space due to joint ED and UC, we propose a DRL algorithm, i.e., the hybrid action finite-horizon DDPG (HAFH-DDPG), that seamlessly integrates two classical DRL algorithms, i.e., deep Q-network (DQN) and deep deterministic policy gradient (DDPG), based on a finite-horizon dynamic programming (DP) framework. Moreover, a diesel generator (DG) selection strategy is presented to support a simplified action space for reducing the computation complexity of this algorithm. Finally, the effectiveness of our proposed algorithm is verified through comparison with several baseline algorithms by experiments with real-world data set.", "paper_url": "http://arxiv.org/abs/2206.01663v1", "pdf_url": "http://arxiv.org/pdf/2206.01663v1", "repo_url": null}, "2206.01634": {"publish_time": "2022-06-03", "title": "Reinforcement Learning with Neural Radiance Fields", "author": "Danny Driess et.al.", "abstract": "It is a long-standing problem to find effective representations for training reinforcement learning (RL) agents. This paper demonstrates that learning state representations with supervision from Neural Radiance Fields (NeRFs) can improve the performance of RL compared to other learned representations or even low-dimensional, hand-engineered state information. Specifically, we propose to train an encoder that maps multiple image observations to a latent space describing the objects in the scene. The decoder built from a latent-conditioned NeRF serves as the supervision signal to learn the latent space. An RL algorithm then operates on the learned latent space as its state representation. We call this NeRF-RL. Our experiments indicate that NeRF as supervision leads to a latent space better suited for the downstream RL tasks involving robotic object manipulations like hanging mugs on hooks, pushing objects, or opening doors. Video: https://dannydriess.github.io/nerf-rl", "paper_url": "http://arxiv.org/abs/2206.01634v1", "pdf_url": "http://arxiv.org/pdf/2206.01634v1", "repo_url": null}, "2206.01626": {"publish_time": "2022-06-03", "title": "Beyond Tabula Rasa: Reincarnating Reinforcement Learning", "author": "Rishabh Agarwal et.al.", "abstract": "Learning tabula rasa, that is without any prior knowledge, is the prevalent workflow in reinforcement learning (RL) research. However, RL systems, when applied to large-scale settings, rarely operate tabula rasa. Such large-scale systems undergo multiple design or algorithmic changes during their development cycle and use ad hoc approaches for incorporating these changes without re-training from scratch, which would have been prohibitively expensive. Additionally, the inefficiency of deep RL typically excludes researchers without access to industrial-scale resources from tackling computationally-demanding problems. To address these issues, we present reincarnating RL as an alternative workflow, where prior computational work (e.g., learned policies) is reused or transferred between design iterations of an RL agent, or from one RL agent to another. As a step towards enabling reincarnating RL from any agent to any other agent, we focus on the specific setting of efficiently transferring an existing sub-optimal policy to a standalone value-based RL agent. We find that existing approaches fail in this setting and propose a simple algorithm to address their limitations. Equipped with this algorithm, we demonstrate reincarnating RL's gains over tabula rasa RL on Atari 2600 games, a challenging locomotion task, and the real-world problem of navigating stratospheric balloons. Overall, this work argues for an alternative approach to RL research, which we believe could significantly improve real-world RL adoption and help democratize it further.", "paper_url": "http://arxiv.org/abs/2206.01626v1", "pdf_url": "http://arxiv.org/pdf/2206.01626v1", "repo_url": null}, "2206.02733": {"publish_time": "2022-06-06", "title": "Deep Reinforcement Learning for Cybersecurity Threat Detection and Protection: A Review", "author": "Mohit Sewak et.al.", "abstract": "The cybersecurity threat landscape has lately become overly complex. Threat actors leverage weaknesses in the network and endpoint security in a very coordinated manner to perpetuate sophisticated attacks that could bring down the entire network and many critical hosts in the network. Increasingly advanced deep and machine learning-based solutions have been used in threat detection and protection. The application of these techniques has been reviewed well in the scientific literature. Deep Reinforcement Learning has shown great promise in developing AI-based solutions for areas that had earlier required advanced human cognizance. Different techniques and algorithms under deep reinforcement learning have shown great promise in applications ranging from games to industrial processes, where it is claimed to augment systems with general AI capabilities. These algorithms have recently also been used in cybersecurity, especially in threat detection and endpoint protection, where these are showing state-of-the-art results. Unlike supervised machines and deep learning, deep reinforcement learning is used in more diverse ways and is empowering many innovative applications in the threat defense landscape. However, there does not exist any comprehensive review of these unique applications and accomplishments. Therefore, in this paper, we intend to fill this gap and provide a comprehensive review of the different applications of deep reinforcement learning in cybersecurity threat detection and protection.", "paper_url": "http://arxiv.org/abs/2206.02733v1", "pdf_url": "http://arxiv.org/pdf/2206.02733v1", "repo_url": null}, "2206.02679": {"publish_time": "2022-06-06", "title": "Real2Sim or Sim2Real: Robotics Visual Insertion using Deep Reinforcement Learning and Real2Sim Policy Adaptation", "author": "Yiwen Chen et.al.", "abstract": "Reinforcement learning has shown a wide usage in robotics tasks, such as insertion and grasping. However, without a practical sim2real strategy, the policy trained in simulation could fail on the real task. There are also wide researches in the sim2real strategies, but most of those methods rely on heavy image rendering, domain randomization training, or tuning. In this work, we solve the insertion task using a pure visual reinforcement learning solution with minimum infrastructure requirement. We also propose a novel sim2real strategy, Real2Sim, which provides a novel and easier solution in policy adaptation. We discuss the advantage of Real2Sim compared with Sim2Real.", "paper_url": "http://arxiv.org/abs/2206.02679v1", "pdf_url": "http://arxiv.org/pdf/2206.02679v1", "repo_url": null}, "2206.02678": {"publish_time": "2022-06-06", "title": "Risk-Sensitive Reinforcement Learning: Iterated CVaR and the Worst Path", "author": "Yihan Du et.al.", "abstract": "In this paper, we study a novel episodic risk-sensitive Reinforcement Learning (RL) problem, named Iterated CVaR RL, where the objective is to maximize the tail of the reward-to-go at each step. Different from existing risk-aware RL formulations, Iterated CVaR RL focuses on safety-at-all-time, by enabling the agent to tightly control the risk of getting into catastrophic situations at each stage, and is applicable to important risk-sensitive tasks that demand strong safety guarantees throughout the decision process, such as autonomous driving, clinical treatment planning and robotics. We investigate Iterated CVaR RL with two performance metrics, i.e., Regret Minimization and Best Policy Identification. For both metrics, we design efficient algorithms ICVaR-RM and ICVaR-BPI, respectively, and provide matching upper and lower bounds with respect to the number of episodes $K$. We also investigate an interesting limiting case of Iterated CVaR RL, called Worst Path RL, where the objective becomes to maximize the minimum possible cumulative reward, and propose an efficient algorithm with constant upper and lower bounds. Finally, the techniques we develop for bounding the change of CVaR due to the value function shift and decomposing the regret via a distorted visitation distribution are novel and can find applications in other risk-sensitive online learning problems.", "paper_url": "http://arxiv.org/abs/2206.02678v1", "pdf_url": "http://arxiv.org/pdf/2206.02678v1", "repo_url": null}, "2206.02675": {"publish_time": "2022-06-06", "title": "Enhancing Safe Exploration Using Safety State Augmentation", "author": "Aivar Sootla et.al.", "abstract": "Safe exploration is a challenging and important problem in model-free reinforcement learning (RL). Often the safety cost is sparse and unknown, which unavoidably leads to constraint violations -- a phenomenon ideally to be avoided in safety-critical applications. We tackle this problem by augmenting the state-space with a safety state, which is nonnegative if and only if the constraint is satisfied. The value of this state also serves as a distance toward constraint violation, while its initial value indicates the available safety budget. This idea allows us to derive policies for scheduling the safety budget during training. We call our approach Simmer (Safe policy IMproveMEnt for RL) to reflect the careful nature of these schedules. We apply this idea to two safe RL problems: RL with constraints imposed on an average cost, and RL with constraints imposed on a cost with probability one. Our experiments suggest that simmering a safe algorithm can improve safety during training for both settings. We further show that Simmer can stabilize training and improve the performance of safe RL with average constraints.", "paper_url": "http://arxiv.org/abs/2206.02675v1", "pdf_url": "http://arxiv.org/pdf/2206.02675v1", "repo_url": null}, "2206.02670": {"publish_time": "2022-06-06", "title": "Robust Adversarial Attacks Detection based on Explainable Deep Reinforcement Learning For UAV Guidance and Planning", "author": "Thomas Hickling et.al.", "abstract": "The danger of adversarial attacks to unprotected Uncrewed Aerial Vehicle (UAV) agents operating in public is growing. Adopting AI-based techniques and more specifically Deep Learning (DL) approaches to control and guide these UAVs can be beneficial in terms of performance but add more concerns regarding the safety of those techniques and their vulnerability against adversarial attacks causing the chances of collisions going up as the agent becomes confused. This paper proposes an innovative approach based on the explainability of DL methods to build an efficient detector that will protect these DL schemes and thus the UAVs adopting them from potential attacks. The agent is adopting a Deep Reinforcement Learning (DRL) scheme for guidance and planning. It is formed and trained with a Deep Deterministic Policy Gradient (DDPG) with Prioritised Experience Replay (PER) DRL scheme that utilises Artificial Potential Field (APF) to improve training times and obstacle avoidance performance. The adversarial attacks are generated by Fast Gradient Sign Method (FGSM) and Basic Iterative Method (BIM) algorithms and reduced obstacle course completion rates from 80\\% to 35\\%. A Realistic Synthetic environment for UAV explainable DRL based planning and guidance including obstacles and adversarial attacks is built. Two adversarial attack detectors are proposed. The first one adopts a Convolutional Neural Network (CNN) architecture and achieves an accuracy in detection of 80\\%. The second detector is developed based on a Long Short Term Memory (LSTM) network and achieves an accuracy of 91\\% with much faster computing times when compared to the CNN based detector.", "paper_url": "http://arxiv.org/abs/2206.02670v1", "pdf_url": "http://arxiv.org/pdf/2206.02670v1", "repo_url": null}, "2206.03467": {"publish_time": "2022-06-07", "title": "Discrete State-Action Abstraction via the Successor Representation", "author": "Amnon Attali et.al.", "abstract": "When reinforcement learning is applied with sparse rewards, agents must spend a prohibitively long time exploring the unknown environment without any learning signal. Abstraction is one approach that provides the agent with an intrinsic reward for transitioning in a latent space. Prior work focuses on dense continuous latent spaces, or requires the user to manually provide the representation. Our approach is the first for automatically learning a discrete abstraction of the underlying environment. Moreover, our method works on arbitrary input spaces, using an end-to-end trainable regularized successor representation model. For transitions between abstract states, we train a set of temporally extended actions in the form of options, i.e., an action abstraction. Our proposed algorithm, Discrete State-Action Abstraction (DSAA), iteratively swaps between training these options and using them to efficiently explore more of the environment to improve the state abstraction. As a result, our model is not only useful for transfer learning but also in the online learning setting. We empirically show that our agent is able to explore the environment and solve provided tasks more efficiently than baseline reinforcement learning algorithms. Our code is publicly available at \\url{https://github.com/amnonattali/dsaa}.", "paper_url": "http://arxiv.org/abs/2206.03467v1", "pdf_url": "http://arxiv.org/pdf/2206.03467v1", "repo_url": "https://github.com/amnonattali/dsaa"}, "2206.03446": {"publish_time": "2022-06-07", "title": "Learning in Observable POMDPs, without Computationally Intractable Oracles", "author": "Noah Golowich et.al.", "abstract": "Much of reinforcement learning theory is built on top of oracles that are computationally hard to implement. Specifically for learning near-optimal policies in Partially Observable Markov Decision Processes (POMDPs), existing algorithms either need to make strong assumptions about the model dynamics (e.g. deterministic transitions) or assume access to an oracle for solving a hard optimistic planning or estimation problem as a subroutine. In this work we develop the first oracle-free learning algorithm for POMDPs under reasonable assumptions. Specifically, we give a quasipolynomial-time end-to-end algorithm for learning in \"observable\" POMDPs, where observability is the assumption that well-separated distributions over states induce well-separated distributions over observations. Our techniques circumvent the more traditional approach of using the principle of optimism under uncertainty to promote exploration, and instead give a novel application of barycentric spanners to constructing policy covers.", "paper_url": "http://arxiv.org/abs/2206.03446v1", "pdf_url": "http://arxiv.org/pdf/2206.03446v1", "repo_url": null}, "2206.03401": {"publish_time": "2022-06-07", "title": "MIX-MAB: Reinforcement Learning-based Resource Allocation Algorithm for LoRaWAN", "author": "Farzad Azizi et.al.", "abstract": "This paper focuses on improving the resource allocation algorithm in terms of packet delivery ratio (PDR), i.e., the number of successfully received packets sent by end devices (EDs) in a long-range wide-area network (LoRaWAN). Setting the transmission parameters significantly affects the PDR. Employing reinforcement learning (RL), we propose a resource allocation algorithm that enables the EDs to configure their transmission parameters in a distributed manner. We model the resource allocation problem as a multi-armed bandit (MAB) and then address it by proposing a two-phase algorithm named MIX-MAB, which consists of the exponential weights for exploration and exploitation (EXP3) and successive elimination (SE) algorithms. We evaluate the MIX-MAB performance through simulation results and compare it with other existing approaches. Numerical results show that the proposed solution performs better than the existing schemes in terms of convergence time and PDR.", "paper_url": "http://arxiv.org/abs/2206.03401v1", "pdf_url": "http://arxiv.org/pdf/2206.03401v1", "repo_url": null}, "2206.03383": {"publish_time": "2022-06-07", "title": "On the Role of Discount Factor in Offline Reinforcement Learning", "author": "Hao Hu et.al.", "abstract": "Offline reinforcement learning (RL) enables effective learning from previously collected data without exploration, which shows great promise in real-world applications when exploration is expensive or even infeasible. The discount factor, $\\gamma$, plays a vital role in improving online RL sample efficiency and estimation accuracy, but the role of the discount factor in offline RL is not well explored. This paper examines two distinct effects of $\\gamma$ in offline RL with theoretical analysis, namely the regularization effect and the pessimism effect. On the one hand, $\\gamma$ is a regulator to trade-off optimality with sample efficiency upon existing offline techniques. On the other hand, lower guidance $\\gamma$ can also be seen as a way of pessimism where we optimize the policy's performance in the worst possible models. We empirically verify the above theoretical observation with tabular MDPs and standard D4RL tasks. The results show that the discount factor plays an essential role in the performance of offline RL algorithms, both under small data regimes upon existing offline methods and in large data regimes without other conservatisms.", "paper_url": "http://arxiv.org/abs/2206.03383v1", "pdf_url": "http://arxiv.org/pdf/2206.03383v1", "repo_url": null}, "2206.03378": {"publish_time": "2022-06-07", "title": "Imitating Past Successes can be Very Suboptimal", "author": "Benjamin Eysenbach et.al.", "abstract": "Prior work has proposed a simple strategy for reinforcement learning (RL): label experience with the outcomes achieved in that experience, and then imitate the relabeled experience. These outcome-conditioned imitation learning methods are appealing because of their simplicity, strong performance, and close ties with supervised learning. However, it remains unclear how these methods relate to the standard RL objective, reward maximization. In this paper, we prove that existing outcome-conditioned imitation learning methods do not necessarily improve the policy; rather, in some settings they can decrease the expected reward. Nonetheless, we show that a simple modification results in a method that does guarantee policy improvement, under some assumptions. Our aim is not to develop an entirely new method, but rather to explain how a variant of outcome-conditioned imitation learning can be used to maximize rewards.", "paper_url": "http://arxiv.org/abs/2206.03378v1", "pdf_url": "http://arxiv.org/pdf/2206.03378v1", "repo_url": null}, "2206.04044": {"publish_time": "2022-06-08", "title": "Model-Based Reinforcement Learning Is Minimax-Optimal for Offline Zero-Sum Markov Games", "author": "Yuling Yan et.al.", "abstract": "This paper makes progress towards learning Nash equilibria in two-player zero-sum Markov games from offline data. Specifically, consider a $\\gamma$-discounted infinite-horizon Markov game with $S$ states, where the max-player has $A$ actions and the min-player has $B$ actions. We propose a pessimistic model-based algorithm with Bernstein-style lower confidence bounds -- called VI-LCB-Game -- that provably finds an $\\varepsilon$-approximate Nash equilibrium with a sample complexity no larger than $\\frac{C_{\\mathsf{clipped}}^{\\star}S(A+B)}{(1-\\gamma)^{3}\\varepsilon^{2}}$ (up to some log factor). Here, $C_{\\mathsf{clipped}}^{\\star}$ is some unilateral clipped concentrability coefficient that reflects the coverage and distribution shift of the available data (vis-\\`a-vis the target data), and the target accuracy $\\varepsilon$ can be any value within $\\big(0,\\frac{1}{1-\\gamma}\\big]$. Our sample complexity bound strengthens prior art by a factor of $\\min\\{A,B\\}$, achieving minimax optimality for the entire $\\varepsilon$-range. An appealing feature of our result lies in algorithmic simplicity, which reveals the unnecessity of variance reduction and sample splitting in achieving sample optimality.", "paper_url": "http://arxiv.org/abs/2206.04044v1", "pdf_url": "http://arxiv.org/pdf/2206.04044v1", "repo_url": null}, "2206.03944": {"publish_time": "2022-06-08", "title": "Designing Reinforcement Learning Algorithms for Digital Interventions: Pre-implementation Guidelines", "author": "Anna L. Trella et.al.", "abstract": "Online reinforcement learning (RL) algorithms are increasingly used to personalize digital interventions in the fields of mobile health and online education. Common challenges in designing and testing an RL algorithm in these settings include ensuring the RL algorithm can learn and run stably under real-time constraints, and accounting for the complexity of the environment, e.g., a lack of accurate mechanistic models for the user dynamics. To guide how one can tackle these challenges, we extend the PCS (Predictability, Computability, Stability) framework, a data science framework that incorporates best practices from machine learning and statistics in supervised learning (Yu and Kumbier, 2020), to the design of RL algorithms for the digital interventions setting. Further, we provide guidelines on how to design simulation environments, a crucial tool for evaluating RL candidate algorithms using the PCS framework. We illustrate the use of the PCS framework for designing an RL algorithm for Oralytics, a mobile health study aiming to improve users' tooth-brushing behaviors through the personalized delivery of intervention messages. Oralytics will go into the field in late 2022.", "paper_url": "http://arxiv.org/abs/2206.03944v1", "pdf_url": "http://arxiv.org/pdf/2206.03944v1", "repo_url": "https://github.com/statisticalreinforcementlearninglab/pcs-for-rl"}, "2206.03934": {"publish_time": "2022-06-08", "title": "A Study of Continual Learning Methods for Q-Learning", "author": "Benedikt Bagus et.al.", "abstract": "We present an empirical study on the use of continual learning (CL) methods in a reinforcement learning (RL) scenario, which, to the best of our knowledge, has not been described before. CL is a very active recent research topic concerned with machine learning under non-stationary data distributions. Although this naturally applies to RL, the use of dedicated CL methods is still uncommon. This may be due to the fact that CL methods often assume a decomposition of CL problems into disjoint sub-tasks of stationary distribution, that the onset of these sub-tasks is known, and that sub-tasks are non-contradictory. In this study, we perform an empirical comparison of selected CL methods in a RL problem where a physically simulated robot must follow a racetrack by vision. In order to make CL methods applicable, we restrict the RL setting and introduce non-conflicting subtasks of known onset, which are however not disjoint and whose distribution, from the learner's point of view, is still non-stationary. Our results show that dedicated CL methods can significantly improve learning when compared to the baseline technique of \"experience replay\".", "paper_url": "http://arxiv.org/abs/2206.03934v1", "pdf_url": "http://arxiv.org/pdf/2206.03934v1", "repo_url": null}, "2206.03931": {"publish_time": "2022-06-08", "title": "Few-shot Prompting Toward Controllable Response Generation", "author": "Hsuan Su et.al.", "abstract": "Much literature has shown that prompt-based learning is an efficient method to make use of the large pre-trained language model. Recent works also exhibit the possibility of steering a chatbot's output by plugging in an appropriate prompt. Gradient-based methods are often used to perturb the prompts. However, some language models are not even available to the public. In this work, we first explored the combination of prompting and reinforcement learning (RL) to steer models' generation without accessing any of the models' parameters. Second, to reduce the training effort and enhance the generalizability to the unseen task, we apply multi-task learning to make the model learn to generalize to new tasks better. The experiment results show that our proposed method can successfully control several state-of-the-art (SOTA) dialogue models without accessing their parameters. Furthermore, the model demonstrates the strong ability to quickly adapt to an unseen task in fewer steps than the baseline model.", "paper_url": "http://arxiv.org/abs/2206.03931v1", "pdf_url": "http://arxiv.org/pdf/2206.03931v1", "repo_url": null}, "2206.03846": {"publish_time": "2022-06-08", "title": "Sim2real for Reinforcement Learning Driven Next Generation Networks", "author": "Peizheng Li et.al.", "abstract": "The next generation of networks will actively embrace artificial intelligence (AI) and machine learning (ML) technologies for automation networks and optimal network operation strategies. The emerging network structure represented by Open RAN (O-RAN) conforms to this trend, and the radio intelligent controller (RIC) at the centre of its specification serves as an ML applications host. Various ML models, especially Reinforcement Learning (RL) models, are regarded as the key to solving RAN-related multi-objective optimization problems. However, it should be recognized that most of the current RL successes are confined to abstract and simplified simulation environments, which may not directly translate to high performance in complex real environments. One of the main reasons is the modelling gap between the simulation and the real environment, which could make the RL agent trained by simulation ill-equipped for the real environment. This issue is termed as the sim2real gap. This article brings to the fore the sim2real challenge within the context of O-RAN. Specifically, it emphasizes the characteristics, and benefits that the digital twins (DT) could have as a place for model development and verification. Several use cases are presented to exemplify and demonstrate failure modes of the simulations trained RL model in real environments. The effectiveness of DT in assisting the development of RL algorithms is discussed. Then the current state of the art learning-based methods commonly used to overcome the sim2real challenge are presented. Finally, the development and deployment concerns for the RL applications realisation in O-RAN are discussed from the view of the potential issues like data interaction, environment bottlenecks, and algorithm design.", "paper_url": "http://arxiv.org/abs/2206.03846v1", "pdf_url": "http://arxiv.org/pdf/2206.03846v1", "repo_url": null}, "2206.04672": {"publish_time": "2022-06-09", "title": "Overcoming the Spectral Bias of Neural Value Approximation", "author": "Ge Yang et.al.", "abstract": "Value approximation using deep neural networks is at the heart of off-policy deep reinforcement learning, and is often the primary module that provides learning signals to the rest of the algorithm. While multi-layer perceptron networks are universal function approximators, recent works in neural kernel regression suggest the presence of a spectral bias, where fitting high-frequency components of the value function requires exponentially more gradient update steps than the low-frequency ones. In this work, we re-examine off-policy reinforcement learning through the lens of kernel regression and propose to overcome such bias via a composite neural tangent kernel. With just a single line-change, our approach, the Fourier feature networks (FFN) produce state-of-the-art performance on challenging continuous control domains with only a fraction of the compute. Faster convergence and better off-policy stability also make it possible to remove the target network without suffering catastrophic divergences, which further reduces TD}(0)'s estimation bias on a few tasks.", "paper_url": "http://arxiv.org/abs/2206.04672v1", "pdf_url": "http://arxiv.org/pdf/2206.04672v1", "repo_url": null}, "2206.04640": {"publish_time": "2022-06-09", "title": "Regret Bounds for Information-Directed Reinforcement Learning", "author": "Botao Hao et.al.", "abstract": "Information-directed sampling (IDS) has revealed its potential as a data-efficient algorithm for reinforcement learning (RL). However, theoretical understanding of IDS for Markov Decision Processes (MDPs) is still limited. We develop novel information-theoretic tools to bound the information ratio and cumulative information gain about the learning target. Our theoretical results shed light on the importance of choosing the learning target such that the practitioners can balance the computation and regret bounds. As a consequence, we derive prior-free Bayesian regret bounds for vanilla-IDS which learns the whole environment under tabular finite-horizon MDPs. In addition, we propose a computationally-efficient regularized-IDS that maximizes an additive form rather than the ratio form and show that it enjoys the same regret bound as vanilla-IDS. With the aid of rate-distortion theory, we improve the regret bound by learning a surrogate, less informative environment. Furthermore, we extend our analysis to linear MDPs and prove similar regret bounds for Thompson sampling as a by-product.", "paper_url": "http://arxiv.org/abs/2206.04640v1", "pdf_url": "http://arxiv.org/pdf/2206.04640v1", "repo_url": null}, "2206.04551": {"publish_time": "2022-06-09", "title": "A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning", "author": "Jixian Guo et.al.", "abstract": "The generalization of model-based reinforcement learning (MBRL) methods to environments with unseen transition dynamics is an important yet challenging problem. Existing methods try to extract environment-specified information $Z$ from past transition segments to make the dynamics prediction model generalizable to different dynamics. However, because environments are not labelled, the extracted information inevitably contains redundant information unrelated to the dynamics in transition segments and thus fails to maintain a crucial property of $Z$: $Z$ should be similar in the same environment and dissimilar in different ones. As a result, the learned dynamics prediction function will deviate from the true one, which undermines the generalization ability. To tackle this problem, we introduce an interventional prediction module to estimate the probability of two estimated $\\hat{z}_i, \\hat{z}_j$ belonging to the same environment. Furthermore, by utilizing the $Z$'s invariance within a single environment, a relational head is proposed to enforce the similarity between $\\hat{{Z}}$ from the same environment. As a result, the redundant information will be reduced in $\\hat{Z}$. We empirically show that $\\hat{{Z}}$ estimated by our method enjoy less redundant information than previous methods, and such $\\hat{{Z}}$ can significantly reduce dynamics prediction errors and improve the performance of model-based RL methods on zero-shot new environments with unseen dynamics. The codes of this method are available at \\url{https://github.com/CR-Gjx/RIA}.", "paper_url": "http://arxiv.org/abs/2206.04551v1", "pdf_url": "http://arxiv.org/pdf/2206.04551v1", "repo_url": "https://github.com/cr-gjx/ria"}, "2206.04547": {"publish_time": "2022-06-09", "title": "Value iteration is optic composition", "author": "Jules Hedges et.al.", "abstract": "Dynamic programming is a class of algorithms used to compute optimal control policies for Markov decision processes. Dynamic programming is ubiquitous in control theory, and is also the foundation of reinforcement learning. In this paper, we show that value improvement, one of the main steps of dynamic programming, can be naturally seen as composition in a category of optics, and intuitively, the optimal value function is the limit of a chain of optic compositions. We illustrate this with three classic examples: the gridworld, the inverted pendulum and the savings problem. This is a first step towards a complete account of reinforcement learning in terms of parametrised optics.", "paper_url": "http://arxiv.org/abs/2206.04547v1", "pdf_url": "http://arxiv.org/pdf/2206.04547v1", "repo_url": null}, "2206.04546": {"publish_time": "2022-06-09", "title": "Pragmatically Learning from Pedagogical Demonstrations in Multi-Goal Environments", "author": "Hugo Caselles-Dupr\u00e9 et.al.", "abstract": "Learning from demonstration methods usually leverage close to optimal demonstrations to accelerate training. By contrast, when demonstrating a task, human teachers deviate from optimal demonstrations and pedagogically modify their behavior by giving demonstrations that best disambiguate the goal they want to demonstrate. Analogously, human learners excel at pragmatically inferring the intent of the teacher, facilitating communication between the two agents. These mechanisms are critical in the few demonstrations regime, where inferring the goal is more difficult. In this paper, we implement pedagogy and pragmatism mechanisms by leveraging a Bayesian model of goal inference from demonstrations. We highlight the benefits of this model in multi-goal teacher-learner setups with two artificial agents that learn with goal-conditioned Reinforcement Learning. We show that combining a pedagogical teacher and a pragmatic learner results in faster learning and reduced goal ambiguity over standard learning from demonstrations, especially in the few demonstrations regime.", "paper_url": "http://arxiv.org/abs/2206.04546v1", "pdf_url": "http://arxiv.org/pdf/2206.04546v1", "repo_url": null}, "2206.05266": {"publish_time": "2022-06-10", "title": "Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?", "author": "Xiang Li et.al.", "abstract": "We investigate whether self-supervised learning (SSL) can improve online reinforcement learning (RL) from pixels. We extend the contrastive reinforcement learning framework (e.g., CURL) that jointly optimizes SSL and RL losses and conduct an extensive amount of experiments with various self-supervised losses. Our observations suggest that the existing SSL framework for RL fails to bring meaningful improvement over the baselines only taking advantage of image augmentation when the same amount of data and augmentation is used. We further perform an evolutionary search to find the optimal combination of multiple self-supervised losses for RL, but find that even such a loss combination fails to meaningfully outperform the methods that only utilize carefully designed image augmentations. Often, the use of self-supervised losses under the existing framework lowered RL performances. We evaluate the approach in multiple different environments including a real-world robot environment and confirm that no single self-supervised loss or image augmentation method can dominate all environments and that the current framework for joint optimization of SSL and RL is limited. Finally, we empirically investigate the pretraining framework for SSL + RL and the properties of representations learned with different approaches.", "paper_url": "http://arxiv.org/abs/2206.05266v1", "pdf_url": "http://arxiv.org/pdf/2206.05266v1", "repo_url": null}, "2206.05240": {"publish_time": "2022-06-10", "title": "ROI Constrained Bidding via Curriculum-Guided Bayesian Reinforcement Learning", "author": "Haozhe Wang et.al.", "abstract": "Real-Time Bidding (RTB) is an important mechanism in modern online advertising systems. Advertisers employ bidding strategies in RTB to optimize their advertising effects subject to various financial requirements, among which a widely adopted one is the return-on-investment (ROI) constraint. ROIs change non-monotonically during the sequential bidding process, usually presenting a see-saw effect between constraint satisfaction and objective optimization. Existing solutions to the constraint-objective trade-off are typically established in static or mildly changing markets. However, these methods fail significantly in non-stationary advertising markets due to their inability to adapt to varying dynamics and partial observability. In this work, we specialize in ROI-Constrained Bidding in non-stationary markets. Based on a Partially Observable Constrained Markov Decision Process, we propose the first hard barrier solution to accommodate non-monotonic constraints. Our method exploits a parameter-free indicator-augmented reward function and develops a Curriculum-Guided Bayesian Reinforcement Learning (CBRL) framework to adaptively control the constraint-objective trade-off in non-stationary advertising markets. Extensive experiments on a large-scale industrial dataset with two problem settings reveal that CBRL generalizes well in both in-distribution and out-of-distribution data regimes, and enjoys outstanding stability.", "paper_url": "http://arxiv.org/abs/2206.05240v1", "pdf_url": "http://arxiv.org/pdf/2206.05240v1", "repo_url": null}, "2206.05200": {"publish_time": "2022-06-10", "title": "Dynamic mean field programming", "author": "George Stamatescu et.al.", "abstract": "A dynamic mean field theory is developed for model based Bayesian reinforcement learning in the large state space limit. In an analogy with the statistical physics of disordered systems, the transition probabilities are interpreted as couplings, and value functions as deterministic spins, and thus the sampled transition probabilities are considered to be quenched random variables. The results reveal that, under standard assumptions, the posterior over Q-values is asymptotically independent and Gaussian across state-action pairs, for infinite horizon problems. The finite horizon case exhibits the same behaviour for all state-actions pairs at each time but has an additional correlation across time, for each state-action pair. The results also hold for policy evaluation. The Gaussian statistics can be computed from a set of coupled mean field equations derived from the Bellman equation, which we call dynamic mean field programming (DMFP). For Q-value iteration, approximate equations are obtained by appealing to extreme value theory, and closed form expressions are found in the independent and identically distributed case. The Lyapunov stability of these closed form equations is studied.", "paper_url": "http://arxiv.org/abs/2206.05200v1", "pdf_url": "http://arxiv.org/pdf/2206.05200v1", "repo_url": null}, "2206.05165": {"publish_time": "2022-06-10", "title": "Multifidelity Reinforcement Learning with Control Variates", "author": "Sami Khairy et.al.", "abstract": "In many computational science and engineering applications, the output of a system of interest corresponding to a given input can be queried at different levels of fidelity with different costs. Typically, low-fidelity data is cheap and abundant, while high-fidelity data is expensive and scarce. In this work we study the reinforcement learning (RL) problem in the presence of multiple environments with different levels of fidelity for a given control task. We focus on improving the RL agent's performance with multifidelity data. Specifically, a multifidelity estimator that exploits the cross-correlations between the low- and high-fidelity returns is proposed to reduce the variance in the estimation of the state-action value function. The proposed estimator, which is based on the method of control variates, is used to design a multifidelity Monte Carlo RL (MFMCRL) algorithm that improves the learning of the agent in the high-fidelity environment. The impacts of variance reduction on policy evaluation and policy improvement are theoretically analyzed by using probability bounds. Our theoretical analysis and numerical experiments demonstrate that for a finite budget of high-fidelity data samples, our proposed MFMCRL agent attains superior performance compared with that of a standard RL agent that uses only the high-fidelity environment data for learning the optimal policy.", "paper_url": "http://arxiv.org/abs/2206.05165v1", "pdf_url": "http://arxiv.org/pdf/2206.05165v1", "repo_url": null}, "2206.05108": {"publish_time": "2022-06-10", "title": "Deep Multi-Agent Reinforcement Learning with Hybrid Action Spaces based on Maximum Entropy", "author": "Hongzhi Hua et.al.", "abstract": "Multi-agent deep reinforcement learning has been applied to address a variety of complex problems with either discrete or continuous action spaces and achieved great success. However, most real-world environments cannot be described by only discrete action spaces or only continuous action spaces. And there are few works having ever utilized deep reinforcement learning (drl) to multi-agent problems with hybrid action spaces. Therefore, we propose a novel algorithm: Deep Multi-Agent Hybrid Soft Actor-Critic (MAHSAC) to fill this gap. This algorithm follows the centralized training but decentralized execution (CTDE) paradigm, and extend the Soft Actor-Critic algorithm (SAC) to handle hybrid action space problems in Multi-Agent environments based on maximum entropy. Our experiences are running on an easy multi-agent particle world with a continuous observation and discrete action space, along with some basic simulated physics. The experimental results show that MAHSAC has good performance in training speed, stability, and anti-interference ability. At the same time, it outperforms existing independent deep hybrid learning method in cooperative scenarios and competitive scenarios.", "paper_url": "http://arxiv.org/abs/2206.05108v1", "pdf_url": "http://arxiv.org/pdf/2206.05108v1", "repo_url": null}, "2206.06289": {"publish_time": "2022-06-13", "title": "Silver-Bullet-3D at ManiSkill 2021: Learning-from-Demonstrations and Heuristic Rule-based Methods for Object Manipulation", "author": "Yingwei Pan et.al.", "abstract": "This paper presents an overview and comparative analysis of our systems designed for the following two tracks in SAPIEN ManiSkill Challenge 2021:   No Interaction Track: The No Interaction track targets for learning policies from pre-collected demonstration trajectories. We investigate both imitation learning-based approach, i.e., imitating the observed behavior using classical supervised learning techniques, and offline reinforcement learning-based approaches, for this track. Moreover, the geometry and texture structures of objects and robotic arms are exploited via Transformer-based networks to facilitate imitation learning.   No Restriction Track: In this track, we design a Heuristic Rule-based Method (HRM) to trigger high-quality object manipulation by decomposing the task into a series of sub-tasks. For each sub-task, the simple rule-based controlling strategies are adopted to predict actions that can be applied to robotic arms.   To ease the implementations of our systems, all the source codes and pre-trained models are available at \\url{https://github.com/caiqi/Silver-Bullet-3D/}.", "paper_url": "http://arxiv.org/abs/2206.06289v1", "pdf_url": "http://arxiv.org/pdf/2206.06289v1", "repo_url": "https://github.com/caiqi/silver-bullet-3d"}, "2206.06282": {"publish_time": "2022-06-13", "title": "Analysis of Randomization Effects on Sim2Real Transfer in Reinforcement Learning for Robotic Manipulation Tasks", "author": "Josip Josifovski et.al.", "abstract": "Randomization is currently a widely used approach in Sim2Real transfer for data-driven learning algorithms in robotics. Still, most Sim2Real studies report results for a specific randomization technique and often on a highly customized robotic system, making it difficult to evaluate different randomization approaches systematically. To address this problem, we define an easy-to-reproduce experimental setup for a robotic reach-and-balance manipulator task, which can serve as a benchmark for comparison. We compare four randomization strategies with three randomized parameters both in simulation and on a real robot. Our results show that more randomization helps in Sim2Real transfer, yet it can also harm the ability of the algorithm to find a good policy in simulation. Fully randomized simulations and fine-tuning show differentiated results and translate better to the real robot than the other approaches tested.", "paper_url": "http://arxiv.org/abs/2206.06282v1", "pdf_url": "http://arxiv.org/pdf/2206.06282v1", "repo_url": null}, "2206.06011": {"publish_time": "2022-06-13", "title": "Reinforcement Learning-based Placement of Charging Stations in Urban Road Networks", "author": "Leonie von Wahl et.al.", "abstract": "The transition from conventional mobility to electromobility largely depends on charging infrastructure availability and optimal placement.This paper examines the optimal placement of charging stations in urban areas. We maximise the charging infrastructure supply over the area and minimise waiting, travel, and charging times while setting budget constraints. Moreover, we include the possibility of charging vehicles at home to obtain a more refined estimation of the actual charging demand throughout the urban area. We formulate the Placement of Charging Stations problem as a non-linear integer optimisation problem that seeks the optimal positions for charging stations and the optimal number of charging piles of different charging types. We design a novel Deep Reinforcement Learning approach to solve the charging station placement problem (PCRL). Extensive experiments on real-world datasets show how the PCRL reduces the waiting and travel time while increasing the benefit of the charging plan compared to five baselines. Compared to the existing infrastructure, we can reduce the waiting time by up to 97% and increase the benefit up to 497%.", "paper_url": "http://arxiv.org/abs/2206.06011v1", "pdf_url": "http://arxiv.org/pdf/2206.06011v1", "repo_url": "https://github.com/ashusao/pcrl"}, "2206.06009": {"publish_time": "2022-06-13", "title": "Relative Policy-Transition Optimization for Fast Policy Transfer", "author": "Lei Han et.al.", "abstract": "We consider the problem of policy transfer between two Markov Decision Processes (MDPs). We introduce a lemma based on existing theoretical results in reinforcement learning (RL) to measure the relativity between two arbitrary MDPs, that is the difference between any two cumulative expected returns defined on different policies and environment dynamics. Based on this lemma, we propose two new algorithms referred to as Relative Policy Optimization (RPO) and Relative Transition Optimization (RTO), which can offer fast policy transfer and dynamics modeling, respectively. RPO updates the policy using the relative policy gradient to transfer the policy evaluated in one environment to maximize the return in another, while RTO updates the parameterized dynamics model (if there exists) using the relative transition gradient to reduce the gap between the dynamics of the two environments. Then, integrating the two algorithms offers the complete algorithm Relative Policy-Transition Optimization (RPTO), in which the policy interacts with the two environments simultaneously, such that data collections from two environments, policy and transition updates are completed in one closed loop to form a principled learning framework for policy transfer. We demonstrate the effectiveness of RPTO in OpenAI gym's classic control tasks by creating policy transfer problems via variant dynamics.", "paper_url": "http://arxiv.org/abs/2206.06009v1", "pdf_url": "http://arxiv.org/pdf/2206.06009v1", "repo_url": null}, "2206.06007": {"publish_time": "2022-06-13", "title": "Intrinsically motivated option learning: a comparative study of recent methods", "author": "Djordje Bo\u017ei\u0107 et.al.", "abstract": "Options represent a framework for reasoning across multiple time scales in reinforcement learning (RL). With the recent active interest in the unsupervised learning paradigm in the RL research community, the option framework was adapted to utilize the concept of empowerment, which corresponds to the amount of influence the agent has on the environment and its ability to perceive this influence, and which can be optimized without any supervision provided by the environment's reward structure. Many recent papers modify this concept in various ways achieving commendable results. Through these various modifications, however, the initial context of empowerment is often lost. In this work we offer a comparative study of such papers through the lens of the original empowerment principle.", "paper_url": "http://arxiv.org/abs/2206.06007v1", "pdf_url": "http://arxiv.org/pdf/2206.06007v1", "repo_url": null}, "2206.06965": {"publish_time": "2022-06-14", "title": "Deep Reinforcement Learning for Exact Combinatorial Optimization: Learning to Branch", "author": "Tianyu Zhang et.al.", "abstract": "Branch-and-bound is a systematic enumerative method for combinatorial optimization, where the performance highly relies on the variable selection strategy. State-of-the-art handcrafted heuristic strategies suffer from relatively slow inference time for each selection, while the current machine learning methods require a significant amount of labeled data. We propose a new approach for solving the data labeling and inference latency issues in combinatorial optimization based on the use of the reinforcement learning (RL) paradigm. We use imitation learning to bootstrap an RL agent and then use Proximal Policy Optimization (PPO) to further explore global optimal actions. Then, a value network is used to run Monte-Carlo tree search (MCTS) to enhance the policy network. We evaluate the performance of our method on four different categories of combinatorial optimization problems and show that our approach performs strongly compared to the state-of-the-art machine learning and heuristics based methods.", "paper_url": "http://arxiv.org/abs/2206.06965v1", "pdf_url": "http://arxiv.org/pdf/2206.06965v1", "repo_url": null}, "2206.06934": {"publish_time": "2022-06-14", "title": "A Layered Reference Model for Penetration Testing with Reinforcement Learning and Attack Graphs", "author": "Tyler Cody et.al.", "abstract": "This paper considers key challenges to using reinforcement learning (RL) with attack graphs to automate penetration testing in real-world applications from a systems perspective. RL approaches to automated penetration testing are actively being developed, but there is no consensus view on the representation of computer networks with which RL should be interacting. Moreover, there are significant open challenges to how those representations can be grounded to the real networks where RL solution methods are applied. This paper elaborates on representation and grounding using topic challenges of interacting with real networks in real-time, emulating realistic adversary behavior, and handling unstable, evolving networks. These challenges are both practical and mathematical, and they directly concern the reliability and dependability of penetration testing systems. This paper proposes a layered reference model to help organize related research and engineering efforts. The presented layered reference model contrasts traditional models of attack graph workflows because it is not scoped to a sequential, feed-forward generation and analysis process, but to broader aspects of lifecycle and continuous deployment. Researchers and practitioners can use the presented layered reference model as a first-principles outline to help orient the systems engineering of their penetration testing systems.", "paper_url": "http://arxiv.org/abs/2206.06934v1", "pdf_url": "http://arxiv.org/pdf/2206.06934v1", "repo_url": null}, "2206.06841": {"publish_time": "2022-06-14", "title": "Robust Reinforcement Learning with Distributional Risk-averse formulation", "author": "Pierre Clavier et.al.", "abstract": "Robust Reinforcement Learning tries to make predictions more robust to changes in the dynamics or rewards of the system. This problem is particularly important when the dynamics and rewards of the environment are estimated from the data. In this paper, we approximate the Robust Reinforcement Learning constrained with a $\\Phi$-divergence using an approximate Risk-Averse formulation. We show that the classical Reinforcement Learning formulation can be robustified using standard deviation penalization of the objective. Two algorithms based on Distributional Reinforcement Learning, one for discrete and one for continuous action spaces are proposed and tested in a classical Gym environment to demonstrate the robustness of the algorithms.", "paper_url": "http://arxiv.org/abs/2206.06841v1", "pdf_url": "http://arxiv.org/pdf/2206.06841v1", "repo_url": null}, "2206.06827": {"publish_time": "2022-06-14", "title": "Variance Reduction for Policy-Gradient Methods via Empirical Variance Minimization", "author": "Kaledin Maxim et.al.", "abstract": "Policy-gradient methods in Reinforcement Learning(RL) are very universal and widely applied in practice but their performance suffers from the high variance of the gradient estimate. Several procedures were proposed to reduce it including actor-critic(AC) and advantage actor-critic(A2C) methods. Recently the approaches have got new perspective due to the introduction of Deep RL: both new control variates(CV) and new sub-sampling procedures became available in the setting of complex models like neural networks. The vital part of CV-based methods is the goal functional for the training of the CV, the most popular one is the least-squares criterion of A2C. Despite its practical success, the criterion is not the only one possible. In this paper we for the first time investigate the performance of the one called Empirical Variance(EV). We observe in the experiments that not only EV-criterion performs not worse than A2C but sometimes can be considerably better. Apart from that, we also prove some theoretical guarantees of the actual variance reduction under very general assumptions and show that A2C least-squares goal functional is an upper bound for EV goal. Our experiments indicate that in terms of variance reduction EV-based methods are much better than A2C and allow stronger variance reduction.", "paper_url": "http://arxiv.org/abs/2206.06827v1", "pdf_url": "http://arxiv.org/pdf/2206.06827v1", "repo_url": null}, "2206.06796": {"publish_time": "2022-06-14", "title": "Open-Ended Learning Strategies for Learning Complex Locomotion Skills", "author": "Fangqin Zhou et.al.", "abstract": "Teaching robots to learn diverse locomotion skills under complex three-dimensional environmental settings via Reinforcement Learning (RL) is still challenging. It has been shown that training agents in simple settings before moving them on to complex settings improves the training process, but so far only in the context of relatively simple locomotion skills. In this work, we adapt the Enhanced Paired Open-Ended Trailblazer (ePOET) approach to train more complex agents to walk efficiently on complex three-dimensional terrains. First, to generate more rugged and diverse three-dimensional training terrains with increasing complexity, we extend the Compositional Pattern Producing Networks - Neuroevolution of Augmenting Topologies (CPPN-NEAT) approach and include randomized shapes. Second, we combine ePOET with Soft Actor-Critic off-policy optimization, yielding ePOET-SAC, to ensure that the agent could learn more diverse skills to solve more challenging tasks. Our experimental results show that the newly generated three-dimensional terrains have sufficient diversity and complexity to guide learning, that ePOET successfully learns complex locomotion skills on these terrains, and that our proposed ePOET-SAC approach slightly improves upon ePOET.", "paper_url": "http://arxiv.org/abs/2206.06796v1", "pdf_url": "http://arxiv.org/pdf/2206.06796v1", "repo_url": null}, "2206.07659": {"publish_time": "2022-06-15", "title": "Model-based RL with Optimistic Posterior Sampling: Structural Conditions and Sample Complexity", "author": "Alekh Agarwal et.al.", "abstract": "We propose a general framework to design posterior sampling methods for model-based RL. We show that the proposed algorithms can be analyzed by reducing regret to Hellinger distance based conditional probability estimation. We further show that optimistic posterior sampling can control this Hellinger distance, when we measure model error via data likelihood. This technique allows us to design and analyze unified posterior sampling algorithms with state-of-the-art sample complexity guarantees for many model-based RL settings. We illustrate our general result in many special cases, demonstrating the versatility of our framework.", "paper_url": "http://arxiv.org/abs/2206.07659v1", "pdf_url": "http://arxiv.org/pdf/2206.07659v1", "repo_url": null}, "2206.07568": {"publish_time": "2022-06-15", "title": "Contrastive Learning as Goal-Conditioned Reinforcement Learning", "author": "Benjamin Eysenbach et.al.", "abstract": "In reinforcement learning (RL), it is easier to solve a task if given a good representation. While deep RL should automatically acquire such good representations, prior work often finds that learning representations in an end-to-end fashion is unstable and instead equip RL algorithms with additional representation learning parts (e.g., auxiliary losses, data augmentation). How can we design RL algorithms that directly acquire good representations? In this paper, instead of adding representation learning parts to an existing RL algorithm, we show (contrastive) representation learning methods can be cast as RL algorithms in their own right. To do this, we build upon prior work and apply contrastive representation learning to action-labeled trajectories, in such a way that the (inner product of) learned representations exactly corresponds to a goal-conditioned value function. We use this idea to reinterpret a prior RL method as performing contrastive learning, and then use the idea to propose a much simpler method that achieves similar performance. Across a range of goal-conditioned RL tasks, we demonstrate that contrastive RL methods achieve higher success rates than prior non-contrastive methods, including in the offline RL setting. We also show that contrastive RL outperforms prior methods on image-based tasks, without using data augmentation or auxiliary objectives.", "paper_url": "http://arxiv.org/abs/2206.07568v1", "pdf_url": "http://arxiv.org/pdf/2206.07568v1", "repo_url": null}, "2206.07536": {"publish_time": "2022-06-15", "title": "Autonomous Platoon Control with Integrated Deep Reinforcement Learning and Dynamic Programming", "author": "Tong Liu et.al.", "abstract": "Deep Reinforcement Learning (DRL) is regarded as a potential method for car-following control and has been mostly studied to support a single following vehicle. However, it is more challenging to learn a stable and efficient car-following policy when there are multiple following vehicles in a platoon, especially with unpredictable leading vehicle behavior. In this context, we adopt an integrated DRL and Dynamic Programming (DP) approach to learn autonomous platoon control policies, which embeds the Deep Deterministic Policy Gradient (DDPG) algorithm into a finite-horizon value iteration framework. Although the DP framework can improve the stability and performance of DDPG, it has the limitations of lower sampling and training efficiency. In this paper, we propose an algorithm, namely Finite-Horizon-DDPG with Sweeping through reduced state space using Stationary approximation (FH-DDPG-SS), which uses three key ideas to overcome the above limitations, i.e., transferring network weights backward in time, stationary policy approximation for earlier time steps, and sweeping through reduced state space. In order to verify the effectiveness of FH-DDPG-SS, simulation using real driving data is performed, where the performance of FH-DDPG-SS is compared with those of the benchmark algorithms. Finally, platoon safety and string stability for FH-DDPG-SS are demonstrated.", "paper_url": "http://arxiv.org/abs/2206.07536v1", "pdf_url": "http://arxiv.org/pdf/2206.07536v1", "repo_url": null}, "2206.07505": {"publish_time": "2022-06-15", "title": "Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning", "author": "Wei Fu et.al.", "abstract": "Many advances in cooperative multi-agent reinforcement learning (MARL) are based on two common design principles: value decomposition and parameter sharing. A typical MARL algorithm of this fashion decomposes a centralized Q-function into local Q-networks with parameters shared across agents. Such an algorithmic paradigm enables centralized training and decentralized execution (CTDE) and leads to efficient learning in practice. Despite all the advantages, we revisit these two principles and show that in certain scenarios, e.g., environments with a highly multi-modal reward landscape, value decomposition, and parameter sharing can be problematic and lead to undesired outcomes. In contrast, policy gradient (PG) methods with individual policies provably converge to an optimal solution in these cases, which partially supports some recent empirical observations that PG can be effective in many MARL testbeds. Inspired by our theoretical analysis, we present practical suggestions on implementing multi-agent PG algorithms for either high rewards or diverse emergent behaviors and empirically validate our findings on a variety of domains, ranging from the simplified matrix and grid-world games to complex benchmarks such as StarCraft Multi-Agent Challenge and Google Research Football. We hope our insights could benefit the community towards developing more general and more powerful MARL algorithms. Check our project website at https://sites.google.com/view/revisiting-marl.", "paper_url": "http://arxiv.org/abs/2206.07505v1", "pdf_url": "http://arxiv.org/pdf/2206.07505v1", "repo_url": null}, "2206.07423": {"publish_time": "2022-06-15", "title": "Zero-shot object goal visual navigation", "author": "Qianfan Zhao et.al.", "abstract": "Object goal visual navigation is a challenging task that aims to guide a robot to find the target object only based on its visual observation, and the target is limited to the classes specified in the training stage. However, in real households, there may exist numerous object classes that the robot needs to deal with, and it is hard for all of these classes to be contained in the training stage. To address this challenge, we propose a zero-shot object navigation task by combining zero-shot learning with object goal visual navigation, which aims at guiding robots to find objects belonging to novel classes without any training samples. This task gives rise to the need to generalize the learned policy to novel classes, which is a less addressed issue of object navigation using deep reinforcement learning. To address this issue, we utilize \"class-unrelated\" data as input to alleviate the overfitting of the classes specified in the training stage. The class-unrelated input consists of detection results and cosine similarity of word embeddings, and does not contain any class-related visual features or knowledge graphs. Extensive experiments on the AI2-THOR platform show that our model outperforms the baseline models in both seen and unseen classes, which proves that our model is less class-sensitive and generalizes better. Our code is available at https://github.com/pioneer-innovation/Zero-Shot-Object-Navigation", "paper_url": "http://arxiv.org/abs/2206.07423v1", "pdf_url": "http://arxiv.org/pdf/2206.07423v1", "repo_url": "https://github.com/pioneer-innovation/zero-shot-object-navigation"}, "2206.08088": {"publish_time": "2022-06-16", "title": "Reinforcement Learning-enhanced Shared-account Cross-domain Sequential Recommendation", "author": "Lei Guo et.al.", "abstract": "Shared-account Cross-domain Sequential Recommendation (SCSR) is an emerging yet challenging task that simultaneously considers the shared-account and cross-domain characteristics in the sequential recommendation. Existing works on SCSR are mainly based on Recurrent Neural Network (RNN) and Graph Neural Network (GNN) but they ignore the fact that although multiple users share a single account, it is mainly occupied by one user at a time. This observation motivates us to learn a more accurate user-specific account representation by attentively focusing on its recent behaviors. Furthermore, though existing works endow lower weights to irrelevant interactions, they may still dilute the domain information and impede the cross-domain recommendation. To address the above issues, we propose a reinforcement learning-based solution, namely RL-ISN, which consists of a basic cross-domain recommender and a reinforcement learning-based domain filter. Specifically, to model the account representation in the shared-account scenario, the basic recommender first clusters users' mixed behaviors as latent users, and then leverages an attention model over them to conduct user identification. To reduce the impact of irrelevant domain information, we formulate the domain filter as a hierarchical reinforcement learning task, where a high-level task is utilized to decide whether to revise the whole transferred sequence or not, and if it does, a low-level task is further performed to determine whether to remove each interaction within it or not. To evaluate the performance of our solution, we conduct extensive experiments on two real-world datasets, and the experimental results demonstrate the superiority of our RL-ISN method compared with the state-of-the-art recommendation methods.", "paper_url": "http://arxiv.org/abs/2206.08088v1", "pdf_url": "http://arxiv.org/pdf/2206.08088v1", "repo_url": null}, "2206.08016": {"publish_time": "2022-06-16", "title": "Backbones-Review: Feature Extraction Networks for Deep Learning and Deep Reinforcement Learning Approaches", "author": "Omar Elharrouss et.al.", "abstract": "To understand the real world using various types of data, Artificial Intelligence (AI) is the most used technique nowadays. While finding the pattern within the analyzed data represents the main task. This is performed by extracting representative features step, which is proceeded using the statistical algorithms or using some specific filters. However, the selection of useful features from large-scale data represented a crucial challenge. Now, with the development of convolution neural networks (CNNs), the feature extraction operation has become more automatic and easier. CNNs allow to work on large-scale size of data, as well as cover different scenarios for a specific task. For computer vision tasks, convolutional networks are used to extract features also for the other parts of a deep learning model. The selection of a suitable network for feature extraction or the other parts of a DL model is not random work. So, the implementation of such a model can be related to the target task as well as the computational complexity of it. Many networks have been proposed and become the famous networks used for any DL models in any AI task. These networks are exploited for feature extraction or at the beginning of any DL model which is named backbones. A backbone is a known network trained in many other tasks before and demonstrates its effectiveness. In this paper, an overview of the existing backbones, e.g. VGGs, ResNets, DenseNet, etc, is given with a detailed description. Also, a couple of computer vision tasks are discussed by providing a review of each task regarding the backbones used. In addition, a comparison in terms of performance is also provided, based on the backbone used for each task.", "paper_url": "http://arxiv.org/abs/2206.08016v1", "pdf_url": "http://arxiv.org/pdf/2206.08016v1", "repo_url": null}, "2206.07989": {"publish_time": "2022-06-16", "title": "Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination", "author": "Jiafei Lyu et.al.", "abstract": "The learned policy of model-free offline reinforcement learning (RL) methods is often constrained to stay within the support of datasets to avoid possible dangerous out-of-distribution actions or states, making it challenging to handle out-of-support region. Model-based RL methods offer a richer dataset and benefit generalization by generating imaginary trajectories with either trained forward or reverse dynamics model. However, the imagined transitions may be inaccurate, thus downgrading the performance of the underlying offline RL method. In this paper, we propose to augment the offline dataset by using trained bidirectional dynamics models and rollout policies with double check. We introduce conservatism by trusting samples that the forward model and backward model agree on. Our method, confidence-aware bidirectional offline model-based imagination, generates reliable samples and can be combined with any model-free offline RL method. Experimental results on the D4RL benchmarks demonstrate that our method significantly boosts the performance of existing model-free offline RL algorithms and achieves competitive or better scores against baseline methods.", "paper_url": "http://arxiv.org/abs/2206.07989v1", "pdf_url": "http://arxiv.org/pdf/2206.07989v1", "repo_url": null}, "2206.07922": {"publish_time": "2022-06-16", "title": "Challenges and Opportunities in Deep Reinforcement Learning with Graph Neural Networks: A Comprehensive review of Algorithms and Applications", "author": "Sai Munikoti et.al.", "abstract": "Deep reinforcement learning (DRL) has empowered a variety of artificial intelligence fields, including pattern recognition, robotics, recommendation-systems, and gaming. Similarly, graph neural networks (GNN) have also demonstrated their superior performance in supervised learning for graph-structured data. In recent times, the fusion of GNN with DRL for graph-structured environments has attracted a lot of attention. This paper provides a comprehensive review of these hybrid works. These works can be classified into two categories: (1) algorithmic enhancement, where DRL and GNN complement each other for better utility; (2) application-specific enhancement, where DRL and GNN support each other. This fusion effectively addresses various complex problems in engineering and life sciences. Based on the review, we further analyze the applicability and benefits of fusing these two domains, especially in terms of increasing generalizability and reducing computational complexity. Finally, the key challenges in integrating DRL and GNN, and potential future research directions are highlighted, which will be of interest to the broader machine learning community.", "paper_url": "http://arxiv.org/abs/2206.07922v1", "pdf_url": "http://arxiv.org/pdf/2206.07922v1", "repo_url": null}, "2206.07915": {"publish_time": "2022-06-16", "title": "Barrier Certified Safety Learning Control: When Sum-of-Square Programming Meets Reinforcement Learning", "author": "Hejun Huang et.al.", "abstract": "Safety guarantee is essential in many engineering implementations. Reinforcement learning provides a useful way to strengthen safety. However, reinforcement learning algorithms cannot completely guarantee safety over realistic operations. To address this issue, this work adopts control barrier functions over reinforcement learning, and proposes a compensated algorithm to completely maintain safety. Specifically, a sum-of-squares programming has been exploited to search for the optimal controller, and tune the learning hyperparameters simultaneously. Thus, the control actions are pledged to be always within the safe region. The effectiveness of proposed method is demonstrated via an inverted pendulum model. Compared to quadratic programming based reinforcement learning methods, our sum-of-squares programming based reinforcement learning has shown its superiority.", "paper_url": "http://arxiv.org/abs/2206.07915v1", "pdf_url": "http://arxiv.org/pdf/2206.07915v1", "repo_url": "https://github.com/wogwan/ccta2022_saferl"}, "2206.08896": {"publish_time": "2022-06-17", "title": "Evolution through Large Models", "author": "Joel Lehman et.al.", "abstract": "This paper pursues the insight that large language models (LLMs) trained to generate code can vastly improve the effectiveness of mutation operators applied to programs in genetic programming (GP). Because such LLMs benefit from training data that includes sequential changes and modifications, they can approximate likely changes that humans would make. To highlight the breadth of implications of such evolution through large models (ELM), in the main experiment ELM combined with MAP-Elites generates hundreds of thousands of functional examples of Python programs that output working ambulating robots in the Sodarace domain, which the original LLM had never seen in pre-training. These examples then help to bootstrap training a new conditional language model that can output the right walker for a particular terrain. The ability to bootstrap new models that can output appropriate artifacts for a given context in a domain where zero training data was previously available carries implications for open-endedness, deep learning, and reinforcement learning. These implications are explored here in depth in the hope of inspiring new directions of research now opened up by ELM.", "paper_url": "http://arxiv.org/abs/2206.08896v1", "pdf_url": "http://arxiv.org/pdf/2206.08896v1", "repo_url": null}, "2206.08888": {"publish_time": "2022-06-17", "title": "Fast Population-Based Reinforcement Learning on a Single Machine", "author": "Arthur Flajolet et.al.", "abstract": "Training populations of agents has demonstrated great promise in Reinforcement Learning for stabilizing training, improving exploration and asymptotic performance, and generating a diverse set of solutions. However, population-based training is often not considered by practitioners as it is perceived to be either prohibitively slow (when implemented sequentially), or computationally expensive (if agents are trained in parallel on independent accelerators). In this work, we compare implementations and revisit previous studies to show that the judicious use of compilation and vectorization allows population-based training to be performed on a single machine with one accelerator with minimal overhead compared to training a single agent. We also show that, when provided with a few accelerators, our protocols extend to large population sizes for applications such as hyperparameter tuning. We hope that this work and the public release of our code will encourage practitioners to use population-based learning more frequently for their research and applications.", "paper_url": "http://arxiv.org/abs/2206.08888v1", "pdf_url": "http://arxiv.org/pdf/2206.08888v1", "repo_url": null}, "2206.08883": {"publish_time": "2022-06-17", "title": "CtrlFormer: Learning Transferable State Representation for Visual Control via Transformer", "author": "Yao Mu et.al.", "abstract": "Transformer has achieved great successes in learning vision and language representation, which is general across various downstream tasks. In visual control, learning transferable state representation that can transfer between different control tasks is important to reduce the training sample size. However, porting Transformer to sample-efficient visual control remains a challenging and unsolved problem. To this end, we propose a novel Control Transformer (CtrlFormer), possessing many appealing benefits that prior arts do not have. Firstly, CtrlFormer jointly learns self-attention mechanisms between visual tokens and policy tokens among different control tasks, where multitask representation can be learned and transferred without catastrophic forgetting. Secondly, we carefully design a contrastive reinforcement learning paradigm to train CtrlFormer, enabling it to achieve high sample efficiency, which is important in control problems. For example, in the DMControl benchmark, unlike recent advanced methods that failed by producing a zero score in the \"Cartpole\" task after transfer learning with 100k samples, CtrlFormer can achieve a state-of-the-art score with only 100k samples while maintaining the performance of previous tasks. The code and models are released in our project homepage.", "paper_url": "http://arxiv.org/abs/2206.08883v1", "pdf_url": "http://arxiv.org/pdf/2206.08883v1", "repo_url": null}, "2206.08881": {"publish_time": "2022-06-17", "title": "Logic-based Reward Shaping for Multi-Agent Reinforcement Learning", "author": "Ingy ElSayed-Aly et.al.", "abstract": "Reinforcement learning (RL) relies heavily on exploration to learn from its environment and maximize observed rewards. Therefore, it is essential to design a reward function that guarantees optimal learning from the received experience. Previous work has combined automata and logic based reward shaping with environment assumptions to provide an automatic mechanism to synthesize the reward function based on the task. However, there is limited work on how to expand logic-based reward shaping to Multi-Agent Reinforcement Learning (MARL). The environment will need to consider the joint state in order to keep track of other agents if the task requires cooperation, thus suffering from the curse of dimensionality with respect to the number of agents. This project explores how logic-based reward shaping for MARL can be designed for different scenarios and tasks. We present a novel method for semi-centralized logic-based MARL reward shaping that is scalable in the number of agents and evaluate it in multiple scenarios.", "paper_url": "http://arxiv.org/abs/2206.08881v1", "pdf_url": "http://arxiv.org/pdf/2206.08881v1", "repo_url": "https://github.com/ingyn/macsrl"}, "2206.08851": {"publish_time": "2022-06-17", "title": "SMPL: Simulated Industrial Manufacturing and Process Control Learning Environments", "author": "Mohan Zhang et.al.", "abstract": "Traditional biological and pharmaceutical manufacturing plants are controlled by human workers or pre-defined thresholds. Modernized factories have advanced process control algorithms such as model predictive control (MPC). However, there is little exploration of applying deep reinforcement learning to control manufacturing plants. One of the reasons is the lack of high fidelity simulations and standard APIs for benchmarking. To bridge this gap, we develop an easy-to-use library that includes five high-fidelity simulation environments: BeerFMTEnv, ReactorEnv, AtropineEnv, PenSimEnv and mAbEnv, which cover a wide range of manufacturing processes. We build these environments on published dynamics models. Furthermore, we benchmark online and offline, model-based and model-free reinforcement learning algorithms for comparisons of follow-up research.", "paper_url": "http://arxiv.org/abs/2206.08851v1", "pdf_url": "http://arxiv.org/pdf/2206.08851v1", "repo_url": "https://github.com/smpl-env/smpl"}, "2206.10558": {"publish_time": "2022-06-21", "title": "EnvPool: A Highly Parallel Reinforcement Learning Environment Execution Engine", "author": "Jiayi Weng et.al.", "abstract": "There has been significant progress in developing reinforcement learning (RL) training systems. Past works such as IMPALA, Apex, Seed RL, Sample Factory, and others aim to improve the system's overall throughput. In this paper, we try to address a common bottleneck in the RL training system, i.e., parallel environment execution, which is often the slowest part of the whole system but receives little attention. With a curated design for paralleling RL environments, we have improved the RL environment simulation speed across different hardware setups, ranging from a laptop, and a modest workstation, to a high-end machine like NVIDIA DGX-A100. On a high-end machine, EnvPool achieves 1 million frames per second for the environment execution on Atari environments and 3 million frames per second on MuJoCo environments. When running on a laptop, the speed of EnvPool is 2.8 times of the Python subprocess. Moreover, great compatibility with existing RL training libraries has been demonstrated in the open-sourced community, including CleanRL, rl_games, DeepMind Acme, etc. Finally, EnvPool allows researchers to iterate their ideas at a much faster pace and has the great potential to become the de facto RL environment execution engine. Example runs show that it takes only 5 minutes to train Atari Pong and MuJoCo Ant, both on a laptop. EnvPool has already been open-sourced at https://github.com/sail-sg/envpool.", "paper_url": "http://arxiv.org/abs/2206.10558v1", "pdf_url": "http://arxiv.org/pdf/2206.10558v1", "repo_url": "https://github.com/vwxyzjn/envpool-cleanrl"}, "2206.10544": {"publish_time": "2022-06-21", "title": "Multi-UAV Planning for Cooperative Wildfire Coverage and Tracking with Quality-of-Service Guarantees", "author": "Esmaeil Seraj et.al.", "abstract": "In recent years, teams of robot and Unmanned Aerial Vehicles (UAVs) have been commissioned by researchers to enable accurate, online wildfire coverage and tracking. While the majority of prior work focuses on the coordination and control of such multi-robot systems, to date, these UAV teams have not been given the ability to reason about a fire's track (i.e., location and propagation dynamics) to provide performance guarantee over a time horizon. Motivated by the problem of aerial wildfire monitoring, we propose a predictive framework which enables cooperation in multi-UAV teams towards collaborative field coverage and fire tracking with probabilistic performance guarantee. Our approach enables UAVs to infer the latent fire propagation dynamics for time-extended coordination in safety-critical conditions. We derive a set of novel, analytical temporal, and tracking-error bounds to enable the UAV-team to distribute their limited resources and cover the entire fire area according to the case-specific estimated states and provide a probabilistic performance guarantee. Our results are not limited to the aerial wildfire monitoring case-study and are generally applicable to problems, such as search-and-rescue, target tracking and border patrol. We evaluate our approach in simulation and provide demonstrations of the proposed framework on a physical multi-robot testbed to account for real robot dynamics and restrictions. Our quantitative evaluations validate the performance of our method accumulating 7.5x and 9.0x smaller tracking-error than state-of-the-art model-based and reinforcement learning benchmarks, respectively.", "paper_url": "http://arxiv.org/abs/2206.10544v1", "pdf_url": "http://arxiv.org/pdf/2206.10544v1", "repo_url": null}, "2206.10464": {"publish_time": "2022-06-21", "title": "Hybridization of evolutionary algorithm and deep reinforcement learning for multi-objective orienteering optimization", "author": "Wei Liu et.al.", "abstract": "Multi-objective orienteering problems (MO-OPs) are classical multi-objective routing problems and have received a lot of attention in the past decades. This study seeks to solve MO-OPs through a problem-decomposition framework, that is, a MO-OP is decomposed into a multi-objective knapsack problem (MOKP) and a travelling salesman problem (TSP). The MOKP and TSP are then solved by a multi-objective evolutionary algorithm (MOEA) and a deep reinforcement learning (DRL) method, respectively. While the MOEA module is for selecting cities, the DRL module is for planning a Hamiltonian path for these cities. An iterative use of these two modules drives the population towards the Pareto front of MO-OPs. The effectiveness of the proposed method is compared against NSGA-II and NSGA-III on various types of MO-OP instances. Experimental results show that our method exhibits the best performance on almost all the test instances, and has shown strong generalization ability.", "paper_url": "http://arxiv.org/abs/2206.10464v1", "pdf_url": "http://arxiv.org/pdf/2206.10464v1", "repo_url": null}, "2206.10451": {"publish_time": "2022-06-21", "title": "Winning the Lottery Ahead of Time: Efficient Early Network Pruning", "author": "John Rachwan et.al.", "abstract": "Pruning, the task of sparsifying deep neural networks, received increasing attention recently. Although state-of-the-art pruning methods extract highly sparse models, they neglect two main challenges: (1) the process of finding these sparse models is often very expensive; (2) unstructured pruning does not provide benefits in terms of GPU memory, training time, or carbon emissions. We propose Early Compression via Gradient Flow Preservation (EarlyCroP), which efficiently extracts state-of-the-art sparse models before or early in training addressing challenge (1), and can be applied in a structured manner addressing challenge (2). This enables us to train sparse networks on commodity GPUs whose dense versions would be too large, thereby saving costs and reducing hardware requirements. We empirically show that EarlyCroP outperforms a rich set of baselines for many tasks (incl. classification, regression) and domains (incl. computer vision, natural language processing, and reinforcment learning). EarlyCroP leads to accuracy comparable to dense training while outperforming pruning baselines.", "paper_url": "http://arxiv.org/abs/2206.10451v1", "pdf_url": "http://arxiv.org/pdf/2206.10451v1", "repo_url": null}, "2206.10442": {"publish_time": "2022-06-21", "title": "Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning", "author": "Haoqi Yuan et.al.", "abstract": "We study offline meta-reinforcement learning, a practical reinforcement learning paradigm that learns from offline data to adapt to new tasks. The distribution of offline data is determined jointly by the behavior policy and the task. Existing offline meta-reinforcement learning algorithms cannot distinguish these factors, making task representations unstable to the change of behavior policies. To address this problem, we propose a contrastive learning framework for task representations that are robust to the distribution mismatch of behavior policies in training and test. We design a bi-level encoder structure, use mutual information maximization to formalize task representation learning, derive a contrastive learning objective, and introduce several approaches to approximate the true distribution of negative pairs. Experiments on a variety of offline meta-reinforcement learning benchmarks demonstrate the advantages of our method over prior methods, especially on the generalization to out-of-distribution behavior policies. The code is available at https://github.com/PKU-AI-Edge/CORRO.", "paper_url": "http://arxiv.org/abs/2206.10442v1", "pdf_url": "http://arxiv.org/pdf/2206.10442v1", "repo_url": "https://github.com/pku-ai-edge/corro"}, "2206.11251": {"publish_time": "2022-06-22", "title": "Behavior Transformers: Cloning $k$ modes with one stone", "author": "Nur Muhammad Mahi Shafiullah et.al.", "abstract": "While behavior learning has made impressive progress in recent times, it lags behind computer vision and natural language processing due to its inability to leverage large, human-generated datasets. Human behaviors have wide variance, multiple modes, and human demonstrations typically do not come with reward labels. These properties limit the applicability of current methods in Offline RL and Behavioral Cloning to learn from large, pre-collected datasets. In this work, we present Behavior Transformer (BeT), a new technique to model unlabeled demonstration data with multiple modes. BeT retrofits standard transformer architectures with action discretization coupled with a multi-task action correction inspired by offset prediction in object detection. This allows us to leverage the multi-modal modeling ability of modern transformers to predict multi-modal continuous actions. We experimentally evaluate BeT on a variety of robotic manipulation and self-driving behavior datasets. We show that BeT significantly improves over prior state-of-the-art work on solving demonstrated tasks while capturing the major modes present in the pre-collected datasets. Finally, through an extensive ablation study, we analyze the importance of every crucial component in BeT. Videos of behavior generated by BeT are available at https://notmahi.github.io/bet", "paper_url": "http://arxiv.org/abs/2206.11251v1", "pdf_url": "http://arxiv.org/pdf/2206.11251v1", "repo_url": "https://github.com/notmahi/bet"}, "2206.11190": {"publish_time": "2022-06-22", "title": "Learning Optimal Treatment Strategies for Sepsis Using Offline Reinforcement Learning in Continuous Space", "author": "Zeyu Wang et.al.", "abstract": "Sepsis is a leading cause of death in the ICU. It is a disease requiring complex interventions in a short period of time, but its optimal treatment strategy remains uncertain. Evidence suggests that the practices of currently used treatment strategies are problematic and may cause harm to patients. To address this decision problem, we propose a new medical decision model based on historical data to help clinicians recommend the best reference option for real-time treatment. Our model combines offline reinforcement learning with deep reinforcement learning to address the problem that traditional reinforcement learning in healthcare cannot interact with the environment, enabling our model to make decisions in a continuous state-action space. We demonstrate that, on average, the treatments recommended by the model are more valuable and reliable than those recommended by clinicians. In a large validation dataset, we found that patients whose actual doses from clinicians matched the AI's decisions had the lowest mortality rates. Our model provides personalized, clinically interpretable treatment decisions for sepsis that can improve patient care.", "paper_url": "http://arxiv.org/abs/2206.11190v1", "pdf_url": "http://arxiv.org/pdf/2206.11190v1", "repo_url": null}, "2206.11004": {"publish_time": "2022-06-22", "title": "Auto-Encoding Adversarial Imitation Learning", "author": "Kaifeng Zhang et.al.", "abstract": "Reinforcement learning (RL) provides a powerful framework for decision-making, but its application in practice often requires a carefully designed reward function. Adversarial Imitation Learning (AIL) sheds light on automatic policy acquisition without access to the reward signal from the environment. In this work, we propose Auto-Encoding Adversarial Imitation Learning (AEAIL), a robust and scalable AIL framework. To induce expert policies from demonstrations, AEAIL utilizes the reconstruction error of an auto-encoder as a reward signal, which provides more information for optimizing policies than the prior discriminator-based ones. Subsequently, we use the derived objective functions to train the auto-encoder and the agent policy. Experiments show that our AEAIL performs superior compared to state-of-the-art methods in the MuJoCo environments. More importantly, AEAIL shows much better robustness when the expert demonstrations are noisy. Specifically, our method achieves $16.4\\%$ and $47.2\\%$ relative improvement overall compared to the best baseline FAIRL and PWIL on clean and noisy expert data, respectively. Video results, open-source code and dataset are available in https://sites.google.com/view/auto-encoding-imitation.", "paper_url": "http://arxiv.org/abs/2206.11004v1", "pdf_url": "http://arxiv.org/pdf/2206.11004v1", "repo_url": null}, "2206.10870": {"publish_time": "2022-06-22", "title": "Decentralized Gossip-Based Stochastic Bilevel Optimization over Communication Networks", "author": "Shuoguang Yang et.al.", "abstract": "Bilevel optimization have gained growing interests, with numerous applications found in meta learning, minimax games, reinforcement learning, and nested composition optimization. This paper studies the problem of distributed bilevel optimization over a network where agents can only communicate with neighbors, including examples from multi-task, multi-agent learning and federated learning. In this paper, we propose a gossip-based distributed bilevel learning algorithm that allows networked agents to solve both the inner and outer optimization problems in a single timescale and share information via network propagation. We show that our algorithm enjoys the $\\mathcal{O}(\\frac{1}{K \\epsilon^2})$ per-agent sample complexity for general nonconvex bilevel optimization and $\\mathcal{O}(\\frac{1}{K \\epsilon})$ for strongly convex objective, achieving a speedup that scales linearly with the network size. The sample complexities are optimal in both $\\epsilon$ and $K$. We test our algorithm on the examples of hyperparameter tuning and decentralized reinforcement learning. Simulated experiments confirmed that our algorithm achieves the state-of-the-art training efficiency and test accuracy.", "paper_url": "http://arxiv.org/abs/2206.10870v1", "pdf_url": "http://arxiv.org/pdf/2206.10870v1", "repo_url": null}, "2206.10787": {"publish_time": "2022-06-22", "title": "Global Planning for Contact-Rich Manipulation via Local Smoothing of Quasi-dynamic Contact Models", "author": "Tao Pang et.al.", "abstract": "The empirical success of Reinforcement Learning (RL) in the setting of contact-rich manipulation leaves much to be understood from a model-based perspective, where the key difficulties are often attributed to (i) the explosion of contact modes, (ii) stiff, non-smooth contact dynamics and the resulting exploding / discontinuous gradients, and (iii) the non-convexity of the planning problem. The stochastic nature of RL addresses (i) and (ii) by effectively sampling and averaging the contact modes. On the other hand, model-based methods have tackled the same challenges by smoothing contact dynamics analytically. Our first contribution is to establish the theoretical equivalence of the two methods for simple systems, and provide qualitative and empirical equivalence on a number of complex examples. In order to further alleviate (ii), our second contribution is a convex, differentiable and quasi-dynamic formulation of contact dynamics, which is amenable to both smoothing schemes, and has proven through experiments to be highly effective for contact-rich planning. Our final contribution resolves (iii), where we show that classical sampling-based motion planning algorithms can be effective in global planning when contact modes are abstracted via smoothing. Applying our method on a collection of challenging contact-rich manipulation tasks, we demonstrate that efficient model-based motion planning can achieve results comparable to RL with dramatically less computation. Video: https://youtu.be/12Ew4xC-VwA", "paper_url": "http://arxiv.org/abs/2206.10787v1", "pdf_url": "http://arxiv.org/pdf/2206.10787v1", "repo_url": null}, "2206.11889": {"publish_time": "2022-06-23", "title": "Provably Efficient Model-Free Constrained RL with Linear Function Approximation", "author": "Arnob Ghosh et.al.", "abstract": "We study the constrained reinforcement learning problem, in which an agent aims to maximize the expected cumulative reward subject to a constraint on the expected total value of a utility function. In contrast to existing model-based approaches or model-free methods accompanied with a `simulator', we aim to develop the first model-free, simulator-free algorithm that achieves a sublinear regret and a sublinear constraint violation even in large-scale systems. To this end, we consider the episodic constrained Markov decision processes with linear function approximation, where the transition dynamics and the reward function can be represented as a linear function of some known feature mapping. We show that $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$ regret and $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$ constraint violation bounds can be achieved, where $d$ is the dimension of the feature mapping, $H$ is the length of the episode, and $T$ is the total number of steps. Our bounds are attained without explicitly estimating the unknown transition model or requiring a simulator, and they depend on the state space only through the dimension of the feature mapping. Hence our bounds hold even when the number of states goes to infinity. Our main results are achieved via novel adaptations of the standard LSVI-UCB algorithms. In particular, we first introduce primal-dual optimization into the LSVI-UCB algorithm to balance between regret and constraint violation. More importantly, we replace the standard greedy selection with respect to the state-action function in LSVI-UCB with a soft-max policy. This turns out to be key in establishing uniform concentration for the constrained case via its approximation-smoothness trade-off. We also show that one can achieve an even zero constraint violation while still maintaining the same order with respect to $T$.", "paper_url": "http://arxiv.org/abs/2206.11889v1", "pdf_url": "http://arxiv.org/pdf/2206.11889v1", "repo_url": null}, "2206.11795": {"publish_time": "2022-06-23", "title": "Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos", "author": "Bowen Baker et.al.", "abstract": "Pretraining on noisy, internet-scale datasets has been heavily studied as a technique for training models with broad, general capabilities for text, images, and other modalities. However, for many sequential decision domains such as robotics, video games, and computer use, publicly available data does not contain the labels required to train behavioral priors in the same way. We extend the internet-scale pretraining paradigm to sequential decision domains through semi-supervised imitation learning wherein agents learn to act by watching online unlabeled videos. Specifically, we show that with a small amount of labeled data we can train an inverse dynamics model accurate enough to label a huge unlabeled source of online data -- here, online videos of people playing Minecraft -- from which we can then train a general behavioral prior. Despite using the native human interface (mouse and keyboard at 20Hz), we show that this behavioral prior has nontrivial zero-shot capabilities and that it can be fine-tuned, with both imitation learning and reinforcement learning, to hard-exploration tasks that are impossible to learn from scratch via reinforcement learning. For many tasks our models exhibit human-level performance, and we are the first to report computer agents that can craft diamond tools, which can take proficient humans upwards of 20 minutes (24,000 environment actions) of gameplay to accomplish.", "paper_url": "http://arxiv.org/abs/2206.11795v1", "pdf_url": "http://arxiv.org/pdf/2206.11795v1", "repo_url": null}, "2206.11715": {"publish_time": "2022-06-23", "title": "Deep Reinforcement Learning-Assisted Federated Learning for Robust Short-term Utility Demand Forecasting in Electricity Wholesale Markets", "author": "Chenghao Huang et.al.", "abstract": "Short-term load forecasting (STLF) plays a significant role in the operation of electricity trading markets. Considering the growing concern of data privacy, federated learning (FL) is increasingly adopted to train STLF models for utility companies (UCs) in recent research. Inspiringly, in wholesale markets, as it is not realistic for power plants (PPs) to access UCs' data directly, FL is definitely a feasible solution of obtaining an accurate STLF model for PPs. However, due to FL's distributed nature and intense competition among UCs, defects increasingly occur and lead to poor performance of the STLF model, indicating that simply adopting FL is not enough. In this paper, we propose a DRL-assisted FL approach, DEfect-AwaRe federated soft actor-critic (DearFSAC), to robustly train an accurate STLF model for PPs to forecast precise short-term utility electricity demand. Firstly. we design a STLF model based on long short-term memory (LSTM) using just historical load data and time data. Furthermore, considering the uncertainty of defects occurrence, a deep reinforcement learning (DRL) algorithm is adopted to assist FL by alleviating model degradation caused by defects. In addition, for faster convergence of FL training, an auto-encoder is designed for both dimension reduction and quality evaluation of uploaded models. In the simulations, we validate our approach on real data of Helsinki's UCs in 2019. The results show that DearFSAC outperforms all the other approaches no matter if defects occur or not.", "paper_url": "http://arxiv.org/abs/2206.11715v1", "pdf_url": "http://arxiv.org/pdf/2206.11715v1", "repo_url": null}, "2206.11708": {"publish_time": "2022-06-23", "title": "Reinforcement Learning under Partial Observability Guided by Learned Environment Models", "author": "Edi Muskardin et.al.", "abstract": "In practical applications, we can rarely assume full observability of a system's environment, despite such knowledge being important for determining a reactive control system's precise interaction with its environment. Therefore, we propose an approach for reinforcement learning (RL) in partially observable environments. While assuming that the environment behaves like a partially observable Markov decision process with known discrete actions, we assume no knowledge about its structure or transition probabilities.   Our approach combines Q-learning with IoAlergia, a method for learning Markov decision processes (MDP). By learning MDP models of the environment from episodes of the RL agent, we enable RL in partially observable domains without explicit, additional memory to track previous interactions for dealing with ambiguities stemming from partial observability. We instead provide RL with additional observations in the form of abstract environment states by simulating new experiences on learned environment models to track the explored states. In our evaluation, we report on the validity of our approach and its promising performance in comparison to six state-of-the-art deep RL techniques with recurrent neural networks and fixed memory.", "paper_url": "http://arxiv.org/abs/2206.11708v1", "pdf_url": "http://arxiv.org/pdf/2206.11708v1", "repo_url": null}, "2206.11693": {"publish_time": "2022-06-23", "title": "Learning Agile Skills via Adversarial Imitation of Rough Partial Demonstrations", "author": "Chenhao Li et.al.", "abstract": "Learning agile skills is one of the main challenges in robotics. To this end, reinforcement learning approaches have achieved impressive results. These methods require explicit task information in terms of a reward function or an expert that can be queried in simulation to provide a target control output, which limits their applicability. In this work, we propose a generative adversarial method for inferring reward functions from partial and potentially physically incompatible demonstrations for successful skill acquirement where reference or expert demonstrations are not easily accessible. Moreover, we show that by using a Wasserstein GAN formulation and transitions from demonstrations with rough and partial information as input, we are able to extract policies that are robust and capable of imitating demonstrated behaviors. Finally, the obtained skills such as a backflip are tested on an agile quadruped robot called Solo 8 and present faithful replication of hand-held human demonstrations.", "paper_url": "http://arxiv.org/abs/2206.11693v1", "pdf_url": "http://arxiv.org/pdf/2206.11693v1", "repo_url": null}, "2206.12330": {"publish_time": "2022-06-24", "title": "Toward multi-target self-organizing pursuit in a partially observable Markov game", "author": "Lijun Sun et.al.", "abstract": "The multiple-target self-organizing pursuit (SOP) problem has wide applications and has been considered a challenging self-organization game for distributed systems, in which intelligent agents cooperatively pursue multiple dynamic targets with partial observations. This work proposes a framework for decentralized multi-agent systems to improve intelligent agents' search and pursuit capabilities. We model a self-organizing system as a partially observable Markov game (POMG) with the features of decentralization, partial observation, and noncommunication. The proposed distributed algorithm: fuzzy self-organizing cooperative coevolution (FSC2) is then leveraged to resolve the three challenges in multi-target SOP: distributed self-organizing search (SOS), distributed task allocation, and distributed single-target pursuit. FSC2 includes a coordinated multi-agent deep reinforcement learning method that enables homogeneous agents to learn natural SOS patterns. Additionally, we propose a fuzzy-based distributed task allocation method, which locally decomposes multi-target SOP into several single-target pursuit problems. The cooperative coevolution principle is employed to coordinate distributed pursuers for each single-target pursuit problem. Therefore, the uncertainties of inherent partial observation and distributed decision-making in the POMG can be alleviated. The experimental results demonstrate that distributed noncommunicating multi-agent coordination with partial observations in all three subtasks are effective, and 2048 FSC2 agents can perform efficient multi-target SOP with an almost 100% capture rate.", "paper_url": "http://arxiv.org/abs/2206.12330v1", "pdf_url": "http://arxiv.org/pdf/2206.12330v1", "repo_url": "https://github.com/lijunsun90/pursuitfsc2"}, "2206.12233": {"publish_time": "2022-06-24", "title": "Reinforcement learning based adaptive metaheuristics", "author": "Michele Tessari et.al.", "abstract": "Parameter adaptation, that is the capability to automatically adjust an algorithm's hyperparameters depending on the problem being faced, is one of the main trends in evolutionary computation applied to numerical optimization. While several handcrafted adaptation policies have been proposed over the years to address this problem, only few attempts have been done so far at apply machine learning to learn such policies. Here, we introduce a general-purpose framework for performing parameter adaptation in continuous-domain metaheuristics based on state-of-the-art reinforcement learning algorithms. We demonstrate the applicability of this framework on two algorithms, namely Covariance Matrix Adaptation Evolution Strategies (CMA-ES) and Differential Evolution (DE), for which we learn, respectively, adaptation policies for the step-size (for CMA-ES), and the scale factor and crossover rate (for DE). We train these policies on a set of 46 benchmark functions at different dimensionalities, with various inputs to the policies, in two settings: one policy per function, and one global policy for all functions. Compared, respectively, to the Cumulative Step-size Adaptation (CSA) policy and to two well-known adaptive DE variants (iDE and jDE), our policies are able to produce competitive results in the majority of cases, especially in the case of DE.", "paper_url": "http://arxiv.org/abs/2206.12233v1", "pdf_url": "http://arxiv.org/pdf/2206.12233v1", "repo_url": null}, "2206.12188": {"publish_time": "2022-06-24", "title": "Dynamic network congestion pricing based on deep reinforcement learning", "author": "Kimihiro Sato et.al.", "abstract": "Traffic congestion is a serious problem in urban areas. Dynamic congestion pricing is one of the useful schemes to eliminate traffic congestion in strategic scale. However, in the reality, an optimal dynamic congestion pricing is very difficult or impossible to determine theoretically, because road networks are usually large and complicated, and behavior of road users is uncertain. To account for this challenge, this work proposes a dynamic congestion pricing method using deep reinforcement learning (DRL). It is designed to eliminate traffic congestion based on observable data in general large-scale road networks, by leveraging the data-driven nature of deep reinforcement learning. One of the novel elements of the proposed method is the distributed and cooperative learning scheme. Specifically, the DRL is implemented by a spatial-temporally distributed manner, and cooperation among DRL agents is established by novel techniques we call spatially shared reward and temporally switching learning. It enables fast and computationally efficient learning in large-scale networks. The numerical experiments using Sioux Falls Network showed that the proposed method works well thanks to the novel learning scheme.", "paper_url": "http://arxiv.org/abs/2206.12188v1", "pdf_url": "http://arxiv.org/pdf/2206.12188v1", "repo_url": null}, "2206.12146": {"publish_time": "2022-06-24", "title": "Multi-Agent Deep Reinforcement Learning for Cost- and Delay-Sensitive Virtual Network Function Placement and Routing", "author": "Shaoyang Wang et.al.", "abstract": "This paper proposes an effective and novel multiagent deep reinforcement learning (MADRL)-based method for solving the joint virtual network function (VNF) placement and routing (P&R), where multiple service requests with differentiated demands are delivered at the same time. The differentiated demands of the service requests are reflected by their delay- and cost-sensitive factors. We first construct a VNF P&R problem to jointly minimize a weighted sum of service delay and resource consumption cost, which is NP-complete. Then, the joint VNF P&R problem is decoupled into two iterative subtasks: placement subtask and routing subtask. Each subtask consists of multiple concurrent parallel sequential decision processes. By invoking the deep deterministic policy gradient method and multi-agent technique, an MADRL-P&R framework is designed to perform the two subtasks. The new joint reward and internal rewards mechanism is proposed to match the goals and constraints of the placement and routing subtasks. We also propose the parameter migration-based model-retraining method to deal with changing network topologies. Corroborated by experiments, the proposed MADRL-P&R framework is superior to its alternatives in terms of service cost and delay, and offers higher flexibility for personalized service demands. The parameter migration-based model-retraining method can efficiently accelerate convergence under moderate network topology changes.", "paper_url": "http://arxiv.org/abs/2206.12146v1", "pdf_url": "http://arxiv.org/pdf/2206.12146v1", "repo_url": null}, "2206.12081": {"publish_time": "2022-06-24", "title": "Computationally Efficient PAC RL in POMDPs with Latent Determinism and Conditional Embeddings", "author": "Masatoshi Uehara et.al.", "abstract": "We study reinforcement learning with function approximation for large-scale Partially Observable Markov Decision Processes (POMDPs) where the state space and observation space are large or even continuous. Particularly, we consider Hilbert space embeddings of POMDP where the feature of latent states and the feature of observations admit a conditional Hilbert space embedding of the observation emission process, and the latent state transition is deterministic. Under the function approximation setup where the optimal latent state-action $Q$-function is linear in the state feature, and the optimal $Q$-function has a gap in actions, we provide a \\emph{computationally and statistically efficient} algorithm for finding the \\emph{exact optimal} policy. We show our algorithm's computational and statistical complexities scale polynomially with respect to the horizon and the intrinsic dimension of the feature on the observation space. Furthermore, we show both the deterministic latent transitions and gap assumptions are necessary to avoid statistical complexity exponential in horizon or dimension. Since our guarantee does not have an explicit dependence on the size of the state and observation spaces, our algorithm provably scales to large-scale POMDPs.", "paper_url": "http://arxiv.org/abs/2206.12081v1", "pdf_url": "http://arxiv.org/pdf/2206.12081v1", "repo_url": null}, "2206.13499": {"publish_time": "2022-06-27", "title": "Prompting Decision Transformer for Few-Shot Policy Generalization", "author": "Mengdi Xu et.al.", "abstract": "Humans can leverage prior experience and learn novel tasks from a handful of demonstrations. In contrast to offline meta-reinforcement learning, which aims to achieve quick adaptation through better algorithm design, we investigate the effect of architecture inductive bias on the few-shot learning capability. We propose a Prompt-based Decision Transformer (Prompt-DT), which leverages the sequential modeling ability of the Transformer architecture and the prompt framework to achieve few-shot adaptation in offline RL. We design the trajectory prompt, which contains segments of the few-shot demonstrations, and encodes task-specific information to guide policy generation. Our experiments in five MuJoCo control benchmarks show that Prompt-DT is a strong few-shot learner without any extra finetuning on unseen target tasks. Prompt-DT outperforms its variants and strong meta offline RL baselines by a large margin with a trajectory prompt containing only a few timesteps. Prompt-DT is also robust to prompt length changes and can generalize to out-of-distribution (OOD) environments.", "paper_url": "http://arxiv.org/abs/2206.13499v1", "pdf_url": "http://arxiv.org/pdf/2206.13499v1", "repo_url": null}, "2206.13464": {"publish_time": "2022-06-27", "title": "When to Trust Your Simulator: Dynamics-Aware Hybrid Offline-and-Online Reinforcement Learning", "author": "Haoyi Niu et.al.", "abstract": "Learning effective reinforcement learning (RL) policies to solve real-world complex tasks can be quite challenging without a high-fidelity simulation environment. In most cases, we are only given imperfect simulators with simplified dynamics, which inevitably lead to severe sim-to-real gaps in RL policy learning. The recently emerged field of offline RL provides another possibility to learn policies directly from pre-collected historical data. However, to achieve reasonable performance, existing offline RL algorithms need impractically large offline data with sufficient state-action space coverage for training. This brings up a new question: is it possible to combine learning from limited real data in offline RL and unrestricted exploration through imperfect simulators in online RL to address the drawbacks of both approaches? In this study, we propose the Dynamics-Aware Hybrid Offline-and-Online Reinforcement Learning (H2O) framework to provide an affirmative answer to this question. H2O introduces a dynamics-aware policy evaluation scheme, which adaptively penalizes the Q function learning on simulated state-action pairs with large dynamics gaps, while also simultaneously allowing learning from a fixed real-world dataset. Through extensive simulation and real-world tasks, as well as theoretical analysis, we demonstrate the superior performance of H2O against other cross-domain online and offline RL algorithms. H2O provides a brand new hybrid offline-and-online RL paradigm, which can potentially shed light on future RL algorithm design for solving practical real-world tasks.", "paper_url": "http://arxiv.org/abs/2206.13464v1", "pdf_url": "http://arxiv.org/pdf/2206.13464v1", "repo_url": "https://github.com/t6-thu/H2O"}, "2206.13452": {"publish_time": "2022-06-27", "title": "Causal Dynamics Learning for Task-Independent State Abstraction", "author": "Zizhao Wang et.al.", "abstract": "Learning dynamics models accurately is an important goal for Model-Based Reinforcement Learning (MBRL), but most MBRL methods learn a dense dynamics model which is vulnerable to spurious correlations and therefore generalizes poorly to unseen states. In this paper, we introduce Causal Dynamics Learning for Task-Independent State Abstraction (CDL), which first learns a theoretically proved causal dynamics model that removes unnecessary dependencies between state variables and the action, thus generalizing well to unseen states. A state abstraction can then be derived from the learned dynamics, which not only improves sample efficiency but also applies to a wider range of tasks than existing state abstraction methods. Evaluated on two simulated environments and downstream tasks, both the dynamics model and policies learned by the proposed method generalize well to unseen states and the derived state abstraction improves sample efficiency compared to learning without it.", "paper_url": "http://arxiv.org/abs/2206.13452v1", "pdf_url": "http://arxiv.org/pdf/2206.13452v1", "repo_url": null}, "2206.13448": {"publish_time": "2022-06-27", "title": "Distinguishing Learning Rules with Brain Machine Interfaces", "author": "Jacob P. Portes et.al.", "abstract": "Despite extensive theoretical work on biologically plausible learning rules, it has been difficult to obtain clear evidence about whether and how such rules are implemented in the brain. We consider biologically plausible supervised- and reinforcement-learning rules and ask whether changes in network activity during learning can be used to determine which learning rule is being used. Supervised learning requires a credit-assignment model estimating the mapping from neural activity to behavior, and, in a biological organism, this model will inevitably be an imperfect approximation of the ideal mapping, leading to a bias in the direction of the weight updates relative to the true gradient. Reinforcement learning, on the other hand, requires no credit-assignment model and tends to make weight updates following the true gradient direction. We derive a metric to distinguish between learning rules by observing changes in the network activity during learning, given that the mapping from brain to behavior is known by the experimenter. Because brain-machine interface (BMI) experiments allow for perfect knowledge of this mapping, we focus on modeling a cursor-control BMI task using recurrent neural networks, showing that learning rules can be distinguished in simulated experiments using only observations that a neuroscience experimenter would plausibly have access to.", "paper_url": "http://arxiv.org/abs/2206.13448v1", "pdf_url": "http://arxiv.org/pdf/2206.13448v1", "repo_url": null}, "2206.13441": {"publish_time": "2022-06-27", "title": "EMVLight: a Multi-agent Reinforcement Learning Framework for an Emergency Vehicle Decentralized Routing and Traffic Signal Control System", "author": "Haoran Su et.al.", "abstract": "Emergency vehicles (EMVs) play a crucial role in responding to time-critical calls such as medical emergencies and fire outbreaks in urban areas. Existing methods for EMV dispatch typically optimize routes based on historical traffic-flow data and design traffic signal pre-emption accordingly; however, we still lack a systematic methodology to address the coupling between EMV routing and traffic signal control. In this paper, we propose EMVLight, a decentralized reinforcement learning (RL) framework for joint dynamic EMV routing and traffic signal pre-emption. We adopt the multi-agent advantage actor-critic method with policy sharing and spatial discounted factor. This framework addresses the coupling between EMV navigation and traffic signal control via an innovative design of multi-class RL agents and a novel pressure-based reward function. The proposed methodology enables EMVLight to learn network-level cooperative traffic signal phasing strategies that not only reduce EMV travel time but also shortens the travel time of non-EMVs. Simulation-based experiments indicate that EMVLight enables up to a $42.6\\%$ reduction in EMV travel time as well as an $23.5\\%$ shorter average travel time compared with existing approaches.", "paper_url": "http://arxiv.org/abs/2206.13441v1", "pdf_url": "http://arxiv.org/pdf/2206.13441v1", "repo_url": null}, "2206.14191": {"publish_time": "2022-06-28", "title": "Zero-Shot Building Control", "author": "Scott R. Jeen et.al.", "abstract": "Heating and cooling systems in buildings account for 31% of global energy use, much of which are regulated by Rule Based Controllers (RBCs) that neither maximise energy efficiency nor minimise emissions by interacting optimally with the grid. Control via Reinforcement Learning (RL) has been shown to significantly improve building energy efficiency, but existing solutions require pre-training in simulators that are prohibitively expensive to obtain for every building in the world. In response, we show it is possible to perform safe, zero-shot control of buildings by combining ideas from system identification and model-based RL. We call this combination PEARL (Probabilistic Emission-Abating Reinforcement Learning) and show it reduces emissions without pre-training, needing only a three hour commissioning period. In experiments across three varied building energy simulations, we show PEARL outperforms an existing RBC once, and popular RL baselines in all cases, reducing building emissions by as much as 31% whilst maintaining thermal comfort.", "paper_url": "http://arxiv.org/abs/2206.14191v1", "pdf_url": "http://arxiv.org/pdf/2206.14191v1", "repo_url": null}, "2206.14176": {"publish_time": "2022-06-28", "title": "DayDreamer: World Models for Physical Robot Learning", "author": "Philipp Wu et.al.", "abstract": "To solve tasks in complex environments, robots need to learn from experience. Deep reinforcement learning is a common approach to robot learning but requires a large amount of trial and error to learn, limiting its deployment in the physical world. As a consequence, many advances in robot learning rely on simulators. On the other hand, learning inside of simulators fails to capture the complexity of the real world, is prone to simulator inaccuracies, and the resulting behaviors do not adapt to changes in the world. The Dreamer algorithm has recently shown great promise for learning from small amounts of interaction by planning within a learned world model, outperforming pure reinforcement learning in video games. Learning a world model to predict the outcomes of potential actions enables planning in imagination, reducing the amount of trial and error needed in the real environment. However, it is unknown whether Dreamer can facilitate faster learning on physical robots. In this paper, we apply Dreamer to 4 robots to learn online and directly in the real world, without simulators. Dreamer trains a quadruped robot to roll off its back, stand up, and walk from scratch and without resets in only 1 hour. We then push the robot and find that Dreamer adapts within 10 minutes to withstand perturbations or quickly roll over and stand back up. On two different robotic arms, Dreamer learns to pick and place multiple objects directly from camera images and sparse rewards, approaching human performance. On a wheeled robot, Dreamer learns to navigate to a goal position purely from camera images, automatically resolving ambiguity about the robot orientation. Using the same hyperparameters across all experiments, we find that Dreamer is capable of online learning in the real world, establishing a strong baseline. We release our infrastructure for future applications of world models to robot learning.", "paper_url": "http://arxiv.org/abs/2206.14176v1", "pdf_url": "http://arxiv.org/pdf/2206.14176v1", "repo_url": null}, "2206.14170": {"publish_time": "2022-06-28", "title": "Risk Perspective Exploration in Distributional Reinforcement Learning", "author": "Jihwan Oh et.al.", "abstract": "Distributional reinforcement learning demonstrates state-of-the-art performance in continuous and discrete control settings with the features of variance and risk, which can be used to explore. However, the exploration method employing the risk property is hard to find, although numerous exploration methods in Distributional RL employ the variance of return distribution per action. In this paper, we present risk scheduling approaches that explore risk levels and optimistic behaviors from a risk perspective. We demonstrate the performance enhancement of the DMIX algorithm using risk scheduling in a multi-agent setting with comprehensive experiments.", "paper_url": "http://arxiv.org/abs/2206.14170v1", "pdf_url": "http://arxiv.org/pdf/2206.14170v1", "repo_url": null}, "2206.14155": {"publish_time": "2022-06-28", "title": "Position-Agnostic Autonomous Navigation in Vineyards with Deep Reinforcement Learning", "author": "Mauro Martini et.al.", "abstract": "Precision agriculture is rapidly attracting research to efficiently introduce automation and robotics solutions to support agricultural activities. Robotic navigation in vineyards and orchards offers competitive advantages in autonomously monitoring and easily accessing crops for harvesting, spraying and performing time-consuming necessary tasks. Nowadays, autonomous navigation algorithms exploit expensive sensors which also require heavy computational cost for data processing. Nonetheless, vineyard rows represent a challenging outdoor scenario where GPS and Visual Odometry techniques often struggle to provide reliable positioning information. In this work, we combine Edge AI with Deep Reinforcement Learning to propose a cutting-edge lightweight solution to tackle the problem of autonomous vineyard navigation without exploiting precise localization data and overcoming task-tailored algorithms with a flexible learning-based approach. We train an end-to-end sensorimotor agent which directly maps noisy depth images and position-agnostic robot state information to velocity commands and guides the robot to the end of a row, continuously adjusting its heading for a collision-free central trajectory. Our extensive experimentation in realistic simulated vineyards demonstrates the effectiveness of our solution and the generalization capabilities of our agent.", "paper_url": "http://arxiv.org/abs/2206.14155v1", "pdf_url": "http://arxiv.org/pdf/2206.14155v1", "repo_url": null}, "2206.14057": {"publish_time": "2022-06-28", "title": "Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-free RL", "author": "Ruiquan Huang et.al.", "abstract": "While the primary goal of the exploration phase in reward-free reinforcement learning (RF-RL) is to reduce the uncertainty in the estimated model with minimum number of trajectories, in practice, the agent often needs to abide by certain safety constraint at the same time. It remains unclear how such safe exploration requirement would affect the corresponding sample complexity to achieve the desired optimality of the obtained policy in planning. In this work, we make a first attempt to answer this question. In particular, we consider the scenario where a safe baseline policy is known beforehand, and propose a unified Safe reWard-frEe ExploraTion (SWEET) framework. We then particularize the SWEET framework to the tabular and the low-rank MDP settings, and develop algorithms coined Tabular-SWEET and Low-rank-SWEET, respectively. Both algorithms leverage the concavity and continuity of the newly introduced truncated value functions, and are guaranteed to achieve zero constraint violation during exploration with high probability. Furthermore, both algorithms can provably find a near-optimal policy subject to any constraint in the planning phase. Remarkably, the sample complexities under both algorithms match or even outperform the state of the art in their constraint-free counterparts up to some constant factors, proving that safety constraint hardly increases the sample complexity for RF-RL.", "paper_url": "http://arxiv.org/abs/2206.14057v1", "pdf_url": "http://arxiv.org/pdf/2206.14057v1", "repo_url": null}, "2206.14666": {"publish_time": "2022-06-29", "title": "Conditionally Elicitable Dynamic Risk Measures for Deep Reinforcement Learning", "author": "Anthony Coache et.al.", "abstract": "We propose a novel framework to solve risk-sensitive reinforcement learning (RL) problems where the agent optimises time-consistent dynamic spectral risk measures. Based on the notion of conditional elicitability, our methodology constructs (strictly consistent) scoring functions that are used as penalizers in the estimation procedure. Our contribution is threefold: we (i) devise an efficient approach to estimate a class of dynamic spectral risk measures with deep neural networks, (ii) prove that these dynamic spectral risk measures may be approximated to any arbitrary accuracy using deep neural networks, and (iii) develop a risk-sensitive actor-critic algorithm that uses full episodes and does not require any additional nested transitions. We compare our conceptually improved reinforcement learning algorithm with the nested simulation approach and illustrate its performance in two settings: statistical arbitrage and portfolio allocation on both simulated and real data.", "paper_url": "http://arxiv.org/abs/2206.14666v1", "pdf_url": "http://arxiv.org/pdf/2206.14666v1", "repo_url": "https://github.com/acoache/rl-elicitabledynamicrisk"}, "2206.14661": {"publish_time": "2022-06-29", "title": "Online vs. Offline Adaptive Domain Randomization Benchmark", "author": "Gabriele Tiboni et.al.", "abstract": "Physics simulators have shown great promise for conveniently learning reinforcement learning policies in safe, unconstrained environments. However, transferring the acquired knowledge to the real world can be challenging due to the reality gap. To this end, several methods have been recently proposed to automatically tune simulator parameters with posterior distributions given real data, for use with domain randomization at training time. These approaches have been shown to work for various robotic tasks under different settings and assumptions. Nevertheless, existing literature lacks a thorough comparison of existing adaptive domain randomization methods with respect to transfer performance and real-data efficiency. In this work, we present an open benchmark for both offline and online methods (SimOpt, BayRn, DROID, DROPO), to shed light on which are most suitable for each setting and task at hand. We found that online methods are limited by the quality of the currently learned policy for the next iteration, while offline methods may sometimes fail when replaying trajectories in simulation with open-loop commands. The code used will be released at https://github.com/gabrieletiboni/adr-benchmark.", "paper_url": "http://arxiv.org/abs/2206.14661v1", "pdf_url": "http://arxiv.org/pdf/2206.14661v1", "repo_url": null}, "2206.14468": {"publish_time": "2022-06-29", "title": "Minimalist and High-performance Conversational Recommendation with Uncertainty Estimation for User Preference", "author": "Yinan Zhang et.al.", "abstract": "Conversational recommendation system (CRS) is emerging as a user-friendly way to capture users' dynamic preferences over candidate items and attributes. Multi-shot CRS is designed to make recommendations multiple times until the user either accepts the recommendation or leaves at the end of their patience. Existing works are trained with reinforcement learning (RL), which may suffer from unstable learning and prohibitively high demands for computing. In this work, we propose a simple and efficient CRS, MInimalist Non-reinforced Interactive COnversational Recommender Network (MINICORN). MINICORN models the epistemic uncertainty of the estimated user preference and queries the user for the attribute with the highest uncertainty. The system employs a simple network architecture and makes the query-vs-recommendation decision using a single rule. Somewhat surprisingly, this minimalist approach outperforms state-of-the-art RL methods on three real-world datasets by large margins. We hope that MINICORN will serve as a valuable baseline for future research.", "paper_url": "http://arxiv.org/abs/2206.14468v1", "pdf_url": "http://arxiv.org/pdf/2206.14468v1", "repo_url": null}, "2206.14420": {"publish_time": "2022-06-29", "title": "Robust optimization for quantum reinforcement learning control using partial observations", "author": "Chen Jiang et.al.", "abstract": "The current quantum reinforcement learning control models often assume that the quantum states are known a priori for control optimization. However, full observation of quantum state is experimentally infeasible due to the exponential scaling of the number of required quantum measurements on the number of qubits. In this paper, we investigate a robust reinforcement learning method using partial observations to overcome this difficulty. This control scheme is compatible with near-term quantum devices, where the noise is prevalent and predetermining the dynamics of quantum state is practically impossible. We show that this simplified control scheme can achieve similar or even better performance when compared to the conventional methods relying on full observation. We demonstrate the effectiveness of this scheme on examples of quantum state control and quantum approximate optimization algorithm. It has been shown that high-fidelity state control can be achieved even if the noise amplitude is at the same level as the control amplitude. Besides, an acceptable level of optimization accuracy can be achieved for QAOA with noisy control Hamiltonian. This robust control optimization model can be trained to compensate the uncertainties in practical quantum computing.", "paper_url": "http://arxiv.org/abs/2206.14420v1", "pdf_url": "http://arxiv.org/pdf/2206.14420v1", "repo_url": null}, "2206.14359": {"publish_time": "2022-06-29", "title": "TE2Rules: Extracting Rule Lists from Tree Ensembles", "author": "G Roshan Lal et.al.", "abstract": "Tree Ensemble (TE) models (e.g. Gradient Boosted Trees and Random Forests) often provide higher prediction performance compared to single decision trees. However, TE models generally lack transparency and interpretability, as humans have difficulty understanding their decision logic. This paper presents a novel approach to convert a TE trained for a binary classification task, to a rule list (RL) that is a global equivalent to the TE and is comprehensible for a human. This RL captures all necessary and sufficient conditions for decision making by the TE. Experiments on benchmark datasets demonstrate that, compared to state-of-the-art methods, (i) predictions from the RL generated by TE2Rules have high fidelity with respect to the original TE, (ii) the RL from TE2Rules has high interpretability measured by the number and the length of the decision rules, (iii) the run-time of TE2Rules algorithm can be reduced significantly at the cost of a slightly lower fidelity, and (iv) the RL is a fast alternative to the state-of-the-art rule-based instance-level outcome explanation techniques.", "paper_url": "http://arxiv.org/abs/2206.14359v1", "pdf_url": "http://arxiv.org/pdf/2206.14359v1", "repo_url": "https://github.com/groshanlal/te2rules"}, "2206.15478": {"publish_time": "2022-06-30", "title": "On the Learning and Learnablity of Quasimetrics", "author": "Tongzhou Wang et.al.", "abstract": "Our world is full of asymmetries. Gravity and wind can make reaching a place easier than coming back. Social artifacts such as genealogy charts and citation graphs are inherently directed. In reinforcement learning and control, optimal goal-reaching strategies are rarely reversible (symmetrical). Distance functions supported on these asymmetrical structures are called quasimetrics. Despite their common appearance, little research has been done on the learning of quasimetrics.   Our theoretical analysis reveals that a common class of learning algorithms, including unconstrained multilayer perceptrons (MLPs), provably fails to learn a quasimetric consistent with training data. In contrast, our proposed Poisson Quasimetric Embedding (PQE) is the first quasimetric learning formulation that both is learnable with gradient-based optimization and enjoys strong performance guarantees. Experiments on random graphs, social graphs, and offline Q-learning demonstrate its effectiveness over many common baselines.", "paper_url": "http://arxiv.org/abs/2206.15478v1", "pdf_url": "http://arxiv.org/pdf/2206.15478v1", "repo_url": "https://github.com/ssnl/poisson_quasimetric_embedding"}, "2206.15477": {"publish_time": "2022-06-30", "title": "Denoised MDPs: Learning World Models Better Than the World Itself", "author": "Tongzhou Wang et.al.", "abstract": "The ability to separate signal from noise, and reason with clean abstractions, is critical to intelligence. With this ability, humans can efficiently perform real world tasks without considering all possible nuisance factors.How can artificial agents do the same? What kind of information can agents safely discard as noises?   In this work, we categorize information out in the wild into four types based on controllability and relation with reward, and formulate useful information as that which is both controllable and reward-relevant. This framework clarifies the kinds information removed by various prior work on representation learning in reinforcement learning (RL), and leads to our proposed approach of learning a Denoised MDP that explicitly factors out certain noise distractors. Extensive experiments on variants of DeepMind Control Suite and RoboDesk demonstrate superior performance of our denoised world model over using raw observations alone, and over prior works, across policy optimization control tasks as well as the non-control task of joint position regression.", "paper_url": "http://arxiv.org/abs/2206.15477v1", "pdf_url": "http://arxiv.org/pdf/2206.15477v1", "repo_url": "https://github.com/facebookresearch/denoised_mdp"}, "2206.15475": {"publish_time": "2022-06-30", "title": "Causal Machine Learning: A Survey and Open Problems", "author": "Jean Kaddour et.al.", "abstract": "Causal Machine Learning (CausalML) is an umbrella term for machine learning methods that formalize the data-generation process as a structural causal model (SCM). This allows one to reason about the effects of changes to this process (i.e., interventions) and what would have happened in hindsight (i.e., counterfactuals). We categorize work in \\causalml into five groups according to the problems they tackle: (1) causal supervised learning, (2) causal generative modeling, (3) causal explanations, (4) causal fairness, (5) causal reinforcement learning. For each category, we systematically compare its methods and point out open problems. Further, we review modality-specific applications in computer vision, natural language processing, and graph representation learning. Finally, we provide an overview of causal benchmarks and a critical discussion of the state of this nascent field, including recommendations for future work.", "paper_url": "http://arxiv.org/abs/2206.15475v1", "pdf_url": "http://arxiv.org/pdf/2206.15475v1", "repo_url": null}, "2206.15469": {"publish_time": "2022-06-30", "title": "Watch and Match: Supercharging Imitation with Regularized Optimal Transport", "author": "Siddhant Haldar et.al.", "abstract": "Imitation learning holds tremendous promise in learning policies efficiently for complex decision making problems. Current state-of-the-art algorithms often use inverse reinforcement learning (IRL), where given a set of expert demonstrations, an agent alternatively infers a reward function and the associated optimal policy. However, such IRL approaches often require substantial online interactions for complex control problems. In this work, we present Regularized Optimal Transport (ROT), a new imitation learning algorithm that builds on recent advances in optimal transport based trajectory-matching. Our key technical insight is that adaptively combining trajectory-matching rewards with behavior cloning can significantly accelerate imitation even with only a few demonstrations. Our experiments on 20 visual control tasks across the DeepMind Control Suite, the OpenAI Robotics Suite, and the Meta-World Benchmark demonstrate an average of 7.8X faster imitation to reach 90% of expert performance compared to prior state-of-the-art methods. On real-world robotic manipulation, with just one demonstration and an hour of online training, ROT achieves an average success rate of 90.1% across 14 tasks.", "paper_url": "http://arxiv.org/abs/2206.15469v1", "pdf_url": "http://arxiv.org/pdf/2206.15469v1", "repo_url": null}, "2206.15378": {"publish_time": "2022-06-30", "title": "Mastering the Game of Stratego with Model-Free Multiagent Reinforcement Learning", "author": "Julien Perolat et.al.", "abstract": "We introduce DeepNash, an autonomous agent capable of learning to play the imperfect information game Stratego from scratch, up to a human expert level. Stratego is one of the few iconic board games that Artificial Intelligence (AI) has not yet mastered. This popular game has an enormous game tree on the order of $10^{535}$ nodes, i.e., $10^{175}$ times larger than that of Go. It has the additional complexity of requiring decision-making under imperfect information, similar to Texas hold'em poker, which has a significantly smaller game tree (on the order of $10^{164}$ nodes). Decisions in Stratego are made over a large number of discrete actions with no obvious link between action and outcome. Episodes are long, with often hundreds of moves before a player wins, and situations in Stratego can not easily be broken down into manageably-sized sub-problems as in poker. For these reasons, Stratego has been a grand challenge for the field of AI for decades, and existing AI methods barely reach an amateur level of play. DeepNash uses a game-theoretic, model-free deep reinforcement learning method, without search, that learns to master Stratego via self-play. The Regularised Nash Dynamics (R-NaD) algorithm, a key component of DeepNash, converges to an approximate Nash equilibrium, instead of 'cycling' around it, by directly modifying the underlying multi-agent learning dynamics. DeepNash beats existing state-of-the-art AI methods in Stratego and achieved a yearly (2022) and all-time top-3 rank on the Gravon games platform, competing with human expert players.", "paper_url": "http://arxiv.org/abs/2206.15378v1", "pdf_url": "http://arxiv.org/pdf/2206.15378v1", "repo_url": null}, "2207.00492": {"publish_time": "2022-07-01", "title": "Reinforcement Learning Based User-Guided Motion Planning for Human-Robot Collaboration", "author": "Tian Yu et.al.", "abstract": "Robots are good at performing repetitive tasks in modern manufacturing industries. However, robot motions are mostly planned and preprogrammed with a notable lack of adaptivity to task changes. Even for slightly changed tasks, the whole system must be reprogrammed by robotics experts. Therefore, it is highly desirable to have a flexible motion planning method, with which robots can adapt to specific task changes in unstructured environments, such as production systems or warehouses, with little or no intervention from non-expert personnel. In this paper, we propose a user-guided motion planning algorithm in combination with the reinforcement learning (RL) method to enable robots automatically generate their motion plans for new tasks by learning from a few kinesthetic human demonstrations. To achieve adaptive motion plans for a specific application environment, e.g., desk assembly or warehouse loading/unloading, a library is built by abstracting features of common human demonstrated tasks. The definition of semantical similarity between features in the library and features of a new task is proposed and further used to construct the reward function in RL. The RL policy can automatically generate motion plans for a new task if it determines that new task constraints can be satisfied with the current library and request additional human demonstrations. Multiple experiments conducted on common tasks and scenarios demonstrate that the proposed user-guided RL-assisted motion planning method is effective.", "paper_url": "http://arxiv.org/abs/2207.00492v1", "pdf_url": "http://arxiv.org/pdf/2207.00492v1", "repo_url": null}, "2207.00475": {"publish_time": "2022-07-01", "title": "Agent with Tangent-based Formulation and Anatomical Perception for Standard Plane Localization in 3D Ultrasound", "author": "Yuxin Zou et.al.", "abstract": "Standard plane (SP) localization is essential in routine clinical ultrasound (US) diagnosis. Compared to 2D US, 3D US can acquire multiple view planes in one scan and provide complete anatomy with the addition of coronal plane. However, manually navigating SPs in 3D US is laborious and biased due to the orientation variability and huge search space. In this study, we introduce a novel reinforcement learning (RL) framework for automatic SP localization in 3D US. Our contribution is three-fold. First, we formulate SP localization in 3D US as a tangent-point-based problem in RL to restructure the action space and significantly reduce the search space. Second, we design an auxiliary task learning strategy to enhance the model's ability to recognize subtle differences crossing Non-SPs and SPs in plane search. Finally, we propose a spatial-anatomical reward to effectively guide learning trajectories by exploiting spatial and anatomical information simultaneously. We explore the efficacy of our approach on localizing four SPs on uterus and fetal brain datasets. The experiments indicate that our approach achieves a high localization accuracy as well as robust performance.", "paper_url": "http://arxiv.org/abs/2207.00475v1", "pdf_url": "http://arxiv.org/pdf/2207.00475v1", "repo_url": null}, "2207.00468": {"publish_time": "2022-07-01", "title": "Reinforcement Learning of Multi-Domain Dialog Policies Via Action Embeddings", "author": "Jorge A. Mendez et.al.", "abstract": "Learning task-oriented dialog policies via reinforcement learning typically requires large amounts of interaction with users, which in practice renders such methods unusable for real-world applications. In order to reduce the data requirements, we propose to leverage data from across different dialog domains, thereby reducing the amount of data required from each given domain. In particular, we propose to learn domain-agnostic action embeddings, which capture general-purpose structure that informs the system how to act given the current dialog context, and are then specialized to a specific domain. We show how this approach is capable of learning with significantly less interaction with users, with a reduction of 35% in the number of dialogs required to learn, and to a higher level of proficiency than training separate policies for each domain on a set of simulated domains.", "paper_url": "http://arxiv.org/abs/2207.00468v1", "pdf_url": "http://arxiv.org/pdf/2207.00468v1", "repo_url": null}, "2207.00461": {"publish_time": "2022-07-01", "title": "Lifelong Inverse Reinforcement Learning", "author": "Jorge A. Mendez et.al.", "abstract": "Methods for learning from demonstration (LfD) have shown success in acquiring behavior policies by imitating a user. However, even for a single task, LfD may require numerous demonstrations. For versatile agents that must learn many tasks via demonstration, this process would substantially burden the user if each task were learned in isolation. To address this challenge, we introduce the novel problem of lifelong learning from demonstration, which allows the agent to continually build upon knowledge learned from previously demonstrated tasks to accelerate the learning of new tasks, reducing the amount of demonstrations required. As one solution to this problem, we propose the first lifelong learning approach to inverse reinforcement learning, which learns consecutive tasks via demonstration, continually transferring knowledge between tasks to improve performance.", "paper_url": "http://arxiv.org/abs/2207.00461v1", "pdf_url": "http://arxiv.org/pdf/2207.00461v1", "repo_url": "https://github.com/lifelong-ml/elirl"}, "2207.00448": {"publish_time": "2022-07-01", "title": "Safe Decision-making for Lane-change of Autonomous Vehicles via Human Demonstration-aided Reinforcement Learning", "author": "Jingda Wu et.al.", "abstract": "Decision-making is critical for lane change in autonomous driving. Reinforcement learning (RL) algorithms aim to identify the values of behaviors in various situations and thus they become a promising pathway to address the decision-making problem. However, poor runtime safety hinders RL-based decision-making strategies from complex driving tasks in practice. To address this problem, human demonstrations are incorporated into the RL-based decision-making strategy in this paper. Decisions made by human subjects in a driving simulator are treated as safe demonstrations, which are stored into the replay buffer and then utilized to enhance the training process of RL. A complex lane change task in an off-ramp scenario is established to examine the performance of the developed strategy. Simulation results suggest that human demonstrations can effectively improve the safety of decisions of RL. And the proposed strategy surpasses other existing learning-based decision-making strategies with respect to multiple driving performances.", "paper_url": "http://arxiv.org/abs/2207.00448v1", "pdf_url": "http://arxiv.org/pdf/2207.00448v1", "repo_url": null}, "2207.01613": {"publish_time": "2022-07-04", "title": "Doubly-Asynchronous Value Iteration: Making Value Iteration Asynchronous in Actions", "author": "Tian Tian et.al.", "abstract": "Value iteration (VI) is a foundational dynamic programming method, important for learning and planning in optimal control and reinforcement learning. VI proceeds in batches, where the update to the value of each state must be completed before the next batch of updates can begin. Completing a single batch is prohibitively expensive if the state space is large, rendering VI impractical for many applications. Asynchronous VI helps to address the large state space problem by updating one state at a time, in-place and in an arbitrary order. However, Asynchronous VI still requires a maximization over the entire action space, making it impractical for domains with large action space. To address this issue, we propose doubly-asynchronous value iteration (DAVI), a new algorithm that generalizes the idea of asynchrony from states to states and actions. More concretely, DAVI maximizes over a sampled subset of actions that can be of any user-defined size. This simple approach of using sampling to reduce computation maintains similarly appealing theoretical properties to VI without the need to wait for a full sweep through the entire action space in each update. In this paper, we show DAVI converges to the optimal value function with probability one, converges at a near-geometric rate with probability 1-delta, and returns a near-optimal policy in computation time that nearly matches a previously established bound for VI. We also empirically demonstrate DAVI's effectiveness in several experiments.", "paper_url": "http://arxiv.org/abs/2207.01613v1", "pdf_url": "http://arxiv.org/pdf/2207.01613v1", "repo_url": null}, "2207.01570": {"publish_time": "2022-07-04", "title": "Goal-Conditioned Generators of Deep Policies", "author": "Francesco Faccio et.al.", "abstract": "Goal-conditioned Reinforcement Learning (RL) aims at learning optimal policies, given goals encoded in special command inputs. Here we study goal-conditioned neural nets (NNs) that learn to generate deep NN policies in form of context-specific weight matrices, similar to Fast Weight Programmers and other methods from the 1990s. Using context commands of the form \"generate a policy that achieves a desired expected return,\" our NN generators combine powerful exploration of parameter space with generalization across commands to iteratively find better and better policies. A form of weight-sharing HyperNetworks and policy embeddings scales our method to generate deep NNs. Experiments show how a single learned policy generator can produce policies that achieve any return seen during training. Finally, we evaluate our algorithm on a set of continuous control tasks where it exhibits competitive performance. Our code is public.", "paper_url": "http://arxiv.org/abs/2207.01570v1", "pdf_url": "http://arxiv.org/pdf/2207.01570v1", "repo_url": null}, "2207.01566": {"publish_time": "2022-07-04", "title": "General Policy Evaluation and Improvement by Learning to Identify Few But Crucial States", "author": "Francesco Faccio et.al.", "abstract": "Learning to evaluate and improve policies is a core problem of Reinforcement Learning (RL). Traditional RL algorithms learn a value function defined for a single policy. A recently explored competitive alternative is to learn a single value function for many policies. Here we combine the actor-critic architecture of Parameter-Based Value Functions and the policy embedding of Policy Evaluation Networks to learn a single value function for evaluating (and thus helping to improve) any policy represented by a deep neural network (NN). The method yields competitive experimental results. In continuous control problems with infinitely many states, our value function minimizes its prediction error by simultaneously learning a small set of `probing states' and a mapping from actions produced in probing states to the policy's return. The method extracts crucial abstract knowledge about the environment in form of very few states sufficient to fully specify the behavior of many policies. A policy improves solely by changing actions in probing states, following the gradient of the value function's predictions. Surprisingly, it is possible to clone the behavior of a near-optimal policy in Swimmer-v3 and Hopper-v3 environments only by knowing how to act in 3 and 5 such learned states, respectively. Remarkably, our value function trained to evaluate NN policies is also invariant to changes of the policy architecture: we show that it allows for zero-shot learning of linear policies competitive with the best policy seen during training. Our code is public.", "paper_url": "http://arxiv.org/abs/2207.01566v1", "pdf_url": "http://arxiv.org/pdf/2207.01566v1", "repo_url": null}, "2207.01443": {"publish_time": "2022-07-04", "title": "Solving the Traveling Salesperson Problem with Precedence Constraints by Deep Reinforcement Learning", "author": "Christian L\u00f6wens et.al.", "abstract": "This work presents solutions to the Traveling Salesperson Problem with precedence constraints (TSPPC) using Deep Reinforcement Learning (DRL) by adapting recent approaches that work well for regular TSPs. Common to these approaches is the use of graph models based on multi-head attention (MHA) layers. One idea for solving the pickup and delivery problem (PDP) is using heterogeneous attentions to embed the different possible roles each node can take. In this work, we generalize this concept of heterogeneous attentions to the TSPPC. Furthermore, we adapt recent ideas to sparsify attentions for better scalability. Overall, we contribute to the research community through the application and evaluation of recent DRL methods in solving the TSPPC.", "paper_url": "http://arxiv.org/abs/2207.01443v1", "pdf_url": "http://arxiv.org/pdf/2207.01443v1", "repo_url": "https://github.com/christianll9/tsppc-drl"}, "2207.01337": {"publish_time": "2022-07-04", "title": "Safe Reinforcement Learning via Confidence-Based Filters", "author": "Sebastian Curi et.al.", "abstract": "Ensuring safety is a crucial challenge when deploying reinforcement learning (RL) to real-world systems. We develop confidence-based safety filters, a control-theoretic approach for certifying state safety constraints for nominal policies learned via standard RL techniques, based on probabilistic dynamics models. Our approach is based on a reformulation of state constraints in terms of cost functions, reducing safety verification to a standard RL task. By exploiting the concept of hallucinating inputs, we extend this formulation to determine a \"backup\" policy that is safe for the unknown system with high probability. Finally, the nominal policy is minimally adjusted at every time step during a roll-out towards the backup policy, such that safe recovery can be guaranteed afterwards. We provide formal safety guarantees, and empirically demonstrate the effectiveness of our approach.", "paper_url": "http://arxiv.org/abs/2207.01337v1", "pdf_url": "http://arxiv.org/pdf/2207.01337v1", "repo_url": null}, "2207.02200": {"publish_time": "2022-07-05", "title": "Offline RL Policies Should be Trained to be Adaptive", "author": "Dibya Ghosh et.al.", "abstract": "Offline RL algorithms must account for the fact that the dataset they are provided may leave many facets of the environment unknown. The most common way to approach this challenge is to employ pessimistic or conservative methods, which avoid behaviors that are too dissimilar from those in the training dataset. However, relying exclusively on conservatism has drawbacks: performance is sensitive to the exact degree of conservatism, and conservative objectives can recover highly suboptimal policies. In this work, we propose that offline RL methods should instead be adaptive in the presence of uncertainty. We show that acting optimally in offline RL in a Bayesian sense involves solving an implicit POMDP. As a result, optimal policies for offline RL must be adaptive, depending not just on the current state but rather all the transitions seen so far during evaluation.We present a model-free algorithm for approximating this optimal adaptive policy, and demonstrate the efficacy of learning such adaptive policies in offline RL benchmarks.", "paper_url": "http://arxiv.org/abs/2207.02200v1", "pdf_url": "http://arxiv.org/pdf/2207.02200v1", "repo_url": null}, "2207.02162": {"publish_time": "2022-07-05", "title": "Tackling Real-World Autonomous Driving using Deep Reinforcement Learning", "author": "Paolo Maramotti et.al.", "abstract": "In the typical autonomous driving stack, planning and control systems represent two of the most crucial components in which data retrieved by sensors and processed by perception algorithms are used to implement a safe and comfortable self-driving behavior. In particular, the planning module predicts the path the autonomous car should follow taking the correct high-level maneuver, while control systems perform a sequence of low-level actions, controlling steering angle, throttle and brake. In this work, we propose a model-free Deep Reinforcement Learning Planner training a neural network that predicts both acceleration and steering angle, thus obtaining a single module able to drive the vehicle using the data processed by localization and perception algorithms on board of the self-driving car. In particular, the system that was fully trained in simulation is able to drive smoothly and safely in obstacle-free environments both in simulation and in a real-world urban area of the city of Parma, proving that the system features good generalization capabilities also driving in those parts outside the training scenarios. Moreover, in order to deploy the system on board of the real self-driving car and to reduce the gap between simulated and real-world performances, we also develop a module represented by a tiny neural network able to reproduce the real vehicle dynamic behavior during the training in simulation.", "paper_url": "http://arxiv.org/abs/2207.02162v1", "pdf_url": "http://arxiv.org/pdf/2207.02162v1", "repo_url": null}, "2207.02099": {"publish_time": "2022-07-05", "title": "An Empirical Study of Implicit Regularization in Deep Offline RL", "author": "Caglar Gulcehre et.al.", "abstract": "Deep neural networks are the most commonly used function approximators in offline Reinforcement Learning these days. Prior works have shown that neural nets trained with TD-learning and gradient descent can exhibit implicit regularization that can be characterized by under-parameterization of these networks. Specifically, the rank of the penultimate feature layer, also called \\textit{effective rank}, has been observed to drastically collapse during the training. In turn, this collapse has been argued to reduce the model's ability to further adapt in later stages of learning, leading to the diminished final performance. Such an association between the effective rank and performance makes effective rank compelling for offline RL, primarily for offline policy evaluation. In this work, we conduct a careful empirical study on the relation between effective rank and performance on three offline RL datasets : bsuite, Atari, and DeepMind lab. We observe that a direct association exists only in restricted settings and disappears in the more extensive hyperparameter sweeps. Also, we empirically identify three phases of learning that explain the impact of implicit regularization on the learning dynamics and found that bootstrapping alone is insufficient to explain the collapse of the effective rank. Further, we show that several other factors could confound the relationship between effective rank and performance and conclude that studying this association under simplistic assumptions could be highly misleading.", "paper_url": "http://arxiv.org/abs/2207.02099v1", "pdf_url": "http://arxiv.org/pdf/2207.02099v1", "repo_url": null}, "2207.02074": {"publish_time": "2022-07-05", "title": "Resource Allocation in Multicore Elastic Optical Networks: A Deep Reinforcement Learning Approach", "author": "Juan Pinto-R\u00edos et.al.", "abstract": "A deep reinforcement learning approach is applied, for the first time, to solve the routing, modulation, spectrum and core allocation (RMSCA) problem in dynamic multicore fiber elastic optical networks (MCF-EONs). To do so, a new environment - compatible with OpenAI's Gym - was designed and implemented to emulate the operation of MCF-EONs. The new environment processes the agent actions (selection of route, core and spectrum slot) by considering the network state and physical-layer-related aspects. The latter includes the available modulation formats and their reach and the inter-core crosstalk (XT), an MCF-related impairment. If the resulting quality of the signal is acceptable, the environment allocates the resources selected by the agent. After processing the agent's action, the environment is configured to give the agent a numerical reward and information about the new network state. The blocking performance of four different agents was compared through simulation to 3 baseline heuristics used in MCF-EONs. Results obtained for the NSFNet and COST239 network topologies show that the best-performing agent achieves, on average, up to a four-times decrease in blocking probability concerning the best-performing baseline heuristic methods.", "paper_url": "http://arxiv.org/abs/2207.02074v1", "pdf_url": "http://arxiv.org/pdf/2207.02074v1", "repo_url": null}, "2207.02016": {"publish_time": "2022-07-05", "title": "Robust Reinforcement Learning in Continuous Control Tasks with Uncertainty Set Regularization", "author": "Yuan Zhang et.al.", "abstract": "Reinforcement learning (RL) is recognized as lacking generalization and robustness under environmental perturbations, which excessively restricts its application for real-world robotics. Prior work claimed that adding regularization to the value function is equivalent to learning a robust policy with uncertain transitions. Although the regularization-robustness transformation is appealing for its simplicity and efficiency, it is still lacking in continuous control tasks. In this paper, we propose a new regularizer named $\\textbf{U}$ncertainty $\\textbf{S}$et $\\textbf{R}$egularizer (USR), by formulating the uncertainty set on the parameter space of the transition function. In particular, USR is flexible enough to be plugged into any existing RL framework. To deal with unknown uncertainty sets, we further propose a novel adversarial approach to generate them based on the value function. We evaluate USR on the Real-world Reinforcement Learning (RWRL) benchmark, demonstrating improvements in the robust performance for perturbed testing environments.", "paper_url": "http://arxiv.org/abs/2207.02016v1", "pdf_url": "http://arxiv.org/pdf/2207.02016v1", "repo_url": null}, "2207.02705": {"publish_time": "2022-07-06", "title": "Incentivizing Proof-of-Stake Blockchain for Secured Data Collection in UAV-Assisted IoT: A Multi-Agent Reinforcement Learning Approach", "author": "Xiao Tang et.al.", "abstract": "The Internet of Things (IoT) can be conveniently deployed while empowering various applications, where the IoT nodes can form clusters to finish certain missions collectively. In this paper, we propose to employ unmanned aerial vehicles (UAVs) to assist the clustered IoT data collection with blockchain-based security provisioning. In particular, the UAVs generate candidate blocks based on the collected data, which are then audited through a lightweight proof-of-stake consensus mechanism within the UAV-based blockchain network. To motivate efficient blockchain while reducing the operational cost, a stake pool is constructed at the active UAV while encouraging stake investment from other UAVs with profit sharing. The problem is formulated to maximize the overall profit through the blockchain system in unit time by jointly investigating the IoT transmission, incentives through investment and profit sharing, and UAV deployment strategies. Then, the problem is solved in a distributed manner while being decoupled into two layers. The inner layer incorporates IoT transmission and incentive design, which are tackled with large-system approximation and one-leader-multi-follower Stackelberg game analysis, respectively. The outer layer for UAV deployment is undertaken with a multi-agent deep deterministic policy gradient approach. Results show the convergence of the proposed learning process and the UAV deployment, and also demonstrated is the performance superiority of our proposal as compared with the baselines.", "paper_url": "http://arxiv.org/abs/2207.02705v1", "pdf_url": "http://arxiv.org/pdf/2207.02705v1", "repo_url": null}, "2207.02575": {"publish_time": "2022-07-06", "title": "Instance-Dependent Near-Optimal Policy Identification in Linear MDPs via Online Experiment Design", "author": "Andrew Wagenmaker et.al.", "abstract": "While much progress has been made in understanding the minimax sample complexity of reinforcement learning (RL) -- the complexity of learning on the \"worst-case\" instance -- such measures of complexity often do not capture the true difficulty of learning. In practice, on an \"easy\" instance, we might hope to achieve a complexity far better than that achievable on the worst-case instance. In this work we seek to understand the \"instance-dependent\" complexity of learning near-optimal policies (PAC RL) in the setting of RL with linear function approximation. We propose an algorithm, \\textsc{Pedel}, which achieves a fine-grained instance-dependent measure of complexity, the first of its kind in the RL with function approximation setting, thereby capturing the difficulty of learning on each particular problem instance. Through an explicit example, we show that \\textsc{Pedel} yields provable gains over low-regret, minimax-optimal algorithms and that such algorithms are unable to hit the instance-optimal rate. Our approach relies on a novel online experiment design-based procedure which focuses the exploration budget on the \"directions\" most relevant to learning a near-optimal policy, and may be of independent interest.", "paper_url": "http://arxiv.org/abs/2207.02575v1", "pdf_url": "http://arxiv.org/pdf/2207.02575v1", "repo_url": null}, "2207.02556": {"publish_time": "2022-07-06", "title": "Deep Learning Approaches to Grasp Synthesis: A Review", "author": "Rhys Newbury et.al.", "abstract": "Grasping is the process of picking an object by applying forces and torques at a set of contacts. Recent advances in deep-learning methods have allowed rapid progress in robotic object grasping. We systematically surveyed the publications over the last decade, with a particular interest in grasping an object using all 6 degrees of freedom of the end-effector pose. Our review found four common methodologies for robotic grasping: sampling-based approaches, direct regression, reinforcement learning, and exemplar approaches. Furthermore, we found two 'supporting methods' around grasping that use deep-learning to support the grasping process, shape approximation, and affordances. We have distilled the publications found in this systematic review (85 papers) into ten key takeaways we consider crucial for future robotic grasping and manipulation research. An online version of the survey is available at https://rhys-newbury.github.io/projects/6dof/", "paper_url": "http://arxiv.org/abs/2207.02556v1", "pdf_url": "http://arxiv.org/pdf/2207.02556v1", "repo_url": null}, "2207.02464": {"publish_time": "2022-07-06", "title": "A Learning System for Motion Planning of Free-Float Dual-Arm Space Manipulator towards Non-Cooperative Object", "author": "Shengjie Wang et.al.", "abstract": "Recent years have seen the emergence of non-cooperative objects in space, like failed satellites and space junk. These objects are usually operated or collected by free-float dual-arm space manipulators. Thanks to eliminating the difficulties of modeling and manual parameter-tuning, reinforcement learning (RL) methods have shown a more promising sign in the trajectory planning of space manipulators. Although previous studies demonstrate their effectiveness, they cannot be applied in tracking dynamic targets with unknown rotation (non-cooperative objects). In this paper, we proposed a learning system for motion planning of free-float dual-arm space manipulator (FFDASM) towards non-cooperative objects. Specifically, our method consists of two modules. Module I realizes the multi-target trajectory planning for two end-effectors within a large target space. Next, Module II takes as input the point clouds of the non-cooperative object to estimate the motional property, and then can predict the position of target points on an non-cooperative object. We leveraged the combination of Module I and Module II to track target points on a spinning object with unknown regularity successfully. Furthermore, the experiments also demonstrate the scalability and generalization of our learning system.", "paper_url": "http://arxiv.org/abs/2207.02464v1", "pdf_url": "http://arxiv.org/pdf/2207.02464v1", "repo_url": "https://github.com/Tsinghua-Space-Robot-Learning-Group/SpaceRobotEnv"}, "2207.02458": {"publish_time": "2022-07-06", "title": "Reinforcement Learning Portfolio Manager Framework with Monte Carlo Simulation", "author": "Jungyu Ahn et.al.", "abstract": "Asset allocation using reinforcement learning has advantages such as flexibility in goal setting and utilization of various information. However, existing asset allocation methods do not consider the following viewpoints in solving the asset allocation problem. First, State design without considering portfolio management and financial market characteristics. Second, Model Overfitting. Third, Model training design without considering the statistical structure of financial time series data. To solve the problem of the existing asset allocation method using reinforcement learning, we propose a new reinforcement learning asset allocation method. First, the state of the portfolio managed by the model is considered as the state of the reinforcement learning agent. Second, Monte Carlo simulation data are used to increase training data complexity to prevent model overfitting. These data can have different patterns, which can increase the complexity of the data. Third, Monte Carlo simulation data are created considering various statistical structures of financial markets. We define the statistical structure of the financial market as the correlation matrix of the assets constituting the financial market. We show experimentally that our method outperforms the benchmark at several test intervals.", "paper_url": "http://arxiv.org/abs/2207.02458v1", "pdf_url": "http://arxiv.org/pdf/2207.02458v1", "repo_url": null}, "2207.03483": {"publish_time": "2022-07-07", "title": "Finding Fallen Objects Via Asynchronous Audio-Visual Integration", "author": "Chuang Gan et.al.", "abstract": "The way an object looks and sounds provide complementary reflections of its physical properties. In many settings cues from vision and audition arrive asynchronously but must be integrated, as when we hear an object dropped on the floor and then must find it. In this paper, we introduce a setting in which to study multi-modal object localization in 3D virtual environments. An object is dropped somewhere in a room. An embodied robot agent, equipped with a camera and microphone, must determine what object has been dropped -- and where -- by combining audio and visual signals with knowledge of the underlying physics. To study this problem, we have generated a large-scale dataset -- the Fallen Objects dataset -- that includes 8000 instances of 30 physical object categories in 64 rooms. The dataset uses the ThreeDWorld platform which can simulate physics-based impact sounds and complex physical interactions between objects in a photorealistic setting. As a first step toward addressing this challenge, we develop a set of embodied agent baselines, based on imitation learning, reinforcement learning, and modular planning, and perform an in-depth analysis of the challenge of this new task.", "paper_url": "http://arxiv.org/abs/2207.03483v1", "pdf_url": "http://arxiv.org/pdf/2207.03483v1", "repo_url": null}, "2207.03470": {"publish_time": "2022-07-07", "title": "For Learning in Symmetric Teams, Local Optima are Global Nash Equilibria", "author": "Scott Emmons et.al.", "abstract": "Although it has been known since the 1970s that a globally optimal strategy profile in a common-payoff game is a Nash equilibrium, global optimality is a strict requirement that limits the result's applicability. In this work, we show that any locally optimal symmetric strategy profile is also a (global) Nash equilibrium. Furthermore, we show that this result is robust to perturbations to the common payoff and to the local optimum. Applied to machine learning, our result provides a global guarantee for any gradient method that finds a local optimum in symmetric strategy space. While this result indicates stability to unilateral deviation, we nevertheless identify broad classes of games where mixed local optima are unstable under joint, asymmetric deviations. We analyze the prevalence of instability by running learning algorithms in a suite of symmetric games, and we conclude by discussing the applicability of our results to multi-agent RL, cooperative inverse RL, and decentralized POMDPs.", "paper_url": "http://arxiv.org/abs/2207.03470v1", "pdf_url": "http://arxiv.org/pdf/2207.03470v1", "repo_url": "https://github.com/scottemmons/coordination"}, "2207.03456": {"publish_time": "2022-07-07", "title": "Stochastic optimal well control in subsurface reservoirs using reinforcement learning", "author": "Atish Dixit et.al.", "abstract": "We present a case study of model-free reinforcement learning (RL) framework to solve stochastic optimal control for a predefined parameter uncertainty distribution and partially observable system. We focus on robust optimal well control problem which is a subject of intensive research activities in the field of subsurface reservoir management. For this problem, the system is partially observed since the data is only available at well locations. Furthermore, the model parameters are highly uncertain due to sparsity of available field data. In principle, RL algorithms are capable of learning optimal action policies -- a map from states to actions -- to maximize a numerical reward signal. In deep RL, this mapping from state to action is parameterized using a deep neural network. In the RL formulation of the robust optimal well control problem, the states are represented by saturation and pressure values at well locations while the actions represent the valve openings controlling the flow through wells. The numerical reward refers to the total sweep efficiency and the uncertain model parameter is the subsurface permeability field. The model parameter uncertainties are handled by introducing a domain randomisation scheme that exploits cluster analysis on its uncertainty distribution. We present numerical results using two state-of-the-art RL algorithms, proximal policy optimization (PPO) and advantage actor-critic (A2C), on two subsurface flow test cases representing two distinct uncertainty distributions of permeability field. The results were benchmarked against optimisation results obtained using differential evolution algorithm. Furthermore, we demonstrate the robustness of the proposed use of RL by evaluating the learned control policy on unseen samples drawn from the parameter uncertainty distribution that were not used during the training process.", "paper_url": "http://arxiv.org/abs/2207.03456v1", "pdf_url": "http://arxiv.org/pdf/2207.03456v1", "repo_url": null}, "2207.03450": {"publish_time": "2022-07-07", "title": "TFCNs: A CNN-Transformer Hybrid Network for Medical Image Segmentation", "author": "Zihan Li et.al.", "abstract": "Medical image segmentation is one of the most fundamental tasks concerning medical information analysis. Various solutions have been proposed so far, including many deep learning-based techniques, such as U-Net, FC-DenseNet, etc. However, high-precision medical image segmentation remains a highly challenging task due to the existence of inherent magnification and distortion in medical images as well as the presence of lesions with similar density to normal tissues. In this paper, we propose TFCNs (Transformers for Fully Convolutional denseNets) to tackle the problem by introducing ResLinear-Transformer (RL-Transformer) and Convolutional Linear Attention Block (CLAB) to FC-DenseNet. TFCNs is not only able to utilize more latent information from the CT images for feature extraction, but also can capture and disseminate semantic features and filter non-semantic features more effectively through the CLAB module. Our experimental results show that TFCNs can achieve state-of-the-art performance with dice scores of 83.72\\% on the Synapse dataset. In addition, we evaluate the robustness of TFCNs for lesion area effects on the COVID-19 public datasets. The Python code will be made publicly available on https://github.com/HUANGLIZI/TFCNs.", "paper_url": "http://arxiv.org/abs/2207.03450v1", "pdf_url": "http://arxiv.org/pdf/2207.03450v1", "repo_url": "https://github.com/huanglizi/tfcns"}, "2207.03449": {"publish_time": "2022-07-07", "title": "Reinforcement Learning for Intra-and-Inter-Bank Borrowing and Lending Mean Field Control Game", "author": "Andrea Angiuli et.al.", "abstract": "We propose a mean field control game model for the intra-and-inter-bank borrowing and lending problem. This framework allows to study the competitive game arising between groups of collaborative banks. The solution is provided in terms of an asymptotic Nash equilibrium between the groups in the infinite horizon. A three-timescale reinforcement learning algorithm is applied to learn the optimal borrowing and lending strategy in a data driven way when the model is unknown. An empirical numerical analysis shows the importance of the three-timescale, the impact of the exploration strategy when the model is unknown, and the convergence of the algorithm.", "paper_url": "http://arxiv.org/abs/2207.03449v1", "pdf_url": "http://arxiv.org/pdf/2207.03449v1", "repo_url": null}}}, "Unsupervised Learning": {"Continual Learning": {"2202.11918": {"publish_time": "2022-02-24", "title": "Phase Continuity: Learning Derivatives of Phase Spectrum for Speech Enhancement", "author": "Doyeon Kim et.al.", "abstract": "Modern neural speech enhancement models usually include various forms of phase information in their training loss terms, either explicitly or implicitly. However, these loss terms are typically designed to reduce the distortion of phase spectrum values at specific frequencies, which ensures they do not significantly affect the quality of the enhanced speech. In this paper, we propose an effective phase reconstruction strategy for neural speech enhancement that can operate in noisy environments. Specifically, we introduce a phase continuity loss that considers relative phase variations across the time and frequency axes. By including this phase continuity loss in a state-of-the-art neural speech enhancement system trained with reconstruction loss and a number of magnitude spectral losses, we show that our proposed method further improves the quality of enhanced speech signals over the baseline, especially when training is done jointly with a magnitude spectrum loss.", "paper_url": "http://arxiv.org/abs/2202.11918v1", "pdf_url": "http://arxiv.org/pdf/2202.11918v1", "repo_url": null}, "2202.11295": {"publish_time": "2022-02-23", "title": "Continual learning-based probabilistic slow feature analysis for multimode dynamic process monitoring", "author": "Jingxin Zhang et.al.", "abstract": "In this paper, a novel multimode dynamic process monitoring approach is proposed by extending elastic weight consolidation (EWC) to probabilistic slow feature analysis (PSFA) in order to extract multimode slow features for online monitoring. EWC was originally introduced in the setting of machine learning of sequential multi-tasks with the aim of avoiding catastrophic forgetting issue, which equally poses as a major challenge in multimode dynamic process monitoring. When a new mode arrives, a set of data should be collected so that this mode can be identified by PSFA and prior knowledge. Then, a regularization term is introduced to prevent new data from significantly interfering with the learned knowledge, where the parameter importance measures are estimated. The proposed method is denoted as PSFA-EWC, which is updated continually and capable of achieving excellent performance for successive modes. Different from traditional multimode monitoring algorithms, PSFA-EWC furnishes backward and forward transfer ability. The significant features of previous modes are retained while consolidating new information, which may contribute to learning new relevant modes. Compared with several known methods, the effectiveness of the proposed method is demonstrated via a continuous stirred tank heater and a practical coal pulverizing system.", "paper_url": "http://arxiv.org/abs/2202.11295v1", "pdf_url": "http://arxiv.org/pdf/2202.11295v1", "repo_url": null}, "2202.10821": {"publish_time": "2022-02-22", "title": "Increasing Depth of Neural Networks for Life-long Learning", "author": "J\u0119drzej Kozal et.al.", "abstract": "Increasing neural network depth is a well-known method for improving neural network performance. Modern deep architectures contain multiple mechanisms that allow hundreds or even thousands of layers to train. This work is trying to answer if extending neural network depth may be beneficial in a life-long learning setting. In particular, we propose a novel method based on adding new layers on top of existing ones to enable the forward transfer of knowledge and adapting previously learned representations for new tasks. We utilize a method of determining the most similar tasks for selecting the best location in our network to add new nodes with trainable parameters. This approach allows for creating a tree-like model, where each node is a set of neural network parameters dedicated to a specific task. The proposed method is inspired by Progressive Neural Network (PNN) concept, therefore it is rehearsal-free and benefits from dynamic change of network structure. However, it requires fewer parameters per task than PNN. Experiments on Permuted MNIST and SplitCIFAR show that the proposed algorithm is on par with other continual learning methods. We also perform ablation studies to clarify the contributions of each system part.", "paper_url": "http://arxiv.org/abs/2202.10821v1", "pdf_url": "http://arxiv.org/pdf/2202.10821v1", "repo_url": null}, "2202.10788": {"publish_time": "2022-02-22", "title": "Explicit Regularization via Regularizer Mirror Descent", "author": "Navid Azizan et.al.", "abstract": "Despite perfectly interpolating the training data, deep neural networks (DNNs) can often generalize fairly well, in part due to the \"implicit regularization\" induced by the learning algorithm. Nonetheless, various forms of regularization, such as \"explicit regularization\" (via weight decay), are often used to avoid overfitting, especially when the data is corrupted. There are several challenges with explicit regularization, most notably unclear convergence properties. Inspired by convergence properties of stochastic mirror descent (SMD) algorithms, we propose a new method for training DNNs with regularization, called regularizer mirror descent (RMD). In highly overparameterized DNNs, SMD simultaneously interpolates the training data and minimizes a certain potential function of the weights. RMD starts with a standard cost which is the sum of the training loss and a convex regularizer of the weights. Reinterpreting this cost as the potential of an \"augmented\" overparameterized network and applying SMD yields RMD. As a result, RMD inherits the properties of SMD and provably converges to a point \"close\" to the minimizer of this cost. RMD is computationally comparable to stochastic gradient descent (SGD) and weight decay, and is parallelizable in the same manner. Our experimental results on training sets with various levels of corruption suggest that the generalization performance of RMD is remarkably robust and significantly better than both SGD and weight decay, which implicitly and explicitly regularize the $\\ell_2$ norm of the weights. RMD can also be used to regularize the weights to a desired weight vector, which is particularly relevant for continual learning.", "paper_url": "http://arxiv.org/abs/2202.10788v1", "pdf_url": "http://arxiv.org/pdf/2202.10788v1", "repo_url": null}, "2202.10688": {"publish_time": "2022-02-22", "title": "Graph Lifelong Learning: A Survey", "author": "Falih Gozi Febrinanto et.al.", "abstract": "Graph learning substantially contributes to solving artificial intelligence (AI) tasks in various graph-related domains such as social networks, biological networks, recommender systems, and computer vision. However, despite its unprecedented prevalence, addressing the dynamic evolution of graph data over time remains a challenge. In many real-world applications, graph data continuously evolves. Current graph learning methods that assume graph representation is complete before the training process begins are not applicable in this setting. This challenge in graph learning motivates the development of a continuous learning process called graph lifelong learning to accommodate the future and refine the previous knowledge in graph data. Unlike existing survey papers that focus on either lifelong learning or graph learning separately, this survey paper covers the motivations, potentials, state-of-the-art approaches (that are well categorized), and open issues of graph lifelong learning. We expect extensive research and development interest in this emerging field.", "paper_url": "http://arxiv.org/abs/2202.10688v1", "pdf_url": "http://arxiv.org/pdf/2202.10688v1", "repo_url": null}, "2202.13657": {"publish_time": "2022-02-28", "title": "Avalanche RL: a Continual Reinforcement Learning Library", "author": "Nicol\u00f2 Lucchesi et.al.", "abstract": "Continual Reinforcement Learning (CRL) is a challenging setting where an agent learns to interact with an environment that is constantly changing over time (the stream of experiences). In this paper, we describe Avalanche RL, a library for Continual Reinforcement Learning which allows to easily train agents on a continuous stream of tasks. Avalanche RL is based on PyTorch and supports any OpenAI Gym environment. Its design is based on Avalanche, one of the more popular continual learning libraries, which allow us to reuse a large number of continual learning strategies and improve the interaction between reinforcement learning and continual learning researchers. Additionally, we propose Continual Habitat-Lab, a novel benchmark and a high-level library which enables the usage of the photorealistic simulator Habitat-Sim for CRL research. Overall, Avalanche RL attempts to unify under a common framework continual reinforcement learning applications, which we hope will foster the growth of the field.", "paper_url": "http://arxiv.org/abs/2202.13657v1", "pdf_url": "http://arxiv.org/pdf/2202.13657v1", "repo_url": "https://github.com/nicklucche/continual-habitat-lab"}, "2202.13369": {"publish_time": "2022-02-27", "title": "Robust Continual Learning through a Comprehensively Progressive Bayesian Neural Network", "author": "Guo Yang et.al.", "abstract": "This work proposes a comprehensively progressive Bayesian neural network for robust continual learning of a sequence of tasks. A Bayesian neural network is progressively pruned and grown such that there are sufficient network resources to represent a sequence of tasks, while the network does not explode. It starts with the contention that similar tasks should have the same number of total network resources, to ensure fair representation of all tasks in a continual learning scenario. Thus, as the data for new task streams in, sufficient neurons are added to the network such that the total number of neurons in each layer of the network, including the shared representations with previous tasks and individual task related representation, are equal for all tasks. The weights that are redundant at the end of training each task are also pruned through re-initialization, in order to be efficiently utilized in the subsequent task. Thus, the network grows progressively, but ensures effective utilization of network resources. We refer to our proposed method as 'Robust Continual Learning through a Comprehensively Progressive Bayesian Neural Network (RCL-CPB)' and evaluate the proposed approach on the MNIST data set, under three different continual learning scenarios. Further to this, we evaluate the performance of RCL-CPB on a homogeneous sequence of tasks using split CIFAR100 (20 tasks of 5 classes each), and a heterogeneous sequence of tasks using MNIST, SVHN and CIFAR10 data sets. The demonstrations and the performance results show that the proposed strategies for progressive BNN enable robust continual learning.", "paper_url": "http://arxiv.org/abs/2202.13369v1", "pdf_url": "http://arxiv.org/pdf/2202.13369v1", "repo_url": null}, "2203.01012": {"publish_time": "2022-03-02", "title": "Continual Feature Selection: Spurious Features in Continual Learning", "author": "Timoth\u00e9e Lesort et.al.", "abstract": "Continual Learning (CL) is the research field addressing learning settings where the data distribution is not static. This paper studies spurious features' influence on continual learning algorithms. Indeed, we show that learning algorithms solve tasks by overfitting features that are not generalizable. To better understand these phenomena and their impact, we propose a domain incremental scenario that we study through various out-of-distribution generalizations and continual learning algorithms. The experiments of this paper show that continual learning algorithms face two related challenges: (1) the spurious features challenge: some features are well correlated with labels in train data but not in test data due to a covariate shift between train and test. (2) the local spurious features challenge: some features correlate well with labels within a task but not within the whole task sequence. The challenge is to learn general features that are neither spurious (in general) nor locally spurious. We prove that the latter is a major cause of performance decrease in continual learning along with catastrophic forgetting. Our results indicate that the best solution to overcome the feature selection problems varies depending on the correlation between spurious features (SFs) and labels. The vanilla replay approach seems to be a powerful approach to deal with SFs, which could explain its good performance in the continual learning literature. This paper presents a different way of understanding performance decrease in continual learning by describing the influence of spurious/local spurious features.", "paper_url": "http://arxiv.org/abs/2203.01012v1", "pdf_url": "http://arxiv.org/pdf/2203.01012v1", "repo_url": null}, "2203.00936": {"publish_time": "2022-03-02", "title": "Continual Learning of Multi-modal Dynamics with External Memory", "author": "Abdullah Akg\u00fcl et.al.", "abstract": "We study the problem of fitting a model to a dynamical environment when new modes of behavior emerge sequentially. The learning model is aware when a new mode appears, but it does not have access to the true modes of individual training sequences. We devise a novel continual learning method that maintains a descriptor of the mode of an encountered sequence in a neural episodic memory. We employ a Dirichlet Process prior on the attention weights of the memory to foster efficient storage of the mode descriptors. Our method performs continual learning by transferring knowledge across tasks by retrieving the descriptors of similar modes of past tasks to the mode of a current sequence and feeding this descriptor into its transition kernel as control input. We observe the continual learning performance of our method to compare favorably to the mainstream parameter transfer approach.", "paper_url": "http://arxiv.org/abs/2203.00936v1", "pdf_url": "http://arxiv.org/pdf/2203.00936v1", "repo_url": null}, "2203.01578": {"publish_time": "2022-03-03", "title": "Continual SLAM: Beyond Lifelong Simultaneous Localization and Mapping through Continual Learning", "author": "Niclas V\u00f6disch et.al.", "abstract": "While lifelong SLAM addresses the capability of a robot to adapt to changes within a single environment over time, in this paper we introduce the task of continual SLAM. Here, a robot is deployed sequentially in a variety of different environments and has to transfer its knowledge of previously experienced environments to thus far unseen environments, while avoiding catastrophic forgetting. This is particularly relevant in the context of vision-based approaches, where the relevant features vary widely between different environments. We propose a novel approach for solving the continual SLAM problem by introducing CL-SLAM. Our approach consists of a dual-network architecture that handles both short-term adaptation and long-term memory retention by incorporating a replay buffer. Extensive evaluations of CL-SLAM in three different environments demonstrate that it outperforms several baselines inspired by existing continual learning-based visual odometry methods. The code of our work is publicly available at http://continual-slam.cs.uni-freiburg.de.", "paper_url": "http://arxiv.org/abs/2203.01578v1", "pdf_url": "http://arxiv.org/pdf/2203.01578v1", "repo_url": "https://github.com/robot-learning-freiburg/CL-SLAM"}, "2203.02108": {"publish_time": "2022-03-04", "title": "Continual Horizontal Federated Learning for Heterogeneous Data", "author": "Junki Mori et.al.", "abstract": "Federated learning is a promising machine learning technique that enables multiple clients to collaboratively build a model without revealing the raw data to each other. Among various types of federated learning methods, horizontal federated learning (HFL) is the best-studied category and handles homogeneous feature spaces. However, in the case of heterogeneous feature spaces, HFL uses only common features and leaves client-specific features unutilized. In this paper, we propose a HFL method using neural networks named continual horizontal federated learning (CHFL), a continual learning approach to improve the performance of HFL by taking advantage of unique features of each client. CHFL splits the network into two columns corresponding to common features and unique features, respectively. It jointly trains the first column by using common features through vanilla HFL and locally trains the second column by using unique features and leveraging the knowledge of the first one via lateral connections without interfering with the federated training of it. We conduct experiments on various real world datasets and show that CHFL greatly outperforms vanilla HFL that only uses common features and local learning that uses all features that each client has.", "paper_url": "http://arxiv.org/abs/2203.02108v1", "pdf_url": "http://arxiv.org/pdf/2203.02108v1", "repo_url": null}, "2203.02026": {"publish_time": "2022-03-03", "title": "Provable and Efficient Continual Representation Learning", "author": "Yingcong Li et.al.", "abstract": "In continual learning (CL), the goal is to design models that can learn a sequence of tasks without catastrophic forgetting. While there is a rich set of techniques for CL, relatively little understanding exists on how representations built by previous tasks benefit new tasks that are added to the network. To address this, we study the problem of continual representation learning (CRL) where we learn an evolving representation as new tasks arrive. Focusing on zero-forgetting methods where tasks are embedded in subnetworks (e.g., PackNet), we first provide experiments demonstrating CRL can significantly boost sample efficiency when learning new tasks. To explain this, we establish theoretical guarantees for CRL by providing sample complexity and generalization error bounds for new tasks by formalizing the statistical benefits of previously-learned representations. Our analysis and experiments also highlight the importance of the order in which we learn the tasks. Specifically, we show that CL benefits if the initial tasks have large sample size and high \"representation diversity\". Diversity ensures that adding new tasks incurs small representation mismatch and can be learned with few samples while training only few additional nonzero weights. Finally, we ask whether one can ensure each task subnetwork to be efficient during inference time while retaining the benefits of representation learning. To this end, we propose an inference-efficient variation of PackNet called Efficient Sparse PackNet (ESPN) which employs joint channel & weight pruning. ESPN embeds tasks in channel-sparse subnets requiring up to 80% less FLOPs to compute while approximately retaining accuracy and is very competitive with a variety of baselines. In summary, this work takes a step towards data and compute-efficient CL with a representation learning perspective. GitHub page: https://github.com/ucr-optml/CtRL", "paper_url": "http://arxiv.org/abs/2203.02026v1", "pdf_url": "http://arxiv.org/pdf/2203.02026v1", "repo_url": "https://github.com/ucr-optml/ctrl"}, "2203.03303": {"publish_time": "2022-03-07", "title": "PAC-Bayesian Lifelong Learning For Multi-Armed Bandits", "author": "Hamish Flynn et.al.", "abstract": "We present a PAC-Bayesian analysis of lifelong learning. In the lifelong learning problem, a sequence of learning tasks is observed one-at-a-time, and the goal is to transfer information acquired from previous tasks to new learning tasks. We consider the case when each learning task is a multi-armed bandit problem. We derive lower bounds on the expected average reward that would be obtained if a given multi-armed bandit algorithm was run in a new task with a particular prior and for a set number of steps. We propose lifelong learning algorithms that use our new bounds as learning objectives. Our proposed algorithms are evaluated in several lifelong multi-armed bandit problems and are found to perform better than a baseline method that does not use generalisation bounds.", "paper_url": "http://arxiv.org/abs/2203.03303v1", "pdf_url": "http://arxiv.org/pdf/2203.03303v1", "repo_url": null}, "2203.03970": {"publish_time": "2022-03-08", "title": "On Generalizing Beyond Domains in Cross-Domain Continual Learning", "author": "Christian Simon et.al.", "abstract": "Humans have the ability to accumulate knowledge of new tasks in varying conditions, but deep neural networks often suffer from catastrophic forgetting of previously learned knowledge after learning a new task. Many recent methods focus on preventing catastrophic forgetting under the assumption of train and test data following similar distributions. In this work, we consider a more realistic scenario of continual learning under domain shifts where the model must generalize its inference to an unseen domain. To this end, we encourage learning semantically meaningful features by equipping the classifier with class similarity metrics as learning parameters which are obtained through Mahalanobis similarity computations. Learning of the backbone representation along with these extra parameters is done seamlessly in an end-to-end manner. In addition, we propose an approach based on the exponential moving average of the parameters for better knowledge distillation. We demonstrate that, to a great extent, existing continual learning algorithms fail to handle the forgetting issue under multiple distributions, while our proposed approach learns new tasks under domain shift with accuracy boosts up to 10% on challenging datasets such as DomainNet and OfficeHome.", "paper_url": "http://arxiv.org/abs/2203.03970v1", "pdf_url": "http://arxiv.org/pdf/2203.03970v1", "repo_url": null}, "2203.03910": {"publish_time": "2022-03-08", "title": "Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation", "author": "Chenze Shao et.al.", "abstract": "Neural networks tend to gradually forget the previously learned knowledge when learning multiple tasks sequentially from dynamic data distributions. This problem is called \\textit{catastrophic forgetting}, which is a fundamental challenge in the continual learning of neural networks. In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training. Neural networks, especially neural machine translation models, suffer from catastrophic forgetting even if they learn from a static training set. To be specific, the final model pays imbalanced attention to training samples, where recently exposed samples attract more attention than earlier samples. The underlying cause is that training samples do not get balanced training in each model update, so we name this problem \\textit{imbalanced training}. To alleviate this problem, we propose Complementary Online Knowledge Distillation (COKD), which uses dynamically updated teacher models trained on specific data orders to iteratively provide complementary knowledge to the student model. Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems.", "paper_url": "http://arxiv.org/abs/2203.03910v1", "pdf_url": "http://arxiv.org/pdf/2203.03910v1", "repo_url": "https://github.com/ictnlp/cokd"}, "2203.03798": {"publish_time": "2022-03-08", "title": "New Insights on Reducing Abrupt Representation Change in Online Continual Learning", "author": "Lucas Caccia et.al.", "abstract": "In the online continual learning paradigm, agents must learn from a changing distribution while respecting memory and compute constraints. Experience Replay (ER), where a small subset of past data is stored and replayed alongside new data, has emerged as a simple and effective learning strategy. In this work, we focus on the change in representations of observed data that arises when previously unobserved classes appear in the incoming data stream, and new classes must be distinguished from previous ones. We shed new light on this question by showing that applying ER causes the newly added classes' representations to overlap significantly with the previous classes, leading to highly disruptive parameter updates. Based on this empirical analysis, we propose a new method which mitigates this issue by shielding the learned representations from drastic adaptation to accommodate new classes. We show that using an asymmetric update rule pushes new classes to adapt to the older ones (rather than the reverse), which is more effective especially at task boundaries, where much of the forgetting typically occurs. Empirical results show significant gains over strong baselines on standard continual learning benchmarks", "paper_url": "http://arxiv.org/abs/2203.03798v1", "pdf_url": "http://arxiv.org/pdf/2203.03798v1", "repo_url": "https://github.com/pclucas14/aml"}, "2203.04640": {"publish_time": "2022-03-09", "title": "Memory Efficient Continual Learning for Neural Text Classification", "author": "Beyza Ermis et.al.", "abstract": "Learning text classifiers based on pre-trained language models has become the standard practice in natural language processing applications. Unfortunately, training large neural language models, such as transformers, from scratch is very costly and requires a vast amount of training data, which might not be available in the application domain of interest. Moreover, in many real-world scenarios, classes are uncovered as more data is seen, calling for class-incremental modelling approaches. In this work we devise a method to perform text classification using pre-trained models on a sequence of classification tasks provided in sequence. We formalize the problem as a continual learning problem where the algorithm learns new tasks without performance degradation on the previous ones and without re-training the model from scratch. We empirically demonstrate that our method requires significantly less model parameters compared to other state of the art methods and that it is significantly faster at inference time. The tight control on the number of model parameters, and so the memory, is not only improving efficiency. It is making possible the usage of the algorithm in real-world applications where deploying a solution with a constantly increasing memory consumption is just unrealistic. While our method suffers little forgetting, it retains a predictive performance on-par with state of the art but less memory efficient methods.", "paper_url": "http://arxiv.org/abs/2203.04640v1", "pdf_url": "http://arxiv.org/pdf/2203.04640v1", "repo_url": null}, "2203.06053": {"publish_time": "2022-03-11", "title": "A Machine Learning Approach for Prosumer Management in Intraday Electricity Markets", "author": "Saeed Mohammadi et.al.", "abstract": "Prosumer operators are dealing with extensive challenges to participate in short-term electricity markets while taking uncertainties into account. Challenges such as variation in demand, solar energy, wind power, and electricity prices as well as faster response time in intraday electricity markets. Machine learning approaches could resolve these challenges due to their ability to continuous learning of complex relations and providing a real-time response. Such approaches are applicable with presence of the high performance computing and big data. To tackle these challenges, a Markov decision process is proposed and solved with a reinforcement learning algorithm with proper observations and actions employing tabular Q-learning. Trained agent converges to a policy which is similar to the global optimal solution. It increases the prosumer's profit by 13.39% compared to the well-known stochastic optimization approach.", "paper_url": "http://arxiv.org/abs/2203.06053v1", "pdf_url": "http://arxiv.org/pdf/2203.06053v1", "repo_url": null}, "2203.05692": {"publish_time": "2022-03-11", "title": "Lifelong Adaptive Machine Learning for Sensor-based Human Activity Recognition Using Prototypical Networks", "author": "Rebecca Adaimi et.al.", "abstract": "Continual learning, also known as lifelong learning, is an emerging research topic that has been attracting increasing interest in the field of machine learning. With human activity recognition (HAR) playing a key role in enabling numerous real-world applications, an essential step towards the long-term deployment of such recognition systems is to extend the activity model to dynamically adapt to changes in people's everyday behavior. Current research in continual learning applied to HAR domain is still under-explored with researchers exploring existing methods developed for computer vision in HAR. Moreover, analysis has so far focused on task-incremental or class-incremental learning paradigms where task boundaries are known. This impedes the applicability of such methods for real-world systems since data is presented in a randomly streaming fashion. To push this field forward, we build on recent advances in the area of continual machine learning and design a lifelong adaptive learning framework using Prototypical Networks, LAPNet-HAR, that processes sensor-based data streams in a task-free data-incremental fashion and mitigates catastrophic forgetting using experience replay and continual prototype adaptation. Online learning is further facilitated using contrastive loss to enforce inter-class separation. LAPNet-HAR is evaluated on 5 publicly available activity datasets in terms of the framework's ability to acquire new information while preserving previous knowledge. Our extensive empirical results demonstrate the effectiveness of LAPNet-HAR in task-free continual learning and uncover useful insights for future challenges.", "paper_url": "http://arxiv.org/abs/2203.05692v1", "pdf_url": "http://arxiv.org/pdf/2203.05692v1", "repo_url": null}, "2203.06855": {"publish_time": "2022-03-14", "title": "DIAS: A Domain-Independent Alife-Based Problem-Solving System", "author": "Babak Hodjat et.al.", "abstract": "A domain-independent problem-solving system based on principles of Artificial Life is introduced. In this system, DIAS, the input and output dimensions of the domain are laid out in a spatial medium. A population of actors, each seeing only part of this medium, solves problems collectively in it. The process is independent of the domain and can be implemented through different kinds of actors. Through a set of experiments on various problem domains, DIAS is shown able to solve problems with different dimensionality and complexity, to require no hyperparameter tuning for new problems, and to exhibit lifelong learning, i.e. adapt rapidly to run-time changes in the problem domain, and do it better than a standard non-collective approach. DIAS therefore demonstrates a role for Alife in building scalable, general, and adaptive problem-solving systems.", "paper_url": "http://arxiv.org/abs/2203.06855v1", "pdf_url": "http://arxiv.org/pdf/2203.06855v1", "repo_url": null}, "2203.06852": {"publish_time": "2022-03-14", "title": "Continual Learning for Multivariate Time Series Tasks with Variable Input Dimensions", "author": "Vibhor Gupta et.al.", "abstract": "We consider a sequence of related multivariate time series learning tasks, such as predicting failures for different instances of a machine from time series of multi-sensor data, or activity recognition tasks over different individuals from multiple wearable sensors. We focus on two under-explored practical challenges arising in such settings: (i) Each task may have a different subset of sensors, i.e., providing different partial observations of the underlying 'system'. This restriction can be due to different manufacturers in the former case, and people wearing more or less measurement devices in the latter (ii) We are not allowed to store or re-access data from a task once it has been observed at the task level. This may be due to privacy considerations in the case of people, or legal restrictions placed by machine owners. Nevertheless, we would like to (a) improve performance on subsequent tasks using experience from completed tasks as well as (b) continue to perform better on past tasks, e.g., update the model and improve predictions on even the first machine after learning from subsequently observed ones. We note that existing continual learning methods do not take into account variability in input dimensions arising due to different subsets of sensors being available across tasks, and struggle to adapt to such variable input dimensions (VID) tasks. In this work, we address this shortcoming of existing methods. To this end, we learn task-specific generative models and classifiers, and use these to augment data for target tasks. Since the input dimensions across tasks vary, we propose a novel conditioning module based on graph neural networks to aid a standard recurrent neural network. We evaluate the efficacy of the proposed approach on three publicly available datasets corresponding to two activity recognition tasks (classification) and one prognostics task (regression).", "paper_url": "http://arxiv.org/abs/2203.06852v1", "pdf_url": "http://arxiv.org/pdf/2203.06852v1", "repo_url": null}, "2203.06654": {"publish_time": "2022-03-13", "title": "Continual Prompt Tuning for Dialog State Tracking", "author": "Qi Zhu et.al.", "abstract": "A desirable dialog system should be able to continually learn new skills without forgetting old ones, and thereby adapt to new domains or tasks in its life cycle. However, continually training a model often leads to a well-known catastrophic forgetting issue. In this paper, we present Continual Prompt Tuning, a parameter-efficient framework that not only avoids forgetting but also enables knowledge transfer between tasks. To avoid forgetting, we only learn and store a few prompt tokens' embeddings for each task while freezing the backbone pre-trained model. To achieve bi-directional knowledge transfer among tasks, we propose several techniques (continual prompt initialization, query fusion, and memory replay) to transfer knowledge from preceding tasks and a memory-guided technique to transfer knowledge from subsequent tasks. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method on continual learning for dialog state tracking, compared with state-of-the-art baselines.", "paper_url": "http://arxiv.org/abs/2203.06654v1", "pdf_url": "http://arxiv.org/pdf/2203.06654v1", "repo_url": "https://github.com/thu-coai/cpt4dst"}, "2203.06514": {"publish_time": "2022-03-12", "title": "Sparsity and Heterogeneous Dropout for Continual Learning in the Null Space of Neural Activations", "author": "Ali Abbasi et.al.", "abstract": "Continual/lifelong learning from a non-stationary input data stream is a cornerstone of intelligence. Despite their phenomenal performance in a wide variety of applications, deep neural networks are prone to forgetting their previously learned information upon learning new ones. This phenomenon is called \"catastrophic forgetting\" and is deeply rooted in the stability-plasticity dilemma. Overcoming catastrophic forgetting in deep neural networks has become an active field of research in recent years. In particular, gradient projection-based methods have recently shown exceptional performance at overcoming catastrophic forgetting. This paper proposes two biologically-inspired mechanisms based on sparsity and heterogeneous dropout that significantly increase a continual learner's performance over a long sequence of tasks. Our proposed approach builds on the Gradient Projection Memory (GPM) framework. We leverage K-winner activations in each layer of a neural network to enforce layer-wise sparse activations for each task, together with a between-task heterogeneous dropout that encourages the network to use non-overlapping activation patterns between different tasks. In addition, we introduce Continual Swiss Roll as a lightweight and interpretable -- yet challenging -- synthetic benchmark for continual learning. Lastly, we provide an in-depth analysis of our proposed method and demonstrate a significant performance boost on various benchmark continual learning problems.", "paper_url": "http://arxiv.org/abs/2203.06514v1", "pdf_url": "http://arxiv.org/pdf/2203.06514v1", "repo_url": null}, "2203.06311": {"publish_time": "2022-03-12", "title": "ELLE: Efficient Lifelong Pre-training for Emerging Data", "author": "Yujia Qin et.al.", "abstract": "Current pre-trained language models (PLM) are typically trained with static data, ignoring that in real-world scenarios, streaming data of various sources may continuously grow. This requires PLMs to integrate the information from all the sources in a lifelong manner. Although this goal could be achieved by exhaustive pre-training on all the existing data, such a process is known to be computationally expensive. To this end, we propose ELLE, aiming at efficient lifelong pre-training for emerging data. Specifically, ELLE consists of (1) function preserved model expansion, which flexibly expands an existing PLM's width and depth to improve the efficiency of knowledge acquisition; and (2) pre-trained domain prompts, which disentangle the versatile knowledge learned during pre-training and stimulate the proper knowledge for downstream tasks. We experiment ELLE with streaming data from 5 domains on BERT and GPT. The results show the superiority of ELLE over various lifelong learning baselines in both pre-training efficiency and downstream performances. The codes are publicly available at https://github.com/thunlp/ELLE.", "paper_url": "http://arxiv.org/abs/2203.06311v1", "pdf_url": "http://arxiv.org/pdf/2203.06311v1", "repo_url": "https://github.com/thunlp/elle"}, "2203.07667": {"publish_time": "2022-03-15", "title": "SATS: Self-Attention Transfer for Continual Semantic Segmentation", "author": "Yiqiao Qiu et.al.", "abstract": "Continually learning to segment more and more types of image regions is a desired capability for many intelligent systems. However, such continual semantic segmentation suffers from the same catastrophic forgetting issue as in continual classification learning. While multiple knowledge distillation strategies originally for continual classification have been well adapted to continual semantic segmentation, they only consider transferring old knowledge based on the outputs from one or more layers of deep fully convolutional networks. Different from existing solutions, this study proposes to transfer a new type of information relevant to knowledge, i.e. the relationships between elements (Eg. pixels or small local regions) within each image which can capture both within-class and between-class knowledge. The relationship information can be effectively obtained from the self-attention maps in a Transformer-style segmentation model. Considering that pixels belonging to the same class in each image often share similar visual properties, a class-specific region pooling is applied to provide more efficient relationship information for knowledge transfer. Extensive evaluations on multiple public benchmarks support that the proposed self-attention transfer method can further effectively alleviate the catastrophic forgetting issue, and its flexible combination with one or more widely adopted strategies significantly outperforms state-of-the-art solu", "paper_url": "http://arxiv.org/abs/2203.07667v1", "pdf_url": "http://arxiv.org/pdf/2203.07667v1", "repo_url": null}, "2203.07454": {"publish_time": "2022-03-14", "title": "L2Explorer: A Lifelong Reinforcement Learning Assessment Environment", "author": "Erik C. Johnson et.al.", "abstract": "Despite groundbreaking progress in reinforcement learning for robotics, gameplay, and other complex domains, major challenges remain in applying reinforcement learning to the evolving, open-world problems often found in critical application spaces. Reinforcement learning solutions tend to generalize poorly when exposed to new tasks outside of the data distribution they are trained on, prompting an interest in continual learning algorithms. In tandem with research on continual learning algorithms, there is a need for challenge environments, carefully designed experiments, and metrics to assess research progress. We address the latter need by introducing a framework for continual reinforcement-learning development and assessment using Lifelong Learning Explorer (L2Explorer), a new, Unity-based, first-person 3D exploration environment that can be continuously reconfigured to generate a range of tasks and task variants structured into complex and evolving evaluation curricula. In contrast to procedurally generated worlds with randomized components, we have developed a systematic approach to defining curricula in response to controlled changes with accompanying metrics to assess transfer, performance recovery, and data efficiency. Taken together, the L2Explorer environment and evaluation approach provides a framework for developing future evaluation methodologies in open-world settings and rigorously evaluating approaches to lifelong learning.", "paper_url": "http://arxiv.org/abs/2203.07454v1", "pdf_url": "http://arxiv.org/pdf/2203.07454v1", "repo_url": null}, "2203.08796": {"publish_time": "2022-03-16", "title": "A Continual Learning Framework for Adaptive Defect Classification and Inspection", "author": "Wenbo Sun et.al.", "abstract": "Machine-vision-based defect classification techniques have been widely adopted for automatic quality inspection in manufacturing processes. This article describes a general framework for classifying defects from high volume data batches with efficient inspection of unlabelled samples. The concept is to construct a detector to identify new defect types, send them to the inspection station for labelling, and dynamically update the classifier in an efficient manner that reduces both storage and computational needs imposed by data samples of previously observed batches. Both a simulation study on image classification and a case study on surface defect detection via 3D point clouds are performed to demonstrate the effectiveness of the proposed method.", "paper_url": "http://arxiv.org/abs/2203.08796v1", "pdf_url": "http://arxiv.org/pdf/2203.08796v1", "repo_url": null}, "2203.08512": {"publish_time": "2022-03-16", "title": "ConTinTin: Continual Learning from Task Instructions", "author": "Wenpeng Yin et.al.", "abstract": "The mainstream machine learning paradigms for NLP often work with two underlying presumptions. First, the target task is predefined and static, a system just needs to learn to solve it exclusively. Second, the supervision of a task mainly comes from a set of labeled examples. A question arises: how to build a system that can keep learning new tasks from their instructions? This work defines a new learning paradigm ConTinTin (Continual Learning from Task Instructions), in which a system should learn a sequence of new tasks one by one, each task is explained by a piece of textual instruction. The system is required to (i) generate the expected outputs of a new task by learning from its instruction, (ii) transfer the knowledge acquired from upstream tasks to help solve downstream tasks (i.e, forward-transfer), and (iii) retain or even improve the performance on earlier tasks after learning new tasks (i.e., backward-transfer). This new problem is studied on a stream of more than 60 tasks, each equipped with an instruction. Technically, our method InstructionSpeak contains two strategies that make full use of task instructions to improve forward-transfer and backward-transfer: one is to learn from the negative output, the other is to re-visit instructions of prior tasks. To our knowledge, this is the first time to study ConTinTin in NLP. In addition to the problem formulation and our promising approach, this work also contributes to providing rich analyses for the community to better understand this novel learning problem.", "paper_url": "http://arxiv.org/abs/2203.08512v1", "pdf_url": "http://arxiv.org/pdf/2203.08512v1", "repo_url": null}, "2203.08399": {"publish_time": "2022-03-16", "title": "Privacy-preserving Online AutoML for Domain-Specific Face Detection", "author": "Chenqian Yan et.al.", "abstract": "Despite the impressive progress of general face detection, the tuning of hyper-parameters and architectures is still critical for the performance of a domain-specific face detector. Though existing AutoML works can speedup such process, they either require tuning from scratch for a new scenario or do not consider data privacy. To scale up, we derive a new AutoML setting from a platform perspective. In such setting, new datasets sequentially arrive at the platform, where an architecture and hyper-parameter configuration is recommended to train the optimal face detector for each dataset. This, however, brings two major challenges: (1) how to predict the best configuration for any given dataset without touching their raw images due to the privacy concern? and (2) how to continuously improve the AutoML algorithm from previous tasks and offer a better warm-up for future ones? We introduce \"HyperFD\", a new privacy-preserving online AutoML framework for face detection. At its core part, a novel meta-feature representation of a dataset as well as its learning paradigm is proposed. Thanks to HyperFD, each local task (client) is able to effectively leverage the learning \"experience\" of previous tasks without uploading raw images to the platform; meanwhile, the meta-feature extractor is continuously learned to better trade off the bias and variance. Extensive experiments demonstrate the effectiveness and efficiency of our design.", "paper_url": "http://arxiv.org/abs/2203.08399v1", "pdf_url": "http://arxiv.org/pdf/2203.08399v1", "repo_url": null}, "2203.09450": {"publish_time": "2022-03-17", "title": "Continual Learning Based on OOD Detection and Task Masking", "author": "Gyuhak Kim et.al.", "abstract": "Existing continual learning techniques focus on either task incremental learning (TIL) or class incremental learning (CIL) problem, but not both. CIL and TIL differ mainly in that the task-id is provided for each test sample during testing for TIL, but not provided for CIL. Continual learning methods intended for one problem have limitations on the other problem. This paper proposes a novel unified approach based on out-of-distribution (OOD) detection and task masking, called CLOM, to solve both problems. The key novelty is that each task is trained as an OOD detection model rather than a traditional supervised learning model, and a task mask is trained to protect each task to prevent forgetting. Our evaluation shows that CLOM outperforms existing state-of-the-art baselines by large margins. The average TIL/CIL accuracy of CLOM over six experiments is 87.6/67.9% while that of the best baselines is only 82.4/55.0%.", "paper_url": "http://arxiv.org/abs/2203.09450v1", "pdf_url": "http://arxiv.org/pdf/2203.09450v1", "repo_url": "https://github.com/k-gyuhak/clom"}, "2203.08994": {"publish_time": "2022-03-17", "title": "AI Autonomy: Self-Initiation, Adaptation and Continual Learning", "author": "Bing Liu et.al.", "abstract": "As more and more AI agents are used in practice, it is time to think about how to make these agents fully autonomous so that they can (1) learn by themselves continually in a self-motivated and self-initiated manner rather than being retrained offline periodically on the initiation of human engineers and (2) accommodate or adapt to unexpected or novel circumstances. As the real-world is an open environment that is full of unknowns or novelties, detecting novelties, characterizing them, accommodating or adapting to them, and gathering ground-truth training data and incrementally learning the unknowns/novelties are critical to making the AI agent more and more knowledgeable and powerful over time. The key challenge is how to automate the process so that it is carried out continually on the agent's own initiative and through its own interactions with humans, other agents and the environment just like human on-the-job learning. This paper proposes a framework (called SOLA) for this learning paradigm to promote the research of building autonomous and continual learning enabled AI agents. To show feasibility, an implemented agent is also described.", "paper_url": "http://arxiv.org/abs/2203.08994v1", "pdf_url": "http://arxiv.org/pdf/2203.08994v1", "repo_url": null}, "2203.09879": {"publish_time": "2022-03-18", "title": "Class-wise Classifier Design Capable of Continual Learning using Adaptive Resonance Theory-based Topological Clustering", "author": "Naoki Masuyama et.al.", "abstract": "This paper proposes a supervised classification algorithm capable of continual learning by utilizing an Adaptive Resonance Theory (ART)-based growing self-organizing clustering algorithm. The ART-based clustering algorithm is theoretically capable of continual learning, and the proposed algorithm independently applies it to each class of training data for generating classifiers. Whenever an additional training data set from a new class is given, a new ART-based clustering will be defined in a different learning space. Thanks to the above-mentioned features, the proposed algorithm realizes continual learning capability. Simulation experiments showed that the proposed algorithm has superior classification performance compared with state-of-the-art clustering-based classification algorithms capable of continual learning.", "paper_url": "http://arxiv.org/abs/2203.09879v1", "pdf_url": "http://arxiv.org/pdf/2203.09879v1", "repo_url": null}, "2203.10681": {"publish_time": "2022-03-21", "title": "Online Continual Learning for Embedded Devices", "author": "Tyler L. Hayes et.al.", "abstract": "Real-time on-device continual learning is needed for new applications such as home robots, user personalization on smartphones, and augmented/virtual reality headsets. However, this setting poses unique challenges: embedded devices have limited memory and compute capacity and conventional machine learning models suffer from catastrophic forgetting when updated on non-stationary data streams. While several online continual learning models have been developed, their effectiveness for embedded applications has not been rigorously studied. In this paper, we first identify criteria that online continual learners must meet to effectively perform real-time, on-device learning. We then study the efficacy of several online continual learning methods when used with mobile neural networks. We measure their performance, memory usage, compute requirements, and ability to generalize to out-of-domain inputs.", "paper_url": "http://arxiv.org/abs/2203.10681v1", "pdf_url": "http://arxiv.org/pdf/2203.10681v1", "repo_url": null}, "2203.10652": {"publish_time": "2022-03-20", "title": "Continual Sequence Generation with Adaptive Compositional Modules", "author": "Yanzhe Zhang et.al.", "abstract": "Continual learning is essential for real-world deployment when there is a need to quickly adapt the model to new tasks without forgetting knowledge of old tasks. Existing work on continual sequence generation either always reuses existing parameters to learn new tasks, which is vulnerable to catastrophic forgetting on dissimilar tasks, or blindly adds new parameters for every new task, which could prevent knowledge sharing between similar tasks. To get the best of both worlds, in this work, we propose continual sequence generation with adaptive compositional modules to adaptively add modules in transformer architectures and compose both old and new modules for new tasks. We also incorporate pseudo experience replay to facilitate knowledge transfer in those shared modules. Experiment results on various sequences of generation tasks show that our framework can adaptively add modules or reuse modules based on task similarity, outperforming state-of-the-art baselines in terms of both performance and parameter efficiency. We make our code public at https://github.com/GT-SALT/Adaptive-Compositional-Modules.", "paper_url": "http://arxiv.org/abs/2203.10652v1", "pdf_url": "http://arxiv.org/pdf/2203.10652v1", "repo_url": null}, "2203.10317": {"publish_time": "2022-03-19", "title": "Practical Recommendations for Replay-based Continual Learning Methods", "author": "Gabriele Merlin et.al.", "abstract": "Continual Learning requires the model to learn from a stream of dynamic, non-stationary data without forgetting previous knowledge. Several approaches have been developed in the literature to tackle the Continual Learning challenge. Among them, Replay approaches have empirically proved to be the most effective ones. Replay operates by saving some samples in memory which are then used to rehearse knowledge during training in subsequent tasks. However, an extensive comparison and deeper understanding of different replay implementation subtleties is still missing in the literature. The aim of this work is to compare and analyze existing replay-based strategies and provide practical recommendations on developing efficient, effective and generally applicable replay-based strategies. In particular, we investigate the role of the memory size value, different weighting policies and discuss about the impact of data augmentation, which allows reaching better performance with lower memory sizes.", "paper_url": "http://arxiv.org/abs/2203.10317v1", "pdf_url": "http://arxiv.org/pdf/2203.10317v1", "repo_url": null}, "2203.10297": {"publish_time": "2022-03-19", "title": "Incremental Few-Shot Learning via Implanting and Compressing", "author": "Yiting Li et.al.", "abstract": "This work focuses on tackling the challenging but realistic visual task of Incremental Few-Shot Learning (IFSL), which requires a model to continually learn novel classes from only a few examples while not forgetting the base classes on which it was pre-trained. Our study reveals that the challenges of IFSL lie in both inter-class separation and novel-class representation. Dur to intra-class variation, a novel class may implicitly leverage the knowledge from multiple base classes to construct its feature representation. Hence, simply reusing the pre-trained embedding space could lead to a scattered feature distribution and result in category confusion. To address such issues, we propose a two-step learning strategy referred to as \\textbf{Im}planting and \\textbf{Co}mpressing (\\textbf{IMCO}), which optimizes both feature space partition and novel class reconstruction in a systematic manner. Specifically, in the \\textbf{Implanting} step, we propose to mimic the data distribution of novel classes with the assistance of data-abundant base set, so that a model could learn semantically-rich features that are beneficial for discriminating between the base and other unseen classes. In the \\textbf{Compressing} step, we adapt the feature extractor to precisely represent each novel class for enhancing intra-class compactness, together with a regularized parameter updating rule for preventing aggressive model updating. Finally, we demonstrate that IMCO outperforms competing baselines with a significant margin, both in image classification task and more challenging object detection task.", "paper_url": "http://arxiv.org/abs/2203.10297v1", "pdf_url": "http://arxiv.org/pdf/2203.10297v1", "repo_url": null}, "2203.11684": {"publish_time": "2022-03-22", "title": "Meta-attention for ViT-backed Continual Learning", "author": "Mengqi Xue et.al.", "abstract": "Continual learning is a longstanding research topic due to its crucial role in tackling continually arriving tasks. Up to now, the study of continual learning in computer vision is mainly restricted to convolutional neural networks (CNNs). However, recently there is a tendency that the newly emerging vision transformers (ViTs) are gradually dominating the field of computer vision, which leaves CNN-based continual learning lagging behind as they can suffer from severe performance degradation if straightforwardly applied to ViTs. In this paper, we study ViT-backed continual learning to strive for higher performance riding on recent advances of ViTs. Inspired by mask-based continual learning methods in CNNs, where a mask is learned per task to adapt the pre-trained ViT to the new task, we propose MEta-ATtention (MEAT), i.e., attention to self-attention, to adapt a pre-trained ViT to new tasks without sacrificing performance on already learned tasks. Unlike prior mask-based methods like Piggyback, where all parameters are associated with corresponding masks, MEAT leverages the characteristics of ViTs and only masks a portion of its parameters. It renders MEAT more efficient and effective with less overhead and higher accuracy. Extensive experiments demonstrate that MEAT exhibits significant superiority to its state-of-the-art CNN counterparts, with 4.0~6.0% absolute boosts in accuracy. Our code has been released at https://github.com/zju-vipa/MEAT-TIL.", "paper_url": "http://arxiv.org/abs/2203.11684v1", "pdf_url": "http://arxiv.org/pdf/2203.11684v1", "repo_url": "https://github.com/zju-vipa/meat-til"}, "2203.11560": {"publish_time": "2022-03-22", "title": "Modelling continual learning in humans with Hebbian context gating and exponentially decaying task signals", "author": "Timo Flesch et.al.", "abstract": "Humans can learn several tasks in succession with minimal mutual interference but perform more poorly when trained on multiple tasks at once. The opposite is true for standard deep neural networks. Here, we propose novel computational constraints for artificial neural networks, inspired by earlier work on gating in the primate prefrontal cortex, that capture the cost of interleaved training and allow the network to learn two tasks in sequence without forgetting. We augment standard stochastic gradient descent with two algorithmic motifs, so-called \"sluggish\" task units and a Hebbian training step that strengthens connections between task units and hidden units that encode task-relevant information. We found that the \"sluggish\" units introduce a switch-cost during training, which biases representations under interleaved training towards a joint representation that ignores the contextual cue, while the Hebbian step promotes the formation of a gating scheme from task units to the hidden layer that produces orthogonal representations which are perfectly guarded against interference. Validating the model on previously published human behavioural data revealed that it matches performance of participants who had been trained on blocked or interleaved curricula, and that these performance differences were driven by misestimation of the true category boundary.", "paper_url": "http://arxiv.org/abs/2203.11560v1", "pdf_url": "http://arxiv.org/pdf/2203.11560v1", "repo_url": "https://github.com/summerfieldlab/flesch_nagy_etal_hebbcl"}, "2203.11997": {"publish_time": "2022-03-22", "title": "Federated Self-Supervised Learning for Acoustic Event Classification", "author": "Meng Feng et.al.", "abstract": "Standard acoustic event classification (AEC) solutions require large-scale collection of data from client devices for model optimization. Federated learning (FL) is a compelling framework that decouples data collection and model training to enhance customer privacy. In this work, we investigate the feasibility of applying FL to improve AEC performance while no customer data can be directly uploaded to the server. We assume no pseudo labels can be inferred from on-device user inputs, aligning with the typical use cases of AEC. We adapt self-supervised learning to the FL framework for on-device continual learning of representations, and it results in improved performance of the downstream AEC classifiers without labeled/pseudo-labeled data available. Compared to the baseline w/o FL, the proposed method improves precision up to 20.3\\% relatively while maintaining the recall. Our work differs from prior work in FL in that our approach does not require user-generated learning targets, and the data we use is collected from our Beta program and is de-identified, to maximally simulate the production settings.", "paper_url": "http://arxiv.org/abs/2203.11997v1", "pdf_url": "http://arxiv.org/pdf/2203.11997v1", "repo_url": null}, "2203.11992": {"publish_time": "2022-03-22", "title": "Resonance in Weight Space: Covariate Shift Can Drive Divergence of SGD with Momentum", "author": "Kirby Banman et.al.", "abstract": "Most convergence guarantees for stochastic gradient descent with momentum (SGDm) rely on iid sampling. Yet, SGDm is often used outside this regime, in settings with temporally correlated input samples such as continual learning and reinforcement learning. Existing work has shown that SGDm with a decaying step-size can converge under Markovian temporal correlation. In this work, we show that SGDm under covariate shift with a fixed step-size can be unstable and diverge. In particular, we show SGDm under covariate shift is a parametric oscillator, and so can suffer from a phenomenon known as resonance. We approximate the learning system as a time varying system of ordinary differential equations, and leverage existing theory to characterize the system's divergence/convergence as resonant/nonresonant modes. The theoretical result is limited to the linear setting with periodic covariate shift, so we empirically supplement this result to show that resonance phenomena persist even under non-periodic covariate shift, nonlinear dynamics with neural networks, and optimizers other than SGDm.", "paper_url": "http://arxiv.org/abs/2203.11992v1", "pdf_url": "http://arxiv.org/pdf/2203.11992v1", "repo_url": null}, "2203.13167": {"publish_time": "2022-03-24", "title": "Towards Exemplar-Free Continual Learning in Vision Transformers: an Account of Attention, Functional and Weight Regularization", "author": "Francesco Pelosin et.al.", "abstract": "In this paper, we investigate the continual learning of Vision Transformers (ViT) for the challenging exemplar-free scenario, with special focus on how to efficiently distill the knowledge of its crucial self-attention mechanism (SAM). Our work takes an initial step towards a surgical investigation of SAM for designing coherent continual learning methods in ViTs. We first carry out an evaluation of established continual learning regularization techniques. We then examine the effect of regularization when applied to two key enablers of SAM: (a) the contextualized embedding layers, for their ability to capture well-scaled representations with respect to the values, and (b) the prescaled attention maps, for carrying value-independent global contextual information. We depict the perks of each distilling strategy on two image recognition benchmarks (CIFAR100 and ImageNet-32) -- while (a) leads to a better overall accuracy, (b) helps enhance the rigidity by maintaining competitive performances. Furthermore, we identify the limitation imposed by the symmetric nature of regularization losses. To alleviate this, we propose an asymmetric variant and apply it to the pooled output distillation (POD) loss adapted for ViTs. Our experiments confirm that introducing asymmetry to POD boosts its plasticity while retaining stability across (a) and (b). Moreover, we acknowledge low forgetting measures for all the compared methods, indicating that ViTs might be naturally inclined continual learner", "paper_url": "http://arxiv.org/abs/2203.13167v1", "pdf_url": "http://arxiv.org/pdf/2203.13167v1", "repo_url": null}, "2203.12817": {"publish_time": "2022-03-24", "title": "Continual Learning and Private Unlearning", "author": "Bo Liu et.al.", "abstract": "As intelligent agents become autonomous over longer periods of time, they may eventually become lifelong counterparts to specific people. If so, it may be common for a user to want the agent to master a task temporarily but later on to forget the task due to privacy concerns. However enabling an agent to \\emph{forget privately} what the user specified without degrading the rest of the learned knowledge is a challenging problem. With the aim of addressing this challenge, this paper formalizes this continual learning and private unlearning (CLPU) problem. The paper further introduces a straightforward but exactly private solution, CLPU-DER++, as the first step towards solving the CLPU problem, along with a set of carefully designed benchmark problems to evaluate the effectiveness of the proposed solution.", "paper_url": "http://arxiv.org/abs/2203.12817v1", "pdf_url": "http://arxiv.org/pdf/2203.12817v1", "repo_url": null}, "2203.13611": {"publish_time": "2022-03-25", "title": "Class-Incremental Learning for Action Recognition in Videos", "author": "Jaeyoo Park et.al.", "abstract": "We tackle catastrophic forgetting problem in the context of class-incremental learning for video recognition, which has not been explored actively despite the popularity of continual learning. Our framework addresses this challenging task by introducing time-channel importance maps and exploiting the importance maps for learning the representations of incoming examples via knowledge distillation. We also incorporate a regularization scheme in our objective function, which encourages individual features obtained from different time steps in a video to be uncorrelated and eventually improves accuracy by alleviating catastrophic forgetting. We evaluate the proposed approach on brand-new splits of class-incremental action recognition benchmarks constructed upon the UCF101, HMDB51, and Something-Something V2 datasets, and demonstrate the effectiveness of our algorithm in comparison to the existing continual learning methods that are originally designed for image data.", "paper_url": "http://arxiv.org/abs/2203.13611v1", "pdf_url": "http://arxiv.org/pdf/2203.13611v1", "repo_url": null}, "2203.13381": {"publish_time": "2022-03-24", "title": "Probing Representation Forgetting in Supervised and Unsupervised Continual Learning", "author": "MohammadReza Davari et.al.", "abstract": "Continual Learning research typically focuses on tackling the phenomenon of catastrophic forgetting in neural networks. Catastrophic forgetting is associated with an abrupt loss of knowledge previously learned by a model when the task, or more broadly the data distribution, being trained on changes. In supervised learning problems this forgetting, resulting from a change in the model's representation, is typically measured or observed by evaluating the decrease in old task performance. However, a model's representation can change without losing knowledge about prior tasks. In this work we consider the concept of representation forgetting, observed by using the difference in performance of an optimal linear classifier before and after a new task is introduced. Using this tool we revisit a number of standard continual learning benchmarks and observe that, through this lens, model representations trained without any explicit control for forgetting often experience small representation forgetting and can sometimes be comparable to methods which explicitly control for forgetting, especially in longer task sequences. We also show that representation forgetting can lead to new insights on the effect of model capacity and loss function used in continual learning. Based on our results, we show that a simple yet competitive approach is to learn representations continually with standard supervised contrastive learning while constructing prototypes of class samples when queried on old samples.", "paper_url": "http://arxiv.org/abs/2203.13381v1", "pdf_url": "http://arxiv.org/pdf/2203.13381v1", "repo_url": null}, "2203.13321": {"publish_time": "2022-03-24", "title": "Addressing Client Drift in Federated Continual Learning with Adaptive Optimization", "author": "Yeshwanth Venkatesha et.al.", "abstract": "Federated learning has been extensively studied and is the prevalent method for privacy-preserving distributed learning in edge devices. Correspondingly, continual learning is an emerging field targeted towards learning multiple tasks sequentially. However, there is little attention towards additional challenges emerging when federated aggregation is performed in a continual learning system. We identify \\textit{client drift} as one of the key weaknesses that arise when vanilla federated averaging is applied in such a system, especially since each client can independently have different order of tasks. We outline a framework for performing Federated Continual Learning (FCL) by using NetTailor as a candidate continual learning approach and show the extent of the problem of client drift. We show that adaptive federated optimization can reduce the adverse impact of client drift and showcase its effectiveness on CIFAR100, MiniImagenet, and Decathlon benchmarks. Further, we provide an empirical analysis highlighting the interplay between different hyperparameters such as client and server learning rates, the number of local training iterations, and communication rounds. Finally, we evaluate our framework on useful characteristics of federated learning systems such as scalability, robustness to the skewness in clients' data distribution, and stragglers.", "paper_url": "http://arxiv.org/abs/2203.13321v1", "pdf_url": "http://arxiv.org/pdf/2203.13321v1", "repo_url": null}, "2203.13307": {"publish_time": "2022-03-24", "title": "Tackling Online One-Class Incremental Learning by Removing Negative Contrasts", "author": "Nader Asadi et.al.", "abstract": "Recent work studies the supervised online continual learning setting where a learner receives a stream of data whose class distribution changes over time. Distinct from other continual learning settings the learner is presented new samples only once and must distinguish between all seen classes. A number of successful methods in this setting focus on storing and replaying a subset of samples alongside incoming data in a computationally efficient manner. One recent proposal ER-AML achieved strong performance in this setting by applying an asymmetric loss based on contrastive learning to the incoming data and replayed data. However, a key ingredient of the proposed method is avoiding contrasts between incoming data and stored data, which makes it impractical for the setting where only one new class is introduced in each phase of the stream. In this work we adapt a recently proposed approach (\\textit{BYOL}) from self-supervised learning to the supervised learning setting, unlocking the constraint on contrasts. We then show that supplementing this with additional regularization on class prototypes yields a new method that achieves strong performance in the one-class incremental learning setting and is competitive with the top performing methods in the multi-class incremental setting.", "paper_url": "http://arxiv.org/abs/2203.13307v1", "pdf_url": "http://arxiv.org/pdf/2203.13307v1", "repo_url": null}, "2203.14544": {"publish_time": "2022-03-28", "title": "Gradient-Matching Coresets for Rehearsal-Based Continual Learning", "author": "Lukas Balles et.al.", "abstract": "The goal of continual learning (CL) is to efficiently update a machine learning model with new data without forgetting previously-learned knowledge. Most widely-used CL methods rely on a rehearsal memory of data points to be reused while training on new data. Curating such a rehearsal memory to maintain a small, informative subset of all the data seen so far is crucial to the success of these methods. We devise a coreset selection method for rehearsal-based continual learning. Our method is based on the idea of gradient matching: The gradients induced by the coreset should match, as closely as possible, those induced by the original training dataset. Inspired by the neural tangent kernel theory, we perform this gradient matching across the model's initialization distribution, allowing us to extract a coreset without having to train the model first. We evaluate the method on a wide range of continual learning scenarios and demonstrate that it improves the performance of rehearsal-based CL methods compared to competing memory management strategies such as reservoir sampling.", "paper_url": "http://arxiv.org/abs/2203.14544v1", "pdf_url": "http://arxiv.org/pdf/2203.14544v1", "repo_url": null}, "2203.14383": {"publish_time": "2022-03-27", "title": "Continual learning: a feature extraction formalization, an efficient algorithm, and fundamental obstructions", "author": "Binghui Peng et.al.", "abstract": "Continual learning is an emerging paradigm in machine learning, wherein a model is exposed in an online fashion to data from multiple different distributions (i.e. environments), and is expected to adapt to the distribution change. Precisely, the goal is to perform well in the new environment, while simultaneously retaining the performance on the previous environments (i.e. avoid \"catastrophic forgetting\") -- without increasing the size of the model.   While this setup has enjoyed a lot of attention in the applied community, there hasn't be theoretical work that even formalizes the desired guarantees. In this paper, we propose a framework for continual learning through the framework of feature extraction -- namely, one in which features, as well as a classifier, are being trained with each environment. When the features are linear, we design an efficient gradient-based algorithm $\\mathsf{DPGD}$, that is guaranteed to perform well on the current environment, as well as avoid catastrophic forgetting. In the general case, when the features are non-linear, we show such an algorithm cannot exist, whether efficient or not.", "paper_url": "http://arxiv.org/abs/2203.14383v1", "pdf_url": "http://arxiv.org/pdf/2203.14383v1", "repo_url": null}, "2203.14327": {"publish_time": "2022-03-27", "title": "Local-Adaptive Face Recognition via Graph-based Meta-Clustering and Regularized Adaptation", "author": "Wenbin Zhu et.al.", "abstract": "Due to the rising concern of data privacy, it's reasonable to assume the local client data can't be transferred to a centralized server, nor their associated identity label is provided. To support continuous learning and fill the last-mile quality gap, we introduce a new problem setup called Local-Adaptive Face Recognition (LaFR). Leveraging the environment-specific local data after the deployment of the initial global model, LaFR aims at getting optimal performance by training local-adapted models automatically and un-supervisely, as opposed to fixing their initial global model. We achieve this by a newly proposed embedding cluster model based on Graph Convolution Network (GCN), which is trained via meta-optimization procedure. Compared with previous works, our meta-clustering model can generalize well in unseen local environments. With the pseudo identity labels from the clustering results, we further introduce novel regularization techniques to improve the model adaptation performance. Extensive experiments on racial and internal sensor adaptation demonstrate that our proposed solution is more effective for adapting face recognition models in each specific environment. Meanwhile, we show that LaFR can further improve the global model by a simple federated aggregation over the updated local models.", "paper_url": "http://arxiv.org/abs/2203.14327v1", "pdf_url": "http://arxiv.org/pdf/2203.14327v1", "repo_url": null}, "2203.14032": {"publish_time": "2022-03-26", "title": "Continual learning of quantum state classification with gradient episodic memory", "author": "Haozhen Situ et.al.", "abstract": "Continual learning is one of the many areas of machine learning research. For the goal of strong artificial intelligence that can mimic human-level intelligence, AI systems would have the ability to adapt to ever-changing scenarios and learn new knowledge continuously without forgetting previously acquired knowledge. A phenomenon called catastrophic forgetting emerges when a machine learning model is trained across multiple tasks. The model's performance on previously learned tasks may drop dramatically during the learning process of the newly seen task. Some continual learning strategies have been proposed to address the catastrophic forgetting problem. Recently, continual learning has also been studied in the context of quantum machine learning. By leveraging the elastic weight consolidation method, a single quantum classifier can perform multiple tasks after being trained consecutively on those tasks. In this work, we incorporate the gradient episodic memory method to train a variational quantum classifier. The gradient of the current task is projected to the closest gradient, avoiding the increase of the loss at previous tasks, but allowing the decrease. We use six quantum state classification tasks to benchmark this method. Numerical simulation results show that better performance is obtained compared to the elastic weight consolidation method. Furthermore, positive transfer of knowledge to previous tasks is observed, which means the classifier's performance on previous tasks is enhanced rather than compromised while learning a new task.", "paper_url": "http://arxiv.org/abs/2203.14032v1", "pdf_url": "http://arxiv.org/pdf/2203.14032v1", "repo_url": null}, "2203.15355": {"publish_time": "2022-03-29", "title": "Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries", "author": "Jihwan Bang et.al.", "abstract": "Learning under a continuously changing data distribution with incorrect labels is a desirable real-world problem yet challenging. A large body of continual learning (CL) methods, however, assumes data streams with clean labels, and online learning scenarios under noisy data streams are yet underexplored. We consider a more practical CL task setup of an online learning from blurry data stream with corrupted labels, where existing CL methods struggle. To address the task, we first argue the importance of both diversity and purity of examples in the episodic memory of continual learning models. To balance diversity and purity in the episodic memory, we propose a novel strategy to manage and use the memory by a unified approach of label noise aware diverse sampling and robust learning with semi-supervised learning. Our empirical validations on four real-world or synthetic noise datasets (CIFAR10 and 100, mini-WebVision, and Food-101N) exhibit that our method significantly outperforms prior arts in this realistic and challenging continual learning scenario. Code and data splits are available in https://github.com/clovaai/puridiver.", "paper_url": "http://arxiv.org/abs/2203.15355v2", "pdf_url": "http://arxiv.org/pdf/2203.15355v2", "repo_url": "https://github.com/clovaai/puridiver"}, "2203.16195": {"publish_time": "2022-03-30", "title": "On the Road to Online Adaptation for Semantic Image Segmentation", "author": "Riccardo Volpi et.al.", "abstract": "We propose a new problem formulation and a corresponding evaluation framework to advance research on unsupervised domain adaptation for semantic image segmentation. The overall goal is fostering the development of adaptive learning systems that will continuously learn, without supervision, in ever-changing environments. Typical protocols that study adaptation algorithms for segmentation models are limited to few domains, adaptation happens offline, and human intervention is generally required, at least to annotate data for hyper-parameter tuning. We argue that such constraints are incompatible with algorithms that can continuously adapt to different real-world situations. To address this, we propose a protocol where models need to learn online, from sequences of temporally correlated images, requiring continuous, frame-by-frame adaptation. We accompany this new protocol with a variety of baselines to tackle the proposed formulation, as well as an extensive analysis of their behaviors, which can serve as a starting point for future research.", "paper_url": "http://arxiv.org/abs/2203.16195v1", "pdf_url": "http://arxiv.org/pdf/2203.16195v1", "repo_url": "https://github.com/naver/oasis"}, "2203.16102": {"publish_time": "2022-03-30", "title": "Continual Normalization: Rethinking Batch Normalization for Online Continual Learning", "author": "Quang Pham et.al.", "abstract": "Existing continual learning methods use Batch Normalization (BN) to facilitate training and improve generalization across tasks. However, the non-i.i.d and non-stationary nature of continual learning data, especially in the online setting, amplify the discrepancy between training and testing in BN and hinder the performance of older tasks. In this work, we study the cross-task normalization effect of BN in online continual learning where BN normalizes the testing data using moments biased towards the current task, resulting in higher catastrophic forgetting. This limitation motivates us to propose a simple yet effective method that we call Continual Normalization (CN) to facilitate training similar to BN while mitigating its negative effect. Extensive experiments on different continual learning algorithms and online scenarios show that CN is a direct replacement for BN and can provide substantial performance improvements. Our implementation is available at \\url{https://github.com/phquang/Continual-Normalization}.", "paper_url": "http://arxiv.org/abs/2203.16102v1", "pdf_url": "http://arxiv.org/pdf/2203.16102v1", "repo_url": null}, "2203.17269": {"publish_time": "2022-03-31", "title": "A Closer Look at Rehearsal-Free Continual Learning", "author": "James Seale Smith et.al.", "abstract": "Continual learning describes a setting where machine learning models learn novel concepts from continuously shifting training data, while simultaneously avoiding degradation of knowledge on previously seen classes (a phenomenon known as the catastrophic forgetting problem) which may disappear from the training data for extended periods of time. Current approaches for continual learning of a single expanding task (aka class-incremental continual learning) require extensive rehearsal of previously seen data to avoid this degradation of knowledge. Unfortunately, rehearsal comes at a sharp cost to memory and computation, and it may also violate data-privacy. Instead, we explore combining knowledge distillation and parameter regularization in new ways to achieve strong continual learning performance without rehearsal. Specifically, we take a deep dive into common continual learning techniques: prediction distillation, feature distillation, L2 parameter regularization, and EWC parameter regularization. We first disprove the common assumption that parameter regularization techniques fail for rehearsal-free continual learning of a single, expanding task. Next, we explore how to leverage knowledge from a pre-trained model in rehearsal-free continual learning and find that vanilla L2 parameter regularization outperforms EWC parameter regularization and feature distillation. We then highlight the impact of the rehearsal-free continual learning settings with a classifier expansion benchmark, showing that a strategy based on our findings combined with a positive/negative label balancing heuristic can close the performance gap between the upper bound and the existing strategies by up to roughly 50%. Finally, we show that a simple method consisting of pre-training, L2 regularization, and prediction distillation can even outperform rehearsal-based methods on the common CIFAR-100 benchmark.", "paper_url": "http://arxiv.org/abs/2203.17269v1", "pdf_url": "http://arxiv.org/pdf/2203.17269v1", "repo_url": null}, "2203.16588": {"publish_time": "2022-03-30", "title": "Constrained Few-shot Class-incremental Learning", "author": "Michael Hersche et.al.", "abstract": "Continually learning new classes from fresh data without forgetting previous knowledge of old classes is a very challenging research problem. Moreover, it is imperative that such learning must respect certain memory and computational constraints such as (i) training samples are limited to only a few per class, (ii) the computational cost of learning a novel class remains constant, and (iii) the memory footprint of the model grows at most linearly with the number of classes observed. To meet the above constraints, we propose C-FSCIL, which is architecturally composed of a frozen meta-learned feature extractor, a trainable fixed-size fully connected layer, and a rewritable dynamically growing memory that stores as many vectors as the number of encountered classes. C-FSCIL provides three update modes that offer a trade-off between accuracy and compute-memory cost of learning novel classes. C-FSCIL exploits hyperdimensional embedding that allows to continually express many more classes than the fixed dimensions in the vector space, with minimal interference. The quality of class vector representations is further improved by aligning them quasi-orthogonally to each other by means of novel loss functions. Experiments on the CIFAR100, miniImageNet, and Omniglot datasets show that C-FSCIL outperforms the baselines with remarkable accuracy and compression. It also scales up to the largest problem size ever tried in this few-shot setting by learning 423 novel classes on top of 1200 base classes with less than 1.6% accuracy drop. Our code is available at https://github.com/IBM/constrained-FSCIL.", "paper_url": "http://arxiv.org/abs/2203.16588v1", "pdf_url": "http://arxiv.org/pdf/2203.16588v1", "repo_url": "https://github.com/ibm/constrained-fscil"}, "2204.00545": {"publish_time": "2022-04-01", "title": "A Novel Multimodal Approach for Studying the Dynamics of Curiosity in Small Group Learning", "author": "Tanmay Sinha et.al.", "abstract": "Curiosity is a vital metacognitive skill in educational contexts, leading to creativity, and a love of learning. And while many school systems increasingly undercut curiosity by teaching to the test, teachers are increasingly interested in how to evoke curiosity in their students to prepare them for a world in which lifelong learning and reskilling will be more and more important. One aspect of curiosity that has received little attention, however, is the role of peers in eliciting curiosity. We present what we believe to be the first theoretical framework that articulates an integrated socio-cognitive account of curiosity that ties observable behaviors in peers to underlying curiosity states. We make a bipartite distinction between individual and interpersonal functions that contribute to curiosity, and multimodal behaviors that fulfill these functions. We validate the proposed framework by leveraging a longitudinal latent variable modeling approach. Findings confirm a positive predictive relationship between the latent variables of individual and interpersonal functions and curiosity, with the interpersonal functions exercising a comparatively stronger influence. Prominent behavioral realizations of these functions are also discovered in a data-driven manner. We instantiate the proposed theoretical framework in a set of strategies and tactics that can be incorporated into learning technologies to indicate, evoke, and scaffold curiosity. This work is a step towards designing learning technologies that can recognize and evoke moment-by-moment curiosity during learning in social contexts and towards a more complete multimodal learning analytics. The underlying rationale is applicable more generally for developing computer support for other metacognitive and socio-emotional skills.", "paper_url": "http://arxiv.org/abs/2204.00545v1", "pdf_url": "http://arxiv.org/pdf/2204.00545v1", "repo_url": null}, "2204.00121": {"publish_time": "2022-03-31", "title": "An MPSoC-based on-line Edge Infrastructure for Embedded Neuromorphic Robotic Controllers", "author": "Enrique Pinero-Fuentes et.al.", "abstract": "In this work, an all-in-one neuromorphic controller system with reduced latency and power consumption for a robotic arm is presented. Biological muscle movement consists of stretching and shrinking fibres via spike-commanded signals that come from motor neurons, which in turn are connected to a central pattern generator neural structure. In addition, biological systems are able to respond to diverse stimuli rather fast and efficiently, and this is based on the way information is coded within neural processes. As opposed to human-created encoding systems, neural ones use neurons and spikes to process the information and make weighted decisions based on a continuous learning process. The Event-Driven Scorbot platform (ED-Scorbot) consists of a 6 Degrees of Freedom (DoF) robotic arm whose controller implements a Spiking Proportional-Integrative- Derivative algorithm, mimicking in this way the previously commented biological systems. In this paper, we present an infrastructure upgrade to the ED-Scorbot platform, replacing the controller hardware, which was comprised of two Spartan Field Programmable Gate Arrays (FPGAs) and a barebone computer, with an edge device, the Xilinx Zynq-7000 SoC (System on Chip) which reduces the response time, power consumption and overall complexity.", "paper_url": "http://arxiv.org/abs/2204.00121v1", "pdf_url": "http://arxiv.org/pdf/2204.00121v1", "repo_url": null}, "2204.00895": {"publish_time": "2022-04-02", "title": "Class-Incremental Learning by Knowledge Distillation with Adaptive Feature Consolidation", "author": "Minsoo Kang et.al.", "abstract": "We present a novel class incremental learning approach based on deep neural networks, which continually learns new tasks with limited memory for storing examples in the previous tasks. Our algorithm is based on knowledge distillation and provides a principled way to maintain the representations of old models while adjusting to new tasks effectively. The proposed method estimates the relationship between the representation changes and the resulting loss increases incurred by model updates. It minimizes the upper bound of the loss increases using the representations, which exploits the estimated importance of each feature map within a backbone model. Based on the importance, the model restricts updates of important features for robustness while allowing changes in less critical features for flexibility. This optimization strategy effectively alleviates the notorious catastrophic forgetting problem despite the limited accessibility of data in the previous tasks. The experimental results show significant accuracy improvement of the proposed algorithm over the existing methods on the standard datasets. Code is available.", "paper_url": "http://arxiv.org/abs/2204.00895v1", "pdf_url": "http://arxiv.org/pdf/2204.00895v1", "repo_url": "https://github.com/kminsoo/afc"}, "2204.02296": {"publish_time": "2022-04-05", "title": "iSDF: Real-Time Neural Signed Distance Fields for Robot Perception", "author": "Joseph Ortiz et.al.", "abstract": "We present iSDF, a continual learning system for real-time signed distance field (SDF) reconstruction. Given a stream of posed depth images from a moving camera, it trains a randomly initialised neural network to map input 3D coordinate to approximate signed distance. The model is self-supervised by minimising a loss that bounds the predicted signed distance using the distance to the closest sampled point in a batch of query points that are actively sampled. In contrast to prior work based on voxel grids, our neural method is able to provide adaptive levels of detail with plausible filling in of partially observed regions and denoising of observations, all while having a more compact representation. In evaluations against alternative methods on real and synthetic datasets of indoor environments, we find that iSDF produces more accurate reconstructions, and better approximations of collision costs and gradients useful for downstream planners in domains from navigation to manipulation. Code and video results can be found at our project page: https://joeaortiz.github.io/iSDF/ .", "paper_url": "http://arxiv.org/abs/2204.02296v1", "pdf_url": "http://arxiv.org/pdf/2204.02296v1", "repo_url": null}, "2204.01934": {"publish_time": "2022-04-05", "title": "Attention Distraction: Watermark Removal Through Continual Learning with Selective Forgetting", "author": "Qi Zhong et.al.", "abstract": "Fine-tuning attacks are effective in removing the embedded watermarks in deep learning models. However, when the source data is unavailable, it is challenging to just erase the watermark without jeopardizing the model performance. In this context, we introduce Attention Distraction (AD), a novel source data-free watermark removal attack, to make the model selectively forget the embedded watermarks by customizing continual learning. In particular, AD first anchors the model's attention on the main task using some unlabeled data. Then, through continual learning, a small number of \\textit{lures} (randomly selected natural images) that are assigned a new label distract the model's attention away from the watermarks. Experimental results from different datasets and networks corroborate that AD can thoroughly remove the watermark with a small resource budget without compromising the model's performance on the main task, which outperforms the state-of-the-art works.", "paper_url": "http://arxiv.org/abs/2204.01934v1", "pdf_url": "http://arxiv.org/pdf/2204.01934v1", "repo_url": null}, "2204.04078": {"publish_time": "2022-04-08", "title": "General Incremental Learning with Domain-aware Categorical Representations", "author": "Jiangwei Xie et.al.", "abstract": "Continual learning is an important problem for achieving human-level intelligence in real-world applications as an agent must continuously accumulate knowledge in response to streaming data/tasks. In this work, we consider a general and yet under-explored incremental learning problem in which both the class distribution and class-specific domain distribution change over time. In addition to the typical challenges in class incremental learning, this setting also faces the intra-class stability-plasticity dilemma and intra-class domain imbalance problems. To address above issues, we develop a novel domain-aware continual learning method based on the EM framework. Specifically, we introduce a flexible class representation based on the von Mises-Fisher mixture model to capture the intra-class structure, using an expansion-and-reduction strategy to dynamically increase the number of components according to the class complexity. Moreover, we design a bi-level balanced memory to cope with data imbalances within and across classes, which combines with a distillation loss to achieve better inter- and intra-class stability-plasticity trade-off. We conduct exhaustive experiments on three benchmarks: iDigits, iDomainNet and iCIFAR-20. The results show that our approach consistently outperforms previous methods by a significant margin, demonstrating its superiority.", "paper_url": "http://arxiv.org/abs/2204.04078v1", "pdf_url": "http://arxiv.org/pdf/2204.04078v1", "repo_url": null}, "2204.03895": {"publish_time": "2022-04-08", "title": "SoundBeam: Target sound extraction conditioned on sound-class labels and enrollment clues for increased performance and continuous learning", "author": "Marc Delcroix et.al.", "abstract": "In many situations, we would like to hear desired sound events (SEs) while being able to ignore interference. Target sound extraction (TSE) aims at tackling this problem by estimating the sound of target SE classes in a mixture while suppressing all other sounds. We can achieve this with a neural network that extracts the target SEs by conditioning it on clues representing the target SE classes. Two types of clues have been proposed, i.e., target SE class labels and enrollment sound samples similar to the target sound. Systems based on SE class labels can directly optimize embedding vectors representing the SE classes, resulting in high extraction performance. However, extending these systems to the extraction of new SE classes not encountered during training is not easy. Enrollment-based approaches extract SEs by finding sounds in the mixtures that share similar characteristics to the enrollment. These approaches do not explicitly rely on SE class definitions and can thus handle new SE classes. In this paper, we introduce a TSE framework, SoundBeam, that combines the advantages of both approaches. We also perform an extensive evaluation of the different TSE schemes using synthesized and real mixtures, which shows the potential of SoundBeam.", "paper_url": "http://arxiv.org/abs/2204.03895v1", "pdf_url": "http://arxiv.org/pdf/2204.03895v1", "repo_url": null}, "2204.05220": {"publish_time": "2022-04-11", "title": "CFA: Constraint-based Finetuning Approach for Generalized Few-Shot Object Detection", "author": "Karim Guirguis et.al.", "abstract": "Few-shot object detection (FSOD) seeks to detect novel categories with limited data by leveraging prior knowledge from abundant base data. Generalized few-shot object detection (G-FSOD) aims to tackle FSOD without forgetting previously seen base classes and, thus, accounts for a more realistic scenario, where both classes are encountered during test time. While current FSOD methods suffer from catastrophic forgetting, G-FSOD addresses this limitation yet exhibits a performance drop on novel tasks compared to the state-of-the-art FSOD. In this work, we propose a constraint-based finetuning approach (CFA) to alleviate catastrophic forgetting, while achieving competitive results on the novel task without increasing the model capacity. CFA adapts a continual learning method, namely Average Gradient Episodic Memory (A-GEM) to G-FSOD. Specifically, more constraints on the gradient search strategy are imposed from which a new gradient update rule is derived, allowing for better knowledge exchange between base and novel classes. To evaluate our method, we conduct extensive experiments on MS-COCO and PASCAL-VOC datasets. Our method outperforms current FSOD and G-FSOD approaches on the novel task with minor degeneration on the base task. Moreover, CFA is orthogonal to FSOD approaches and operates as a plug-and-play module without increasing the model capacity or inference time.", "paper_url": "http://arxiv.org/abs/2204.05220v1", "pdf_url": "http://arxiv.org/pdf/2204.05220v1", "repo_url": null}, "2204.04799": {"publish_time": "2022-04-10", "title": "DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning", "author": "Zifeng Wang et.al.", "abstract": "Continual learning aims to enable a single model to learn a sequence of tasks without catastrophic forgetting. Top-performing methods usually require a rehearsal buffer to store past pristine examples for experience replay, which, however, limits their practical value due to privacy and memory constraints. In this work, we present a simple yet effective framework, DualPrompt, which learns a tiny set of parameters, called prompts, to properly instruct a pre-trained model to learn tasks arriving sequentially without buffering past examples. DualPrompt presents a novel approach to attach complementary prompts to the pre-trained backbone, and then formulates the objective as learning task-invariant and task-specific \"instructions\". With extensive experimental validation, DualPrompt consistently sets state-of-the-art performance under the challenging class-incremental setting. In particular, DualPrompt outperforms recent advanced continual learning methods with relatively large buffer sizes. We also introduce a more challenging benchmark, Split ImageNet-R, to help generalize rehearsal-free continual learning research. Source code is available at https://github.com/google-research/l2p.", "paper_url": "http://arxiv.org/abs/2204.04799v1", "pdf_url": "http://arxiv.org/pdf/2204.04799v1", "repo_url": "https://github.com/google-research/l2p"}, "2204.04795": {"publish_time": "2022-04-10", "title": "Edge Continual Learning for Dynamic Digital Twins over Wireless Networks", "author": "Omar Hashash et.al.", "abstract": "Digital twins (DTs) constitute a critical link between the real-world and the metaverse. To guarantee a robust connection between these two worlds, DTs should maintain accurate representations of the physical applications, while preserving synchronization between real and digital entities. In this paper, a novel edge continual learning framework is proposed to accurately model the evolving affinity between a physical twin (PT) and its corresponding cyber twin (CT) while maintaining their utmost synchronization. In particular, a CT is simulated as a deep neural network (DNN) at the wireless network edge to model an autonomous vehicle traversing an episodically dynamic environment. As the vehicular PT updates its driving policy in each episode, the CT is required to concurrently adapt its DNN model to the PT, which gives rise to a de-synchronization gap. Considering the history-aware nature of DTs, the model update process is posed a dual objective optimization problem whose goal is to jointly minimize the loss function over all encountered episodes and the corresponding de-synchronization time. As the de-synchronization time continues to increase over sequential episodes, an elastic weight consolidation (EWC) technique that regularizes the DT history is proposed to limit de-synchronization time. Furthermore, to address the plasticity-stability tradeoff accompanying the progressive growth of the EWC regularization terms, a modified EWC method that considers fair execution between the historical episodes of the DTs is adopted. Ultimately, the proposed framework achieves a simultaneously accurate and synchronous CT model that is robust to catastrophic forgetting. Simulation results show that the proposed solution can achieve an accuracy of 90 % while guaranteeing a minimal desynchronization time.", "paper_url": "http://arxiv.org/abs/2204.04795v1", "pdf_url": "http://arxiv.org/pdf/2204.04795v1", "repo_url": null}, "2204.04763": {"publish_time": "2022-04-10", "title": "Information-theoretic Online Memory Selection for Continual Learning", "author": "Shengyang Sun et.al.", "abstract": "A challenging problem in task-free continual learning is the online selection of a representative replay memory from data streams. In this work, we investigate the online memory selection problem from an information-theoretic perspective. To gather the most information, we propose the \\textit{surprise} and the \\textit{learnability} criteria to pick informative points and to avoid outliers. We present a Bayesian model to compute the criteria efficiently by exploiting rank-one matrix structures. We demonstrate that these criteria encourage selecting informative points in a greedy algorithm for online memory selection. Furthermore, by identifying the importance of \\textit{the timing to update the memory}, we introduce a stochastic information-theoretic reservoir sampler (InfoRS), which conducts sampling among selective points with high information. Compared to reservoir sampling, InfoRS demonstrates improved robustness against data imbalance. Finally, empirical performances over continual learning benchmarks manifest its efficiency and efficacy.", "paper_url": "http://arxiv.org/abs/2204.04763v1", "pdf_url": "http://arxiv.org/pdf/2204.04763v1", "repo_url": null}, "2204.04297": {"publish_time": "2022-04-08", "title": "Learning to modulate random weights can induce task-specific contexts for economical meta and continual learning", "author": "Jinyung Hong et.al.", "abstract": "Neural networks are vulnerable to catastrophic forgetting when data distributions are non-stationary during continual online learning; learning of a later task often leads to forgetting of an earlier task. One solution approach is model-agnostic continual meta-learning, whereby both task-specific and meta parameters are trained. Here, we depart from this view and introduce a novel neural-network architecture inspired by neuromodulation in biological nervous systems. Neuromodulation is the biological mechanism that dynamically controls and fine-tunes synaptic dynamics to complement the behavioral context in real-time, which has received limited attention in machine learning. We introduce a single-hidden-layer network that learns only a relatively small context vector per task (task-specific parameters) that neuromodulates unchanging, randomized weights (meta parameters) that transform the input. We show that when task boundaries are available, this approach can eliminate catastrophic forgetting entirely while also drastically reducing the number of learnable parameters relative to other context-vector-based approaches. Furthermore, by combining this model with a simple meta-learning approach for inferring task identity, we demonstrate that the model can be generalized into a framework to perform continual learning without knowledge of task boundaries. Finally, we showcase the framework in a supervised continual online learning scenario and discuss the implications of the proposed formalism.", "paper_url": "http://arxiv.org/abs/2204.04297v1", "pdf_url": "http://arxiv.org/pdf/2204.04297v1", "repo_url": null}, "2204.05928": {"publish_time": "2022-04-12", "title": "Dynamic Dialogue Policy Transformer for Continual Reinforcement Learning", "author": "Christian Geishauser et.al.", "abstract": "Continual learning is one of the key components of human learning and a necessary requirement of artificial intelligence. As dialogue can potentially span infinitely many topics and tasks, a task-oriented dialogue system must have the capability to continually learn, dynamically adapting to new challenges while preserving the knowledge it already acquired. Despite the importance, continual reinforcement learning of the dialogue policy has remained largely unaddressed. The lack of a framework with training protocols, baseline models and suitable metrics, has so far hindered research in this direction. In this work we fill precisely this gap, enabling research in dialogue policy optimisation to go from static to dynamic learning. We provide a continual learning algorithm, baseline architectures and metrics for assessing continual learning models. Moreover, we propose the dynamic dialogue policy transformer (DDPT), a novel dynamic architecture that can integrate new knowledge seamlessly, is capable of handling large state spaces and obtains significant zero-shot performance when being exposed to unseen domains, without any growth in network parameter size.", "paper_url": "http://arxiv.org/abs/2204.05928v1", "pdf_url": "http://arxiv.org/pdf/2204.05928v1", "repo_url": null}, "2204.05893": {"publish_time": "2022-04-12", "title": "Offline Distillation for Robot Lifelong Learning with Imbalanced Experience", "author": "Wenxuan Zhou et.al.", "abstract": "Robots will experience non-stationary environment dynamics throughout their lifetime: the robot dynamics can change due to wear and tear, or its surroundings may change over time. Eventually, the robots should perform well in all of the environment variations it has encountered. At the same time, it should still be able to learn fast in a new environment. We investigate two challenges in such a lifelong learning setting: first, existing off-policy algorithms struggle with the trade-off between being conservative to maintain good performance in the old environment and learning efficiently in the new environment. We propose the Offline Distillation Pipeline to break this trade-off by separating the training procedure into interleaved phases of online interaction and offline distillation. Second, training with the combined datasets from multiple environments across the lifetime might create a significant performance drop compared to training on the datasets individually. Our hypothesis is that both the imbalanced quality and size of the datasets exacerbate the extrapolation error of the Q-function during offline training over the \"weaker\" dataset. We propose a simple fix to the issue by keeping the policy closer to the dataset during the distillation phase. In the experiments, we demonstrate these challenges and the proposed solutions with a simulated bipedal robot walking task across various environment changes. We show that the Offline Distillation Pipeline achieves better performance across all the encountered environments without affecting data collection. We also provide a comprehensive empirical study to support our hypothesis on the data imbalance issue.", "paper_url": "http://arxiv.org/abs/2204.05893v1", "pdf_url": "http://arxiv.org/pdf/2204.05893v1", "repo_url": null}, "2204.05842": {"publish_time": "2022-04-12", "title": "Generative Negative Replay for Continual Learning", "author": "Gabriele Graffieti et.al.", "abstract": "Learning continually is a key aspect of intelligence and a necessary ability to solve many real-life problems. One of the most effective strategies to control catastrophic forgetting, the Achilles' heel of continual learning, is storing part of the old data and replaying them interleaved with new experiences (also known as the replay approach). Generative replay, which is using generative models to provide replay patterns on demand, is particularly intriguing, however, it was shown to be effective mainly under simplified assumptions, such as simple scenarios and low-dimensional data. In this paper, we show that, while the generated data are usually not able to improve the classification accuracy for the old classes, they can be effective as negative examples (or antagonists) to better learn the new classes, especially when the learning experiences are small and contain examples of just one or few classes. The proposed approach is validated on complex class-incremental and data-incremental continual learning scenarios (CORe50 and ImageNet-1000) composed of high-dimensional data and a large number of training experiences: a setup where existing generative replay approaches usually fail.", "paper_url": "http://arxiv.org/abs/2204.05842v1", "pdf_url": "http://arxiv.org/pdf/2204.05842v1", "repo_url": null}, "2204.05737": {"publish_time": "2022-04-12", "title": "LifeLonger: A Benchmark for Continual Disease Classification", "author": "Mohammad Mahdi Derakhshani et.al.", "abstract": "Deep learning models have shown a great effectiveness in recognition of findings in medical images. However, they cannot handle the ever-changing clinical environment, bringing newly annotated medical data from different sources. To exploit the incoming streams of data, these models would benefit largely from sequentially learning from new samples, without forgetting the previously obtained knowledge. In this paper we introduce LifeLonger, a benchmark for continual disease classification on the MedMNIST collection, by applying existing state-of-the-art continual learning methods. In particular, we consider three continual learning scenarios, namely, task and class incremental learning and the newly defined cross-domain incremental learning. Task and class incremental learning of diseases address the issue of classifying new samples without re-training the models from scratch, while cross-domain incremental learning addresses the issue of dealing with datasets originating from different institutions while retaining the previously obtained knowledge. We perform a thorough analysis of the performance and examine how the well-known challenges of continual learning, such as the catastrophic forgetting exhibit themselves in this setting. The encouraging results demonstrate that continual learning has a major potential to advance disease classification and to produce a more robust and efficient learning framework for clinical settings. The code repository, data partitions and baseline results for the complete benchmark will be made publicly available.", "paper_url": "http://arxiv.org/abs/2204.05737v1", "pdf_url": "http://arxiv.org/pdf/2204.05737v1", "repo_url": null}, "2204.05624": {"publish_time": "2022-04-12", "title": "Continual Predictive Learning from Videos", "author": "Geng Chen et.al.", "abstract": "Predictive learning ideally builds the world model of physical processes in one or more given environments. Typical setups assume that we can collect data from all environments at all times. In practice, however, different prediction tasks may arrive sequentially so that the environments may change persistently throughout the training procedure. Can we develop predictive learning algorithms that can deal with more realistic, non-stationary physical environments? In this paper, we study a new continual learning problem in the context of video prediction, and observe that most existing methods suffer from severe catastrophic forgetting in this setup. To tackle this problem, we propose the continual predictive learning (CPL) approach, which learns a mixture world model via predictive experience replay and performs test-time adaptation with non-parametric task inference. We construct two new benchmarks based on RoboNet and KTH, in which different tasks correspond to different physical robotic environments or human actions. Our approach is shown to effectively mitigate forgetting and remarkably outperform the na\\\"ive combinations of previous art in video prediction and continual learning.", "paper_url": "http://arxiv.org/abs/2204.05624v1", "pdf_url": "http://arxiv.org/pdf/2204.05624v1", "repo_url": "https://github.com/jc043/cpl"}, "2204.07429": {"publish_time": "2022-04-15", "title": "Experimentally realized memristive memory augmented neural network", "author": "Ruibin Mao et.al.", "abstract": "Lifelong on-device learning is a key challenge for machine intelligence, and this requires learning from few, often single, samples. Memory augmented neural network has been proposed to achieve the goal, but the memory module has to be stored in an off-chip memory due to its size. Therefore the practical use has been heavily limited. Previous works on emerging memory-based implementation have difficulties in scaling up because different modules with various structures are difficult to integrate on the same chip and the small sense margin of the content addressable memory for the memory module heavily limited the degree of mismatch calculation. In this work, we implement the entire memory augmented neural network architecture in a fully integrated memristive crossbar platform and achieve an accuracy that closely matches standard software on digital hardware for the Omniglot dataset. The successful demonstration is supported by implementing new functions in crossbars in addition to widely reported matrix multiplications. For example, the locality-sensitive hashing operation is implemented in crossbar arrays by exploiting the intrinsic stochasticity of memristor devices. Besides, the content-addressable memory module is realized in crossbars, which also supports the degree of mismatches. Simulations based on experimentally validated models show such an implementation can be efficiently scaled up for one-shot learning on the Mini-ImageNet dataset. The successful demonstration paves the way for practical on-device lifelong learning and opens possibilities for novel attention-based algorithms not possible in conventional hardware.", "paper_url": "http://arxiv.org/abs/2204.07429v1", "pdf_url": "http://arxiv.org/pdf/2204.07429v1", "repo_url": null}, "2204.07299": {"publish_time": "2022-04-15", "title": "Where to Go for the Holidays: Towards Mixed-Type Dialogs for Clarification of User Goals", "author": "Zeming Liu et.al.", "abstract": "Most dialog systems posit that users have figured out clear and specific goals before starting an interaction. For example, users have determined the departure, the destination, and the travel time for booking a flight. However, in many scenarios, limited by experience and knowledge, users may know what they need, but still struggle to figure out clear and specific goals by determining all the necessary slots.   In this paper, we identify this challenge and make a step forward by collecting a new human-to-human mixed-type dialog corpus. It contains 5k dialog sessions and 168k utterances for 4 dialog types and 5 domains. Within each session, an agent first provides user-goal-related knowledge to help figure out clear and specific goals, and then help achieve them.   Furthermore, we propose a mixed-type dialog model with a novel Prompt-based continual learning mechanism. Specifically, the mechanism enables the model to continually strengthen its ability on any specific type by utilizing existing dialog corpora effectively.", "paper_url": "http://arxiv.org/abs/2204.07299v1", "pdf_url": "http://arxiv.org/pdf/2204.07299v1", "repo_url": null}, "2204.07275": {"publish_time": "2022-04-15", "title": "Incremental Prompting: Episodic Memory Prompt for Lifelong Event Detection", "author": "Minqian Liu et.al.", "abstract": "Lifelong event detection aims to incrementally update a model with new event types and data while retaining the capability on previously learned old types. One critical challenge is that the model would catastrophically forget old types when continually trained on new data. In this paper, we introduce Episodic Memory Prompts (EMP) to explicitly preserve the learned task-specific knowledge. Our method adopts continuous prompt for each task and they are optimized to instruct the model prediction and learn event-specific representation. The EMPs learned in previous tasks are carried along with the model in subsequent tasks, and can serve as a memory module that keeps the old knowledge and transferring to new tasks. Experiment results demonstrate the effectiveness of our method. Furthermore, we also conduct a comprehensive analysis of the new and old event types in lifelong learning.", "paper_url": "http://arxiv.org/abs/2204.07275v1", "pdf_url": "http://arxiv.org/pdf/2204.07275v1", "repo_url": null}, "2204.08043": {"publish_time": "2022-04-17", "title": "Continual Hippocampus Segmentation with Transformers", "author": "Amin Ranem et.al.", "abstract": "In clinical settings, where acquisition conditions and patient populations change over time, continual learning is key for ensuring the safe use of deep neural networks. Yet most existing work focuses on convolutional architectures and image classification. Instead, radiologists prefer to work with segmentation models that outline specific regions-of-interest, for which Transformer-based architectures are gaining traction. The self-attention mechanism of Transformers could potentially mitigate catastrophic forgetting, opening the way for more robust medical image segmentation. In this work, we explore how recently-proposed Transformer mechanisms for semantic segmentation behave in sequential learning scenarios, and analyse how best to adapt continual learning strategies for this setting. Our evaluation on hippocampus segmentation shows that Transformer mechanisms mitigate catastrophic forgetting for medical image segmentation compared to purely convolutional architectures, and demonstrates that regularising ViT modules should be done with caution.", "paper_url": "http://arxiv.org/abs/2204.08043v1", "pdf_url": "http://arxiv.org/pdf/2204.08043v1", "repo_url": "https://github.com/MECLabTUDA/Lifelong-nnUNet"}, "2204.07729": {"publish_time": "2022-04-16", "title": "Efficient Bayesian Policy Reuse with a Scalable Observation Model in Deep Reinforcement Learning", "author": "Jinmei Liu et.al.", "abstract": "Bayesian policy reuse (BPR) is a general policy transfer framework for selecting a source policy from an offline library by inferring the task belief based on some observation signals and a trained observation model. In this paper, we propose an improved BPR method to achieve more efficient policy transfer in deep reinforcement learning (DRL). First, most BPR algorithms use the episodic return as the observation signal that contains limited information and cannot be obtained until the end of an episode. Instead, we employ the state transition sample, which is informative and instantaneous, as the observation signal for faster and more accurate task inference. Second, BPR algorithms usually require numerous samples to estimate the probability distribution of the tabular-based observation model, which may be expensive and even infeasible to learn and maintain, especially when using the state transition sample as the signal. Hence, we propose a scalable observation model based on fitting state transition functions of source tasks from only a small number of samples, which can generalize to any signals observed in the target task. Moreover, we extend the offline-mode BPR to the continual learning setting by expanding the scalable observation model in a plug-and-play fashion, which can avoid negative transfer when faced with new unknown tasks. Experimental results show that our method can consistently facilitate faster and more efficient policy transfer.", "paper_url": "http://arxiv.org/abs/2204.07729v2", "pdf_url": "http://arxiv.org/pdf/2204.07729v2", "repo_url": null}, "2204.08499": {"publish_time": "2022-04-18", "title": "DeepCore: A Comprehensive Library for Coreset Selection in Deep Learning", "author": "Chengcheng Guo et.al.", "abstract": "Coreset selection, which aims to select a subset of the most informative training samples, is a long-standing learning problem that can benefit many downstream tasks such as data-efficient learning, continual learning, neural architecture search, active learning, etc. However, many existing coreset selection methods are not designed for deep learning, which may have high complexity and poor generalization ability to unseen representations. In addition, the recently proposed methods are evaluated on models, datasets, and settings of different complexities. To advance the research of coreset selection in deep learning, we contribute a comprehensive code library, namely DeepCore, and provide an empirical study on popular coreset selection methods on CIFAR10 and ImageNet datasets. Extensive experiment results show that, although some methods perform better in certain experiment settings, random selection is still a strong baseline.", "paper_url": "http://arxiv.org/abs/2204.08499v1", "pdf_url": "http://arxiv.org/pdf/2204.08499v1", "repo_url": "https://github.com/patrickzh/deepcore"}, "2204.09517": {"publish_time": "2022-04-18", "title": "Entropy-based Stability-Plasticity for Lifelong Learning", "author": "Vladimir Araujo et.al.", "abstract": "The ability to continuously learn remains elusive for deep learning models. Unlike humans, models cannot accumulate knowledge in their weights when learning new tasks, mainly due to an excess of plasticity and the low incentive to reuse weights when training a new task. To address the stability-plasticity dilemma in neural networks, we propose a novel method called Entropy-based Stability-Plasticity (ESP). Our approach can decide dynamically how much each model layer should be modified via a plasticity factor. We incorporate branch layers and an entropy-based criterion into the model to find such factor. Our experiments in the domains of natural language and vision show the effectiveness of our approach in leveraging prior knowledge by reducing interference. Also, in some cases, it is possible to freeze layers during training leading to speed up in training.", "paper_url": "http://arxiv.org/abs/2204.09517v1", "pdf_url": "http://arxiv.org/pdf/2204.09517v1", "repo_url": "https://github.com/vgaraujov/esp-cl"}, "2204.09881": {"publish_time": "2022-04-21", "title": "CNLL: A Semi-supervised Approach For Continual Noisy Label Learning", "author": "Nazmul Karim et.al.", "abstract": "The task of continual learning requires careful design of algorithms that can tackle catastrophic forgetting. However, the noisy label, which is inevitable in a real-world scenario, seems to exacerbate the situation. While very few studies have addressed the issue of continual learning under noisy labels, long training time and complicated training schemes limit their applications in most cases. In contrast, we propose a simple purification technique to effectively cleanse the online data stream that is both cost-effective and more accurate. After purification, we perform fine-tuning in a semi-supervised fashion that ensures the participation of all available samples. Training in this fashion helps us learn a better representation that results in state-of-the-art (SOTA) performance. Through extensive experimentation on 3 benchmark datasets, MNIST, CIFAR10 and CIFAR100, we show the effectiveness of our proposed approach. We achieve a 24.8% performance gain for CIFAR10 with 20% noise over previous SOTA methods. Our code is publicly available.", "paper_url": "http://arxiv.org/abs/2204.09881v1", "pdf_url": "http://arxiv.org/pdf/2204.09881v1", "repo_url": null}, "2204.10830": {"publish_time": "2022-04-22", "title": "Memory Bounds for Continual Learning", "author": "Xi Chen et.al.", "abstract": "Continual learning, or lifelong learning, is a formidable current challenge to machine learning. It requires the learner to solve a sequence of $k$ different learning tasks, one after the other, while retaining its aptitude for earlier tasks; the continual learner should scale better than the obvious solution of developing and maintaining a separate learner for each of the $k$ tasks. We embark on a complexity-theoretic study of continual learning in the PAC framework. We make novel uses of communication complexity to establish that any continual learner, even an improper one, needs memory that grows linearly with $k$, strongly suggesting that the problem is intractable. When logarithmically many passes over the learning tasks are allowed, we provide an algorithm based on multiplicative weights update whose memory requirement scales well; we also establish that improper learning is necessary for such performance. We conjecture that these results may lead to new promising approaches to continual learning.", "paper_url": "http://arxiv.org/abs/2204.10830v1", "pdf_url": "http://arxiv.org/pdf/2204.10830v1", "repo_url": null}, "2204.10595": {"publish_time": "2022-04-22", "title": "Spacing Loss for Discovering Novel Categories", "author": "K J Joseph et.al.", "abstract": "Novel Class Discovery (NCD) is a learning paradigm, where a machine learning model is tasked to semantically group instances from unlabeled data, by utilizing labeled instances from a disjoint set of classes. In this work, we first characterize existing NCD approaches into single-stage and two-stage methods based on whether they require access to labeled and unlabeled data together while discovering new classes. Next, we devise a simple yet powerful loss function that enforces separability in the latent space using cues from multi-dimensional scaling, which we refer to as Spacing Loss. Our proposed formulation can either operate as a standalone method or can be plugged into existing methods to enhance them. We validate the efficacy of Spacing Loss with thorough experimental evaluation across multiple settings on CIFAR-10 and CIFAR-100 datasets.", "paper_url": "http://arxiv.org/abs/2204.10595v1", "pdf_url": "http://arxiv.org/pdf/2204.10595v1", "repo_url": "https://github.com/josephkj/awesome-novel-class-discovery"}, "2204.10535": {"publish_time": "2022-04-22", "title": "Alleviating Representational Shift for Continual Fine-tuning", "author": "Shibo Jie et.al.", "abstract": "We study a practical setting of continual learning: fine-tuning on a pre-trained model continually. Previous work has found that, when training on new tasks, the features (penultimate layer representations) of previous data will change, called representational shift. Besides the shift of features, we reveal that the intermediate layers' representational shift (IRS) also matters since it disrupts batch normalization, which is another crucial cause of catastrophic forgetting. Motivated by this, we propose ConFiT, a fine-tuning method incorporating two components, cross-convolution batch normalization (Xconv BN) and hierarchical fine-tuning. Xconv BN maintains pre-convolution running means instead of post-convolution, and recovers post-convolution ones before testing, which corrects the inaccurate estimates of means under IRS. Hierarchical fine-tuning leverages a multi-stage strategy to fine-tune the pre-trained network, preventing massive changes in Conv layers and thus alleviating IRS. Experimental results on four datasets show that our method remarkably outperforms several state-of-the-art methods with lower storage overhead.", "paper_url": "http://arxiv.org/abs/2204.10535v1", "pdf_url": "http://arxiv.org/pdf/2204.10535v1", "repo_url": "https://github.com/jieshibo/confit"}, "2204.11667": {"publish_time": "2022-04-25", "title": "Multi-Head Distillation for Continual Unsupervised Domain Adaptation in Semantic Segmentation", "author": "Antoine Saporta et.al.", "abstract": "Unsupervised Domain Adaptation (UDA) is a transfer learning task which aims at training on an unlabeled target domain by leveraging a labeled source domain. Beyond the traditional scope of UDA with a single source domain and a single target domain, real-world perception systems face a variety of scenarios to handle, from varying lighting conditions to many cities around the world. In this context, UDAs with several domains increase the challenges with the addition of distribution shifts within the different target domains. This work focuses on a novel framework for learning UDA, continuous UDA, in which models operate on multiple target domains discovered sequentially, without access to previous target domains. We propose MuHDi, for Multi-Head Distillation, a method that solves the catastrophic forgetting problem, inherent in continual learning tasks. MuHDi performs distillation at multiple levels from the previous model as well as an auxiliary target-specialist segmentation head. We report both extensive ablation and experiments on challenging multi-target UDA semantic segmentation benchmarks to validate the proposed learning scheme and architecture.", "paper_url": "http://arxiv.org/abs/2204.11667v1", "pdf_url": "http://arxiv.org/pdf/2204.11667v1", "repo_url": "https://github.com/valeoai/MuHDi"}, "2204.11165": {"publish_time": "2022-04-24", "title": "ReLoop: A Self-Correction Continual Learning Loop for Recommender Systems", "author": "Guohao Cai et.al.", "abstract": "Deep learning-based recommendation has become a widely adopted technique in various online applications. Typically, a deployed model undergoes frequent re-training to capture users' dynamic behaviors from newly collected interaction logs. However, the current model training process only acquires users' feedbacks as labels, but fail to take into account the errors made in previous recommendations. Inspired by the intuition that humans usually reflect and learn from mistakes, in this paper, we attempt to build a self-correction learning loop (dubbed ReLoop) for recommender systems. In particular, a new customized loss is employed to encourage every new model version to reduce prediction errors over the previous model version during training. Our ReLoop learning framework enables a continual self-correction process in the long run and thus is expected to obtain better performance over existing training strategies. Both offline experiments and an online A/B test have been conducted to validate the effectiveness of ReLoop.", "paper_url": "http://arxiv.org/abs/2204.11165v1", "pdf_url": "http://arxiv.org/pdf/2204.11165v1", "repo_url": null}, "2204.11010": {"publish_time": "2022-04-23", "title": "GFCL: A GRU-based Federated Continual Learning Framework against Adversarial Attacks in IoV", "author": "Anum Talpur et.al.", "abstract": "The integration of ML in 5G-based Internet of Vehicles (IoV) networks has enabled intelligent transportation and smart traffic management. Nonetheless, the security against adversarial attacks is also increasingly becoming a challenging task. Specifically, Deep Reinforcement Learning (DRL) is one of the widely used ML designs in IoV applications. The standard ML security techniques are not effective in DRL where the algorithm learns to solve sequential decision-making through continuous interaction with the environment, and the environment is time-varying, dynamic, and mobile. In this paper, we propose a Gated Recurrent Unit (GRU)-based federated continual learning (GFCL) anomaly detection framework against adversarial attacks in IoV. The objective is to present a lightweight and scalable framework that learns and detects the illegitimate behavior without having a-priori training dataset consisting of attack samples. We use GRU to predict a future data sequence to analyze and detect illegitimate behavior from vehicles in a federated learning-based distributed manner. We investigate the performance of our framework using real-world vehicle mobility traces. The results demonstrate the effectiveness of our proposed solution for different performance metrics.", "paper_url": "http://arxiv.org/abs/2204.11010v1", "pdf_url": "http://arxiv.org/pdf/2204.11010v1", "repo_url": null}, "2204.12193": {"publish_time": "2022-04-26", "title": "Stochastic Coherence Over Attention Trajectory For Continuous Learning In Video Streams", "author": "Matteo Tiezzi et.al.", "abstract": "Devising intelligent agents able to live in an environment and learn by observing the surroundings is a longstanding goal of Artificial Intelligence. From a bare Machine Learning perspective, challenges arise when the agent is prevented from leveraging large fully-annotated dataset, but rather the interactions with supervisory signals are sparsely distributed over space and time. This paper proposes a novel neural-network-based approach to progressively and autonomously develop pixel-wise representations in a video stream. The proposed method is based on a human-like attention mechanism that allows the agent to learn by observing what is moving in the attended locations. Spatio-temporal stochastic coherence along the attention trajectory, paired with a contrastive term, leads to an unsupervised learning criterion that naturally copes with the considered setting. Differently from most existing works, the learned representations are used in open-set class-incremental classification of each frame pixel, relying on few supervisions. Our experiments leverage 3D virtual environments and they show that the proposed agents can learn to distinguish objects just by observing the video stream. Inheriting features from state-of-the art models is not as powerful as one might expect.", "paper_url": "http://arxiv.org/abs/2204.12193v1", "pdf_url": "http://arxiv.org/pdf/2204.12193v1", "repo_url": "https://github.com/sailab-code/cl_stochastic_coherence"}, "2204.12010": {"publish_time": "2022-04-26", "title": "Theoretical Understanding of the Information Flow on Continual Learning Performance", "author": "Josh Andle et.al.", "abstract": "Continual learning (CL) is a setting in which an agent has to learn from an incoming stream of data sequentially. CL performance evaluates the model's ability to continually learn and solve new problems with incremental available information over time while retaining previous knowledge. Despite the numerous previous solutions to bypass the catastrophic forgetting (CF) of previously seen tasks during the learning process, most of them still suffer significant forgetting, expensive memory cost, or lack of theoretical understanding of neural networks' conduct while learning new tasks. While the issue that CL performance degrades under different training regimes has been extensively studied empirically, insufficient attention has been paid from a theoretical angle. In this paper, we establish a probabilistic framework to analyze information flow through layers in networks for task sequences and its impact on learning performance. Our objective is to optimize the information preservation between layers while learning new tasks to manage task-specific knowledge passing throughout the layers while maintaining model performance on previous tasks. In particular, we study CL performance's relationship with information flow in the network to answer the question \"How can knowledge of information flow between layers be used to alleviate CF?\". Our analysis provides novel insights of information adaptation within the layers during the incremental task learning process. Through our experiments, we provide empirical evidence and practically highlight the performance improvement across multiple tasks.", "paper_url": "http://arxiv.org/abs/2204.12010v1", "pdf_url": "http://arxiv.org/pdf/2204.12010v1", "repo_url": null}, "2204.13074": {"publish_time": "2022-04-27", "title": "Towards Teachable Reasoning Systems", "author": "Bhavana Dalvi et.al.", "abstract": "Our goal is a teachable reasoning system for question-answering (QA), where a user can interact with faithful answer explanations, and correct errors so that the system improves over time. Our approach is three-fold: First, generated chains of reasoning show how answers are implied by the system's own internal beliefs. Second, users can interact with the explanations to identify erroneous model beliefs and provide corrections. Third, we augment the model with a dynamic memory of such corrections. Retrievals from memory are used as additional context for QA, to help avoid previous mistakes in similar new situations - a novel type of memory-based continuous learning. To our knowledge, this is the first system to generate chains that are both faithful (the answer follows from the reasoning) and truthful (the chain reflects the system's own beliefs, as ascertained by self-querying). In evaluation, users judge that a majority (65%+) of generated chains clearly show how an answer follows from a set of facts - substantially better than a high-performance baseline. We also find that using simulated feedback, our system (called EntailmentWriter) continually improves with time, requiring feedback on only 25% of training examples to reach within 1% of the upper-bound (feedback on all examples). We observe a similar trend with real users. This suggests new opportunities for using language models in an interactive setting where users can inspect, debug, correct, and improve a system's performance over time.", "paper_url": "http://arxiv.org/abs/2204.13074v1", "pdf_url": "http://arxiv.org/pdf/2204.13074v1", "repo_url": null}, "2204.12639": {"publish_time": "2022-04-27", "title": "Executive Function: A Contrastive Value Policy for Resampling and Relabeling Perceptions via Hindsight Summarization?", "author": "Chris Lengerich et.al.", "abstract": "We develop the few-shot continual learning task from first principles and hypothesize an evolutionary motivation and mechanism of action for executive function as a contrastive value policy which resamples and relabels perception data via hindsight summarization to minimize attended prediction error, similar to an online prompt engineering problem. This is made feasible by the use of a memory policy and a pretrained network with inductive biases for a grammar of learning and is trained to maximize evolutionary survival. We show how this model of executive function can be used to implement hypothesis testing as a stream of consciousness and may explain observations of human few-shot learning and neuroanatomy.", "paper_url": "http://arxiv.org/abs/2204.12639v1", "pdf_url": "http://arxiv.org/pdf/2204.12639v1", "repo_url": null}, "2204.13349": {"publish_time": "2022-04-28", "title": "Continual Learning with Bayesian Model based on a Fixed Pre-trained Feature Extractor", "author": "Yang Yang et.al.", "abstract": "Deep learning has shown its human-level performance in various applications. However, current deep learning models are characterised by catastrophic forgetting of old knowledge when learning new classes. This poses a challenge particularly in intelligent diagnosis systems where initially only training data of a limited number of diseases are available. In this case, updating the intelligent system with data of new diseases would inevitably downgrade its performance on previously learned diseases. Inspired by the process of learning new knowledge in human brains, we propose a Bayesian generative model for continual learning built on a fixed pre-trained feature extractor. In this model, knowledge of each old class can be compactly represented by a collection of statistical distributions, e.g. with Gaussian mixture models, and naturally kept from forgetting in continual learning over time. Unlike existing class-incremental learning methods, the proposed approach is not sensitive to the continual learning process and can be additionally well applied to the data-incremental learning scenario. Experiments on multiple medical and natural image classification tasks showed that the proposed approach outperforms state-of-the-art approaches which even keep some images of old classes during continual learning of new classes.", "paper_url": "http://arxiv.org/abs/2204.13349v1", "pdf_url": "http://arxiv.org/pdf/2204.13349v1", "repo_url": null}, "2204.13591": {"publish_time": "2022-04-26", "title": "Continual Learning for Peer-to-Peer Federated Learning: A Study on Automated Brain Metastasis Identification", "author": "Yixing Huang et.al.", "abstract": "Due to data privacy constraints, data sharing among multiple centers is restricted. Continual learning, as one approach to peer-to-peer federated learning, can promote multicenter collaboration on deep learning algorithm development by sharing intermediate models instead of training data. This work aims to investigate the feasibility of continual learning for multicenter collaboration on an exemplary application of brain metastasis identification using DeepMedic. 920 T1 MRI contrast enhanced volumes are split to simulate multicenter collaboration scenarios. A continual learning algorithm, synaptic intelligence (SI), is applied to preserve important model weights for training one center after another. In a bilateral collaboration scenario, continual learning with SI achieves a sensitivity of 0.917, and naive continual learning without SI achieves a sensitivity of 0.906, while two models trained on internal data solely without continual learning achieve sensitivity of 0.853 and 0.831 only. In a seven-center multilateral collaboration scenario, the models trained on internal datasets (100 volumes each center) without continual learning obtain a mean sensitivity value of 0.725. With single-visit continual learning (i.e., the shared model visits each center only once during training), the sensitivity is improved to 0.788 and 0.849 without SI and with SI, respectively. With iterative continual learning (i.e., the shared model revisits each center multiple times during training), the sensitivity is further improved to 0.914, which is identical to the sensitivity using mixed data for training. Our experiments demonstrate that continual learning can improve brain metastasis identification performance for centers with limited data. This study demonstrates the feasibility of applying continual learning for peer-to-peer federated learning in multicenter collaboration.", "paper_url": "http://arxiv.org/abs/2204.13591v1", "pdf_url": "http://arxiv.org/pdf/2204.13591v1", "repo_url": null}, "2204.14211": {"publish_time": "2022-04-29", "title": "TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models", "author": "Joel Jang et.al.", "abstract": "Language Models (LMs) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. This is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of LMs to frequently-updated knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a lifelong benchmark for ever-evolving LMs that utilizes the difference between consecutive snapshots of English Wikipedia and English Wikidata for training and evaluation, respectively. The benchmark hence allows researchers to periodically track an LM's ability to retain previous knowledge and acquire updated/new knowledge at each point in time. We also find that training an LM on the diff data through continual learning methods achieves similar or better perplexity than on the entire snapshot in our benchmark with 12 times less computational cost, which verifies that factual knowledge in LMs can be safely updated with minimal training data via continual learning. The dataset and the code are available at https://github.com/joeljang/temporalwiki .", "paper_url": "http://arxiv.org/abs/2204.14211v1", "pdf_url": "http://arxiv.org/pdf/2204.14211v1", "repo_url": "https://github.com/joeljang/temporalwiki"}, "2205.00329": {"publish_time": "2022-04-30", "title": "Foundational Models for Continual Learning: An Empirical Study of Latent Replay", "author": "Oleksiy Ostapenko et.al.", "abstract": "Rapid development of large-scale pre-training has resulted in foundation models that can act as effective feature extractors on a variety of downstream tasks and domains. Motivated by this, we study the efficacy of pre-trained vision models as a foundation for downstream continual learning (CL) scenarios. Our goal is twofold. First, we want to understand the compute-accuracy trade-off between CL in the raw-data space and in the latent space of pre-trained encoders. Second, we investigate how the characteristics of the encoder, the pre-training algorithm and data, as well as of the resulting latent space affect CL performance. For this, we compare the efficacy of various pre-trained models in large-scale benchmarking scenarios with a vanilla replay setting applied in the latent and in the raw-data space. Notably, this study shows how transfer, forgetting, task similarity and learning are dependent on the input data characteristics and not necessarily on the CL algorithms. First, we show that under some circumstances reasonable CL performance can readily be achieved with a non-parametric classifier at negligible compute. We then show how models pre-trained on broader data result in better performance for various replay sizes. We explain this with representational similarity and transfer properties of these representations. Finally, we show the effectiveness of self-supervised pre-training for downstream domains that are out-of-distribution as compared to the pre-training domain. We point out and validate several research directions that can further increase the efficacy of latent CL including representation ensembling. The diverse set of datasets used in this study can serve as a compute-efficient playground for further CL research. The codebase is available under https://github.com/oleksost/latent_CL.", "paper_url": "http://arxiv.org/abs/2205.00329v1", "pdf_url": "http://arxiv.org/pdf/2205.00329v1", "repo_url": "https://github.com/oleksost/latent_cl"}, "2205.01586": {"publish_time": "2022-05-03", "title": "Simpler is Better: off-the-shelf Continual Learning Through Pretrained Backbones", "author": "Francesco Pelosin et.al.", "abstract": "In this short paper, we propose a baseline (off-the-shelf) for Continual Learning of Computer Vision problems, by leveraging the power of pretrained models. By doing so, we devise a simple approach achieving strong performance for most of the common benchmarks. Our approach is fast since requires no parameters updates and has minimal memory requirements (order of KBytes). In particular, the \"training\" phase reorders data and exploit the power of pretrained models to compute a class prototype and fill a memory bank. At inference time we match the closest prototype through a knn-like approach, providing us the prediction. We will see how this naive solution can act as an off-the-shelf continual learning system. In order to better consolidate our results, we compare the devised pipeline with common CNN models and show the superiority of Vision Transformers, suggesting that such architectures have the ability to produce features of higher quality. Moreover, this simple pipeline, raises the same questions raised by previous works \\cite{gdumb} on the effective progresses made by the CL community especially in the dataset considered and the usage of pretrained models. Code is live at https://github.com/francesco-p/off-the-shelf-cl", "paper_url": "http://arxiv.org/abs/2205.01586v1", "pdf_url": "http://arxiv.org/pdf/2205.01586v1", "repo_url": null}, "2205.02014": {"publish_time": "2022-05-04", "title": "On Continual Model Refinement in Out-of-Distribution Data Streams", "author": "Bill Yuchen Lin et.al.", "abstract": "Real-world natural language processing (NLP) models need to be continually updated to fix the prediction errors in out-of-distribution (OOD) data streams while overcoming catastrophic forgetting. However, existing continual learning (CL) problem setups cannot cover such a realistic and complex scenario. In response to this, we propose a new CL problem formulation dubbed continual model refinement (CMR). Compared to prior CL settings, CMR is more practical and introduces unique challenges (boundary-agnostic and non-stationary distribution shift, diverse mixtures of multiple OOD data clusters, error-centric streams, etc.). We extend several existing CL approaches to the CMR setting and evaluate them extensively. For benchmarking and analysis, we propose a general sampling algorithm to obtain dynamic OOD data streams with controllable non-stationarity, as well as a suite of metrics measuring various aspects of online performance. Our experiments and detailed analysis reveal the promise and challenges of the CMR problem, supporting that studying CMR in dynamic OOD streams can benefit the longevity of deployed NLP models in production.", "paper_url": "http://arxiv.org/abs/2205.02014v1", "pdf_url": "http://arxiv.org/pdf/2205.02014v1", "repo_url": null}, "2205.01982": {"publish_time": "2022-05-04", "title": "Lifelong Ensemble Learning based on Multiple Representations for Few-Shot Object Recognition", "author": "Hamidreza Kasaei et.al.", "abstract": "Service robots are integrating more and more into our daily lives to help us with various tasks. In such environments, robots frequently face new objects while working in the environment and need to learn them in an open-ended fashion. Furthermore, such robots must be able to recognize a wide range of object categories. In this paper, we present a lifelong ensemble learning approach based on multiple representations to address the few-shot object recognition problem. In particular, we form ensemble methods based on deep representations and handcrafted 3D shape descriptors. To facilitate lifelong learning, each approach is equipped with a memory unit for storing and retrieving object information instantly. The proposed model is suitable for open-ended learning scenarios where the number of 3D object categories is not fixed and can grow over time. We have performed extensive sets of experiments to assess the performance of the proposed approach in offline, and open-ended scenarios. For the evaluation purpose, in addition to real object datasets, we generate a large synthetic household objects dataset consisting of 27000 views of 90 objects. Experimental results demonstrate the effectiveness of the proposed method on 3D object recognition tasks, as well as its superior performance over the state-of-the-art approaches. Additionally, we demonstrated the effectiveness of our approach in both simulated and real-robot settings, where the robot rapidly learned new categories from limited examples.", "paper_url": "http://arxiv.org/abs/2205.01982v1", "pdf_url": "http://arxiv.org/pdf/2205.01982v1", "repo_url": null}, "2205.03307": {"publish_time": "2022-05-06", "title": "Forget Less, Count Better: A Domain-Incremental Self-Distillation Learning Benchmark for Lifelong Crowd Counting", "author": "Jiaqi Gao et.al.", "abstract": "Crowd Counting has important applications in public safety and pandemic control. A robust and practical crowd counting system has to be capable of continuously learning with the new-coming domain data in real-world scenarios instead of fitting one domain only. Off-the-shelf methods have some drawbacks to handle multiple domains. 1) The models will achieve limited performance (even drop dramatically) among old domains after training images from new domains due to the discrepancies of intrinsic data distributions from various domains, which is called catastrophic forgetting. 2) The well-trained model in a specific domain achieves imperfect performance among other unseen domains because of the domain shift. 3) It leads to linearly-increased storage overhead either mixing all the data for training or simply training dozens of separate models for different domains when new ones are available. To overcome these issues, we investigate a new task of crowd counting under the incremental domains training setting, namely, Lifelong Crowd Counting. It aims at alleviating the catastrophic forgetting and improving the generalization ability using a single model updated by the incremental domains. To be more specific, we propose a self-distillation learning framework as a benchmark~(Forget Less, Count Better, FLCB) for lifelong crowd counting, which helps the model sustainably leverage previous meaningful knowledge for better crowd counting to mitigate the forgetting when the new data arrive. Meanwhile, a new quantitative metric, normalized backward transfer~(nBwT), is developed to evaluate the forgetting degree of the model in the lifelong learning process. Extensive experimental results demonstrate the superiority of our proposed benchmark in achieving a low catastrophic forgetting degree and strong generalization ability.", "paper_url": "http://arxiv.org/abs/2205.03307v1", "pdf_url": "http://arxiv.org/pdf/2205.03307v1", "repo_url": null}, "2205.03055": {"publish_time": "2022-05-06", "title": "Continual Object Detection via Prototypical Task Correlation Guided Gating Mechanism", "author": "Binbin Yang et.al.", "abstract": "Continual learning is a challenging real-world problem for constructing a mature AI system when data are provided in a streaming fashion. Despite recent progress in continual classification, the researches of continual object detection are impeded by the diverse sizes and numbers of objects in each image. Different from previous works that tune the whole network for all tasks, in this work, we present a simple and flexible framework for continual object detection via pRotOtypical taSk corrElaTion guided gaTing mechAnism (ROSETTA). Concretely, a unified framework is shared by all tasks while task-aware gates are introduced to automatically select sub-models for specific tasks. In this way, various knowledge can be successively memorized by storing their corresponding sub-model weights in this system. To make ROSETTA automatically determine which experience is available and useful, a prototypical task correlation guided Gating Diversity Controller(GDC) is introduced to adaptively adjust the diversity of gates for the new task based on class-specific prototypes. GDC module computes class-to-class correlation matrix to depict the cross-task correlation, and hereby activates more exclusive gates for the new task if a significant domain gap is observed. Comprehensive experiments on COCO-VOC, KITTI-Kitchen, class-incremental detection on VOC and sequential learning of four tasks show that ROSETTA yields state-of-the-art performance on both task-based and class-based continual object detection.", "paper_url": "http://arxiv.org/abs/2205.03055v1", "pdf_url": "http://arxiv.org/pdf/2205.03055v1", "repo_url": "https://github.com/dkxocl/rosseta"}, "2205.04424": {"publish_time": "2022-05-09", "title": "Accelerated Reinforcement Learning for Temporal Logic Control Objectives", "author": "Yiannis Kantaros et.al.", "abstract": "This paper addresses the problem of learning control policies for mobile robots modeled as unknown Markov Decision Processes (MDPs) that are tasked with temporal logic missions, such as sequencing, coverage, or surveillance. The MDP captures uncertainty in the workspace structure and the outcomes of control decisions. The control objective is to synthesize a control policy that maximizes the probability of accomplishing a high-level task, specified as a Linear Temporal Logic (LTL) formula. To address this problem, we propose a novel accelerated model-based reinforcement learning (RL) algorithm for LTL control objectives that is capable of learning control policies significantly faster than related approaches. Its sample-efficiency relies on biasing exploration towards directions that may contribute to task satisfaction. This is accomplished by leveraging an automaton representation of the LTL task as well as a continuously learned MDP model. Finally, we provide extensive comparative experiments that demonstrate the sample efficiency of the proposed method against recent temporal logic RL methods.", "paper_url": "http://arxiv.org/abs/2205.04424v2", "pdf_url": "http://arxiv.org/pdf/2205.04424v2", "repo_url": null}, "2205.04383": {"publish_time": "2022-05-09", "title": "Online Unsupervised Domain Adaptation for Person Re-identification", "author": "Hamza Rami et.al.", "abstract": "Unsupervised domain adaptation for person re-identification (Person Re-ID) is the task of transferring the learned knowledge on the labeled source domain to the unlabeled target domain. Most of the recent papers that address this problem adopt an offline training setting. More precisely, the training of the Re-ID model is done assuming that we have access to the complete training target domain data set. In this paper, we argue that the target domain generally consists of a stream of data in a practical real-world application, where data is continuously increasing from the different network's cameras. The Re-ID solutions are also constrained by confidentiality regulations stating that the collected data can be stored for only a limited period, hence the model can no longer get access to previously seen target images. Therefore, we present a new yet practical online setting for Unsupervised Domain Adaptation for person Re-ID with two main constraints: Online Adaptation and Privacy Protection. We then adapt and evaluate the state-of-the-art UDA algorithms on this new online setting using the well-known Market-1501, Duke, and MSMT17 benchmarks.", "paper_url": "http://arxiv.org/abs/2205.04383v1", "pdf_url": "http://arxiv.org/pdf/2205.04383v1", "repo_url": null}, "2205.04352": {"publish_time": "2022-05-09", "title": "Learning Self-adaptations for IoT Networks: A Genetic Programming Approach", "author": "Jia Li et.al.", "abstract": "Internet of Things (IoT) is a pivotal technology in application domains that require connectivity and interoperability between large numbers of devices. IoT systems predominantly use a software-defined network (SDN) architecture as their core communication backbone. This architecture offers several advantages, including the flexibility to make IoT networks self-adaptive through software programmability. In general, self-adaptation solutions need to periodically monitor, reason about, and adapt a running system. The adaptation step involves generating an adaptation strategy and applying it to the running system whenever an anomaly arises. In this paper, we argue that, rather than generating individual adaptation strategies, the goal should be to adapt the logic / code of the running system in such a way that the system itself would learn how to steer clear of future anomalies, without triggering self-adaptation too frequently. We instantiate and empirically assess this idea in the context of IoT networks. Specifically, using genetic programming (GP), we propose a self-adaptation solution that continuously learns and updates the control constructs in the data-forwarding logic of SDN-based IoT networks. Our evaluation, performed using open-source synthetic and industrial data, indicates that, compared to a baseline adaptation technique that attempts to generate individual adaptations, our GP-based approach is more effective in resolving network congestion, and further, reduces the frequency of adaptation interventions over time. In addition, we compare our approach against a standard data-forwarding algorithm from the network literature, demonstrating that our approach significantly reduces packet loss.", "paper_url": "http://arxiv.org/abs/2205.04352v1", "pdf_url": "http://arxiv.org/pdf/2205.04352v1", "repo_url": null}, "2205.04040": {"publish_time": "2022-05-09", "title": "ProQA: Structural Prompt-based Pre-training for Unified Question Answering", "author": "Wanjun Zhong et.al.", "abstract": "Question Answering (QA) is a longstanding challenge in natural language processing. Existing QA works mostly focus on specific question types, knowledge domains, or reasoning skills. The specialty in QA research hinders systems from modeling commonalities between tasks and generalization for wider applications. To address this issue, we present ProQA, a unified QA paradigm that solves various tasks through a single model. ProQA takes a unified structural prompt as the bridge and improves the QA-centric ability by structural prompt-based pre-training. Through a structurally designed prompt-based input schema, ProQA concurrently models the knowledge generalization for all QA tasks while keeping the knowledge customization for every specific QA task. Furthermore, ProQA is pre-trained with structural prompt-formatted large-scale synthesized corpus, which empowers the model with the commonly-required QA ability. Experimental results on 11 QA benchmarks demonstrate that ProQA consistently boosts performance on both full data fine-tuning, few-shot learning, and zero-shot testing scenarios. Furthermore, ProQA exhibits strong ability in both continual learning and transfer learning by taking the advantages of the structural prompt.", "paper_url": "http://arxiv.org/abs/2205.04040v1", "pdf_url": "http://arxiv.org/pdf/2205.04040v1", "repo_url": null}, "2205.04590": {"publish_time": "2022-05-09", "title": "A Verification Framework for Certifying Learning-Based Safety-Critical Aviation Systems", "author": "Ali Baheri et.al.", "abstract": "We present a safety verification framework for design-time and run-time assurance of learning-based components in aviation systems. Our proposed framework integrates two novel methodologies. From the design-time assurance perspective, we propose offline mixed-fidelity verification tools that incorporate knowledge from different levels of granularity in simulated environments. From the run-time assurance perspective, we propose reachability- and statistics-based online monitoring and safety guards for a learning-based decision-making model to complement the offline verification methods. This framework is designed to be loosely coupled among modules, allowing the individual modules to be developed using independent methodologies and techniques, under varying circumstances and with different tool access. The proposed framework offers feasible solutions for meeting system safety requirements at different stages throughout the system development and deployment cycle, enabling the continuous learning and assessment of the system product.", "paper_url": "http://arxiv.org/abs/2205.04590v2", "pdf_url": "http://arxiv.org/pdf/2205.04590v2", "repo_url": null}, "2205.05467": {"publish_time": "2022-05-11", "title": "A Continual Deepfake Detection Benchmark: Dataset, Methods, and Essentials", "author": "Chuqiao Li et.al.", "abstract": "There have been emerging a number of benchmarks and techniques for the detection of deepfakes. However, very few works study the detection of incrementally appearing deepfakes in the real-world scenarios. To simulate the wild scenes, this paper suggests a continual deepfake detection benchmark (CDDB) over a new collection of deepfakes from both known and unknown generative models. The suggested CDDB designs multiple evaluations on the detection over easy, hard, and long sequence of deepfake tasks, with a set of appropriate measures. In addition, we exploit multiple approaches to adapt multiclass incremental learning methods, commonly used in the continual visual recognition, to the continual deepfake detection problem. We evaluate several methods, including the adapted ones, on the proposed CDDB. Within the proposed benchmark, we explore some commonly known essentials of standard continual learning. Our study provides new insights on these essentials in the context of continual deepfake detection. The suggested CDDB is clearly more challenging than the existing benchmarks, which thus offers a suitable evaluation avenue to the future research. Our benchmark dataset and the source code will be made publicly available.", "paper_url": "http://arxiv.org/abs/2205.05467v2", "pdf_url": "http://arxiv.org/pdf/2205.05467v2", "repo_url": null}, "2205.06376": {"publish_time": "2022-05-12", "title": "KASAM: Spline Additive Models for Function Approximation", "author": "Heinrich van Deventer et.al.", "abstract": "Neural networks have been criticised for their inability to perform continual learning due to catastrophic forgetting and rapid unlearning of a past concept when a new concept is introduced. Catastrophic forgetting can be alleviated by specifically designed models and training techniques. This paper outlines a novel Spline Additive Model (SAM). SAM exhibits intrinsic memory retention with sufficient expressive power for many practical tasks, but is not a universal function approximator. SAM is extended with the Kolmogorov-Arnold representation theorem to a novel universal function approximator, called the Kolmogorov-Arnold Spline Additive Model - KASAM. The memory retention, expressive power and limitations of SAM and KASAM are illustrated analytically and empirically. SAM exhibited robust but imperfect memory retention, with small regions of overlapping interference in sequential learning tasks. KASAM exhibited greater susceptibility to catastrophic forgetting. KASAM in combination with pseudo-rehearsal training techniques exhibited superior performance in regression tasks and memory retention.", "paper_url": "http://arxiv.org/abs/2205.06376v1", "pdf_url": "http://arxiv.org/pdf/2205.06376v1", "repo_url": "https://github.com/hpdeventer/kasam"}, "2205.07390": {"publish_time": "2022-05-15", "title": "Learning Representations for New Sound Classes With Continual Self-Supervised Learning", "author": "Zhepei Wang et.al.", "abstract": "In this paper, we present a self-supervised learning framework for continually learning representations for new sound classes. The proposed system relies on a continually trained neural encoder that is trained with similarity-based learning objectives without using labels. We show that representations learned with the proposed method generalize better and are less susceptible to catastrophic forgetting than fully-supervised approaches. Remarkably, our technique does not store past data or models and is more computationally efficient than distillation-based methods. To accurately assess the system performance, in addition to using existing protocols, we propose two realistic evaluation protocols that use only a small amount of labeled data to simulate practical use cases.", "paper_url": "http://arxiv.org/abs/2205.07390v1", "pdf_url": "http://arxiv.org/pdf/2205.07390v1", "repo_url": null}, "2205.08013": {"publish_time": "2022-05-16", "title": "Continual learning on 3D point clouds with random compressed rehearsal", "author": "Maciej Zamorski et.al.", "abstract": "Contemporary deep neural networks offer state-of-the-art results when applied to visual reasoning, e.g., in the context of 3D point cloud data. Point clouds are important datatype for precise modeling of three-dimensional environments, but effective processing of this type of data proves to be challenging. In the world of large, heavily-parameterized network architectures and continuously-streamed data, there is an increasing need for machine learning models that can be trained on additional data. Unfortunately, currently available models cannot fully leverage training on additional data without losing their past knowledge. Combating this phenomenon, called catastrophic forgetting, is one of the main objectives of continual learning. Continual learning for deep neural networks has been an active field of research, primarily in 2D computer vision, natural language processing, reinforcement learning, and robotics. However, in 3D computer vision, there are hardly any continual learning solutions specifically designed to take advantage of point cloud structure. This work proposes a novel neural network architecture capable of continual learning on 3D point cloud data. We utilize point cloud structure properties for preserving a heavily compressed set of past data. By using rehearsal and reconstruction as regularization methods of the learning process, our approach achieves a significant decrease of catastrophic forgetting compared to the existing solutions on several most popular point cloud datasets considering two continual learning settings: when a task is known beforehand, and in the challenging scenario of when task information is unknown to the model.", "paper_url": "http://arxiv.org/abs/2205.08013v1", "pdf_url": "http://arxiv.org/pdf/2205.08013v1", "repo_url": null}, "2205.09029": {"publish_time": "2022-05-18", "title": "Maslow's Hammer for Catastrophic Forgetting: Node Re-Use vs Node Activation", "author": "Sebastian Lee et.al.", "abstract": "Continual learning - learning new tasks in sequence while maintaining performance on old tasks - remains particularly challenging for artificial neural networks. Surprisingly, the amount of forgetting does not increase with the dissimilarity between the learned tasks, but appears to be worst in an intermediate similarity regime.   In this paper we theoretically analyse both a synthetic teacher-student framework and a real data setup to provide an explanation of this phenomenon that we name Maslow's hammer hypothesis. Our analysis reveals the presence of a trade-off between node activation and node re-use that results in worst forgetting in the intermediate regime. Using this understanding we reinterpret popular algorithmic interventions for catastrophic interference in terms of this trade-off, and identify the regimes in which they are most effective.", "paper_url": "http://arxiv.org/abs/2205.09029v1", "pdf_url": "http://arxiv.org/pdf/2205.09029v1", "repo_url": "https://github.com/seblee97/student_teacher_catastrophic"}, "2205.08975": {"publish_time": "2022-05-18", "title": "Personalized Behaviour Models: A Survey Focusing on Autism Therapy Applications", "author": "Micha\u0142 Stolarz et.al.", "abstract": "Children with Autism Spectrum Disorder find robots easier to communicate with than humans. Thus, robots have been introduced in autism therapies. However, due to the environmental complexity, the used robots often have to be controlled manually. This is a significant drawback of such systems and it is required to make them more autonomous. In particular, the robot should interpret the child's state and continuously adapt its actions according to the behaviour of the child under therapy. This survey elaborates on different forms of personalized robot behaviour models. Various approaches from the field of Human-Robot Interaction, as well as Child-Robot Interaction, are discussed. The aim is to compare them in terms of their deficits, feasibility in real scenarios, and potential usability for autism-specific Robot-Assisted Therapy. The general challenge for algorithms based on which the robot learns proper interaction strategies during therapeutic games is to increase the robot's autonomy, thereby providing a basis for a robot's decision-making.", "paper_url": "http://arxiv.org/abs/2205.08975v1", "pdf_url": "http://arxiv.org/pdf/2205.08975v1", "repo_url": null}, "2205.09588": {"publish_time": "2022-05-19", "title": "How catastrophic can catastrophic forgetting be in linear regression?", "author": "Itay Evron et.al.", "abstract": "To better understand catastrophic forgetting, we study fitting an overparameterized linear model to a sequence of tasks with different input distributions. We analyze how much the model forgets the true labels of earlier tasks after training on subsequent tasks, obtaining exact expressions and bounds. We establish connections between continual learning in the linear setting and two other research areas: alternating projections and the Kaczmarz method. In specific settings, we highlight differences between forgetting and convergence to the offline solution as studied in those areas. In particular, when T tasks in d dimensions are presented cyclically for k iterations, we prove an upper bound of T^2 * min{1/sqrt(k), d/k} on the forgetting. This stands in contrast to the convergence to the offline solution, which can be arbitrarily slow according to existing alternating projection results. We further show that the T^2 factor can be lifted when tasks are presented in a random ordering.", "paper_url": "http://arxiv.org/abs/2205.09588v1", "pdf_url": "http://arxiv.org/pdf/2205.09588v1", "repo_url": null}, "2205.09357": {"publish_time": "2022-05-19", "title": "Continual Pre-Training Mitigates Forgetting in Language and Vision", "author": "Andrea Cossu et.al.", "abstract": "Pre-trained models are nowadays a fundamental component of machine learning research. In continual learning, they are commonly used to initialize the model before training on the stream of non-stationary data. However, pre-training is rarely applied during continual learning. We formalize and investigate the characteristics of the continual pre-training scenario in both language and vision environments, where a model is continually pre-trained on a stream of incoming data and only later fine-tuned to different downstream tasks. We show that continually pre-trained models are robust against catastrophic forgetting and we provide strong empirical evidence supporting the fact that self-supervised pre-training is more effective in retaining previous knowledge than supervised protocols. Code is provided at https://github.com/AndreaCossu/continual-pretraining-nlp-vision .", "paper_url": "http://arxiv.org/abs/2205.09357v1", "pdf_url": "http://arxiv.org/pdf/2205.09357v1", "repo_url": "https://github.com/andreacossu/continual-pretraining-nlp-vision"}, "2205.09347": {"publish_time": "2022-05-19", "title": "Bypassing Logits Bias in Online Class-Incremental Learning with a Generative Framework", "author": "Gehui Shen et.al.", "abstract": "Continual learning requires the model to maintain the learned knowledge while learning from a non-i.i.d data stream continually. Due to the single-pass training setting, online continual learning is very challenging, but it is closer to the real-world scenarios where quick adaptation to new data is appealing. In this paper, we focus on online class-incremental learning setting in which new classes emerge over time. Almost all existing methods are replay-based with a softmax classifier. However, the inherent logits bias problem in the softmax classifier is a main cause of catastrophic forgetting while existing solutions are not applicable for online settings. To bypass this problem, we abandon the softmax classifier and propose a novel generative framework based on the feature space. In our framework, a generative classifier which utilizes replay memory is used for inference, and the training objective is a pair-based metric learning loss which is proven theoretically to optimize the feature space in a generative way. In order to improve the ability to learn new data, we further propose a hybrid of generative and discriminative loss to train the model. Extensive experiments on several benchmarks, including newly introduced task-free datasets, show that our method beats a series of state-of-the-art replay-based methods with discriminative classifiers, and reduces catastrophic forgetting consistently with a remarkable margin.", "paper_url": "http://arxiv.org/abs/2205.09347v1", "pdf_url": "http://arxiv.org/pdf/2205.09347v1", "repo_url": null}, "2205.09891": {"publish_time": "2022-05-19", "title": "Interpolating Compressed Parameter Subspaces", "author": "Siddhartha Datta et.al.", "abstract": "Inspired by recent work on neural subspaces and mode connectivity, we revisit parameter subspace sampling for shifted and/or interpolatable input distributions (instead of a single, unshifted distribution). We enforce a compressed geometric structure upon a set of trained parameters mapped to a set of train-time distributions, denoting the resulting subspaces as Compressed Parameter Subspaces (CPS). We show the success and failure modes of the types of shifted distributions whose optimal parameters reside in the CPS. We find that ensembling point-estimates within a CPS can yield a high average accuracy across a range of test-time distributions, including backdoor, adversarial, permutation, stylization and rotation perturbations. We also find that the CPS can contain low-loss point-estimates for various task shifts (albeit interpolated, perturbed, unseen or non-identical coarse labels). We further demonstrate this property in a continual learning setting with CIFAR100.", "paper_url": "http://arxiv.org/abs/2205.09891v1", "pdf_url": "http://arxiv.org/pdf/2205.09891v1", "repo_url": null}, "2205.11319": {"publish_time": "2022-05-23", "title": "Continual Barlow Twins: continual self-supervised learning for remote sensing semantic segmentation", "author": "Valerio Marsocci et.al.", "abstract": "In the field of Earth Observation (EO), Continual Learning (CL) algorithms have been proposed to deal with large datasets by decomposing them into several subsets and processing them incrementally. The majority of these algorithms assume that data is (a) coming from a single source, and (b) fully labeled. Real-world EO datasets are instead characterized by a large heterogeneity (e.g., coming from aerial, satellite, or drone scenarios), and for the most part they are unlabeled, meaning they can be fully exploited only through the emerging Self-Supervised Learning (SSL) paradigm. For these reasons, in this paper we propose a new algorithm for merging SSL and CL for remote sensing applications, that we call Continual Barlow Twins (CBT). It combines the advantages of one of the simplest self-supervision techniques, i.e., Barlow Twins, with the Elastic Weight Consolidation method to avoid catastrophic forgetting. In addition, for the first time we evaluate SSL methods on a highly heterogeneous EO dataset, showing the effectiveness of these strategies on a novel combination of three almost non-overlapping domains datasets (airborne Potsdam dataset, satellite US3D dataset, and drone UAVid dataset), on a crucial downstream task in EO, i.e., semantic segmentation. Encouraging results show the superiority of SSL in this setting, and the effectiveness of creating an incremental effective pretrained feature extractor, based on ResNet50, without the need of relying on the complete availability of all the data, with a valuable saving of time and resources.", "paper_url": "http://arxiv.org/abs/2205.11319v1", "pdf_url": "http://arxiv.org/pdf/2205.11319v1", "repo_url": null}, "2205.11152": {"publish_time": "2022-05-23", "title": "Cross-lingual Lifelong Learning", "author": "Meryem M'hamdi et.al.", "abstract": "The longstanding goal of multi-lingual learning has been to develop a universal cross-lingual model that can withstand the changes in multi-lingual data distributions. However, most existing models assume full access to the target languages in advance, whereas in realistic scenarios this is not often the case, as new languages can be incorporated later on. In this paper, we present the Cross-lingual Lifelong Learning (CLL) challenge, where a model is continually fine-tuned to adapt to emerging data from different languages. We provide insights into what makes multilingual sequential learning particularly challenging. To surmount such challenges, we benchmark a representative set of cross-lingual continual learning algorithms and analyze their knowledge preservation, accumulation, and generalization capabilities compared to baselines on carefully curated datastreams. The implications of this analysis include a recipe for how to measure and balance between different cross-lingual continual learning desiderata, which goes beyond conventional transfer learning.", "paper_url": "http://arxiv.org/abs/2205.11152v1", "pdf_url": "http://arxiv.org/pdf/2205.11152v1", "repo_url": null}, "2205.11126": {"publish_time": "2022-05-23", "title": "KRNet: Towards Efficient Knowledge Replay", "author": "Yingying Zhang et.al.", "abstract": "The knowledge replay technique has been widely used in many tasks such as continual learning and continuous domain adaptation. The key lies in how to effectively encode the knowledge extracted from previous data and replay them during current training procedure. A simple yet effective model to achieve knowledge replay is autoencoder. However, the number of stored latent codes in autoencoder increases linearly with the scale of data and the trained encoder is redundant for the replaying stage. In this paper, we propose a novel and efficient knowledge recording network (KRNet) which directly maps an arbitrary sample identity number to the corresponding datum. Compared with autoencoder, our KRNet requires significantly ($400\\times$) less storage cost for the latent codes and can be trained without the encoder sub-network. Extensive experiments validate the efficiency of KRNet, and as a showcase, it is successfully applied in the task of continual learning.", "paper_url": "http://arxiv.org/abs/2205.11126v1", "pdf_url": "http://arxiv.org/pdf/2205.11126v1", "repo_url": null}, "2205.11071": {"publish_time": "2022-05-23", "title": "Self-distilled Knowledge Delegator for Exemplar-free Class Incremental Learning", "author": "Fanfan Ye et.al.", "abstract": "Exemplar-free incremental learning is extremely challenging due to inaccessibility of data from old tasks. In this paper, we attempt to exploit the knowledge encoded in a previously trained classification model to handle the catastrophic forgetting problem in continual learning. Specifically, we introduce a so-called knowledge delegator, which is capable of transferring knowledge from the trained model to a randomly re-initialized new model by generating informative samples. Given the previous model only, the delegator is effectively learned using a self-distillation mechanism in a data-free manner. The knowledge extracted by the delegator is then utilized to maintain the performance of the model on old tasks in incremental learning. This simple incremental learning framework surpasses existing exemplar-free methods by a large margin on four widely used class incremental benchmarks, namely CIFAR-100, ImageNet-Subset, Caltech-101 and Flowers-102. Notably, we achieve comparable performance to some exemplar-based methods without accessing any exemplars.", "paper_url": "http://arxiv.org/abs/2205.11071v1", "pdf_url": "http://arxiv.org/pdf/2205.11071v1", "repo_url": null}, "2205.10956": {"publish_time": "2022-05-22", "title": "CIRCLE: Continual Repair across Programming Languages", "author": "Wei Yuan et.al.", "abstract": "Automatic Program Repair (APR) aims at fixing buggy source code with less manual debugging efforts, which plays a vital role in improving software reliability and development productivity. Recent APR works have achieved remarkable progress via applying deep learning (DL), particularly neural machine translation (NMT) techniques. However, we observe that existing DL-based APR models suffer from at least two severe drawbacks: (1) Most of them can only generate patches for a single programming language, as a result, to repair multiple languages, we have to build and train many repairing models. (2) Most of them are developed in an offline manner. Therefore, they won't function when there are new-coming requirements. To address the above problems, a T5-based APR framework equipped with continual learning ability across multiple programming languages is proposed, namely \\emph{C}ont\\emph{I}nual \\emph{R}epair a\\emph{C}ross Programming \\emph{L}anguag\\emph{E}s (\\emph{CIRCLE}). Specifically, (1) CIRCLE utilizes a prompting function to narrow the gap between natural language processing (NLP) pre-trained tasks and APR. (2) CIRCLE adopts a difficulty-based rehearsal strategy to achieve lifelong learning for APR without access to the full historical data. (3) An elastic regularization method is employed to strengthen CIRCLE's continual learning ability further, preventing it from catastrophic forgetting. (4) CIRCLE applies a simple but effective re-repairing method to revise generated errors caused by crossing multiple programming languages. We train CIRCLE for four languages (i.e., C, JAVA, JavaScript, and Python) and evaluate it on five commonly used benchmarks. The experimental results demonstrate that CIRCLE not only effectively and efficiently repairs multiple programming languages in continual learning settings, but also achieves state-of-the-art performance with a single repair model.", "paper_url": "http://arxiv.org/abs/2205.10956v1", "pdf_url": "http://arxiv.org/pdf/2205.10956v1", "repo_url": null}, "2205.11736": {"publish_time": "2022-05-24", "title": "Towards a Defense against Backdoor Attacks in Continual Federated Learning", "author": "Shuaiqi Wang et.al.", "abstract": "Backdoor attacks are a major concern in federated learning (FL) pipelines where training data is sourced from untrusted clients over long periods of time (i.e., continual learning). Preventing such attacks is difficult because defenders in FL do not have access to raw training data. Moreover, in a phenomenon we call backdoor leakage, models trained continuously eventually suffer from backdoors due to cumulative errors in backdoor defense mechanisms. We propose a novel framework for defending against backdoor attacks in the federated continual learning setting. Our framework trains two models in parallel: a backbone model and a shadow model. The backbone is trained without any defense mechanism to obtain good performance on the main task. The shadow model combines recent ideas from robust covariance estimation-based filters with early-stopping to control the attack success rate even as the data distribution changes. We provide theoretical motivation for this design and show experimentally that our framework significantly improves upon existing defenses against backdoor attacks.", "paper_url": "http://arxiv.org/abs/2205.11736v1", "pdf_url": "http://arxiv.org/pdf/2205.11736v1", "repo_url": "https://github.com/wsqwsq/Towards-a-Defense-against-Backdoor-Attacks-in-Continual-Federated-Learning"}, "2205.11713": {"publish_time": "2022-05-24", "title": "Thalamus: a brain-inspired algorithm for biologically-plausible continual learning and disentangled representations", "author": "Ali Hummos et.al.", "abstract": "Animals thrive in a constantly changing environment and leverage the temporal structure to learn well-factorized causal representations. In contrast, traditional neural networks suffer from forgetting in changing environments and many methods have been proposed to limit forgetting with different trade-offs. Inspired by the brain thalamocortical circuit, we introduce a simple algorithm that uses optimization at inference time to generate internal representations of temporal context and to infer current context dynamically, allowing the agent to parse the stream of temporal experience into discrete events and organize learning about them. We show that a network trained on a series of tasks using traditional weight updates can infer tasks dynamically using gradient descent steps in the latent task embedding space (latent updates). We then alternate between the weight updates and the latent updates to arrive at Thalamus, a task-agnostic algorithm capable of discovering disentangled representations in a stream of unlabeled tasks using simple gradient descent. On a continual learning benchmark, it achieves competitive end average accuracy and demonstrates knowledge transfer. After learning a subset of tasks it can generalize to unseen tasks as they become reachable within the well-factorized latent space, through one-shot latent updates. The algorithm meets many of the desiderata of an ideal continually learning agent in open-ended environments, and its simplicity suggests fundamental computations in circuits with abundant feedback control loops such as the thalamocortical circuits in the brain.", "paper_url": "http://arxiv.org/abs/2205.11713v1", "pdf_url": "http://arxiv.org/pdf/2205.11713v1", "repo_url": null}, "2205.12755": {"publish_time": "2022-05-25", "title": "An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems", "author": "Andrea Gesmundo et.al.", "abstract": "Multitask learning assumes that models capable of learning from multiple tasks can achieve better quality and efficiency via knowledge transfer, a key feature of human learning. Though, state of the art ML models rely on high customization for each task and leverage size and data scale rather than scaling the number of tasks. Also, continual learning, that adds the temporal aspect to multitask, is often focused to the study of common pitfalls such as catastrophic forgetting instead of being studied at a large scale as a critical component to build the next generation artificial intelligence. We propose an evolutionary method that can generate a large scale multitask model, and can support the dynamic and continuous addition of new tasks. The generated multitask model is sparsely activated and integrates a task-based routing that guarantees bounded compute cost and fewer added parameters per task as the model expands. The proposed method relies on a knowledge compartmentalization technique to achieve immunity against catastrophic forgetting and other common pitfalls such as gradient interference and negative transfer. We empirically show that the proposed method can jointly solve and achieve competitive results on 69image classification tasks, for example achieving the best test accuracy reported fora model trained only on public data for competitive tasks such as cifar10: 99.43%.", "paper_url": "http://arxiv.org/abs/2205.12755v1", "pdf_url": "http://arxiv.org/pdf/2205.12755v1", "repo_url": null}, "2205.12393": {"publish_time": "2022-05-24", "title": "Continual-T0: Progressively Instructing 50+ Tasks to Language Models Without Forgetting", "author": "Thomas Scialom et.al.", "abstract": "Recent work on large language models relies on the intuition that most natural language processing tasks can be described via natural language instructions. Language models trained on these instructions show strong zero-shot performance on several standard datasets. However, these models even though impressive still perform poorly on a wide range of tasks outside of their respective training and evaluation sets. To address this limitation, we argue that a model should be able to keep extending its knowledge and abilities, without forgetting previous skills. In spite of the limited success of Continual Learning we show that Language Models can be continual learners. We empirically investigate the reason for this success and conclude that Continual Learning emerges from self-supervision pre-training. Our resulting model Continual-T0 (CT0) is able to learn diverse new tasks, while still maintaining good performance on previous tasks, spanning remarkably through 70 datasets in total. Finally, we show that CT0 is able to combine instructions in ways it was never trained for, demonstrating some compositionality.", "paper_url": "http://arxiv.org/abs/2205.12393v1", "pdf_url": "http://arxiv.org/pdf/2205.12393v1", "repo_url": null}, "2205.12295": {"publish_time": "2022-05-24", "title": "lpSpikeCon: Enabling Low-Precision Spiking Neural Network Processing for Efficient Unsupervised Continual Learning on Autonomous Agents", "author": "Rachmad Vidya Wicaksana Putra et.al.", "abstract": "Recent advances have shown that SNN-based systems can efficiently perform unsupervised continual learning due to their bio-plausible learning rule, e.g., Spike-Timing-Dependent Plasticity (STDP). Such learning capabilities are especially beneficial for use cases like autonomous agents (e.g., robots and UAVs) that need to continuously adapt to dynamically changing scenarios/environments, where new data gathered directly from the environment may have novel features that should be learned online. Current state-of-the-art works employ high-precision weights (i.e., 32 bit) for both training and inference phases, which pose high memory and energy costs thereby hindering efficient embedded implementations of such systems for battery-driven mobile autonomous systems. On the other hand, precision reduction may jeopardize the quality of unsupervised continual learning due to information loss. Towards this, we propose lpSpikeCon, a novel methodology to enable low-precision SNN processing for efficient unsupervised continual learning on resource-constrained autonomous agents/systems. Our lpSpikeCon methodology employs the following key steps: (1) analyzing the impacts of training the SNN model under unsupervised continual learning settings with reduced weight precision on the inference accuracy; (2) leveraging this study to identify SNN parameters that have a significant impact on the inference accuracy; and (3) developing an algorithm for searching the respective SNN parameter values that improve the quality of unsupervised continual learning. The experimental results show that our lpSpikeCon can reduce weight memory of the SNN model by 8x (i.e., by judiciously employing 4-bit weights) for performing online training with unsupervised continual learning and achieve no accuracy loss in the inference phase, as compared to the baseline model with 32-bit weights across different network sizes.", "paper_url": "http://arxiv.org/abs/2205.12295v1", "pdf_url": "http://arxiv.org/pdf/2205.12295v1", "repo_url": null}, "2205.13452": {"publish_time": "2022-05-26", "title": "Continual evaluation for lifelong learning: Identifying the stability gap", "author": "Matthias De Lange et.al.", "abstract": "Introducing a time dependency on the data generating distribution has proven to be difficult for gradient-based training of neural networks, as the greedy updates result in catastrophic forgetting of previous timesteps. Continual learning aims to overcome the greedy optimization to enable continuous accumulation of knowledge over time. The data stream is typically divided into locally stationary distributions, called tasks, allowing task-based evaluation on held-out data from the training tasks. Contemporary evaluation protocols and metrics in continual learning are task-based and quantify the trade-off between stability and plasticity only at task transitions. However, our empirical evidence suggests that between task transitions significant, temporary forgetting can occur, remaining unidentified in task-based evaluation. Therefore, we propose a framework for continual evaluation that establishes per-iteration evaluation and define a new set of metrics that enables identifying the worst-case performance of the learner over its lifetime. Performing continual evaluation, we empirically identify that replay suffers from a stability gap: upon learning a new task, there is a substantial but transient decrease in performance on past tasks. Further conceptual and empirical analysis suggests not only replay-based, but also regularization-based continual learning methods are prone to the stability gap.", "paper_url": "http://arxiv.org/abs/2205.13452v1", "pdf_url": "http://arxiv.org/pdf/2205.13452v1", "repo_url": "https://github.com/mattdl/continualevaluation"}, "2205.13384": {"publish_time": "2022-05-26", "title": "Continual Learning for Visual Search with Backward Consistent Feature Embedding", "author": "Timmy S. T. Wan et.al.", "abstract": "In visual search, the gallery set could be incrementally growing and added to the database in practice. However, existing methods rely on the model trained on the entire dataset, ignoring the continual updating of the model. Besides, as the model updates, the new model must re-extract features for the entire gallery set to maintain compatible feature space, imposing a high computational cost for a large gallery set. To address the issues of long-term visual search, we introduce a continual learning (CL) approach that can handle the incrementally growing gallery set with backward embedding consistency. We enforce the losses of inter-session data coherence, neighbor-session model coherence, and intra-session discrimination to conduct a continual learner. In addition to the disjoint setup, our CL solution also tackles the situation of increasingly adding new classes for the blurry boundary without assuming all categories known in the beginning and during model update. To our knowledge, this is the first CL method both tackling the issue of backward-consistent feature embedding and allowing novel classes to occur in the new sessions. Extensive experiments on various benchmarks show the efficacy of our approach under a wide range of setups.", "paper_url": "http://arxiv.org/abs/2205.13384v1", "pdf_url": "http://arxiv.org/pdf/2205.13384v1", "repo_url": "https://github.com/ivclab/cvs"}, "2205.13359": {"publish_time": "2022-05-26", "title": "Feature Forgetting in Continual Representation Learning", "author": "Xiao Zhang et.al.", "abstract": "In continual and lifelong learning, good representation learning can help increase performance and reduce sample complexity when learning new tasks. There is evidence that representations do not suffer from \"catastrophic forgetting\" even in plain continual learning, but little further fact is known about its characteristics. In this paper, we aim to gain more understanding about representation learning in continual learning, especially on the feature forgetting problem. We devise a protocol for evaluating representation in continual learning, and then use it to present an overview of the basic trends of continual representation learning, showing its consistent deficiency and potential issues. To study the feature forgetting problem, we create a synthetic dataset to identify and visualize the prevalence of feature forgetting in neural networks. Finally, we propose a simple technique using gating adapters to mitigate feature forgetting. We conclude by discussing that improving representation learning benefits both old and new tasks in continual learning.", "paper_url": "http://arxiv.org/abs/2205.13359v1", "pdf_url": "http://arxiv.org/pdf/2205.13359v1", "repo_url": null}, "2205.13323": {"publish_time": "2022-05-26", "title": "The Effect of Task Ordering in Continual Learning", "author": "Samuel J. Bell et.al.", "abstract": "We investigate the effect of task ordering on continual learning performance. We conduct an extensive series of empirical experiments on synthetic and naturalistic datasets and show that reordering tasks significantly affects the amount of catastrophic forgetting. Connecting to the field of curriculum learning, we show that the effect of task ordering can be exploited to modify continual learning performance, and present a simple approach for doing so. Our method computes the distance between all pairs of tasks, where distance is defined as the source task curvature of a gradient step toward the target task. Using statistically rigorous methods and sound experimental design, we show that task ordering is an important aspect of continual learning that can be modified for improved performance.", "paper_url": "http://arxiv.org/abs/2205.13323v1", "pdf_url": "http://arxiv.org/pdf/2205.13323v1", "repo_url": null}, "2205.13066": {"publish_time": "2022-05-25", "title": "Semi-supervised Drifted Stream Learning with Short Lookback", "author": "Weijieying Ren et.al.", "abstract": "In many scenarios, 1) data streams are generated in real time; 2) labeled data are expensive and only limited labels are available in the beginning; 3) real-world data is not always i.i.d. and data drift over time gradually; 4) the storage of historical streams is limited and model updating can only be achieved based on a very short lookback window. This learning setting limits the applicability and availability of many Machine Learning (ML) algorithms. We generalize the learning task under such setting as a semi-supervised drifted stream learning with short lookback problem (SDSL). SDSL imposes two under-addressed challenges on existing methods in semi-supervised learning, continuous learning, and domain adaptation: 1) robust pseudo-labeling under gradual shifts and 2) anti-forgetting adaptation with short lookback. To tackle these challenges, we propose a principled and generic generation-replay framework to solve SDSL. The framework is able to accomplish: 1) robust pseudo-labeling in the generation step; 2) anti-forgetting adaption in the replay step. To achieve robust pseudo-labeling, we develop a novel pseudo-label classification model to leverage supervised knowledge of previously labeled data, unsupervised knowledge of new data, and, structure knowledge of invariant label semantics. To achieve adaptive anti-forgetting model replay, we propose to view the anti-forgetting adaptation task as a flat region search problem. We propose a novel minimax game-based replay objective function to solve the flat region search problem and develop an effective optimization solver. Finally, we present extensive experiments to demonstrate our framework can effectively address the task of anti-forgetting learning in drifted streams with short lookback.", "paper_url": "http://arxiv.org/abs/2205.13066v1", "pdf_url": "http://arxiv.org/pdf/2205.13066v1", "repo_url": null}, "2205.14495": {"publish_time": "2022-05-28", "title": "Task-Agnostic Continual Reinforcement Learning: In Praise of a Simple Baseline", "author": "Massimo Caccia et.al.", "abstract": "We study task-agnostic continual reinforcement learning (TACRL) in which standard RL challenges are compounded with partial observability stemming from task agnosticism, as well as additional difficulties of continual learning (CL), i.e., learning on a non-stationary sequence of tasks. Here we compare TACRL methods with their soft upper bounds prescribed by previous literature: multi-task learning (MTL) methods which do not have to deal with non-stationary data distributions, as well as task-aware methods, which are allowed to operate under full observability. We consider a previously unexplored and straightforward baseline for TACRL, replay-based recurrent RL (3RL), in which we augment an RL algorithm with recurrent mechanisms to address partial observability and experience replay mechanisms to address catastrophic forgetting in CL.   Studying empirical performance in a sequence of RL tasks, we find surprising occurrences of 3RL matching and overcoming the MTL and task-aware soft upper bounds. We lay out hypotheses that could explain this inflection point of continual and task-agnostic learning research. Our hypotheses are empirically tested in continuous control tasks via a large-scale study of the popular multi-task and continual learning benchmark Meta-World. By analyzing different training statistics including gradient conflict, we find evidence that 3RL's outperformance stems from its ability to quickly infer how new tasks relate with the previous ones, enabling forward transfer.", "paper_url": "http://arxiv.org/abs/2205.14495v1", "pdf_url": "http://arxiv.org/pdf/2205.14495v1", "repo_url": null}, "2205.15827": {"publish_time": "2022-05-31", "title": "Robust Anytime Learning of Markov Decision Processes", "author": "Marnix Suilen et.al.", "abstract": "Markov decision processes (MDPs) are formal models commonly used in sequential decision-making. MDPs capture the stochasticity that may arise, for instance, from imprecise actuators via probabilities in the transition function. However, in data-driven applications, deriving precise probabilities from (limited) data introduces statistical errors that may lead to unexpected or undesirable outcomes. Uncertain MDPs (uMDPs) do not require precise probabilities but instead use so-called uncertainty sets in the transitions, accounting for such limited data. Tools from the formal verification community efficiently compute robust policies that provably adhere to formal specifications, like safety constraints, under the worst-case instance in the uncertainty set. We continuously learn the transition probabilities of an MDP in a robust anytime-learning approach that combines a dedicated Bayesian inference scheme with the computation of robust policies. In particular, our method (1) approximates probabilities as intervals, (2) adapts to new data that may be inconsistent with an intermediate model, and (3) may be stopped at any time to compute a robust policy on the uMDP that faithfully captures the data so far. We show the effectiveness of our approach and compare it to robust policies computed on uMDPs learned by the UCRL2 reinforcement learning algorithm in an experimental evaluation on several benchmarks.", "paper_url": "http://arxiv.org/abs/2205.15827v1", "pdf_url": "http://arxiv.org/pdf/2205.15827v1", "repo_url": null}, "2205.15496": {"publish_time": "2022-05-31", "title": "Towards Lifelong Federated Learning in Autonomous Mobile Robots with Continuous Sim-to-Real Transfer", "author": "Xianjia Yu et.al.", "abstract": "The role of deep learning (DL) in robotics has significantly deepened over the last decade. Intelligent robotic systems today are highly connected systems that rely on DL for a variety of perception, control, and other tasks. At the same time, autonomous robots are being increasingly deployed as part of fleets, with collaboration among robots becoming a more relevant factor. From the perspective of collaborative learning, federated learning (FL) enables continuous training of models in a distributed, privacy-preserving way. This paper focuses on vision-based obstacle avoidance for mobile robot navigation. On this basis, we explore the potential of FL for distributed systems of mobile robots enabling continuous learning via the engagement of robots in both simulated and real-world scenarios. We extend previous works by studying the performance of different image classifiers for FL, compared to centralized, cloud-based learning with a priori aggregated data. We also introduce an approach to continuous learning from mobile robots with extended sensor suites able to provide automatically labeled data while they are completing other tasks. We show that higher accuracies can be achieved by training the models in both simulation and reality, enabling continuous updates to deployed models.", "paper_url": "http://arxiv.org/abs/2205.15496v1", "pdf_url": "http://arxiv.org/pdf/2205.15496v1", "repo_url": null}, "2205.15445": {"publish_time": "2022-05-30", "title": "Continual Object Detection: A review of definitions, strategies, and challenges", "author": "Angelo G. Menezes et.al.", "abstract": "The field of Continual Learning investigates the ability to learn consecutive tasks without losing performance on those previously learned. Its focus has been mainly on incremental classification tasks. We believe that research in continual object detection deserves even more attention due to its vast range of applications in robotics and autonomous vehicles. This scenario is more complex than conventional classification given the occurrence of instances of classes that are unknown at the time, but can appear in subsequent tasks as a new class to be learned, resulting in missing annotations and conflicts with the background label. In this review, we analyze the current strategies proposed to tackle the problem of class-incremental object detection. Our main contributions are: (1) a short and systematic review of the methods that propose solutions to traditional incremental object detection scenarios; (2) A comprehensive evaluation of the existing approaches using a new metric to quantify the stability and plasticity of each technique in a standard way; (3) an overview of the current trends within continual object detection and a discussion of possible future research directions.", "paper_url": "http://arxiv.org/abs/2205.15445v1", "pdf_url": "http://arxiv.org/pdf/2205.15445v1", "repo_url": null}, "2206.00388": {"publish_time": "2022-06-01", "title": "Transfer without Forgetting", "author": "Matteo Boschini et.al.", "abstract": "This work investigates the entanglement between Continual Learning (CL) and Transfer Learning (TL). In particular, we shed light on the widespread application of network pretraining, highlighting that it is itself subject to catastrophic forgetting. Unfortunately, this issue leads to the under-exploitation of knowledge transfer during later tasks. On this ground, we propose Transfer without Forgetting (TwF), a hybrid Continual Transfer Learning approach building upon a fixed pretrained sibling network, which continuously propagates the knowledge inherent in the source domain through a layer-wise loss term. Our experiments indicate that TwF steadily outperforms other CL methods across a variety of settings, averaging a 4.81% gain in Class-Incremental accuracy over a variety of datasets and different buffer sizes.", "paper_url": "http://arxiv.org/abs/2206.00388v1", "pdf_url": "http://arxiv.org/pdf/2206.00388v1", "repo_url": "https://github.com/mbosc/twf"}, "2206.00309": {"publish_time": "2022-06-01", "title": "Label-Efficient Online Continual Object Detection in Streaming Video", "author": "Jay Zhangjie Wu et.al.", "abstract": "To thrive in evolving environments, humans are capable of continual acquisition and transfer of new knowledge, from a continuous video stream, with minimal supervisions, while retaining previously learnt experiences. In contrast to human learning, most standard continual learning benchmarks focus on learning from static iid images in fully supervised settings. Here, we examine a more realistic and challenging problem$\\unicode{x2014}$Label-Efficient Online Continual Object Detection (LEOCOD) in video streams. By addressing this problem, it would greatly benefit many real-world applications with reduced annotation costs and retraining time. To tackle this problem, we seek inspirations from complementary learning systems (CLS) in human brains and propose a computational model, dubbed as Efficient-CLS. Functionally correlated with the hippocampus and the neocortex in CLS, Efficient-CLS posits a memory encoding mechanism involving bidirectional interaction between fast and slow learners via synaptic weight transfers and pattern replays. We test Efficient-CLS and competitive baselines in two challenging real-world video stream datasets. Like humans, Efficient-CLS learns to detect new object classes incrementally from a continuous temporal stream of non-repeating video with minimal forgetting. Remarkably, with only 25% annotated video frames, our Efficient-CLS still leads among all comparative models, which are trained with 100% annotations on all video frames. The data and source code will be publicly available at https://github.com/showlab/Efficient-CLS.", "paper_url": "http://arxiv.org/abs/2206.00309v1", "pdf_url": "http://arxiv.org/pdf/2206.00309v1", "repo_url": "https://github.com/showlab/efficient-cls"}, "2206.00270": {"publish_time": "2022-06-01", "title": "Provably Efficient Lifelong Reinforcement Learning with Linear Function Approximation", "author": "Sanae Amani et.al.", "abstract": "We study lifelong reinforcement learning (RL) in a regret minimization setting of linear contextual Markov decision process (MDP), where the agent needs to learn a multi-task policy while solving a streaming sequence of tasks. We propose an algorithm, called UCB Lifelong Value Distillation (UCBlvd), that provably achieves sublinear regret for any sequence of tasks, which may be adaptively chosen based on the agent's past behaviors. Remarkably, our algorithm uses only sublinear number of planning calls, which means that the agent eventually learns a policy that is near optimal for multiple tasks (seen or unseen) without the need of deliberate planning. A key to this property is a new structural assumption that enables computation sharing across tasks during exploration. Specifically, for $K$ task episodes of horizon $H$, our algorithm has a regret bound $\\tilde{\\mathcal{O}}(\\sqrt{(d^3+d^\\prime d)H^4K})$ based on $\\mathcal{O}(dH\\log(K))$ number of planning calls, where $d$ and $d^\\prime$ are the feature dimensions of the dynamics and rewards, respectively. This theoretical guarantee implies that our algorithm can enable a lifelong learning agent to accumulate experiences and learn to rapidly solve new tasks.", "paper_url": "http://arxiv.org/abs/2206.00270v1", "pdf_url": "http://arxiv.org/pdf/2206.00270v1", "repo_url": null}, "2206.00719": {"publish_time": "2022-06-01", "title": "Dataset Distillation using Neural Feature Regression", "author": "Yongchao Zhou et.al.", "abstract": "Dataset distillation aims to learn a small synthetic dataset that preserves most of the information from the original dataset. Dataset distillation can be formulated as a bi-level meta-learning problem where the outer loop optimizes the meta-dataset and the inner loop trains a model on the distilled data. Meta-gradient computation is one of the key challenges in this formulation, as differentiating through the inner loop learning procedure introduces significant computation and memory costs. In this paper, we address these challenges using neural Feature Regression with Pooling (FRePo), achieving the state-of-the-art performance with an order of magnitude less memory requirement and two orders of magnitude faster training than previous methods. The proposed algorithm is analogous to truncated backpropagation through time with a pool of models to alleviate various types of overfitting in dataset distillation. FRePo significantly outperforms the previous methods on CIFAR100, Tiny ImageNet, and ImageNet-1K. Furthermore, we show that high-quality distilled data can greatly improve various downstream applications, such as continual learning and membership inference defense.", "paper_url": "http://arxiv.org/abs/2206.00719v1", "pdf_url": "http://arxiv.org/pdf/2206.00719v1", "repo_url": null}, "2206.01649": {"publish_time": "2022-06-03", "title": "Neural Differential Equations for Learning to Program Neural Nets Through Continuous Learning Rules", "author": "Kazuki Irie et.al.", "abstract": "Neural ordinary differential equations (ODEs) have attracted much attention as continuous-time counterparts of deep residual neural networks (NNs), and numerous extensions for recurrent NNs have been proposed. Since the 1980s, ODEs have also been used to derive theoretical results for NN learning rules, e.g., the famous connection between Oja's rule and principal component analysis. Such rules are typically expressed as additive iterative update processes which have straightforward ODE counterparts. Here we introduce a novel combination of learning rules and Neural ODEs to build continuous-time sequence processing nets that learn to manipulate short-term memory in rapidly changing synaptic connections of other nets. This yields continuous-time counterparts of Fast Weight Programmers and linear Transformers. Our novel models outperform the best existing Neural Controlled Differential Equation based models on various time series classification tasks, while also addressing their scalability limitations. Our code is public.", "paper_url": "http://arxiv.org/abs/2206.01649v1", "pdf_url": "http://arxiv.org/pdf/2206.01649v1", "repo_url": "https://github.com/idsia/neuraldiffeq-fwp"}, "2206.02577": {"publish_time": "2022-06-03", "title": "Effects of Auxiliary Knowledge on Continual Learning", "author": "Giovanni Bellitto et.al.", "abstract": "In Continual Learning (CL), a neural network is trained on a stream of data whose distribution changes over time. In this context, the main problem is how to learn new information without forgetting old knowledge (i.e., Catastrophic Forgetting). Most existing CL approaches focus on finding solutions to preserve acquired knowledge, so working on the past of the model. However, we argue that as the model has to continually learn new tasks, it is also important to put focus on the present knowledge that could improve following tasks learning. In this paper we propose a new, simple, CL algorithm that focuses on solving the current task in a way that might facilitate the learning of the next ones. More specifically, our approach combines the main data stream with a secondary, diverse and uncorrelated stream, from which the network can draw auxiliary knowledge. This helps the model from different perspectives, since auxiliary data may contain useful features for the current and the next tasks and incoming task classes can be mapped onto auxiliary classes. Furthermore, the addition of data to the current task is implicitly making the classifier more robust as we are forcing the extraction of more discriminative features. Our method can outperform existing state-of-the-art models on the most common CL Image Classification benchmarks.", "paper_url": "http://arxiv.org/abs/2206.02577v1", "pdf_url": "http://arxiv.org/pdf/2206.02577v1", "repo_url": null}, "2206.03483": {"publish_time": "2022-06-07", "title": "Few-Shot Learning by Dimensionality Reduction in Gradient Space", "author": "Martin Gauch et.al.", "abstract": "We introduce SubGD, a novel few-shot learning method which is based on the recent finding that stochastic gradient descent updates tend to live in a low-dimensional parameter subspace. In experimental and theoretical analyses, we show that models confined to a suitable predefined subspace generalize well for few-shot learning. A suitable subspace fulfills three criteria across the given tasks: it (a) allows to reduce the training error by gradient flow, (b) leads to models that generalize well, and (c) can be identified by stochastic gradient descent. SubGD identifies these subspaces from an eigendecomposition of the auto-correlation matrix of update directions across different tasks. Demonstrably, we can identify low-dimensional suitable subspaces for few-shot learning of dynamical systems, which have varying properties described by one or few parameters of the analytical system description. Such systems are ubiquitous among real-world applications in science and engineering. We experimentally corroborate the advantages of SubGD on three distinct dynamical systems problem settings, significantly outperforming popular few-shot learning methods both in terms of sample efficiency and performance.", "paper_url": "http://arxiv.org/abs/2206.03483v1", "pdf_url": "http://arxiv.org/pdf/2206.03483v1", "repo_url": "https://github.com/ml-jku/subgd"}, "2206.02916": {"publish_time": "2022-06-06", "title": "Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks", "author": "Zhiwei Deng et.al.", "abstract": "We propose an algorithm that compresses the critical information of a large dataset into compact addressable memories. These memories can then be recalled to quickly re-train a neural network and recover the performance (instead of storing and re-training on the full original dataset).   Building upon the dataset distillation framework, we make a key observation that a shared common representation allows for more efficient and effective distillation. Concretely, we learn a set of bases (aka \"memories\") which are shared between classes and combined through learned flexible addressing functions to generate a diverse set of training examples. This leads to several benefits: 1) the size of compressed data does not necessarily grow linearly with the number of classes; 2) an overall higher compression rate with more effective distillation is achieved; and 3) more generalized queries are allowed beyond recalling the original classes.   We demonstrate state-of-the-art results on the dataset distillation task across five benchmarks, including up to 16.5% and 9.7% in retained accuracy improvement when distilling CIFAR10 and CIFAR100 respectively. We then leverage our framework to perform continual learning, achieving state-of-the-art results on four benchmarks, with 23.2% accuracy improvement on MANY.", "paper_url": "http://arxiv.org/abs/2206.02916v1", "pdf_url": "http://arxiv.org/pdf/2206.02916v1", "repo_url": null}, "2206.04016": {"publish_time": "2022-06-08", "title": "SYNERgy between SYNaptic consolidation and Experience Replay for general continual learning", "author": "Fahad Sarfraz et.al.", "abstract": "Continual learning (CL) in the brain is facilitated by a complex set of mechanisms. This includes the interplay of multiple memory systems for consolidating information as posited by the complementary learning systems (CLS) theory and synaptic consolidation for protecting the acquired knowledge from erasure. Thus, we propose a general CL method that creates a synergy between SYNaptic consolidation and dual memory Experience Replay (SYNERgy). Our method maintains a semantic memory that accumulates and consolidates information across the tasks and interacts with the episodic memory for effective replay. It further employs synaptic consolidation by tracking the importance of parameters during the training trajectory and anchoring them to the consolidated parameters in the semantic memory. To the best of our knowledge, our study is the first to employ dual memory experience replay in conjunction with synaptic consolidation that is suitable for general CL whereby the network does not utilize task boundaries or task labels during training or inference. Our evaluation on various challenging CL scenarios and characteristics analyses demonstrate the efficacy of incorporating both synaptic consolidation and CLS theory in enabling effective CL in DNNs.", "paper_url": "http://arxiv.org/abs/2206.04016v1", "pdf_url": "http://arxiv.org/pdf/2206.04016v1", "repo_url": "https://github.com/neurai-lab/synergy"}, "2206.03954": {"publish_time": "2022-06-08", "title": "Mathematical model bridges disparate timescales of lifelong learning", "author": "Mingzhen Lu et.al.", "abstract": "Lifelong learning occurs on timescales ranging from minutes to decades. People can lose themselves in a new skill, practicing for hours until exhausted. And they can pursue mastery over days or decades, perhaps abandoning old skills entirely to seek out new challenges. A full understanding of learning requires an account that integrates these timescales. Here, we present a minimal quantitative model that unifies the nested timescales of learning. Our dynamical model recovers classic accounts of skill acquisition, and describes how learning emerges from moment-to-moment dynamics of motivation, fatigue, and work, while also situated within longer-term dynamics of skill selection, mastery, and abandonment. We apply this model to explore the benefits and pitfalls of a variety of training regimes and to characterize individual differences in motivation and skill development. Our model connects previously disparate timescales -- and the subdisciplines that typically study each timescale in isolation -- to offer a unified account of the timecourse of skill acquisition.", "paper_url": "http://arxiv.org/abs/2206.03954v1", "pdf_url": "http://arxiv.org/pdf/2206.03954v1", "repo_url": "https://github.com/vc-yang/multiscale_learning_model"}, "2206.03934": {"publish_time": "2022-06-08", "title": "A Study of Continual Learning Methods for Q-Learning", "author": "Benedikt Bagus et.al.", "abstract": "We present an empirical study on the use of continual learning (CL) methods in a reinforcement learning (RL) scenario, which, to the best of our knowledge, has not been described before. CL is a very active recent research topic concerned with machine learning under non-stationary data distributions. Although this naturally applies to RL, the use of dedicated CL methods is still uncommon. This may be due to the fact that CL methods often assume a decomposition of CL problems into disjoint sub-tasks of stationary distribution, that the onset of these sub-tasks is known, and that sub-tasks are non-contradictory. In this study, we perform an empirical comparison of selected CL methods in a RL problem where a physically simulated robot must follow a racetrack by vision. In order to make CL methods applicable, we restrict the RL setting and introduce non-conflicting subtasks of known onset, which are however not disjoint and whose distribution, from the learner's point of view, is still non-stationary. Our results show that dedicated CL methods can significantly improve learning when compared to the baseline technique of \"experience replay\".", "paper_url": "http://arxiv.org/abs/2206.03934v1", "pdf_url": "http://arxiv.org/pdf/2206.03934v1", "repo_url": null}, "2206.05846": {"publish_time": "2022-06-12", "title": "InBiaseD: Inductive Bias Distillation to Improve Generalization and Robustness through Shape-awareness", "author": "Shruthi Gowda et.al.", "abstract": "Humans rely less on spurious correlations and trivial cues, such as texture, compared to deep neural networks which lead to better generalization and robustness. It can be attributed to the prior knowledge or the high-level cognitive inductive bias present in the brain. Therefore, introducing meaningful inductive bias to neural networks can help learn more generic and high-level representations and alleviate some of the shortcomings. We propose InBiaseD to distill inductive bias and bring shape-awareness to the neural networks. Our method includes a bias alignment objective that enforces the networks to learn more generic representations that are less vulnerable to unintended cues in the data which results in improved generalization performance. InBiaseD is less susceptible to shortcut learning and also exhibits lower texture bias. The better representations also aid in improving robustness to adversarial attacks and we hence plugin InBiaseD seamlessly into the existing adversarial training schemes to show a better trade-off between generalization and robustness.", "paper_url": "http://arxiv.org/abs/2206.05846v1", "pdf_url": "http://arxiv.org/pdf/2206.05846v1", "repo_url": null}, "2206.05750": {"publish_time": "2022-06-12", "title": "Matching options to tasks using Option-Indexed Hierarchical Reinforcement Learning", "author": "Kushal Chauhan et.al.", "abstract": "The options framework in Hierarchical Reinforcement Learning breaks down overall goals into a combination of options or simpler tasks and associated policies, allowing for abstraction in the action space. Ideally, these options can be reused across different higher-level goals; indeed, such reuse is necessary to realize the vision of a continual learning agent that can effectively leverage its prior experience. Previous approaches have only proposed limited forms of transfer of prelearned options to new task settings. We propose a novel option indexing approach to hierarchical learning (OI-HRL), where we learn an affinity function between options and the items present in the environment. This allows us to effectively reuse a large library of pretrained options, in zero-shot generalization at test time, by restricting goal-directed learning to only those options relevant to the task at hand. We develop a meta-training loop that learns the representations of options and environments over a series of HRL problems, by incorporating feedback about the relevance of retrieved options to the higher-level goal. We evaluate OI-HRL in two simulated settings - the CraftWorld and AI2THOR environments - and show that we achieve performance competitive with oracular baselines, and substantial gains over a baseline that has the entire option pool available for learning the hierarchical policy.", "paper_url": "http://arxiv.org/abs/2206.05750v1", "pdf_url": "http://arxiv.org/pdf/2206.05750v1", "repo_url": null}, "2206.05625": {"publish_time": "2022-06-11", "title": "A Review on Plastic Artificial Neural Networks: Exploring the Intersection between Neural Architecture Search and Continual Learning", "author": "Mohamed Shahawy et.al.", "abstract": "Despite the significant advances achieved in Artificial Neural Networks (ANNs), their design process remains notoriously tedious, depending primarily on intuition, experience and trial-and-error. This human-dependent process is often time-consuming and prone to errors. Furthermore, the models are generally bound to their training contexts, with no considerations of changes to their surrounding environments. Continual adaptability and automation of neural networks is of paramount importance to several domains where model accessibility is limited after deployment (e.g IoT devices, self-driving vehicles, etc). Additionally, even accessible models require frequent maintenance post-deployment to overcome issues such as Concept/Data Drift, which can be cumbersome and restrictive. The current state of the art on adaptive ANNs is still a premature area of research; nevertheless, Neural Architecture Search (NAS), a form of AutoML, and Continual Learning (CL) have recently gained an increasing momentum in the Deep Learning research field, aiming to provide more robust and adaptive ANN development frameworks. This study is the first extensive review on the intersection between AutoML and CL, outlining research directions for the different methods that can facilitate full automation and lifelong plasticity in ANNs.", "paper_url": "http://arxiv.org/abs/2206.05625v1", "pdf_url": "http://arxiv.org/pdf/2206.05625v1", "repo_url": null}, "2206.05555": {"publish_time": "2022-06-11", "title": "A Unified Continuous Learning Framework for Multi-modal Knowledge Discovery and Pre-training", "author": "Zhihao Fan et.al.", "abstract": "Multi-modal pre-training and knowledge discovery are two important research topics in multi-modal machine learning. Nevertheless, none of existing works make attempts to link knowledge discovery with knowledge guided multi-modal pre-training. In this paper, we propose to unify them into a continuous learning framework for mutual improvement. Taking the open-domain uni-modal datasets of images and texts as input, we maintain a knowledge graph as the foundation to support these two tasks. For knowledge discovery, a pre-trained model is used to identify cross-modal links on the graph. For model pre-training, the knowledge graph is used as the external knowledge to guide the model updating. These two steps are iteratively performed in our framework for continuous learning. The experimental results on MS-COCO and Flickr30K with respect to both knowledge discovery and the pre-trained model validate the effectiveness of our framework.", "paper_url": "http://arxiv.org/abs/2206.05555v1", "pdf_url": "http://arxiv.org/pdf/2206.05555v1", "repo_url": null}, "2206.06957": {"publish_time": "2022-06-14", "title": "Continual-Learning-as-a-Service (CLaaS): On-Demand Efficient Adaptation of Predictive Models", "author": "Rudy Semola et.al.", "abstract": "Predictive machine learning models nowadays are often updated in a stateless and expensive way. The two main future trends for companies that want to build machine learning-based applications and systems are real-time inference and continual updating. Unfortunately, both trends require a mature infrastructure that is hard and costly to realize on-premise. This paper defines a novel software service and model delivery infrastructure termed Continual Learning-as-a-Service (CLaaS) to address these issues. Specifically, it embraces continual machine learning and continuous integration techniques. It provides support for model updating and validation tools for data scientists without an on-premise solution and in an efficient, stateful and easy-to-use manner. Finally, this CL model service is easy to encapsulate in any machine learning infrastructure or cloud system. This paper presents the design and implementation of a CLaaS instantiation, called LiquidBrain, evaluated in two real-world scenarios. The former is a robotic object recognition setting using the CORe50 dataset while the latter is a named category and attribute prediction using the DeepFashion-C dataset in the fashion domain. Our preliminary results suggest the usability and efficiency of the Continual Learning model services and the effectiveness of the solution in addressing real-world use-cases regardless of where the computation happens in the continuum Edge-Cloud.", "paper_url": "http://arxiv.org/abs/2206.06957v1", "pdf_url": "http://arxiv.org/pdf/2206.06957v1", "repo_url": null}, "2206.06813": {"publish_time": "2022-06-14", "title": "Learning towards Synchronous Network Memorizability and Generalizability for Continual Segmentation across Multiple Sites", "author": "Jingyang Zhang et.al.", "abstract": "In clinical practice, a segmentation network is often required to continually learn on a sequential data stream from multiple sites rather than a consolidated set, due to the storage cost and privacy restriction. However, during the continual learning process, existing methods are usually restricted in either network memorizability on previous sites or generalizability on unseen sites. This paper aims to tackle the challenging problem of Synchronous Memorizability and Generalizability (SMG) and to simultaneously improve performance on both previous and unseen sites, with a novel proposed SMG-learning framework. First, we propose a Synchronous Gradient Alignment (SGA) objective, which \\emph{not only} promotes the network memorizability by enforcing coordinated optimization for a small exemplar set from previous sites (called replay buffer), \\emph{but also} enhances the generalizability by facilitating site-invariance under simulated domain shift. Second, to simplify the optimization of SGA objective, we design a Dual-Meta algorithm that approximates the SGA objective as dual meta-objectives for optimization without expensive computation overhead. Third, for efficient rehearsal, we configure the replay buffer comprehensively considering additional inter-site diversity to reduce redundancy. Experiments on prostate MRI data sequentially acquired from six institutes demonstrate that our method can simultaneously achieve higher memorizability and generalizability over state-of-the-art methods. Code is available at https://github.com/jingyzhang/SMG-Learning.", "paper_url": "http://arxiv.org/abs/2206.06813v1", "pdf_url": "http://arxiv.org/pdf/2206.06813v1", "repo_url": null}, "2206.06485": {"publish_time": "2022-06-13", "title": "What Should I Know? Using Meta-gradient Descent for Predictive Feature Discovery in a Single Stream of Experience", "author": "Alexandra Kearney et.al.", "abstract": "In computational reinforcement learning, a growing body of work seeks to construct an agent's perception of the world through predictions of future sensations; predictions about environment observations are used as additional input features to enable better goal-directed decision-making. An open challenge in this line of work is determining from the infinitely many predictions that the agent could possibly make which predictions might best support decision-making. This challenge is especially apparent in continual learning problems where a single stream of experience is available to a singular agent. As a primary contribution, we introduce a meta-gradient descent process by which an agent learns 1) what predictions to make, 2) the estimates for its chosen predictions, and 3) how to use those estimates to generate policies that maximize future reward -- all during a single ongoing process of continual learning. In this manuscript we consider predictions expressed as General Value Functions: temporally extended estimates of the accumulation of a future signal. We demonstrate that through interaction with the environment an agent can independently select predictions that resolve partial-observability, resulting in performance similar to expertly specified GVFs. By learning, rather than manually specifying these predictions, we enable the agent to identify useful predictions in a self-supervised manner, taking a step towards truly autonomous systems.", "paper_url": "http://arxiv.org/abs/2206.06485v1", "pdf_url": "http://arxiv.org/pdf/2206.06485v1", "repo_url": null}, "2206.08101": {"publish_time": "2022-06-16", "title": "Is Continual Learning Truly Learning Representations Continually?", "author": "Sungmin Cha et.al.", "abstract": "Continual learning (CL) aims to learn from sequentially arriving tasks without forgetting previous tasks. Whereas CL algorithms have tried to achieve higher average test accuracy across all the tasks learned so far, learning continuously useful representations is critical for successful generalization and downstream transfer. To measure representational quality, we re-train only the output layers using a small balanced dataset for all the tasks, evaluating the average accuracy without any biased predictions toward the current task. We also test on several downstream tasks, measuring transfer learning accuracy of the learned representations. By testing our new formalism on ImageNet-100 and ImageNet-1000, we find that using more exemplar memory is the only option to make a meaningful difference in learned representations, and most of the regularization- or distillation-based CL algorithms that use the exemplar memory fail to learn continuously useful representations in class-incremental learning. Surprisingly, unsupervised (or self-supervised) CL with sufficient memory size can achieve comparable performance to the supervised counterparts. Considering non-trivial labeling costs, we claim that finding more efficient unsupervised CL algorithms that minimally use exemplary memory would be the next promising direction for CL research.", "paper_url": "http://arxiv.org/abs/2206.08101v1", "pdf_url": "http://arxiv.org/pdf/2206.08101v1", "repo_url": null}, "2206.07996": {"publish_time": "2022-06-16", "title": "Continual Learning with Guarantees via Weight Interval Constraints", "author": "Maciej Wo\u0142czyk et.al.", "abstract": "We introduce a new training paradigm that enforces interval constraints on neural network parameter space to control forgetting. Contemporary Continual Learning (CL) methods focus on training neural networks efficiently from a stream of data, while reducing the negative impact of catastrophic forgetting, yet they do not provide any firm guarantees that network performance will not deteriorate uncontrollably over time. In this work, we show how to put bounds on forgetting by reformulating continual learning of a model as a continual contraction of its parameter space. To that end, we propose Hyperrectangle Training, a new training methodology where each task is represented by a hyperrectangle in the parameter space, fully contained in the hyperrectangles of the previous tasks. This formulation reduces the NP-hard CL problem back to polynomial time while providing full resilience against forgetting. We validate our claim by developing InterContiNet (Interval Continual Learning) algorithm which leverages interval arithmetic to effectively model parameter regions as hyperrectangles. Through experimental results, we show that our approach performs well in a continual learning setup without storing data from previous tasks.", "paper_url": "http://arxiv.org/abs/2206.07996v1", "pdf_url": "http://arxiv.org/pdf/2206.07996v1", "repo_url": "https://github.com/gmum/intercontinet"}, "2206.07932": {"publish_time": "2022-06-16", "title": "Lifelong Wandering: A realistic few-shot online continual learning setting", "author": "Mayank Lunayach et.al.", "abstract": "Online few-shot learning describes a setting where models are trained and evaluated on a stream of data while learning emerging classes. While prior work in this setting has achieved very promising performance on instance classification when learning from data-streams composed of a single indoor environment, we propose to extend this setting to consider object classification on a series of several indoor environments, which is likely to occur in applications such as robotics. Importantly, our setting, which we refer to as online few-shot continual learning, injects the well-studied issue of catastrophic forgetting into the few-shot online learning paradigm. In this work, we benchmark several existing methods and adapted baselines within our setting, and show there exists a trade-off between catastrophic forgetting and online performance. Our findings motivate the need for future work in this setting, which can achieve better online performance without catastrophic forgetting.", "paper_url": "http://arxiv.org/abs/2206.07932v1", "pdf_url": "http://arxiv.org/pdf/2206.07932v1", "repo_url": null}, "2206.07877": {"publish_time": "2022-06-16", "title": "Roadblocks to Attracting Students to Software Testing Careers: Comparisons of Replicated Studies", "author": "Rodrigo E. C. Souza et.al.", "abstract": "Context. Recently, a family of studies highlighted the unpopularity of software testing careers among undergraduate students in software engineering and computer science courses. The original study and its replications explored the perception of students in universities in four countries (Cana-da, China, India, and Malaysia), and indicated that most students do not consider a career in software testing as an option after graduation. This scenario represents a problem for the software industry since the lack of skilled testing professionals might decrease the quality of software projects and increase the number of unsuccessful projects. Goal. The present study aims to replicate, in Brazil, the studies conducted in the other four countries to establish comparisons and support the development of strategies to improve the visibility and importance of software testing among undergraduate students across the globe. Method. We followed the same protocol in the original study to collect data using a questionnaire and analyzed the answers using descriptive statistics and qualitative data analysis. Results. Our findings indicate similarities among the results obtained in Brazil in comparison to those obtained from other countries. We observed that students are not motivated to follow a testing career in the software industry based on a belief that testing activities lack challenges and opportunities for continuous learning. Conclusions. In summary, students seem to be interested in learning more about software testing. However, the lack of discussions about the theme in software development courses, as well as the limited offer of courses focused on software quality at the university level reduce the visibility of this area, which causes a decrease in the interest in this career.", "paper_url": "http://arxiv.org/abs/2206.07877v1", "pdf_url": "http://arxiv.org/pdf/2206.07877v1", "repo_url": null}, "2206.07842": {"publish_time": "2022-06-15", "title": "Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning", "author": "Tianlong Chen et.al.", "abstract": "Class-incremental learning (CIL) suffers from the notorious dilemma between learning newly added classes and preserving previously learned class knowledge. That catastrophic forgetting issue could be mitigated by storing historical data for replay, which yet would cause memory overheads as well as imbalanced prediction updates. To address this dilemma, we propose to leverage \"free\" external unlabeled data querying in continual learning. We first present a CIL with Queried Unlabeled Data (CIL-QUD) scheme, where we only store a handful of past training samples as anchors and use them to query relevant unlabeled examples each time. Along with new and past stored data, the queried unlabeled are effectively utilized, through learning-without-forgetting (LwF) regularizers and class-balance training. Besides preserving model generalization over past and current tasks, we next study the problem of adversarial robustness for CIL-QUD. Inspired by the recent success of learning robust models with unlabeled data, we explore a new robustness-aware CIL setting, where the learned adversarial robustness has to resist forgetting and be transferred as new tasks come in continually. While existing options easily fail, we show queried unlabeled data can continue to benefit, and seamlessly extend CIL-QUD into its robustified versions, RCIL-QUD. Extensive experiments demonstrate that CIL-QUD achieves substantial accuracy gains on CIFAR-10 and CIFAR-100, compared to previous state-of-the-art CIL approaches. Moreover, RCIL-QUD establishes the first strong milestone for robustness-aware CIL. Codes are available in https://github.com/VITA-Group/CIL-QUD.", "paper_url": "http://arxiv.org/abs/2206.07842v1", "pdf_url": "http://arxiv.org/pdf/2206.07842v1", "repo_url": null}, "2206.08853": {"publish_time": "2022-06-17", "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge", "author": "Linxi Fan et.al.", "abstract": "Autonomous agents have made great strides in specialist domains like Atari games and Go. However, they typically learn tabula rasa in isolated environments with limited and manually conceived objectives, thus failing to generalize across a wide spectrum of tasks and capabilities. Inspired by how humans continually learn and adapt in the open world, we advocate a trinity of ingredients for building generalist agents: 1) an environment that supports a multitude of tasks and goals, 2) a large-scale database of multimodal knowledge, and 3) a flexible and scalable agent architecture. We introduce MineDojo, a new framework built on the popular Minecraft game that features a simulation suite with thousands of diverse open-ended tasks and an internet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and forum discussions. Using MineDojo's data, we propose a novel agent learning algorithm that leverages large pre-trained video-language models as a learned reward function. Our agent is able to solve a variety of open-ended tasks specified in free-form language without any manually designed dense shaping reward. We open-source the simulation suite and knowledge bases (https://minedojo.org) to promote research towards the goal of generally capable embodied agents.", "paper_url": "http://arxiv.org/abs/2206.08853v1", "pdf_url": "http://arxiv.org/pdf/2206.08853v1", "repo_url": "https://github.com/MineDojo/MineDojo"}, "2206.08489": {"publish_time": "2022-06-17", "title": "Debugging using Orthogonal Gradient Descent", "author": "Narsimha Chilkuri et.al.", "abstract": "In this report we consider the following problem: Given a trained model that is partially faulty, can we correct its behaviour without having to train the model from scratch? In other words, can we ``debug\" neural networks similar to how we address bugs in our mathematical models and standard computer code. We base our approach on the hypothesis that debugging can be treated as a two-task continual learning problem. In particular, we employ a modified version of a continual learning algorithm called Orthogonal Gradient Descent (OGD) to demonstrate, via two simple experiments on the MNIST dataset, that we can in-fact \\textit{unlearn} the undesirable behaviour while retaining the general performance of the model, and we can additionally \\textit{relearn} the appropriate behaviour, both without having to train the model from scratch.", "paper_url": "http://arxiv.org/abs/2206.08489v1", "pdf_url": "http://arxiv.org/pdf/2206.08489v1", "repo_url": null}, "2206.09117": {"publish_time": "2022-06-18", "title": "NISPA: Neuro-Inspired Stability-Plasticity Adaptation for Continual Learning in Sparse Networks", "author": "Mustafa Burak Gurbuz et.al.", "abstract": "The goal of continual learning (CL) is to learn different tasks over time. The main desiderata associated with CL are to maintain performance on older tasks, leverage the latter to improve learning of future tasks, and to introduce minimal overhead in the training process (for instance, to not require a growing model or retraining). We propose the Neuro-Inspired Stability-Plasticity Adaptation (NISPA) architecture that addresses these desiderata through a sparse neural network with fixed density. NISPA forms stable paths to preserve learned knowledge from older tasks. Also, NISPA uses connection rewiring to create new plastic paths that reuse existing knowledge on novel tasks. Our extensive evaluation on EMNIST, FashionMNIST, CIFAR10, and CIFAR100 datasets shows that NISPA significantly outperforms representative state-of-the-art continual learning baselines, and it uses up to ten times fewer learnable parameters compared to baselines. We also make the case that sparsity is an essential ingredient for continual learning. The NISPA code is available at https://github.com/BurakGurbuz97/NISPA.", "paper_url": "http://arxiv.org/abs/2206.09117v1", "pdf_url": "http://arxiv.org/pdf/2206.09117v1", "repo_url": "https://github.com/burakgurbuz97/nispa"}, "2206.09059": {"publish_time": "2022-06-18", "title": "CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks", "author": "Tejas Srinivasan et.al.", "abstract": "Current state-of-the-art vision-and-language models are evaluated on tasks either individually or in a multi-task setting, overlooking the challenges of continually learning (CL) tasks as they arrive. Existing CL benchmarks have facilitated research on task adaptation and mitigating \"catastrophic forgetting\", but are limited to vision-only and language-only tasks. We present CLiMB, a benchmark to study the challenge of learning multimodal tasks in a CL setting, and to systematically evaluate how upstream continual learning can rapidly generalize to new multimodal and unimodal tasks. CLiMB includes implementations of several CL algorithms and a modified Vision-Language Transformer (ViLT) model that can be deployed on both multimodal and unimodal tasks. We find that common CL methods can help mitigate forgetting during multimodal task learning, but do not enable cross-task knowledge transfer. We envision that CLiMB will facilitate research on a new class of CL algorithms for this challenging multimodal setting.", "paper_url": "http://arxiv.org/abs/2206.09059v1", "pdf_url": "http://arxiv.org/pdf/2206.09059v1", "repo_url": "https://github.com/glamor-usc/climb"}, "2206.11849": {"publish_time": "2022-06-23", "title": "Sample Condensation in Online Continual Learning", "author": "Mattia Sangermano et.al.", "abstract": "Online Continual learning is a challenging learning scenario where the model must learn from a non-stationary stream of data where each sample is seen only once. The main challenge is to incrementally learn while avoiding catastrophic forgetting, namely the problem of forgetting previously acquired knowledge while learning from new data. A popular solution in these scenario is to use a small memory to retain old data and rehearse them over time. Unfortunately, due to the limited memory size, the quality of the memory will deteriorate over time. In this paper we propose OLCGM, a novel replay-based continual learning strategy that uses knowledge condensation techniques to continuously compress the memory and achieve a better use of its limited size. The sample condensation step compresses old samples, instead of removing them like other replay strategies. As a result, the experiments show that, whenever the memory budget is limited compared to the complexity of the data, OLCGM improves the final accuracy compared to state-of-the-art replay strategies.", "paper_url": "http://arxiv.org/abs/2206.11849v1", "pdf_url": "http://arxiv.org/pdf/2206.11849v1", "repo_url": null}, "2206.11354": {"publish_time": "2022-06-22", "title": "Continual Learning for Affective Robotics: A Proof of Concept for Wellbeing", "author": "Nikhil Churamani et.al.", "abstract": "Sustaining real-world human-robot interactions requires robots to be sensitive to human behavioural idiosyncrasies and adapt their perception and behaviour models to cater to these individual preferences. For affective robots, this entails learning to adapt to individual affective behaviour to offer a personalised interaction experience to each individual. Continual Learning (CL) has been shown to enable real-time adaptation in agents, allowing them to learn with incrementally acquired data while preserving past knowledge. In this work, we present a novel framework for real-world application of CL for modelling personalised human-robot interactions using a CL-based affect perception mechanism. To evaluate the proposed framework, we undertake a proof-of-concept user study with 20 participants interacting with the Pepper robot using three variants of interaction behaviour: static and scripted, using affect-based adaptation without personalisation, and using affect-based adaptation with continual personalisation. Our results demonstrate a clear preference in the participants for CL-based continual personalisation with significant improvements observed in the robot's anthropomorphism, animacy and likeability ratings as well as the interactions being rated significantly higher for warmth and comfort as the robot is rated as significantly better at understanding how the participants feel.", "paper_url": "http://arxiv.org/abs/2206.11354v1", "pdf_url": "http://arxiv.org/pdf/2206.11354v1", "repo_url": null}, "2206.13336": {"publish_time": "2022-06-27", "title": "Continual Learning of Dynamical Systems with Competitive Federated Reservoir Computing", "author": "Leonard Bereska et.al.", "abstract": "Machine learning recently proved efficient in learning differential equations and dynamical systems from data. However, the data is commonly assumed to originate from a single never-changing system. In contrast, when modeling real-world dynamical processes, the data distribution often shifts due to changes in the underlying system dynamics. Continual learning of these processes aims to rapidly adapt to abrupt system changes without forgetting previous dynamical regimes. This work proposes an approach to continual learning based on reservoir computing, a state-of-the-art method for training recurrent neural networks on complex spatiotemporal dynamical systems. Reservoir computing fixes the recurrent network weights - hence these cannot be forgotten - and only updates linear projection heads to the output. We propose to train multiple competitive prediction heads concurrently. Inspired by neuroscience's predictive coding, only the most predictive heads activate, laterally inhibiting and thus protecting the inactive heads from forgetting induced by interfering parameter updates. We show that this multi-head reservoir minimizes interference and catastrophic forgetting on several dynamical systems, including the Van-der-Pol oscillator, the chaotic Lorenz attractor, and the high-dimensional Lorenz-96 weather model. Our results suggest that reservoir computing is a promising candidate framework for the continual learning of dynamical systems. We provide our code for data generation, method, and comparisons at \\url{https://github.com/leonardbereska/multiheadreservoir}.", "paper_url": "http://arxiv.org/abs/2206.13336v1", "pdf_url": "http://arxiv.org/pdf/2206.13336v1", "repo_url": "https://github.com/leonardbereska/multiheadreservoir"}, "2206.14085": {"publish_time": "2022-06-28", "title": "Continual Learning with Transformers for Image Classification", "author": "Beyza Ermis et.al.", "abstract": "In many real-world scenarios, data to train machine learning models become available over time. However, neural network models struggle to continually learn new concepts without forgetting what has been learnt in the past. This phenomenon is known as catastrophic forgetting and it is often difficult to prevent due to practical constraints, such as the amount of data that can be stored or the limited computation sources that can be used. Moreover, training large neural networks, such as Transformers, from scratch is very costly and requires a vast amount of training data, which might not be available in the application domain of interest. A recent trend indicates that dynamic architectures based on an expansion of the parameters can reduce catastrophic forgetting efficiently in continual learning, but this needs complex tuning to balance the growing number of parameters and barely share any information across tasks. As a result, they struggle to scale to a large number of tasks without significant overhead. In this paper, we validate in the computer vision domain a recent solution called Adaptive Distillation of Adapters (ADA), which is developed to perform continual learning using pre-trained Transformers and Adapters on text classification tasks. We empirically demonstrate on different classification tasks that this method maintains a good predictive performance without retraining the model or increasing the number of model parameters over the time. Besides it is significantly faster at inference time compared to the state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2206.14085v1", "pdf_url": "http://arxiv.org/pdf/2206.14085v1", "repo_url": null}, "2206.13720": {"publish_time": "2022-06-28", "title": "SHELS: Exclusive Feature Sets for Novelty Detection and Continual Learning Without Class Boundaries", "author": "Meghna Gummadi et.al.", "abstract": "While deep neural networks (DNNs) have achieved impressive classification performance in closed-world learning scenarios, they typically fail to generalize to unseen categories in dynamic open-world environments, in which the number of concepts is unbounded. In contrast, human and animal learners have the ability to incrementally update their knowledge by recognizing and adapting to novel observations. In particular, humans characterize concepts via exclusive (unique) sets of essential features, which are used for both recognizing known classes and identifying novelty. Inspired by natural learners, we introduce a Sparse High-level-Exclusive, Low-level-Shared feature representation (SHELS) that simultaneously encourages learning exclusive sets of high-level features and essential, shared low-level features. The exclusivity of the high-level features enables the DNN to automatically detect out-of-distribution (OOD) data, while the efficient use of capacity via sparse low-level features permits accommodating new knowledge. The resulting approach uses OOD detection to perform class-incremental continual learning without known class boundaries. We show that using SHELS for novelty detection results in statistically significant improvements over state-of-the-art OOD detection approaches over a variety of benchmark datasets. Further, we demonstrate that the SHELS model mitigates catastrophic forgetting in a class-incremental learning setting,enabling a combined novelty detection and accommodation framework that supports learning in open-world settings", "paper_url": "http://arxiv.org/abs/2206.13720v1", "pdf_url": "http://arxiv.org/pdf/2206.13720v1", "repo_url": "https://github.com/lifelong-ml/shels"}, "2206.14349": {"publish_time": "2022-06-29", "title": "Fleet-DAgger: Interactive Robot Fleet Learning with Scalable Human Supervision", "author": "Ryan Hoque et.al.", "abstract": "Commercial and industrial deployments of robot fleets often fall back on remote human teleoperators during execution when robots are at risk or unable to make task progress. With continual learning, interventions from the remote pool of humans can also be used to improve the robot fleet control policy over time. A central question is how to effectively allocate limited human attention to individual robots. Prior work addresses this in the single-robot, single-human setting. We formalize the Interactive Fleet Learning (IFL) setting, in which multiple robots interactively query and learn from multiple human supervisors. We present a fully implemented open-source IFL benchmark suite of GPU-accelerated Isaac Gym environments for the evaluation of IFL algorithms. We propose Fleet-DAgger, a family of IFL algorithms, and compare a novel Fleet-DAgger algorithm to 4 baselines in simulation. We also perform 1000 trials of a physical block-pushing experiment with 4 ABB YuMi robot arms. Experiments suggest that the allocation of humans to robots significantly affects robot fleet performance, and that our algorithm achieves up to 8.8x higher return on human effort than baselines. See https://tinyurl.com/fleet-dagger for code, videos, and supplemental material.", "paper_url": "http://arxiv.org/abs/2206.14349v1", "pdf_url": "http://arxiv.org/pdf/2206.14349v1", "repo_url": null}, "2206.14607": {"publish_time": "2022-06-28", "title": "NERDA-Con: Extending NER models for Continual Learning -- Integrating Distinct Tasks and Updating Distribution Shifts", "author": "Supriti Vijay et.al.", "abstract": "With increasing applications in areas such as biomedical information extraction pipelines and social media analytics, Named Entity Recognition (NER) has become an indispensable tool for knowledge extraction. However, with the gradual shift in language structure and vocabulary, NERs are plagued with distribution shifts, making them redundant or not as profitable without re-training. Re-training NERs based on Large Language Models (LLMs) from scratch over newly acquired data poses economic disadvantages. In contrast, re-training only with newly acquired data will result in Catastrophic Forgetting of previously acquired knowledge. Therefore, we propose NERDA-Con, a pipeline for training NERs with LLM bases by incorporating the concept of Elastic Weight Consolidation (EWC) into the NER fine-tuning NERDA pipeline. As we believe our work has implications to be utilized in the pipeline of continual learning and NER, we open-source our code as well as provide the fine-tuning library of the same name NERDA-Con at https://github.com/SupritiVijay/NERDA-Con and https://pypi.org/project/NERDA-Con/.", "paper_url": "http://arxiv.org/abs/2206.14607v1", "pdf_url": "http://arxiv.org/pdf/2206.14607v1", "repo_url": "https://github.com/supritivijay/nerda-con"}, "2206.14581": {"publish_time": "2022-06-27", "title": "On-device Synaptic Memory Consolidation using Fowler-Nordheim Quantum-tunneling", "author": "Mustafizur Rahman et.al.", "abstract": "Synaptic memory consolidation has been heralded as one of the key mechanisms for supporting continual learning in neuromorphic Artificial Intelligence (AI) systems. Here we report that a Fowler-Nordheim (FN) quantum-tunneling device can implement synaptic memory consolidation similar to what can be achieved by algorithmic consolidation models like the cascade and the elastic weight consolidation (EWC) models. The proposed FN-synapse not only stores the synaptic weight but also stores the synapse's historical usage statistic on the device itself. We also show that the operation of the FN-synapse is near-optimal in terms of the synaptic lifetime and we demonstrate that a network comprising FN-synapses outperforms a comparable EWC network for a small benchmark continual learning task. With an energy footprint of femtojoules per synaptic update, we believe that the proposed FN-synapse provides an ultra-energy-efficient approach for implementing both synaptic memory consolidation and persistent learning.", "paper_url": "http://arxiv.org/abs/2206.14581v1", "pdf_url": "http://arxiv.org/pdf/2206.14581v1", "repo_url": null}, "2206.15472": {"publish_time": "2022-06-30", "title": "On-Device Training Under 256KB Memory", "author": "Ji Lin et.al.", "abstract": "On-device training enables the model to adapt to new data collected from the sensors by fine-tuning a pre-trained model. However, the training memory consumption is prohibitive for IoT devices that have tiny memory resources. We propose an algorithm-system co-design framework to make on-device training possible with only 256KB of memory. On-device training faces two unique challenges: (1) the quantized graphs of neural networks are hard to optimize due to mixed bit-precision and the lack of normalization; (2) the limited hardware resource (memory and computation) does not allow full backward computation. To cope with the optimization difficulty, we propose Quantization-Aware Scaling to calibrate the gradient scales and stabilize quantized training. To reduce the memory footprint, we propose Sparse Update to skip the gradient computation of less important layers and sub-tensors. The algorithm innovation is implemented by a lightweight training system, Tiny Training Engine, which prunes the backward computation graph to support sparse updates and offloads the runtime auto-differentiation to compile time. Our framework is the first practical solution for on-device transfer learning of visual recognition on tiny IoT devices (e.g., a microcontroller with only 256KB SRAM), using less than 1/100 of the memory of existing frameworks while matching the accuracy of cloud training+edge deployment for the tinyML application VWW. Our study enables IoT devices to not only perform inference but also continuously adapt to new data for on-device lifelong learning.", "paper_url": "http://arxiv.org/abs/2206.15472v1", "pdf_url": "http://arxiv.org/pdf/2206.15472v1", "repo_url": null}, "2207.00461": {"publish_time": "2022-07-01", "title": "Lifelong Inverse Reinforcement Learning", "author": "Jorge A. Mendez et.al.", "abstract": "Methods for learning from demonstration (LfD) have shown success in acquiring behavior policies by imitating a user. However, even for a single task, LfD may require numerous demonstrations. For versatile agents that must learn many tasks via demonstration, this process would substantially burden the user if each task were learned in isolation. To address this challenge, we introduce the novel problem of lifelong learning from demonstration, which allows the agent to continually build upon knowledge learned from previously demonstrated tasks to accelerate the learning of new tasks, reducing the amount of demonstrations required. As one solution to this problem, we propose the first lifelong learning approach to inverse reinforcement learning, which learns consecutive tasks via demonstration, continually transferring knowledge between tasks to improve performance.", "paper_url": "http://arxiv.org/abs/2207.00461v1", "pdf_url": "http://arxiv.org/pdf/2207.00461v1", "repo_url": "https://github.com/lifelong-ml/elirl"}, "2207.00430": {"publish_time": "2022-07-01", "title": "How trial-to-trial learning shapes mappings in the mental lexicon: Modelling Lexical Decision with Linear Discriminative Learning", "author": "Maria Heitmeier et.al.", "abstract": "Priming and antipriming can be modelled with error-driven learning (Marsolek, 2008), by assuming that the learning of the prime influences processing of the target stimulus. This implies that participants are continuously learning in priming studies, and predicts that they are also learning in each trial of other psycholinguistic experiments. This study investigates whether trial-to-trial learning can be detected in lexical decision experiments. We used the Discriminative Lexicon Model (DLM; Baayen et al., 2019), a model of the mental lexicon with meaning representations from distributional semantics, which models incremental learning with the Widrow-Hoff rule. We used data from the British Lexicon Project (BLP; Keuleers et al., 2012) and simulated the lexical decision experiment with the DLM on a trial-by-trial basis for each subject individually. Then, reaction times for words and nonwords were predicted with Generalised Additive Models, using measures derived from the DLM simulations as predictors. Models were developed with the data of two subjects and tested on all other subjects. We extracted measures from two simulations for each subject (one with learning updates between trials and one without), and used them as input to two GAMs. Learning-based models showed better model fit than the non-learning ones for the majority of subjects. Our measures also provided insights into lexical processing and enabled us to explore individual differences with Linear Mixed Models. This demonstrates the potential of the DLM to model behavioural data and leads to the conclusion that trial-to-trial learning can indeed be detected in psycholinguistic experiments.", "paper_url": "http://arxiv.org/abs/2207.00430v1", "pdf_url": "http://arxiv.org/pdf/2207.00430v1", "repo_url": null}, "2207.00010": {"publish_time": "2022-06-29", "title": "Continual Learning for Human State Monitoring", "author": "Federico Matteoni et.al.", "abstract": "Continual Learning (CL) on time series data represents a promising but under-studied avenue for real-world applications. We propose two new CL benchmarks for Human State Monitoring. We carefully designed the benchmarks to mirror real-world environments in which new subjects are continuously added. We conducted an empirical evaluation to assess the ability of popular CL strategies to mitigate forgetting in our benchmarks. Our results show that, possibly due to the domain-incremental properties of our benchmarks, forgetting can be easily tackled even with a simple finetuning and that existing strategies struggle in accumulating knowledge over a fixed, held-out, test subject.", "paper_url": "http://arxiv.org/abs/2207.00010v1", "pdf_url": "http://arxiv.org/pdf/2207.00010v1", "repo_url": null}, "2207.01562": {"publish_time": "2022-07-04", "title": "Progressive Latent Replay for efficient Generative Rehearsal", "author": "Stanis\u0142aw Pawlak et.al.", "abstract": "We introduce a new method for internal replay that modulates the frequency of rehearsal based on the depth of the network. While replay strategies mitigate the effects of catastrophic forgetting in neural networks, recent works on generative replay show that performing the rehearsal only on the deeper layers of the network improves the performance in continual learning. However, the generative approach introduces additional computational overhead, limiting its applications. Motivated by the observation that earlier layers of neural networks forget less abruptly, we propose to update network layers with varying frequency using intermediate-level features during replay. This reduces the computational burden by omitting computations for both deeper layers of the generator and earlier layers of the main model. We name our method Progressive Latent Replay and show that it outperforms Internal Replay while using significantly fewer resources.", "paper_url": "http://arxiv.org/abs/2207.01562v2", "pdf_url": "http://arxiv.org/pdf/2207.01562v2", "repo_url": null}, "2207.01145": {"publish_time": "2022-07-04", "title": "It's all About Consistency: A Study on Memory Composition for Replay-Based Methods in Continual Learning", "author": "Julio Hurtado et.al.", "abstract": "Continual Learning methods strive to mitigate Catastrophic Forgetting (CF), where knowledge from previously learned tasks is lost when learning a new one. Among those algorithms, some maintain a subset of samples from previous tasks when training. These samples are referred to as a memory. These methods have shown outstanding performance while being conceptually simple and easy to implement. Yet, despite their popularity, little has been done to understand which elements to be included into the memory. Currently, this memory is often filled via random sampling with no guiding principles that may aid in retaining previous knowledge. In this work, we propose a criterion based on the learning consistency of a sample called Consistency AWare Sampling (CAWS). This criterion prioritizes samples that are easier to learn by deep networks. We perform studies on three different memory-based methods: AGEM, GDumb, and Experience Replay, on MNIST, CIFAR-10 and CIFAR-100 datasets. We show that using the most consistent elements yields performance gains when constrained by a compute budget; when under no such constrain, random sampling is a strong baseline. However, using CAWS on Experience Replay yields improved performance over the random baseline. Finally, we show that CAWS achieves similar results to a popular memory selection method while requiring significantly less computational resources.", "paper_url": "http://arxiv.org/abs/2207.01145v1", "pdf_url": "http://arxiv.org/pdf/2207.01145v1", "repo_url": null}, "2207.01036": {"publish_time": "2022-07-03", "title": "Memory-Based Label-Text Tuning for Few-Shot Class-Incremental Learning", "author": "Jinze Li et.al.", "abstract": "Few-shot class-incremental learning(FSCIL) focuses on designing learning algorithms that can continually learn a sequence of new tasks from a few samples without forgetting old ones. The difficulties are that training on a sequence of limited data from new tasks leads to severe overfitting issues and causes the well-known catastrophic forgetting problem. Existing researches mainly utilize the image information, such as storing the image knowledge of previous tasks or limiting classifiers updating. However, they ignore analyzing the informative and less noisy text information of class labels. In this work, we propose leveraging the label-text information by adopting the memory prompt. The memory prompt can learn new data sequentially, and meanwhile store the previous knowledge. Furthermore, to optimize the memory prompt without undermining the stored knowledge, we propose a stimulation-based training strategy. It optimizes the memory prompt depending on the image embedding stimulation, which is the distribution of the image embedding elements. Experiments show that our proposed method outperforms all prior state-of-the-art approaches, significantly mitigating the catastrophic forgetting and overfitting problems.", "paper_url": "http://arxiv.org/abs/2207.01036v1", "pdf_url": "http://arxiv.org/pdf/2207.01036v1", "repo_url": null}}, "Meta Learning": {"2202.12888": {"publish_time": "2022-02-25", "title": "Meta-Learning for Simple Regret Minimization", "author": "Mohammadjavad Azizi et.al.", "abstract": "We develop a meta-learning framework for simple regret minimization in bandits. In this framework, a learning agent interacts with a sequence of bandit tasks, which are sampled i.i.d.\\ from an unknown prior distribution, and learns its meta-parameters to perform better on future tasks. We propose the first Bayesian and frequentist algorithms for this meta-learning problem. The Bayesian algorithm has access to a prior distribution over the meta-parameters and its meta simple regret over $m$ bandit tasks with horizon $n$ is mere $\\tilde{O}(m / \\sqrt{n})$. This is while we show that the meta simple regret of the frequentist algorithm is $\\tilde{O}(\\sqrt{m} n + m/ \\sqrt{n})$, and thus, worse. However, the algorithm is more general, because it does not need a prior distribution over the meta-parameters, and is easier to implement for various distributions. We instantiate our algorithms for several classes of bandit problems. Our algorithms are general and we complement our theory by evaluating them empirically in several environments.", "paper_url": "http://arxiv.org/abs/2202.12888v1", "pdf_url": "http://arxiv.org/pdf/2202.12888v1", "repo_url": "https://github.com/Azizimj/Meta-SRM"}, "2202.12450": {"publish_time": "2022-02-25", "title": "MetaVA: Curriculum Meta-learning and Pre-fine-tuning of Deep Neural Networks for Detecting Ventricular Arrhythmias based on ECGs", "author": "Wenrui Zhang et.al.", "abstract": "Ventricular arrhythmias (VA) are the main causes of sudden cardiac death. Developing machine learning methods for detecting VA based on electrocardiograms (ECGs) can help save people's lives. However, developing such machine learning models for ECGs is challenging because of the following: 1) group-level diversity from different subjects and 2) individual-level diversity from different moments of a single subject. In this study, we aim to solve these problems in the pre-training and fine-tuning stages. For the pre-training stage, we propose a novel model agnostic meta-learning (MAML) with curriculum learning (CL) method to solve group-level diversity. MAML is expected to better transfer the knowledge from a large dataset and use only a few recordings to quickly adapt the model to a new person. CL is supposed to further improve MAML by meta-learning from easy to difficult tasks. For the fine-tuning stage, we propose improved pre-fine-tuning to solve individual-level diversity. We conduct experiments using a combination of three publicly available ECG datasets. The results show that our method outperforms the compared methods in terms of all evaluation metrics. Ablation studies show that MAML and CL could help perform more evenly, and pre-fine-tuning could better fit the model to training data.", "paper_url": "http://arxiv.org/abs/2202.12450v1", "pdf_url": "http://arxiv.org/pdf/2202.12450v1", "repo_url": null}, "2202.12396": {"publish_time": "2022-02-24", "title": "Finite-Sum Compositional Stochastic Optimization: Theory and Applications", "author": "Bokun Wang et.al.", "abstract": "This paper studies stochastic optimization for a sum of compositional functions, where the inner-level function of each summand is coupled with the corresponding summation index. We refer to this family of problems as finite-sum coupled compositional optimization (FCCO). It has broad applications in machine learning for optimizing non-convex or convex compositional measures/objectives such as average precision (AP), $p$-norm push, listwise ranking losses, neighborhood component analysis (NCA), deep survival analysis, deep latent variable models, softmax functions, and model agnostic meta-learning, which deserves finer analysis. Yet, existing algorithms and analysis are restricted in one or other aspects. The contribution of this paper is to provide a comprehensive analysis of a simple stochastic algorithm for both non-convex and convex objectives. The key results are {\\bf improved oracle complexities with the parallel speed-up} by the moving-average based stochastic estimator with mini-batching. Our theoretical analysis also exhibits new insights for improving the practical implementation by sampling the batches of equal size for the outer and inner levels. Numerical experiments on AP maximization and $p$-norm push optimization corroborate some aspects of the theory.", "paper_url": "http://arxiv.org/abs/2202.12396v1", "pdf_url": "http://arxiv.org/pdf/2202.12396v1", "repo_url": null}, "2202.12326": {"publish_time": "2022-02-24", "title": "Towards Better Meta-Initialization with Task Augmentation for Kindergarten-aged Speech Recognition", "author": "Yunzheng Zhu et.al.", "abstract": "Children's automatic speech recognition (ASR) is always difficult due to, in part, the data scarcity problem, especially for kindergarten-aged kids. When data are scarce, the model might overfit to the training data, and hence good starting points for training are essential. Recently, meta-learning was proposed to learn model initialization (MI) for ASR tasks of different languages. This method leads to good performance when the model is adapted to an unseen language. However, MI is vulnerable to overfitting on training tasks (learner overfitting). It is also unknown whether MI generalizes to other low-resource tasks. In this paper, we validate the effectiveness of MI in children's ASR and attempt to alleviate the problem of learner overfitting. To achieve model-agnostic meta-learning (MAML), we regard children's speech at each age as a different task. In terms of learner overfitting, we propose a task-level augmentation method by simulating new ages using frequency warping techniques. Detailed experiments are conducted to show the impact of task augmentation on each age for kindergarten-aged speech. As a result, our approach achieves a relative word error rate (WER) improvement of 51% over the baseline system with no augmentation or initialization.", "paper_url": "http://arxiv.org/abs/2202.12326v1", "pdf_url": "http://arxiv.org/pdf/2202.12326v1", "repo_url": null}, "2202.11490": {"publish_time": "2022-02-23", "title": "Towards Tailored Models on Private AIoT Devices: Federated Direct Neural Architecture Search", "author": "Chunhui Zhang et.al.", "abstract": "Neural networks often encounter various stringent resource constraints while deploying on edge devices. To tackle these problems with less human efforts, automated machine learning becomes popular in finding various neural architectures that fit diverse Artificial Intelligence of Things (AIoT) scenarios. Recently, to prevent the leakage of private information while enable automated machine intelligence, there is an emerging trend to integrate federated learning and neural architecture search (NAS). Although promising as it may seem, the coupling of difficulties from both tenets makes the algorithm development quite challenging. In particular, how to efficiently search the optimal neural architecture directly from massive non-independent and identically distributed (non-IID) data among AIoT devices in a federated manner is a hard nut to crack. In this paper, to tackle this challenge, by leveraging the advances in ProxylessNAS, we propose a Federated Direct Neural Architecture Search (FDNAS) framework that allows for hardware-friendly NAS from non- IID data across devices. To further adapt to both various data distributions and different types of devices with heterogeneous embedded hardware platforms, inspired by meta-learning, a Cluster Federated Direct Neural Architecture Search (CFDNAS) framework is proposed to achieve device-aware NAS, in the sense that each device can learn a tailored deep learning model for its particular data distribution and hardware constraint. Extensive experiments on non-IID datasets have shown the state-of-the-art accuracy-efficiency trade-offs achieved by the proposed solution in the presence of both data and device heterogeneity.", "paper_url": "http://arxiv.org/abs/2202.11490v1", "pdf_url": "http://arxiv.org/pdf/2202.11490v1", "repo_url": null}, "2202.13611": {"publish_time": "2022-02-28", "title": "Prepare for Trouble and Make it Double. Supervised and Unsupervised Stacking for AnomalyBased Intrusion Detection", "author": "Tommaso Zoppi et.al.", "abstract": "In the last decades, researchers, practitioners and companies struggled in devising mechanisms to detect malicious activities originating security threats. Amongst the many solutions, network intrusion detection emerged as one of the most popular to analyze network traffic and detect ongoing intrusions based on rules or by means of Machine Learners (MLs), which process such traffic and learn a model to suspect intrusions. Supervised MLs are very effective in detecting known threats, but struggle in identifying zero-day attacks (unknown during learning phase), which instead can be detected through unsupervised MLs. Unfortunately, there are no definitive answers on the combined use of both approaches for network intrusion detection. In this paper we first expand the problem of zero-day attacks and motivate the need to combine supervised and unsupervised algorithms. We propose the adoption of meta-learning, in the form of a two-layer Stacker, to create a mixed approach that detects both known and unknown threats. Then we implement and empirically evaluate our Stacker through an experimental campaign that allows i) debating on meta-features crafted through unsupervised base-level learners, ii) electing the most promising supervised meta-level classifiers, and iii) benchmarking classification scores of the Stacker with respect to supervised and unsupervised classifiers. Last, we compare our solution with existing works from the recent literature. Overall, our Stacker reduces misclassifications with respect to (un)supervised ML algorithms in all the 7 public datasets we considered, and outperforms existing studies in 6 out of those 7 datasets. In particular, it turns out to be more effective in detecting zero-day attacks than supervised algorithms, limiting their main weakness but still maintaining adequate capabilities in detecting known attacks.", "paper_url": "http://arxiv.org/abs/2202.13611v1", "pdf_url": "http://arxiv.org/pdf/2202.13611v1", "repo_url": null}, "2202.13474": {"publish_time": "2022-02-27", "title": "Interpretable Concept-based Prototypical Networks for Few-Shot Learning", "author": "Mohammad Reza Zarei et.al.", "abstract": "Few-shot learning aims at recognizing new instances from classes with limited samples. This challenging task is usually alleviated by performing meta-learning on similar tasks. However, the resulting models are black-boxes. There has been growing concerns about deploying black-box machine learning models and FSL is not an exception in this regard. In this paper, we propose a method for FSL based on a set of human-interpretable concepts. It constructs a set of metric spaces associated with the concepts and classifies samples of novel classes by aggregating concept-specific decisions. The proposed method does not require concept annotations for query samples. This interpretable method achieved results on a par with six previously state-of-the-art black-box FSL methods on the CUB fine-grained bird classification dataset.", "paper_url": "http://arxiv.org/abs/2202.13474v1", "pdf_url": "http://arxiv.org/pdf/2202.13474v1", "repo_url": null}, "2202.13227": {"publish_time": "2022-02-26", "title": "Towards Scalable and Robust Structured Bandits: A Meta-Learning Framework", "author": "Runzhe Wan et.al.", "abstract": "Online learning in large-scale structured bandits is known to be challenging due to the curse of dimensionality. In this paper, we propose a unified meta-learning framework for a general class of structured bandit problems where the parameter space can be factorized to item-level. The novel bandit algorithm is general to be applied to many popular problems,scalable to the huge parameter and action spaces, and robust to the specification of the generalization model. At the core of this framework is a Bayesian hierarchical model that allows information sharing among items via their features, upon which we design a meta Thompson sampling algorithm. Three representative examples are discussed thoroughly. Both theoretical analysis and numerical results support the usefulness of the proposed method.", "paper_url": "http://arxiv.org/abs/2202.13227v1", "pdf_url": "http://arxiv.org/pdf/2202.13227v1", "repo_url": null}, "2202.13117": {"publish_time": "2022-02-26", "title": "An Unsupervised Cross-Modal Hashing Method Robust to Noisy Training Image-Text Correspondences in Remote Sensing", "author": "Georgii Mikriukov et.al.", "abstract": "The development of accurate and scalable cross-modal image-text retrieval methods, where queries from one modality (e.g., text) can be matched to archive entries from another (e.g., remote sensing image) has attracted great attention in remote sensing (RS). Most of the existing methods assume that a reliable multi-modal training set with accurately matched text-image pairs is existing. However, this assumption may not always hold since the multi-modal training sets may include noisy pairs (i.e., textual descriptions/captions associated to training images can be noisy), distorting the learning process of the retrieval methods. To address this problem, we propose a novel unsupervised cross-modal hashing method robust to the noisy image-text correspondences (CHNR). CHNR consists of three modules: 1) feature extraction module, which extracts feature representations of image-text pairs; 2) noise detection module, which detects potential noisy correspondences; and 3) hashing module that generates cross-modal binary hash codes. The proposed CHNR includes two training phases: i) meta-learning phase that uses a small portion of clean (i.e., reliable) data to train the noise detection module in an adversarial fashion; and ii) the main training phase for which the trained noise detection module is used to identify noisy correspondences while the hashing module is trained on the noisy multi-modal training set. Experimental results show that the proposed CHNR outperforms state-of-the-art methods. Our code is publicly available at https://git.tu-berlin.de/rsim/chnr", "paper_url": "http://arxiv.org/abs/2202.13117v1", "pdf_url": "http://arxiv.org/pdf/2202.13117v1", "repo_url": "https://git.tu-berlin.de/rsim/chnr"}, "2202.13001": {"publish_time": "2022-02-25", "title": "Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms", "author": "MohammadJavad Azizi et.al.", "abstract": "We study a sequential decision problem where the learner faces a sequence of $K$-armed stochastic bandit tasks. The tasks may be designed by an adversary, but the adversary is constrained to choose the optimal arm of each task in a smaller (but unknown) subset of $M$ arms. The task boundaries might be known (the bandit meta-learning setting), or unknown (the non-stationary bandit setting), and the number of tasks $N$ as well as the total number of rounds $T$ are known ($N$ could be unknown in the meta-learning setting). We design an algorithm based on a reduction to bandit submodular maximization, and show that its regret in both settings is smaller than the simple baseline of $\\tilde{O}(\\sqrt{KNT})$ that can be obtained by using standard algorithms designed for non-stationary bandit problems. For the bandit meta-learning problem with fixed task length $\\tau$, we show that the regret of the algorithm is bounded as $\\tilde{O}(N\\sqrt{M \\tau}+N^{2/3})$. Under additional assumptions on the identifiability of the optimal arms in each task, we show a bandit meta-learning algorithm with an improved $\\tilde{O}(N\\sqrt{M \\tau}+N^{1/2})$ regret.", "paper_url": "http://arxiv.org/abs/2202.13001v1", "pdf_url": "http://arxiv.org/pdf/2202.13001v1", "repo_url": "https://github.com/duongnhatthang/meta-bandit"}, "2203.00089": {"publish_time": "2022-02-28", "title": "Amortized Proximal Optimization", "author": "Juhan Bae et.al.", "abstract": "We propose a framework for online meta-optimization of parameters that govern optimization, called Amortized Proximal Optimization (APO). We first interpret various existing neural network optimizers as approximate stochastic proximal point methods which trade off the current-batch loss with proximity terms in both function space and weight space. The idea behind APO is to amortize the minimization of the proximal point objective by meta-learning the parameters of an update rule. We show how APO can be used to adapt a learning rate or a structured preconditioning matrix. Under appropriate assumptions, APO can recover existing optimizers such as natural gradient descent and KFAC. It enjoys low computational overhead and avoids expensive and numerically sensitive operations required by some second-order optimizers, such as matrix inverses. We empirically test APO for online adaptation of learning rates and structured preconditioning matrices for regression, image reconstruction, image classification, and natural language translation tasks. Empirically, the learning rate schedules found by APO generally outperform optimal fixed learning rates and are competitive with manually tuned decay schedules. Using APO to adapt a structured preconditioning matrix generally results in optimization performance competitive with second-order methods. Moreover, the absence of matrix inversion provides numerical stability, making it effective for low precision training.", "paper_url": "http://arxiv.org/abs/2203.00089v1", "pdf_url": "http://arxiv.org/pdf/2203.00089v1", "repo_url": null}, "2203.01123": {"publish_time": "2022-03-01", "title": "A Constrained Optimization Approach to Bilevel Optimization with Multiple Inner Minima", "author": "Daouda Sow et.al.", "abstract": "Bilevel optimization has found extensive applications in modern machine learning problems such as hyperparameter optimization, neural architecture search, meta-learning, etc. While bilevel problems with a unique inner minimal point (e.g., where the inner function is strongly convex) are well understood, bilevel problems with multiple inner minimal points remains to be a challenging and open problem. Existing algorithms designed for such a problem were applicable to restricted situations and do not come with the full guarantee of convergence. In this paper, we propose a new approach, which convert the bilevel problem to an equivalent constrained optimization, and then the primal-dual algorithm can be used to solve the problem. Such an approach enjoys a few advantages including (a) addresses the multiple inner minima challenge; (b) features fully first-order efficiency without involving second-order Hessian and Jacobian computations, as opposed to most existing gradient-based bilevel algorithms; (c) admits the convergence guarantee via constrained nonconvex optimization. Our experiments further demonstrate the desired performance of the proposed approach.", "paper_url": "http://arxiv.org/abs/2203.01123v1", "pdf_url": "http://arxiv.org/pdf/2203.01123v1", "repo_url": null}, "2203.01924": {"publish_time": "2022-03-03", "title": "Min-Max Bilevel Multi-objective Optimization with Applications in Machine Learning", "author": "Alex Gu et.al.", "abstract": "This paper is the first to propose a generic min-max bilevel multi-objective optimization framework, highlighting applications in representation learning and hyperparameter optimization. In many machine learning applications such as meta-learning, multi-task learning, and representation learning, a subset of the parameters are shared by all the tasks, while each specific task has its own set of additional parameters. By leveraging the recent advances of nonconvex min-max optimization, we propose a gradient descent-ascent bilevel optimization (MORBiT) algorithm which is able to extract a set of shared parameters that is robust over all tasks and further overcomes the distributional shift between training and testing tasks. Theoretical analyses show that MORBiT converges to the first-order stationary point at a rate of $\\mathcal{O}(\\sqrt{n}K^{-2/5})$ for a class of nonconvex problems, where $K$ denotes the total number of iterations and $n$ denotes the number of tasks. Overall, we formulate a min-max bilevel multi-objective optimization problem, provide a single loop two-timescale algorithm with convergence rate guarantees, and show theoretical bounds on the generalization abilities of the optimizer. Experimental results on sinusoid regression and representation learning showcase the superiority of MORBiT over state-of-the-art methods, validating our convergence and generalization results.", "paper_url": "http://arxiv.org/abs/2203.01924v1", "pdf_url": "http://arxiv.org/pdf/2203.01924v1", "repo_url": null}, "2203.01482": {"publish_time": "2022-03-03", "title": "MetaDT: Meta Decision Tree for Interpretable Few-Shot Learning", "author": "Baoquan Zhang et.al.", "abstract": "Few-Shot Learning (FSL) is a challenging task, which aims to recognize novel classes with few examples. Recently, lots of methods have been proposed from the perspective of meta-learning and representation learning for improving FSL performance. However, few works focus on the interpretability of FSL decision process. In this paper, we take a step towards the interpretable FSL by proposing a novel decision tree-based meta-learning framework, namely, MetaDT. Our insight is replacing the last black-box FSL classifier of the existing representation learning methods by an interpretable decision tree with meta-learning. The key challenge is how to effectively learn the decision tree (i.e., the tree structure and the parameters of each node) in the FSL setting. To address the challenge, we introduce a tree-like class hierarchy as our prior: 1) the hierarchy is directly employed as the tree structure; 2) by regarding the class hierarchy as an undirected graph, a graph convolution-based decision tree inference network is designed as our meta-learner to learn to infer the parameters of each node. At last, a two-loop optimization mechanism is incorporated into our framework for a fast adaptation of the decision tree with few examples. Extensive experiments on performance comparison and interpretability analysis show the effectiveness and superiority of our MetaDT. Our code will be publicly available upon acceptance.", "paper_url": "http://arxiv.org/abs/2203.01482v1", "pdf_url": "http://arxiv.org/pdf/2203.01482v1", "repo_url": null}, "2203.01443": {"publish_time": "2022-03-02", "title": "Continuous-Time Meta-Learning with Forward Mode Differentiation", "author": "Tristan Deleu et.al.", "abstract": "Drawing inspiration from gradient-based meta-learning methods with infinitely small gradient steps, we introduce Continuous-Time Meta-Learning (COMLN), a meta-learning algorithm where adaptation follows the dynamics of a gradient vector field. Specifically, representations of the inputs are meta-learned such that a task-specific linear classifier is obtained as a solution of an ordinary differential equation (ODE). Treating the learning process as an ODE offers the notable advantage that the length of the trajectory is now continuous, as opposed to a fixed and discrete number of gradient steps. As a consequence, we can optimize the amount of adaptation necessary to solve a new task using stochastic gradient descent, in addition to learning the initial conditions as is standard practice in gradient-based meta-learning. Importantly, in order to compute the exact meta-gradients required for the outer-loop updates, we devise an efficient algorithm based on forward mode differentiation, whose memory requirements do not scale with the length of the learning trajectory, thus allowing longer adaptation in constant memory. We provide analytical guarantees for the stability of COMLN, we show empirically its efficiency in terms of runtime and memory usage, and we illustrate its effectiveness on a range of few-shot image classification problems.", "paper_url": "http://arxiv.org/abs/2203.01443v1", "pdf_url": "http://arxiv.org/pdf/2203.01443v1", "repo_url": null}, "2203.02113": {"publish_time": "2022-03-04", "title": "FS-COCO: Towards Understanding of Freehand Sketches of Common Objects in Context", "author": "Pinaki Nath Chowdhury et.al.", "abstract": "We advance sketch research to scenes with the first dataset of freehand scene sketches, FS-COCO. With practical applications in mind, we collect sketches that convey well scene content but can be sketched within a few minutes by a person with any sketching skills. Our dataset comprises 10,000 freehand scene vector sketches with per point space-time information by 100 non-expert individuals, offering both object- and scene-level abstraction. Each sketch is augmented with its text description. Using our dataset, we study for the first time the problem of the fine-grained image retrieval from freehand scene sketches and sketch captions. We draw insights on (i) Scene salience encoded in sketches with strokes temporal order; (ii) The retrieval performance accuracy from scene sketches against image captions; (iii) Complementarity of information in sketches and image captions, as well as the potential benefit of combining the two modalities. In addition, we propose new solutions enabled by our dataset (i) We adopt meta-learning to show how the retrieval model can be fine-tuned to a new user style given just a small set of sketches, (ii) We extend a popular vector sketch LSTM-based encoder to handle sketches with larger complexity than was supported by previous work. Namely, we propose a hierarchical sketch decoder, which we leverage at a sketch-specific \"pretext\" task. Our dataset enables for the first time research on freehand scene sketch understanding and its practical applications.", "paper_url": "http://arxiv.org/abs/2203.02113v1", "pdf_url": "http://arxiv.org/pdf/2203.02113v1", "repo_url": null}, "2203.03328": {"publish_time": "2022-03-07", "title": "Automated Few-Shot Time Series Forecasting based on Bi-level Programming", "author": "Jiangjiao Xu et.al.", "abstract": "New micro-grid design with renewable energy sources and battery storage systems can help improve greenhouse gas emissions and reduce the operational cost. To provide an effective short-/long-term forecasting of both energy generation and load demand, time series predictive modeling has been one of the key tools to guide the optimal decision-making for planning and operation. One of the critical challenges of time series renewable energy forecasting is the lack of historical data to train an adequate predictive model. Moreover, the performance of a machine learning model is sensitive to the choice of its corresponding hyperparameters. Bearing these considerations in mind, this paper develops a BiLO-Auto-TSF/ML framework that automates the optimal design of a few-shot learning pipeline from a bi-level programming perspective. Specifically, the lower-level meta-learning helps boost the base-learner to mitigate the small data challenge while the hyperparameter optimization at the upper level proactively searches for the optimal hyperparameter configurations for both base- and meta-learners. Note that the proposed framework is so general that any off-the-shelf machine learning method can be used in a plug-in manner. Comprehensive experiments fully demonstrate the effectiveness of our proposed BiLO-Auto-TSF/ML framework to search for a high-performance few-shot learning pipeline for various energy sources.", "paper_url": "http://arxiv.org/abs/2203.03328v1", "pdf_url": "http://arxiv.org/pdf/2203.03328v1", "repo_url": null}, "2203.03279": {"publish_time": "2022-03-07", "title": "Evaluating State of the Art, Forecasting Ensembles- and Meta-learning Strategies for Model Fusion", "author": "Pieter Cawood et.al.", "abstract": "Techniques of hybridisation and ensemble learning are popular model fusion techniques for improving the predictive power of forecasting methods. With limited research that instigates combining these two promising approaches, this paper focuses on the utility of the Exponential-Smoothing-Recurrent Neural Network (ES-RNN) in the pool of base models for different ensembles. We compare against some state of the art ensembling techniques and arithmetic model averaging as a benchmark. We experiment with the M4 forecasting data set of 100,000 time-series, and the results show that the Feature-based Forecast Model Averaging (FFORMA), on average, is the best technique for late data fusion with the ES-RNN. However, considering the M4's Daily subset of data, stacking was the only successful ensemble at dealing with the case where all base model performances are similar. Our experimental results indicate that we attain state of the art forecasting results compared to N-BEATS as a benchmark. We conclude that model averaging is a more robust ensemble than model selection and stacking strategies. Further, the results show that gradient boosting is superior for implementing ensemble learning strategies.", "paper_url": "http://arxiv.org/abs/2203.03279v1", "pdf_url": "http://arxiv.org/pdf/2203.03279v1", "repo_url": null}, "2203.03191": {"publish_time": "2022-03-07", "title": "Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features", "author": "Florian Lux et.al.", "abstract": "While neural text-to-speech systems perform remarkably well in high-resource scenarios, they cannot be applied to the majority of the over 6,000 spoken languages in the world due to a lack of appropriate training data. In this work, we use embeddings derived from articulatory vectors rather than embeddings derived from phoneme identities to learn phoneme representations that hold across languages. In conjunction with language agnostic meta learning, this enables us to fine-tune a high-quality text-to-speech model on just 30 minutes of data in a previously unseen language spoken by a previously unseen speaker.", "paper_url": "http://arxiv.org/abs/2203.03191v1", "pdf_url": "http://arxiv.org/pdf/2203.03191v1", "repo_url": "https://github.com/digitalphonetics/ims-toucan"}, "2203.03059": {"publish_time": "2022-03-06", "title": "Is Bayesian Model-Agnostic Meta Learning Better than Model-Agnostic Meta Learning, Provably?", "author": "Lisha Chen et.al.", "abstract": "Meta learning aims at learning a model that can quickly adapt to unseen tasks. Widely used meta learning methods include model agnostic meta learning (MAML), implicit MAML, Bayesian MAML. Thanks to its ability of modeling uncertainty, Bayesian MAML often has advantageous empirical performance. However, the theoretical understanding of Bayesian MAML is still limited, especially on questions such as if and when Bayesian MAML has provably better performance than MAML. In this paper, we aim to provide theoretical justifications for Bayesian MAML's advantageous performance by comparing the meta test risks of MAML and Bayesian MAML. In the meta linear regression, under both the distribution agnostic and linear centroid cases, we have established that Bayesian MAML indeed has provably lower meta test risks than MAML. We verify our theoretical results through experiments.", "paper_url": "http://arxiv.org/abs/2203.03059v1", "pdf_url": "http://arxiv.org/pdf/2203.03059v1", "repo_url": "https://github.com/lisha-chen/Bayesian-MAML-vs-MAML"}, "2203.02711": {"publish_time": "2022-03-05", "title": "Meta Mirror Descent: Optimiser Learning for Fast Convergence", "author": "Boyan Gao et.al.", "abstract": "Optimisers are an essential component for training machine learning models, and their design influences learning speed and generalisation. Several studies have attempted to learn more effective gradient-descent optimisers via solving a bi-level optimisation problem where generalisation error is minimised with respect to optimiser parameters. However, most existing optimiser learning methods are intuitively motivated, without clear theoretical support. We take a different perspective starting from mirror descent rather than gradient descent, and meta-learning the corresponding Bregman divergence. Within this paradigm, we formalise a novel meta-learning objective of minimising the regret bound of learning. The resulting framework, termed Meta Mirror Descent (MetaMD), learns to accelerate optimisation speed. Unlike many meta-learned optimisers, it also supports convergence and generalisation guarantees and uniquely does so without requiring validation data. We evaluate our framework on a variety of tasks and architectures in terms of convergence rate and generalisation error and demonstrate strong performance.", "paper_url": "http://arxiv.org/abs/2203.02711v1", "pdf_url": "http://arxiv.org/pdf/2203.02711v1", "repo_url": null}, "2203.03978": {"publish_time": "2022-03-08", "title": "Contrastive Conditional Neural Processes", "author": "Zesheng Ye et.al.", "abstract": "Conditional Neural Processes~(CNPs) bridge neural networks with probabilistic inference to approximate functions of Stochastic Processes under meta-learning settings. Given a batch of non-{\\it i.i.d} function instantiations, CNPs are jointly optimized for in-instantiation observation prediction and cross-instantiation meta-representation adaptation within a generative reconstruction pipeline. There can be a challenge in tying together such two targets when the distribution of function observations scales to high-dimensional and noisy spaces. Instead, noise contrastive estimation might be able to provide more robust representations by learning distributional matching objectives to combat such inherent limitation of generative models. In light of this, we propose to equip CNPs by 1) aligning prediction with encoded ground-truth observation, and 2) decoupling meta-representation adaptation from generative reconstruction. Specifically, two auxiliary contrastive branches are set up hierarchically, namely in-instantiation temporal contrastive learning~({\\tt TCL}) and cross-instantiation function contrastive learning~({\\tt FCL}), to facilitate local predictive alignment and global function consistency, respectively. We empirically show that {\\tt TCL} captures high-level abstraction of observations, whereas {\\tt FCL} helps identify underlying functions, which in turn provides more efficient representations. Our model outperforms other CNPs variants when evaluating function distribution reconstruction and parameter identification across 1D, 2D and high-dimensional time-series.", "paper_url": "http://arxiv.org/abs/2203.03978v1", "pdf_url": "http://arxiv.org/pdf/2203.03978v1", "repo_url": null}, "2203.04905": {"publish_time": "2022-03-09", "title": "What Matters For Meta-Learning Vision Regression Tasks?", "author": "Ning Gao et.al.", "abstract": "Meta-learning is widely used in few-shot classification and function regression due to its ability to quickly adapt to unseen tasks. However, it has not yet been well explored on regression tasks with high dimensional inputs such as images. This paper makes two main contributions that help understand this barely explored area. \\emph{First}, we design two new types of cross-category level vision regression tasks, namely object discovery and pose estimation of unprecedented complexity in the meta-learning domain for computer vision. To this end, we (i) exhaustively evaluate common meta-learning techniques on these tasks, and (ii) quantitatively analyze the effect of various deep learning techniques commonly used in recent meta-learning algorithms in order to strengthen the generalization capability: data augmentation, domain randomization, task augmentation and meta-regularization. Finally, we (iii) provide some insights and practical recommendations for training meta-learning algorithms on vision regression tasks. \\emph{Second}, we propose the addition of functional contrastive learning (FCL) over the task representations in Conditional Neural Processes (CNPs) and train in an end-to-end fashion. The experimental results show that the results of prior work are misleading as a consequence of a poor choice of the loss function as well as too small meta-training sets. Specifically, we find that CNPs outperform MAML on most tasks without fine-tuning. Furthermore, we observe that naive task augmentation without a tailored design results in underfitting.", "paper_url": "http://arxiv.org/abs/2203.04905v1", "pdf_url": "http://arxiv.org/pdf/2203.04905v1", "repo_url": null}, "2203.04904": {"publish_time": "2022-03-09", "title": "Model-Agnostic Multitask Fine-tuning for Few-shot Vision-Language Transfer Learning", "author": "Zhenhailong Wang et.al.", "abstract": "Despite achieving state-of-the-art zero-shot performance, existing vision-language models, e.g., CLIP, still fall short of domain-specific classification tasks, e.g., Fungi Classification. In the context of few-shot transfer learning, traditional fine-tuning fails to prevent highly expressive model from exploiting spurious correlations in the training data. On the other hand, although model-agnostic meta-learning (MAML) presents as a natural alternative for transfer learning, the expensive computation due to implicit second-order optimization limits its use in large-scale models and datasets. In this work we aim to further improve the generalization of existing vision-language models on unseen tasks via a simple yet efficient fine-tuning strategy based on uniform task sampling. We term our method as Model-Agnostic Multitask Fine-tuning (MAMF). Compared with MAML, MAMF discards the bi-level optimization and uses only first-order gradients, which makes it easily scalable and computationally efficient. Due to the uniform task sampling procedure, MAMF consistently outperforms the classical fine-tuning method for few-shot transfer learning on five benchmark datasets. Empirically, we further discover that the effectiveness of first-order MAML is highly dependent on the zero-shot performance of the pretrained model, and our simple algorithm can outperform first-order MAML on more challenging datasets with low zero-shot performance.", "paper_url": "http://arxiv.org/abs/2203.04904v1", "pdf_url": "http://arxiv.org/pdf/2203.04904v1", "repo_url": null}, "2203.04540": {"publish_time": "2022-03-09", "title": "MetaCon: Unified Predictive Segments System with Trillion Concept Meta-Learning", "author": "Keqian Li et.al.", "abstract": "Accurate understanding of users in terms of predicative segments play an essential role in the day to day operation of modern internet enterprises. Nevertheless, there are significant challenges that limit the quality of data, especially on long tail predictive tasks. In this work, we present MetaCon, our unified predicative segments system with scalable, trillion concepts meta learning that addresses these challenges. It builds on top of a flat concept representation that summarizes entities' heterogeneous digital footprint, jointly considers the entire spectrum of predicative tasks as a single learning task, and leverages principled meta learning approach with efficient first order meta-optimization procedure under a provable performance guarantee in order to solve the learning task. Experiments on both proprietary production datasets and public structured learning tasks demonstrate that MetaCon can lead to substantial improvements over state of the art recommendation and ranking approaches.", "paper_url": "http://arxiv.org/abs/2203.04540v1", "pdf_url": "http://arxiv.org/pdf/2203.04540v1", "repo_url": null}, "2203.04291": {"publish_time": "2022-03-07", "title": "Learning from Few Examples: A Summary of Approaches to Few-Shot Learning", "author": "Archit Parnami et.al.", "abstract": "Few-Shot Learning refers to the problem of learning the underlying pattern in the data just from a few training samples. Requiring a large number of data samples, many deep learning solutions suffer from data hunger and extensively high computation time and resources. Furthermore, data is often not available due to not only the nature of the problem or privacy concerns but also the cost of data preparation. Data collection, preprocessing, and labeling are strenuous human tasks. Therefore, few-shot learning that could drastically reduce the turnaround time of building machine learning applications emerges as a low-cost solution. This survey paper comprises a representative list of recently proposed few-shot learning algorithms. Given the learning dynamics and characteristics, the approaches to few-shot learning problems are discussed in the perspectives of meta-learning, transfer learning, and hybrid approaches (i.e., different variations of the few-shot learning problem).", "paper_url": "http://arxiv.org/abs/2203.04291v1", "pdf_url": "http://arxiv.org/pdf/2203.04291v1", "repo_url": null}, "2203.05119": {"publish_time": "2022-03-10", "title": "MetAug: Contrastive Learning via Meta Feature Augmentation", "author": "Jiangmeng Li et.al.", "abstract": "What matters for contrastive learning? We argue that contrastive learning heavily relies on informative features, or \"hard\" (positive or negative) features. Early works include more informative features by applying complex data augmentations and large batch size or memory bank, and recent works design elaborate sampling approaches to explore informative features. The key challenge toward exploring such features is that the source multi-view data is generated by applying random data augmentations, making it infeasible to always add useful information in the augmented data. Consequently, the informativeness of features learned from such augmented data is limited. In response, we propose to directly augment the features in latent space, thereby learning discriminative representations without a large amount of input data. We perform a meta learning technique to build the augmentation generator that updates its network parameters by considering the performance of the encoder. However, insufficient input data may lead the encoder to learn collapsed features and therefore malfunction the augmentation generator. A new margin-injected regularization is further added in the objective function to avoid the encoder learning a degenerate mapping. To contrast all features in one gradient back-propagation step, we adopt the proposed optimization-driven unified contrastive loss instead of the conventional contrastive loss. Empirically, our method achieves state-of-the-art results on several benchmark datasets.", "paper_url": "http://arxiv.org/abs/2203.05119v1", "pdf_url": "http://arxiv.org/pdf/2203.05119v1", "repo_url": null}, "2203.05882": {"publish_time": "2022-03-11", "title": "Improving the transferability of speech separation by meta-learning", "author": "Kuan-Po Huang et.al.", "abstract": "Speech separation aims to separate multiple speech sources from a speech mixture. Although speech separation is well-solved on some existing English speech separation benchmarks, it is worthy of more investigation on the generalizability of speech separation models on the accents or languages unseen during training. This paper adopts meta-learning based methods to improve the transferability of speech separation models. With the meta-learning based methods, we discovered that only using speech data with one accent, the native English accent, as our training data, the models still can be adapted to new unseen accents on the Speech Accent Archive. We compared the results with a human-rated native-likeness of accents, showing that the transferability of MAML methods has less relation to the similarity of data between the training and testing phase compared to the typical transfer learning methods. Furthermore, we found that models can deal with different language data from the CommonVoice corpus during the testing phase. Most of all, the MAML methods outperform typical transfer learning methods when it comes to new accents, new speakers, new languages, and noisy environments.", "paper_url": "http://arxiv.org/abs/2203.05882v1", "pdf_url": "http://arxiv.org/pdf/2203.05882v1", "repo_url": "https://github.com/nobel861017/mtss"}, "2203.07725": {"publish_time": "2022-03-15", "title": "Meta Ordinal Regression Forest for Medical Image Classification with Ordinal Labels", "author": "Yiming Lei et.al.", "abstract": "The performance of medical image classification has been enhanced by deep convolutional neural networks (CNNs), which are typically trained with cross-entropy (CE) loss. However, when the label presents an intrinsic ordinal property in nature, e.g., the development from benign to malignant tumor, CE loss cannot take into account such ordinal information to allow for better generalization. To improve model generalization with ordinal information, we propose a novel meta ordinal regression forest (MORF) method for medical image classification with ordinal labels, which learns the ordinal relationship through the combination of convolutional neural network and differential forest in a meta-learning framework. The merits of the proposed MORF come from the following two components: a tree-wise weighting net (TWW-Net) and a grouped feature selection (GFS) module. First, the TWW-Net assigns each tree in the forest with a specific weight that is mapped from the classification loss of the corresponding tree. Hence, all the trees possess varying weights, which is helpful for alleviating the tree-wise prediction variance. Second, the GFS module enables a dynamic forest rather than a fixed one that was previously used, allowing for random feature perturbation. During training, we alternatively optimize the parameters of the CNN backbone and TWW-Net in the meta-learning framework through calculating the Hessian matrix. Experimental results on two medical image classification datasets with ordinal labels, i.e., LIDC-IDRI and Breast Ultrasound Dataset, demonstrate the superior performances of our MORF method over existing state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2203.07725v1", "pdf_url": "http://arxiv.org/pdf/2203.07725v1", "repo_url": null}, "2203.07615": {"publish_time": "2022-03-15", "title": "Learning What Not to Segment: A New Perspective on Few-Shot Segmentation", "author": "Chunbo Lang et.al.", "abstract": "Recently few-shot segmentation (FSS) has been extensively developed. Most previous works strive to achieve generalization through the meta-learning framework derived from classification tasks; however, the trained models are biased towards the seen classes instead of being ideally class-agnostic, thus hindering the recognition of new concepts. This paper proposes a fresh and straightforward insight to alleviate the problem. Specifically, we apply an additional branch (base learner) to the conventional FSS model (meta learner) to explicitly identify the targets of base classes, i.e., the regions that do not need to be segmented. Then, the coarse results output by these two learners in parallel are adaptively integrated to yield precise segmentation prediction. Considering the sensitivity of meta learner, we further introduce an adjustment factor to estimate the scene differences between the input image pairs for facilitating the model ensemble forecasting. The substantial performance gains on PASCAL-5i and COCO-20i verify the effectiveness, and surprisingly, our versatile scheme sets a new state-of-the-art even with two plain learners. Moreover, in light of the unique nature of the proposed approach, we also extend it to a more realistic but challenging setting, i.e., generalized FSS, where the pixels of both base and novel classes are required to be determined. The source code is available at github.com/chunbolang/BAM.", "paper_url": "http://arxiv.org/abs/2203.07615v1", "pdf_url": "http://arxiv.org/pdf/2203.07615v1", "repo_url": "https://github.com/chunbolang/BAM"}, "2203.07910": {"publish_time": "2022-03-14", "title": "Deep Transfer Learning with Graph Neural Network for Sensor-Based Human Activity Recognition", "author": "Yan Yan et.al.", "abstract": "The sensor-based human activity recognition (HAR) in mobile application scenarios is often confronted with sensor modalities variation and annotated data deficiency. Given this observation, we devised a graph-inspired deep learning approach toward the sensor-based HAR tasks, which was further used to build a deep transfer learning model toward giving a tentative solution for these two challenging problems. Specifically, we present a multi-layer residual structure involved graph convolutional neural network (ResGCNN) toward the sensor-based HAR tasks, namely the HAR-ResGCNN approach. Experimental results on the PAMAP2 and mHealth data sets demonstrate that our ResGCNN is effective at capturing the characteristics of actions with comparable results compared to other sensor-based HAR models (with an average accuracy of 98.18% and 99.07%, respectively). More importantly, the deep transfer learning experiments using the ResGCNN model show excellent transferability and few-shot learning performance. The graph-based framework shows good meta-learning ability and is supposed to be a promising solution in sensor-based HAR tasks.", "paper_url": "http://arxiv.org/abs/2203.07910v1", "pdf_url": "http://arxiv.org/pdf/2203.07910v1", "repo_url": null}, "2203.08775": {"publish_time": "2022-03-16", "title": "Practical Conditional Neural Processes Via Tractable Dependent Predictions", "author": "Stratis Markou et.al.", "abstract": "Conditional Neural Processes (CNPs; Garnelo et al., 2018a) are meta-learning models which leverage the flexibility of deep learning to produce well-calibrated predictions and naturally handle off-the-grid and missing data. CNPs scale to large datasets and train with ease. Due to these features, CNPs appear well-suited to tasks from environmental sciences or healthcare. Unfortunately, CNPs do not produce correlated predictions, making them fundamentally inappropriate for many estimation and decision making tasks. Predicting heat waves or floods, for example, requires modelling dependencies in temperature or precipitation over time and space. Existing approaches which model output dependencies, such as Neural Processes (NPs; Garnelo et al., 2018b) or the FullConvGNP (Bruinsma et al., 2021), are either complicated to train or prohibitively expensive. What is needed is an approach which provides dependent predictions, but is simple to train and computationally tractable. In this work, we present a new class of Neural Process models that make correlated predictions and support exact maximum likelihood training that is simple and scalable. We extend the proposed models by using invertible output transformations, to capture non-Gaussian output distributions. Our models can be used in downstream estimation tasks which require dependent function samples. By accounting for output dependencies, our models show improved predictive performance on a range of experiments with synthetic and real data.", "paper_url": "http://arxiv.org/abs/2203.08775v1", "pdf_url": "http://arxiv.org/pdf/2203.08775v1", "repo_url": null}, "2203.09137": {"publish_time": "2022-03-17", "title": "Global Convergence of MAML and Theory-Inspired Neural Architecture Search for Few-Shot Learning", "author": "Haoxiang Wang et.al.", "abstract": "Model-agnostic meta-learning (MAML) and its variants have become popular approaches for few-shot learning. However, due to the non-convexity of deep neural nets (DNNs) and the bi-level formulation of MAML, the theoretical properties of MAML with DNNs remain largely unknown. In this paper, we first prove that MAML with over-parameterized DNNs is guaranteed to converge to global optima at a linear rate. Our convergence analysis indicates that MAML with over-parameterized DNNs is equivalent to kernel regression with a novel class of kernels, which we name as Meta Neural Tangent Kernels (MetaNTK). Then, we propose MetaNTK-NAS, a new training-free neural architecture search (NAS) method for few-shot learning that uses MetaNTK to rank and select architectures. Empirically, we compare our MetaNTK-NAS with previous NAS methods on two popular few-shot learning benchmarks, miniImageNet, and tieredImageNet. We show that the performance of MetaNTK-NAS is comparable or better than the state-of-the-art NAS method designed for few-shot learning while enjoying more than 100x speedup. We believe the efficiency of MetaNTK-NAS makes itself more practical for many real-world tasks.", "paper_url": "http://arxiv.org/abs/2203.09137v1", "pdf_url": "http://arxiv.org/pdf/2203.09137v1", "repo_url": "https://github.com/yitewang/metantk-nas"}, "2203.08951": {"publish_time": "2022-03-16", "title": "Meta-Learning of NAS for Few-shot Learning in Medical Image Applications", "author": "Viet-Khoa Vo-Ho et.al.", "abstract": "Deep learning methods have been successful in solving tasks in machine learning and have made breakthroughs in many sectors owing to their ability to automatically extract features from unstructured data. However, their performance relies on manual trial-and-error processes for selecting an appropriate network architecture, hyperparameters for training, and pre-/post-procedures. Even though it has been shown that network architecture plays a critical role in learning feature representation feature from data and the final performance, searching for the best network architecture is computationally intensive and heavily relies on researchers' experience. Automated machine learning (AutoML) and its advanced techniques i.e. Neural Architecture Search (NAS) have been promoted to address those limitations. Not only in general computer vision tasks, but NAS has also motivated various applications in multiple areas including medical imaging. In medical imaging, NAS has significant progress in improving the accuracy of image classification, segmentation, reconstruction, and more. However, NAS requires the availability of large annotated data, considerable computation resources, and pre-defined tasks. To address such limitations, meta-learning has been adopted in the scenarios of few-shot learning and multiple tasks. In this book chapter, we first present a brief review of NAS by discussing well-known approaches in search space, search strategy, and evaluation strategy. We then introduce various NAS approaches in medical imaging with different applications such as classification, segmentation, detection, reconstruction, etc. Meta-learning in NAS for few-shot learning and multiple tasks is then explained. Finally, we describe several open problems in NAS.", "paper_url": "http://arxiv.org/abs/2203.08951v1", "pdf_url": "http://arxiv.org/pdf/2203.08951v1", "repo_url": null}, "2203.09661": {"publish_time": "2022-03-17", "title": "Meta Reinforcement Learning for Adaptive Control: An Offline Approach", "author": "Daniel G. McClement et.al.", "abstract": "Meta-learning is a branch of machine learning which trains neural network models to synthesize a wide variety of data in order to rapidly solve new problems. In process control, many systems have similar and well-understood dynamics, which suggests it is feasible to create a generalizable controller through meta-learning. In this work, we formulate a meta reinforcement learning (meta-RL) control strategy that takes advantage of known, offline information for training, such as the system gain or time constant, yet efficiently controls novel systems in a completely model-free fashion. Our meta-RL agent has a recurrent structure that accumulates \"context\" for its current dynamics through a hidden state variable. This end-to-end architecture enables the agent to automatically adapt to changes in the process dynamics. Moreover, the same agent can be deployed on systems with previously unseen nonlinearities and timescales. In tests reported here, the meta-RL agent was trained entirely offline, yet produced excellent results in novel settings. A key design element is the ability to leverage model-based information offline during training, while maintaining a model-free policy structure for interacting with novel environments. To illustrate the approach, we take the actions proposed by the meta-RL agent to be changes to gains of a proportional-integral controller, resulting in a generalized, adaptive, closed-loop tuning strategy. Meta-learning is a promising approach for constructing sample-efficient intelligent controllers.", "paper_url": "http://arxiv.org/abs/2203.09661v1", "pdf_url": "http://arxiv.org/pdf/2203.09661v1", "repo_url": null}, "2203.11074": {"publish_time": "2022-03-21", "title": "Distributed Stochastic Compositional Optimization Problems over Directed Networks", "author": "Shengchao Zhao et.al.", "abstract": "We study the distributed stochastic compositional optimization problems over directed communication networks in which agents privately own a stochastic compositional objective function and collaborate to minimize the sum of all objective functions. We propose a distributed stochastic compositional gradient descent method, where the gradient tracking and the stochastic correction techniques are employed to adapt to the networks' directed structure and increase the accuracy of inner function estimation. When the objective function is smooth, the proposed method achieves the convergence rate $\\mathcal{O}\\left(k^{-1/2}\\right)$ and sample complexity $\\mathcal{O}\\left(\\frac{1}{\\epsilon^2}\\right)$ for finding the ($\\epsilon$)-stationary point. When the objective function is strongly convex, the convergence rate is improved to $\\mathcal{O}\\left(k^{-1}\\right)$. Moreover, the asymptotic normality of Polyak-Ruppert averaged iterates of the proposed method is also presented. We demonstrate the empirical performance of the proposed method on model-agnostic meta-learning problem and logistic regression problem.", "paper_url": "http://arxiv.org/abs/2203.11074v1", "pdf_url": "http://arxiv.org/pdf/2203.11074v1", "repo_url": null}, "2203.10395": {"publish_time": "2022-03-19", "title": "Towards Robust Semantic Segmentation of Accident Scenes via Multi-Source Mixed Sampling and Meta-Learning", "author": "Xinyu Luo et.al.", "abstract": "Autonomous vehicles utilize urban scene segmentation to understand the real world like a human and react accordingly. Semantic segmentation of normal scenes has experienced a remarkable rise in accuracy on conventional benchmarks. However, a significant portion of real-life accidents features abnormal scenes, such as those with object deformations, overturns, and unexpected traffic behaviors. Since even small mis-segmentation of driving scenes can lead to serious threats to human lives, the robustness of such models in accident scenarios is an extremely important factor in ensuring safety of intelligent transportation systems.   In this paper, we propose a Multi-source Meta-learning Unsupervised Domain Adaptation (MMUDA) framework, to improve the generalization of segmentation transformers to extreme accident scenes. In MMUDA, we make use of Multi-Domain Mixed Sampling to augment the images of multiple-source domains (normal scenes) with the target data appearances (abnormal scenes). To train our model, we intertwine and study a meta-learning strategy in the multi-source setting for robustifying the segmentation results. We further enhance the segmentation backbone (SegFormer) with a HybridASPP decoder design, featuring large window attention spatial pyramid pooling and strip pooling, to efficiently aggregate long-range contextual dependencies. Our approach achieves a mIoU score of 46.97% on the DADA-seg benchmark, surpassing the previous state-of-the-art model by more than 7.50%. Code will be made publicly available at https://github.com/xinyu-laura/MMUDA.", "paper_url": "http://arxiv.org/abs/2203.10395v1", "pdf_url": "http://arxiv.org/pdf/2203.10395v1", "repo_url": "https://github.com/xinyu-laura/mmuda"}, "2203.10354": {"publish_time": "2022-03-19", "title": "Meta-Learning for Online Update of Recommender Systems", "author": "Minseok Kim et.al.", "abstract": "Online recommender systems should be always aligned with users' current interest to accurately suggest items that each user would like. Since user interest usually evolves over time, the update strategy should be flexible to quickly catch users' current interest from continuously generated new user-item interactions. Existing update strategies focus either on the importance of each user-item interaction or the learning rate for each recommender parameter, but such one-directional flexibility is insufficient to adapt to varying relationships between interactions and parameters. In this paper, we propose MeLON, a meta-learning based novel online recommender update strategy that supports two-directional flexibility. It is featured with an adaptive learning rate for each parameter-interaction pair for inducing a recommender to quickly learn users' up-to-date interest. The procedure of MeLON is optimized following a meta-learning approach: it learns how a recommender learns to generate the optimal learning rates for future updates. Specifically, MeLON first enriches the meaning of each interaction based on previous interactions and identifies the role of each parameter for the interaction; and then combines these two pieces of information to generate an adaptive learning rate. Theoretical analysis and extensive evaluation on three real-world online recommender datasets validate the effectiveness of MeLON.", "paper_url": "http://arxiv.org/abs/2203.10354v1", "pdf_url": "http://arxiv.org/pdf/2203.10354v1", "repo_url": "https://github.com/kaist-dmlab/MeLON"}, "2203.10250": {"publish_time": "2022-03-19", "title": "Meta-X$_{NLG}$: A Meta-Learning Approach Based on Language Clustering for Zero-Shot Cross-Lingual Transfer and Generation", "author": "Kaushal Kumar Maurya et.al.", "abstract": "Recently, the NLP community has witnessed a rapid advancement in multilingual and cross-lingual transfer research where the supervision is transferred from high-resource languages (HRLs) to low-resource languages (LRLs). However, the cross-lingual transfer is not uniform across languages, particularly in the zero-shot setting. Towards this goal, one promising research direction is to learn shareable structures across multiple tasks with limited annotated data. The downstream multilingual applications may benefit from such a learning setup as most of the languages across the globe are low-resource and share some structures with other languages. In this paper, we propose a novel meta-learning framework (called Meta-X$_{NLG}$) to learn shareable structures from typologically diverse languages based on meta-learning and language clustering. This is a step towards uniform cross-lingual transfer for unseen languages. We first cluster the languages based on language representations and identify the centroid language of each cluster. Then, a meta-learning algorithm is trained with all centroid languages and evaluated on the other languages in the zero-shot setting. We demonstrate the effectiveness of this modeling on two NLG tasks (Abstractive Text Summarization and Question Generation), 5 popular datasets and 30 typologically diverse languages. Consistent improvements over strong baselines demonstrate the efficacy of the proposed framework. The careful design of the model makes this end-to-end NLG setup less vulnerable to the accidental translation problem, which is a prominent concern in zero-shot cross-lingual NLG tasks.", "paper_url": "http://arxiv.org/abs/2203.10250v1", "pdf_url": "http://arxiv.org/pdf/2203.10250v1", "repo_url": null}, "2203.10185": {"publish_time": "2022-03-18", "title": "Negative Inner-Loop Learning Rates Learn Universal Features", "author": "Tom Starshak et.al.", "abstract": "Model Agnostic Meta-Learning (MAML) consists of two optimization loops: the outer loop learns a meta-initialization of model parameters that is shared across tasks, and the inner loop task-specific adaptation step. A variant of MAML, Meta-SGD, uses the same two loop structure, but also learns the learning-rate for the adaptation step. Little attention has been paid to how the learned learning-rate of Meta-SGD affects feature reuse. In this paper, we study the effect that a learned learning-rate has on the per-task feature representations in Meta-SGD. The learned learning-rate of Meta-SGD often contains negative values. During the adaptation phase, these negative learning rates push features away from task-specific features and towards task-agnostic features.   We performed several experiments on the Mini-Imagenet dataset. Two neural networks were trained, one with MAML, and one with Meta-SGD. The feature quality for both models was tested as follows: strip away the linear classification layer, pass labeled and unlabeled samples through this encoder, classify the unlabeled samples according to their nearest neighbor. This process was performed: 1) after training and using the meta-initialization parameters; 2) after adaptation, and validated on that task; and 3) after adaptation, and validated on a different task. The MAML trained model improved on the task it was adapted to, but had worse performance on other tasks. The Meta-SGD trained model was the opposite; it had worse performance on the task it was adapted to, but improved on other tasks. This confirms the hypothesis that Meta-SGD's negative learning rates cause the model to learn task-agnostic features rather than simply adapt to task specific features.", "paper_url": "http://arxiv.org/abs/2203.10185v1", "pdf_url": "http://arxiv.org/pdf/2203.10185v1", "repo_url": null}, "2203.11670": {"publish_time": "2022-03-22", "title": "Improving Meta-learning for Low-resource Text Classification and Generation via Memory Imitation", "author": "Yingxiu Zhao et.al.", "abstract": "Building models of natural language processing (NLP) is challenging in low-resource scenarios where only limited data are available. Optimization-based meta-learning algorithms achieve promising results in low-resource scenarios by adapting a well-generalized model initialization to handle new tasks. Nonetheless, these approaches suffer from the memorization overfitting issue, where the model tends to memorize the meta-training tasks while ignoring support sets when adapting to new tasks. To address this issue, we propose a memory imitation meta-learning (MemIML) method that enhances the model's reliance on support sets for task adaptation. Specifically, we introduce a task-specific memory module to store support set information and construct an imitation module to force query sets to imitate the behaviors of some representative support-set samples stored in the memory. A theoretical analysis is provided to prove the effectiveness of our method, and empirical results also demonstrate that our method outperforms competitive baselines on both text classification and generation tasks.", "paper_url": "http://arxiv.org/abs/2203.11670v1", "pdf_url": "http://arxiv.org/pdf/2203.11670v1", "repo_url": null}, "2203.12304": {"publish_time": "2022-03-23", "title": "Domain-Generalized Textured Surface Anomaly Detection", "author": "Shang-Fu Chen et.al.", "abstract": "Anomaly detection aims to identify abnormal data that deviates from the normal ones, while typically requiring a sufficient amount of normal data to train the model for performing this task. Despite the success of recent anomaly detection methods, performing anomaly detection in an unseen domain remain a challenging task. In this paper, we address the task of domain-generalized textured surface anomaly detection. By observing normal and abnormal surface data across multiple source domains, our model is expected to be generalized to an unseen textured surface of interest, in which only a small number of normal data can be observed during testing. Although with only image-level labels observed in the training data, our patch-based meta-learning model exhibits promising generalization ability: not only can it generalize to unseen image domains, but it can also localize abnormal regions in the query image. Our experiments verify that our model performs favorably against state-of-the-art anomaly detection and domain generalization approaches in various settings.", "paper_url": "http://arxiv.org/abs/2203.12304v1", "pdf_url": "http://arxiv.org/pdf/2203.12304v1", "repo_url": null}, "2203.12274": {"publish_time": "2022-03-23", "title": "Pre-training to Match for Unified Low-shot Relation Extraction", "author": "Fangchao Liu et.al.", "abstract": "Low-shot relation extraction~(RE) aims to recognize novel relations with very few or even no samples, which is critical in real scenario application. Few-shot and zero-shot RE are two representative low-shot RE tasks, which seem to be with similar target but require totally different underlying abilities. In this paper, we propose Multi-Choice Matching Networks to unify low-shot relation extraction. To fill in the gap between zero-shot and few-shot RE, we propose the triplet-paraphrase meta-training, which leverages triplet paraphrase to pre-train zero-shot label matching ability and uses meta-learning paradigm to learn few-shot instance summarizing ability. Experimental results on three different low-shot RE tasks show that the proposed method outperforms strong baselines by a large margin, and achieve the best performance on few-shot RE leaderboard.", "paper_url": "http://arxiv.org/abs/2203.12274v1", "pdf_url": "http://arxiv.org/pdf/2203.12274v1", "repo_url": "https://github.com/fc-liu/mcmn"}, "2203.12768": {"publish_time": "2022-03-23", "title": "Multidimensional Belief Quantification for Label-Efficient Meta-Learning", "author": "Deep Pandey et.al.", "abstract": "Optimization-based meta-learning offers a promising direction for few-shot learning that is essential for many real-world computer vision applications. However, learning from few samples introduces uncertainty, and quantifying model confidence for few-shot predictions is essential for many critical domains. Furthermore, few-shot tasks used in meta training are usually sampled randomly from a task distribution for an iterative model update, leading to high labeling costs and computational overhead in meta-training. We propose a novel uncertainty-aware task selection model for label efficient meta-learning. The proposed model formulates a multidimensional belief measure, which can quantify the known uncertainty and lower bound the unknown uncertainty of any given task. Our theoretical result establishes an important relationship between the conflicting belief and the incorrect belief. The theoretical result allows us to estimate the total uncertainty of a task, which provides a principled criterion for task selection. A novel multi-query task formulation is further developed to improve both the computational and labeling efficiency of meta-learning. Experiments conducted over multiple real-world few-shot image classification tasks demonstrate the effectiveness of the proposed model.", "paper_url": "http://arxiv.org/abs/2203.12768v1", "pdf_url": "http://arxiv.org/pdf/2203.12768v1", "repo_url": null}, "2203.12715": {"publish_time": "2022-03-23", "title": "Predicting Multi-Antenna Frequency-Selective Channels via Meta-Learned Linear Filters based on Long-Short Term Channel Decomposition", "author": "Sangwoo Park et.al.", "abstract": "An efficient data-driven prediction strategy for multi-antenna frequency-selective channels must operate based on a small number of pilot symbols. This paper proposes novel channel prediction algorithms that address this goal by integrating transfer and meta-learning with a reduced-rank parametrization of the channel. The proposed methods optimize linear predictors by utilizing data from previous frames, which are generally characterized by distinct propagation characteristics, in order to enable fast training on the time slots of the current frame. The proposed predictors rely on a novel long-short-term decomposition (LSTD) of the linear prediction model that leverages the disaggregation of the channel into long-term space-time signatures and fading amplitudes. We first develop predictors for single-antenna frequency-flat channels based on transfer/meta-learned quadratic regularization. Then, we introduce transfer and meta-learning algorithms for LSTD-based prediction models that build on equilibrium propagation (EP) and alternating least squares (ALS). Numerical results under the 3GPP 5G standard channel model demonstrate the impact of transfer and meta-learning on reducing the number of pilots for channel prediction, as well as the merits of the proposed LSTD parametrization.", "paper_url": "http://arxiv.org/abs/2203.12715v1", "pdf_url": "http://arxiv.org/pdf/2203.12715v1", "repo_url": null}, "2203.12653": {"publish_time": "2022-03-23", "title": "Iterative Implicit Gradients for Nonconvex Optimization with Variational Inequality Constraints", "author": "Harshal D. Kaushik et.al.", "abstract": "We propose an implicit gradient based scheme for a constrained optimization problem with nonconvex loss function, which can be potentially used to analyze a variety of applications in machine learning, including meta-learning, hyperparameter optimization, and reinforcement learning. The proposed algorithm is based on the iterative differentiation (ITD) strategy. We extend the convergence and rate analysis of the current literature of bilevel optimization to a constrained bilevel structure with the motivation of learning under constraints. For addressing bilevel optimization using any first-order scheme, it involves the gradient of the inner-level optimal solution with respect to the outer variable (implicit gradient). In this paper, taking into account of a possible large-scale structure, we propose an efficient way of obtaining the implicit gradient. We further provide error bounds with respect to the true gradients. Further, we provide nonasymptotic rate results.", "paper_url": "http://arxiv.org/abs/2203.12653v1", "pdf_url": "http://arxiv.org/pdf/2203.12653v1", "repo_url": null}, "2203.13610": {"publish_time": "2022-03-25", "title": "Learning to Adapt to Unseen Abnormal Activities under Weak Supervision", "author": "Jaeyoo Park et.al.", "abstract": "We present a meta-learning framework for weakly supervised anomaly detection in videos, where the detector learns to adapt to unseen types of abnormal activities effectively when only video-level annotations of binary labels are available. Our work is motivated by the fact that existing methods suffer from poor generalization to diverse unseen examples. We claim that an anomaly detector equipped with a meta-learning scheme alleviates the limitation by leading the model to an initialization point for better optimization. We evaluate the performance of our framework on two challenging datasets, UCF-Crime and ShanghaiTech. The experimental results demonstrate that our algorithm boosts the capability to localize unseen abnormal events in a weakly supervised setting. Besides the technical contributions, we perform the annotation of missing labels in the UCF-Crime dataset and make our task evaluated effectively.", "paper_url": "http://arxiv.org/abs/2203.13610v1", "pdf_url": "http://arxiv.org/pdf/2203.13610v1", "repo_url": null}, "2203.13465": {"publish_time": "2022-03-25", "title": "CAD: Co-Adapting Discriminative Features for Improved Few-Shot Classification", "author": "Philip Chikontwe et.al.", "abstract": "Few-shot classification is a challenging problem that aims to learn a model that can adapt to unseen classes given a few labeled samples. Recent approaches pre-train a feature extractor, and then fine-tune for episodic meta-learning. Other methods leverage spatial features to learn pixel-level correspondence while jointly training a classifier. However, results using such approaches show marginal improvements. In this paper, inspired by the transformer style self-attention mechanism, we propose a strategy to cross-attend and re-weight discriminative features for few-shot classification. Given a base representation of support and query images after global pooling, we introduce a single shared module that projects features and cross-attends in two aspects: (i) query to support, and (ii) support to query. The module computes attention scores between features to produce an attention pooled representation of features in the same class that is later added to the original representation followed by a projection head. This effectively re-weights features in both aspects (i & ii) to produce features that better facilitate improved metric-based meta-learning. Extensive experiments on public benchmarks show our approach outperforms state-of-the-art methods by 3%~5%.", "paper_url": "http://arxiv.org/abs/2203.13465v1", "pdf_url": "http://arxiv.org/pdf/2203.13465v1", "repo_url": null}, "2203.14855": {"publish_time": "2022-03-28", "title": "Modular Adaptive Policy Selection for Multi-Task Imitation Learning through Task Division", "author": "Dafni Antotsiou et.al.", "abstract": "Deep imitation learning requires many expert demonstrations, which can be hard to obtain, especially when many tasks are involved. However, different tasks often share similarities, so learning them jointly can greatly benefit them and alleviate the need for many demonstrations. But, joint multi-task learning often suffers from negative transfer, sharing information that should be task-specific. In this work, we introduce a method to perform multi-task imitation while allowing for task-specific features. This is done by using proto-policies as modules to divide the tasks into simple sub-behaviours that can be shared. The proto-policies operate in parallel and are adaptively chosen by a selector mechanism that is jointly trained with the modules. Experiments on different sets of tasks show that our method improves upon the accuracy of single agents, task-conditioned and multi-headed multi-task agents, as well as state-of-the-art meta learning agents. We also demonstrate its ability to autonomously divide the tasks into both shared and task-specific sub-behaviours.", "paper_url": "http://arxiv.org/abs/2203.14855v1", "pdf_url": "http://arxiv.org/pdf/2203.14855v1", "repo_url": null}, "2203.14840": {"publish_time": "2022-03-28", "title": "A Framework of Meta Functional Learning for Regularising Knowledge Transfer", "author": "Pan Li et.al.", "abstract": "Machine learning classifiers' capability is largely dependent on the scale of available training data and limited by the model overfitting in data-scarce learning tasks. To address this problem, this work proposes a novel framework of Meta Functional Learning (MFL) by meta-learning a generalisable functional model from data-rich tasks whilst simultaneously regularising knowledge transfer to data-scarce tasks. The MFL computes meta-knowledge on functional regularisation generalisable to different learning tasks by which functional training on limited labelled data promotes more discriminative functions to be learned. Based on this framework, we formulate three variants of MFL: MFL with Prototypes (MFL-P) which learns a functional by auxiliary prototypes, Composite MFL (ComMFL) that transfers knowledge from both functional space and representational space, and MFL with Iterative Updates (MFL-IU) which improves knowledge transfer regularisation from MFL by progressively learning the functional regularisation in knowledge transfer. Moreover, we generalise these variants for knowledge transfer regularisation from binary classifiers to multi-class classifiers. Extensive experiments on two few-shot learning scenarios, Few-Shot Learning (FSL) and Cross-Domain Few-Shot Learning (CD-FSL), show that meta functional learning for knowledge transfer regularisation can improve FSL classifiers.", "paper_url": "http://arxiv.org/abs/2203.14840v1", "pdf_url": "http://arxiv.org/pdf/2203.14840v1", "repo_url": null}, "2203.14691": {"publish_time": "2022-03-28", "title": "Sketch3T: Test-Time Training for Zero-Shot SBIR", "author": "Aneeshan Sain et.al.", "abstract": "Zero-shot sketch-based image retrieval typically asks for a trained model to be applied as is to unseen categories. In this paper, we question to argue that this setup by definition is not compatible with the inherent abstract and subjective nature of sketches, i.e., the model might transfer well to new categories, but will not understand sketches existing in different test-time distribution as a result. We thus extend ZS-SBIR asking it to transfer to both categories and sketch distributions. Our key contribution is a test-time training paradigm that can adapt using just one sketch. Since there is no paired photo, we make use of a sketch raster-vector reconstruction module as a self-supervised auxiliary task. To maintain the fidelity of the trained cross-modal joint embedding during test-time update, we design a novel meta-learning based training paradigm to learn a separation between model updates incurred by this auxiliary task from those off the primary objective of discriminative learning. Extensive experiments show our model to outperform state of-the-arts, thanks to the proposed test-time adaption that not only transfers to new categories but also accommodates to new sketching styles.", "paper_url": "http://arxiv.org/abs/2203.14691v1", "pdf_url": "http://arxiv.org/pdf/2203.14691v1", "repo_url": null}, "2203.14607": {"publish_time": "2022-03-28", "title": "Boosting Black-Box Adversarial Attacks with Meta Learning", "author": "Junjie Fu et.al.", "abstract": "Deep neural networks (DNNs) have achieved remarkable success in diverse fields. However, it has been demonstrated that DNNs are very vulnerable to adversarial examples even in black-box settings. A large number of black-box attack methods have been proposed to in the literature. However, those methods usually suffer from low success rates and large query counts, which cannot fully satisfy practical purposes. In this paper, we propose a hybrid attack method which trains meta adversarial perturbations (MAPs) on surrogate models and performs black-box attacks by estimating gradients of the models. Our method uses the meta adversarial perturbation as an initialization and subsequently trains any black-box attack method for several epochs. Furthermore, the MAPs enjoy favorable transferability and universality, in the sense that they can be employed to boost performance of other black-box adversarial attack methods. Extensive experiments demonstrate that our method can not only improve the attack success rates, but also reduces the number of queries compared to other methods.", "paper_url": "http://arxiv.org/abs/2203.14607v1", "pdf_url": "http://arxiv.org/pdf/2203.14607v1", "repo_url": null}, "2203.14565": {"publish_time": "2022-03-28", "title": "Style-Guided Domain Adaptation for Face Presentation Attack Detection", "author": "Young-Eun Kim et.al.", "abstract": "Domain adaptation (DA) or domain generalization (DG) for face presentation attack detection (PAD) has attracted attention recently with its robustness against unseen attack scenarios. Existing DA/DG-based PAD methods, however, have not yet fully explored the domain-specific style information that can provide knowledge regarding attack styles (e.g., materials, background, illumination and resolution). In this paper, we introduce a novel Style-Guided Domain Adaptation (SGDA) framework for inference-time adaptive PAD. Specifically, Style-Selective Normalization (SSN) is proposed to explore the domain-specific style information within the high-order feature statistics. The proposed SSN enables the adaptation of the model to the target domain by reducing the style difference between the target and the source domains. Moreover, we carefully design Style-Aware Meta-Learning (SAML) to boost the adaptation ability, which simulates the inference-time adaptation with style selection process on virtual test domain. In contrast to previous domain adaptation approaches, our method does not require either additional auxiliary models (e.g., domain adaptors) or the unlabeled target domain during training, which makes our method more practical to PAD task. To verify our experiments, we utilize the public datasets: MSU-MFSD, CASIA-FASD, OULU-NPU and Idiap REPLAYATTACK. In most assessments, the result demonstrates a notable gap of performance compared to the conventional DA/DG-based PAD methods.", "paper_url": "http://arxiv.org/abs/2203.14565v1", "pdf_url": "http://arxiv.org/pdf/2203.14565v1", "repo_url": null}, "2203.15674": {"publish_time": "2022-03-29", "title": "Exploring Frequency Adversarial Attacks for Face Forgery Detection", "author": "Shuai Jia et.al.", "abstract": "Various facial manipulation techniques have drawn serious public concerns in morality, security, and privacy. Although existing face forgery classifiers achieve promising performance on detecting fake images, these methods are vulnerable to adversarial examples with injected imperceptible perturbations on the pixels. Meanwhile, many face forgery detectors always utilize the frequency diversity between real and fake faces as a crucial clue. In this paper, instead of injecting adversarial perturbations into the spatial domain, we propose a frequency adversarial attack method against face forgery detectors. Concretely, we apply discrete cosine transform (DCT) on the input images and introduce a fusion module to capture the salient region of adversary in the frequency domain. Compared with existing adversarial attacks (e.g. FGSM, PGD) in the spatial domain, our method is more imperceptible to human observers and does not degrade the visual quality of the original images. Moreover, inspired by the idea of meta-learning, we also propose a hybrid adversarial attack that performs attacks in both the spatial and frequency domains. Extensive experiments indicate that the proposed method fools not only the spatial-based detectors but also the state-of-the-art frequency-based detectors effectively. In addition, the proposed frequency attack enhances the transferability across face forgery detectors as black-box attacks.", "paper_url": "http://arxiv.org/abs/2203.15674v1", "pdf_url": "http://arxiv.org/pdf/2203.15674v1", "repo_url": null}, "2203.15297": {"publish_time": "2022-03-29", "title": "Kernel Modulation: A Parameter-Efficient Method for Training Convolutional Neural Networks", "author": "Yuhuang Hu et.al.", "abstract": "Deep Neural Networks, particularly Convolutional Neural Networks (ConvNets), have achieved incredible success in many vision tasks, but they usually require millions of parameters for good accuracy performance. With increasing applications that use ConvNets, updating hundreds of networks for multiple tasks on an embedded device can be costly in terms of memory, bandwidth, and energy. Approaches to reduce this cost include model compression and parameter-efficient models that adapt a subset of network layers for each new task. This work proposes a novel parameter-efficient kernel modulation (KM) method that adapts all parameters of a base network instead of a subset of layers. KM uses lightweight task-specialized kernel modulators that require only an additional 1.4% of the base network parameters. With multiple tasks, only the task-specialized KM weights are communicated and stored on the end-user device. We applied this method in training ConvNets for Transfer Learning and Meta-Learning scenarios. Our results show that KM delivers up to 9% higher accuracy than other parameter-efficient methods on the Transfer Learning benchmark.", "paper_url": "http://arxiv.org/abs/2203.15297v1", "pdf_url": "http://arxiv.org/pdf/2203.15297v1", "repo_url": null}, "2203.15972": {"publish_time": "2022-03-30", "title": "Higher-Order Generalization Bounds: Learning Deep Probabilistic Programs via PAC-Bayes Objectives", "author": "Jonathan Warrell et.al.", "abstract": "Deep Probabilistic Programming (DPP) allows powerful models based on recursive computation to be learned using efficient deep-learning optimization techniques. Additionally, DPP offers a unified perspective, where inference and learning algorithms are treated on a par with models as stochastic programs. Here, we offer a framework for representing and learning flexible PAC-Bayes bounds as stochastic programs using DPP-based methods. In particular, we show that DPP techniques may be leveraged to derive generalization bounds that draw on the compositionality of DPP representations. In turn, the bounds we introduce offer principled training objectives for higher-order probabilistic programs. We offer a definition of a higher-order generalization bound, which naturally encompasses single- and multi-task generalization perspectives (including transfer- and meta-learning) and a novel class of bound based on a learned measure of model complexity. Further, we show how modified forms of all higher-order bounds can be efficiently optimized as objectives for DPP training, using variational techniques. We test our framework using single- and multi-task generalization settings on synthetic and biological data, showing improved performance and generalization prediction using flexible DPP model representations and learned complexity measures.", "paper_url": "http://arxiv.org/abs/2203.15972v1", "pdf_url": "http://arxiv.org/pdf/2203.15972v1", "repo_url": null}, "2203.15936": {"publish_time": "2022-03-29", "title": "A Simple Yet Effective Pretraining Strategy for Graph Few-shot Learning", "author": "Zhen Tan et.al.", "abstract": "Recently, increasing attention has been devoted to the graph few-shot learning problem, where the target novel classes only contain a few labeled nodes. Among many existing endeavors, episodic meta-learning has become the most prevailing paradigm, and its episodic emulation of the test environment is believed to equip the graph neural network models with adaptability to novel node classes. However, in the image domain, recent results have shown that feature reuse is more likely to be the key of meta-learning to few-shot extrapolation. Based on such observation, in this work, we propose a simple transductive fine-tuning based framework as a new paradigm for graph few-shot learning. In the proposed paradigm, a graph encoder backbone is pretrained with base classes, and a simple linear classifier is fine-tuned by the few labeled samples and is tasked to classify the unlabeled ones. For pretraining, we propose a supervised contrastive learning framework with data augmentation strategies specific for few-shot node classification to improve the extrapolation of a GNN encoder. Finally, extensive experiments conducted on three benchmark datasets demonstrate the superior advantage of our framework over the state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2203.15936v1", "pdf_url": "http://arxiv.org/pdf/2203.15936v1", "repo_url": null}, "2203.16309": {"publish_time": "2022-03-29", "title": "Zero-shot meta-learning for small-scale data from human subjects", "author": "Julie Jiang et.al.", "abstract": "While developments in machine learning led to impressive performance gains on big data, many human subjects data are, in actuality, small and sparsely labeled. Existing methods applied to such data often do not easily generalize to out-of-sample subjects. Instead, models must make predictions on test data that may be drawn from a different distribution, a problem known as \\textit{zero-shot learning}. To address this challenge, we develop an end-to-end framework using a meta-learning approach, which enables the model to rapidly adapt to a new prediction task with limited training data for out-of-sample test data. We use three real-world small-scale human subjects datasets (two randomized control studies and one observational study), for which we predict treatment outcomes for held-out treatment groups. Our model learns the latent treatment effects of each intervention and, by design, can naturally handle multi-task predictions. We show that our model performs the best holistically for each held-out group and especially when the test group is distinctly different from the training group. Our model has implications for improved generalization of small-size human studies to the wider population.", "paper_url": "http://arxiv.org/abs/2203.16309v1", "pdf_url": "http://arxiv.org/pdf/2203.16309v1", "repo_url": null}, "2203.17218": {"publish_time": "2022-03-31", "title": "Improved Relation Networks for End-to-End Speaker Verification and Identification", "author": "Ashutosh Chaubey et.al.", "abstract": "Speaker identification systems in a real-world scenario are tasked to identify a speaker amongst a set of enrolled speakers given just a few samples for each enrolled speaker. This paper demonstrates the effectiveness of meta-learning and relation networks for this use case. We propose improved relation networks for speaker verification and few-shot (unseen) speaker identification. The use of relation networks facilitates joint training of the frontend speaker encoder and the backend model. Inspired by the use of prototypical networks in speaker verification and to increase the discriminability of the speaker embeddings, we train the model to classify samples in the current episode amongst all speakers present in the training set. Furthermore, we propose a new training regime for faster model convergence by extracting more information from a given meta-learning episode with negligible extra computation. We evaluate the proposed techniques on VoxCeleb, SITW and VCTK datasets on the tasks of speaker verification and unseen speaker identification. The proposed approach outperforms the existing approaches consistently on both tasks.", "paper_url": "http://arxiv.org/abs/2203.17218v1", "pdf_url": "http://arxiv.org/pdf/2203.17218v1", "repo_url": null}, "2203.17089": {"publish_time": "2022-03-31", "title": "Quantum-Aided Meta-Learning for Bayesian Binary Neural Networks via Born Machines", "author": "Ivana Nikoloska et.al.", "abstract": "Near-term noisy intermediate-scale quantum circuits can efficiently implement implicit probabilistic models in discrete spaces, supporting distributions that are practically infeasible to sample from using classical means. One of the possible applications of such models, also known as Born machines, is probabilistic inference, which is at the core of Bayesian methods. This paper studies the use of Born machines for the problem of training binary Bayesian neural networks. In the proposed approach, a Born machine is used to model the variational distribution of the binary weights of the neural network, and data from multiple tasks is used to reduce training data requirements on new tasks. The method combines gradient-based meta-learning and variational inference via Born machines, and is shown in a prototypical regression problem to outperform conventional joint learning strategies.", "paper_url": "http://arxiv.org/abs/2203.17089v1", "pdf_url": "http://arxiv.org/pdf/2203.17089v1", "repo_url": null}, "2203.17030": {"publish_time": "2022-03-31", "title": "Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks", "author": "Da-Wei Zhou et.al.", "abstract": "New classes arise frequently in our ever-changing world, e.g., emerging topics in social media and new types of products in e-commerce. A model should recognize new classes and meanwhile maintain discriminability over old classes. Under severe circumstances, only limited novel instances are available to incrementally update the model. The task of recognizing few-shot new classes without forgetting old classes is called few-shot class-incremental learning (FSCIL). In this work, we propose a new paradigm for FSCIL based on meta-learning by LearnIng Multi-phase Incremental Tasks (LIMIT), which synthesizes fake FSCIL tasks from the base dataset. The data format of fake tasks is consistent with the `real' incremental tasks, and we can build a generalizable feature space for the unseen tasks through meta-learning. Besides, LIMIT also constructs a calibration module based on transformer, which calibrates the old class classifiers and new class prototypes into the same scale and fills in the semantic gap. The calibration module also adaptively contextualizes the instance-specific embedding with a set-to-set function. LIMIT efficiently adapts to new classes and meanwhile resists forgetting over old classes. Experiments on three benchmark datasets (CIFAR100, miniImageNet, and CUB200) and large-scale dataset, i.e., ImageNet ILSVRC2012 validate that LIMIT achieves state-of-the-art performance.", "paper_url": "http://arxiv.org/abs/2203.17030v1", "pdf_url": "http://arxiv.org/pdf/2203.17030v1", "repo_url": null}, "2203.16639": {"publish_time": "2022-03-30", "title": "FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic descriptions, and Conceptual Relations", "author": "Lingjie Mei et.al.", "abstract": "We present a meta-learning framework for learning new visual concepts quickly, from just one or a few examples, guided by multiple naturally occurring data streams: simultaneously looking at images, reading sentences that describe the objects in the scene, and interpreting supplemental sentences that relate the novel concept with other concepts. The learned concepts support downstream applications, such as answering questions by reasoning about unseen images. Our model, namely FALCON, represents individual visual concepts, such as colors and shapes, as axis-aligned boxes in a high-dimensional space (the \"box embedding space\"). Given an input image and its paired sentence, our model first resolves the referential expression in the sentence and associates the novel concept with particular objects in the scene. Next, our model interprets supplemental sentences to relate the novel concept with other known concepts, such as \"X has property Y\" or \"X is a kind of Y\". Finally, it infers an optimal box embedding for the novel concept that jointly 1) maximizes the likelihood of the observed instances in the image, and 2) satisfies the relationships between the novel concepts and the known ones. We demonstrate the effectiveness of our model on both synthetic and real-world datasets.", "paper_url": "http://arxiv.org/abs/2203.16639v1", "pdf_url": "http://arxiv.org/pdf/2203.16639v1", "repo_url": null}, "2203.16588": {"publish_time": "2022-03-30", "title": "Constrained Few-shot Class-incremental Learning", "author": "Michael Hersche et.al.", "abstract": "Continually learning new classes from fresh data without forgetting previous knowledge of old classes is a very challenging research problem. Moreover, it is imperative that such learning must respect certain memory and computational constraints such as (i) training samples are limited to only a few per class, (ii) the computational cost of learning a novel class remains constant, and (iii) the memory footprint of the model grows at most linearly with the number of classes observed. To meet the above constraints, we propose C-FSCIL, which is architecturally composed of a frozen meta-learned feature extractor, a trainable fixed-size fully connected layer, and a rewritable dynamically growing memory that stores as many vectors as the number of encountered classes. C-FSCIL provides three update modes that offer a trade-off between accuracy and compute-memory cost of learning novel classes. C-FSCIL exploits hyperdimensional embedding that allows to continually express many more classes than the fixed dimensions in the vector space, with minimal interference. The quality of class vector representations is further improved by aligning them quasi-orthogonally to each other by means of novel loss functions. Experiments on the CIFAR100, miniImageNet, and Omniglot datasets show that C-FSCIL outperforms the baselines with remarkable accuracy and compression. It also scales up to the largest problem size ever tried in this few-shot setting by learning 423 novel classes on top of 1200 base classes with less than 1.6% accuracy drop. Our code is available at https://github.com/IBM/constrained-FSCIL.", "paper_url": "http://arxiv.org/abs/2203.16588v1", "pdf_url": "http://arxiv.org/pdf/2203.16588v1", "repo_url": "https://github.com/ibm/constrained-fscil"}, "2204.00352": {"publish_time": "2022-04-01", "title": "On the Efficiency of Integrating Self-supervised Learning and Meta-learning for User-defined Few-shot Keyword Spotting", "author": "Wei-Tsung Kao et.al.", "abstract": "User-defined keyword spotting is a task to detect new spoken terms defined by users. This can be viewed as a few-shot learning problem since it is unreasonable for users to define their desired keywords by providing many examples. To solve this problem, previous works try to incorporate self-supervised learning models or apply meta-learning algorithms. But it is unclear whether self-supervised learning and meta-learning are complementary and which combination of the two types of approaches is most effective for few-shot keyword discovery. In this work, we systematically study these questions by utilizing various self-supervised learning models and combining them with a wide variety of meta-learning algorithms. Our result shows that HuBERT combined with Matching network achieves the best result and is robust to the changes of few-shot examples.", "paper_url": "http://arxiv.org/abs/2204.00352v1", "pdf_url": "http://arxiv.org/pdf/2204.00352v1", "repo_url": null}, "2204.00327": {"publish_time": "2022-04-01", "title": "Diverse Preference Augmentation with Multiple Domains for Cold-start Recommendations", "author": "Yan Zhang et.al.", "abstract": "Cold-start issues have been more and more challenging for providing accurate recommendations with the fast increase of users and items. Most existing approaches attempt to solve the intractable problems via content-aware recommendations based on auxiliary information and/or cross-domain recommendations with transfer learning. Their performances are often constrained by the extremely sparse user-item interactions, unavailable side information, or very limited domain-shared users. Recently, meta-learners with meta-augmentation by adding noises to labels have been proven to be effective to avoid overfitting and shown good performance on new tasks. Motivated by the idea of meta-augmentation, in this paper, by treating a user's preference over items as a task, we propose a so-called Diverse Preference Augmentation framework with multiple source domains based on meta-learning (referred to as MetaDPA) to i) generate diverse ratings in a new domain of interest (known as target domain) to handle overfitting on the case of sparse interactions, and to ii) learn a preference model in the target domain via a meta-learning scheme to alleviate cold-start issues. Specifically, we first conduct multi-source domain adaptation by dual conditional variational autoencoders and impose a Multi-domain InfoMax (MDI) constraint on the latent representations to learn domain-shared and domain-specific preference properties. To avoid overfitting, we add a Mutually-Exclusive (ME) constraint on the output of decoders to generate diverse ratings given content data. Finally, these generated diverse ratings and the original ratings are introduced into the meta-training procedure to learn a preference meta-learner, which produces good generalization ability on cold-start recommendation tasks. Experiments on real-world datasets show our proposed MetaDPA clearly outperforms the current state-of-the-art baselines.", "paper_url": "http://arxiv.org/abs/2204.00327v1", "pdf_url": "http://arxiv.org/pdf/2204.00327v1", "repo_url": null}, "2204.01513": {"publish_time": "2022-04-04", "title": "Context-aware Visual Tracking with Joint Meta-updating", "author": "Qiuhong Shen et.al.", "abstract": "Visual object tracking acts as a pivotal component in various emerging video applications. Despite the numerous developments in visual tracking, existing deep trackers are still likely to fail when tracking against objects with dramatic variation. These deep trackers usually do not perform online update or update single sub-branch of the tracking model, for which they cannot adapt to the appearance variation of objects. Efficient updating methods are therefore crucial for tracking while previous meta-updater optimizes trackers directly over parameter space, which is prone to over-fit even collapse on longer sequences. To address these issues, we propose a context-aware tracking model to optimize the tracker over the representation space, which jointly meta-update both branches by exploiting information along the whole sequence, such that it can avoid the over-fitting problem. First, we note that the embedded features of the localization branch and the box-estimation branch, focusing on the local and global information of the target, are effective complements to each other. Based on this insight, we devise a context-aggregation module to fuse information in historical frames, followed by a context-aware module to learn affinity vectors for both branches of the tracker. Besides, we develop a dedicated meta-learning scheme, on account of fast and stable updating with limited training samples. The proposed tracking method achieves an EAO score of 0.514 on VOT2018 with the speed of 40FPS, demonstrating its capability of improving the accuracy and robustness of the underlying tracker with little speed drop.", "paper_url": "http://arxiv.org/abs/2204.01513v1", "pdf_url": "http://arxiv.org/pdf/2204.01513v1", "repo_url": null}, "2204.01437": {"publish_time": "2022-04-04", "title": "Disentangling Abstraction from Statistical Pattern Matching in Human and Machine Learning", "author": "Sreejan Kumar et.al.", "abstract": "The ability to acquire abstract knowledge is a hallmark of human intelligence and is believed by many to be one of the core differences between humans and neural network models. Agents can be endowed with an inductive bias towards abstraction through meta-learning, where they are trained on a distribution of tasks that share some abstract structure that can be learned and applied. However, because neural networks are hard to interpret, it can be difficult to tell whether agents have learned the underlying abstraction, or alternatively statistical patterns that are characteristic of that abstraction. In this work, we compare the performance of humans and agents in a meta-reinforcement learning paradigm in which tasks are generated from abstract rules. We define a novel methodology for building \"task metamers\" that closely match the statistics of the abstract tasks but use a different underlying generative process, and evaluate performance on both abstract and metamer tasks. In our first set of experiments, we found that humans perform better at abstract tasks than metamer tasks whereas a widely-used meta-reinforcement learning agent performs worse on the abstract tasks than the matched metamers. In a second set of experiments, we base the tasks on abstractions derived directly from empirically identified human priors. We utilize the same procedure to generate corresponding metamer tasks, and see the same double dissociation between humans and agents. This work provides a foundation for characterizing differences between humans and machine learning that can be used in future work towards developing machines with human-like behavior.", "paper_url": "http://arxiv.org/abs/2204.01437v1", "pdf_url": "http://arxiv.org/pdf/2204.01437v1", "repo_url": "https://github.com/sreejank/Abstract_Neural_Metamers"}, "2204.00970": {"publish_time": "2022-04-03", "title": "A Dynamic Meta-Learning Model for Time-Sensitive Cold-Start Recommendations", "author": "Krishna Prasad Neupane et.al.", "abstract": "We present a novel dynamic recommendation model that focuses on users who have interactions in the past but turn relatively inactive recently. Making effective recommendations to these time-sensitive cold-start users is critical to maintain the user base of a recommender system. Due to the sparse recent interactions, it is challenging to capture these users' current preferences precisely. Solely relying on their historical interactions may also lead to outdated recommendations misaligned with their recent interests. The proposed model leverages historical and current user-item interactions and dynamically factorizes a user's (latent) preference into time-specific and time-evolving representations that jointly affect user behaviors. These latent factors further interact with an optimized item embedding to achieve accurate and timely recommendations. Experiments over real-world data help demonstrate the effectiveness of the proposed time-sensitive cold-start recommendation model.", "paper_url": "http://arxiv.org/abs/2204.00970v1", "pdf_url": "http://arxiv.org/pdf/2204.00970v1", "repo_url": null}, "2204.00929": {"publish_time": "2022-04-02", "title": "AutoProtoNet: Interpretability for Prototypical Networks", "author": "Pedro Sandoval-Segura et.al.", "abstract": "In meta-learning approaches, it is difficult for a practitioner to make sense of what kind of representations the model employs. Without this ability, it can be difficult to both understand what the model knows as well as to make meaningful corrections. To address these challenges, we introduce AutoProtoNet, which builds interpretability into Prototypical Networks by training an embedding space suitable for reconstructing inputs, while remaining convenient for few-shot learning. We demonstrate how points in this embedding space can be visualized and used to understand class representations. We also devise a prototype refinement method, which allows a human to debug inadequate classification parameters. We use this debugging technique on a custom classification task and find that it leads to accuracy improvements on a validation set consisting of in-the-wild images. We advocate for interpretability in meta-learning approaches and show that there are interactive ways for a human to enhance meta-learning algorithms.", "paper_url": "http://arxiv.org/abs/2204.00929v1", "pdf_url": "http://arxiv.org/pdf/2204.00929v1", "repo_url": null}, "2204.02210": {"publish_time": "2022-04-05", "title": "Model Based Meta Learning of Critics for Policy Gradients", "author": "Sarah Bechtle et.al.", "abstract": "Being able to seamlessly generalize across different tasks is fundamental for robots to act in our world. However, learning representations that generalize quickly to new scenarios is still an open research problem in reinforcement learning. In this paper we present a framework to meta-learn the critic for gradient-based policy learning. Concretely, we propose a model-based bi-level optimization algorithm that updates the critics parameters such that the policy that is learned with the updated critic gets closer to solving the meta-training tasks. We illustrate that our algorithm leads to learned critics that resemble the ground truth Q function for a given task. Finally, after meta-training, the learned critic can be used to learn new policies for new unseen task and environment settings via model-free policy gradient optimization, without requiring a model. We present results that show the generalization capabilities of our learned critic to new tasks and dynamics when used to learn a new policy in a new scenario.", "paper_url": "http://arxiv.org/abs/2204.02210v1", "pdf_url": "http://arxiv.org/pdf/2204.02210v1", "repo_url": null}, "2204.02121": {"publish_time": "2022-04-05", "title": "MetaAudio: A Few-Shot Audio Classification Benchmark", "author": "Calum Heggan et.al.", "abstract": "Currently available benchmarks for few-shot learning (machine learning with few training examples) are limited in the domains they cover, primarily focusing on image classification. This work aims to alleviate this reliance on image-based benchmarks by offering the first comprehensive, public and fully reproducible audio based alternative, covering a variety of sound domains and experimental settings. We compare the few-shot classification performance of a variety of techniques on seven audio datasets (spanning environmental sounds to human-speech). Extending this, we carry out in-depth analyses of joint training (where all datasets are used during training) and cross-dataset adaptation protocols, establishing the possibility of a generalised audio few-shot classification algorithm. Our experimentation shows gradient-based meta-learning methods such as MAML and Meta-Curvature consistently outperform both metric and baseline methods. We also demonstrate that the joint training routine helps overall generalisation for the environmental sound databases included, as well as being a somewhat-effective method of tackling the cross-dataset/domain setting.", "paper_url": "http://arxiv.org/abs/2204.02121v1", "pdf_url": "http://arxiv.org/pdf/2204.02121v1", "repo_url": "https://github.com/cheggan/metaaudio-a-few-shot-audio-classification-benchmark"}, "2204.01905": {"publish_time": "2022-04-05", "title": "Learning to Adapt to Domain Shifts with Few-shot Samples in Anomalous Sound Detection", "author": "Bingqing Chen et.al.", "abstract": "Anomaly detection has many important applications, such as monitoring industrial equipment. Despite recent advances in anomaly detection with deep-learning methods, it is unclear how existing solutions would perform under out-of-distribution scenarios, e.g., due to shifts in machine load or environmental noise. Grounded in the application of machine health monitoring, we propose a framework that adapts to new conditions with few-shot samples. Building upon prior work, we adopt a classification-based approach for anomaly detection and show its equivalence to mixture density estimation of the normal samples. We incorporate an episodic training procedure to match the few-shot setting during inference. We define multiple auxiliary classification tasks based on meta-information and leverage gradient-based meta-learning to improve generalization to different shifts. We evaluate our proposed method on a recently-released dataset of audio measurements from different machine types. It improved upon two baselines by around 10% and is on par with best-performing model reported on the dataset.", "paper_url": "http://arxiv.org/abs/2204.01905v1", "pdf_url": "http://arxiv.org/pdf/2204.01905v1", "repo_url": null}, "2204.03609": {"publish_time": "2022-04-07", "title": "Pin the Memory: Learning to Generalize Semantic Segmentation", "author": "Jin Kim et.al.", "abstract": "The rise of deep neural networks has led to several breakthroughs for semantic segmentation. In spite of this, a model trained on source domain often fails to work properly in new challenging domains, that is directly concerned with the generalization capability of the model. In this paper, we present a novel memory-guided domain generalization method for semantic segmentation based on meta-learning framework. Especially, our method abstracts the conceptual knowledge of semantic classes into categorical memory which is constant beyond the domains. Upon the meta-learning concept, we repeatedly train memory-guided networks and simulate virtual test to 1) learn how to memorize a domain-agnostic and distinct information of classes and 2) offer an externally settled memory as a class-guidance to reduce the ambiguity of representation in the test data of arbitrary unseen domain. To this end, we also propose memory divergence and feature cohesion losses, which encourage to learn memory reading and update processes for category-aware domain generalization. Extensive experiments for semantic segmentation demonstrate the superior generalization capability of our method over state-of-the-art works on various benchmarks.", "paper_url": "http://arxiv.org/abs/2204.03609v1", "pdf_url": "http://arxiv.org/pdf/2204.03609v1", "repo_url": null}, "2204.03511": {"publish_time": "2022-04-07", "title": "Interval Bound Propagation$\\unicode{x2013}$aided Few$\\unicode{x002d}$shot Learning", "author": "Shounak Datta et.al.", "abstract": "Few-shot learning aims to transfer the knowledge acquired from training on a diverse set of tasks, from a given task distribution, to generalize to unseen tasks, from the same distribution, with a limited amount of labeled data. The underlying requirement for effective few-shot generalization is to learn a good representation of the task manifold. One way to encourage this is to preserve local neighborhoods in the feature space learned by the few-shot learner. To this end, we introduce the notion of interval bounds from the provably robust training literature to few-shot learning. The interval bounds are used to characterize neighborhoods around the training tasks. These neighborhoods can then be preserved by minimizing the distance between a task and its respective bounds. We further introduce a novel strategy to artificially form new tasks for training by interpolating between the available tasks and their respective interval bounds, to aid in cases with a scarcity of tasks. We apply our framework to both model-agnostic meta-learning as well as prototype-based metric-learning paradigms. The efficacy of our proposed approach is evident from the improved performance on several datasets from diverse domains in comparison to a sizable number of recent competitors.", "paper_url": "http://arxiv.org/abs/2204.03511v2", "pdf_url": "http://arxiv.org/pdf/2204.03511v2", "repo_url": null}, "2204.04952": {"publish_time": "2022-04-11", "title": "MGIMN: Multi-Grained Interactive Matching Network for Few-shot Text Classification", "author": "Jianhai Zhang et.al.", "abstract": "Text classification struggles to generalize to unseen classes with very few labeled text instances per class. In such a few-shot learning (FSL) setting, metric-based meta-learning approaches have shown promising results. Previous studies mainly aim to derive a prototype representation for each class. However, they neglect that it is challenging-yet-unnecessary to construct a compact representation which expresses the entire meaning for each class. They also ignore the importance to capture the inter-dependency between query and the support set for few-shot text classification. To deal with these issues, we propose a meta-learning based method MGIMN which performs instance-wise comparison followed by aggregation to generate class-wise matching vectors instead of prototype learning. The key of instance-wise comparison is the interactive matching within the class-specific context and episode-specific context. Extensive experiments demonstrate that the proposed method significantly outperforms the existing state-of-the-art approaches, under both the standard FSL and generalized FSL settings.", "paper_url": "http://arxiv.org/abs/2204.04952v1", "pdf_url": "http://arxiv.org/pdf/2204.04952v1", "repo_url": null}, "2204.04348": {"publish_time": "2022-04-09", "title": "Neural networks embrace learned diversity", "author": "Anshul Choudhary et.al.", "abstract": "Diversity conveys advantages in nature, yet homogeneous neurons typically comprise the layers of artificial neural networks. Here we construct neural networks from neurons that learn their own activation functions, quickly diversify, and subsequently outperform their homogeneous counterparts. Sub-networks instantiate the neurons, which meta-learn especially efficient sets of nonlinear responses. Such learned diversity provides examples of dynamical systems selecting diversity over uniformity and elucidates the role of diversity in natural and artificial systems.", "paper_url": "http://arxiv.org/abs/2204.04348v1", "pdf_url": "http://arxiv.org/pdf/2204.04348v1", "repo_url": "https://github.com/nonlinearartificialintelligencelab/diversityNN"}, "2204.04297": {"publish_time": "2022-04-08", "title": "Learning to modulate random weights can induce task-specific contexts for economical meta and continual learning", "author": "Jinyung Hong et.al.", "abstract": "Neural networks are vulnerable to catastrophic forgetting when data distributions are non-stationary during continual online learning; learning of a later task often leads to forgetting of an earlier task. One solution approach is model-agnostic continual meta-learning, whereby both task-specific and meta parameters are trained. Here, we depart from this view and introduce a novel neural-network architecture inspired by neuromodulation in biological nervous systems. Neuromodulation is the biological mechanism that dynamically controls and fine-tunes synaptic dynamics to complement the behavioral context in real-time, which has received limited attention in machine learning. We introduce a single-hidden-layer network that learns only a relatively small context vector per task (task-specific parameters) that neuromodulates unchanging, randomized weights (meta parameters) that transform the input. We show that when task boundaries are available, this approach can eliminate catastrophic forgetting entirely while also drastically reducing the number of learnable parameters relative to other context-vector-based approaches. Furthermore, by combining this model with a simple meta-learning approach for inferring task identity, we demonstrate that the model can be generalized into a framework to perform continual learning without knowledge of task boundaries. Finally, we showcase the framework in a supervised continual online learning scenario and discuss the implications of the proposed formalism.", "paper_url": "http://arxiv.org/abs/2204.04297v1", "pdf_url": "http://arxiv.org/pdf/2204.04297v1", "repo_url": null}, "2204.05751": {"publish_time": "2022-04-12", "title": "Decomposed Meta-Learning for Few-Shot Named Entity Recognition", "author": "Tingting Ma et.al.", "abstract": "Few-shot named entity recognition (NER) systems aim at recognizing novel-class named entities based on only a few labeled examples. In this paper, we present a decomposed meta-learning approach which addresses the problem of few-shot NER by sequentially tackling few-shot span detection and few-shot entity typing using meta-learning. In particular, we take the few-shot span detection as a sequence labeling problem and train the span detector by introducing the model-agnostic meta-learning (MAML) algorithm to find a good model parameter initialization that could fast adapt to new entity classes. For few-shot entity typing, we propose MAML-ProtoNet, i.e., MAML-enhanced prototypical networks to find a good embedding space that can better distinguish text span representations from different entity classes. Extensive experiments on various benchmarks show that our approach achieves superior performance over prior methods.", "paper_url": "http://arxiv.org/abs/2204.05751v2", "pdf_url": "http://arxiv.org/pdf/2204.05751v2", "repo_url": "https://github.com/microsoft/vert-papers"}, "2204.05547": {"publish_time": "2022-04-12", "title": "DistPro: Searching A Fast Knowledge Distillation Process via Meta Optimization", "author": "Xueqing Deng et.al.", "abstract": "Recent Knowledge distillation (KD) studies show that different manually designed schemes impact the learned results significantly. Yet, in KD, automatically searching an optimal distillation scheme has not yet been well explored. In this paper, we propose DistPro, a novel framework which searches for an optimal KD process via differentiable meta-learning. Specifically, given a pair of student and teacher networks, DistPro first sets up a rich set of KD connection from the transmitting layers of the teacher to the receiving layers of the student, and in the meanwhile, various transforms are also proposed for comparing feature maps along its pathway for the distillation. Then, each combination of a connection and a transform choice (pathway) is associated with a stochastic weighting process which indicates its importance at every step during the distillation. In the searching stage, the process can be effectively learned through our proposed bi-level meta-optimization strategy. In the distillation stage, DistPro adopts the learned processes for knowledge distillation, which significantly improves the student accuracy especially when faster training is required. Lastly, we find the learned processes can be generalized between similar tasks and networks. In our experiments, DistPro produces state-of-the-art (SoTA) accuracy under varying number of learning epochs on popular datasets, i.e. CIFAR100 and ImageNet, which demonstrate the effectiveness of our framework.", "paper_url": "http://arxiv.org/abs/2204.05547v1", "pdf_url": "http://arxiv.org/pdf/2204.05547v1", "repo_url": null}, "2204.05449": {"publish_time": "2022-04-11", "title": "Neural Processes with Stochastic Attention: Paying more attention to the context dataset", "author": "Mingyu Kim et.al.", "abstract": "Neural processes (NPs) aim to stochastically complete unseen data points based on a given context dataset. NPs essentially leverage a given dataset as a context representation to derive a suitable identifier for a novel task. To improve the prediction accuracy, many variants of NPs have investigated context embedding approaches that generally design novel network architectures and aggregation functions satisfying permutation invariant. In this work, we propose a stochastic attention mechanism for NPs to capture appropriate context information. From the perspective of information theory, we demonstrate that the proposed method encourages context embedding to be differentiated from a target dataset, allowing NPs to consider features in a target dataset and context embedding independently. We observe that the proposed method can appropriately capture context embedding even under noisy data sets and restricted task distributions, where typical NPs suffer from a lack of context embeddings. We empirically show that our approach substantially outperforms conventional NPs in various domains through 1D regression, predator-prey model, and image completion. Moreover, the proposed method is also validated by MovieLens-10k dataset, a real-world problem.", "paper_url": "http://arxiv.org/abs/2204.05449v1", "pdf_url": "http://arxiv.org/pdf/2204.05449v1", "repo_url": null}, "2204.05432": {"publish_time": "2022-04-11", "title": "A Simple Approach to Adversarial Robustness in Few-shot Image Classification", "author": "Akshayvarun Subramanya et.al.", "abstract": "Few-shot image classification, where the goal is to generalize to tasks with limited labeled data, has seen great progress over the years. However, the classifiers are vulnerable to adversarial examples, posing a question regarding their generalization capabilities. Recent works have tried to combine meta-learning approaches with adversarial training to improve the robustness of few-shot classifiers. We show that a simple transfer-learning based approach can be used to train adversarially robust few-shot classifiers. We also present a method for novel classification task based on calibrating the centroid of the few-shot category towards the base classes. We show that standard adversarial training on base categories along with calibrated centroid-based classifier in the novel categories, outperforms or is on-par with state-of-the-art advanced methods on standard benchmarks for few-shot learning. Our method is simple, easy to scale, and with little effort can lead to robust few-shot classifiers. Code is available here: \\url{https://github.com/UCDvision/Simple_few_shot.git}", "paper_url": "http://arxiv.org/abs/2204.05432v1", "pdf_url": "http://arxiv.org/pdf/2204.05432v1", "repo_url": null}, "2204.06832": {"publish_time": "2022-04-14", "title": "Self-Guided Learning to Denoise for Robust Recommendation", "author": "Yunjun Gao et.al.", "abstract": "The ubiquity of implicit feedback makes them the default choice to build modern recommender systems. Generally speaking, observed interactions are considered as positive samples, while unobserved interactions are considered as negative ones. However, implicit feedback is inherently noisy because of the ubiquitous presence of noisy-positive and noisy-negative interactions. Recently, some studies have noticed the importance of denoising implicit feedback for recommendations, and enhanced the robustness of recommendation models to some extent. Nonetheless, they typically fail to (1) capture the hard yet clean interactions for learning comprehensive user preference, and (2) provide a universal denoising solution that can be applied to various kinds of recommendation models.   In this paper, we thoroughly investigate the memorization effect of recommendation models, and propose a new denoising paradigm, i.e., Self-Guided Denoising Learning (SGDL), which is able to collect memorized interactions at the early stage of the training (i.e., \"noise-resistant\" period), and leverage those data as denoising signals to guide the following training (i.e., \"noise-sensitive\" period) of the model in a meta-learning manner. Besides, our method can automatically switch its learning phase at the memorization point from memorization to self-guided learning, and select clean and informative memorized data via a novel adaptive denoising scheduler to improve the robustness. We incorporate SGDL with four representative recommendation models (i.e., NeuMF, CDAE, NGCF and LightGCN) and different loss functions (i.e., binary cross-entropy and BPR loss). The experimental results on three benchmark datasets demonstrate the effectiveness of SGDL over the state-of-the-art denoising methods like T-CE, IR, DeCA, and even state-of-the-art robust graph-based methods like SGCN and SGL.", "paper_url": "http://arxiv.org/abs/2204.06832v1", "pdf_url": "http://arxiv.org/pdf/2204.06832v1", "repo_url": "https://github.com/scottdyt/sgdl"}, "2204.06767": {"publish_time": "2022-04-14", "title": "Learning Task-Aware Energy Disaggregation: a Federated Approach", "author": "Ruohong Liu et.al.", "abstract": "We consider the problem of learning the energy disaggregation signals for residential load data. Such task is referred as non-intrusive load monitoring (NILM), and in order to find individual devices' power consumption profiles based on aggregated meter measurements, a machine learning model is usually trained based on large amount of training data coming from a number of residential homes. Yet collecting such residential load datasets require both huge efforts and customers' approval on sharing metering data, while load data coming from different regions or electricity users may exhibit heterogeneous usage patterns. Both practical concerns make training a single, centralized NILM model challenging. In this paper, we propose a decentralized and task-adaptive learning scheme for NILM tasks, where nested meta learning and federated learning steps are designed for learning task-specific models collectively. Simulation results on benchmark dataset validate proposed algorithm's performance on efficiently inferring appliance-level consumption for a variety of homes and appliances.", "paper_url": "http://arxiv.org/abs/2204.06767v1", "pdf_url": "http://arxiv.org/pdf/2204.06767v1", "repo_url": null}, "2204.06716": {"publish_time": "2022-04-14", "title": "Control-oriented meta-learning", "author": "Spencer M. Richards et.al.", "abstract": "Real-time adaptation is imperative to the control of robots operating in complex, dynamic environments. Adaptive control laws can endow even nonlinear systems with good trajectory tracking performance, provided that any uncertain dynamics terms are linearly parameterizable with known nonlinear features. However, it is often difficult to specify such features a priori, such as for aerodynamic disturbances on rotorcraft or interaction forces between a manipulator arm and various objects. In this paper, we turn to data-driven modeling with neural networks to learn, offline from past data, an adaptive controller with an internal parametric model of these nonlinear features. Our key insight is that we can better prepare the controller for deployment with control-oriented meta-learning of features in closed-loop simulation, rather than regression-oriented meta-learning of features to fit input-output data. Specifically, we meta-learn the adaptive controller with closed-loop tracking simulation as the base-learner and the average tracking error as the meta-objective. With both fully-actuated and underactuated nonlinear planar rotorcraft subject to wind, we demonstrate that our adaptive controller outperforms other controllers trained with regression-oriented meta-learning when deployed in closed-loop for trajectory tracking control.", "paper_url": "http://arxiv.org/abs/2204.06716v1", "pdf_url": "http://arxiv.org/pdf/2204.06716v1", "repo_url": "https://github.com/StanfordASL/Adaptive-Control-Oriented-Meta-Learning"}, "2204.07501": {"publish_time": "2022-04-15", "title": "Evaluating few shot and Contrastive learning Methods for Code Clone Detection", "author": "Mohamad Khajezade et.al.", "abstract": "Context: Code Clone Detection (CCD) is a software engineering task that is used for plagiarism detection, code search, and code comprehension. Recently, deep learning-based models have achieved an F1 score (a metric used to assess classifiers) of $\\sim$95\\% on the CodeXGLUE benchmark. These models require many training data, mainly fine-tuned on Java or C++ datasets. However, no previous study evaluates the generalizability of these models where a limited amount of annotated data is available.   Objective: The main objective of this research is to assess the ability of the CCD models as well as few shot learning algorithms for unseen programming problems and new languages (i.e., the model is not trained on these problems/languages).   Method: We assess the generalizability of the state of the art models for CCD in few shot settings (i.e., only a few samples are available for fine-tuning) by setting three scenarios: i) unseen problems, ii) unseen languages, iii) combination of new languages and new problems. We choose three datasets of BigCloneBench, POJ-104, and CodeNet and Java, C++, and Ruby languages. Then, we employ Model Agnostic Meta-learning (MAML), where the model learns a meta-learner capable of extracting transferable knowledge from the train set; so that the model can be fine-tuned using a few samples. Finally, we combine contrastive learning with MAML to further study whether it can improve the results of MAML.", "paper_url": "http://arxiv.org/abs/2204.07501v1", "pdf_url": "http://arxiv.org/pdf/2204.07501v1", "repo_url": null}, "2204.07311": {"publish_time": "2022-04-15", "title": "MetaSets: Meta-Learning on Point Sets for Generalizable Representations", "author": "Chao Huang et.al.", "abstract": "Deep learning techniques for point clouds have achieved strong performance on a range of 3D vision tasks. However, it is costly to annotate large-scale point sets, making it critical to learn generalizable representations that can transfer well across different point sets. In this paper, we study a new problem of 3D Domain Generalization (3DDG) with the goal to generalize the model to other unseen domains of point clouds without any access to them in the training process. It is a challenging problem due to the substantial geometry shift from simulated to real data, such that most existing 3D models underperform due to overfitting the complete geometries in the source domain. We propose to tackle this problem via MetaSets, which meta-learns point cloud representations from a group of classification tasks on carefully-designed transformed point sets containing specific geometry priors. The learned representations are more generalizable to various unseen domains of different geometries. We design two benchmarks for Sim-to-Real transfer of 3D point clouds. Experimental results show that MetaSets outperforms existing 3D deep learning methods by large margins.", "paper_url": "http://arxiv.org/abs/2204.07311v1", "pdf_url": "http://arxiv.org/pdf/2204.07311v1", "repo_url": null}, "2204.07305": {"publish_time": "2022-04-15", "title": "Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference", "author": "Shell Xu Hu et.al.", "abstract": "Few-shot learning (FSL) is an important and topical problem in computer vision that has motivated extensive research into numerous methods spanning from sophisticated meta-learning methods to simple transfer learning baselines. We seek to push the limits of a simple-but-effective pipeline for more realistic and practical settings of few-shot image classification. To this end, we explore few-shot learning from the perspective of neural network architecture, as well as a three stage pipeline of network updates under different data supplies, where unsupervised external data is considered for pre-training, base categories are used to simulate few-shot tasks for meta-training, and the scarcely labelled data of an novel task is taken for fine-tuning. We investigate questions such as: (1) How pre-training on external data benefits FSL? (2) How state-of-the-art transformer architectures can be exploited? and (3) How fine-tuning mitigates domain shift? Ultimately, we show that a simple transformer-based pipeline yields surprisingly good performance on standard benchmarks such as Mini-ImageNet, CIFAR-FS, CDFSL and Meta-Dataset. Our code and demo are available at https://hushell.github.io/pmf.", "paper_url": "http://arxiv.org/abs/2204.07305v1", "pdf_url": "http://arxiv.org/pdf/2204.07305v1", "repo_url": null}, "2204.08358": {"publish_time": "2022-04-18", "title": "AutoMLBench: A Comprehensive Experimental Evaluation of Automated Machine Learning Frameworks", "author": "Hassan Eldeeb et.al.", "abstract": "Nowadays, machine learning is playing a crucial role in harnessing the power of the massive amounts of data that we are currently producing every day in our digital world. With the booming demand for machine learning applications, it has been recognized that the number of knowledgeable data scientists can not scale with the growing data volumes and application needs in our digital world. In response to this demand, several automated machine learning (AutoML) techniques and frameworks have been developed to fill the gap of human expertise by automating the process of building machine learning pipelines. In this study, we present a comprehensive evaluation and comparison of the performance characteristics of six popular AutoML frameworks, namely, Auto-Weka, AutoSKlearn, TPOT, Recipe, ATM, and SmartML across 100 data sets from established AutoML benchmark suites. Our experimental evaluation considers different aspects for its comparison including the performance impact of several design decisions including time budget, size of search space, meta-learning, and ensemble construction. The results of our study reveal various interesting insights that can significantly guide and impact the design of AutoML frameworks.", "paper_url": "http://arxiv.org/abs/2204.08358v1", "pdf_url": "http://arxiv.org/pdf/2204.08358v1", "repo_url": null}, "2204.07841": {"publish_time": "2022-04-16", "title": "Multimodal Few-Shot Object Detection with Meta-Learning Based Cross-Modal Prompting", "author": "Guangxing Han et.al.", "abstract": "We study multimodal few-shot object detection (FSOD) in this paper, using both few-shot visual examples and class semantic information for detection. Most of previous works focus on either few-shot or zero-shot object detection, ignoring the complementarity of visual and semantic information. We first show that meta-learning and prompt-based learning, the most commonly-used methods for few-shot learning and zero-shot transferring from pre-trained vision-language models to downstream tasks, are conceptually similar. They both reformulate the objective of downstream tasks the same as the pre-training tasks, and mostly without tuning the parameters of pre-trained models. Based on this observation, we propose to combine meta-learning with prompt-based learning for multimodal FSOD without fine-tuning, by learning transferable class-agnostic multimodal FSOD models over many-shot base classes. Specifically, to better exploit the pre-trained vision-language models, the meta-learning based cross-modal prompting is proposed to generate soft prompts and further used to extract the semantic prototype, conditioned on the few-shot visual examples. Then, the extracted semantic prototype and few-shot visual prototype are fused to generate the multimodal prototype for detection. Our models can efficiently fuse the visual and semantic information at both token-level and feature-level. We comprehensively evaluate the proposed multimodal FSOD models on multiple few-shot object detection benchmarks, achieving promising results.", "paper_url": "http://arxiv.org/abs/2204.07841v1", "pdf_url": "http://arxiv.org/pdf/2204.07841v1", "repo_url": null}, "2204.08993": {"publish_time": "2022-04-19", "title": "Metappearance: Meta-Learning for Visual Appearance Reproduction", "author": "Michael Fischer et.al.", "abstract": "There currently are two main approaches to reproducing visual appearance using Machine Learning (ML): The first is training models that generalize over different instances of a problem, e.g., different images from a dataset. Such models learn priors over the data corpus and use this knowledge to provide fast inference with little input, often as a one-shot operation. However, this generality comes at the cost of fidelity, as such methods often struggle to achieve the final quality required. The second approach does not train a model that generalizes across the data, but overfits to a single instance of a problem, e.g., a flash image of a material. This produces detailed and high-quality results, but requires time-consuming training and is, as mere non-linear function fitting, unable to exploit previous experience. Techniques such as fine-tuning or auto-decoders combine both approaches but are sequential and rely on per-exemplar optimization. We suggest to combine both techniques end-to-end using meta-learning: We over-fit onto a single problem instance in an inner loop, while also learning how to do so efficiently in an outer-loop that builds intuition over many optimization runs. We demonstrate this concept to be versatile and efficient, applying it to RGB textures, Bi-directional Reflectance Distribution Functions (BRDFs), or Spatially-varying BRDFs (svBRDFs).", "paper_url": "http://arxiv.org/abs/2204.08993v1", "pdf_url": "http://arxiv.org/pdf/2204.08993v1", "repo_url": null}, "2204.10810": {"publish_time": "2022-04-22", "title": "Learning to Scaffold: Optimizing Model Explanations for Teaching", "author": "Patrick Fernandes et.al.", "abstract": "Modern machine learning models are opaque, and as a result there is a burgeoning academic subfield on methods that explain these models' behavior. However, what is the precise goal of providing such explanations, and how can we demonstrate that explanations achieve this goal? Some research argues that explanations should help teach a student (either human or machine) to simulate the model being explained, and that the quality of explanations can be measured by the simulation accuracy of students on unexplained examples. In this work, leveraging meta-learning techniques, we extend this idea to improve the quality of the explanations themselves, specifically by optimizing explanations such that student models more effectively learn to simulate the original model. We train models on three natural language processing and computer vision tasks, and find that students trained with explanations extracted with our framework are able to simulate the teacher significantly more effectively than ones produced with previous methods. Through human annotations and a user study, we further find that these learned explanations more closely align with how humans would explain the required decisions in these tasks. Our code is available at https://github.com/coderpat/learning-scaffold", "paper_url": "http://arxiv.org/abs/2204.10810v1", "pdf_url": "http://arxiv.org/pdf/2204.10810v1", "repo_url": "https://github.com/coderpat/learning-scaffold"}, "2204.10689": {"publish_time": "2022-04-22", "title": "Reinforcing Generated Images via Meta-learning for One-Shot Fine-Grained Visual Recognition", "author": "Satoshi Tsutsui et.al.", "abstract": "One-shot fine-grained visual recognition often suffers from the problem of having few training examples for new fine-grained classes. To alleviate this problem, off-the-shelf image generation techniques based on Generative Adversarial Networks (GANs) can potentially create additional training images. However, these GAN-generated images are often not helpful for actually improving the accuracy of one-shot fine-grained recognition. In this paper, we propose a meta-learning framework to combine generated images with original images, so that the resulting \"hybrid\" training images improve one-shot learning. Specifically, the generic image generator is updated by a few training instances of novel classes, and a Meta Image Reinforcing Network (MetaIRNet) is proposed to conduct one-shot fine-grained recognition as well as image reinforcement. Our experiments demonstrate consistent improvement over baselines on one-shot fine-grained image classification benchmarks. Furthermore, our analysis shows that the reinforced images have more diversity compared to the original and GAN-generated images.", "paper_url": "http://arxiv.org/abs/2204.10689v1", "pdf_url": "http://arxiv.org/pdf/2204.10689v1", "repo_url": null}, "2204.11828": {"publish_time": "2022-04-25", "title": "Skill-based Meta-Reinforcement Learning", "author": "Taewook Nam et.al.", "abstract": "While deep reinforcement learning methods have shown impressive results in robot learning, their sample inefficiency makes the learning of complex, long-horizon behaviors with real robot systems infeasible. To mitigate this issue, meta-reinforcement learning methods aim to enable fast learning on novel tasks by learning how to learn. Yet, the application has been limited to short-horizon tasks with dense rewards. To enable learning long-horizon behaviors, recent works have explored leveraging prior experience in the form of offline datasets without reward or task annotations. While these approaches yield improved sample efficiency, millions of interactions with environments are still required to solve complex tasks. In this work, we devise a method that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to solve unseen target tasks with orders of magnitude fewer environment interactions. Our core idea is to leverage prior experience extracted from offline datasets during meta-learning. Specifically, we propose to (1) extract reusable skills and a skill prior from offline datasets, (2) meta-train a high-level policy that learns to efficiently compose learned skills into long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve an unseen target task. Experimental results on continuous control tasks in navigation and manipulation demonstrate that the proposed method can efficiently solve long-horizon novel target tasks by combining the strengths of meta-learning and the usage of offline datasets, while prior approaches in RL, meta-RL, and multi-task RL require substantially more environment interactions to solve the tasks.", "paper_url": "http://arxiv.org/abs/2204.11828v1", "pdf_url": "http://arxiv.org/pdf/2204.11828v1", "repo_url": null}, "2204.12466": {"publish_time": "2022-04-26", "title": "Meta-free representation learning for few-shot learning via stochastic weight averaging", "author": "Kuilin Chen et.al.", "abstract": "Recent studies on few-shot classification using transfer learning pose challenges to the effectiveness and efficiency of episodic meta-learning algorithms. Transfer learning approaches are a natural alternative, but they are restricted to few-shot classification. Moreover, little attention has been on the development of probabilistic models with well-calibrated uncertainty from few-shot samples, except for some Bayesian episodic learning algorithms. To tackle the aforementioned issues, we propose a new transfer learning method to obtain accurate and reliable models for few-shot regression and classification. The resulting method does not require episodic meta-learning and is called meta-free representation learning (MFRL). MFRL first finds low-rank representation generalizing well on meta-test tasks. Given the learned representation, probabilistic linear models are fine-tuned with few-shot samples to obtain models with well-calibrated uncertainty. The proposed method not only achieves the highest accuracy on a wide range of few-shot learning benchmark datasets but also correctly quantifies the prediction uncertainty. In addition, weight averaging and temperature scaling are effective in improving the accuracy and reliability of few-shot learning in existing meta-learning algorithms with a wide range of learning paradigms and model architectures.", "paper_url": "http://arxiv.org/abs/2204.12466v1", "pdf_url": "http://arxiv.org/pdf/2204.12466v1", "repo_url": null}, "2204.12111": {"publish_time": "2022-04-26", "title": "Function-words Enhanced Attention Networks for Few-Shot Inverse Relation Classification", "author": "Chunliu Dou et.al.", "abstract": "The relation classification is to identify semantic relations between two entities in a given text. While existing models perform well for classifying inverse relations with large datasets, their performance is significantly reduced for few-shot learning. In this paper, we propose a function words adaptively enhanced attention framework (FAEA) for few-shot inverse relation classification, in which a hybrid attention model is designed to attend class-related function words based on meta-learning. As the involvement of function words brings in significant intra-class redundancy, an adaptive message passing mechanism is introduced to capture and transfer inter-class differences.We mathematically analyze the negative impact of function words from dot-product measurement, which explains why message passing mechanism effectively reduces the impact. Our experimental results show that FAEA outperforms strong baselines, especially the inverse relation accuracy is improved by 14.33% under 1-shot setting in FewRel1.0.", "paper_url": "http://arxiv.org/abs/2204.12111v1", "pdf_url": "http://arxiv.org/pdf/2204.12111v1", "repo_url": null}, "2204.11942": {"publish_time": "2022-04-25", "title": "Meta-AF: Meta-Learning for Adaptive Filters", "author": "Jonah Casebeer et.al.", "abstract": "Adaptive filtering algorithms are pervasive throughout modern society and have had a significant impact on a wide variety of domains including audio processing, telecommunications, biomedical sensing, astropyhysics and cosmology, seismology, and many more. Adaptive filters typically operate via specialized online, iterative optimization methods such as least-mean squares or recursive least squares and aim to process signals in unknown or nonstationary environments. Such algorithms, however, can be slow and laborious to develop, require domain expertise to create, and necessitate mathematical insight for improvement. In this work, we seek to go beyond the limits of human-derived adaptive filter algorithms and present a comprehensive framework for learning online, adaptive signal processing algorithms or update rules directly from data. To do so, we frame the development of adaptive filters as a meta-learning problem in the context of deep learning and use a form of self-supervision to learn online iterative update rules for adaptive filters. To demonstrate our approach, we focus on audio applications and systematically develop meta-learned adaptive filters for five canonical audio problems including system identification, acoustic echo cancellation, blind equalization, multi-channel dereverberation, and beamforming. For each application, we compare against common baselines and/or current state-of-the-art methods and show we can learn high-performing adaptive filters that operate in real-time and, in most cases, significantly out perform all past specially developed methods for each task using a single general-purpose configuration of our method.", "paper_url": "http://arxiv.org/abs/2204.11942v1", "pdf_url": "http://arxiv.org/pdf/2204.11942v1", "repo_url": null}, "2204.11897": {"publish_time": "2022-04-25", "title": "Reinforcement Teaching", "author": "Alex Lewandowski et.al.", "abstract": "We propose Reinforcement Teaching: a framework for meta-learning in which a teaching policy is learned, through reinforcement, to control a student's learning process. The student's learning process is modelled as a Markov reward process and the teacher, with its action-space, interacts with the induced Markov decision process. We show that, for many learning processes, the student's learnable parameters form a Markov state. To avoid having the teacher learn directly from parameters, we propose the Parameter Embedder that learns a representation of a student's state from its input/output behaviour. Next, we use learning progress to shape the teacher's reward towards maximizing the student's performance. To demonstrate the generality of Reinforcement Teaching, we conducted experiments in which a teacher learns to significantly improve supervised and reinforcement learners by using a combination of learning progress reward and a Parameter Embedded state. These results show that Reinforcement Teaching is not only an expressive framework capable of unifying different approaches, but also provides meta-learning with the plethora of tools from reinforcement learning.", "paper_url": "http://arxiv.org/abs/2204.11897v1", "pdf_url": "http://arxiv.org/pdf/2204.11897v1", "repo_url": null}, "2204.12668": {"publish_time": "2022-04-27", "title": "Adaptable Text Matching via Meta-Weight Regulator", "author": "Bo Zhang et.al.", "abstract": "Neural text matching models have been used in a range of applications such as question answering and natural language inference, and have yielded a good performance. However, these neural models are of a limited adaptability, resulting in a decline in performance when encountering test examples from a different dataset or even a different task. The adaptability is particularly important in the few-shot setting: in many cases, there is only a limited amount of labeled data available for a target dataset or task, while we may have access to a richly labeled source dataset or task. However, adapting a model trained on the abundant source data to a few-shot target dataset or task is challenging. To tackle this challenge, we propose a Meta-Weight Regulator (MWR), which is a meta-learning approach that learns to assign weights to the source examples based on their relevance to the target loss. Specifically, MWR first trains the model on the uniformly weighted source examples, and measures the efficacy of the model on the target examples via a loss function. By iteratively performing a (meta) gradient descent, high-order gradients are propagated to the source examples. These gradients are then used to update the weights of source examples, in a way that is relevant to the target performance. As MWR is model-agnostic, it can be applied to any backbone neural model. Extensive experiments are conducted with various backbone text matching models, on four widely used datasets and two tasks. The results demonstrate that our proposed approach significantly outperforms a number of existing adaptation methods and effectively improves the cross-dataset and cross-task adaptability of the neural text matching models in the few-shot setting.", "paper_url": "http://arxiv.org/abs/2204.12668v1", "pdf_url": "http://arxiv.org/pdf/2204.12668v1", "repo_url": null}, "2204.12637": {"publish_time": "2022-04-27", "title": "Meta-Learning Based Early Fault Detection for Rolling Bearings via Few-Shot Anomaly Detection", "author": "Wenbin Song et.al.", "abstract": "Early fault detection (EFD) of rolling bearings can recognize slight deviation of the health states and contribute to the stability of mechanical systems. In practice, very limited target bearing data are available to conduct EFD, which makes it hard to adapt to the EFD task of new bearings. To address this problem, many transfer learning based EFD methods utilize historical data to learn transferable domain knowledge and conduct early fault detection on new target bearings. However, most existing methods only consider the distribution drift across different working conditions but ignore the difference between bearings under the same working condition, which is called Unit-to-Unit Variability (UtUV). The setting of EFD with limited target data considering UtUV can be formulated as a Few-shot Anomaly Detection task. Therefore, this paper proposes a novel EFD method based on meta-learning considering UtUV. The proposed method can learn a generic metric based on Relation Network (RN) to measure the similarity between normal data and the new arrival target bearing data. Besides, the proposed method utilizes a health state embedding strategy to decrease false alarms. The performance of proposed method is tested on two bearing datasets. The results show that the proposed method can detect incipient faults earlier than the baselines with lower false alarms.", "paper_url": "http://arxiv.org/abs/2204.12637v1", "pdf_url": "http://arxiv.org/pdf/2204.12637v1", "repo_url": null}, "2205.00895": {"publish_time": "2022-05-02", "title": "On the generalization capabilities of FSL methods through domain adaptation: a case study in endoscopic kidney stone image classification", "author": "Mauricio Mendez-Ruiz et.al.", "abstract": "Deep learning has shown great promise in diverse areas of computer vision, such as image classification, object detection and semantic segmentation, among many others. However, as it has been repeatedly demonstrated, deep learning methods trained on a dataset do not generalize well to datasets from other domains or even to similar datasets, due to data distribution shifts. In this work, we propose the use of a meta-learning based few-shot learning approach to alleviate these problems. In order to demonstrate its efficacy, we use two datasets of kidney stones samples acquired with different endoscopes and different acquisition conditions. The results show how such methods are indeed capable of handling domain-shifts by attaining an accuracy of 74.38% and 88.52% in the 5-way 5-shot and 5-way 20-shot settings respectively. Instead, in the same dataset, traditional Deep Learning (DL) methods attain only an accuracy of 45%.", "paper_url": "http://arxiv.org/abs/2205.00895v1", "pdf_url": "http://arxiv.org/pdf/2205.00895v1", "repo_url": null}, "2205.00167": {"publish_time": "2022-04-30", "title": "An Initial Look at Self-Reprogramming Artificial Intelligence", "author": "Alex Sheng et.al.", "abstract": "Rapid progress in deep learning research has greatly extended the capabilities of artificial intelligence technology. Conventional AI models are constrained to explicit human-designed algorithms, although a growing body of work in meta-learning, neural architecture search, and related approaches have explored algorithms that self-modify to some extent. In this paper, we develop and experimentally validate the first fully self-reprogramming AI system. Applying AI-based computer code generation to AI itself, we implement an algorithm with the ability to continuously modify and rewrite its own neural network source code.", "paper_url": "http://arxiv.org/abs/2205.00167v1", "pdf_url": "http://arxiv.org/pdf/2205.00167v1", "repo_url": null}, "2205.00097": {"publish_time": "2022-04-29", "title": "Fast and Scalable Human Pose Estimation using mmWave Point Cloud", "author": "Sizhe An et.al.", "abstract": "Millimeter-Wave (mmWave) radar can enable high-resolution human pose estimation with low cost and computational requirements. However, mmWave data point cloud, the primary input to processing algorithms, is highly sparse and carries significantly less information than other alternatives such as video frames. Furthermore, the scarce labeled mmWave data impedes the development of machine learning (ML) models that can generalize to unseen scenarios. We propose a fast and scalable human pose estimation (FUSE) framework that combines multi-frame representation and meta-learning to address these challenges. Experimental evaluations show that FUSE adapts to the unseen scenarios 4$\\times$ faster than current supervised learning approaches and estimates human joint coordinates with about 7 cm mean absolute error.", "paper_url": "http://arxiv.org/abs/2205.00097v1", "pdf_url": "http://arxiv.org/pdf/2205.00097v1", "repo_url": null}, "2205.00085": {"publish_time": "2022-04-29", "title": "Line of Sight Curvature for Missile Guidance using Reinforcement Meta-Learning", "author": "Brian Gaudet et.al.", "abstract": "We use reinforcement meta learning to optimize a line of sight curvature policy that increases the effectiveness of a guidance system against maneuvering targets. The policy is implemented as a recurrent neural network that maps navigation system outputs to a Euler 321 attitude representation. The attitude representation is then used to construct a direction cosine matrix that biases the observed line of sight vector. The line of sight rotation rate derived from the biased line of sight is then mapped to a commanded acceleration by the guidance system. By varying the bias as a function of navigation system outputs, the policy enhances accuracy against highly maneuvering targets. Importantly, our method does not require an estimate of target acceleration. In our experiments, we demonstrate that when our method is combined with proportional navigation, the system significantly outperforms augmented proportional navigation with perfect knowledge of target acceleration, achieving improved accuracy with less control effort against a wide range of target maneuvers.", "paper_url": "http://arxiv.org/abs/2205.00085v1", "pdf_url": "http://arxiv.org/pdf/2205.00085v1", "repo_url": null}, "2205.01500": {"publish_time": "2022-05-03", "title": "Meta Learning for Natural Language Processing: A Survey", "author": "Hung-yi Lee et.al.", "abstract": "Deep learning has been the mainstream technique in natural language processing (NLP) area. However, the techniques require many labeled data and are less generalizable across domains. Meta-learning is an arising field in machine learning studying approaches to learn better learning algorithms. Approaches aim at improving algorithms in various aspects, including data efficiency and generalizability. Efficacy of approaches has been shown in many NLP tasks, but there is no systematic survey of these approaches in NLP, which hinders more researchers from joining the field. Our goal with this survey paper is to offer researchers pointers to relevant meta-learning works in NLP and attract more attention from the NLP community to drive future innovation. This paper first introduces the general concepts of meta-learning and the common approaches. Then we summarize task construction settings and application of meta-learning for various NLP problems and review the development of meta-learning in NLP community.", "paper_url": "http://arxiv.org/abs/2205.01500v1", "pdf_url": "http://arxiv.org/pdf/2205.01500v1", "repo_url": null}, "2205.02708": {"publish_time": "2022-05-05", "title": "Meta-learning Feature Representations for Adaptive Gaussian Processes via Implicit Differentiation", "author": "Wenlin Chen et.al.", "abstract": "We propose Adaptive Deep Kernel Fitting (ADKF), a general framework for learning deep kernels by interpolating between meta-learning and conventional learning. Our approach employs a bilevel optimization objective where we meta-learn feature representations that are generally useful across tasks, in the sense that task-specific Gaussian process models estimated on top of such features achieve the lowest possible predictive loss on average across tasks. We solve the resulting nested optimization problem using the implicit function theorem. We show that ADKF contains Deep Kernel Learning and Deep Kernel Transfer as special cases. Although ADKF is a completely general method, we argue that it is especially well-suited for drug discovery problems and demonstrate that it significantly outperforms previous state-of-the-art methods on a variety of real-world few-shot molecular property prediction tasks and out-of-domain molecular optimization tasks.", "paper_url": "http://arxiv.org/abs/2205.02708v1", "pdf_url": "http://arxiv.org/pdf/2205.02708v1", "repo_url": null}, "2205.03231": {"publish_time": "2022-05-03", "title": "Side-aware Meta-Learning for Cross-Dataset Listener Diagnosis with Subjective Tinnitus", "author": "Yun Li et.al.", "abstract": "With the development of digital technology, machine learning has paved the way for the next generation of tinnitus diagnoses. Although machine learning has been widely applied in EEG-based tinnitus analysis, most current models are dataset-specific. Each dataset may be limited to a specific range of symptoms, overall disease severity, and demographic attributes; further, dataset formats may differ, impacting model performance. This paper proposes a side-aware meta-learning for cross-dataset tinnitus diagnosis, which can effectively classify tinnitus in subjects of divergent ages and genders from different data collection processes. Owing to the superiority of meta-learning, our method does not rely on large-scale datasets like conventional deep learning models. Moreover, we design a subject-specific training process to assist the model in fitting the data pattern of different patients or healthy people. Our method achieves a high accuracy of 73.8\\% in the cross-dataset classification. We conduct an extensive analysis to show the effectiveness of side information of ears in enhancing model performance and side-aware meta-learning in improving the quality of the learned features.", "paper_url": "http://arxiv.org/abs/2205.03231v1", "pdf_url": "http://arxiv.org/pdf/2205.03231v1", "repo_url": null}, "2205.04334": {"publish_time": "2022-05-09", "title": "Panoptic Neural Fields: A Semantic Object-Aware Neural Scene Representation", "author": "Abhijit Kundu et.al.", "abstract": "We present Panoptic Neural Fields (PNF), an object-aware neural scene representation that decomposes a scene into a set of objects (things) and background (stuff). Each object is represented by an oriented 3D bounding box and a multi-layer perceptron (MLP) that takes position, direction, and time and outputs density and radiance. The background stuff is represented by a similar MLP that additionally outputs semantic labels. Each object MLPs are instance-specific and thus can be smaller and faster than previous object-aware approaches, while still leveraging category-specific priors incorporated via meta-learned initialization. Our model builds a panoptic radiance field representation of any scene from just color images. We use off-the-shelf algorithms to predict camera poses, object tracks, and 2D image semantic segmentations. Then we jointly optimize the MLP weights and bounding box parameters using analysis-by-synthesis with self-supervision from color images and pseudo-supervision from predicted semantic segmentations. During experiments with real-world dynamic scenes, we find that our model can be used effectively for several tasks like novel view synthesis, 2D panoptic segmentation, 3D scene editing, and multiview depth prediction.", "paper_url": "http://arxiv.org/abs/2205.04334v1", "pdf_url": "http://arxiv.org/pdf/2205.04334v1", "repo_url": null}, "2205.04692": {"publish_time": "2022-05-10", "title": "Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting", "author": "Mingyang Chen et.al.", "abstract": "We study the knowledge extrapolation problem to embed new components (i.e., entities and relations) that come with emerging knowledge graphs (KGs) in the federated setting. In this problem, a model trained on an existing KG needs to embed an emerging KG with unseen entities and relations. To solve this problem, we introduce the meta-learning setting, where a set of tasks are sampled on the existing KG to mimic the link prediction task on the emerging KG. Based on sampled tasks, we meta-train a graph neural network framework that can construct features for unseen components based on structural information and output embeddings for them. Experimental results show that our proposed method can effectively embed unseen components and outperforms models that consider inductive settings for KGs and baselines that directly use conventional KG embedding methods.", "paper_url": "http://arxiv.org/abs/2205.04692v1", "pdf_url": "http://arxiv.org/pdf/2205.04692v1", "repo_url": "https://github.com/zjukg/maker"}, "2205.05831": {"publish_time": "2022-05-12", "title": "Cross-domain Few-shot Meta-learning Using Stacking", "author": "Hongyu Wang et.al.", "abstract": "Cross-domain few-shot meta-learning (CDFSML) addresses learning problems where knowledge needs to be transferred from several source domains into an instance-scarce target domain with an explicitly different input distribution. Recently published CDFSML methods generally construct a \"universal model\" that combines knowledge of multiple source domains into one backbone feature extractor. This enables efficient inference but necessitates re-computation of the backbone whenever a new source domain is added. Moreover, state-of-the-art methods derive their universal model from a collection of backbones -- normally one for each source domain -- and the backbones may be constrained to have the same architecture as the universal model. We propose a CDFSML method that is inspired by the classic stacking approach to meta learning. It imposes no constraints on the backbones' architecture or feature shape and does not incur the computational overhead of (re-)computing a universal model. Given a target-domain task, it fine-tunes each backbone independently, uses cross-validation to extract meta training data from the task's instance-scarce support set, and learns a simple linear meta classifier from this data. We evaluate our stacking approach on the well-known Meta-Dataset benchmark, targeting image classification with convolutional neural networks, and show that it often yields substantially higher accuracy than competing methods.", "paper_url": "http://arxiv.org/abs/2205.05831v1", "pdf_url": "http://arxiv.org/pdf/2205.05831v1", "repo_url": null}, "2205.06182": {"publish_time": "2022-05-11", "title": "Improved Meta Learning for Low Resource Speech Recognition", "author": "Satwinder Singh et.al.", "abstract": "We propose a new meta learning based framework for low resource speech recognition that improves the previous model agnostic meta learning (MAML) approach. The MAML is a simple yet powerful meta learning approach. However, the MAML presents some core deficiencies such as training instabilities and slower convergence speed. To address these issues, we adopt multi-step loss (MSL). The MSL aims to calculate losses at every step of the inner loop of MAML and then combines them with a weighted importance vector. The importance vector ensures that the loss at the last step has more importance than the previous steps. Our empirical evaluation shows that MSL significantly improves the stability of the training procedure and it thus also improves the accuracy of the overall system. Our proposed system outperforms MAML based low resource ASR system on various languages in terms of character error rates and stable training behavior.", "paper_url": "http://arxiv.org/abs/2205.06182v1", "pdf_url": "http://arxiv.org/pdf/2205.06182v1", "repo_url": null}, "2205.06743": {"publish_time": "2022-05-13", "title": "A Comprehensive Survey of Few-shot Learning: Evolution, Applications, Challenges, and Opportunities", "author": "Yisheng Song et.al.", "abstract": "Few-shot learning (FSL) has emerged as an effective learning method and shows great potential. Despite the recent creative works in tackling FSL tasks, learning valid information rapidly from just a few or even zero samples still remains a serious challenge. In this context, we extensively investigated 200+ latest papers on FSL published in the past three years, aiming to present a timely and comprehensive overview of the most recent advances in FSL along with impartial comparisons of the strengths and weaknesses of the existing works. For the sake of avoiding conceptual confusion, we first elaborate and compare a set of similar concepts including few-shot learning, transfer learning, and meta-learning. Furthermore, we propose a novel taxonomy to classify the existing work according to the level of abstraction of knowledge in accordance with the challenges of FSL. To enrich this survey, in each subsection we provide in-depth analysis and insightful discussion about recent advances on these topics. Moreover, taking computer vision as an example, we highlight the important application of FSL, covering various research hotspots. Finally, we conclude the survey with unique insights into the technology evolution trends together with potential future research opportunities in the hope of providing guidance to follow-up research.", "paper_url": "http://arxiv.org/abs/2205.06743v1", "pdf_url": "http://arxiv.org/pdf/2205.06743v1", "repo_url": null}, "2205.06548": {"publish_time": "2022-05-13", "title": "Meta Balanced Network for Fair Face Recognition", "author": "Mei Wang et.al.", "abstract": "Although deep face recognition has achieved impressive progress in recent years, controversy has arisen regarding discrimination based on skin tone, questioning their deployment into real-world scenarios. In this paper, we aim to systematically and scientifically study this bias from both data and algorithm aspects. First, using the dermatologist approved Fitzpatrick Skin Type classification system and Individual Typology Angle, we contribute a benchmark called Identity Shades (IDS) database, which effectively quantifies the degree of the bias with respect to skin tone in existing face recognition algorithms and commercial APIs. Further, we provide two skin-tone aware training datasets, called BUPT-Globalface dataset and BUPT-Balancedface dataset, to remove bias in training data. Finally, to mitigate the algorithmic bias, we propose a novel meta-learning algorithm, called Meta Balanced Network (MBN), which learns adaptive margins in large margin loss such that the model optimized by this loss can perform fairly across people with different skin tones. To determine the margins, our method optimizes a meta skewness loss on a clean and unbiased meta set and utilizes backward-on-backward automatic differentiation to perform a second order gradient descent step on the current margins. Extensive experiments show that MBN successfully mitigates bias and learns more balanced performance for people with different skin tones in face recognition. The proposed datasets are available at http://www.whdeng.cn/RFW/index.html.", "paper_url": "http://arxiv.org/abs/2205.06548v1", "pdf_url": "http://arxiv.org/pdf/2205.06548v1", "repo_url": null}, "2205.06355": {"publish_time": "2022-05-12", "title": "Warm-starting DARTS using meta-learning", "author": "Matej Grobelnik et.al.", "abstract": "Neural architecture search (NAS) has shown great promise in the field of automated machine learning (AutoML). NAS has outperformed hand-designed networks and made a significant step forward in the field of automating the design of deep neural networks, thus further reducing the need for human expertise. However, most research is done targeting a single specific task, leaving research of NAS methods over multiple tasks mostly overlooked. Generally, there exist two popular ways to find an architecture for some novel task. Either searching from scratch, which is ineffective by design, or transferring discovered architectures from other tasks, which provides no performance guarantees and is probably not optimal. In this work, we present a meta-learning framework to warm-start Differentiable architecture search (DARTS). DARTS is a NAS method that can be initialized with a transferred architecture and is able to quickly adapt to new tasks. A task similarity measure is used to determine which transfer architecture is selected, as transfer architectures found on similar tasks will likely perform better. Additionally, we employ a simple meta-transfer architecture that was learned over multiple tasks. Experiments show that warm-started DARTS is able to find competitive performing architectures while reducing searching costs on average by 60%.", "paper_url": "http://arxiv.org/abs/2205.06355v1", "pdf_url": "http://arxiv.org/pdf/2205.06355v1", "repo_url": null}, "2205.06326": {"publish_time": "2022-05-12", "title": "Multi-Environment Meta-Learning in Stochastic Linear Bandits", "author": "Ahmadreza Moradipari et.al.", "abstract": "In this work we investigate meta-learning (or learning-to-learn) approaches in multi-task linear stochastic bandit problems that can originate from multiple environments. Inspired by the work of [1] on meta-learning in a sequence of linear bandit problems whose parameters are sampled from a single distribution (i.e., a single environment), here we consider the feasibility of meta-learning when task parameters are drawn from a mixture distribution instead. For this problem, we propose a regularized version of the OFUL algorithm that, when trained on tasks with labeled environments, achieves low regret on a new task without requiring knowledge of the environment from which the new task originates. Specifically, our regret bound for the new algorithm captures the effect of environment misclassification and highlights the benefits over learning each task separately or meta-learning without recognition of the distinct mixture components.", "paper_url": "http://arxiv.org/abs/2205.06326v1", "pdf_url": "http://arxiv.org/pdf/2205.06326v1", "repo_url": null}, "2205.07315": {"publish_time": "2022-05-15", "title": "Parameter Adaptation for Joint Distribution Shifts", "author": "Siddhartha Datta et.al.", "abstract": "While different methods exist to tackle distinct types of distribution shift, such as label shift (in the form of adversarial attacks) or domain shift, tackling the joint shift setting is still an open problem. Through the study of a joint distribution shift manifesting both adversarial and domain-specific perturbations, we not only show that a joint shift worsens model performance compared to their individual shifts, but that the use of a similar domain worsens performance than a dissimilar domain. To curb the performance drop, we study the use of perturbation sets motivated by input and parameter space bounds, and adopt a meta learning strategy (hypernetworks) to model parameters w.r.t. test-time inputs to recover performance.", "paper_url": "http://arxiv.org/abs/2205.07315v1", "pdf_url": "http://arxiv.org/pdf/2205.07315v1", "repo_url": null}, "2205.06908": {"publish_time": "2022-05-13", "title": "Neural-Fly Enables Rapid Learning for Agile Flight in Strong Winds", "author": "Michael O'Connell et.al.", "abstract": "Executing safe and precise flight maneuvers in dynamic high-speed winds is important for the ongoing commoditization of uninhabited aerial vehicles (UAVs). However, because the relationship between various wind conditions and its effect on aircraft maneuverability is not well understood, it is challenging to design effective robot controllers using traditional control design methods. We present Neural-Fly, a learning-based approach that allows rapid online adaptation by incorporating pretrained representations through deep learning. Neural-Fly builds on two key observations that aerodynamics in different wind conditions share a common representation and that the wind-specific part lies in a low-dimensional space. To that end, Neural-Fly uses a proposed learning algorithm, domain adversarially invariant meta-learning (DAIML), to learn the shared representation, only using 12 minutes of flight data. With the learned representation as a basis, Neural-Fly then uses a composite adaptation law to update a set of linear coefficients for mixing the basis elements. When evaluated under challenging wind conditions generated with the Caltech Real Weather Wind Tunnel, with wind speeds up to 43.6 kilometers/hour (12.1 meters/second), Neural-Fly achieves precise flight control with substantially smaller tracking error than state-of-the-art nonlinear and adaptive controllers. In addition to strong empirical performance, the exponential stability of Neural-Fly results in robustness guarantees. Last, our control design extrapolates to unseen wind conditions, is shown to be effective for outdoor flights with only onboard sensors, and can transfer across drones with minimal performance degradation.", "paper_url": "http://arxiv.org/abs/2205.06908v1", "pdf_url": "http://arxiv.org/pdf/2205.06908v1", "repo_url": "https://github.com/aerorobotics/neural-fly"}, "2205.08957": {"publish_time": "2022-05-18", "title": "Meta-Learning Sparse Compression Networks", "author": "Jonathan Richard Schwarz et.al.", "abstract": "Recent work in Deep Learning has re-imagined the representation of data as functions mapping from a coordinate space to an underlying continuous signal. When such functions are approximated by neural networks this introduces a compelling alternative to the more common multi-dimensional array representation. Recent work on such Implicit Neural Representations (INRs) has shown that - following careful architecture search - INRs can outperform established compression methods such as JPEG (e.g. Dupont et al., 2021). In this paper, we propose crucial steps towards making such ideas scalable: Firstly, we employ stateof-the-art network sparsification techniques to drastically improve compression. Secondly, introduce the first method allowing for sparsification to be employed in the inner-loop of commonly used Meta-Learning algorithms, drastically improving both compression and the computational cost of learning INRs. The generality of this formalism allows us to present results on diverse data modalities such as images, manifolds, signed distance functions, 3D shapes and scenes, several of which establish new state-of-the-art results.", "paper_url": "http://arxiv.org/abs/2205.08957v1", "pdf_url": "http://arxiv.org/pdf/2205.08957v1", "repo_url": null}, "2205.08787": {"publish_time": "2022-05-18", "title": "Cross-subject Action Unit Detection with Meta Learning and Transformer-based Relation Modeling", "author": "Jiyuan Cao et.al.", "abstract": "Facial Action Unit (AU) detection is a crucial task for emotion analysis from facial movements. The apparent differences of different subjects sometimes mislead changes brought by AUs, resulting in inaccurate results. However, most of the existing AU detection methods based on deep learning didn't consider the identity information of different subjects. The paper proposes a meta-learning-based cross-subject AU detection model to eliminate the identity-caused differences. Besides, a transformer-based relation learning module is introduced to learn the latent relations of multiple AUs. To be specific, our proposed work is composed of two sub-tasks. The first sub-task is meta-learning-based AU local region representation learning, called MARL, which learns discriminative representation of local AU regions that incorporates the shared information of multiple subjects and eliminates identity-caused differences. The second sub-task uses the local region representation of AU of the first sub-task as input, then adds relationship learning based on the transformer encoder architecture to capture AU relationships. The entire training process is cascaded. Ablation study and visualization show that our MARL can eliminate identity-caused differences, thus obtaining a robust and generalized AU discriminative embedding representation. Our results prove that on the two public datasets BP4D and DISFA, our method is superior to the state-of-the-art technology, and the F1 score is improved by 1.3% and 1.4%, respectively.", "paper_url": "http://arxiv.org/abs/2205.08787v1", "pdf_url": "http://arxiv.org/pdf/2205.08787v1", "repo_url": null}, "2205.08755": {"publish_time": "2022-05-18", "title": "Persian Natural Language Inference: A Meta-learning approach", "author": "Heydar Soudani et.al.", "abstract": "Incorporating information from other languages can improve the results of tasks in low-resource languages. A powerful method of building functional natural language processing systems for low-resource languages is to combine multilingual pre-trained representations with cross-lingual transfer learning. In general, however, shared representations are learned separately, either across tasks or across languages. This paper proposes a meta-learning approach for inferring natural language in Persian. Alternately, meta-learning uses different task information (such as QA in Persian) or other language information (such as natural language inference in English). Also, we investigate the role of task augmentation strategy for forming additional high-quality tasks. We evaluate the proposed method using four languages and an auxiliary task. Compared to the baseline approach, the proposed model consistently outperforms it, improving accuracy by roughly six percent. We also examine the effect of finding appropriate initial parameters using zero-shot evaluation and CCA similarity.", "paper_url": "http://arxiv.org/abs/2205.08755v1", "pdf_url": "http://arxiv.org/pdf/2205.08755v1", "repo_url": "https://github.com/hassanmojab/metanli"}, "2205.09990": {"publish_time": "2022-05-20", "title": "Set-based Meta-Interpolation for Few-Task Meta-Learning", "author": "Seanie Lee et.al.", "abstract": "Meta-learning approaches enable machine learning systems to adapt to new tasks given few examples by leveraging knowledge from related tasks. However, a large number of meta-training tasks are still required for generalization to unseen tasks during meta-testing, which introduces a critical bottleneck for real-world problems that come with only few tasks, due to various reasons including the difficulty and cost of constructing tasks. Recently, several task augmentation methods have been proposed to tackle this issue using domain-specific knowledge to design augmentation techniques to densify the meta-training task distribution. However, such reliance on domain-specific knowledge renders these methods inapplicable to other domains. While Manifold Mixup based task augmentation methods are domain-agnostic, we empirically find them ineffective on non-image domains. To tackle these limitations, we propose a novel domain-agnostic task augmentation method, Meta-Interpolation, which utilizes expressive neural set functions to densify the meta-training task distribution using bilevel optimization. We empirically validate the efficacy of Meta-Interpolation on eight datasets spanning across various domains such as image classification, molecule property prediction, text classification and speech recognition. Experimentally, we show that Meta-Interpolation consistently outperforms all the relevant baselines. Theoretically, we prove that task interpolation with the set function regularizes the meta-learner to improve generalization.", "paper_url": "http://arxiv.org/abs/2205.09990v1", "pdf_url": "http://arxiv.org/pdf/2205.09990v1", "repo_url": null}, "2205.09930": {"publish_time": "2022-05-20", "title": "BayesPCN: A Continually Learnable Predictive Coding Associative Memory", "author": "Jason Yoo et.al.", "abstract": "Associative memory plays an important role in human intelligence and its mechanisms have been linked to attention in machine learning. While the machine learning community's interest in associative memories has recently been rekindled, most work has focused on memory recall ($read$) over memory learning ($write$). In this paper, we present BayesPCN, a hierarchical associative memory capable of performing continual one-shot memory writes without meta-learning. Moreover, BayesPCN is able to gradually forget past observations ($forget$) to free its memory. Experiments show that BayesPCN can recall corrupted i.i.d. high-dimensional data observed hundreds of \"timesteps\" ago without a significant drop in recall ability compared to the state-of-the-art offline-learned associative memory models.", "paper_url": "http://arxiv.org/abs/2205.09930v1", "pdf_url": "http://arxiv.org/pdf/2205.09930v1", "repo_url": null}, "2205.11110": {"publish_time": "2022-05-23", "title": "Meta-Learning Regrasping Strategies for Physical-Agnostic Objects", "author": "Ruijie Chen et.al.", "abstract": "Grasping inhomogeneous objects, practical use in real-world applications, remains a challenging task due to the unknown physical properties such as mass distribution and coefficient of friction. In this study, we propose a vision-based meta-learning algorithm to learn physical properties in an agnostic way. In particular, we employ Conditional Neural Processes (CNPs) on top of DexNet-2.0. CNPs learn physical embeddings rapidly from a few observations where each observation is composed of i) the cropped depth image, ii) the grasping height between the gripper and estimated grasping point, and iii) the binary grasping result. Our modified conditional DexNet-2.0 (DexNet-CNP) updates the predicted grasping quality iteratively from new observations, which can be executed in an online fashion. We evaluate our method in the Pybullet simulator using various shape primitive objects with different physical parameters. The results show that our model outperforms the original DexNet-2.0 and is able to generalize on unseen objects with different shapes.", "paper_url": "http://arxiv.org/abs/2205.11110v1", "pdf_url": "http://arxiv.org/pdf/2205.11110v1", "repo_url": null}, "2205.10736": {"publish_time": "2022-05-22", "title": "Should Models Be Accurate?", "author": "Esra'a Saleh et.al.", "abstract": "Model-based Reinforcement Learning (MBRL) holds promise for data-efficiency by planning with model-generated experience in addition to learning with experience from the environment. However, in complex or changing environments, models in MBRL will inevitably be imperfect, and their detrimental effects on learning can be difficult to mitigate. In this work, we question whether the objective of these models should be the accurate simulation of environment dynamics at all. We focus our investigations on Dyna-style planning in a prediction setting. First, we highlight and support three motivating points: a perfectly accurate model of environment dynamics is not practically achievable, is not necessary, and is not always the most useful anyways. Second, we introduce a meta-learning algorithm for training models with a focus on their usefulness to the learner instead of their accuracy in modelling the environment. Our experiments show that in a simple non-stationary environment, our algorithm enables faster learning than even using an accurate model built with domain-specific knowledge of the non-stationarity.", "paper_url": "http://arxiv.org/abs/2205.10736v1", "pdf_url": "http://arxiv.org/pdf/2205.10736v1", "repo_url": null}, "2205.11264": {"publish_time": "2022-05-20", "title": "Adaptive Fairness-Aware Online Meta-Learning for Changing Environments", "author": "Chen Zhao et.al.", "abstract": "The fairness-aware online learning framework has arisen as a powerful tool for the continual lifelong learning setting. The goal for the learner is to sequentially learn new tasks where they come one after another over time and the learner ensures the statistic parity of the new coming task across different protected sub-populations (e.g. race and gender). A major drawback of existing methods is that they make heavy use of the i.i.d assumption for data and hence provide static regret analysis for the framework. However, low static regret cannot imply a good performance in changing environments where tasks are sampled from heterogeneous distributions. To address the fairness-aware online learning problem in changing environments, in this paper, we first construct a novel regret metric FairSAR by adding long-term fairness constraints onto a strongly adapted loss regret. Furthermore, to determine a good model parameter at each round, we propose a novel adaptive fairness-aware online meta-learning algorithm, namely FairSAOML, which is able to adapt to changing environments in both bias control and model precision. The problem is formulated in the form of a bi-level convex-concave optimization with respect to the model's primal and dual parameters that are associated with the model's accuracy and fairness, respectively. The theoretic analysis provides sub-linear upper bounds for both loss regret and violation of cumulative fairness constraints. Our experimental evaluation on different real-world datasets with settings of changing environments suggests that the proposed FairSAOML significantly outperforms alternatives based on the best prior online learning approaches.", "paper_url": "http://arxiv.org/abs/2205.11264v1", "pdf_url": "http://arxiv.org/pdf/2205.11264v1", "repo_url": null}, "2205.10362": {"publish_time": "2022-05-20", "title": "FIND:Explainable Framework for Meta-learning", "author": "Xinyue Shao et.al.", "abstract": "Meta-learning is used to efficiently enable the automatic selection of machine learning models by combining data and prior knowledge. Since the traditional meta-learning technique lacks explainability, as well as shortcomings in terms of transparency and fairness, achieving explainability for meta-learning is crucial. This paper proposes FIND, an interpretable meta-learning framework that not only can explain the recommendation results of meta-learning algorithm selection, but also provide a more complete and accurate explanation of the recommendation algorithm's performance on specific datasets combined with business scenarios. The validity and correctness of this framework have been demonstrated by extensive experiments.", "paper_url": "http://arxiv.org/abs/2205.10362v1", "pdf_url": "http://arxiv.org/pdf/2205.10362v1", "repo_url": null}, "2205.11799": {"publish_time": "2022-05-24", "title": "Formulating Few-shot Fine-tuning Towards Language Model Pre-training: A Pilot Study on Named Entity Recognition", "author": "Zihan Wang et.al.", "abstract": "Fine-tuning pre-trained language models has recently become a common practice in building NLP models for various tasks, especially few-shot tasks. We argue that under the few-shot setting, formulating fine-tuning closer to the pre-training objectives shall be able to unleash more benefits from the pre-trained language models. In this work, we take few-shot named entity recognition (NER) for a pilot study, where existing fine-tuning strategies are much different from pre-training. We propose a novel few-shot fine-tuning framework for NER, FFF-NER. Specifically, we introduce three new types of tokens, \"is-entity\", \"which-type\" and bracket, so we can formulate the NER fine-tuning as (masked) token prediction or generation, depending on the choice of pre-trained language models. In our experiments, we apply FFF-NER to fine-tune both BERT and BART for few-shot NER on several benchmark datasets and observe significant improvements over existing fine-tuning strategies, including sequence labeling, prototype meta-learning, and prompt-based approaches. We further perform a series of ablation studies, showing few-shot NER performance is strongly correlated with the similarity between fine-tuning and pre-training.", "paper_url": "http://arxiv.org/abs/2205.11799v1", "pdf_url": "http://arxiv.org/pdf/2205.11799v1", "repo_url": null}, "2205.11558": {"publish_time": "2022-05-23", "title": "Using Natural Language and Program Abstractions to Instill Human Inductive Biases in Machines", "author": "Sreejan Kumar et.al.", "abstract": "Strong inductive biases are a key component of human intelligence, allowing people to quickly learn a variety of tasks. Although meta-learning has emerged as an approach for endowing neural networks with useful inductive biases, agents trained by meta-learning may acquire very different strategies from humans. We show that co-training these agents on predicting representations from natural language task descriptions and from programs induced to generate such tasks guides them toward human-like inductive biases. Human-generated language descriptions and program induction with library learning both result in more human-like behavior in downstream meta-reinforcement learning agents than less abstract controls (synthetic language descriptions, program induction without library learning), suggesting that the abstraction supported by these representations is key.", "paper_url": "http://arxiv.org/abs/2205.11558v1", "pdf_url": "http://arxiv.org/pdf/2205.11558v1", "repo_url": null}, "2205.12475": {"publish_time": "2022-05-25", "title": "Low Resource Style Transfer via Domain Adaptive Meta Learning", "author": "Xiangyang Li et.al.", "abstract": "Text style transfer (TST) without parallel data has achieved some practical success. However, most of the existing unsupervised text style transfer methods suffer from (i) requiring massive amounts of non-parallel data to guide transferring different text styles. (ii) colossal performance degradation when fine-tuning the model in new domains. In this work, we propose DAML-ATM (Domain Adaptive Meta-Learning with Adversarial Transfer Model), which consists of two parts: DAML and ATM. DAML is a domain adaptive meta-learning approach to learn general knowledge in multiple heterogeneous source domains, capable of adapting to new unseen domains with a small amount of data. Moreover, we propose a new unsupervised TST approach Adversarial Transfer Model (ATM), composed of a sequence-to-sequence pre-trained language model and uses adversarial style training for better content preservation and style transfer. Results on multi-domain datasets demonstrate that our approach generalizes well on unseen low-resource domains, achieving state-of-the-art results against ten strong baselines.", "paper_url": "http://arxiv.org/abs/2205.12475v1", "pdf_url": "http://arxiv.org/pdf/2205.12475v1", "repo_url": null}, "2205.12471": {"publish_time": "2022-05-25", "title": "Learning a Better Initialization for Soft Prompts via Meta-Learning", "author": "Yukun Huang et.al.", "abstract": "Prompt tuning (PT) is an effective approach to adapting pre-trained language models to downstream tasks. Without a good initialization, prompt tuning doesn't perform well under few-shot settings. So pre-trained prompt tuning (PPT) is proposed to initialize prompts by leveraging pre-training data. We propose MetaPT (Meta-learned Prompt Tuning) to further improve PPT's initialization by considering latent structure within the pre-training data. Specifically, we introduce the structure by first clustering pre-training data into different auxiliary tasks with unsupervised methods. Then we use these tasks to pre-train prompts with a meta-learning algorithm. Such a process can make prompts learn a better initialization by discovering commonalities among these auxiliary tasks. We evaluate our method on seven downstream tasks. Our MetaPT achieves better and more stable performance than the state-of-the-art method.", "paper_url": "http://arxiv.org/abs/2205.12471v1", "pdf_url": "http://arxiv.org/pdf/2205.12471v1", "repo_url": null}, "2205.12453": {"publish_time": "2022-05-25", "title": "Know Where You're Going: Meta-Learning for Parameter-Efficient Fine-tuning", "author": "Mozhdeh Gheini et.al.", "abstract": "A recent family of techniques, dubbed as lightweight fine-tuning methods, facilitates parameter-efficient transfer learning by updating only a small set of additional parameters while keeping the parameters of the pretrained language model frozen. While proven to be an effective method, there are no existing studies on if and how such knowledge of the downstream fine-tuning approach should affect the pretraining stage. In this work, we show that taking the ultimate choice of fine-tuning method into consideration boosts the performance of parameter-efficient fine-tuning. By relying on optimization-based meta-learning using MAML with certain modifications for our distinct purpose, we prime the pretrained model specifically for parameter-efficient fine-tuning, resulting in gains of up to 1.7 points on cross-lingual NER fine-tuning. Our ablation settings and analyses further reveal that the tweaks we introduce in MAML are crucial for the attained gains.", "paper_url": "http://arxiv.org/abs/2205.12453v1", "pdf_url": "http://arxiv.org/pdf/2205.12453v1", "repo_url": null}, "2205.12407": {"publish_time": "2022-05-24", "title": "Convolutional Neural Processes for Inpainting Satellite Images", "author": "Alexander Pondaven et.al.", "abstract": "The widespread availability of satellite images has allowed researchers to model complex systems such as disease dynamics. However, many satellite images have missing values due to measurement defects, which render them unusable without data imputation. For example, the scanline corrector for the LANDSAT 7 satellite broke down in 2003, resulting in a loss of around 20\\% of its data. Inpainting involves predicting what is missing based on the known pixels and is an old problem in image processing, classically based on PDEs or interpolation methods, but recent deep learning approaches have shown promise. However, many of these methods do not explicitly take into account the inherent spatiotemporal structure of satellite images. In this work, we cast satellite image inpainting as a natural meta-learning problem, and propose using convolutional neural processes (ConvNPs) where we frame each satellite image as its own task or 2D regression problem. We show ConvNPs can outperform classical methods and state-of-the-art deep learning inpainting models on a scanline inpainting problem for LANDSAT 7 satellite images, assessed on a variety of in and out-of-distribution images.", "paper_url": "http://arxiv.org/abs/2205.12407v1", "pdf_url": "http://arxiv.org/pdf/2205.12407v1", "repo_url": null}, "2205.13320": {"publish_time": "2022-05-26", "title": "Towards Learning Universal Hyperparameter Optimizers with Transformers", "author": "Yutian Chen et.al.", "abstract": "Meta-learning hyperparameter optimization (HPO) algorithms from prior experiments is a promising approach to improve optimization efficiency over objective functions from a similar distribution. However, existing methods are restricted to learning from experiments sharing the same set of hyperparameters. In this paper, we introduce the OptFormer, the first text-based Transformer HPO framework that provides a universal end-to-end interface for jointly learning policy and function prediction when trained on vast tuning data from the wild. Our extensive experiments demonstrate that the OptFormer can imitate at least 7 different HPO algorithms, which can be further improved via its function uncertainty estimates. Compared to a Gaussian Process, the OptFormer also learns a robust prior distribution for hyperparameter response functions, and can thereby provide more accurate and better calibrated predictions. This work paves the path to future extensions for training a Transformer-based model as a general HPO optimizer.", "paper_url": "http://arxiv.org/abs/2205.13320v1", "pdf_url": "http://arxiv.org/pdf/2205.13320v1", "repo_url": null}, "2205.13225": {"publish_time": "2022-05-26", "title": "Collaborative Distillation Meta Learning for Simulation Intensive Hardware Design", "author": "Haeyeon Kim et.al.", "abstract": "This paper proposes a novel collaborative distillation meta learning (CDML) framework for simulation intensive hardware design problems. Deep reinforcement learning (DRL) has shown promising performance in various hardware design problems. However, previous works on DRL-based hardware design only dealt with problems with simplified objectives, which are not practical. In fact, the objective evaluation of real-world electrical performance through simulation is costly in terms of both time and computation, making DRL scheme involving extensive reward calculations not suitable. In this paper, we apply the CDML framework to decoupling capacitor placement problem (DPP), one of the significant simulation intensive hardware design problems. The CDML framework consists of a context-based meta learner and collaborative distillation scheme to produce a reusable solver. The context-based meta learner captures the location of probing port (i.e., target circuit block) and improves generalization capability. The collaborative distillation scheme with equivariant label transformation imposes the action-permutation (AP)-equivariant nature of placement problems, which not only improves sample efficiency but also improves generalization capability. Extensive experimental results verified that our CDML outperforms both neural baselines and iterative conventional design methods in terms of real-world objective, power integrity, with zero-shot transfer-ability.", "paper_url": "http://arxiv.org/abs/2205.13225v1", "pdf_url": "http://arxiv.org/pdf/2205.13225v1", "repo_url": null}, "2205.14128": {"publish_time": "2022-05-27", "title": "Meta-Learning Adversarial Bandits", "author": "Maria-Florina Balcan et.al.", "abstract": "We study online learning with bandit feedback across multiple tasks, with the goal of improving average performance across tasks if they are similar according to some natural task-similarity measure. As the first to target the adversarial setting, we design a unified meta-algorithm that yields setting-specific guarantees for two important cases: multi-armed bandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-algorithm tunes the initialization, step-size, and entropy parameter of the Tsallis-entropy generalization of the well-known Exp3 method, with the task-averaged regret provably improving if the entropy of the distribution over estimated optima-in-hindsight is small. For BLO, we learn the initialization, step-size, and boundary-offset of online mirror descent (OMD) with self-concordant barrier regularizers, showing that task-averaged regret varies directly with a measure induced by these functions on the interior of the action space. Our adaptive guarantees rely on proving that unregularized follow-the-leader combined with multiplicative weights is enough to online learn a non-smooth and non-convex sequence of affine functions of Bregman divergences that upper-bound the regret of OMD.", "paper_url": "http://arxiv.org/abs/2205.14128v1", "pdf_url": "http://arxiv.org/pdf/2205.14128v1", "repo_url": null}, "2205.13947": {"publish_time": "2022-05-27", "title": "Spatio-Temporal Graph Few-Shot Learning with Cross-City Knowledge Transfer", "author": "Bin Lu et.al.", "abstract": "Spatio-temporal graph learning is a key method for urban computing tasks, such as traffic flow, taxi demand and air quality forecasting. Due to the high cost of data collection, some developing cities have few available data, which makes it infeasible to train a well-performed model. To address this challenge, cross-city knowledge transfer has shown its promise, where the model learned from data-sufficient cities is leveraged to benefit the learning process of data-scarce cities. However, the spatio-temporal graphs among different cities show irregular structures and varied features, which limits the feasibility of existing Few-Shot Learning (\\emph{FSL}) methods. Therefore, we propose a model-agnostic few-shot learning framework for spatio-temporal graph called ST-GFSL. Specifically, to enhance feature extraction by transfering cross-city knowledge, ST-GFSL proposes to generate non-shared parameters based on node-level meta knowledge. The nodes in target city transfer the knowledge via parameter matching, retrieving from similar spatio-temporal characteristics. Furthermore, we propose to reconstruct the graph structure during meta-learning. The graph reconstruction loss is defined to guide structure-aware learning, avoiding structure deviation among different datasets. We conduct comprehensive experiments on four traffic speed prediction benchmarks and the results demonstrate the effectiveness of ST-GFSL compared with state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2205.13947v1", "pdf_url": "http://arxiv.org/pdf/2205.13947v1", "repo_url": null}, "2205.15271": {"publish_time": "2022-05-30", "title": "MetaSSD: Meta-Learned Self-Supervised Detection", "author": "Moon Jeong Park et.al.", "abstract": "Deep learning-based symbol detector gains increasing attention due to the simple algorithm design than the traditional model-based algorithms such as Viterbi and BCJR. The supervised learning framework is often employed to predict the input symbols, where training symbols are used to train the model. There are two major limitations in the supervised approaches: a) a model needs to be retrained from scratch when new train symbols come to adapt to a new channel status, and b) the length of the training symbols needs to be longer than a certain threshold to make the model generalize well on unseen symbols. To overcome these challenges, we propose a meta-learning-based self-supervised symbol detector named MetaSSD. Our contribution is two-fold: a) meta-learning helps the model adapt to a new channel environment based on experience with various meta-training environments, and b) self-supervised learning helps the model to use relatively less supervision than the previously suggested learning-based detectors. In experiments, MetaSSD outperforms OFDM-MMSE with noisy channel information and shows comparable results with BCJR. Further ablation studies show the necessity of each component in our framework.", "paper_url": "http://arxiv.org/abs/2205.15271v1", "pdf_url": "http://arxiv.org/pdf/2205.15271v1", "repo_url": "https://github.com/ml-postech/metassd"}, "2205.15219": {"publish_time": "2022-05-30", "title": "Automatic Short Math Answer Grading via In-context Meta-learning", "author": "Mengxue Zhang et.al.", "abstract": "Automatic short answer grading is an important research direction in the exploration of how to use artificial intelligence (AI)-based tools to improve education. Current state-of-the-art approaches use neural language models to create vectorized representations of students responses, followed by classifiers to predict the score. However, these approaches have several key limitations, including i) they use pre-trained language models that are not well-adapted to educational subject domains and/or student-generated text and ii) they almost always train one model per question, ignoring the linkage across a question and result in a significant model storage problem due to the size of advanced language models. In this paper, we study the problem of automatic short answer grading for students' responses to math questions and propose a novel framework for this task. First, we use MathBERT, a variant of the popular language model BERT adapted to mathematical content, as our base model and fine-tune it for the downstream task of student response grading. Second, we use an in-context learning approach that provides scoring examples as input to the language model to provide additional context information and promote generalization to previously unseen questions. We evaluate our framework on a real-world dataset of student responses to open-ended math questions and show that our framework (often significantly) outperforms existing approaches, especially for new questions that are not seen during training.", "paper_url": "http://arxiv.org/abs/2205.15219v1", "pdf_url": "http://arxiv.org/pdf/2205.15219v1", "repo_url": "https://github.com/kikumaru818/meta_math_scoring"}, "2205.15100": {"publish_time": "2022-05-30", "title": "Meta Representation Learning with Contextual Linear Bandits", "author": "Leonardo Cella et.al.", "abstract": "Meta-learning seeks to build algorithms that rapidly learn how to solve new learning problems based on previous experience. In this paper we investigate meta-learning in the setting of stochastic linear bandit tasks. We assume that the tasks share a low dimensional representation, which has been partially acquired from previous learning tasks. We aim to leverage this information in order to learn a new downstream bandit task, which shares the same representation. Our principal contribution is to show that if the learned representation estimates well the unknown one, then the downstream task can be efficiently learned by a greedy policy that we propose in this work. We derive an upper bound on the regret of this policy, which is, up to logarithmic factors, of order $r\\sqrt{N}(1\\vee \\sqrt{d/T})$, where $N$ is the horizon of the downstream task, $T$ is the number of training tasks, $d$ the ambient dimension and $r \\ll d$ the dimension of the representation. We highlight that our strategy does not need to know $r$. We note that if $T> d$ our bound achieves the same rate of optimal minimax bandit algorithms using the true underlying representation. Our analysis is inspired and builds in part upon previous work on meta-learning in the i.i.d. full information setting \\citep{tripuraneni2021provable,boursier2022trace}. As a separate contribution we show how to relax certain assumptions in those works, thereby improving their representation learning and risk analysis.", "paper_url": "http://arxiv.org/abs/2205.15100v1", "pdf_url": "http://arxiv.org/pdf/2205.15100v1", "repo_url": null}, "2205.15014": {"publish_time": "2022-05-30", "title": "Task-Prior Conditional Variational Auto-Encoder for Few-Shot Image Classification", "author": "Zaiyun Yang et.al.", "abstract": "Transductive methods always outperform inductive methods in few-shot image classification scenarios. However, the existing few-shot methods contain a latent condition: the number of samples in each class is the same, which may be unrealistic. To cope with those cases where the query shots of each class are nonuniform (i.e. nonuniform few-shot learning), we propose a Task-Prior Conditional Variational Auto-Encoder model named TP-VAE, conditioned on support shots and constrained by a task-level prior regularization. Our method obtains high performance in the more challenging nonuniform few-shot scenarios. Moreover, our method outperforms the state-of-the-art in a wide range of standard few-shot image classification scenarios. Among them, the accuracy of 1-shot increased by about 3\\%.", "paper_url": "http://arxiv.org/abs/2205.15014v1", "pdf_url": "http://arxiv.org/pdf/2205.15014v1", "repo_url": null}, "2205.14834": {"publish_time": "2022-05-30", "title": "GraMeR: Graph Meta Reinforcement Learning for Multi-Objective Influence Maximization", "author": "Sai Munikoti et.al.", "abstract": "Influence maximization (IM) is a combinatorial problem of identifying a subset of nodes called the seed nodes in a network (graph), which when activated, provide a maximal spread of influence in the network for a given diffusion model and a budget for seed set size. IM has numerous applications such as viral marketing, epidemic control, sensor placement and other network-related tasks. However, the uses are limited due to the computational complexity of current algorithms. Recently, learning heuristics for IM have been explored to ease the computational burden. However, there are serious limitations in current approaches such as: (1) IM formulations only consider influence via spread and ignore self activation; (2) scalability to large graphs; (3) generalizability across graph families; (4) low computational efficiency with a large running time to identify seed sets for every test network. In this work, we address each of these limitations through a unique approach that involves (1) formulating a generic IM problem as a Markov decision process that handles both intrinsic and influence activations; (2) employing double Q learning to estimate seed nodes; (3) ensuring scalability via sub-graph based representations; and (4) incorporating generalizability via meta-learning across graph families. Extensive experiments are carried out in various standard networks to validate performance of the proposed Graph Meta Reinforcement learning (GraMeR) framework. The results indicate that GraMeR is multiple orders faster and generic than conventional approaches.", "paper_url": "http://arxiv.org/abs/2205.14834v1", "pdf_url": "http://arxiv.org/pdf/2205.14834v1", "repo_url": null}, "2205.15921": {"publish_time": "2022-05-31", "title": "Online Meta-Learning in Adversarial Multi-Armed Bandits", "author": "Ilya Osadchiy et.al.", "abstract": "We study meta-learning for adversarial multi-armed bandits. We consider the online-within-online setup, in which a player (learner) encounters a sequence of multi-armed bandit episodes. The player's performance is measured as regret against the best arm in each episode, according to the losses generated by an adversary. The difficulty of the problem depends on the empirical distribution of the per-episode best arm chosen by the adversary. We present an algorithm that can leverage the non-uniformity in this empirical distribution, and derive problem-dependent regret bounds. This solution comprises an inner learner that plays each episode separately, and an outer learner that updates the hyper-parameters of the inner algorithm between the episodes. In the case where the best arm distribution is far from uniform, it improves upon the best bound that can be achieved by any online algorithm executed on each episode individually without meta-learning.", "paper_url": "http://arxiv.org/abs/2205.15921v1", "pdf_url": "http://arxiv.org/pdf/2205.15921v1", "repo_url": null}, "2205.15745": {"publish_time": "2022-05-31", "title": "HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks", "author": "M. Przewi\u0119\u017alikowski et.al.", "abstract": "The aim of Few-Shot learning methods is to train models which can easily adapt to previously unseen tasks, based on small amounts of data. One of the most popular and elegant Few-Shot learning approaches is Model-Agnostic Meta-Learning (MAML). The main idea behind this method is to learn the general weights of the meta-model, which are further adapted to specific problems in a small number of gradient steps. However, the model's main limitation lies in the fact that the update procedure is realized by gradient-based optimisation. In consequence, MAML cannot always modify weights to the essential level in one or even a few gradient iterations. On the other hand, using many gradient steps results in a complex and time-consuming optimization procedure, which is hard to train in practice, and may lead to overfitting. In this paper, we propose HyperMAML, a novel generalization of MAML, where the training of the update procedure is also part of the model. Namely, in HyperMAML, instead of updating the weights with gradient descent, we use for this purpose a trainable Hypernetwork. Consequently, in this framework, the model can generate significant updates whose range is not limited to a fixed number of gradient steps. Experiments show that HyperMAML consistently outperforms MAML and performs comparably to other state-of-the-art techniques in a number of standard Few-Shot learning benchmarks.", "paper_url": "http://arxiv.org/abs/2205.15745v1", "pdf_url": "http://arxiv.org/pdf/2205.15745v1", "repo_url": null}, "2205.15619": {"publish_time": "2022-05-31", "title": "Meta-ticket: Finding optimal subnetworks for few-shot learning within randomly initialized neural networks", "author": "Daiki Chijiwa et.al.", "abstract": "Few-shot learning for neural networks (NNs) is an important problem that aims to train NNs with a few data. The main challenge is how to avoid overfitting since over-parameterized NNs can easily overfit to such small dataset. Previous work (e.g. MAML by Finn et al. 2017) tackles this challenge by meta-learning, which learns how to learn from a few data by using various tasks. On the other hand, one conventional approach to avoid overfitting is restricting hypothesis spaces by endowing sparse NN structures like convolution layers in computer vision. However, although such manually-designed sparse structures are sample-efficient for sufficiently large datasets, they are still insufficient for few-shot learning. Then the following questions naturally arise: (1) Can we find sparse structures effective for few-shot learning by meta-learning? (2) What benefits will it bring in terms of meta-generalization? In this work, we propose a novel meta-learning approach, called Meta-ticket, to find optimal sparse subnetworks for few-shot learning within randomly initialized NNs. We empirically validated that Meta-ticket successfully discover sparse subnetworks that can learn specialized features for each given task. Due to this task-wise adaptation ability, Meta-ticket achieves superior meta-generalization compared to MAML-based methods especially with large NNs.", "paper_url": "http://arxiv.org/abs/2205.15619v1", "pdf_url": "http://arxiv.org/pdf/2205.15619v1", "repo_url": "https://github.com/dchiji-ntt/meta-ticket"}, "2206.00092": {"publish_time": "2022-05-31", "title": "FHIST: A Benchmark for Few-shot Classification of Histological Images", "author": "Fereshteh Shakeri et.al.", "abstract": "Few-shot learning has recently attracted wide interest in image classification, but almost all the current public benchmarks are focused on natural images. The few-shot paradigm is highly relevant in medical-imaging applications due to the scarcity of labeled data, as annotations are expensive and require specialized expertise. However, in medical imaging, few-shot learning research is sparse, limited to private data sets and is at its early stage. In particular, the few-shot setting is of high interest in histology due to the diversity and fine granularity of cancer related tissue classification tasks, and the variety of data-preparation techniques. This paper introduces a highly diversified public benchmark, gathered from various public datasets, for few-shot histology data classification. We build few-shot tasks and base-training data with various tissue types, different levels of domain shifts stemming from various cancer sites, and different class-granularity levels, thereby reflecting realistic scenarios. We evaluate the performances of state-of-the-art few-shot learning methods on our benchmark, and observe that simple fine-tuning and regularization methods achieve better results than the popular meta-learning and episodic-training paradigm. Furthermore, we introduce three scenarios based on the domain shifts between the source and target histology data: near-domain, middle-domain and out-domain. Our experiments display the potential of few-shot learning in histology classification, with state-of-art few shot learning methods approaching the supervised-learning baselines in the near-domain setting. In our out-domain setting, for 5-way 5-shot, the best performing method reaches 60% accuracy. We believe that our work could help in building realistic evaluations and fair comparisons of few-shot learning methods and will further encourage research in the few-shot paradigm.", "paper_url": "http://arxiv.org/abs/2206.00092v1", "pdf_url": "http://arxiv.org/pdf/2206.00092v1", "repo_url": null}, "2206.00047": {"publish_time": "2022-05-31", "title": "Evolving Domain Generalization", "author": "Wei Wang et.al.", "abstract": "Domain generalization aims to learn a predictive model from multiple different but related source tasks that can generalize well to a target task without the need of accessing any target data. Existing domain generalization methods ignore the relationship between tasks, implicitly assuming that all the tasks are sampled from a stationary environment. Therefore, they can fail when deployed in an evolving environment. To this end, we formulate and study the \\emph{evolving domain generalization} (EDG) scenario, which exploits not only the source data but also their evolving pattern to generate a model for the unseen task. Our theoretical result reveals the benefits of modeling the relation between two consecutive tasks by learning a globally consistent directional mapping function. In practice, our analysis also suggests solving the DDG problem in a meta-learning manner, which leads to \\emph{directional prototypical network}, the first method for the DDG problem. Empirical evaluation of both synthetic and real-world data sets validates the effectiveness of our approach.", "paper_url": "http://arxiv.org/abs/2206.00047v1", "pdf_url": "http://arxiv.org/pdf/2206.00047v1", "repo_url": null}, "2206.00787": {"publish_time": "2022-06-01", "title": "On the Generalization of Neural Combinatorial Optimization Heuristics", "author": "Sahil Manchanda et.al.", "abstract": "Neural Combinatorial Optimization approaches have recently leveraged the expressiveness and flexibility of deep neural networks to learn efficient heuristics for hard Combinatorial Optimization (CO) problems. However, most of the current methods lack generalization: for a given CO problem, heuristics which are trained on instances with certain characteristics underperform when tested on instances with different characteristics. While some previous works have focused on varying the training instances properties, we postulate that a one-size-fit-all model is out of reach. Instead, we formalize solving a CO problem over a given instance distribution as a separate learning task and investigate meta-learning techniques to learn a model on a variety of tasks, in order to optimize its capacity to adapt to new tasks. Through extensive experiments, on two CO problems, using both synthetic and realistic instances, we show that our proposed meta-learning approach significantly improves the generalization of two state-of-the-art models.", "paper_url": "http://arxiv.org/abs/2206.00787v1", "pdf_url": "http://arxiv.org/pdf/2206.00787v1", "repo_url": null}, "2206.00719": {"publish_time": "2022-06-01", "title": "Dataset Distillation using Neural Feature Regression", "author": "Yongchao Zhou et.al.", "abstract": "Dataset distillation aims to learn a small synthetic dataset that preserves most of the information from the original dataset. Dataset distillation can be formulated as a bi-level meta-learning problem where the outer loop optimizes the meta-dataset and the inner loop trains a model on the distilled data. Meta-gradient computation is one of the key challenges in this formulation, as differentiating through the inner loop learning procedure introduces significant computation and memory costs. In this paper, we address these challenges using neural Feature Regression with Pooling (FRePo), achieving the state-of-the-art performance with an order of magnitude less memory requirement and two orders of magnitude faster training than previous methods. The proposed algorithm is analogous to truncated backpropagation through time with a pool of models to alleviate various types of overfitting in dataset distillation. FRePo significantly outperforms the previous methods on CIFAR100, Tiny ImageNet, and ImageNet-1K. Furthermore, we show that high-quality distilled data can greatly improve various downstream applications, such as continual learning and membership inference defense.", "paper_url": "http://arxiv.org/abs/2206.00719v1", "pdf_url": "http://arxiv.org/pdf/2206.00719v1", "repo_url": null}, "2206.00694": {"publish_time": "2022-06-01", "title": "Meta-SysId: A Meta-Learning Approach for Simultaneous Identification and Prediction", "author": "Junyoung Park et.al.", "abstract": "In this paper, we propose Meta-SysId, a meta-learning approach to model sets of systems that have behavior governed by common but unknown laws and that differentiate themselves by their context. Inspired by classical modeling-and-identification approaches, Meta-SysId learns to represent the common law through shared parameters and relies on online optimization to compute system-specific context. Compared to optimization-based meta-learning methods, the separation between class parameters and context variables reduces the computational burden while allowing batch computations and a simple training scheme. We test Meta-SysId on polynomial regression, time-series prediction, model-based control, and real-world traffic prediction domains, empirically finding it outperforms or is competitive with meta-learning baselines.", "paper_url": "http://arxiv.org/abs/2206.00694v1", "pdf_url": "http://arxiv.org/pdf/2206.00694v1", "repo_url": null}, "2206.01690": {"publish_time": "2022-06-03", "title": "Dynamic Kernel Selection for Improved Generalization and Memory Efficiency in Meta-learning", "author": "Arnav Chavan et.al.", "abstract": "Gradient based meta-learning methods are prone to overfit on the meta-training set, and this behaviour is more prominent with large and complex networks. Moreover, large networks restrict the application of meta-learning models on low-power edge devices. While choosing smaller networks avoid these issues to a certain extent, it affects the overall generalization leading to reduced performance. Clearly, there is an approximately optimal choice of network architecture that is best suited for every meta-learning problem, however, identifying it beforehand is not straightforward. In this paper, we present MetaDOCK, a task-specific dynamic kernel selection strategy for designing compressed CNN models that generalize well on unseen tasks in meta-learning. Our method is based on the hypothesis that for a given set of similar tasks, not all kernels of the network are needed by each individual task. Rather, each task uses only a fraction of the kernels, and the selection of the kernels per task can be learnt dynamically as a part of the inner update steps. MetaDOCK compresses the meta-model as well as the task-specific inner models, thus providing significant reduction in model size for each task, and through constraining the number of active kernels for every task, it implicitly mitigates the issue of meta-overfitting. We show that for the same inference budget, pruned versions of large CNN models obtained using our approach consistently outperform the conventional choices of CNN models. MetaDOCK couples well with popular meta-learning approaches such as iMAML. The efficacy of our method is validated on CIFAR-fs and mini-ImageNet datasets, and we have observed that our approach can provide improvements in model accuracy of up to 2% on standard meta-learning benchmark, while reducing the model size by more than 75%.", "paper_url": "http://arxiv.org/abs/2206.01690v1", "pdf_url": "http://arxiv.org/pdf/2206.01690v1", "repo_url": null}, "2206.01408": {"publish_time": "2022-06-03", "title": "MetaLR: Layer-wise Learning Rate based on Meta-Learning for Adaptively Fine-tuning Medical Pre-trained Models", "author": "Yixiong Chen et.al.", "abstract": "When applying transfer learning for medical image analysis, downstream tasks often have significant gaps with the pre-training tasks. Previous methods mainly focus on improving the transferabilities of the pre-trained models to bridge the gaps. In fact, model fine-tuning can also play a very important role in tackling this problem. A conventional fine-tuning method is updating all deep neural networks (DNNs) layers by a single learning rate (LR), which ignores the unique transferabilities of different layers. In this work, we explore the behaviors of different layers in the fine-tuning stage. More precisely, we first hypothesize that lower-level layers are more domain-specific while higher-level layers are more task-specific, which is verified by a simple bi-directional fine-tuning scheme. It is harder for the pre-trained specific layers to transfer to new tasks than general layers. On this basis, to make different layers better co-adapt to the downstream tasks according to their transferabilities, a meta-learning-based LR learner, namely MetaLR, is proposed to assign LRs for each layer automatically. Extensive experiments on various medical applications (i.e., POCUS, BUSI, Chest X-ray, and LiTS) well confirm our hypothesis and show the superior performance of the proposed methods to previous state-of-the-art fine-tuning methods.", "paper_url": "http://arxiv.org/abs/2206.01408v1", "pdf_url": "http://arxiv.org/pdf/2206.01408v1", "repo_url": null}, "2206.02780": {"publish_time": "2022-06-06", "title": "GenSDF: Two-Stage Learning of Generalizable Signed Distance Functions", "author": "Gene Chou et.al.", "abstract": "We investigate the generalization capabilities of neural signed distance functions (SDFs) for learning 3D object representations for unseen and unlabeled point clouds. Existing methods can fit SDFs to a handful of object classes and boast fine detail or fast inference speeds, but do not generalize well to unseen shapes. We introduce a two-stage semi-supervised meta-learning approach that transfers shape priors from labeled to unlabeled data to reconstruct unseen object categories. The first stage uses an episodic training scheme to simulate training on unlabeled data and meta-learns initial shape priors. The second stage then introduces unlabeled data with disjoint classes in a semi-supervised scheme to diversify these priors and achieve generalization. We assess our method on both synthetic data and real collected point clouds. Experimental results and analysis validate that our approach outperforms existing neural SDF methods and is capable of robust zero-shot inference on 100+ unseen classes. Code can be found at https://github.com/princeton-computational-imaging/gensdf.", "paper_url": "http://arxiv.org/abs/2206.02780v1", "pdf_url": "http://arxiv.org/pdf/2206.02780v1", "repo_url": null}, "2206.02716": {"publish_time": "2022-06-06", "title": "Stacked unsupervised learning with a network architecture found by supervised meta-learning", "author": "Kyle Luther et.al.", "abstract": "Stacked unsupervised learning (SUL) seems more biologically plausible than backpropagation, because learning is local to each layer. But SUL has fallen far short of backpropagation in practical applications, undermining the idea that SUL can explain how brains learn. Here we show an SUL algorithm that can perform completely unsupervised clustering of MNIST digits with comparable accuracy relative to unsupervised algorithms based on backpropagation. Our algorithm is exceeded only by self-supervised methods requiring training data augmentation by geometric distortions. The only prior knowledge in our unsupervised algorithm is implicit in the network architecture. Multiple convolutional \"energy layers\" contain a sum-of-squares nonlinearity, inspired by \"energy models\" of primary visual cortex. Convolutional kernels are learned with a fast minibatch implementation of the K-Subspaces algorithm. High accuracy requires preprocessing with an initial whitening layer, representations that are less sparse during inference than learning, and rescaling for gain control. The hyperparameters of the network architecture are found by supervised meta-learning, which optimizes unsupervised clustering accuracy. We regard such dependence of unsupervised learning on prior knowledge implicit in network architecture as biologically plausible, and analogous to the dependence of brain architecture on evolutionary history.", "paper_url": "http://arxiv.org/abs/2206.02716v1", "pdf_url": "http://arxiv.org/pdf/2206.02716v1", "repo_url": null}, "2206.02179": {"publish_time": "2022-06-05", "title": "A Simple Meta-learning Paradigm for Zero-shot Intent Classification with Mixture Attention Mechanism", "author": "Han Liu et.al.", "abstract": "Zero-shot intent classification is a vital and challenging task in dialogue systems, which aims to deal with numerous fast-emerging unacquainted intents without annotated training data. To obtain more satisfactory performance, the crucial points lie in two aspects: extracting better utterance features and strengthening the model generalization ability. In this paper, we propose a simple yet effective meta-learning paradigm for zero-shot intent classification. To learn better semantic representations for utterances, we introduce a new mixture attention mechanism, which encodes the pertinent word occurrence patterns by leveraging the distributional signature attention and multi-layer perceptron attention simultaneously. To strengthen the transfer ability of the model from seen classes to unseen classes, we reformulate zero-shot intent classification with a meta-learning strategy, which trains the model by simulating multiple zero-shot classification tasks on seen categories, and promotes the model generalization ability with a meta-adapting procedure on mimic unseen categories. Extensive experiments on two real-world dialogue datasets in different languages show that our model outperforms other strong baselines on both standard and generalized zero-shot intent classification tasks.", "paper_url": "http://arxiv.org/abs/2206.02179v1", "pdf_url": "http://arxiv.org/pdf/2206.02179v1", "repo_url": null}, "2206.01944": {"publish_time": "2022-06-04", "title": "Robust Meta-learning with Sampling Noise and Label Noise via Eigen-Reptile", "author": "Dong Chen et.al.", "abstract": "Recent years have seen a surge of interest in meta-learning techniques for tackling the few-shot learning (FSL) problem. However, the meta-learner is prone to overfitting since there are only a few available samples, which can be identified as sampling noise on a clean dataset. Moreover, when handling the data with noisy labels, the meta-learner could be extremely sensitive to label noise on a corrupted dataset. To address these two challenges, we present Eigen-Reptile (ER) that updates the meta-parameters with the main direction of historical task-specific parameters to alleviate sampling and label noise. Specifically, the main direction is computed in a fast way, where the scale of the calculated matrix is related to the number of gradient steps instead of the number of parameters. Furthermore, to obtain a more accurate main direction for Eigen-Reptile in the presence of many noisy labels, we further propose Introspective Self-paced Learning (ISPL). We have theoretically and experimentally demonstrated the soundness and effectiveness of the proposed Eigen-Reptile and ISPL. Particularly, our experiments on different tasks show that the proposed method is able to outperform or achieve highly competitive performance compared with other gradient-based methods with or without noisy labels. The code and data for the proposed method are provided for research purposes https://github.com/Anfeather/Eigen-Reptile.", "paper_url": "http://arxiv.org/abs/2206.01944v1", "pdf_url": "http://arxiv.org/pdf/2206.01944v1", "repo_url": "https://github.com/anfeather/eigen-reptile"}, "2206.03436": {"publish_time": "2022-06-07", "title": "Federated Hetero-Task Learning", "author": "Liuyi Yao et.al.", "abstract": "To investigate the heterogeneity of federated learning in real-world scenarios, we generalize the classical federated learning to federated hetero-task learning, which emphasizes the inconsistency across the participants in federated learning in terms of both data distribution and learning tasks. We also present B-FHTL, a federated hetero-task learning benchmark consisted of simulation dataset, FL protocols and a unified evaluation mechanism. B-FHTL dataset contains three well-designed federated learning tasks with increasing heterogeneity. Each task simulates the clients with different data distributions and learning tasks. To ensure fair comparison among different FL algorithms, B-FHTL builds in a full suite of FL protocols by providing high-level APIs to avoid privacy leakage, and presets most common evaluation metrics spanning across different learning tasks, such as regression, classification, text generation and etc. Furthermore, we compare the FL algorithms in fields of federated multi-task learning, federated personalization and federated meta learning within B-FHTL, and highlight the influence of heterogeneity and difficulties of federated hetero-task learning. Our benchmark, including the federated dataset, protocols, the evaluation mechanism and the preliminary experiment, is open-sourced at https://github.com/alibaba/FederatedScope/tree/contest/v1.0.", "paper_url": "http://arxiv.org/abs/2206.03436v1", "pdf_url": "http://arxiv.org/pdf/2206.03436v1", "repo_url": "https://github.com/alibaba/federatedscope"}, "2206.03271": {"publish_time": "2022-06-07", "title": "On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning", "author": "Zhao Mandi et.al.", "abstract": "Intelligent agents should have the ability to leverage knowledge from previously learned tasks in order to learn new ones quickly and efficiently. Meta-learning approaches have emerged as a popular solution to achieve this. However, meta-reinforcement learning (meta-RL) algorithms have thus far been restricted to simple environments with narrow task distributions. Moreover, the paradigm of pretraining followed by fine-tuning to adapt to new tasks has emerged as a simple yet effective solution in supervised and self-supervised learning. This calls into question the benefits of meta-learning approaches also in reinforcement learning, which typically come at the cost of high complexity. We hence investigate meta-RL approaches in a variety of vision-based benchmarks, including Procgen, RLBench, and Atari, where evaluations are made on completely novel tasks. Our findings show that when meta-learning approaches are evaluated on different tasks (rather than different variations of the same task), multi-task pretraining with fine-tuning on new tasks performs equally as well, or better, than meta-pretraining with meta test-time adaptation. This is encouraging for future research, as multi-task pretraining tends to be simpler and computationally cheaper than meta-RL. From these findings, we advocate for evaluating future meta-RL methods on more challenging tasks and including multi-task pretraining with fine-tuning as a simple, yet strong baseline.", "paper_url": "http://arxiv.org/abs/2206.03271v1", "pdf_url": "http://arxiv.org/pdf/2206.03271v1", "repo_url": null}, "2206.03130": {"publish_time": "2022-06-07", "title": "Towards Meta-learned Algorithm Selection using Implicit Fidelity Information", "author": "Aditya Mohan et.al.", "abstract": "Automatically selecting the best performing algorithm for a given dataset or ranking multiple of them by their expected performance supports users in developing new machine learning applications. Most approaches for this problem rely on dataset meta-features and landmarking performances to capture the salient topology of the datasets and those topologies that the algorithms attend to. Landmarking usually exploits cheap algorithms not necessarily in the pool of candidate algorithms to get inexpensive approximations of the topology. While somewhat indicative, handcrafted dataset meta-features and landmarks are likely insufficient descriptors, strongly depending on the alignment of the geometries the landmarks and candidates search for. We propose IMFAS, a method to exploit multi-fidelity landmarking information directly from the candidate algorithms in the form of non-parametrically non-myopic meta-learned learning curves via LSTM networks in a few-shot setting during testing. Using this mechanism, IMFAS jointly learns the topology of of the datasets and the inductive biases of algorithms without expensively training them to convergence. IMFAS produces informative landmarks, easily enriched by arbitrary meta-features at a low computational cost, capable of producing the desired ranking using cheaper fidelities. We additionally show that it is able to beat Successive Halving with at most half the fidelity sequence during test time", "paper_url": "http://arxiv.org/abs/2206.03130v1", "pdf_url": "http://arxiv.org/pdf/2206.03130v1", "repo_url": null}, "2206.03996": {"publish_time": "2022-06-08", "title": "Sharp-MAML: Sharpness-Aware Model-Agnostic Meta Learning", "author": "Momin Abbas et.al.", "abstract": "Model-agnostic meta learning (MAML) is currently one of the dominating approaches for few-shot meta-learning. Albeit its effectiveness, the optimization of MAML can be challenging due to the innate bilevel problem structure. Specifically, the loss landscape of MAML is much more complex with possibly more saddle points and local minimizers than its empirical risk minimization counterpart. To address this challenge, we leverage the recently invented sharpness-aware minimization and develop a sharpness-aware MAML approach that we term Sharp-MAML. We empirically demonstrate that Sharp-MAML and its computation-efficient variant can outperform popular existing MAML baselines (e.g., $+12\\%$ accuracy on Mini-Imagenet). We complement the empirical study with the convergence rate analysis and the generalization bound of Sharp-MAML. To the best of our knowledge, this is the first empirical and theoretical study on sharpness-aware minimization in the context of bilevel learning. The code is available at https://github.com/mominabbass/Sharp-MAML.", "paper_url": "http://arxiv.org/abs/2206.03996v1", "pdf_url": "http://arxiv.org/pdf/2206.03996v1", "repo_url": "https://github.com/mominabbass/sharp-maml"}, "2206.03597": {"publish_time": "2022-06-07", "title": "Meta-Learning Transferable Parameterized Skills", "author": "Haotian Fu et.al.", "abstract": "We propose a novel parameterized skill-learning algorithm that aims to learn transferable parameterized skills and synthesize them into a new action space that supports efficient learning in long-horizon tasks. We first propose novel learning objectives -- trajectory-centric diversity and smoothness -- that allow an agent to meta-learn reusable parameterized skills. Our agent can use these learned skills to construct a temporally-extended parameterized-action Markov decision process, for which we propose a hierarchical actor-critic algorithm that aims to efficiently learn a high-level control policy with the learned skills. We empirically demonstrate that the proposed algorithms enable an agent to solve a complicated long-horizon obstacle-course environment.", "paper_url": "http://arxiv.org/abs/2206.03597v1", "pdf_url": "http://arxiv.org/pdf/2206.03597v1", "repo_url": null}, "2206.03851": {"publish_time": "2022-06-07", "title": "Towards Bridging Algorithm and Theory for Unbiased Recommendation", "author": "Teng Xiao et.al.", "abstract": "This work studies the problem of learning unbiased algorithms from biased feedback for recommender systems. We address this problem from both theoretical and algorithmic perspectives. Recent works in unbiased learning have advanced the state-of-the-art with various techniques such as meta-learning, knowledge distillation, and information bottleneck. Despite their empirical successes, most of them lack theoretical guarantee, forming non-negligible gaps between the theories and recent algorithms. To this end, we first view the unbiased recommendation problem from a distribution shift perspective. We theoretically analyze the generalization bounds of unbiased learning and suggest their close relations with recent unbiased learning objectives. Based on the theoretical analysis, we further propose a principled framework, Adversarial Self-Training (AST), for unbiased recommendation. Empirical evaluation on real-world and semi-synthetic datasets demonstrate the effectiveness of the proposed AST.", "paper_url": "http://arxiv.org/abs/2206.03851v1", "pdf_url": "http://arxiv.org/pdf/2206.03851v1", "repo_url": null}, "2206.04486": {"publish_time": "2022-06-09", "title": "Data-Efficient Brain Connectome Analysis via Multi-Task Meta-Learning", "author": "Yi Yang et.al.", "abstract": "Brain networks characterize complex connectivities among brain regions as graph structures, which provide a powerful means to study brain connectomes. In recent years, graph neural networks have emerged as a prevalent paradigm of learning with structured data. However, most brain network datasets are limited in sample sizes due to the relatively high cost of data acquisition, which hinders the deep learning models from sufficient training. Inspired by meta-learning that learns new concepts fast with limited training examples, this paper studies data-efficient training strategies for analyzing brain connectomes in a cross-dataset setting. Specifically, we propose to meta-train the model on datasets of large sample sizes and transfer the knowledge to small datasets. In addition, we also explore two brain-network-oriented designs, including atlas transformation and adaptive task reweighing. Compared to other pre-training strategies, our meta-learning-based approach achieves higher and stabler performance, which demonstrates the effectiveness of our proposed solutions. The framework is also able to derive new insights regarding the similarities among datasets and diseases in a data-driven fashion.", "paper_url": "http://arxiv.org/abs/2206.04486v1", "pdf_url": "http://arxiv.org/pdf/2206.04486v1", "repo_url": null}, "2206.04415": {"publish_time": "2022-06-09", "title": "Deep Meta-learning in Recommendation Systems: A Survey", "author": "Chunyang Wang et.al.", "abstract": "Deep neural network based recommendation systems have achieved great success as information filtering techniques in recent years. However, since model training from scratch requires sufficient data, deep learning-based recommendation methods still face the bottlenecks of insufficient data and computational inefficiency. Meta-learning, as an emerging paradigm that learns to improve the learning efficiency and generalization ability of algorithms, has shown its strength in tackling the data sparsity issue. Recently, a growing number of studies on deep meta-learning based recommenddation systems have emerged for improving the performance under recommendation scenarios where available data is limited, e.g. user cold-start and item cold-start. Therefore, this survey provides a timely and comprehensive overview of current deep meta-learning based recommendation methods. Specifically, we propose a taxonomy to discuss existing methods according to recommendation scenarios, meta-learning techniques, and meta-knowledge representations, which could provide the design space for meta-learning based recommendation methods. For each recommendation scenario, we further discuss technical details about how existing methods apply meta-learning to improve the generalization ability of recommendation models. Finally, we also point out several limitations in current research and highlight some promising directions for future research in this area.", "paper_url": "http://arxiv.org/abs/2206.04415v1", "pdf_url": "http://arxiv.org/pdf/2206.04415v1", "repo_url": null}, "2206.04335": {"publish_time": "2022-06-09", "title": "Learning to generate imaginary tasks for improving generalization in meta-learning", "author": "Yichen Wu et.al.", "abstract": "The success of meta-learning on existing benchmarks is predicated on the assumption that the distribution of meta-training tasks covers meta-testing tasks. Frequent violation of the assumption in applications with either insufficient tasks or a very narrow meta-training task distribution leads to memorization or learner overfitting. Recent solutions have pursued augmentation of meta-training tasks, while it is still an open question to generate both correct and sufficiently imaginary tasks. In this paper, we seek an approach that up-samples meta-training tasks from the task representation via a task up-sampling network. Besides, the resulting approach named Adversarial Task Up-sampling (ATU) suffices to generate tasks that can maximally contribute to the latest meta-learner by maximizing an adversarial loss. On few-shot sine regression and image classification datasets, we empirically validate the marked improvement of ATU over state-of-the-art task augmentation strategies in the meta-testing performance and also the quality of up-sampled tasks.", "paper_url": "http://arxiv.org/abs/2206.04335v1", "pdf_url": "http://arxiv.org/pdf/2206.04335v1", "repo_url": null}, "2206.05181": {"publish_time": "2022-06-10", "title": "Lightweight Conditional Model Extrapolation for Streaming Data under Class-Prior Shift", "author": "Paulina Tomaszewska et.al.", "abstract": "We introduce LIMES, a new method for learning with non-stationary streaming data, inspired by the recent success of meta-learning. The main idea is not to attempt to learn a single classifier that would have to work well across all occurring data distributions, nor many separate classifiers, but to exploit a hybrid strategy: we learn a single set of model parameters from which a specific classifier for any specific data distribution is derived via classifier adaptation. Assuming a multi-class classification setting with class-prior shift, the adaptation step can be performed analytically with only the classifier's bias terms being affected. Another contribution of our work is an extrapolation step that predicts suitable adaptation parameters for future time steps based on the previous data. In combination, we obtain a lightweight procedure for learning from streaming data with varying class distribution that adds no trainable parameters and almost no memory or computational overhead compared to training a single model. Experiments on a set of exemplary tasks using Twitter data show that LIMES achieves higher accuracy than alternative approaches, especially with respect to the relevant real-world metric of lowest within-day accuracy.", "paper_url": "http://arxiv.org/abs/2206.05181v1", "pdf_url": "http://arxiv.org/pdf/2206.05181v1", "repo_url": "https://github.com/ptomaszewska/limes"}, "2206.04789": {"publish_time": "2022-06-09", "title": "Comprehensive Fair Meta-learned Recommender System", "author": "Tianxin Wei et.al.", "abstract": "In recommender systems, one common challenge is the cold-start problem, where interactions are very limited for fresh users in the systems. To address this challenge, recently, many works introduce the meta-optimization idea into the recommendation scenarios, i.e. learning to learn the user preference by only a few past interaction items. The core idea is to learn global shared meta-initialization parameters for all users and rapidly adapt them into local parameters for each user respectively. They aim at deriving general knowledge across preference learning of various users, so as to rapidly adapt to the future new user with the learned prior and a small amount of training data. However, previous works have shown that recommender systems are generally vulnerable to bias and unfairness. Despite the success of meta-learning at improving the recommendation performance with cold-start, the fairness issues are largely overlooked. In this paper, we propose a comprehensive fair meta-learning framework, named CLOVER, for ensuring the fairness of meta-learned recommendation models. We systematically study three kinds of fairness - individual fairness, counterfactual fairness, and group fairness in the recommender systems, and propose to satisfy all three kinds via a multi-task adversarial learning scheme. Our framework offers a generic training paradigm that is applicable to different meta-learned recommender systems. We demonstrate the effectiveness of CLOVER on the representative meta-learned user preference estimator on three real-world data sets. Empirical results show that CLOVER achieves comprehensive fairness without deteriorating the overall cold-start recommendation performance.", "paper_url": "http://arxiv.org/abs/2206.04789v1", "pdf_url": "http://arxiv.org/pdf/2206.04789v1", "repo_url": "https://github.com/weitianxin/CLOVER"}, "2206.05930": {"publish_time": "2022-06-13", "title": "Faster Optimization-Based Meta-Learning Adaptation Phase", "author": "Kostiantyn Khabarlak et.al.", "abstract": "Neural networks require a large amount of annotated data to learn. Meta-learning algorithms propose a way to decrease the number of training samples to only a few. One of the most prominent optimization-based meta-learning algorithms is Model-Agnostic Meta-Learning (MAML). However, the key procedure of adaptation to new tasks in MAML is quite slow. In this work we propose an improvement to MAML meta-learning algorithm. We introduce Lambda patterns by which we restrict which weight are updated in the network during the adaptation phase. This makes it possible to skip certain gradient computations. The fastest pattern is selected given an allowed quality degradation threshold parameter. In certain cases, quality improvement is possible by a careful pattern selection. The experiments conducted have shown that via Lambda adaptation pattern selection, it is possible to significantly improve the MAML method in the following areas: adaptation time has been decreased by a factor of 3 with minimal accuracy loss; accuracy for one-step adaptation has been substantially improved.", "paper_url": "http://arxiv.org/abs/2206.05930v1", "pdf_url": "http://arxiv.org/pdf/2206.05930v1", "repo_url": null}, "2206.05454": {"publish_time": "2022-06-11", "title": "A General framework for PAC-Bayes Bounds for Meta-Learning", "author": "Arezou Rezazadeh et.al.", "abstract": "Meta learning automatically infers an inductive bias, that includes the hyperparameter of the base-learning algorithm, by observing data from a finite number of related tasks. This paper studies PAC-Bayes bounds on meta generalization gap. The meta-generalization gap comprises two sources of generalization gaps: the environment-level and task-level gaps resulting from observation of a finite number of tasks and data samples per task, respectively. In this paper, by upper bounding arbitrary convex functions, which link the expected and empirical losses at the environment and also per-task levels, we obtain new PAC-Bayes bounds. Using these bounds, we develop new PAC-Bayes meta-learning algorithms. Numerical examples demonstrate the merits of the proposed novel bounds and algorithm in comparison to prior PAC-Bayes bounds for meta-learning.", "paper_url": "http://arxiv.org/abs/2206.05454v1", "pdf_url": "http://arxiv.org/pdf/2206.05454v1", "repo_url": null}, "2206.06872": {"publish_time": "2022-06-14", "title": "On Provably Robust Meta-Bayesian Optimization", "author": "Zhongxiang Dai et.al.", "abstract": "Bayesian optimization (BO) has become popular for sequential optimization of black-box functions. When BO is used to optimize a target function, we often have access to previous evaluations of potentially related functions. This begs the question as to whether we can leverage these previous experiences to accelerate the current BO task through meta-learning (meta-BO), while ensuring robustness against potentially harmful dissimilar tasks that could sabotage the convergence of BO. This paper introduces two scalable and provably robust meta-BO algorithms: robust meta-Gaussian process-upper confidence bound (RM-GP-UCB) and RM-GP-Thompson sampling (RM-GP-TS). We prove that both algorithms are asymptotically no-regret even when some or all previous tasks are dissimilar to the current task, and show that RM-GP-UCB enjoys a better theoretical robustness than RM-GP-TS. We also exploit the theoretical guarantees to optimize the weights assigned to individual previous tasks through regret minimization via online learning, which diminishes the impact of dissimilar tasks and hence further enhances the robustness. Empirical evaluations show that (a) RM-GP-UCB performs effectively and consistently across various applications, and (b) RM-GP-TS, despite being less robust than RM-GP-UCB both in theory and in practice, performs competitively in some scenarios with less dissimilar tasks and is more computationally efficient.", "paper_url": "http://arxiv.org/abs/2206.06872v2", "pdf_url": "http://arxiv.org/pdf/2206.06872v2", "repo_url": "https://github.com/daizhongxiang/meta-bo"}, "2206.06568": {"publish_time": "2022-06-14", "title": "Distributed and Distribution-Robust Meta Reinforcement Learning (D2-RMRL) for Data Pre-storing and Routing in Cube Satellite Networks", "author": "Ye Hu et.al.", "abstract": "In this paper, the problem of data pre-storing and routing in dynamic, resource-constrained cube satellite networks is studied. In such a network, each cube satellite delivers requested data to user clusters under its coverage. A group of ground gateways will route and pre-store certain data to the satellites, such that the ground users can be directly served with the pre-stored data. This pre-storing and routing design problem is formulated as a decentralized Markov decision process (Dec-MDP) in which we seek to find the optimal strategy that maximizes the pre-store hit rate, i.e., the fraction of users being directly served with the pre-stored data. To obtain the optimal strategy, a distributed distribution-robust meta reinforcement learning (D2-RMRL) algorithm is proposed that consists of three key ingredients: value-decomposition for achieving the global optimum in distributed setting with minimum communication overhead, meta learning to obtain the optimal initial to reduce the training time under dynamic conditions, and pre-training to further speed up the meta training procedure. Simulation results show that, using the proposed value decomposition and meta training techniques, the satellite networks can achieve a 31.8% improvement of the pre-store hits and a 40.7% improvement of the convergence speed, compared to a baseline reinforcement learning algorithm. Moreover, the use of the proposed pre-training mechanism helps to shorten the meta-learning procedure by up to 43.7%.", "paper_url": "http://arxiv.org/abs/2206.06568v1", "pdf_url": "http://arxiv.org/pdf/2206.06568v1", "repo_url": null}, "2206.06460": {"publish_time": "2022-06-13", "title": "MetaTPTrans: A Meta Learning Approach for Multilingual Code Representation Learning", "author": "Weiguo Pian et.al.", "abstract": "Representation learning of source code is essential for applying machine learning to software engineering tasks. Learning code representation across different programming languages has been shown to be more effective than learning from single-language datasets, since more training data from multi-language datasets improves the model's ability to extract language-agnostic information from source code. However, existing multi-language models overlook the language-specific information which is crucial for downstream tasks that is training on multi-language datasets, while only focusing on learning shared parameters among the different languages. To address this problem, we propose MetaTPTrans, a meta learning approach for multilingual code representation learning. MetaTPTrans generates different parameters for the feature extractor according to the specific programming language of the input source code snippet, enabling the model to learn both language-agnostics and language-specific information. Experimental results show that MetaTPTrans improves the F1 score of state-of-the-art approaches significantly by up to 2.40 percentage points for code summarization, a language-agnostic task; and the prediction accuracy of Top-1 (Top-5) by up to 7.32 (13.15) percentage points for code completion, a language-specific task.", "paper_url": "http://arxiv.org/abs/2206.06460v1", "pdf_url": "http://arxiv.org/pdf/2206.06460v1", "repo_url": null}, "2206.07351": {"publish_time": "2022-06-15", "title": "RecBole 2.0: Towards a More Up-to-Date Recommendation Library", "author": "Wayne Xin Zhao et.al.", "abstract": "In order to support the study of recent advances in recommender systems, this paper presents an extended recommendation library consisting of eight packages for up-to-date topics and architectures. First of all, from a data perspective, we consider three important topics related to data issues (i.e., sparsity, bias and distribution shift), and develop five packages accordingly: meta-learning, data augmentation, debiasing, fairness and cross-domain recommendation. Furthermore, from a model perspective, we develop two benchmarking packages for Transformer-based and graph neural network (GNN)-based models, respectively. All the packages (consisting of 65 new models) are developed based on a popular recommendation framework RecBole, ensuring that both the implementation and interface are unified. For each package, we provide complete implementations from data loading, experimental setup, evaluation and algorithm implementation. This library provides a valuable resource to facilitate the up-to-date research in recommender systems. The project is released at the link: https://github.com/RUCAIBox/RecBole2.0.", "paper_url": "http://arxiv.org/abs/2206.07351v2", "pdf_url": "http://arxiv.org/pdf/2206.07351v2", "repo_url": "https://github.com/rucaibox/recbole2.0"}, "2206.07260": {"publish_time": "2022-06-15", "title": "On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot Adaptation", "author": "Markus Hiller et.al.", "abstract": "Inspired by the concept of preconditioning, we propose a novel method to increase adaptation speed for gradient-based meta-learning methods without incurring extra parameters. We demonstrate that recasting the optimization problem to a non-linear least-squares formulation provides a principled way to actively enforce a $\\textit{well-conditioned}$ parameter space for meta-learning models based on the concepts of the condition number and local curvature. Our comprehensive evaluations show that the proposed method significantly outperforms its unconstrained counterpart especially during initial adaptation steps, while achieving comparable or better overall results on several few-shot classification tasks -- creating the possibility of dynamically choosing the number of adaptation steps at inference time.", "paper_url": "http://arxiv.org/abs/2206.07260v1", "pdf_url": "http://arxiv.org/pdf/2206.07260v1", "repo_url": null}, "2206.07162": {"publish_time": "2022-06-14", "title": "Category-Agnostic 6D Pose Estimation with Conditional Neural Processes", "author": "Yumeng Li et.al.", "abstract": "We present a novel meta-learning approach for 6D pose estimation on unknown objects. In contrast to \"instance-level\" pose estimation methods, our algorithm learns object representation in a category-agnostic way, which endows it with strong generalization capabilities within and across object categories. Specifically, we employ a conditional neural process-based meta-learning approach to train an encoder to capture texture and geometry of an object in a latent representation, based on very few RGB-D images and ground-truth keypoints. The latent representation is then used by a simultaneously meta-trained decoder to predict the 6D pose of the object in new images. To evaluate our algorithm, experiments are conducted on our new fully-annotated synthetic datasets generated from Multiple Categories in Multiple Scenes (MCMS). Experimental results demonstrate that our model performs well on unseen objects with various shapes and appearances.", "paper_url": "http://arxiv.org/abs/2206.07162v1", "pdf_url": "http://arxiv.org/pdf/2206.07162v1", "repo_url": null}, "2206.08138": {"publish_time": "2022-06-15", "title": "Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification", "author": "Adrian El Baz et.al.", "abstract": "Although deep neural networks are capable of achieving performance superior to humans on various tasks, they are notorious for requiring large amounts of data and computing resources, restricting their success to domains where such resources are available. Metalearning methods can address this problem by transferring knowledge from related tasks, thus reducing the amount of data and computing resources needed to learn new tasks. We organize the MetaDL competition series, which provide opportunities for research groups all over the world to create and experimentally assess new meta-(deep)learning solutions for real problems. In this paper, authored collaboratively between the competition organizers and the top-ranked participants, we describe the design of the competition, the datasets, the best experimental results, as well as the top-ranked methods in the NeurIPS 2021 challenge, which attracted 15 active teams who made it to the final phase (by outperforming the baseline), making over 100 code submissions during the feedback phase. The solutions of the top participants have been open-sourced. The lessons learned include that learning good representations is essential for effective transfer learning.", "paper_url": "http://arxiv.org/abs/2206.08138v1", "pdf_url": "http://arxiv.org/pdf/2206.08138v1", "repo_url": null}, "2206.08720": {"publish_time": "2022-06-17", "title": "Fast Finite Width Neural Tangent Kernel", "author": "Roman Novak et.al.", "abstract": "The Neural Tangent Kernel (NTK), defined as $\\Theta_\\theta^f(x_1, x_2) = \\left[\\partial f(\\theta, x_1)\\big/\\partial \\theta\\right] \\left[\\partial f(\\theta, x_2)\\big/\\partial \\theta\\right]^T$ where $\\left[\\partial f(\\theta, \\cdot)\\big/\\partial \\theta\\right]$ is a neural network (NN) Jacobian, has emerged as a central object of study in deep learning. In the infinite width limit, the NTK can sometimes be computed analytically and is useful for understanding training and generalization of NN architectures. At finite widths, the NTK is also used to better initialize NNs, compare the conditioning across models, perform architecture search, and do meta-learning. Unfortunately, the finite width NTK is notoriously expensive to compute, which severely limits its practical utility. We perform the first in-depth analysis of the compute and memory requirements for NTK computation in finite width networks. Leveraging the structure of neural networks, we further propose two novel algorithms that change the exponent of the compute and memory requirements of the finite width NTK, dramatically improving efficiency. Our algorithms can be applied in a black box fashion to any differentiable function, including those implementing neural networks. We open-source our implementations within the Neural Tangents package (arXiv:1912.02803) at https://github.com/google/neural-tangents.", "paper_url": "http://arxiv.org/abs/2206.08720v1", "pdf_url": "http://arxiv.org/pdf/2206.08720v1", "repo_url": "https://github.com/iclr2022anon/fast_finite_width_ntk"}, "2206.08594": {"publish_time": "2022-06-17", "title": "Accelerating numerical methods by gradient-based meta-solving", "author": "Sohei Arisaka et.al.", "abstract": "In science and engineering applications, it is often required to solve similar computational problems repeatedly. In such cases, we can utilize the data from previously solved problem instances to improve the efficiency of finding subsequent solutions. This offers a unique opportunity to combine machine learning (in particular, meta-learning) and scientific computing. To date, a variety of such domain-specific methods have been proposed in the literature, but a generic approach for designing these methods remains under-explored. In this paper, we tackle this issue by formulating a general framework to describe these problems, and propose a gradient-based algorithm to solve them in a unified way. As an illustration of this approach, we study the adaptive generation of parameters for iterative solvers to accelerate the solution of differential equations. We demonstrate the performance and versatility of our method through theoretical analysis and numerical experiments, including applications to incompressible flow simulations and an inverse problem of parameter estimation.", "paper_url": "http://arxiv.org/abs/2206.08594v1", "pdf_url": "http://arxiv.org/pdf/2206.08594v1", "repo_url": "https://github.com/arisakaso/gbms"}, "2206.08476": {"publish_time": "2022-06-16", "title": "Zero-Shot AutoML with Pretrained Models", "author": "Ekrem \u00d6zt\u00fcrk et.al.", "abstract": "Given a new dataset D and a low compute budget, how should we choose a pre-trained model to fine-tune to D, and set the fine-tuning hyperparameters without risking overfitting, particularly if D is small? Here, we extend automated machine learning (AutoML) to best make these choices. Our domain-independent meta-learning approach learns a zero-shot surrogate model which, at test time, allows to select the right deep learning (DL) pipeline (including the pre-trained model and fine-tuning hyperparameters) for a new dataset D given only trivial meta-features describing D such as image resolution or the number of classes. To train this zero-shot model, we collect performance data for many DL pipelines on a large collection of datasets and meta-train on this data to minimize a pairwise ranking objective. We evaluate our approach under the strict time limit of the vision track of the ChaLearn AutoDL challenge benchmark, clearly outperforming all challenge contenders.", "paper_url": "http://arxiv.org/abs/2206.08476v1", "pdf_url": "http://arxiv.org/pdf/2206.08476v1", "repo_url": "https://github.com/automl/zero-shot-automl-with-pretrained-models"}, "2206.09966": {"publish_time": "2022-06-20", "title": "Meta-Learning Digitized-Counterdiabatic Quantum Optimization", "author": "Pranav Chandarana et.al.", "abstract": "Solving optimization tasks using variational quantum algorithms has emerged as a crucial application of the current noisy intermediate-scale quantum devices. However, these algorithms face several difficulties like finding suitable ansatz and appropriate initial parameters, among others. In this work, we tackle the problem of finding suitable initial parameters for variational optimization by employing a meta-learning technique using recurrent neural networks. We investigate this technique with the recently proposed digitized-counterdiabatic quantum approximate optimization algorithm (DC-QAOA) that utilizes counterdiabatic protocols to improve the state-of-the-art QAOA. The combination of meta learning and DC-QAOA enables us to find optimal initial parameters for different models, such as MaxCut problem and the Sherrington-Kirkpatrick model. Decreasing the number of iterations of optimization as well as enhancing the performance, our protocol designs short depth circuit ansatz with optimal initial parameters by incorporating shortcuts-to-adiabaticity principles into machine learning methods for the near-term devices.", "paper_url": "http://arxiv.org/abs/2206.09966v1", "pdf_url": "http://arxiv.org/pdf/2206.09966v1", "repo_url": null}, "2206.09543": {"publish_time": "2022-06-20", "title": "Meta-learning for Out-of-Distribution Detection via Density Estimation in Latent Space", "author": "Tomoharu Iwata et.al.", "abstract": "Many neural network-based out-of-distribution (OoD) detection methods have been proposed. However, they require many training data for each target task. We propose a simple yet effective meta-learning method to detect OoD with small in-distribution data in a target task. With the proposed method, the OoD detection is performed by density estimation in a latent space. A neural network shared among all tasks is used to flexibly map instances in the original space to the latent space. The neural network is meta-learned such that the expected OoD detection performance is improved by using various tasks that are different from the target tasks. This meta-learning procedure enables us to obtain appropriate representations in the latent space for OoD detection. For density estimation, we use a Gaussian mixture model (GMM) with full covariance for each class. We can adapt the GMM parameters to in-distribution data in each task in a closed form by maximizing the likelihood. Since the closed form solution is differentiable, we can meta-learn the neural network efficiently with a stochastic gradient descent method by incorporating the solution into the meta-learning objective function. In experiments using six datasets, we demonstrate that the proposed method achieves better performance than existing meta-learning and OoD detection methods.", "paper_url": "http://arxiv.org/abs/2206.09543v1", "pdf_url": "http://arxiv.org/pdf/2206.09543v1", "repo_url": null}, "2206.09280": {"publish_time": "2022-06-18", "title": "AutoGML: Fast Automatic Model Selection for Graph Machine Learning", "author": "Namyong Park et.al.", "abstract": "Given a graph learning task, such as link prediction, on a new graph dataset, how can we automatically select the best method as well as its hyperparameters (collectively called a model)? Model selection for graph learning has been largely ad hoc. A typical approach has been to apply popular methods to new datasets, but this is often suboptimal. On the other hand, systematically comparing models on the new graph quickly becomes too costly, or even impractical. In this work, we develop the first meta-learning approach for automatic graph machine learning, called AutoGML, which capitalizes on the prior performances of a large body of existing methods on benchmark graph datasets, and carries over this prior experience to automatically select an effective model to use for the new graph, without any model training or evaluations. To capture the similarity across graphs from different domains, we introduce specialized meta-graph features that quantify the structural characteristics of a graph. Then we design a meta-graph that represents the relations among models and graphs, and develop a graph meta-learner operating on the meta-graph, which estimates the relevance of each model to different graphs. Through extensive experiments, we show that using AutoGML to select a method for the new graph significantly outperforms consistently applying popular methods as well as several existing meta-learners, while being extremely fast at test time.", "paper_url": "http://arxiv.org/abs/2206.09280v1", "pdf_url": "http://arxiv.org/pdf/2206.09280v1", "repo_url": null}, "2206.09262": {"publish_time": "2022-06-18", "title": "Motley: Benchmarking Heterogeneity and Personalization in Federated Learning", "author": "Shanshan Wu et.al.", "abstract": "Personalized federated learning considers learning models unique to each client in a heterogeneous network. The resulting client-specific models have been purported to improve metrics such as accuracy, fairness, and robustness in federated networks. However, despite a plethora of work in this area, it remains unclear: (1) which personalization techniques are most effective in various settings, and (2) how important personalization truly is for realistic federated applications. To better answer these questions, we propose Motley, a benchmark for personalized federated learning. Motley consists of a suite of cross-device and cross-silo federated datasets from varied problem domains, as well as thorough evaluation metrics for better understanding the possible impacts of personalization. We establish baselines on the benchmark by comparing a number of representative personalized federated learning methods. These initial results highlight strengths and weaknesses of existing approaches, and raise several open questions for the community. Motley aims to provide a reproducible means with which to advance developments in personalized and heterogeneity-aware federated learning, as well as the related areas of transfer learning, meta-learning, and multi-task learning.", "paper_url": "http://arxiv.org/abs/2206.09262v1", "pdf_url": "http://arxiv.org/pdf/2206.09262v1", "repo_url": "https://github.com/google-research/federated"}, "2206.09195": {"publish_time": "2022-06-18", "title": "EEML: Ensemble Embedded Meta-learning", "author": "Geng Li et.al.", "abstract": "To accelerate learning process with few samples, meta-learning resorts to prior knowledge from previous tasks. However, the inconsistent task distribution and heterogeneity is hard to be handled through a global sharing model initialization. In this paper, based on gradient-based meta-learning, we propose an ensemble embedded meta-learning algorithm (EEML) that explicitly utilizes multi-model-ensemble to organize prior knowledge into diverse specific experts. We rely on a task embedding cluster mechanism to deliver diverse tasks to matching experts in training process and instruct how experts collaborate in test phase. As a result, the multi experts can focus on their own area of expertise and cooperate in upcoming task to solve the task heterogeneity. The experimental results show that the proposed method outperforms recent state-of-the-arts easily in few-shot learning problem, which validates the importance of differentiation and cooperation.", "paper_url": "http://arxiv.org/abs/2206.09195v1", "pdf_url": "http://arxiv.org/pdf/2206.09195v1", "repo_url": null}, "2206.10870": {"publish_time": "2022-06-22", "title": "Decentralized Gossip-Based Stochastic Bilevel Optimization over Communication Networks", "author": "Shuoguang Yang et.al.", "abstract": "Bilevel optimization have gained growing interests, with numerous applications found in meta learning, minimax games, reinforcement learning, and nested composition optimization. This paper studies the problem of distributed bilevel optimization over a network where agents can only communicate with neighbors, including examples from multi-task, multi-agent learning and federated learning. In this paper, we propose a gossip-based distributed bilevel learning algorithm that allows networked agents to solve both the inner and outer optimization problems in a single timescale and share information via network propagation. We show that our algorithm enjoys the $\\mathcal{O}(\\frac{1}{K \\epsilon^2})$ per-agent sample complexity for general nonconvex bilevel optimization and $\\mathcal{O}(\\frac{1}{K \\epsilon})$ for strongly convex objective, achieving a speedup that scales linearly with the network size. The sample complexities are optimal in both $\\epsilon$ and $K$. We test our algorithm on the examples of hyperparameter tuning and decentralized reinforcement learning. Simulated experiments confirmed that our algorithm achieves the state-of-the-art training efficiency and test accuracy.", "paper_url": "http://arxiv.org/abs/2206.10870v1", "pdf_url": "http://arxiv.org/pdf/2206.10870v1", "repo_url": null}, "2206.11886": {"publish_time": "2022-06-23", "title": "On the Generalizability and Predictability of Recommender Systems", "author": "Duncan McElfresh et.al.", "abstract": "While other areas of machine learning have seen more and more automation, designing a high-performing recommender system still requires a high level of human effort. Furthermore, recent work has shown that modern recommender system algorithms do not always improve over well-tuned baselines. A natural follow-up question is, \"how do we choose the right algorithm for a new dataset and performance metric?\" In this work, we start by giving the first large-scale study of recommender system approaches by comparing 18 algorithms and 100 sets of hyperparameters across 85 datasets and 315 metrics. We find that the best algorithms and hyperparameters are highly dependent on the dataset and performance metric, however, there are also strong correlations between the performance of each algorithm and various meta-features of the datasets. Motivated by these findings, we create RecZilla, a meta-learning approach to recommender systems that uses a model to predict the best algorithm and hyperparameters for new, unseen datasets. By using far more meta-training data than prior work, RecZilla is able to substantially reduce the level of human involvement when faced with a new recommender system application. We not only release our code and pretrained RecZilla models, but also all of our raw experimental results, so that practitioners can train a RecZilla model for their desired performance metric: https://github.com/naszilla/reczilla.", "paper_url": "http://arxiv.org/abs/2206.11886v1", "pdf_url": "http://arxiv.org/pdf/2206.11886v1", "repo_url": "https://github.com/naszilla/reczilla"}, "2206.11378": {"publish_time": "2022-06-22", "title": "Multi-Access Point Coordination for Next-Gen Wi-Fi Networks Aided by Deep Reinforcement Learning", "author": "Lyutianyang Zhang et.al.", "abstract": "Wi-Fi in the enterprise - characterized by overlapping Wi-Fi cells - constitutes the design challenge for next-generation networks. Standardization for recently started IEEE 802.11be (Wi-Fi 7) Working Groups has focused on significant medium access control layer changes that emphasize the role of the access point (AP) in radio resource management (RRM) for coordinating channel access due to the high collision probability with the distributed coordination function (DCF), especially in dense overlapping Wi-Fi networks. This paper proposes a novel multi-AP coordination system architecture aided by a centralized AP controller (APC). Meanwhile, a deep reinforcement learning channel access (DLCA) protocol is developed to replace the binary exponential backoff mechanism in DCF to enhance the network throughput by enabling the coordination of APs. First-Order Model-Agnostic Meta-Learning further enhances the network throughput. Subsequently, we also put forward a new greedy algorithm to maintain proportional fairness (PF) among multiple APs. Via the simulation, the performance of DLCA protocol in dense overlapping Wi-Fi networks is verified to have strong stability and outperform baselines such as Shared Transmission Opportunity (SH-TXOP) and Request-to-Send/Clear-to-Send (RTS/CTS) in terms of the network throughput by 10% and 3% as well as the network utility considering proportional fairness by 28.3% and 13.8%, respectively.", "paper_url": "http://arxiv.org/abs/2206.11378v1", "pdf_url": "http://arxiv.org/pdf/2206.11378v1", "repo_url": null}, "2206.13482": {"publish_time": "2022-06-27", "title": "Understanding Benign Overfitting in Nested Meta Learning", "author": "Lisha Chen et.al.", "abstract": "Meta learning has demonstrated tremendous success in few-shot learning with limited supervised data. In those settings, the meta model is usually overparameterized. While the conventional statistical learning theory suggests that overparameterized models tend to overfit, empirical evidence reveals that overparameterized meta learning methods still work well -- a phenomenon often called ``benign overfitting.'' To understand this phenomenon, we focus on the meta learning settings with a challenging nested structure that we term the nested meta learning, and analyze its generalization performance under an overparameterized meta learning model. While our analysis uses the relatively tractable linear models, our theory contributes to understanding the delicate interplay among data heterogeneity, model adaptation and benign overfitting in nested meta learning tasks. We corroborate our theoretical claims through numerical simulations.", "paper_url": "http://arxiv.org/abs/2206.13482v1", "pdf_url": "http://arxiv.org/pdf/2206.13482v1", "repo_url": null}, "2206.13074": {"publish_time": "2022-06-27", "title": "Leveraging Language for Accelerated Learning of Tool Manipulation", "author": "Allen Z. Ren et.al.", "abstract": "Robust and generalized tool manipulation requires an understanding of the properties and affordances of different tools. We investigate whether linguistic information about a tool (e.g., its geometry, common uses) can help control policies adapt faster to new tools for a given task. We obtain diverse descriptions of various tools in natural language and use pre-trained language models to generate their feature representations. We then perform language-conditioned meta-learning to learn policies that can efficiently adapt to new tools given their corresponding text descriptions. Our results demonstrate that combining linguistic information and meta-learning significantly accelerates tool learning in several manipulation tasks including pushing, lifting, sweeping, and hammering.", "paper_url": "http://arxiv.org/abs/2206.13074v1", "pdf_url": "http://arxiv.org/pdf/2206.13074v1", "repo_url": null}, "2206.12938": {"publish_time": "2022-06-26", "title": "Stackelberg Risk Preference Design", "author": "Shutian Liu et.al.", "abstract": "Risk measures are commonly used to capture the risk preferences of decision-makers (DMs). The decisions of DMs can be nudged or manipulated when their risk preferences are influenced by factors like the perception of losses and the availability of information about the uncertainties. In this work, we propose a Stackelberg risk preference design (STRIPE) problem to capture a designer's incentive to influence DMs' risk preferences. STRIPE consists of two levels. In the lower-level, individual DMs in a population, known as the followers, respond to uncertainties according to their risk preference types that specify their risk measures. In the upper-level, the leader influences the distribution of the types to induce targeted decisions and steers the follower's preferences to it. Our analysis centers around the solution concept of approximate Stackelberg equilibrium that yields suboptimal behaviors of the players. We show the existence of the approximate Stackelberg equilibrium. The primitive risk perception gap, defined as the Wasserstein distance between the original and the target type distributions, is important in estimating the optimal design cost. We connect the leader's optimality tolerance on the cost with her ambiguity tolerance on the follower's approximate solutions leveraging Lipschitzian properties of the lower-level solution mapping. To obtain the Stackelberg equilibrium, we reformulate STRIPE into a single-level optimization problem using the spectral representations of law-invariant coherent risk measures. We create a data-driven approach for computation and study its performance guarantees. We apply STRIPE to contract design problems to mitigate the intensity of moral hazard. Moreover, we connect STRIPE with meta-learning problems and derive adaptation performance estimates of the meta-parameter using the sensitivity of the optimal value function in the lower-level.", "paper_url": "http://arxiv.org/abs/2206.12938v1", "pdf_url": "http://arxiv.org/pdf/2206.12938v1", "repo_url": null}, "2206.12705": {"publish_time": "2022-06-25", "title": "p-Meta: Towards On-device Deep Model Adaptation", "author": "Zhongnan Qu et.al.", "abstract": "Data collected by IoT devices are often private and have a large diversity across users. Therefore, learning requires pre-training a model with available representative data samples, deploying the pre-trained model on IoT devices, and adapting the deployed model on the device with local data. Such an on-device adaption for deep learning empowered applications demands data and memory efficiency. However, existing gradient-based meta learning schemes fail to support memory-efficient adaptation. To this end, we propose p-Meta, a new meta learning method that enforces structure-wise partial parameter updates while ensuring fast generalization to unseen tasks. Evaluations on few-shot image classification and reinforcement learning tasks show that p-Meta not only improves the accuracy but also substantially reduces the peak dynamic memory by a factor of 2.5 on average compared to state-of-the-art few-shot adaptation methods.", "paper_url": "http://arxiv.org/abs/2206.12705v1", "pdf_url": "http://arxiv.org/pdf/2206.12705v1", "repo_url": null}, "2206.14801": {"publish_time": "2022-06-29", "title": "Meta-Learning over Time for Destination Prediction Tasks", "author": "Mark Tenzer et.al.", "abstract": "A need to understand and predict vehicles' behavior underlies both public and private goals in the transportation domain, including urban planning and management, ride-sharing services, and intelligent transportation systems. Individuals' preferences and intended destinations vary throughout the day, week, and year: for example, bars are most popular in the evenings, and beaches are most popular in the summer. Despite this principle, we note that recent studies on a popular benchmark dataset from Porto, Portugal have found, at best, only marginal improvements in predictive performance from incorporating temporal information. We propose an approach based on hypernetworks, a variant of meta-learning (\"learning to learn\") in which a neural network learns to change its own weights in response to an input. In our case, the weights responsible for destination prediction vary with the metadata, in particular the time, of the input trajectory. The time-conditioned weights notably improve the model's error relative to ablation studies and comparable prior work, and we confirm our hypothesis that knowledge of time should improve prediction of a vehicle's intended destination.", "paper_url": "http://arxiv.org/abs/2206.14801v1", "pdf_url": "http://arxiv.org/pdf/2206.14801v1", "repo_url": null}, "2206.14647": {"publish_time": "2022-06-28", "title": "Meta-Wrapper: Differentiable Wrapping Operator for User Interest Selection in CTR Prediction", "author": "Tianwei Cao et.al.", "abstract": "Click-through rate (CTR) prediction, whose goal is to predict the probability of the user to click on an item, has become increasingly significant in the recommender systems. Recently, some deep learning models with the ability to automatically extract the user interest from his/her behaviors have achieved great success. In these work, the attention mechanism is used to select the user interested items in historical behaviors, improving the performance of the CTR predictor. Normally, these attentive modules can be jointly trained with the base predictor by using gradient descents. In this paper, we regard user interest modeling as a feature selection problem, which we call user interest selection. For such a problem, we propose a novel approach under the framework of the wrapper method, which is named Meta-Wrapper. More specifically, we use a differentiable module as our wrapping operator and then recast its learning problem as a continuous bilevel optimization. Moreover, we use a meta-learning algorithm to solve the optimization and theoretically prove its convergence. Meanwhile, we also provide theoretical analysis to show that our proposed method 1) efficiencies the wrapper-based feature selection, and 2) achieves better resistance to overfitting. Finally, extensive experiments on three public datasets manifest the superiority of our method in boosting the performance of CTR prediction.", "paper_url": "http://arxiv.org/abs/2206.14647v1", "pdf_url": "http://arxiv.org/pdf/2206.14647v1", "repo_url": null}, "2207.01332": {"publish_time": "2022-07-04", "title": "The least-control principle for learning at equilibrium", "author": "Alexander Meulemans et.al.", "abstract": "Equilibrium systems are a powerful way to express neural computations. As special cases, they include models of great current interest in both neuroscience and machine learning, such as equilibrium recurrent neural networks, deep equilibrium models, or meta-learning. Here, we present a new principle for learning such systems with a temporally- and spatially-local rule. Our principle casts learning as a least-control problem, where we first introduce an optimal controller to lead the system towards a solution state, and then define learning as reducing the amount of control needed to reach such a state. We show that incorporating learning signals within a dynamics as an optimal control enables transmitting credit assignment information in previously unknown ways, avoids storing intermediate states in memory, and does not rely on infinitesimal learning signals. In practice, our principle leads to strong performance matching that of leading gradient-based learning methods when applied to an array of problems involving recurrent neural networks and meta-learning. Our results shed light on how the brain might learn and offer new ways of approaching a broad class of machine learning problems.", "paper_url": "http://arxiv.org/abs/2207.01332v1", "pdf_url": "http://arxiv.org/pdf/2207.01332v1", "repo_url": null}, "2207.00814": {"publish_time": "2022-06-30", "title": "Customized Conversational Recommender Systems", "author": "Shuokai Li et.al.", "abstract": "Conversational recommender systems (CRS) aim to capture user's current intentions and provide recommendations through real-time multi-turn conversational interactions. As a human-machine interactive system, it is essential for CRS to improve the user experience. However, most CRS methods neglect the importance of user experience. In this paper, we propose two key points for CRS to improve the user experience: (1) Speaking like a human, human can speak with different styles according to the current dialogue context. (2) Identifying fine-grained intentions, even for the same utterance, different users have diverse finegrained intentions, which are related to users' inherent preference. Based on the observations, we propose a novel CRS model, coined Customized Conversational Recommender System (CCRS), which customizes CRS model for users from three perspectives. For human-like dialogue services, we propose multi-style dialogue response generator which selects context-aware speaking style for utterance generation. To provide personalized recommendations, we extract user's current fine-grained intentions from dialogue context with the guidance of user's inherent preferences. Finally, to customize the model parameters for each user, we train the model from the meta-learning perspective. Extensive experiments and a series of analyses have shown the superiority of our CCRS on both the recommendation and dialogue services.", "paper_url": "http://arxiv.org/abs/2207.00814v1", "pdf_url": "http://arxiv.org/pdf/2207.00814v1", "repo_url": null}, "2207.02066": {"publish_time": "2022-07-05", "title": "Test-time Adaptation for Real Image Denoising via Meta-transfer Learning", "author": "Agus Gunawan et.al.", "abstract": "In recent years, a ton of research has been conducted on real image denoising tasks. However, the efforts are more focused on improving real image denoising through creating a better network architecture. We explore a different direction where we propose to improve real image denoising performance through a better learning strategy that can enable test-time adaptation on the multi-task network. The learning strategy is two stages where the first stage pre-train the network using meta-auxiliary learning to get better meta-initialization. Meanwhile, we use meta-learning for fine-tuning (meta-transfer learning) the network as the second stage of our training to enable test-time adaptation on real noisy images. To exploit a better learning strategy, we also propose a network architecture with self-supervised masked reconstruction loss. Experiments on a real noisy dataset show the contribution of the proposed method and show that the proposed method can outperform other SOTA methods.", "paper_url": "http://arxiv.org/abs/2207.02066v1", "pdf_url": "http://arxiv.org/pdf/2207.02066v1", "repo_url": null}, "2207.01848": {"publish_time": "2022-07-05", "title": "Meta-Learning a Real-Time Tabular AutoML Method For Small Data", "author": "Noah Hollmann et.al.", "abstract": "We present TabPFN, an AutoML method that is competitive with the state of the art on small tabular datasets while being over 1,000$\\times$ faster. Our method is very simple: it is fully entailed in the weights of a single neural network, and a single forward pass directly yields predictions for a new dataset. Our AutoML method is meta-learned using the Transformer-based Prior-Data Fitted Network (PFN) architecture and approximates Bayesian inference with a prior that is based on assumptions of simplicity and causal structures. The prior contains a large space of structural causal models and Bayesian neural networks with a bias for small architectures and thus low complexity. Furthermore, we extend the PFN approach to differentiably calibrate the prior's hyperparameters on real data. By doing so, we separate our abstract prior assumptions from their heuristic calibration on real data. Afterwards, the calibrated hyperparameters are fixed and TabPFN can be applied to any new tabular dataset at the push of a button. Finally, on 30 datasets from the OpenML-CC18 suite we show that our method outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with predictions produced in less than a second. We provide all our code and our final trained TabPFN in the supplementary materials.", "paper_url": "http://arxiv.org/abs/2207.01848v1", "pdf_url": "http://arxiv.org/pdf/2207.01848v1", "repo_url": "https://github.com/noahho/tabpfn"}, "2207.01784": {"publish_time": "2022-07-05", "title": "A Unified Meta-Learning Framework for Dynamic Transfer Learning", "author": "Jun Wu et.al.", "abstract": "Transfer learning refers to the transfer of knowledge or information from a relevant source task to a target task. However, most existing works assume both tasks are sampled from a stationary task distribution, thereby leading to the sub-optimal performance for dynamic tasks drawn from a non-stationary task distribution in real scenarios. To bridge this gap, in this paper, we study a more realistic and challenging transfer learning setting with dynamic tasks, i.e., source and target tasks are continuously evolving over time. We theoretically show that the expected error on the dynamic target task can be tightly bounded in terms of source knowledge and consecutive distribution discrepancy across tasks. This result motivates us to propose a generic meta-learning framework L2E for modeling the knowledge transferability on dynamic tasks. It is centered around a task-guided meta-learning problem with a group of meta-pairs of tasks, based on which we are able to learn the prior model initialization for fast adaptation on the newest target task. L2E enjoys the following properties: (1) effective knowledge transferability across dynamic tasks; (2) fast adaptation to the new target task; (3) mitigation of catastrophic forgetting on historical target tasks; and (4) flexibility in incorporating any existing static transfer learning algorithms. Extensive experiments on various image data sets demonstrate the effectiveness of the proposed L2E framework.", "paper_url": "http://arxiv.org/abs/2207.01784v1", "pdf_url": "http://arxiv.org/pdf/2207.01784v1", "repo_url": "https://github.com/jwu4sml/l2e"}, "2207.01723": {"publish_time": "2022-07-04", "title": "Adaptive Fine-Grained Sketch-Based Image Retrieval", "author": "Ayan Kumar Bhunia et.al.", "abstract": "The recent focus on Fine-Grained Sketch-Based Image Retrieval (FG-SBIR) has shifted towards generalising a model to new categories without any training data from them. In real-world applications, however, a trained FG-SBIR model is often applied to both new categories and different human sketchers, i.e., different drawing styles. Although this complicates the generalisation problem, fortunately, a handful of examples are typically available, enabling the model to adapt to the new category/style. In this paper, we offer a novel perspective -- instead of asking for a model that generalises, we advocate for one that quickly adapts, with just very few samples during testing (in a few-shot manner). To solve this new problem, we introduce a novel model-agnostic meta-learning (MAML) based framework with several key modifications: (1) As a retrieval task with a margin-based contrastive loss, we simplify the MAML training in the inner loop to make it more stable and tractable. (2) The margin in our contrastive loss is also meta-learned with the rest of the model. (3) Three additional regularisation losses are introduced in the outer loop, to make the meta-learned FG-SBIR model more effective for category/style adaptation. Extensive experiments on public datasets suggest a large gain over generalisation and zero-shot based approaches, and a few strong few-shot baselines.", "paper_url": "http://arxiv.org/abs/2207.01723v2", "pdf_url": "http://arxiv.org/pdf/2207.01723v2", "repo_url": null}, "2207.02440": {"publish_time": "2022-07-06", "title": "PAC Prediction Sets for Meta-Learning", "author": "Sangdon Park et.al.", "abstract": "Uncertainty quantification is a key component of machine learning models targeted at safety-critical systems such as in healthcare or autonomous vehicles. We study this problem in the context of meta learning, where the goal is to quickly adapt a predictor to new tasks. In particular, we propose a novel algorithm to construct \\emph{PAC prediction sets}, which capture uncertainty via sets of labels, that can be adapted to new tasks with only a few training examples. These prediction sets satisfy an extension of the typical PAC guarantee to the meta learning setting; in particular, the PAC guarantee holds with high probability over future tasks. We demonstrate the efficacy of our approach on four datasets across three application domains: mini-ImageNet and CIFAR10-C in the visual domain, FewRel in the language domain, and the CDC Heart Dataset in the medical domain. In particular, our prediction sets satisfy the PAC guarantee while having smaller size compared to other baselines that also satisfy this guarantee.", "paper_url": "http://arxiv.org/abs/2207.02440v1", "pdf_url": "http://arxiv.org/pdf/2207.02440v1", "repo_url": null}, "2207.03448": {"publish_time": "2022-07-07", "title": "Adaptive Personlization in Federated Learning for Highly Non-i.i.d. Data", "author": "Yousef Yeganeh et.al.", "abstract": "Federated learning (FL) is a distributed learning method that offers medical institutes the prospect of collaboration in a global model while preserving the privacy of their patients. Although most medical centers conduct similar medical imaging tasks, their differences, such as specializations, number of patients, and devices, lead to distinctive data distributions. Data heterogeneity poses a challenge for FL and the personalization of the local models. In this work, we investigate an adaptive hierarchical clustering method for FL to produce intermediate semi-global models, so clients with similar data distribution have the chance of forming a more specialized model. Our method forms several clusters consisting of clients with the most similar data distributions; then, each cluster continues to train separately. Inside the cluster, we use meta-learning to improve the personalization of the participants' models. We compare the clustering approach with classical FedAvg and centralized training by evaluating our proposed methods on the HAM10k dataset for skin lesion classification with extreme heterogeneous data distribution. Our experiments demonstrate significant performance gain in heterogeneous distribution compared to standard FL methods in classification accuracy. Moreover, we show that the models converge faster if applied in clusters and outperform centralized training while using only a small subset of data.", "paper_url": "http://arxiv.org/abs/2207.03448v1", "pdf_url": "http://arxiv.org/pdf/2207.03448v1", "repo_url": null}, "2207.03132": {"publish_time": "2022-07-07", "title": "Style Interleaved Learning for Generalizable Person Re-identification", "author": "Wentao Tan et.al.", "abstract": "Domain generalization (DG) for person re-identification (ReID) is a challenging problem, as there is no access to target domain data permitted during the training process. Most existing DG ReID methods employ the same features for the updating of the feature extractor and classifier parameters. This common practice causes the model to overfit to existing feature styles in the source domain, resulting in sub-optimal generalization ability on target domains even if meta-learning is used. To solve this problem, we propose a novel style interleaved learning framework. Unlike conventional learning strategies, interleaved learning incorporates two forward propagations and one backward propagation for each iteration. We employ the features of interleaved styles to update the feature extractor and classifiers using different forward propagations, which helps the model avoid overfitting to certain domain styles. In order to fully explore the advantages of style interleaved learning, we further propose a novel feature stylization approach to diversify feature styles. This approach not only mixes the feature styles of multiple training samples, but also samples new and meaningful feature styles from batch-level style distribution. Extensive experimental results show that our model consistently outperforms state-of-the-art methods on large-scale benchmarks for DG ReID, yielding clear advantages in computational efficiency. Code is available at https://github.com/WentaoTan/Interleaved-Learning.", "paper_url": "http://arxiv.org/abs/2207.03132v1", "pdf_url": "http://arxiv.org/pdf/2207.03132v1", "repo_url": null}, "2207.03051": {"publish_time": "2022-07-07", "title": "A Large Scale Search Dataset for Unbiased Learning to Rank", "author": "Lixin Zou et.al.", "abstract": "The unbiased learning to rank (ULTR) problem has been greatly advanced by recent deep learning techniques and well-designed debias algorithms. However, promising results on the existing benchmark datasets may not be extended to the practical scenario due to the following disadvantages observed from those popular benchmark datasets: (1) outdated semantic feature extraction where state-of-the-art large scale pre-trained language models like BERT cannot be exploited due to the missing of the original text;(2) incomplete display features for in-depth study of ULTR, e.g., missing the displayed abstract of documents for analyzing the click necessary bias; (3) lacking real-world user feedback, leading to the prevalence of synthetic datasets in the empirical study. To overcome the above disadvantages, we introduce the Baidu-ULTR dataset. It involves randomly sampled 1.2 billion searching sessions and 7,008 expert annotated queries, which is orders of magnitude larger than the existing ones. Baidu-ULTR provides:(1) the original semantic feature and a pre-trained language model for easy usage; (2) sufficient display information such as position, displayed height, and displayed abstract, enabling the comprehensive study of different biases with advanced techniques such as causal discovery and meta-learning; and (3) rich user feedback on search result pages (SERPs) like dwelling time, allowing for user engagement optimization and promoting the exploration of multi-task learning in ULTR. In this paper, we present the design principle of Baidu-ULTR and the performance of benchmark ULTR algorithms on this new data resource, favoring the exploration of ranking for long-tail queries and pre-training tasks for ranking. The Baidu-ULTR dataset and corresponding baseline implementation are available at https://github.com/ChuXiaokai/baidu_ultr_dataset.", "paper_url": "http://arxiv.org/abs/2207.03051v1", "pdf_url": "http://arxiv.org/pdf/2207.03051v1", "repo_url": "https://github.com/chuxiaokai/baidu_ultr_dataset"}, "2207.03333": {"publish_time": "2022-07-06", "title": "FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments", "author": "Jishnu Jaykumar P et.al.", "abstract": "We introduce the Few-Shot Object Learning (FewSOL) dataset for object recognition with a few images per object. We captured 336 real-world objects with 9 RGB-D images per object from different views. Object segmentation masks, object poses and object attributes are provided. In addition, synthetic images generated using 330 3D object models are used to augment the dataset. We investigated (i) few-shot object classification and (ii) joint object segmentation and few-shot classification with the state-of-the-art methods for few-shot learning and meta-learning using our dataset. The evaluation results show that there is still a large margin to be improved for few-shot object classification in robotic environments. Our dataset can be used to study a set of few-shot object recognition problems such as classification, detection and segmentation, shape reconstruction, pose estimation, keypoint correspondences and attribute recognition. The dataset and code are available at https://irvlutd.github.io/FewSOL.", "paper_url": "http://arxiv.org/abs/2207.03333v1", "pdf_url": "http://arxiv.org/pdf/2207.03333v1", "repo_url": "https://github.com/IRVLUTD/meta-dataset"}}, "Transfer Learning": {"2202.12814": {"publish_time": "2022-02-25", "title": "The Reality of Multi-Lingual Machine Translation", "author": "Tom Kocmi et.al.", "abstract": "Our book \"The Reality of Multi-Lingual Machine Translation\" discusses the benefits and perils of using more than two languages in machine translation systems. While focused on the particular task of sequence-to-sequence processing and multi-task learning, the book targets somewhat beyond the area of natural language processing. Machine translation is for us a prime example of deep learning applications where human skills and learning capabilities are taken as a benchmark that many try to match and surpass. We document that some of the gains observed in multi-lingual translation may result from simpler effects than the assumed cross-lingual transfer of knowledge.   In the first, rather general part, the book will lead you through the motivation for multi-linguality, the versatility of deep neural networks especially in sequence-to-sequence tasks to complications of this learning. We conclude the general part with warnings against too optimistic and unjustified explanations of the gains that neural networks demonstrate.   In the second part, we fully delve into multi-lingual models, with a particularly careful examination of transfer learning as one of the more straightforward approaches utilizing additional languages. The recent multi-lingual techniques, including massive models, are surveyed and practical aspects of deploying systems for many languages are discussed. The conclusion highlights the open problem of machine understanding and reminds of two ethical aspects of building large-scale models: the inclusivity of research and its ecological trace.", "paper_url": "http://arxiv.org/abs/2202.12814v1", "pdf_url": "http://arxiv.org/pdf/2202.12814v1", "repo_url": null}, "2202.12576": {"publish_time": "2022-02-25", "title": "A Survey of Multilingual Models for Automatic Speech Recognition", "author": "Hemant Yadav et.al.", "abstract": "Although Automatic Speech Recognition (ASR) systems have achieved human-like performance for a few languages, the majority of the world's languages do not have usable systems due to the lack of large speech datasets to train these models. Cross-lingual transfer is an attractive solution to this problem, because low-resource languages can potentially benefit from higher-resource languages either through transfer learning, or being jointly trained in the same multilingual model. The problem of cross-lingual transfer has been well studied in ASR, however, recent advances in Self Supervised Learning are opening up avenues for unlabeled speech data to be used in multilingual ASR models, which can pave the way for improved performance on low-resource languages. In this paper, we survey the state of the art in multilingual ASR models that are built with cross-lingual transfer in mind. We present best practices for building multilingual models from research across diverse languages and techniques, discuss open questions and provide recommendations for future work.", "paper_url": "http://arxiv.org/abs/2202.12576v1", "pdf_url": "http://arxiv.org/pdf/2202.12576v1", "repo_url": null}, "2202.12505": {"publish_time": "2022-02-25", "title": "A Deep Learning Approach for Network-wide Dynamic Traffic Prediction during Hurricane Evacuation", "author": "Rezaur Rahman et.al.", "abstract": "Proactive evacuation traffic management largely depends on real-time monitoring and prediction of traffic flow at a high spatiotemporal resolution. However, evacuation traffic prediction is challenging due to the uncertainties caused by sudden changes in projected hurricane paths and consequently household evacuation behavior. Moreover, modeling spatiotemporal traffic flow patterns requires extensive data over a longer time period, whereas evacuations typically last for 2 to 5 days. In this paper, we present a novel data-driven approach for predicting evacuation traffic at a network scale. We develop a dynamic graph convolution LSTM (DGCN-LSTM) model to learn the network dynamics of hurricane evacuation. We first train the model for non-evacuation period traffic data showing that the model outperforms existing deep learning models for predicting non-evacuation period traffic with an RMSE value of 226.84. However, when we apply the model for evacuation period, the RMSE value increased to 1440.99. We overcome this issue by adopting a transfer learning approach with additional features related to evacuation traffic demand such as distance from the evacuation zone, time to landfall, and other zonal level features to control the transfer of information (network dynamics) from non-evacuation periods to evacuation periods. The final transfer learned DGCN-LSTM model performs well to predict evacuation traffic flow (RMSE=399.69). The implemented model can be applied to predict evacuation traffic over a longer forecasting horizon (6 hour). It will assist transportation agencies to activate appropriate traffic management strategies to reduce delays for evacuating traffic.", "paper_url": "http://arxiv.org/abs/2202.12505v1", "pdf_url": "http://arxiv.org/pdf/2202.12505v1", "repo_url": null}, "2202.12174": {"publish_time": "2022-02-24", "title": "Collaborative Training of Heterogeneous Reinforcement Learning Agents in Environments with Sparse Rewards: What and When to Share?", "author": "Alain Andres et.al.", "abstract": "In the early stages of human life, babies develop their skills by exploring different scenarios motivated by their inherent satisfaction rather than by extrinsic rewards from the environment. This behavior, referred to as intrinsic motivation, has emerged as one solution to address the exploration challenge derived from reinforcement learning environments with sparse rewards. Diverse exploration approaches have been proposed to accelerate the learning process over single- and multi-agent problems with homogeneous agents. However, scarce studies have elaborated on collaborative learning frameworks between heterogeneous agents deployed into the same environment, but interacting with different instances of the latter without any prior knowledge. Beyond the heterogeneity, each agent's characteristics grant access only to a subset of the full state space, which may hide different exploration strategies and optimal solutions. In this work we combine ideas from intrinsic motivation and transfer learning. Specifically, we focus on sharing parameters in actor-critic model architectures and on combining information obtained through intrinsic motivation with the aim of having a more efficient exploration and faster learning. We test our strategies through experiments performed over a modified ViZDooM's My Way Home scenario, which is more challenging than its original version and allows evaluating the heterogeneity between agents. Our results reveal different ways in which a collaborative framework with little additional computational cost can outperform an independent learning process without knowledge sharing. Additionally, we depict the need for modulating correctly the importance between the extrinsic and intrinsic rewards to avoid undesired agent behaviors.", "paper_url": "http://arxiv.org/abs/2202.12174v1", "pdf_url": "http://arxiv.org/pdf/2202.12174v1", "repo_url": null}, "2202.11685": {"publish_time": "2022-02-23", "title": "A Class of Geometric Structures in Transfer Learning: Minimax Bounds and Optimality", "author": "Xuhui Zhang et.al.", "abstract": "We study the problem of transfer learning, observing that previous efforts to understand its information-theoretic limits do not fully exploit the geometric structure of the source and target domains. In contrast, our study first illustrates the benefits of incorporating a natural geometric structure within a linear regression model, which corresponds to the generalized eigenvalue problem formed by the Gram matrices of both domains. We next establish a finite-sample minimax lower bound, propose a refined model interpolation estimator that enjoys a matching upper bound, and then extend our framework to multiple source domains and generalized linear models. Surprisingly, as long as information is available on the distance between the source and target parameters, negative-transfer does not occur. Simulation studies show that our proposed interpolation estimator outperforms state-of-the-art transfer learning methods in both moderate- and high-dimensional settings.", "paper_url": "http://arxiv.org/abs/2202.11685v1", "pdf_url": "http://arxiv.org/pdf/2202.11685v1", "repo_url": null}, "2202.13626": {"publish_time": "2022-02-28", "title": "Improving Response Time of Home IoT Services in Federated Learning", "author": "Dongjun Hwang et.al.", "abstract": "For intelligent home IoT services with sensors and machine learning, we need to upload IoT data to the cloud server which cannot share private data for training. A recent machine learning approach, called federated learning, keeps user data on the device in the distributed computing environment. Though federated learning is useful for protecting privacy, it experiences poor performance in terms of the end-to-end response time in home IoT services, because IoT devices are usually controlled by remote servers in the cloud. In addition, it is difficult to achieve the high accuracy of federated learning models due to insufficient data problems and model inversion attacks. In this paper, we propose a local IoT control method for a federated learning home service that recognizes the user behavior in the home network quickly and accurately. We present a federated learning client with transfer learning and differential privacy to solve data scarcity and data model inversion attack problems. From experiments, we show that the local control of home IoT devices for user authentication and control message transmission by the federated learning clients improves the response time to less than 1 second. Moreover, we demonstrate that federated learning with transfer learning achieves 97% of accuracy under 9,000 samples, which is only 2% of the difference from centralized learning.", "paper_url": "http://arxiv.org/abs/2202.13626v1", "pdf_url": "http://arxiv.org/pdf/2202.13626v1", "repo_url": "https://github.com/hwangdongjun/federated_learning_using_websockets"}, "2202.13403": {"publish_time": "2022-02-27", "title": "A Multimodal German Dataset for Automatic Lip Reading Systems and Transfer Learning", "author": "Gerald Schwiebert et.al.", "abstract": "Large datasets as required for deep learning of lip reading do not exist in many languages. In this paper we present the dataset GLips (German Lips) consisting of 250,000 publicly available videos of the faces of speakers of the Hessian Parliament, which was processed for word-level lip reading using an automatic pipeline. The format is similar to that of the English language LRW (Lip Reading in the Wild) dataset, with each video encoding one word of interest in a context of 1.16 seconds duration, which yields compatibility for studying transfer learning between both datasets. By training a deep neural network, we investigate whether lip reading has language-independent features, so that datasets of different languages can be used to improve lip reading models. We demonstrate learning from scratch and show that transfer learning from LRW to GLips and vice versa improves learning speed and performance, in particular for the validation set.", "paper_url": "http://arxiv.org/abs/2202.13403v1", "pdf_url": "http://arxiv.org/pdf/2202.13403v1", "repo_url": null}, "2202.13174": {"publish_time": "2022-02-26", "title": "BioADAPT-MRC: Adversarial Learning-based Domain Adaptation Improves Biomedical Machine Reading Comprehension Task", "author": "Maria Mahbub et.al.", "abstract": "Motivation: Biomedical machine reading comprehension (biomedical-MRC) aims to comprehend complex biomedical narratives and assist healthcare professionals in retrieving information from them. The high performance of modern neural network-based MRC systems depends on high-quality, large-scale, human-annotated training datasets. In the biomedical domain, a crucial challenge in creating such datasets is the requirement for domain knowledge, inducing the scarcity of labeled data and the need for transfer learning from the labeled general-purpose (source) domain to the biomedical (target) domain. However, there is a discrepancy in marginal distributions between the general-purpose and biomedical domains due to the variances in topics. Therefore, direct-transferring of learned representations from a model trained on a general-purpose domain to the biomedical domain can hurt the model's performance.   Results: We present an adversarial learning-based domain adaptation framework for the biomedical machine reading comprehension task (BioADAPT-MRC), a neural network-based method to address the discrepancies in the marginal distributions between the general and biomedical domain datasets. BioADAPT-MRC relaxes the need for generating pseudo labels for training a well-performing biomedical-MRC model. We extensively evaluate the performance of BioADAPT-MRC by comparing it with the best existing methods on three widely used benchmark biomedical-MRC datasets -- BioASQ-7b, BioASQ-8b, and BioASQ-9b. Our results suggest that without using any synthetic or human-annotated data from the biomedical domain, BioADAPT-MRC can achieve state-of-the-art performance on these datasets.   Availability: BioADAPT-MRC is freely available as an open-source project at\\\\https://github.com/mmahbub/BioADAPT-MRC", "paper_url": "http://arxiv.org/abs/2202.13174v1", "pdf_url": "http://arxiv.org/pdf/2202.13174v1", "repo_url": null}, "2203.00585": {"publish_time": "2022-03-01", "title": "Self-Supervised Vision Transformers Learn Visual Concepts in Histopathology", "author": "Richard J. Chen et.al.", "abstract": "Tissue phenotyping is a fundamental task in learning objective characterizations of histopathologic biomarkers within the tumor-immune microenvironment in cancer pathology. However, whole-slide imaging (WSI) is a complex computer vision in which: 1) WSIs have enormous image resolutions with precludes large-scale pixel-level efforts in data curation, and 2) diversity of morphological phenotypes results in inter- and intra-observer variability in tissue labeling. To address these limitations, current efforts have proposed using pretrained image encoders (transfer learning from ImageNet, self-supervised pretraining) in extracting morphological features from pathology, but have not been extensively validated. In this work, we conduct a search for good representations in pathology by training a variety of self-supervised models with validation on a variety of weakly-supervised and patch-level tasks. Our key finding is in discovering that Vision Transformers using DINO-based knowledge distillation are able to learn data-efficient and interpretable features in histology images wherein the different attention heads learn distinct morphological phenotypes. We make evaluation code and pretrained weights publicly-available at: https://github.com/Richarizardd/Self-Supervised-ViT-Path.", "paper_url": "http://arxiv.org/abs/2203.00585v1", "pdf_url": "http://arxiv.org/pdf/2203.00585v1", "repo_url": "https://github.com/richarizardd/self-supervised-vit-path"}, "2203.00355": {"publish_time": "2022-03-01", "title": "Tempera: Spatial Transformer Feature Pyramid Network for Cardiac MRI Segmentation", "author": "Christoforos Galazis et.al.", "abstract": "Assessing the structure and function of the right ventricle (RV) is important in the diagnosis of several cardiac pathologies. However, it remains more challenging to segment the RV than the left ventricle (LV). In this paper, we focus on segmenting the RV in both short (SA) and long-axis (LA) cardiac MR images simultaneously. For this task, we propose a new multi-input/output architecture, hybrid 2D/3D geometric spatial TransformEr Multi-Pass fEature pyRAmid (Tempera). Our feature pyramid extends current designs by allowing not only a multi-scale feature output but multi-scale SA and LA input images as well. Tempera transfers learned features between SA and LA images via layer weight sharing and incorporates a geometric target transformer to map the predicted SA segmentation to LA space. Our model achieves an average Dice score of 0.836 and 0.798 for the SA and LA, respectively, and 26.31 mm and 31.19 mm Hausdorff distances. This opens up the potential for the incorporation of RV segmentation models into clinical workflows.", "paper_url": "http://arxiv.org/abs/2203.00355v1", "pdf_url": "http://arxiv.org/pdf/2203.00355v1", "repo_url": "https://github.com/cgalaz01/mnms2_challenge"}, "2203.00251": {"publish_time": "2022-03-01", "title": "FIRL: Fast Imitation and Policy Reuse Learning", "author": "Yiwen Chen et.al.", "abstract": "Intelligent robotics policies have been widely researched for challenging applications such as opening doors, washing dishes, and table organization. We refer to a \"Policy Pool\", containing skills that be easily accessed and reused. There are researches to leverage the pool, such as policy reuse, modular learning, assembly learning, transfer learning, hierarchical reinforcement learning (HRL), etc. However, most methods generally do not perform well in learning efficiency and require large datasets for training. This work focuses on enabling fast learning based on the policy pool. It should learn fast enough in one-shot or few-shot by avoiding learning from scratch. We also allow it to interact and learn from humans, but the training period should be within minutes. We propose FIRL, Fast (one-shot) Imitation, and Policy Reuse Learning. Instead of learning a new skill from scratch, it performs the one-shot imitation learning on the higher layer under a 2-layer hierarchical mechanism. Our method reduces a complex task learning to a simple regression problem that it could solve in a few offline iterations. The agent could have a good command of a new task given a one-shot demonstration. We demonstrate this method on the OpenDoors mini-grid environment, and the code is available on http://www.github.com/yiwc/firl.", "paper_url": "http://arxiv.org/abs/2203.00251v1", "pdf_url": "http://arxiv.org/pdf/2203.00251v1", "repo_url": "https://github.com/yiwc/firl"}, "2203.01311": {"publish_time": "2022-03-02", "title": "HighMMT: Towards Modality and Task Generalization for High-Modality Representation Learning", "author": "Paul Pu Liang et.al.", "abstract": "Learning multimodal representations involves discovering correspondences and integrating information from multiple heterogeneous sources of data. While recent research has begun to explore the design of more general-purpose multimodal models (contrary to prior focus on domain and modality-specific architectures), these methods are still largely focused on a small set of modalities in the language, vision, and audio space. In order to accelerate generalization towards diverse and understudied modalities, we investigate methods for high-modality (a large set of diverse modalities) and partially-observable (each task only defined on a small subset of modalities) scenarios. To tackle these challenges, we design a general multimodal model that enables multitask and transfer learning: multitask learning with shared parameters enables stable parameter counts (addressing scalability), and cross-modal transfer learning enables information sharing across modalities and tasks (addressing partial observability). Our resulting model generalizes across text, image, video, audio, time-series, sensors, tables, and set modalities from different research areas, improves the tradeoff between performance and efficiency, transfers to new modalities and tasks, and reveals surprising insights on the nature of information sharing in multitask models. We release our code and benchmarks which we hope will present a unified platform for subsequent theoretical and empirical analysis: https://github.com/pliang279/HighMMT.", "paper_url": "http://arxiv.org/abs/2203.01311v2", "pdf_url": "http://arxiv.org/pdf/2203.01311v2", "repo_url": "https://github.com/pliang279/highmmt"}, "2203.01265": {"publish_time": "2022-03-02", "title": "Self-supervised Transformer for Deepfake Detection", "author": "Hanqing Zhao et.al.", "abstract": "The fast evolution and widespread of deepfake techniques in real-world scenarios require stronger generalization abilities of face forgery detectors. Some works capture the features that are unrelated to method-specific artifacts, such as clues of blending boundary, accumulated up-sampling, to strengthen the generalization ability. However, the effectiveness of these methods can be easily corrupted by post-processing operations such as compression. Inspired by transfer learning, neural networks pre-trained on other large-scale face-related tasks may provide useful features for deepfake detection. For example, lip movement has been proved to be a kind of robust and good-transferring highlevel semantic feature, which can be learned from the lipreading task. However, the existing method pre-trains the lip feature extraction model in a supervised manner, which requires plenty of human resources in data annotation and increases the difficulty of obtaining training data. In this paper, we propose a self-supervised transformer based audio-visual contrastive learning method. The proposed method learns mouth motion representations by encouraging the paired video and audio representations to be close while unpaired ones to be diverse. After pre-training with our method, the model will then be partially fine-tuned for deepfake detection task. Extensive experiments show that our self-supervised method performs comparably or even better than the supervised pre-training counterpart.", "paper_url": "http://arxiv.org/abs/2203.01265v1", "pdf_url": "http://arxiv.org/pdf/2203.01265v1", "repo_url": null}, "2203.01187": {"publish_time": "2022-03-02", "title": "Visual Feature Encoding for GNNs on Road Networks", "author": "Oliver Stromann et.al.", "abstract": "In this work, we present a novel approach to learning an encoding of visual features into graph neural networks with the application on road network data. We propose an architecture that combines state-of-the-art vision backbone networks with graph neural networks. More specifically, we perform a road type classification task on an Open Street Map road network through encoding of satellite imagery using various ResNet architectures. Our architecture further enables fine-tuning and a transfer-learning approach is evaluated by pretraining on the NWPU-RESISC45 image classification dataset for remote sensing and comparing them to purely ImageNet-pretrained ResNet models as visual feature encoders. The results show not only that the visual feature encoders are superior to low-level visual features, but also that the fine-tuning of the visual feature encoder to a general remote sensing dataset such as NWPU-RESISC45 can further improve the performance of a GNN on a machine learning task like road type classification.", "paper_url": "http://arxiv.org/abs/2203.01187v1", "pdf_url": "http://arxiv.org/pdf/2203.01187v1", "repo_url": null}, "2203.01111": {"publish_time": "2022-03-02", "title": "Large-Scale Hate Speech Detection with Cross-Domain Transfer", "author": "Cagri Toraman et.al.", "abstract": "The performance of hate speech detection models relies on the datasets on which the models are trained. Existing datasets are mostly prepared with a limited number of instances or hate domains that define hate topics. This hinders large-scale analysis and transfer learning with respect to hate domains. In this study, we construct large-scale tweet datasets for hate speech detection in English and a low-resource language, Turkish, consisting of human-labeled 100k tweets per each. Our datasets are designed to have equal number of tweets distributed over five domains. The experimental results supported by statistical tests show that Transformer-based language models outperform conventional bag-of-words and neural models by at least 5% in English and 10% in Turkish for large-scale hate speech detection. The performance is also scalable to different training sizes, such that 98% of performance in English, and 97% in Turkish, are recovered when 20% of training instances are used. We further examine the generalization ability of cross-domain transfer among hate domains. We show that 96% of the performance of a target domain in average is recovered by other domains for English, and 92% for Turkish. Gender and religion are more successful to generalize to other domains, while sports fail most.", "paper_url": "http://arxiv.org/abs/2203.01111v1", "pdf_url": "http://arxiv.org/pdf/2203.01111v1", "repo_url": "https://github.com/avaapm/hatespeech"}, "2203.00853": {"publish_time": "2022-03-02", "title": "Transfer Learning of High-Fidelity Opacity Spectra in Autoencoders and Surrogate Models", "author": "Michael D. Vander Wal et.al.", "abstract": "Simulations of high energy density physics are expensive, largely in part for the need to produce non-local thermodynamic equilibrium opacities. High-fidelity spectra may reveal new physics in the simulations not seen with low-fidelity spectra, but the cost of these simulations also scale with the level of fidelity of the opacities being used. Neural networks are capable of reproducing these spectra, but neural networks need data to to train them which limits the level of fidelity of the training data. This paper demonstrates that it is possible to reproduce high-fidelity spectra with median errors in the realm of 3\\% to 4\\% using as few as 50 samples of high-fidelity Krypton data by performing transfer learning on a neural network trained on many times more low-fidelity data.", "paper_url": "http://arxiv.org/abs/2203.00853v1", "pdf_url": "http://arxiv.org/pdf/2203.00853v1", "repo_url": null}, "2203.01655": {"publish_time": "2022-03-03", "title": "On partitioning of an SHM problem and parallels with transfer learning", "author": "G. Tsialiamanis et.al.", "abstract": "In the current work, a problem-splitting approach and a scheme motivated by transfer learning is applied to a structural health monitoring problem. The specific problem in this case is that of localising damage on an aircraft wing. The original experiment is described, together with the initial approach, in which a neural network was trained to localise damage. The results were not ideal, partly because of a scarcity of training data, and partly because of the difficulty in resolving two of the damage cases. In the current paper, the problem is split into two sub-problems and an increase in classification accuracy is obtained. The sub-problems are obtained by separating out the most difficult-to-classify damage cases. A second approach to the problem is considered by adopting ideas from transfer learning (usually applied in much deeper) networks to see if a network trained on the simpler damage cases can help with feature extraction in the more difficult cases. The transfer of a fixed trained batch of layers between the networks is found to improve classification by making the classes more separable in the feature space and to speed up convergence.", "paper_url": "http://arxiv.org/abs/2203.01655v1", "pdf_url": "http://arxiv.org/pdf/2203.01655v1", "repo_url": null}, "2203.03443": {"publish_time": "2022-03-07", "title": "Generalization Through The Lens Of Leave-One-Out Error", "author": "Gregor Bachmann et.al.", "abstract": "Despite the tremendous empirical success of deep learning models to solve various learning tasks, our theoretical understanding of their generalization ability is very limited. Classical generalization bounds based on tools such as the VC dimension or Rademacher complexity, are so far unsuitable for deep models and it is doubtful that these techniques can yield tight bounds even in the most idealistic settings (Nagarajan & Kolter, 2019). In this work, we instead revisit the concept of leave-one-out (LOO) error to measure the generalization ability of deep models in the so-called kernel regime. While popular in statistics, the LOO error has been largely overlooked in the context of deep learning. By building upon the recently established connection between neural networks and kernel learning, we leverage the closed-form expression for the leave-one-out error, giving us access to an efficient proxy for the test error. We show both theoretically and empirically that the leave-one-out error is capable of capturing various phenomena in generalization theory, such as double descent, random labels or transfer learning. Our work therefore demonstrates that the leave-one-out error provides a tractable way to estimate the generalization ability of deep neural networks in the kernel regime, opening the door to potential, new research directions in the field of generalization.", "paper_url": "http://arxiv.org/abs/2203.03443v1", "pdf_url": "http://arxiv.org/pdf/2203.03443v1", "repo_url": "https://github.com/gregorbachmann/leaveoneout"}, "2203.03227": {"publish_time": "2022-03-07", "title": "Knowledge Transfer in Deep Reinforcement Learning for Slice-Aware Mobility Robustness Optimization", "author": "Qi Liao et.al.", "abstract": "The legacy mobility robustness optimization (MRO) in self-organizing networks aims at improving handover performance by optimizing cell-specific handover parameters. However, such solutions cannot satisfy the needs of next-generation network with network slicing, because it only guarantees the received signal strength but not the per-slice service quality. To provide the truly seamless mobility service, we propose a deep reinforcement learning-based slice-aware mobility robustness optimization (SAMRO) approach, which improves handover performance with per-slice service assurance by optimizing slice-specific handover parameters. Moreover, to allow safe and sample efficient online training, we develop a two-step transfer learning scheme: 1) regularized offline reinforcement learning, and 2) effective online fine-tuning with mixed experience replay. System-level simulations show that compared against the legacy MRO algorithms, SAMRO significantly improves slice-aware service continuation while optimizing the handover performance.", "paper_url": "http://arxiv.org/abs/2203.03227v1", "pdf_url": "http://arxiv.org/pdf/2203.03227v1", "repo_url": null}, "2203.04287": {"publish_time": "2022-03-08", "title": "A Simple Multi-Modality Transfer Learning Baseline for Sign Language Translation", "author": "Yutong Chen et.al.", "abstract": "This paper proposes a simple transfer learning baseline for sign language translation. Existing sign language datasets (e.g. PHOENIX-2014T, CSL-Daily) contain only about 10K-20K pairs of sign videos, gloss annotations and texts, which are an order of magnitude smaller than typical parallel data for training spoken language translation models. Data is thus a bottleneck for training effective sign language translation models. To mitigate this problem, we propose to progressively pretrain the model from general-domain datasets that include a large amount of external supervision to within-domain datasets. Concretely, we pretrain the sign-to-gloss visual network on the general domain of human actions and the within-domain of a sign-to-gloss dataset, and pretrain the gloss-to-text translation network on the general domain of a multilingual corpus and the within-domain of a gloss-to-text corpus. The joint model is fine-tuned with an additional module named the visual-language mapper that connects the two networks. This simple baseline surpasses the previous state-of-the-art results on two sign language translation benchmarks, demonstrating the effectiveness of transfer learning. With its simplicity and strong performance, this approach can serve as a solid baseline for future research.", "paper_url": "http://arxiv.org/abs/2203.04287v1", "pdf_url": "http://arxiv.org/pdf/2203.04287v1", "repo_url": null}, "2203.04027": {"publish_time": "2022-03-08", "title": "Data augmentation with mixtures of max-entropy transformations for filling-level classification", "author": "Apostolos Modas et.al.", "abstract": "We address the problem of distribution shifts in test-time data with a principled data augmentation scheme for the task of content-level classification. In such a task, properties such as shape or transparency of test-time containers (cup or drinking glass) may differ from those represented in the training data. Dealing with such distribution shifts using standard augmentation schemes is challenging and transforming the training images to cover the properties of the test-time instances requires sophisticated image manipulations. We therefore generate diverse augmentations using a family of max-entropy transformations that create samples with new shapes, colors and spectral characteristics. We show that such a principled augmentation scheme, alone, can replace current approaches that use transfer learning or can be used in combination with transfer learning to improve its performance.", "paper_url": "http://arxiv.org/abs/2203.04027v1", "pdf_url": "http://arxiv.org/pdf/2203.04027v1", "repo_url": null}, "2203.03878": {"publish_time": "2022-03-08", "title": "HyperPELT: Unified Parameter-Efficient Language Model Tuning for Both Language and Vision-and-Language Tasks", "author": "Zhengkun Zhang et.al.", "abstract": "The workflow of pretraining and fine-tuning has emerged as a popular paradigm for solving various NLP and V&L (Vision-and-Language) downstream tasks. With the capacity of pretrained models growing rapidly, how to perform parameter-efficient fine-tuning has become fairly important for quick transfer learning and deployment. In this paper, we design a novel unified parameter-efficient transfer learning framework that works effectively on both pure language and V&L tasks. In particular, we use a shared hypernetwork that takes trainable hyper-embeddings as input, and outputs weights for fine-tuning different small modules in a pretrained language model, such as tuning the parameters inserted into multi-head attention blocks (i.e., prefix-tuning) and feed-forward blocks (i.e., adapter-tuning). We define a set of embeddings (e.g., layer, block, task and visual embeddings) as the key components to calculate hyper-embeddings, which thus can support both pure language and V&L tasks. Our proposed framework adds fewer trainable parameters in multi-task learning while achieving superior performances and transfer ability compared to state-of-the-art methods. Empirical results on the GLUE benchmark and multiple V&L tasks confirm the effectiveness of our framework on both textual and visual modalities.", "paper_url": "http://arxiv.org/abs/2203.03878v1", "pdf_url": "http://arxiv.org/pdf/2203.03878v1", "repo_url": null}, "2203.03871": {"publish_time": "2022-03-08", "title": "Discriminability-Transferability Trade-Off: An Information-Theoretic Perspective", "author": "Quan Cui et.al.", "abstract": "This work simultaneously considers the discriminability and transferability properties of deep representations in the typical supervised learning task, i.e., image classification. By a comprehensive temporal analysis, we observe a trade-off between these two properties. The discriminability keeps increasing with the training progressing while the transferability intensely diminishes in the later training period.   From the perspective of information-bottleneck theory, we reveal that the incompatibility between discriminability and transferability is attributed to the over-compression of input information. More importantly, we investigate why and how the InfoNCE loss can alleviate the over-compression, and further present a learning framework, named contrastive temporal coding~(CTC), to counteract the over-compression and alleviate the incompatibility. Extensive experiments validate that CTC successfully mitigates the incompatibility, yielding discriminative and transferable representations. Noticeable improvements are achieved on the image classification task and challenging transfer learning tasks. We hope that this work will raise the significance of the transferability property in the conventional supervised learning setting. Code will be publicly available.", "paper_url": "http://arxiv.org/abs/2203.03871v1", "pdf_url": "http://arxiv.org/pdf/2203.03871v1", "repo_url": null}, "2203.04904": {"publish_time": "2022-03-09", "title": "Model-Agnostic Multitask Fine-tuning for Few-shot Vision-Language Transfer Learning", "author": "Zhenhailong Wang et.al.", "abstract": "Despite achieving state-of-the-art zero-shot performance, existing vision-language models, e.g., CLIP, still fall short of domain-specific classification tasks, e.g., Fungi Classification. In the context of few-shot transfer learning, traditional fine-tuning fails to prevent highly expressive model from exploiting spurious correlations in the training data. On the other hand, although model-agnostic meta-learning (MAML) presents as a natural alternative for transfer learning, the expensive computation due to implicit second-order optimization limits its use in large-scale models and datasets. In this work we aim to further improve the generalization of existing vision-language models on unseen tasks via a simple yet efficient fine-tuning strategy based on uniform task sampling. We term our method as Model-Agnostic Multitask Fine-tuning (MAMF). Compared with MAML, MAMF discards the bi-level optimization and uses only first-order gradients, which makes it easily scalable and computationally efficient. Due to the uniform task sampling procedure, MAMF consistently outperforms the classical fine-tuning method for few-shot transfer learning on five benchmark datasets. Empirically, we further discover that the effectiveness of first-order MAML is highly dependent on the zero-shot performance of the pretrained model, and our simple algorithm can outperform first-order MAML on more challenging datasets with low zero-shot performance.", "paper_url": "http://arxiv.org/abs/2203.04904v1", "pdf_url": "http://arxiv.org/pdf/2203.04904v1", "repo_url": null}, "2203.04863": {"publish_time": "2022-03-09", "title": "Unsupervised Alignment of Distributional Word Embeddings", "author": "Aissatou Diallo et.al.", "abstract": "Cross-domain alignment play a key roles in tasks ranging from machine translation to transfer learning. Recently, purely unsupervised methods operating on monolingual embeddings have successfully been used to infer a bilingual lexicon without relying on supervision. However, current state-of-the art methods only focus on point vectors although distributional embeddings have proven to embed richer semantic information when representing words. In this paper, we propose stochastic optimization approach for aligning probabilistic embeddings. Finally, we evaluate our method on the problem of unsupervised word translation, by aligning word embeddings trained on monolingual data. We show that the proposed approach achieves good performance on the bilingual lexicon induction task across several language pairs and performs better than the point-vector based approach.", "paper_url": "http://arxiv.org/abs/2203.04863v1", "pdf_url": "http://arxiv.org/pdf/2203.04863v1", "repo_url": null}, "2203.04729": {"publish_time": "2022-03-09", "title": "Pretrained Domain-Specific Language Model for General Information Retrieval Tasks in the AEC Domain", "author": "Zhe Zheng et.al.", "abstract": "As an essential task for the architecture, engineering, and construction (AEC) industry, information retrieval (IR) from unstructured textual data based on natural language processing (NLP) is gaining increasing attention. Although various deep learning (DL) models for IR tasks have been investigated in the AEC domain, it is still unclear how domain corpora and domain-specific pretrained DL models can improve performance in various IR tasks. To this end, this work systematically explores the impacts of domain corpora and various transfer learning techniques on the performance of DL models for IR tasks and proposes a pretrained domain-specific language model for the AEC domain. First, both in-domain and close-domain corpora are developed. Then, two types of pretrained models, including traditional wording embedding models and BERT-based models, are pretrained based on various domain corpora and transfer learning strategies. Finally, several widely used DL models for IR tasks are further trained and tested based on various configurations and pretrained models. The result shows that domain corpora have opposite effects on traditional word embedding models for text classification and named entity recognition tasks but can further improve the performance of BERT-based models in all tasks. Meanwhile, BERT-based models dramatically outperform traditional methods in all IR tasks, with maximum improvements of 5.4% and 10.1% in the F1 score, respectively. This research contributes to the body of knowledge in two ways: 1) demonstrating the advantages of domain corpora and pretrained DL models and 2) opening the first domain-specific dataset and pretrained language model for the AEC domain, to the best of our knowledge. Thus, this work sheds light on the adoption and application of pretrained models in the AEC domain.", "paper_url": "http://arxiv.org/abs/2203.04729v1", "pdf_url": "http://arxiv.org/pdf/2203.04729v1", "repo_url": "https://github.com/skydustz/aec-domain-corpora"}, "2203.04482": {"publish_time": "2022-03-09", "title": "Multi-Agent Policy Transfer via Task Relationship Modeling", "author": "Rongjun Qin et.al.", "abstract": "Team adaptation to new cooperative tasks is a hallmark of human intelligence, which has yet to be fully realized in learning agents. Previous work on multi-agent transfer learning accommodate teams of different sizes, heavily relying on the generalization ability of neural networks for adapting to unseen tasks. We believe that the relationship among tasks provides the key information for policy adaptation. In this paper, we try to discover and exploit common structures among tasks for more efficient transfer, and propose to learn effect-based task representations as a common space of tasks, using an alternatively fixed training scheme. We demonstrate that the task representation can capture the relationship among tasks, and can generalize to unseen tasks. As a result, the proposed method can help transfer learned cooperation knowledge to new tasks after training on a few source tasks. We also find that fine-tuning the transferred policies help solve tasks that are hard to learn from scratch.", "paper_url": "http://arxiv.org/abs/2203.04482v1", "pdf_url": "http://arxiv.org/pdf/2203.04482v1", "repo_url": null}, "2203.05208": {"publish_time": "2022-03-10", "title": "Transferring Dual Stochastic Graph Convolutional Network for Facial Micro-expression Recognition", "author": "Hui Tang et.al.", "abstract": "Micro-expression recognition has drawn increasing attention due to its wide application in lie detection, criminal detection and psychological consultation. To improve the recognition performance of the small micro-expression data, this paper presents a transferring dual stochastic Graph Convolutional Network (TDSGCN) model. We propose a stochastic graph construction method and dual graph convolutional network to extract more discriminative features from the micro-expression images. We use transfer learning to pre-train SGCNs from macro expression data. Optical flow algorithm is also integrated to extract their temporal features. We fuse both spatial and temporal features to improve the recognition performance. To the best of our knowledge, this is the first attempt to utilize the transferring learning and graph convolutional network in micro-expression recognition task. In addition, to handle the class imbalance problem of dataset, we focus on the design of focal loss function. Through extensive evaluation, our proposed method achieves state-of-the-art performance on SAMM and recently released MMEW benchmarks. Our code will be publicly available accompanying this paper.", "paper_url": "http://arxiv.org/abs/2203.05208v1", "pdf_url": "http://arxiv.org/pdf/2203.05208v1", "repo_url": null}, "2203.05126": {"publish_time": "2022-03-10", "title": "PACTran: PAC-Bayesian Metrics for Estimating the Transferability of Pretrained Models to Classification Tasks", "author": "Nan Ding et.al.", "abstract": "With the increasing abundance of pretrained models in recent years, the problem of selecting the best pretrained checkpoint for a particular downstream classification task has been gaining increased attention. Although several methods have recently been proposed to tackle the selection problem (e.g. LEEP, H-score), these methods resort to applying heuristics that are not well motivated by learning theory. In this paper we present PACTran, a theoretically grounded family of metrics for pretrained model selection and transferability measurement. We first show how to derive PACTran metrics from the optimal PAC-Bayesian bound under the transfer learning setting. We then empirically evaluate three metric instantiations of PACTran on a number of vision tasks (VTAB) as well as a language-and-vision (OKVQA) task. An analysis of the results shows PACTran is a more consistent and effective transferability measure compared to existing selection methods.", "paper_url": "http://arxiv.org/abs/2203.05126v1", "pdf_url": "http://arxiv.org/pdf/2203.05126v1", "repo_url": null}, "2203.05026": {"publish_time": "2022-03-09", "title": "Transfer Learning as an Essential Tool for Digital Twins in Renewable Energy Systems", "author": "Chandana Priya Nivarthi et.al.", "abstract": "Transfer learning (TL), the next frontier in machine learning (ML), has gained much popularity in recent years, due to the various challenges faced in ML, like the requirement of vast amounts of training data, expensive and time-consuming labelling processes for data samples, and long training duration for models. TL is useful in tackling these problems, as it focuses on transferring knowledge from previously solved tasks to new tasks. Digital twins and other intelligent systems need to utilise TL to use the previously gained knowledge and solve new tasks in a more self-reliant way, and to incrementally increase their knowledge base. Therefore, in this article, the critical challenges in power forecasting and anomaly detection in the context of renewable energy systems are identified, and a potential TL framework to meet these challenges is proposed. This article also proposes a feature embedding approach to handle the missing sensors data. The proposed TL methods help to make a system more autonomous in the context of organic computing.", "paper_url": "http://arxiv.org/abs/2203.05026v1", "pdf_url": "http://arxiv.org/pdf/2203.05026v1", "repo_url": null}, "2203.06107": {"publish_time": "2022-03-11", "title": "REX: Reasoning-aware and Grounded Explanation", "author": "Shi Chen et.al.", "abstract": "Effectiveness and interpretability are two essential properties for trustworthy AI systems. Most recent studies in visual reasoning are dedicated to improving the accuracy of predicted answers, and less attention is paid to explaining the rationales behind the decisions. As a result, they commonly take advantage of spurious biases instead of actually reasoning on the visual-textual data, and have yet developed the capability to explain their decision making by considering key information from both modalities. This paper aims to close the gap from three distinct perspectives: first, we define a new type of multi-modal explanations that explain the decisions by progressively traversing the reasoning process and grounding keywords in the images. We develop a functional program to sequentially execute different reasoning steps and construct a new dataset with 1,040,830 multi-modal explanations. Second, we identify the critical need to tightly couple important components across the visual and textual modalities for explaining the decisions, and propose a novel explanation generation method that explicitly models the pairwise correspondence between words and regions of interest. It improves the visual grounding capability by a considerable margin, resulting in enhanced interpretability and reasoning performance. Finally, with our new data and method, we perform extensive analyses to study the effectiveness of our explanation under different settings, including multi-task learning and transfer learning. Our code and data are available at https://github.com/szzexpoi/rex.", "paper_url": "http://arxiv.org/abs/2203.06107v1", "pdf_url": "http://arxiv.org/pdf/2203.06107v1", "repo_url": "https://github.com/szzexpoi/rex"}, "2203.05908": {"publish_time": "2022-03-11", "title": "BabyNet: Reconstructing 3D faces of babies from uncalibrated photographs", "author": "Araceli Morales et.al.", "abstract": "We present a 3D face reconstruction system that aims at recovering the 3D facial geometry of babies from uncalibrated photographs, BabyNet. Since the 3D facial geometry of babies differs substantially from that of adults, baby-specific facial reconstruction systems are needed. BabyNet consists of two stages: 1) a 3D graph convolutional autoencoder learns a latent space of the baby 3D facial shape; and 2) a 2D encoder that maps photographs to the 3D latent space based on representative features extracted using transfer learning. In this way, using the pre-trained 3D decoder, we can recover a 3D face from 2D images. We evaluate BabyNet and show that 1) methods based on adult datasets cannot model the 3D facial geometry of babies, which proves the need for a baby-specific method, and 2) BabyNet outperforms classical model-fitting methods even when a baby-specific 3D morphable model, such as BabyFM, is used.", "paper_url": "http://arxiv.org/abs/2203.05908v1", "pdf_url": "http://arxiv.org/pdf/2203.05908v1", "repo_url": null}, "2203.05882": {"publish_time": "2022-03-11", "title": "Improving the transferability of speech separation by meta-learning", "author": "Kuan-Po Huang et.al.", "abstract": "Speech separation aims to separate multiple speech sources from a speech mixture. Although speech separation is well-solved on some existing English speech separation benchmarks, it is worthy of more investigation on the generalizability of speech separation models on the accents or languages unseen during training. This paper adopts meta-learning based methods to improve the transferability of speech separation models. With the meta-learning based methods, we discovered that only using speech data with one accent, the native English accent, as our training data, the models still can be adapted to new unseen accents on the Speech Accent Archive. We compared the results with a human-rated native-likeness of accents, showing that the transferability of MAML methods has less relation to the similarity of data between the training and testing phase compared to the typical transfer learning methods. Furthermore, we found that models can deal with different language data from the CommonVoice corpus during the testing phase. Most of all, the MAML methods outperform typical transfer learning methods when it comes to new accents, new speakers, new languages, and noisy environments.", "paper_url": "http://arxiv.org/abs/2203.05882v1", "pdf_url": "http://arxiv.org/pdf/2203.05882v1", "repo_url": null}, "2203.05811": {"publish_time": "2022-03-11", "title": "Reprogramming FairGANs with Variational Auto-Encoders: A New Transfer Learning Model", "author": "Beatrice Nobile et.al.", "abstract": "Fairness-aware GANs (FairGANs) exploit the mechanisms of Generative Adversarial Networks (GANs) to impose fairness on the generated data, freeing them from both disparate impact and disparate treatment. Given the model's advantages and performance, we introduce a novel learning framework to transfer a pre-trained FairGAN to other tasks. This reprogramming process has the goal of maintaining the FairGAN's main targets of data utility, classification utility, and data fairness, while widening its applicability and ease of use. In this paper we present the technical extensions required to adapt the original architecture to this new framework (and in particular the use of Variational Auto-Encoders), and discuss the benefits, trade-offs, and limitations of the new model.", "paper_url": "http://arxiv.org/abs/2203.05811v1", "pdf_url": "http://arxiv.org/pdf/2203.05811v1", "repo_url": null}, "2203.05733": {"publish_time": "2022-03-11", "title": "A Survey of Surface Defect Detection of Industrial Products Based on A Small Number of Labeled Data", "author": "Qifan Jin et.al.", "abstract": "The surface defect detection method based on visual perception has been widely used in industrial quality inspection. Because defect data are not easy to obtain and the annotation of a large number of defect data will waste a lot of manpower and material resources. Therefore, this paper reviews the methods of surface defect detection of industrial products based on a small number of labeled data, and this method is divided into traditional image processing-based industrial product surface defect detection methods and deep learning-based industrial product surface defect detection methods suitable for a small number of labeled data. The traditional image processing-based industrial product surface defect detection methods are divided into statistical methods, spectral methods and model methods. Deep learning-based industrial product surface defect detection methods suitable for a small number of labeled data are divided into based on data augmentation, based on transfer learning, model-based fine-tuning, semi-supervised, weak supervised and unsupervised.", "paper_url": "http://arxiv.org/abs/2203.05733v1", "pdf_url": "http://arxiv.org/pdf/2203.05733v1", "repo_url": null}, "2203.06849": {"publish_time": "2022-03-14", "title": "SUPERB-SG: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities", "author": "Hsiang-Sheng Tsai et.al.", "abstract": "Transfer learning has proven to be crucial in advancing the state of speech and natural language processing research in recent years. In speech, a model pre-trained by self-supervised learning transfers remarkably well on multiple tasks. However, the lack of a consistent evaluation methodology is limiting towards a holistic understanding of the efficacy of such models. SUPERB was a step towards introducing a common benchmark to evaluate pre-trained models across various speech tasks. In this paper, we introduce SUPERB-SG, a new benchmark focused on evaluating the semantic and generative capabilities of pre-trained models by increasing task diversity and difficulty over SUPERB. We use a lightweight methodology to test the robustness of representations learned by pre-trained models under shifts in data domain and quality across different types of tasks. It entails freezing pre-trained model parameters, only using simple task-specific trainable heads. The goal is to be inclusive of all researchers, and encourage efficient use of computational resources. We also show that the task diversity of SUPERB-SG coupled with limited task supervision is an effective recipe for evaluating the generalizability of model representation.", "paper_url": "http://arxiv.org/abs/2203.06849v1", "pdf_url": "http://arxiv.org/pdf/2203.06849v1", "repo_url": "https://github.com/s3prl/s3prl"}, "2203.06836": {"publish_time": "2022-03-14", "title": "Bures Joint Distribution Alignment with Dynamic Margin for Unsupervised Domain Adaptation", "author": "Yong-Hui Liu et.al.", "abstract": "Unsupervised domain adaptation (UDA) is one of the prominent tasks of transfer learning, and it provides an effective approach to mitigate the distribution shift between the labeled source domain and the unlabeled target domain. Prior works mainly focus on aligning the marginal distributions or the estimated class-conditional distributions. However, the joint dependency among the feature and the label is crucial for the adaptation task and is not fully exploited. To address this problem, we propose the Bures Joint Distribution Alignment (BJDA) algorithm which directly models the joint distribution shift based on the optimal transport theory in the infinite-dimensional kernel spaces. Specifically, we propose a novel alignment loss term that minimizes the kernel Bures-Wasserstein distance between the joint distributions. Technically, BJDA can effectively capture the nonlinear structures underlying the data. In addition, we introduce a dynamic margin in contrastive learning phase to flexibly characterize the class separability and improve the discriminative ability of representations. It also avoids the cross-validation procedure to determine the margin parameter in traditional triplet loss based methods. Extensive experiments show that BJDA is very effective for the UDA tasks, as it outperforms state-of-the-art algorithms in most experimental settings. In particular, BJDA improves the average accuracy of UDA tasks by 2.8% on Adaptiope, 1.4% on Office-Caltech10, and 1.1% on ImageCLEF-DA.", "paper_url": "http://arxiv.org/abs/2203.06836v1", "pdf_url": "http://arxiv.org/pdf/2203.06836v1", "repo_url": null}, "2203.06570": {"publish_time": "2022-03-13", "title": "Model Inversion Attack against Transfer Learning: Inverting a Model without Accessing It", "author": "Dayong Ye et.al.", "abstract": "Transfer learning is an important approach that produces pre-trained teacher models which can be used to quickly build specialized student models. However, recent research on transfer learning has found that it is vulnerable to various attacks, e.g., misclassification and backdoor attacks. However, it is still not clear whether transfer learning is vulnerable to model inversion attacks. Launching a model inversion attack against transfer learning scheme is challenging. Not only does the student model hide its structural parameters, but it is also inaccessible to the adversary. Hence, when targeting a student model, both the white-box and black-box versions of existing model inversion attacks fail. White-box attacks fail as they need the target model's parameters. Black-box attacks fail as they depend on making repeated queries of the target model. However, they may not mean that transfer learning models are impervious to model inversion attacks. Hence, with this paper, we initiate research into model inversion attacks against transfer learning schemes with two novel attack methods. Both are black-box attacks, suiting different situations, that do not rely on queries to the target student model. In the first method, the adversary has the data samples that share the same distribution as the training set of the teacher model. In the second method, the adversary does not have any such samples. Experiments show that highly recognizable data records can be recovered with both of these methods. This means that even if a model is an inaccessible black-box, it can still be inverted.", "paper_url": "http://arxiv.org/abs/2203.06570v1", "pdf_url": "http://arxiv.org/pdf/2203.06570v1", "repo_url": null}, "2203.06288": {"publish_time": "2022-03-11", "title": "Estimating Cluster Masses from SDSS Multi-band Images with Transfer Learning", "author": "Sheng-Chieh Lin et.al.", "abstract": "The total masses of galaxy clusters characterize many aspects of astrophysics and the underlying cosmology. It is crucial to obtain reliable and accurate mass estimates for numerous galaxy clusters over a wide range of redshifts and mass scales. We present a transfer-learning approach to estimate cluster masses using the ugriz-band images in the SDSS Data Release 12. The target masses are derived from X-ray or SZ measurements that are only available for a small subset of the clusters. We designed a semi-supervised deep learning model consisting of two convolutional neural networks. In the first network, a feature extractor is trained to classify the SDSS photometric bands. The second network takes the previously trained features as inputs to estimate their total masses. The training and testing processes in this work depend purely on real observational data. Our algorithm reaches a mean absolute error (MAE) of 0.232 dex on average and 0.214 dex for the best fold. The performance is comparable to that given by redMaPPer, 0.192 dex. We have further applied a joint integrated gradient and class activation mapping method to interpret such a two-step neural network. The performance of our algorithm is likely to improve as the size of training dataset increases. This proof-of-concept experiment demonstrates the potential of deep learning in maximizing the scientific return of the current and future large cluster surveys.", "paper_url": "http://arxiv.org/abs/2203.06288v1", "pdf_url": "http://arxiv.org/pdf/2203.06288v1", "repo_url": null}, "2203.06210": {"publish_time": "2022-03-11", "title": "Leveraging universality of jet taggers through transfer learning", "author": "Fr\u00e9d\u00e9ric A. Dreyer et.al.", "abstract": "A significant challenge in the tagging of boosted objects via machine-learning technology is the prohibitive computational cost associated with training sophisticated models. Nevertheless, the universality of QCD suggests that a large amount of the information learnt in the training is common to different physical signals and experimental setups. In this article, we explore the use of transfer learning techniques to develop fast and data-efficient jet taggers that leverage such universality. We consider the graph neural networks LundNet and ParticleNet, and introduce two prescriptions to transfer an existing tagger into a new signal based either on fine-tuning all the weights of a model or alternatively on freezing a fraction of them. In the case of $W$-boson and top-quark tagging, we find that one can obtain reliable taggers using an order of magnitude less data with a corresponding speed-up of the training process. Moreover, while keeping the size of the training data set fixed, we observe a speed-up of the training by up to a factor of three. This offers a promising avenue to facilitate the use of such tools in collider physics experiments.", "paper_url": "http://arxiv.org/abs/2203.06210v1", "pdf_url": "http://arxiv.org/pdf/2203.06210v1", "repo_url": null}, "2203.07910": {"publish_time": "2022-03-14", "title": "Deep Transfer Learning with Graph Neural Network for Sensor-Based Human Activity Recognition", "author": "Yan Yan et.al.", "abstract": "The sensor-based human activity recognition (HAR) in mobile application scenarios is often confronted with sensor modalities variation and annotated data deficiency. Given this observation, we devised a graph-inspired deep learning approach toward the sensor-based HAR tasks, which was further used to build a deep transfer learning model toward giving a tentative solution for these two challenging problems. Specifically, we present a multi-layer residual structure involved graph convolutional neural network (ResGCNN) toward the sensor-based HAR tasks, namely the HAR-ResGCNN approach. Experimental results on the PAMAP2 and mHealth data sets demonstrate that our ResGCNN is effective at capturing the characteristics of actions with comparable results compared to other sensor-based HAR models (with an average accuracy of 98.18% and 99.07%, respectively). More importantly, the deep transfer learning experiments using the ResGCNN model show excellent transferability and few-shot learning performance. The graph-based framework shows good meta-learning ability and is supposed to be a promising solution in sensor-based HAR tasks.", "paper_url": "http://arxiv.org/abs/2203.07910v1", "pdf_url": "http://arxiv.org/pdf/2203.07910v1", "repo_url": null}, "2203.08777": {"publish_time": "2022-03-16", "title": "Object discovery and representation networks", "author": "Olivier J. H\u00e9naff et.al.", "abstract": "The promise of self-supervised learning (SSL) is to leverage large amounts of unlabeled data to solve complex tasks. While there has been excellent progress with simple, image-level learning, recent methods have shown the advantage of including knowledge of image structure. However, by introducing hand-crafted image segmentations to define regions of interest, or specialized augmentation strategies, these methods sacrifice the simplicity and generality that makes SSL so powerful. Instead, we propose a self-supervised learning paradigm that discovers the structure encoded in these priors by itself. Our method, Odin, couples object discovery and representation networks to discover meaningful image segmentations without any supervision. The resulting learning paradigm is simpler, less brittle, and more general, and achieves state-of-the-art transfer learning results for object detection and instance segmentation on COCO, and semantic segmentation on PASCAL and Cityscapes, while strongly surpassing supervised pre-training for video segmentation on DAVIS.", "paper_url": "http://arxiv.org/abs/2203.08777v1", "pdf_url": "http://arxiv.org/pdf/2203.08777v1", "repo_url": null}, "2203.08612": {"publish_time": "2022-03-16", "title": "CtlGAN: Few-shot Artistic Portraits Generation with Contrastive Transfer Learning", "author": "Yue Wang et.al.", "abstract": "Generating artistic portraits is a challenging problem in computer vision. Existing portrait stylization models that generate good quality results are based on Image-to-Image Translation and require abundant data from both source and target domains. However, without enough data, these methods would result in overfitting. In this work, we propose CtlGAN, a new few-shot artistic portraits generation model with a novel contrastive transfer learning strategy. We adapt a pretrained StyleGAN in the source domain to a target artistic domain with no more than 10 artistic faces. To reduce overfitting to the few training examples, we introduce a novel Cross-Domain Triplet loss which explicitly encourages the target instances generated from different latent codes to be distinguishable. We propose a new encoder which embeds real faces into Z+ space and proposes a dual-path training strategy to better cope with the adapted decoder and eliminate the artifacts. Extensive qualitative, quantitative comparisons and a user study show our method significantly outperforms state-of-the-arts under 10-shot and 1-shot settings and generates high quality artistic portraits. The code will be made publicly available.", "paper_url": "http://arxiv.org/abs/2203.08612v1", "pdf_url": "http://arxiv.org/pdf/2203.08612v1", "repo_url": null}, "2203.08378": {"publish_time": "2022-03-16", "title": "Transforming Sequence Tagging Into A Seq2Seq Task", "author": "Karthik Raman et.al.", "abstract": "Pretrained, large, generative language models (LMs) have had great success in a wide range of sequence tagging and structured prediction tasks. Casting a sequence tagging task as a Seq2Seq one requires deciding the formats of the input and output sequences. However, we lack a principled understanding of the trade-offs associated with these formats (such as the effect on model accuracy, sequence length, multilingual generalization, hallucination). In this paper, we rigorously study different formats one could use for casting input text sentences and their output labels into the input and target (i.e., output) of a Seq2Seq model. Along the way, we introduce a new format, which we show to not only be simpler but also more effective. Additionally the new format demonstrates significant gains in the multilingual settings -- both zero-shot transfer learning and joint training. Lastly, we find that the new format is more robust and almost completely devoid of hallucination -- an issue we find common in existing formats. With well over a 1000 experiments studying 14 different formats, over 7 diverse public benchmarks -- including 3 multilingual datasets spanning 7 languages -- we believe our findings provide a strong empirical basis in understanding how we should tackle sequence tagging tasks.", "paper_url": "http://arxiv.org/abs/2203.08378v1", "pdf_url": "http://arxiv.org/pdf/2203.08378v1", "repo_url": null}, "2203.09445": {"publish_time": "2022-03-17", "title": "Image Super-Resolution With Deep Variational Autoencoders", "author": "Darius Chira et.al.", "abstract": "Image super-resolution (SR) techniques are used to generate a high-resolution image from a low-resolution image. Until now, deep generative models such as autoregressive models and Generative Adversarial Networks (GANs) have proven to be effective at modelling high-resolution images. Models based on Variational Autoencoders (VAEs) have often been criticized for their feeble generative performance, but with new advancements such as VDVAE (very deep VAE), there is now strong evidence that deep VAEs have the potential to outperform current state-of-the-art models for high-resolution image generation. In this paper, we introduce VDVAE-SR, a new model that aims to exploit the most recent deep VAE methodologies to improve upon image super-resolution using transfer learning on pretrained VDVAEs. Through qualitative and quantitative evaluations, we show that the proposed model is competitive with other state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2203.09445v1", "pdf_url": "http://arxiv.org/pdf/2203.09445v1", "repo_url": null}, "2203.09348": {"publish_time": "2022-03-17", "title": "POSTER: Diagnosis of COVID-19 through Transfer Learning Techniques on CT Scans: A Comparison of Deep Learning Models", "author": "Aeyan Ashraf et.al.", "abstract": "The novel coronavirus disease (COVID-19) constitutes a public health emergency globally. It is a deadly disease which has infected more than 230 million people worldwide. Therefore, early and unswerving detection of COVID-19 is necessary. Evidence of this virus is most commonly being tested by RT-PCR test. This test is not 100% reliable as it is known to give false positives and false negatives. Other methods like X-Ray images or CT scans show the detailed imaging of lungs and have been proven more reliable. This paper compares different deep learning models used to detect COVID-19 through transfer learning technique on CT scan dataset. VGG-16 outperforms all the other models achieving an accuracy of 85.33% on the dataset.", "paper_url": "http://arxiv.org/abs/2203.09348v1", "pdf_url": "http://arxiv.org/pdf/2203.09348v1", "repo_url": null}, "2203.09279": {"publish_time": "2022-03-17", "title": "Transfer learning for cross-modal demand prediction of bike-share and public transit", "author": "Mingzhuang Hua et.al.", "abstract": "The urban transportation system is a combination of multiple transport modes, and the interdependencies across those modes exist. This means that the travel demand across different travel modes could be correlated as one mode may receive demand from or create demand for another mode, not to mention natural correlations between different demand time series due to general demand flow patterns across the network. It is expectable that cross-modal ripple effects become more prevalent, with Mobility as a Service. Therefore, by propagating demand data across modes, a better demand prediction could be obtained. To this end, this study explores various machine learning models and transfer learning strategies for cross-modal demand prediction. The trip data of bike-share, metro, and taxi are processed as the station-level passenger flows, and then the proposed prediction method is tested in the large-scale case studies of Nanjing and Chicago. The results suggest that prediction models with transfer learning perform better than unimodal prediction models. Furthermore, stacked Long Short-Term Memory model performs particularly well in cross-modal demand prediction. These results verify our combined method's forecasting improvement over existing benchmarks and demonstrate the good transferability for cross-modal demand prediction in multiple cities.", "paper_url": "http://arxiv.org/abs/2203.09279v1", "pdf_url": "http://arxiv.org/pdf/2203.09279v1", "repo_url": null}, "2203.09270": {"publish_time": "2022-03-17", "title": "Mixing Up Contrastive Learning: Self-Supervised Representation Learning for Time Series", "author": "Kristoffer Wickstr\u00f8m et.al.", "abstract": "The lack of labeled data is a key challenge for learning useful representation from time series data. However, an unsupervised representation framework that is capable of producing high quality representations could be of great value. It is key to enabling transfer learning, which is especially beneficial for medical applications, where there is an abundance of data but labeling is costly and time consuming. We propose an unsupervised contrastive learning framework that is motivated from the perspective of label smoothing. The proposed approach uses a novel contrastive loss that naturally exploits a data augmentation scheme in which new samples are generated by mixing two data samples with a mixing component. The task in the proposed framework is to predict the mixing component, which is utilized as soft targets in the loss function. Experiments demonstrate the framework's superior performance compared to other representation learning approaches on both univariate and multivariate time series and illustrate its benefits for transfer learning for clinical time series.", "paper_url": "http://arxiv.org/abs/2203.09270v1", "pdf_url": "http://arxiv.org/pdf/2203.09270v1", "repo_url": "https://github.com/wickstrom/mixupcontrastivelearning"}, "2203.09132": {"publish_time": "2022-03-17", "title": "Feature-informed Latent Space Regularization for Music Source Separation", "author": "Yun-Ning Hung et.al.", "abstract": "The integration of additional side information to improve music source separation has been investigated numerous times, e.g., by adding features to the input or by adding learning targets in a multi-task learning scenario. These approaches, however, require additional annotations such as musical scores, instrument labels, etc. in training and possibly during inference. The available datasets for source separation do not usually provide these additional annotations. In this work, we explore transfer learning strategies to incorporate VGGish features with a state-of-the-art source separation model; VGGish features are known to be a very condensed representation of audio content and have been successfully used in many MIR tasks. We introduce three approaches to incorporate the features, including two latent space regularization methods and one naive concatenation method. Experimental results show that our proposed approaches improve several evaluation metrics for music source separation.", "paper_url": "http://arxiv.org/abs/2203.09132v1", "pdf_url": "http://arxiv.org/pdf/2203.09132v1", "repo_url": null}, "2203.09855": {"publish_time": "2022-03-18", "title": "Multi-Modal Masked Pre-Training for Monocular Panoramic Depth Completion", "author": "Zhiqiang Yan et.al.", "abstract": "In this paper, we formulate a potentially valuable panoramic depth completion (PDC) task as panoramic 3D cameras often produce 360{\\deg} depth with missing data in complex scenes. Its goal is to recover dense panoramic depths from raw sparse ones and panoramic RGB images. To deal with the PDC task, we train a deep network that takes both depth and image as inputs for the dense panoramic depth recovery. However, it needs to face a challenging optimization problem of the network parameters due to its non-convex objective function. To address this problem, we propose a simple yet effective approach termed M{^3}PT: multi-modal masked pre-training. Specifically, during pre-training, we simultaneously cover up patches of the panoramic RGB image and sparse depth by shared random mask, then reconstruct the sparse depth in the masked regions. To our best knowledge, it is the first time that we show the effectiveness of masked pre-training in a multi-modal vision task, instead of the single-modal task resolved by masked autoencoders (MAE). Different from MAE where fine-tuning completely discards the decoder part of pre-training, there is no architectural difference between the pre-training and fine-tuning stages in our M$^{3}$PT as they only differ in the prediction density, which potentially makes the transfer learning more convenient and effective. Extensive experiments verify the effectiveness of M{^3}PT on three panoramic datasets. Notably, we improve the state-of-the-art baselines by averagely 26.2% in RMSE, 51.7% in MRE, 49.7% in MAE, and 37.5% in RMSElog on three benchmark datasets. Codes and pre-trained models are available at https://github.com/anonymoustbd/MMMPT.", "paper_url": "http://arxiv.org/abs/2203.09855v1", "pdf_url": "http://arxiv.org/pdf/2203.09855v1", "repo_url": null}, "2203.09825": {"publish_time": "2022-03-18", "title": "AdaVocoder: Adaptive Vocoder for Custom Voice", "author": "Xin Yuan et.al.", "abstract": "Custom voice is to construct a personal speech synthesis system by adapting the source speech synthesis model to the target model through the target few recordings. The solution to constructing a custom voice is to combine an adaptive acoustic model with a robust vocoder. However, training a robust vocoder usually requires a multi-speaker dataset, which should include various age groups and various timbres, so that the trained vocoder can be used for unseen speakers. Collecting such a multi-speaker dataset is difficult, and the dataset distribution always has a mismatch with the distribution of the target speaker dataset. This paper proposes an adaptive vocoder for custom voice from another novel perspective to solve the above problems. The adaptive vocoder mainly uses a cross-domain consistency loss to solve the overfitting problem encountered by the GAN-based neural vocoder in the transfer learning of few-shot scenes. We construct two adaptive vocoders, AdaMelGAN and AdaHiFi-GAN. First, We pre-train the source vocoder model on AISHELL3 and CSMSC datasets, respectively. Then, fine-tune it on the internal dataset VXI-children with few adaptation data. The empirical results show that a high-quality custom voice system can be built by combining a adaptive acoustic model with a adaptive vocoder.", "paper_url": "http://arxiv.org/abs/2203.09825v1", "pdf_url": "http://arxiv.org/pdf/2203.09825v1", "repo_url": null}, "2203.09777": {"publish_time": "2022-03-18", "title": "Transferable Class-Modelling for Decentralized Source Attribution of GAN-Generated Images", "author": "Brandon B. G. Khoo et.al.", "abstract": "GAN-generated deepfakes as a genre of digital images are gaining ground as both catalysts of artistic expression and malicious forms of deception, therefore demanding systems to enforce and accredit their ethical use. Existing techniques for the source attribution of synthetic images identify subtle intrinsic fingerprints using multiclass classification neural nets limited in functionality and scalability. Hence, we redefine the deepfake detection and source attribution problems as a series of related binary classification tasks. We leverage transfer learning to rapidly adapt forgery detection networks for multiple independent attribution problems, by proposing a semi-decentralized modular design to solve them simultaneously and efficiently. Class activation mapping is also demonstrated as an effective means of feature localization for model interpretation. Our models are determined via experimentation to be competitive with current benchmarks, and capable of decent performance on human portraits in ideal conditions. Decentralized fingerprint-based attribution is found to retain validity in the presence of novel sources, but is more susceptible to type II errors that intensify with image perturbations and attributive uncertainty. We describe both our conceptual framework and model prototypes for further enhancement when investigating the technical limits of reactive deepfake attribution.", "paper_url": "http://arxiv.org/abs/2203.09777v1", "pdf_url": "http://arxiv.org/pdf/2203.09777v1", "repo_url": "https://github.com/quarxilon/generator_attribution"}, "2203.11096": {"publish_time": "2022-03-21", "title": "CLIP meets GamePhysics: Towards bug identification in gameplay videos using zero-shot transfer learning", "author": "Mohammad Reza Taesiri et.al.", "abstract": "Gameplay videos contain rich information about how players interact with the game and how the game responds. Sharing gameplay videos on social media platforms, such as Reddit, has become a common practice for many players. Often, players will share gameplay videos that showcase video game bugs. Such gameplay videos are software artifacts that can be utilized for game testing, as they provide insight for bug analysis. Although large repositories of gameplay videos exist, parsing and mining them in an effective and structured fashion has still remained a big challenge. In this paper, we propose a search method that accepts any English text query as input to retrieve relevant videos from large repositories of gameplay videos. Our approach does not rely on any external information (such as video metadata); it works solely based on the content of the video. By leveraging the zero-shot transfer capabilities of the Contrastive Language-Image Pre-Training (CLIP) model, our approach does not require any data labeling or training. To evaluate our approach, we present the $\\texttt{GamePhysics}$ dataset consisting of 26,954 videos from 1,873 games, that were collected from the GamePhysics section on the Reddit website. Our approach shows promising results in our extensive analysis of simple queries, compound queries, and bug queries, indicating that our approach is useful for object and event detection in gameplay videos. An example application of our approach is as a gameplay video search engine to aid in reproducing video game bugs. Please visit the following link for the code and the data: $\\href{https://asgaardlab.github.io/CLIPxGamePhysics/}{\\text{asgaardlab.github.io/CLIPxGamePhysics/}}$", "paper_url": "http://arxiv.org/abs/2203.11096v1", "pdf_url": "http://arxiv.org/pdf/2203.11096v1", "repo_url": null}, "2203.11008": {"publish_time": "2022-03-21", "title": "Transformer-based HTR for Historical Documents", "author": "Phillip Benjamin Str\u00f6bel et.al.", "abstract": "We apply the TrOCR framework to real-world, historical manuscripts and show that TrOCR per se is a strong model, ideal for transfer learning. TrOCR has been trained on English only, but it can adapt to other languages that use the Latin alphabet fairly easily and with little training material. We compare TrOCR against a SOTA HTR framework (Transkribus) and show that it can beat such systems. This finding is essential since Transkribus performs best when it has access to baseline information, which is not needed at all to fine-tune TrOCR.", "paper_url": "http://arxiv.org/abs/2203.11008v1", "pdf_url": "http://arxiv.org/pdf/2203.11008v1", "repo_url": null}, "2203.10546": {"publish_time": "2022-03-20", "title": "Towards 3D Scene Understanding by Referring Synthetic Models", "author": "Runnan Chen et.al.", "abstract": "Promising performance has been achieved for visual perception on the point cloud. However, the current methods typically rely on labour-extensive annotations on the scene scans. In this paper, we explore how synthetic models alleviate the real scene annotation burden, i.e., taking the labelled 3D synthetic models as reference for supervision, the neural network aims to recognize specific categories of objects on a real scene scan (without scene annotation for supervision). The problem studies how to transfer knowledge from synthetic 3D models to real 3D scenes and is named Referring Transfer Learning (RTL). The main challenge is solving the model-to-scene (from a single model to the scene) and synthetic-to-real (from synthetic model to real scene's object) gap between the synthetic model and the real scene. To this end, we propose a simple yet effective framework to perform two alignment operations. First, physical data alignment aims to make the synthetic models cover the diversity of the scene's objects with data processing techniques. Then a novel \\textbf{convex-hull regularized feature alignment} introduces learnable prototypes to project the point features of both synthetic models and real scenes to a unified feature space, which alleviates the domain gap. These operations ease the model-to-scene and synthetic-to-real difficulty for a network to recognize the target objects on a real unseen scene. Experiments show that our method achieves the average mAP of 46.08\\% and 55.49\\% on the ScanNet and S3DIS datasets by learning the synthetic models from the ModelNet dataset. Code will be publicly available.", "paper_url": "http://arxiv.org/abs/2203.10546v1", "pdf_url": "http://arxiv.org/pdf/2203.10546v1", "repo_url": null}, "2203.10456": {"publish_time": "2022-03-20", "title": "simCrossTrans: A Simple Cross-Modality Transfer Learning for Object Detection with ConvNets or Vision Transformers", "author": "Xiaoke Shen et.al.", "abstract": "Transfer learning is widely used in computer vision (CV), natural language processing (NLP) and achieves great success. Most transfer learning systems are based on the same modality (e.g. RGB image in CV and text in NLP). However, the cross-modality transfer learning (CMTL) systems are scarce. In this work, we study CMTL from 2D to 3D sensor to explore the upper bound performance of 3D sensor only systems, which play critical roles in robotic navigation and perform well in low light scenarios. While most CMTL pipelines from 2D to 3D vision are complicated and based on Convolutional Neural Networks (ConvNets), ours is easy to implement, expand and based on both ConvNets and Vision transformers(ViTs): 1) By converting point clouds to pseudo-images, we can use an almost identical network from pre-trained models based on 2D images. This makes our system easy to implement and expand. 2) Recently ViTs have been showing good performance and robustness to occlusions, one of the key reasons for poor performance of 3D vision systems. We explored both ViT and ConvNet with similar model sizes to investigate the performance difference. We name our approach simCrossTrans: simple cross-modality transfer learning with ConvNets or ViTs. Experiments on SUN RGB-D dataset show: with simCrossTrans we achieve $13.2\\%$ and $16.1\\%$ absolute performance gain based on ConvNets and ViTs separately. We also observed the ViTs based performs $9.7\\%$ better than the ConvNets one, showing the power of simCrossTrans with ViT. simCrossTrans with ViTs surpasses the previous state-of-the-art (SOTA) by a large margin of $+15.4\\%$ mAP50. Compared with the previous 2D detection SOTA based RGB images, our depth image only system only has a $1\\%$ gap. The code, training/inference logs and models are publicly available at https://github.com/liketheflower/simCrossTrans", "paper_url": "http://arxiv.org/abs/2203.10456v1", "pdf_url": "http://arxiv.org/pdf/2203.10456v1", "repo_url": null}, "2203.10425": {"publish_time": "2022-03-20", "title": "A Study on Robustness to Perturbations for Representations of Environmental Sound", "author": "Sangeeta Srivastava et.al.", "abstract": "Many audio applications, such as environmental sound analysis, are increasingly using general-purpose audio representations for transfer learning. The robustness of such representations has been determined by evaluating them across a variety of domains and applications. However, it is unclear how the application-specific evaluation can be utilized to predict the impact of variability in real-world deployments caused by myriad microphones' range and acoustic conditions, commonly known as \\textit{channel effects}. In this paper, we integrate the results of various distance metrics with downstream performance to make a more informed prediction of how robust the representations or embeddings are to the audio channel effects. To accomplish this, we use two embeddings, YAMNet and OpenL$^3$, and three distance metrics to quantify the change in the embeddings when injecting perturbations to the audio signal that imitate channel effects. In monophonic (UrbanSound8K) and polyphonic (SONYC UST) data, we show a combination of two distances, Fr\\'echet Audio Distance (FAD) and Cophenetic Correlation Distance (CPCD), correlates well with the effects of perturbations. We further discuss the limitations of each distance measure.", "paper_url": "http://arxiv.org/abs/2203.10425v1", "pdf_url": "http://arxiv.org/pdf/2203.10425v1", "repo_url": null}, "2203.11856": {"publish_time": "2022-03-22", "title": "A Computational Approach to Understand Mental Health from Reddit: Knowledge-aware Multitask Learning Framework", "author": "Usha Lokala et.al.", "abstract": "Analyzing gender is critical to study mental health (MH) support in CVD (cardiovascular disease). The existing studies on using social media for extracting MH symptoms consider symptom detection and tend to ignore user context, disease, or gender. The current study aims to design and evaluate a system to capture how MH symptoms associated with CVD are expressed differently with the gender on social media. We observe that the reliable detection of MH symptoms expressed by persons with heart disease in user posts is challenging because of the co-existence of (dis)similar MH symptoms in one post and due to variation in the description of symptoms based on gender. We collect a corpus of $150k$ items (posts and comments) annotated using the subreddit labels and transfer learning approaches. We propose GeM, a novel task-adaptive multi-task learning approach to identify the MH symptoms in CVD patients based on gender. Specifically, we adapt a knowledge-assisted RoBERTa based bi-encoder model to capture CVD-related MH symptoms. Moreover, it enhances the reliability for differentiating the gender language in MH symptoms when compared to the state-of-art language models. Our model achieves high (statistically significant) performance and predicts four labels of MH issues and two gender labels, which outperforms RoBERTa, improving the recall by 2.14% on the symptom identification task and by 2.55% on the gender identification task.", "paper_url": "http://arxiv.org/abs/2203.11856v1", "pdf_url": "http://arxiv.org/pdf/2203.11856v1", "repo_url": null}, "2203.11562": {"publish_time": "2022-03-22", "title": "A Text-to-Speech Pipeline, Evaluation Methodology, and Initial Fine-Tuning Results for Child Speech Synthesis", "author": "Rishabh Jain et.al.", "abstract": "Speech synthesis has come a long way as current text-to-speech (TTS) models can now generate natural human-sounding speech. However, most of the TTS research focuses on using adult speech data and there has been very limited work done on child speech synthesis. This study developed and validated a training pipeline for fine-tuning state-of-the-art (SOTA) neural TTS models using child speech datasets. This approach adopts a multispeaker TTS retuning workflow to provide a transfer-learning pipeline. A publicly available child speech dataset was cleaned to provide a smaller subset of approximately 19 hours, which formed the basis of our fine-tuning experiments. Both subjective and objective evaluations were performed using a pretrained MOSNet for objective evaluation and a novel subjective framework for mean opinion score (MOS) evaluations. Subjective evaluations achieved the MOS of 3.92 for speech intelligibility, 3.85 for voice naturalness, and 3.96 for voice consistency. Objective evaluation using a pretrained MOSNet showed a strong correlation between real and synthetic child voices. The final trained model was able to synthesize child-like speech from reference audio samples as short as 5 seconds.", "paper_url": "http://arxiv.org/abs/2203.11562v1", "pdf_url": "http://arxiv.org/pdf/2203.11562v1", "repo_url": null}, "2203.11544": {"publish_time": "2022-03-22", "title": "Visuo-Haptic Object Perception for Robots: An Overview", "author": "Nicol\u00e1s Navarro-Guerrero et.al.", "abstract": "This article summarizes the current state of multimodal object perception for robotic applications. It covers aspects of biological inspiration, sensor technologies, data sets, and sensory data processing for object recognition and grasping. Firstly, the biological basis of multimodal object perception is outlined. Then the sensing technologies and data collection strategies are discussed. Next, an introduction to the main computational aspects is presented, highlighting a few representative articles for each main application area, including object recognition, object manipulation and grasping, texture recognition, and transfer learning. Finally, informed by the current advancements in each area, this article outlines promising new research directions.", "paper_url": "http://arxiv.org/abs/2203.11544v1", "pdf_url": "http://arxiv.org/pdf/2203.11544v1", "repo_url": null}, "2203.11542": {"publish_time": "2022-03-22", "title": "Mask Usage Recognition using Vision Transformer with Transfer Learning and Data Augmentation", "author": "Hensel Donato Jahja et.al.", "abstract": "The COVID-19 pandemic has disrupted various levels of society. The use of masks is essential in preventing the spread of COVID-19 by identifying an image of a person using a mask. Although only 23.1% of people use masks correctly, Artificial Neural Networks (ANN) can help classify the use of good masks to help slow the spread of the Covid-19 virus. However, it requires a large dataset to train an ANN that can classify the use of masks correctly. MaskedFace-Net is a suitable dataset consisting of 137016 digital images with 4 class labels, namely Mask, Mask Chin, Mask Mouth Chin, and Mask Nose Mouth. Mask classification training utilizes Vision Transformers (ViT) architecture with transfer learning method using pre-trained weights on ImageNet-21k, with random augmentation. In addition, the hyper-parameters of training of 20 epochs, an Stochastic Gradient Descent (SGD) optimizer with a learning rate of 0.03, a batch size of 64, a Gaussian Cumulative Distribution (GeLU) activation function, and a Cross-Entropy loss function are used to be applied on the training of three architectures of ViT, namely Base-16, Large-16, and Huge-14. Furthermore, comparisons of with and without augmentation and transfer learning are conducted. This study found that the best classification is transfer learning and augmentation using ViT Huge-14. Using this method on MaskedFace-Net dataset, the research reaches an accuracy of 0.9601 on training data, 0.9412 on validation data, and 0.9534 on test data. This research shows that training the ViT model with data augmentation and transfer learning improves classification of the mask usage, even better than convolutional-based Residual Network (ResNet).", "paper_url": "http://arxiv.org/abs/2203.11542v1", "pdf_url": "http://arxiv.org/pdf/2203.11542v1", "repo_url": null}, "2203.11461": {"publish_time": "2022-03-22", "title": "Locally Adaptive Transfer Learning Algorithms for Large-Scale Multiple Testing", "author": "Ziyi Liang et.al.", "abstract": "Transfer learning has enjoyed increasing popularity in a range of big data applications. In the context of large-scale multiple testing, the goal is to extract and transfer knowledge learned from related source domains to improve the accuracy of simultaneously testing of a large number of hypotheses in the target domain. This article develops a locally adaptive transfer learning algorithm (LATLA) for transfer learning for multiple testing. In contrast with existing covariate-assisted multiple testing methods that require the auxiliary covariates to be collected alongside the primary data on the same testing units, LATLA provides a principled and generic transfer learning framework that is capable of incorporating multiple samples of auxiliary data from related source domains, possibly in different dimensions/structures and from diverse populations. Both the theoretical and numerical results show that LATLA controls the false discovery rate and outperforms existing methods in power. LATLA is illustrated through an application to genome-wide association studies for the identification of disease-associated SNPs by cross-utilizing the auxiliary data from a related linkage analysis.", "paper_url": "http://arxiv.org/abs/2203.11461v1", "pdf_url": "http://arxiv.org/pdf/2203.11461v1", "repo_url": null}, "2203.12443": {"publish_time": "2022-03-23", "title": "Machine learning aided atomic structure identification of interfacial ionic hydrates from atomic force microscopy images", "author": "Binze Tang et.al.", "abstract": "Relevant to broad applied fields and natural processes, interfacial ionic hydrates has been widely studied by ultrahigh-resolution atomic force microscopy (AFM). However, the complex relationship between AFM signal and the investigated system makes it difficult to determine the atomic structure of such complex system from AFM images alone. Using machine learning, we achieved precise identification of the atomic structures of interfacial water/ionic hydrates based on AFM images, including the position of each atom and the orientation of water molecules. Furthermore, it was found that structure prediction of ionic hydrates can be achieved cost-effectively by transfer learning using neural network (NN) trained with easily available interfacial water data. Thus, this work provides an efficient and economical methodology which not only opens up avenues to determine atomic structures of more complex systems from AFM images, but may also help to interpret other science-wide studies involving sophisticated experimental results.", "paper_url": "http://arxiv.org/abs/2203.12443v1", "pdf_url": "http://arxiv.org/pdf/2203.12443v1", "repo_url": null}, "2203.13248": {"publish_time": "2022-03-24", "title": "Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer", "author": "Shuai Yang et.al.", "abstract": "Recent studies on StyleGAN show high performance on artistic portrait generation by transfer learning with limited data. In this paper, we explore more challenging exemplar-based high-resolution portrait style transfer by introducing a novel DualStyleGAN with flexible control of dual styles of the original face domain and the extended artistic portrait domain. Different from StyleGAN, DualStyleGAN provides a natural way of style transfer by characterizing the content and style of a portrait with an intrinsic style path and a new extrinsic style path, respectively. The delicately designed extrinsic style path enables our model to modulate both the color and complex structural styles hierarchically to precisely pastiche the style example. Furthermore, a novel progressive fine-tuning scheme is introduced to smoothly transform the generative space of the model to the target domain, even with the above modifications on the network architecture. Experiments demonstrate the superiority of DualStyleGAN over state-of-the-art methods in high-quality portrait style transfer and flexible style control.", "paper_url": "http://arxiv.org/abs/2203.13248v1", "pdf_url": "http://arxiv.org/pdf/2203.13248v1", "repo_url": "https://github.com/williamyang1991/DualStyleGAN"}, "2203.12881": {"publish_time": "2022-03-24", "title": "Can Unsupervised Knowledge Transfer from Social Discussions Help Argument Mining?", "author": "Subhabrata Dutta et.al.", "abstract": "Identifying argument components from unstructured texts and predicting the relationships expressed among them are two primary steps of argument mining. The intrinsic complexity of these tasks demands powerful learning models. While pretrained Transformer-based Language Models (LM) have been shown to provide state-of-the-art results over different NLP tasks, the scarcity of manually annotated data and the highly domain-dependent nature of argumentation restrict the capabilities of such models. In this work, we propose a novel transfer learning strategy to overcome these challenges. We utilize argumentation-rich social discussions from the ChangeMyView subreddit as a source of unsupervised, argumentative discourse-aware knowledge by finetuning pretrained LMs on a selectively masked language modeling task. Furthermore, we introduce a novel prompt-based strategy for inter-component relation prediction that compliments our proposed finetuning method while leveraging on the discourse context. Exhaustive experiments show the generalization capability of our method on these two tasks over within-domain as well as out-of-domain datasets, outperforming several existing and employed strong baselines.", "paper_url": "http://arxiv.org/abs/2203.12881v1", "pdf_url": "http://arxiv.org/pdf/2203.12881v1", "repo_url": "https://github.com/jeevesh8/arg_mining"}, "2203.12803": {"publish_time": "2022-03-24", "title": "When Accuracy Meets Privacy: Two-Stage Federated Transfer Learning Framework in Classification of Medical Images on Limited Data: A COVID-19 Case Study", "author": "Alexandros Shikun Zhang et.al.", "abstract": "COVID-19 pandemic has spread rapidly and caused a shortage of global medical resources. The efficiency of COVID-19 diagnosis has become highly significant. As deep learning and convolutional neural network (CNN) has been widely utilized and been verified in analyzing medical images, it has become a powerful tool for computer-assisted diagnosis. However, there are two most significant challenges in medical image classification with the help of deep learning and neural networks, one of them is the difficulty of acquiring enough samples, which may lead to model overfitting. Privacy concerns mainly bring the other challenge since medical-related records are often deemed patients' private information and protected by laws such as GDPR and HIPPA. Federated learning can ensure the model training is decentralized on different devices and no data is shared among them, which guarantees privacy. However, with data located on different devices, the accessible data of each device could be limited. Since transfer learning has been verified in dealing with limited data with good performance, therefore, in this paper, We made a trial to implement federated learning and transfer learning techniques using CNNs to classify COVID-19 using lung CT scans. We also explored the impact of dataset distribution at the client-side in federated learning and the number of training epochs a model is trained. Finally, we obtained very high performance with federated learning, demonstrating our success in leveraging accuracy and privacy.", "paper_url": "http://arxiv.org/abs/2203.12803v1", "pdf_url": "http://arxiv.org/pdf/2203.12803v1", "repo_url": null}, "2203.13718": {"publish_time": "2022-03-25", "title": "Digital Fingerprinting of Microstructures", "author": "Michael D. White et.al.", "abstract": "Finding efficient means of fingerprinting microstructural information is a critical step towards harnessing data-centric machine learning approaches. A statistical framework is systematically developed for compressed characterisation of a population of images, which includes some classical computer vision methods as special cases. The focus is on materials microstructure. The ultimate purpose is to rapidly fingerprint sample images in the context of various high-throughput design/make/test scenarios. This includes, but is not limited to, quantification of the disparity between microstructures for quality control, classifying microstructures, predicting materials properties from image data and identifying potential processing routes to engineer new materials with specific properties. Here, we consider microstructure classification and utilise the resulting features over a range of related machine learning tasks, namely supervised, semi-supervised, and unsupervised learning.   The approach is applied to two distinct datasets to illustrate various aspects and some recommendations are made based on the findings. In particular, methods that leverage transfer learning with convolutional neural networks (CNNs), pretrained on the ImageNet dataset, are generally shown to outperform other methods. Additionally, dimensionality reduction of these CNN-based fingerprints is shown to have negligible impact on classification accuracy for the supervised learning approaches considered. In situations where there is a large dataset with only a handful of images labelled, graph-based label propagation to unlabelled data is shown to be favourable over discarding unlabelled data and performing supervised learning. In particular, label propagation by Poisson learning is shown to be highly effective at low label rates.", "paper_url": "http://arxiv.org/abs/2203.13718v1", "pdf_url": "http://arxiv.org/pdf/2203.13718v1", "repo_url": null}, "2203.13628": {"publish_time": "2022-03-25", "title": "DeLoRes: Decorrelating Latent Spaces for Low-Resource Audio Representation Learning", "author": "Sreyan Ghosh et.al.", "abstract": "Inspired by the recent progress in self-supervised learning for computer vision, in this paper, through the DeLoRes learning framework, we introduce two new general-purpose audio representation learning approaches, the DeLoRes-S and DeLoRes-M. Our main objective is to make our network learn representations in a resource-constrained setting (both data and compute), that can generalize well across a diverse set of downstream tasks. Inspired from the Barlow Twins objective function, we propose to learn embeddings that are invariant to distortions of an input audio sample, while making sure that they contain non-redundant information about the sample. To achieve this, we measure the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of an audio segment sampled from an audio file and make it as close to the identity matrix as possible. We call this the DeLoRes learning framework, which we employ in different fashions with the DeLoRes-S and DeLoRes-M. We use a combination of a small subset of the large-scale AudioSet dataset and FSD50K for self-supervised learning and are able to learn with less than half the parameters compared to state-of-the-art algorithms. For evaluation, we transfer these learned representations to 11 downstream classification tasks, including speech, music, and animal sounds, and achieve state-of-the-art results on 7 out of 11 tasks on linear evaluation with DeLoRes-M and show competitive results with DeLoRes-S, even when pre-trained using only a fraction of the total data when compared to prior art. Our transfer learning evaluation setup also shows extremely competitive results for both DeLoRes-S and DeLoRes-M, with DeLoRes-M achieving state-of-the-art in 4 tasks.", "paper_url": "http://arxiv.org/abs/2203.13628v1", "pdf_url": "http://arxiv.org/pdf/2203.13628v1", "repo_url": null}, "2203.13461": {"publish_time": "2022-03-25", "title": "Interpretation of Chest x-rays affected by bullets using deep transfer learning", "author": "Shaheer Khan et.al.", "abstract": "The potential of deep learning, especially in medical imaging, initiated astonishing results and improved the methodologies after every passing day. Deep learning in radiology provides the opportunity to classify, detect and segment different diseases automatically. In the proposed study, we worked on a non-trivial aspect of medical imaging where we classified and localized the X-Rays affected by bullets. We tested Images on different classification and localization models to get considerable accuracy. The replicated data set used in the study was replicated on different images of chest X-Rays. The proposed model worked not only on chest radiographs but other body organs X-rays like leg, abdomen, head, even the training dataset based on chest radiographs. Custom models have been used for classification and localization purposes after tuning parameters. Finally, the results of our findings manifested using different frameworks. This might assist the research enlightening towards this field. To the best of our knowledge, this is the first study on the detection and classification of radiographs affected by bullets using deep learning.", "paper_url": "http://arxiv.org/abs/2203.13461v1", "pdf_url": "http://arxiv.org/pdf/2203.13461v1", "repo_url": null}, "2203.13453": {"publish_time": "2022-03-25", "title": "CNN LEGO: Disassembling and Assembling Convolutional Neural Network", "author": "Jiacong Hu et.al.", "abstract": "Convolutional Neural Network (CNN), which mimics human visual perception mechanism, has been successfully used in many computer vision areas. Some psychophysical studies show that the visual perception mechanism synchronously processes the form, color, movement, depth, etc., in the initial stage [7,20] and then integrates all information for final recognition [38]. What's more, the human visual system [20] contains different subdivisions or different tasks. Inspired by the above visual perception mechanism, we investigate a new task, termed as Model Disassembling and Assembling (MDA-Task), which can disassemble the deep models into independent parts and assemble those parts into a new deep model without performance cost like playing LEGO toys. To this end, we propose a feature route attribution technique (FRAT) for disassembling CNN classifiers in this paper. In FRAT, the positive derivatives of predicted class probability w.r.t. the feature maps are adopted to locate the critical features in each layer. Then, relevance analysis between the critical features and preceding/subsequent parameter layers is adopted to bridge the route between two adjacent parameter layers. In the assembling phase, class-wise components of each layer are assembled into a new deep model for a specific task. Extensive experiments demonstrate that the assembled CNN classifier can achieve close accuracy with the original classifier without any fine-tune, and excess original performance with one-epoch fine-tune. What's more, we also conduct massive experiments to verify the broad application of MDA-Task on model decision route visualization, model compression, knowledge distillation, transfer learning, incremental learning, and so on.", "paper_url": "http://arxiv.org/abs/2203.13453v1", "pdf_url": "http://arxiv.org/pdf/2203.13453v1", "repo_url": null}, "2203.13421": {"publish_time": "2022-03-25", "title": "Learning Losses for Strategic Classification", "author": "Tosca Lechner et.al.", "abstract": "Strategic classification, i.e. classification under possible strategic manipulations of features, has received a lot of attention from both the machine learning and the game theory community. Most works focus on analysing properties of the optimal decision rule under such manipulations. In our work we take a learning theoretic perspective, focusing on the sample complexity needed to learn a good decision rule which is robust to strategic manipulation. We perform this analysis by introducing a novel loss function, the \\emph{strategic manipulation loss}, which takes into account both the accuracy of the final decision rule and its vulnerability to manipulation. We analyse the sample complexity for a known graph of possible manipulations in terms of the complexity of the function class and the manipulation graph. Additionally, we initialize the study of learning under unknown manipulation capabilities of the involved agents. Using techniques from transfer learning theory, we define a similarity measure for manipulation graphs and show that learning outcomes are robust with respect to small changes in the manipulation graph. Lastly, we analyse the (sample complexity of) learning of the manipulation capability of agents with respect to this similarity measure, providing novel guarantees for strategic classification with respect to an unknown manipulation graph.", "paper_url": "http://arxiv.org/abs/2203.13421v1", "pdf_url": "http://arxiv.org/pdf/2203.13421v1", "repo_url": null}, "2203.14940": {"publish_time": "2022-03-28", "title": "Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model", "author": "Yu Du et.al.", "abstract": "Recently, vision-language pre-training shows great potential in open-vocabulary object detection, where detectors trained on base classes are devised for detecting new classes. The class text embedding is firstly generated by feeding prompts to the text encoder of a pre-trained vision-language model. It is then used as the region classifier to supervise the training of a detector. The key element that leads to the success of this model is the proper prompt, which requires careful words tuning and ingenious design. To avoid laborious prompt engineering, there are some prompt representation learning methods being proposed for the image classification task, which however can only be sub-optimal solutions when applied to the detection task. In this paper, we introduce a novel method, detection prompt (DetPro), to learn continuous prompt representations for open-vocabulary object detection based on the pre-trained vision-language model. Different from the previous classification-oriented methods, DetPro has two highlights: 1) a background interpretation scheme to include the proposals in image background into the prompt training; 2) a context grading scheme to separate proposals in image foreground for tailored prompt training. We assemble DetPro with ViLD, a recent state-of-the-art open-world object detector, and conduct experiments on the LVIS as well as transfer learning on the Pascal VOC, COCO, Objects365 datasets. Experimental results show that our DetPro outperforms the baseline ViLD in all settings, e.g., +3.4 APbox and +3.0 APmask improvements on the novel classes of LVIS. Code and models are available at https://github.com/dyabel/detpro.", "paper_url": "http://arxiv.org/abs/2203.14940v1", "pdf_url": "http://arxiv.org/pdf/2203.14940v1", "repo_url": "https://github.com/dyabel/detpro"}, "2203.14865": {"publish_time": "2022-03-28", "title": "Towards Transferable Speech Emotion Representation: On loss functions for cross-lingual latent representations", "author": "Sneha Das et.al.", "abstract": "In recent years, speech emotion recognition (SER) has been used in wide ranging applications, from healthcare to the commercial sector. In addition to signal processing approaches, methods for SER now also use deep learning techniques which provide transfer learning possibilities. However, generalizing over languages, corpora and recording conditions is still an open challenge. In this work we address this gap by exploring loss functions that aid in transferability, specifically to non-tonal languages. We propose a variational autoencoder (VAE) with KL annealing and a semi-supervised VAE to obtain more consistent latent embedding distributions across data sets. To ensure transferability, the distribution of the latent embedding should be similar across non-tonal languages (data sets). We start by presenting a low-complexity SER based on a denoising-autoencoder, which achieves an unweighted classification accuracy of over 52.09% for four-class emotion classification. This performance is comparable to that of similar baseline methods. Following this, we employ a VAE, the semi-supervised VAE and the VAE with KL annealing to obtain a more regularized latent space. We show that while the DAE has the highest classification accuracy among the methods, the semi-supervised VAE has a comparable classification accuracy and a more consistent latent embedding distribution over data sets.", "paper_url": "http://arxiv.org/abs/2203.14865v1", "pdf_url": "http://arxiv.org/pdf/2203.14865v1", "repo_url": null}, "2203.14415": {"publish_time": "2022-03-27", "title": "Mugs: A Multi-Granular Self-Supervised Learning Framework", "author": "Pan Zhou et.al.", "abstract": "In self-supervised learning, multi-granular features are heavily desired though rarely investigated, as different downstream tasks (e.g., general and fine-grained classification) often require different or multi-granular features, e.g.~fine- or coarse-grained one or their mixture. In this work, for the first time, we propose an effective MUlti-Granular Self-supervised learning (Mugs) framework to explicitly learn multi-granular visual features. Mugs has three complementary granular supervisions: 1) an instance discrimination supervision (IDS), 2) a novel local-group discrimination supervision (LGDS), and 3) a group discrimination supervision (GDS). IDS distinguishes different instances to learn instance-level fine-grained features. LGDS aggregates features of an image and its neighbors into a local-group feature, and pulls local-group features from different crops of the same image together and push them away for others. It provides complementary instance supervision to IDS via an extra alignment on local neighbors, and scatters different local-groups separately to increase discriminability. Accordingly, it helps learn high-level fine-grained features at a local-group level. Finally, to prevent similar local-groups from being scattered randomly or far away, GDS brings similar samples close and thus pulls similar local-groups together, capturing coarse-grained features at a (semantic) group level. Consequently, Mugs can capture three granular features that often enjoy higher generality on diverse downstream tasks over single-granular features, e.g.~instance-level fine-grained features in contrastive learning. By only pretraining on ImageNet-1K, Mugs sets new SoTA linear probing accuracy 82.1$\\%$ on ImageNet-1K and improves previous SoTA by $1.1\\%$. It also surpasses SoTAs on other tasks, e.g. transfer learning, detection and segmentation.", "paper_url": "http://arxiv.org/abs/2203.14415v1", "pdf_url": "http://arxiv.org/pdf/2203.14415v1", "repo_url": "https://github.com/sail-sg/mugs"}, "2203.14298": {"publish_time": "2022-03-27", "title": "Benchmarking Algorithms for Automatic License Plate Recognition", "author": "Marcel Del Castillo Velarde et.al.", "abstract": "We evaluated a lightweight Convolutional Neural Network (CNN) called LPRNet [1] for automatic License Plate Recognition (LPR). We evaluated the algorithm on two datasets, one composed of real license plate images and the other of synthetic license plate images. In addition, we compared its performance against Tesseract [2], an Optical Character Recognition engine. We measured performance based on recognition accuracy and Levenshtein Distance. LPRNet is an end-to-end framework and demonstrated robust performance on both datasets, delivering 90 and 89 percent recognition accuracy on test sets of 1000 real and synthetic license plate images, respectively. Tesseract was not trained using real license plate images and performed well only on the synthetic dataset after pre-processing steps delivering 93 percent recognition accuracy. Finally, Pareto analysis for frequency analysis of misclassified characters allowed us to find in detail which characters were the most conflicting ones according to the percentage of accumulated error. Depending on the region, license plate images possess particular characteristics. Once properly trained, LPRNet can be used to recognize characters from a specific region and dataset. Future work can focus on applying transfer learning to utilize the features learned by LPRNet and fine-tune it given a smaller, newer dataset of license plates.", "paper_url": "http://arxiv.org/abs/2203.14298v1", "pdf_url": "http://arxiv.org/pdf/2203.14298v1", "repo_url": null}, "2203.14205": {"publish_time": "2022-03-27", "title": "An Empirical Study and Comparison of Recent Few-Shot Object Detection Algorithms", "author": "Tianying Liu et.al.", "abstract": "The generic object detection (GOD) task has been successfully tackled by recent deep neural networks, trained by an avalanche of annotated training samples from some common classes. However, it is still non-trivial to generalize these object detectors to the novel long-tailed object classes, which has only few labeled training samples. To this end, the Few-Shot Object Detection (FSOD) has been topical recently, as it mimics the humans' ability of learning to learn, and intelligently transfers the learnt generic object knowledge from the common heavy-tailed, to the novel long-tailed object classes. Especially, the research in this emerging field has been flourish in the recent years with various benchmarks, backbones, and methodologies proposed. To review these FSOD works, there are several insightful FSOD survey articles that systematically study and compare them as the groups of fine-tuning/transfer learning, and meta-learning methods. In contrast, we compare these FSOD algorithms from the new perspective and taxonomy of their contributions, i.e., data-oriented, model-oriented, and algorithm oriented ones. Thus, an empirical study and comparison has been conducted on the recent achievements of FSOD. Furthermore, we also analyze the technical challenges, the merits and demerits of these methods, and envision the future directions of FSOD. Specifically, we give an overview of FSOD, including the problem definition, common datasets, and evaluation protocols. A new taxonomy is then proposed based on the role of prior knowledge during object detection of novel classes. Following this taxonomy, we provide a systematic review of the advances in FSOD. Finally, further discussions on performance, challenges, and future directions are presented.", "paper_url": "http://arxiv.org/abs/2203.14205v1", "pdf_url": "http://arxiv.org/pdf/2203.14205v1", "repo_url": null}, "2203.15447": {"publish_time": "2022-03-29", "title": "Transfer Learning Framework for Low-Resource Text-to-Speech using a Large-Scale Unlabeled Speech Corpus", "author": "Minchan Kim et.al.", "abstract": "Training a text-to-speech (TTS) model requires a large scale text labeled speech corpus, which is troublesome to collect. In this paper, we propose a transfer learning framework for TTS that utilizes a large amount of unlabeled speech dataset for pre-training. By leveraging wav2vec2.0 representation, unlabeled speech can highly improve performance, especially in the lack of labeled speech. We also extend the proposed method to zero-shot multi-speaker TTS (ZS-TTS). The experimental results verify the effectiveness of the proposed method in terms of naturalness, intelligibility, and speaker generalization. We highlight that the single speaker TTS model fine-tuned on the only 10 minutes of labeled dataset outperforms the other baselines, and the ZS-TTS model fine-tuned on the only 30 minutes of single speaker dataset can generate the voice of the arbitrary speaker, by pre-training on unlabeled multi-speaker speech corpus.", "paper_url": "http://arxiv.org/abs/2203.15447v1", "pdf_url": "http://arxiv.org/pdf/2203.15447v1", "repo_url": null}, "2203.15297": {"publish_time": "2022-03-29", "title": "Kernel Modulation: A Parameter-Efficient Method for Training Convolutional Neural Networks", "author": "Yuhuang Hu et.al.", "abstract": "Deep Neural Networks, particularly Convolutional Neural Networks (ConvNets), have achieved incredible success in many vision tasks, but they usually require millions of parameters for good accuracy performance. With increasing applications that use ConvNets, updating hundreds of networks for multiple tasks on an embedded device can be costly in terms of memory, bandwidth, and energy. Approaches to reduce this cost include model compression and parameter-efficient models that adapt a subset of network layers for each new task. This work proposes a novel parameter-efficient kernel modulation (KM) method that adapts all parameters of a base network instead of a subset of layers. KM uses lightweight task-specialized kernel modulators that require only an additional 1.4% of the base network parameters. With multiple tasks, only the task-specialized KM weights are communicated and stored on the end-user device. We applied this method in training ConvNets for Transfer Learning and Meta-Learning scenarios. Our results show that KM delivers up to 9% higher accuracy than other parameter-efficient methods on the Transfer Learning benchmark.", "paper_url": "http://arxiv.org/abs/2203.15297v1", "pdf_url": "http://arxiv.org/pdf/2203.15297v1", "repo_url": null}, "2203.17205": {"publish_time": "2022-03-31", "title": "Leverage Your Local and Global Representations: A New Self-Supervised Learning Strategy", "author": "Tong Zhang et.al.", "abstract": "Self-supervised learning (SSL) methods aim to learn view-invariant representations by maximizing the similarity between the features extracted from different crops of the same image regardless of cropping size and content. In essence, this strategy ignores the fact that two crops may truly contain different image information, e.g., background and small objects, and thus tends to restrain the diversity of the learned representations. %To this end, the existing strategies typically employ loss functions that enforces the networks to discard part of valuable information, e.g. background and small objects, and sacrifices the diversity of representation. In this work, we address this issue by introducing a new self-supervised learning strategy, LoGo, that explicitly reasons about {\\bf Lo}cal and {\\bf G}l{\\bf o}bal crops. To achieve view invariance, LoGo encourages similarity between global crops from the same image, as well as between a global and a local crop. However, to correctly encode the fact that the content of smaller crops may differ entirely, LoGo promotes two local crops to have dissimilar representations, while being close to global crops. Our LoGo strategy can easily be applied to existing SSL methods. Our extensive experiments on a variety of datasets and using different self-supervised learning frameworks validate its superiority over existing approaches. Noticeably, we achieve better results than supervised models on transfer learning when using only $1/10$ of the data.", "paper_url": "http://arxiv.org/abs/2203.17205v1", "pdf_url": "http://arxiv.org/pdf/2203.17205v1", "repo_url": null}, "2203.17070": {"publish_time": "2022-03-31", "title": "Traffic4cast at NeurIPS 2021 - Temporal and Spatial Few-Shot Transfer Learning in Gridded Geo-Spatial Processes", "author": "Christian Eichenberger et.al.", "abstract": "The IARAI Traffic4cast competitions at NeurIPS 2019 and 2020 showed that neural networks can successfully predict future traffic conditions 1 hour into the future on simply aggregated GPS probe data in time and space bins. We thus reinterpreted the challenge of forecasting traffic conditions as a movie completion task. U-Nets proved to be the winning architecture, demonstrating an ability to extract relevant features in this complex real-world geo-spatial process. Building on the previous competitions, Traffic4cast 2021 now focuses on the question of model robustness and generalizability across time and space. Moving from one city to an entirely different city, or moving from pre-COVID times to times after COVID hit the world thus introduces a clear domain shift. We thus, for the first time, release data featuring such domain shifts. The competition now covers ten cities over 2 years, providing data compiled from over 10^12 GPS probe data. Winning solutions captured traffic dynamics sufficiently well to even cope with these complex domain shifts. Surprisingly, this seemed to require only the previous 1h traffic dynamic history and static road graph as input.", "paper_url": "http://arxiv.org/abs/2203.17070v1", "pdf_url": "http://arxiv.org/pdf/2203.17070v1", "repo_url": "https://github.com/iarai/NeurIPS2021-traffic4cast"}, "2203.17013": {"publish_time": "2022-03-31", "title": "A Temporal Learning Approach to Inpainting Endoscopic Specularities and Its effect on Image Correspondence", "author": "Rema Daher et.al.", "abstract": "Video streams are utilised to guide minimally-invasive surgery and diagnostic procedures in a wide range of procedures, and many computer assisted techniques have been developed to automatically analyse them. These approaches can provide additional information to the surgeon such as lesion detection, instrument navigation, or anatomy 3D shape modeling. However, the necessary image features to recognise these patterns are not always reliably detected due to the presence of irregular light patterns such as specular highlight reflections. In this paper, we aim at removing specular highlights from endoscopic videos using machine learning. We propose using a temporal generative adversarial network (GAN) to inpaint the hidden anatomy under specularities, inferring its appearance spatially and from neighbouring frames where they are not present in the same location. This is achieved using in-vivo data of gastric endoscopy (Hyper-Kvasir) in a fully unsupervised manner that relies on automatic detection of specular highlights. System evaluations show significant improvements to traditional methods through direct comparison as well as other machine learning techniques through an ablation study that depicts the importance of the network's temporal and transfer learning components. The generalizability of our system to different surgical setups and procedures was also evaluated qualitatively on in-vivo data of gastric endoscopy and ex-vivo porcine data (SERV-CT, SCARED). We also assess the effect of our method in computer vision tasks that underpin 3D reconstruction and camera motion estimation, namely stereo disparity, optical flow, and sparse point feature matching. These are evaluated quantitatively and qualitatively and results show a positive effect of specular highlight inpainting on these tasks in a novel comprehensive analysis.", "paper_url": "http://arxiv.org/abs/2203.17013v1", "pdf_url": "http://arxiv.org/pdf/2203.17013v1", "repo_url": null}, "2203.16926": {"publish_time": "2022-03-31", "title": "Domain Adaptation for Sparse-Data Settings: What Do We Gain by Not Using Bert?", "author": "Marina Sedinkina et.al.", "abstract": "The practical success of much of NLP depends on the availability of training data. However, in real-world scenarios, training data is often scarce, not least because many application domains are restricted and specific. In this work, we compare different methods to handle this problem and provide guidelines for building NLP applications when there is only a small amount of labeled training data available for a specific domain. While transfer learning with pre-trained language models outperforms other methods across tasks, alternatives do not perform much worse while requiring much less computational effort, thus significantly reducing monetary and environmental cost. We examine the performance tradeoffs of several such alternatives, including models that can be trained up to 175K times faster and do not require a single GPU.", "paper_url": "http://arxiv.org/abs/2203.16926v1", "pdf_url": "http://arxiv.org/pdf/2203.16926v1", "repo_url": null}, "2204.00484": {"publish_time": "2022-04-01", "title": "Proper Reuse of Image Classification Features Improves Object Detection", "author": "Cristina Vasconcelos et.al.", "abstract": "A common practice in transfer learning is to initialize the downstream model weights by pre-training on a data-abundant upstream task. In object detection specifically, the feature backbone is typically initialized with Imagenet classifier weights and fine-tuned on the object detection task. Recent works show this is not strictly necessary under longer training regimes and provide recipes for training the backbone from scratch. We investigate the opposite direction of this end-to-end training trend: we show that an extreme form of knowledge preservation -- freezing the classifier-initialized backbone -- consistently improves many different detection models, and leads to considerable resource savings. We hypothesize and corroborate experimentally that the remaining detector components capacity and structure is a crucial factor in leveraging the frozen backbone. Immediate applications of our findings include performance improvements on hard cases like detection of long-tail object classes and computational and memory resource savings that contribute to making the field more accessible to researchers with access to fewer computational resources.", "paper_url": "http://arxiv.org/abs/2204.00484v1", "pdf_url": "http://arxiv.org/pdf/2204.00484v1", "repo_url": null}, "2204.00477": {"publish_time": "2022-04-01", "title": "Autonomous crater detection on asteroids using a fully-convolutional neural network", "author": "Francesco Latorre et.al.", "abstract": "This paper shows the application of autonomous Crater Detection using the U-Net, a Fully-Convolutional Neural Network, on Ceres. The U-Net is trained on optical images of the Moon Global Morphology Mosaic based on data collected by the LRO and manual crater catalogues. The Moon-trained network will be tested on Dawn optical images of Ceres: this task is accomplished by means of a Transfer Learning (TL) approach. The trained model has been fine-tuned using 100, 500 and 1000 additional images of Ceres. The test performance was measured on 350 never before seen images, reaching a testing accuracy of 96.24%, 96.95% and 97.19%, respectively. This means that despite the intrinsic differences between the Moon and Ceres, TL works with encouraging results. The output of the U-Net contains predicted craters: it will be post-processed applying global thresholding for image binarization and a template matching algorithm to extract craters positions and radii in the pixel space. Post-processed craters will be counted and compared to the ground truth data in order to compute image segmentation metrics: precision, recall and F1 score. These indices will be computed, and their effect will be discussed for tasks such as automated crater cataloguing and optical navigation.", "paper_url": "http://arxiv.org/abs/2204.00477v1", "pdf_url": "http://arxiv.org/pdf/2204.00477v1", "repo_url": null}, "2204.00327": {"publish_time": "2022-04-01", "title": "Diverse Preference Augmentation with Multiple Domains for Cold-start Recommendations", "author": "Yan Zhang et.al.", "abstract": "Cold-start issues have been more and more challenging for providing accurate recommendations with the fast increase of users and items. Most existing approaches attempt to solve the intractable problems via content-aware recommendations based on auxiliary information and/or cross-domain recommendations with transfer learning. Their performances are often constrained by the extremely sparse user-item interactions, unavailable side information, or very limited domain-shared users. Recently, meta-learners with meta-augmentation by adding noises to labels have been proven to be effective to avoid overfitting and shown good performance on new tasks. Motivated by the idea of meta-augmentation, in this paper, by treating a user's preference over items as a task, we propose a so-called Diverse Preference Augmentation framework with multiple source domains based on meta-learning (referred to as MetaDPA) to i) generate diverse ratings in a new domain of interest (known as target domain) to handle overfitting on the case of sparse interactions, and to ii) learn a preference model in the target domain via a meta-learning scheme to alleviate cold-start issues. Specifically, we first conduct multi-source domain adaptation by dual conditional variational autoencoders and impose a Multi-domain InfoMax (MDI) constraint on the latent representations to learn domain-shared and domain-specific preference properties. To avoid overfitting, we add a Mutually-Exclusive (ME) constraint on the output of decoders to generate diverse ratings given content data. Finally, these generated diverse ratings and the original ratings are introduced into the meta-training procedure to learn a preference meta-learner, which produces good generalization ability on cold-start recommendation tasks. Experiments on real-world datasets show our proposed MetaDPA clearly outperforms the current state-of-the-art baselines.", "paper_url": "http://arxiv.org/abs/2204.00327v1", "pdf_url": "http://arxiv.org/pdf/2204.00327v1", "repo_url": null}, "2204.00132": {"publish_time": "2022-03-31", "title": "Real-Time and Robust 3D Object Detection Within Road-Side LiDARs Using Domain Adaptation", "author": "Walter Zimmer et.al.", "abstract": "This work aims to address the challenges in domain adaptation of 3D object detection using infrastructure LiDARs. We design a model DASE-ProPillars that can detect vehicles in infrastructure-based LiDARs in real-time. Our model uses PointPillars as the baseline model with additional modules to improve the 3D detection performance. To prove the effectiveness of our proposed modules in DASE-ProPillars, we train and evaluate the model on two datasets, the open source A9-Dataset and a semi-synthetic infrastructure dataset created within the Regensburg Next project. We do several sets of experiments for each module in the DASE-ProPillars detector that show that our model outperforms the SE-ProPillars baseline on the real A9 test set and a semi-synthetic A9 test set, while maintaining an inference speed of 45 Hz (22 ms). We apply domain adaptation from the semi-synthetic A9-Dataset to the semi-synthetic dataset from the Regensburg Next project by applying transfer learning and achieve a 3D mAP@0.25 of 93.49% on the Car class of the target test set using 40 recall positions.", "paper_url": "http://arxiv.org/abs/2204.00132v1", "pdf_url": "http://arxiv.org/pdf/2204.00132v1", "repo_url": null}, "2204.01626": {"publish_time": "2022-04-04", "title": "Stuttgart Open Relay Degradation Dataset (SOReDD)", "author": "Benjamin Maschler et.al.", "abstract": "Real-life industrial use cases for machine learning oftentimes involve heterogeneous and dynamic assets, processes and data, resulting in a need to continuously adapt the learning algorithm accordingly. Industrial transfer learning offers to lower the effort of such adaptation by allowing the utilization of previously acquired knowledge in solving new (variants of) tasks. Being data-driven methods, the development of industrial transfer learning algorithms naturally requires appropriate datasets for training. However, open-source datasets suitable for transfer learning training, i.e. spanning different assets, processes and data (variants), are rare. With the Stuttgart Open Relay Degradation Dataset (SOReDD) we want to offer such a dataset. It provides data on the degradation of different electromechanical relays under different operating conditions, allowing for a large number of different transfer scenarios. Although such relays themselves are usually inexpensive standard components, their failure often leads to the failure of a machine as a whole due to their role as the central power switching element of a machine. The main cost factor in the event of a relay defect is therefore not the relay itself, but the reduced machine availability. It is therefore desirable to predict relay degradation as accurately as possible for specific applications in order to be able to replace relays in good time and avoid unplanned machine downtimes. Nevertheless, data-driven failure prediction for electromechanical relays faces the challenge that relay degradation behavior is highly dependent on the operating conditions, high-resolution measurement data on relay degradation behavior is only collected in rare cases, and such data can then only cover a fraction of the possible operating environments. Relays are thus representative of many other central standard components in automation technology.", "paper_url": "http://arxiv.org/abs/2204.01626v1", "pdf_url": "http://arxiv.org/pdf/2204.01626v1", "repo_url": null}, "2204.01620": {"publish_time": "2022-04-04", "title": "Towards Deep Industrial Transfer Learning: Clustering for Transfer Case Selection", "author": "Benjamin Maschler et.al.", "abstract": "Industrial transfer learning increases the adaptability of deep learning algorithms towards heterogenous and dynamic industrial use cases without high manual efforts. The appropriate selection of what to transfer can vastly improve a transfer's results. In this paper, a transfer case selection based upon clustering is presented. Founded on a survey of clustering algorithms, the BIRCH algorithm is selected for this purpose. It is evaluated on an industrial time series dataset from a discrete manufacturing scenario. Results underline the approaches' applicability caused by its results' reproducibility and practical indifference to sequence, size and dimensionality of (sub-)datasets to be clustered sequentially.", "paper_url": "http://arxiv.org/abs/2204.01620v1", "pdf_url": "http://arxiv.org/pdf/2204.01620v1", "repo_url": null}, "2204.01457": {"publish_time": "2022-04-04", "title": "SHiFT: An Efficient, Flexible Search Engine for Transfer Learning", "author": "Cedric Renggli et.al.", "abstract": "Transfer learning can be seen as a data- and compute-efficient alternative to training models from scratch. The emergence of rich model repositories, such as TensorFlow Hub, enables practitioners and researchers to unleash the potential of these models across a wide range of downstream tasks. As these repositories keep growing exponentially, efficiently selecting a good model for the task at hand becomes paramount. By carefully comparing various selection and search strategies, we realize that no single method outperforms the others, and hybrid or mixed strategies can be beneficial. Therefore, we propose SHiFT, the first downstream task-aware, flexible, and efficient model search engine for transfer learning. These properties are enabled by a custom query language SHiFT-QL together with a cost-based decision maker, which we empirically validate. Motivated by the iterative nature of machine learning development, we further support efficient incremental executions of our queries, which requires a careful implementation when jointly used with our optimizations.", "paper_url": "http://arxiv.org/abs/2204.01457v1", "pdf_url": "http://arxiv.org/pdf/2204.01457v1", "repo_url": "https://github.com/ds3lab/shift"}, "2204.01411": {"publish_time": "2022-04-04", "title": "Computer-Aided Extraction of Select MRI Markers of Cerebral Small Vessel Disease: A Systematic Review", "author": "Jiyang Jiang et.al.", "abstract": "Cerebral small vessel disease (CSVD) is a major vascular contributor to cognitive impairment in ageing, including dementias. Imaging remains the most promising method for in vivo studies of CSVD. To replace the subjective and laborious visual rating approaches, emerging studies have applied state-of-the-art artificial intelligence to extract imaging biomarkers of CSVD from MRI scans. We aimed to summarise published computer-aided methods to examine three imaging biomarkers of CSVD, namely cerebral microbleeds (CMB), dilated perivascular spaces (PVS), and lacunes of presumed vascular origin. Seventy-one classical image processing, classical machine learning, and deep learning studies were identified. CMB and PVS have been better studied, compared to lacunes. While good performance metrics have been achieved in local test datasets, there have not been generalisable pipelines validated in different research or clinical cohorts. Transfer learning and weak supervision techniques have been applied to accommodate the limitations in training data. Future studies could consider pooling data from multiple sources to increase diversity, and validating the performance of the methods using both image processing metrics and associations with clinical measures.", "paper_url": "http://arxiv.org/abs/2204.01411v1", "pdf_url": "http://arxiv.org/pdf/2204.01411v1", "repo_url": null}, "2204.01387": {"publish_time": "2022-04-04", "title": "Anti-Spoofing Using Transfer Learning with Variational Information Bottleneck", "author": "Youngsik Eom et.al.", "abstract": "Recent advances in sophisticated synthetic speech generated from text-to-speech (TTS) or voice conversion (VC) systems cause threats to the existing automatic speaker verification (ASV) systems. Since such synthetic speech is generated from diverse algorithms, generalization ability with using limited training data is indispensable for a robust anti-spoofing system. In this work, we propose a transfer learning scheme based on the wav2vec 2.0 pretrained model with variational information bottleneck (VIB) for speech anti-spoofing task. Evaluation on the ASVspoof 2019 logical access (LA) database shows that our method improves the performance of distinguishing unseen spoofed and genuine speech, outperforming current state-of-the-art anti-spoofing systems. Furthermore, we show that the proposed system improves performance in low-resource and cross-dataset settings of anti-spoofing task significantly, demonstrating that our system is also robust in terms of data size and data distribution.", "paper_url": "http://arxiv.org/abs/2204.01387v1", "pdf_url": "http://arxiv.org/pdf/2204.01387v1", "repo_url": null}, "2204.02325": {"publish_time": "2022-04-05", "title": "A lightweight and accurate YOLO-like network for small target detection in Aerial Imagery", "author": "Alessandro Betti et.al.", "abstract": "Despite the breakthrough deep learning performances achieved for automatic object detection, small target detection is still a challenging problem, especially when looking at fast and accurate solutions suitable for mobile or edge applications. In this work we present YOLO-S, a simple, fast and efficient network for small target detection. The architecture exploits a small feature extractor based on Darknet20, as well as skip connection, via both bypass and concatenation, and reshape-passthrough layer to alleviate the vanishing gradient problem, promote feature reuse across network and combine low-level positional information with more meaningful high-level information. To verify the performances of YOLO-S, we build \"AIRES\", a novel dataset for cAr detectIon fRom hElicopter imageS acquired in Europe, and set up experiments on both AIRES and VEDAI datasets, benchmarking this architecture with four baseline detectors. Furthermore, in order to handle efficiently the issue of data insufficiency and domain gap when dealing with a transfer learning strategy, we introduce a transitional learning task over a combined dataset based on DOTAv2 and VEDAI and demonstrate that can enhance the overall accuracy with respect to more general features transferred from COCO data. YOLO-S is from 25% to 50% faster than YOLOv3 and only 15-25% slower than Tiny-YOLOv3, outperforming also YOLOv3 in terms of accuracy in a wide range of experiments. Further simulations performed on SARD dataset demonstrate also its applicability to different scenarios such as for search and rescue operations. Besides, YOLO-S has an 87% decrease of parameter size and almost one half FLOPs of YOLOv3, making practical the deployment for low-power industrial applications.", "paper_url": "http://arxiv.org/abs/2204.02325v1", "pdf_url": "http://arxiv.org/pdf/2204.02325v1", "repo_url": null}, "2204.01916": {"publish_time": "2022-04-05", "title": "Domain-Aware Contrastive Knowledge Transfer for Multi-domain Imbalanced Data", "author": "Zixuan Ke et.al.", "abstract": "In many real-world machine learning applications, samples belong to a set of domains e.g., for product reviews each review belongs to a product category. In this paper, we study multi-domain imbalanced learning (MIL), the scenario that there is imbalance not only in classes but also in domains. In the MIL setting, different domains exhibit different patterns and there is a varying degree of similarity and divergence among domains posing opportunities and challenges for transfer learning especially when faced with limited or insufficient training data. We propose a novel domain-aware contrastive knowledge transfer method called DCMI to (1) identify the shared domain knowledge to encourage positive transfer among similar domains (in particular from head domains to tail domains); (2) isolate the domain-specific knowledge to minimize the negative transfer from dissimilar domains. We evaluated the performance of DCMI on three different datasets showing significant improvements in different MIL scenarios.", "paper_url": "http://arxiv.org/abs/2204.01916v1", "pdf_url": "http://arxiv.org/pdf/2204.01916v1", "repo_url": null}, "2204.02802": {"publish_time": "2022-04-06", "title": "Dimensionality Expansion and Transfer Learning for Next Generation Energy Management Systems", "author": "Bla\u017e Bertalani\u010d et.al.", "abstract": "Electrical management systems (EMS) are playing a central role in enabling energy savings. They can be deployed within an everyday household where they monitor and manage appliances and help residents be more energy efficient and subsequently also more economical. One of they key functionalities of EMS is to automatically detect and identify appliances within a household through the process of load monitoring. In this paper, we propose a new transfer learning approach for building EMS (BEMS) and study the trade-offs in terms of numbers of samples and target classes in adapting a backbone model during the transfer process. We also perform a first time analysis of feature expansion through video-like transformation of time series data for device classification in non intrusive load monitoring (NILM) and propose a deep learning architecture enabling accurate appliance identification. We examine the relative performance of our method on 5 different representative low-frequency datasets and show that our method performs with an average F1 score of 0.88 on these datasets.", "paper_url": "http://arxiv.org/abs/2204.02802v1", "pdf_url": "http://arxiv.org/pdf/2204.02802v1", "repo_url": null}, "2204.02712": {"publish_time": "2022-04-06", "title": "A New Dataset for Topic-Based Paragraph Classification in Genocide-Related Court Transcripts", "author": "Miriam Schirmer et.al.", "abstract": "Recent progress in natural language processing has been impressive in many different areas with transformer-based approaches setting new benchmarks for a wide range of applications. This development has also lowered the barriers for people outside the NLP community to tap into the tools and resources applied to a variety of domain-specific applications. The bottleneck however still remains the lack of annotated gold-standard collections as soon as one's research or professional interest falls outside the scope of what is readily available. One such area is genocide-related research (also including the work of experts who have a professional interest in accessing, exploring and searching large-scale document collections on the topic, such as lawyers). We present GTC (Genocide Transcript Corpus), the first annotated corpus of genocide-related court transcripts which serves three purposes: (1) to provide a first reference corpus for the community, (2) to establish benchmark performances (using state-of-the-art transformer-based approaches) for the new classification task of paragraph identification of violence-related witness statements, (3) to explore first steps towards transfer learning within the domain. We consider our contribution to be addressing in particular this year's hot topic on Language Technology for All.", "paper_url": "http://arxiv.org/abs/2204.02712v1", "pdf_url": "http://arxiv.org/pdf/2204.02712v1", "repo_url": null}, "2204.02685": {"publish_time": "2022-04-06", "title": "Language Model for Text Analytic in Cybersecurity", "author": "Ehsan Aghaei et.al.", "abstract": "NLP is a form of artificial intelligence and machine learning concerned with a computer or machine's ability to understand and interpret human language. Language models are crucial in text analytics and NLP since they allow computers to interpret qualitative input and convert it to quantitative data that they can use in other tasks. In essence, in the context of transfer learning, language models are typically trained on a large generic corpus, referred to as the pre-training stage, and then fine-tuned to a specific underlying task. As a result, pre-trained language models are mostly used as a baseline model that incorporates a broad grasp of the context and may be further customized to be used in a new NLP task.   The majority of pre-trained models are trained on corpora from general domains, such as Twitter, newswire, Wikipedia, and Web. Such off-the-shelf NLP models trained on general text may be inefficient and inaccurate in specialized fields. In this paper, we propose a cybersecurity language model called SecureBERT, which is able to capture the text connotations in the cybersecurity domain, and therefore could further be used in automation for many important cybersecurity tasks that would otherwise rely on human expertise and tedious manual efforts. SecureBERT is trained on a large corpus of cybersecurity text collected and preprocessed by us from a variety of sources in cybersecurity and the general computing domain. Using our proposed methods for tokenization and model weights adjustment, SecureBERT is not only able to preserve the understanding of general English as most pre-trained language models can do, but also effective when applied to text that has cybersecurity implications.", "paper_url": "http://arxiv.org/abs/2204.02685v1", "pdf_url": "http://arxiv.org/pdf/2204.02685v1", "repo_url": null}, "2204.02581": {"publish_time": "2022-04-06", "title": "Banana Sub-Family Classification and Quality Prediction using Computer Vision", "author": "Narayana Darapaneni et.al.", "abstract": "India is the second largest producer of fruits and vegetables in the world, and one of the largest consumers of fruits like Banana, Papaya and Mangoes through retail and ecommerce giants like BigBasket, Grofers and Amazon Fresh. However, adoption of technology in supply chain and retail stores is still low and there is a great potential to adopt computer-vision based technology for identification and classification of fruits. We have chosen banana fruit to build a computer vision based model to carry out the following three use-cases (a) Identify Banana from a given image (b) Determine sub-family or variety of Banana (c) Determine the quality of Banana. Successful execution of these use-cases using computer-vision model would greatly help with overall inventory management automation, quality control, quick and efficient weighing and billing which all are manual labor intensive currently. In this work, we suggest a machine learning pipeline that combines the ideas of CNNs, transfer learning, and data augmentation towards improving Banana fruit sub family and quality image classification. We have built a basic CNN and then went on to tune a MobileNet Banana classification model using a combination of self-curated and publicly-available dataset of 3064 images. The results show an overall 93.4% and 100% accuracy for sub-family/variety and for quality test classifications respectively.", "paper_url": "http://arxiv.org/abs/2204.02581v1", "pdf_url": "http://arxiv.org/pdf/2204.02581v1", "repo_url": null}, "2204.03649": {"publish_time": "2022-04-07", "title": "Unsupervised Prompt Learning for Vision-Language Models", "author": "Tony Huang et.al.", "abstract": "Contrastive vision-language models like CLIP have shown great progress in zero-shot transfer learning. This new paradigm uses large-scale image-text pairs for training and aligns images and texts in a common embedding space. In the inference stage, the proper text description, known as prompt, needs to be carefully designed for zero-shot transfer. To avoid laborious prompt engineering and simultaneously improve transfer performance, recent works such as CoOp, CLIP-Adapter and Tip-Adapter propose to adapt vision-language models for downstream image recognition tasks by either optimizing the continuous prompt representations or training an additional adapter network on top of the pre-trained vision-language models on a small set of labeled data. Though promising improvements are achieved, using labeled images from target datasets may violate the intention of zero-shot transfer of pre-trained vision-language models. In this paper, we propose an unsupervised prompt learning (UPL) framework, which does not require any annotations of the target dataset, to improve the zero-shot transfer of CLIP-like vision-language models. Experimentally, for zero-shot transfer, our UPL outperforms original CLIP with prompt engineering and on ImageNet as well as other 10 datasets. An enhanced version of UPL is even on par with the 8-shot CoOp and the 8-shot TIP-Adapter on most datasets while our method does not need any labeled images for training. Code and models are available at https://github.com/tonyhuang2022/UPL.", "paper_url": "http://arxiv.org/abs/2204.03649v1", "pdf_url": "http://arxiv.org/pdf/2204.03649v1", "repo_url": "https://github.com/tonyhuang2022/upl"}, "2204.03618": {"publish_time": "2022-04-07", "title": "Pneumonia Detection in Chest X-Rays using Neural Networks", "author": "Narayana Darapaneni et.al.", "abstract": "With the advancement in AI, deep learning techniques are widely used to design robust classification models in several areas such as medical diagnosis tasks in which it achieves good performance. In this paper, we have proposed the CNN model (Convolutional Neural Network) for the classification of Chest X-ray images for Radiological Society of North America Pneumonia (RSNA) datasets. The study also tries to achieve the same RSNA benchmark results using the limited computational resources by trying out various approaches to the methodologies that have been implemented in recent years. The proposed method is based on a non-complex CNN and the use of transfer learning algorithms like Xception, InceptionV3/V4, EfficientNetB7. Along with this, the study also tries to achieve the same RSNA benchmark results using the limited computational resources by trying out various approaches to the methodologies that have been implemented in recent years. The RSNA benchmark MAP score is 0.25, but using the Mask RCNN model on a stratified sample of 3017 along with image augmentation gave a MAP score of 0.15. Meanwhile, the YoloV3 without any hyperparameter tuning gave the MAP score of 0.32 but still, the loss keeps decreasing. Running the model for a greater number of iterations can give better results.", "paper_url": "http://arxiv.org/abs/2204.03618v1", "pdf_url": "http://arxiv.org/pdf/2204.03618v1", "repo_url": null}, "2204.03610": {"publish_time": "2022-04-07", "title": "Unified Contrastive Learning in Image-Text-Label Space", "author": "Jianwei Yang et.al.", "abstract": "Visual recognition is recently learned via either supervised learning on human-annotated image-label data or language-image contrastive learning with webly-crawled image-text pairs. While supervised learning may result in a more discriminative representation, language-image pretraining shows unprecedented zero-shot recognition capability, largely due to the different properties of data sources and learning objectives. In this work, we introduce a new formulation by combining the two data sources into a common image-text-label space. In this space, we propose a new learning paradigm, called Unified Contrastive Learning (UniCL) with a single learning objective to seamlessly prompt the synergy of two data types. Extensive experiments show that our UniCL is an effective way of learning semantically rich yet discriminative representations, universally for image recognition in zero-shot, linear-probe, fully finetuning and transfer learning scenarios. Particularly, it attains gains up to 9.2% and 14.5% in average on zero-shot recognition benchmarks over the language-image contrastive learning and supervised learning methods, respectively. In linear probe setting, it also boosts the performance over the two methods by 7.3% and 3.4%, respectively. Our study also indicates that UniCL stand-alone is a good learner on pure image-label data, rivaling the supervised learning methods across three image classification datasets and two types of vision backbones, ResNet and Swin Transformer. Code is available at https://github.com/microsoft/UniCL.", "paper_url": "http://arxiv.org/abs/2204.03610v1", "pdf_url": "http://arxiv.org/pdf/2204.03610v1", "repo_url": "https://github.com/microsoft/unicl"}, "2204.03572": {"publish_time": "2022-04-07", "title": "A Pathology-Based Machine Learning Method to Assist in Epithelial Dysplasia Diagnosis", "author": "Karoline da Rocha et.al.", "abstract": "The Epithelial Dysplasia (ED) is a tissue alteration commonly present in lesions preceding oral cancer, being its presence one of the most important factors in the progression toward carcinoma. This study proposes a method to design a low computational cost classification system to support the detection of dysplastic epithelia, contributing to reduce the variability of pathologist assessments. We employ a multilayer artificial neural network (MLP-ANN) and defining the regions of the epithelium to be assessed based on the knowledge of the pathologist. The performance of the proposed solution was statistically evaluated. The implemented MLP-ANN presented an average accuracy of 87%, with a variability much inferior to that obtained from three trained evaluators. Moreover, the proposed solution led to results which are very close to those obtained using a convolutional neural network (CNN) implemented by transfer learning, with 100 times less computational complexity. In conclusion, our results show that a simple neural network structure can lead to a performance equivalent to that of much more complex structures, which are routinely used in the literature.", "paper_url": "http://arxiv.org/abs/2204.03572v1", "pdf_url": "http://arxiv.org/pdf/2204.03572v1", "repo_url": null}, "2204.03350": {"publish_time": "2022-04-07", "title": "Implementing a Real-Time, YOLOv5 based Social Distancing Measuring System for Covid-19", "author": "Narayana Darapaneni et.al.", "abstract": "The purpose of this work is, to provide a YOLOv5 deep learning-based social distance monitoring framework using an overhead view perspective. In addition, we have developed a custom defined model YOLOv5 modified CSP (Cross Stage Partial Network) and assessed the performance on COCO and Visdrone dataset with and without transfer learning. Our findings show that the developed model successfully identifies the individual who violates the social distances. The accuracy of 81.7% for the modified bottleneck CSP without transfer learning is observed on COCO dataset after training the model for 300 epochs whereas for the same epochs, the default YOLOv5 model is attaining 80.1% accuracy with transfer learning. This shows an improvement in accuracy by our modified bottleneck CSP model. For the Visdrone dataset, we are able to achieve an accuracy of upto 56.5% for certain classes and especially an accuracy of 40% for people and pedestrians with transfer learning using the default YOLOv5s model for 30 epochs. While the modified bottleneck CSP is able to perform slightly better than the default model with an accuracy score of upto 58.1% for certain classes and an accuracy of ~40.4% for people and pedestrians.", "paper_url": "http://arxiv.org/abs/2204.03350v1", "pdf_url": "http://arxiv.org/pdf/2204.03350v1", "repo_url": null}, "2204.03959": {"publish_time": "2022-04-08", "title": "Blockchain as an Enabler for Transfer Learning in Smart Environments", "author": "Amin Anjomshoaa et.al.", "abstract": "The knowledge, embodied in machine learning models for intelligent systems, is commonly associated with time-consuming and costly processes such as large-scale data collection, data labelling, network training, and fine-tuning of models. Sharing and reuse of these elaborated models between intelligent systems deployed in a different environment, which is known as transfer learning, would facilitate the adoption of services for the users and accelerates the uptake of intelligent systems in environments such as smart building and smart city applications. In this context, the communication and knowledge exchange between AI-enabled environments depend on a complicated networks of systems, system of systems, digital assets, and their chain of dependencies that hardly follows the centralized schema of traditional information systems. Rather, it requires an adaptive decentralized system architecture that is empowered by features such as data provenance, workflow transparency, and validation of process participants. In this research, we propose a decentralized and adaptive software framework based on blockchain and knowledge graph technologies that supports the knowledge exchange and interoperability between IoT-enabled environments, in a transparent and trustworthy way.", "paper_url": "http://arxiv.org/abs/2204.03959v1", "pdf_url": "http://arxiv.org/pdf/2204.03959v1", "repo_url": null}, "2204.03934": {"publish_time": "2022-04-08", "title": "Does Robustness on ImageNet Transfer to Downstream Tasks?", "author": "Yutaro Yamada et.al.", "abstract": "As clean ImageNet accuracy nears its ceiling, the research community is increasingly more concerned about robust accuracy under distributional shifts. While a variety of methods have been proposed to robustify neural networks, these techniques often target models trained on ImageNet classification. At the same time, it is a common practice to use ImageNet pretrained backbones for downstream tasks such as object detection, semantic segmentation, and image classification from different domains. This raises a question: Can these robust image classifiers transfer robustness to downstream tasks? For object detection and semantic segmentation, we find that a vanilla Swin Transformer, a variant of Vision Transformer tailored for dense prediction tasks, transfers robustness better than Convolutional Neural Networks that are trained to be robust to the corrupted version of ImageNet. For CIFAR10 classification, we find that models that are robustified for ImageNet do not retain robustness when fully fine-tuned. These findings suggest that current robustification techniques tend to emphasize ImageNet evaluations. Moreover, network architecture is a strong source of robustness when we consider transfer learning.", "paper_url": "http://arxiv.org/abs/2204.03934v1", "pdf_url": "http://arxiv.org/pdf/2204.03934v1", "repo_url": null}, "2204.03831": {"publish_time": "2022-04-08", "title": "Marvelous Agglutinative Language Effect on Cross Lingual Transfer Learning", "author": "Wooyoung Kim et.al.", "abstract": "As for multilingual language models, it is important to select languages for training because of the curse of multilinguality. (Conneau et al., 2020). It is known that using languages with similar language structures is effective for cross lingual transfer learning (Pires et al., 2019). However, we demonstrate that using agglutinative languages such as Korean is more effective in cross lingual transfer learning. This is a great discovery that will change the training strategy of cross lingual transfer learning.", "paper_url": "http://arxiv.org/abs/2204.03831v1", "pdf_url": "http://arxiv.org/pdf/2204.03831v1", "repo_url": null}, "2204.05003": {"publish_time": "2022-04-11", "title": "Local convergence rates of the least squares estimator with applications to transfer learning", "author": "Johannes Schmidt-Hieber et.al.", "abstract": "Convergence properties of empirical risk minimizers can be conveniently expressed in terms of the associated population risk. To derive bounds for the performance of the estimator under covariate shift, however, pointwise convergence rates are required. Under weak assumptions on the design distribution, it is shown that the least squares estimator (LSE) over $1$-Lipschitz functions is also minimax rate optimal with respect to a weighted uniform norm, where the weighting accounts in a natural way for the non-uniformity of the design distribution. This moreover implies that although least squares is a global criterion, the LSE turns out to be locally adaptive. We develop a new indirect proof technique that establishes the local convergence behavior based on a carefully chosen local perturbation of the LSE. These local rates are then used to construct a rate-optimal estimator for transfer learning under covariate shift.", "paper_url": "http://arxiv.org/abs/2204.05003v1", "pdf_url": "http://arxiv.org/pdf/2204.05003v1", "repo_url": null}, "2204.04950": {"publish_time": "2022-04-11", "title": "Commonality in Natural Images Rescues GANs: Pretraining GANs with Generic and Privacy-free Synthetic Data", "author": "Kyungjune Baek et.al.", "abstract": "Transfer learning for GANs successfully improves generation performance under low-shot regimes. However, existing studies show that the pretrained model using a single benchmark dataset is not generalized to various target datasets. More importantly, the pretrained model can be vulnerable to copyright or privacy risks as membership inference attack advances. To resolve both issues, we propose an effective and unbiased data synthesizer, namely Primitives-PS, inspired by the generic characteristics of natural images. Specifically, we utilize 1) the generic statistics on the frequency magnitude spectrum, 2) the elementary shape (i.e., image composition via elementary shapes) for representing the structure information, and 3) the existence of saliency as prior. Since our synthesizer only considers the generic properties of natural images, the single model pretrained on our dataset can be consistently transferred to various target datasets, and even outperforms the previous methods pretrained with the natural images in terms of Fr'echet inception distance. Extensive analysis, ablation study, and evaluations demonstrate that each component of our data synthesizer is effective, and provide insights on the desirable nature of the pretrained model for the transferability of GANs.", "paper_url": "http://arxiv.org/abs/2204.04950v1", "pdf_url": "http://arxiv.org/pdf/2204.04950v1", "repo_url": "https://github.com/friedronaldo/primitives-ps"}, "2204.04837": {"publish_time": "2022-04-11", "title": "Dependable Intrusion Detection System for IoT: A Deep Transfer Learning-based Approach", "author": "Sk. Tanzir Mehedi et.al.", "abstract": "Security concerns for IoT applications have been alarming because of their widespread use in different enterprise systems. The potential threats to these applications are constantly emerging and changing, and therefore, sophisticated and dependable defense solutions are necessary against such threats. With the rapid development of IoT networks and evolving threat types, the traditional machine learning-based IDS must update to cope with the security requirements of the current sustainable IoT environment. In recent years, deep learning, and deep transfer learning have progressed and experienced great success in different fields and have emerged as a potential solution for dependable network intrusion detection. However, new and emerging challenges have arisen related to the accuracy, efficiency, scalability, and dependability of the traditional IDS in a heterogeneous IoT setup. This manuscript proposes a deep transfer learning-based dependable IDS model that outperforms several existing approaches. The unique contributions include effective attribute selection, which is best suited to identify normal and attack scenarios for a small amount of labeled data, designing a dependable deep transfer learning-based ResNet model, and evaluating considering real-world data. To this end, a comprehensive experimental performance evaluation has been conducted. Extensive analysis and performance evaluation show that the proposed model is robust, more efficient, and has demonstrated better performance, ensuring dependability.", "paper_url": "http://arxiv.org/abs/2204.04837v1", "pdf_url": "http://arxiv.org/pdf/2204.04837v1", "repo_url": null}, "2204.04793": {"publish_time": "2022-04-10", "title": "Fake news detection using parallel BERT deep neural networks", "author": "Mahmood Farokhian et.al.", "abstract": "Fake news is a growing challenge for social networks and media. Detection of fake news always has been a problem for many years, but after the evolution of social networks and increasing speed of news dissemination in recent years has been considered again. There are several approaches to solving this problem, one of which is to detect fake news based on its text style using deep neural networks. In recent years, one of the most used forms of deep neural networks for natural language processing is transfer learning with transformers. BERT is one of the most promising transformers who outperforms other models in many NLP benchmarks. This article, we introduce MWPBert, which uses two parallel BERT networks to perform veracity detection on full-text news articles. One of the BERT networks encodes news headline, and another encodes news body. Since the input length of the BERT network is limited and constant and the news body is usually a long text, we cannot fed the whole news text into the BERT. Therefore, using the MaxWorth algorithm, we selected the part of the news text that is more valuable for fact-checking, and fed it into the BERT network. Finally, we encode the output of the two BERT networks to an output network to classify the news. The experiment results showed that the proposed model outperformed previous models in terms of accuracy and other performance measures.", "paper_url": "http://arxiv.org/abs/2204.04793v1", "pdf_url": "http://arxiv.org/pdf/2204.04793v1", "repo_url": null}, "2204.04497": {"publish_time": "2022-04-09", "title": "IDPG: An Instance-Dependent Prompt Generation Method", "author": "Zhuofeng Wu et.al.", "abstract": "Prompt tuning is a new, efficient NLP transfer learning paradigm that adds a task-specific prompt in each input instance during the model training stage. It freezes the pre-trained language model and only optimizes a few task-specific prompts. In this paper, we propose a conditional prompt generation method to generate prompts for each input instance, referred to as the Instance-Dependent Prompt Generation (IDPG). Unlike traditional prompt tuning methods that use a fixed prompt, IDPG introduces a lightweight and trainable component to generate prompts based on each input sentence. Extensive experiments on ten natural language understanding (NLU) tasks show that the proposed strategy consistently outperforms various prompt tuning baselines and is on par with other efficient transfer learning methods such as Compacter while tuning far fewer model parameters.", "paper_url": "http://arxiv.org/abs/2204.04497v1", "pdf_url": "http://arxiv.org/pdf/2204.04497v1", "repo_url": null}, "2204.05432": {"publish_time": "2022-04-11", "title": "A Simple Approach to Adversarial Robustness in Few-shot Image Classification", "author": "Akshayvarun Subramanya et.al.", "abstract": "Few-shot image classification, where the goal is to generalize to tasks with limited labeled data, has seen great progress over the years. However, the classifiers are vulnerable to adversarial examples, posing a question regarding their generalization capabilities. Recent works have tried to combine meta-learning approaches with adversarial training to improve the robustness of few-shot classifiers. We show that a simple transfer-learning based approach can be used to train adversarially robust few-shot classifiers. We also present a method for novel classification task based on calibrating the centroid of the few-shot category towards the base classes. We show that standard adversarial training on base categories along with calibrated centroid-based classifier in the novel categories, outperforms or is on-par with state-of-the-art advanced methods on standard benchmarks for few-shot learning. Our method is simple, easy to scale, and with little effort can lead to robust few-shot classifiers. Code is available here: \\url{https://github.com/UCDvision/Simple_few_shot.git}", "paper_url": "http://arxiv.org/abs/2204.05432v1", "pdf_url": "http://arxiv.org/pdf/2204.05432v1", "repo_url": null}, "2204.05400": {"publish_time": "2022-04-11", "title": "Transfer Learning for Autonomous Chatter Detection in Machining", "author": "Melih C. Yesilli et.al.", "abstract": "Large-amplitude chatter vibrations are one of the most important phenomena in machining processes. It is often detrimental in cutting operations causing a poor surface finish and decreased tool life. Therefore, chatter detection using machine learning has been an active research area over the last decade. Three challenges can be identified in applying machine learning for chatter detection at large in industry: an insufficient understanding of the universality of chatter features across different processes, the need for automating feature extraction, and the existence of limited data for each specific workpiece-machine tool combination. These three challenges can be grouped under the umbrella of transfer learning. This paper studies automating chatter detection by evaluating transfer learning of prominent as well as novel chatter detection methods. We investigate chatter classification accuracy using a variety of features extracted from turning and milling experiments with different cutting configurations. The studied methods include Fast Fourier Transform (FFT), Power Spectral Density (PSD), the Auto-correlation Function (ACF), Wavelet Packet Transform (WPT), and Ensemble Empirical Mode Decomposition (EEMD). We also examine more recent approaches based on Topological Data Analysis (TDA) and similarity measures of time series based on Discrete Time Warping (DTW). We evaluate the transfer learning potential of each approach by training and testing both within and across the turning and milling data sets. Our results show that carefully chosen time-frequency features can lead to high classification accuracies albeit at the cost of requiring manual pre-processing and the tagging of an expert user. On the other hand, we found that the TDA and DTW approaches can provide accuracies and F1 scores on par with the time-frequency methods without the need for manual preprocessing.", "paper_url": "http://arxiv.org/abs/2204.05400v1", "pdf_url": "http://arxiv.org/pdf/2204.05400v1", "repo_url": null}, "2204.06487": {"publish_time": "2022-04-13", "title": "Multilingual Language Model Adaptive Fine-Tuning: A Study on African Languages", "author": "Jesujoba O. Alabi et.al.", "abstract": "Multilingual pre-trained language models (PLMs) have demonstrated impressive performance on several downstream tasks on both high resourced and low-resourced languages. However, there is still a large performance drop for languages unseen during pre-training, especially African languages. One of the most effective approaches to adapt to a new language is language adaptive fine-tuning (LAFT) -- fine-tuning a multilingual PLM on monolingual texts of a language using the same pre-training objective. However, African languages with large monolingual texts are few, and adapting to each of them individually takes large disk space and limits the cross-lingual transfer abilities of the resulting models because they have been specialized for a single language. In this paper, we perform multilingual adaptive fine-tuning (MAFT) on 17 most-resourced African languages and three other high-resource languages widely spoken on the African continent -- English, French, and Arabic to encourage cross-lingual transfer learning. Additionally, to further specialize the multilingual PLM, we removed vocabulary tokens from the embedding layer that corresponds to non-African writing scripts before MAFT, thus reducing the model size by around 50\\%. Our evaluation on two multilingual PLMs (AfriBERTa and XLM-R) and three NLP tasks (NER, news topic classification, and sentiment classification) shows that our approach is competitive to applying LAFT on individual languages while requiring significantly less disk space. Finally, we show that our adapted PLM also improves the zero-shot cross-lingual transfer abilities of parameter efficient fine-tuning methods.", "paper_url": "http://arxiv.org/abs/2204.06487v1", "pdf_url": "http://arxiv.org/pdf/2204.06487v1", "repo_url": null}, "2204.06343": {"publish_time": "2022-04-13", "title": "Single-grasp deformable object discrimination: the effect of gripper morphology, sensing modalities, and action parameters", "author": "Michal Pliska et.al.", "abstract": "We studied the discrimination of deformable objects by grasping them using 4 different robot hands / grippers: Barrett hand (3 fingers with adjustable configuration, 96 tactile, 8 position, 3 torque sensors), qb SoftHand (5 fingers, 1 motor, position and current feedback), and two industrial type parallel jaw grippers with position and effort feedback (Robotiq 2F-85 and OnRobot RG6). A set of 9 ordinary objects differing in size and stiffness and another highly challenging set of 20 polyurethane foams differing in material properties only was used. We systematically compare the grippers' performance, together with the effects of: (1) type of classifier (k-NN, SVM, LSTM) operating on raw time series or on features, (2) action parameters (grasping configuration and speed of squeezing), (3) contribution of sensory modalities. Classification results are complemented by visualization of the data using PCA. We found: (i) all the grippers but the qb SoftHand could reliably distinguish the ordinary objects set; (ii) Barrett Hand reached around 95% accuracy on the foams; OnRobot RG6 around 75% and Robotiq 2F-85 around 70%; (iii) across all grippers, SVM over features and LSTM on raw time series performed best; (iv) faster compression speeds degrade classification performance; (v) transfer learning between compression speeds worked well for the Barrett Hand only; transfer between grasping configurations is limited; (vi) ablation experiments provided intriguing insights -- sometimes a single sensory channel suffices for discrimination. Overall, the Barrett Hand as a complex and expensive device with rich sensory feedback provided best results, but uncalibrated parallel jaw grippers without tactile sensors can have sufficient performance for single-grasp object discrimination based on position and effort data only. Transfer learning between the different robot hands remains a challenge.", "paper_url": "http://arxiv.org/abs/2204.06343v1", "pdf_url": "http://arxiv.org/pdf/2204.06343v1", "repo_url": null}, "2204.07118": {"publish_time": "2022-04-14", "title": "DeiT III: Revenge of the ViT", "author": "Hugo Touvron et.al.", "abstract": "A Vision Transformer (ViT) is a simple neural architecture amenable to serve several computer vision tasks. It has limited built-in architectural priors, in contrast to more recent architectures that incorporate priors either about the input data or of specific tasks. Recent works show that ViTs benefit from self-supervised pre-training, in particular BerT-like pre-training like BeiT. In this paper, we revisit the supervised training of ViTs. Our procedure builds upon and simplifies a recipe introduced for training ResNet-50. It includes a new simple data-augmentation procedure with only 3 augmentations, closer to the practice in self-supervised learning. Our evaluations on Image classification (ImageNet-1k with and without pre-training on ImageNet-21k), transfer learning and semantic segmentation show that our procedure outperforms by a large margin previous fully supervised training recipes for ViT. It also reveals that the performance of our ViT trained with supervision is comparable to that of more recent architectures. Our results could serve as better baselines for recent self-supervised approaches demonstrated on ViT.", "paper_url": "http://arxiv.org/abs/2204.07118v1", "pdf_url": "http://arxiv.org/pdf/2204.07118v1", "repo_url": null}, "2204.07082": {"publish_time": "2022-04-14", "title": "Dialogue Strategy Adaptation to New Action Sets Using Multi-dimensional Modelling", "author": "Simon Keizer et.al.", "abstract": "A major bottleneck for building statistical spoken dialogue systems for new domains and applications is the need for large amounts of training data. To address this problem, we adopt the multi-dimensional approach to dialogue management and evaluate its potential for transfer learning. Specifically, we exploit pre-trained task-independent policies to speed up training for an extended task-specific action set, in which the single summary action for requesting a slot is replaced by multiple slot-specific request actions. Policy optimisation and evaluation experiments using an agenda-based user simulator show that with limited training data, much better performance levels can be achieved when using the proposed multi-dimensional adaptation method. We confirm this improvement in a crowd-sourced human user evaluation of our spoken dialogue system, comparing partially trained policies. The multi-dimensional system (with adaptation on limited training data in the target scenario) outperforms the one-dimensional baseline (without adaptation on the same amount of training data) by 7% perceived success rate.", "paper_url": "http://arxiv.org/abs/2204.07082v1", "pdf_url": "http://arxiv.org/pdf/2204.07082v1", "repo_url": null}, "2204.06846": {"publish_time": "2022-04-14", "title": "OmniPD: One-Step Person Detection in Top-View Omnidirectional Indoor Scenes", "author": "Jingrui Yu et.al.", "abstract": "We propose a one-step person detector for topview omnidirectional indoor scenes based on convolutional neural networks (CNNs). While state of the art person detectors reach competitive results on perspective images, missing CNN architectures as well as training data that follows the distortion of omnidirectional images makes current approaches not applicable to our data. The method predicts bounding boxes of multiple persons directly in omnidirectional images without perspective transformation, which reduces overhead of pre- and post-processing and enables real-time performance. The basic idea is to utilize transfer learning to fine-tune CNNs trained on perspective images with data augmentation techniques for detection in omnidirectional images. We fine-tune two variants of Single Shot MultiBox detectors (SSDs). The first one uses Mobilenet v1 FPN as feature extractor (moSSD). The second one uses ResNet50 v1 FPN (resSSD). Both models are pre-trained on Microsoft Common Objects in Context (COCO) dataset. We fine-tune both models on PASCAL VOC07 and VOC12 datasets, specifically on class person. Random 90-degree rotation and random vertical flipping are used for data augmentation in addition to the methods proposed by original SSD. We reach an average precision (AP) of 67.3 % with moSSD and 74.9 % with resSSD onthe evaluation dataset. To enhance the fine-tuning process, we add a subset of HDA Person dataset and a subset of PIROPOdatabase and reduce the number of perspective images to PASCAL VOC07. The AP rises to 83.2 % for moSSD and 86.3 % for resSSD, respectively. The average inference speed is 28 ms per image for moSSD and 38 ms per image for resSSD using Nvidia Quadro P6000. Our method is applicable to other CNN-based object detectors and can potentially generalize for detecting other objects in omnidirectional images.", "paper_url": "http://arxiv.org/abs/2204.06846v1", "pdf_url": "http://arxiv.org/pdf/2204.06846v1", "repo_url": null}, "2204.06614": {"publish_time": "2022-04-13", "title": "Accurate Clinical Toxicity Prediction using Multi-task Deep Neural Nets and Contrastive Molecular Explanations", "author": "Bhanushee Sharma et.al.", "abstract": "Explainable ML for molecular toxicity prediction is a promising approach for efficient drug development and chemical safety. A predictive ML model of toxicity can reduce experimental cost and time while mitigating ethical concerns by significantly reducing animal and clinical testing. Herein, we use a deep learning framework for simultaneously modeling in vitro, in vivo, and clinical toxicity data. Two different molecular input representations are used: Morgan fingerprints and pre-training SMILES embeddings. A multi-task deep learning model accurately predicts toxicity for all endpoints, including clinical, as indicated by AUROC and balanced accuracy. In particular, SMILES embeddings as input to the multi-task model improved clinical toxicity predictions compared to existing models in MoleculeNet benchmark. Additionally, our multi-task approach is comprehensive in the sense that it is comparable to state-of-the-art approaches for specific endpoints in in vitro, in vivo and clinical platforms. Through both the multi-task model and transfer learning, we were able to indicate the minimal need of in vivo data for clinical toxicity predictions. To provide confidence and explain the model's predictions, we adapt a post-hoc contrastive explanation method that returns pertinent positive and pertinent negative features, which correspond well to known mutagenic and reactive toxicophores, such as unsubstituted bonded heteroatoms, aromatic amines, and Michael receptors. Furthermore, toxicophore recovery by pertinent feature analysis captures more of the in vitro (53%) and in vivo (56%), rather than of the clinical (8%), endpoints, and indeed uncovers a preference in known toxicophore data towards in vitro and in vivo experimental data. To our knowledge, this is the first contrastive explanation, using both present and absent substructures, for predictions of clinical and in vivo molecular toxicity.", "paper_url": "http://arxiv.org/abs/2204.06614v1", "pdf_url": "http://arxiv.org/pdf/2204.06614v1", "repo_url": "https://github.com/IBM/Contrastive-Explanation-Method"}, "2204.07437": {"publish_time": "2022-04-15", "title": "Transfer Learning for Instance Segmentation of Waste Bottles using Mask R-CNN Algorithm", "author": "Punitha Jaikumar et.al.", "abstract": "This paper proposes a methodological approach with a transfer learning scheme for plastic waste bottle detection and instance segmentation using the \\textit{mask region proposal convolutional neural network} (Mask R-CNN). Plastic bottles constitute one of the major pollutants posing a serious threat to the environment both in oceans and on land. The automated identification and segregation of bottles can facilitate plastic waste recycling. We prepare a custom-made dataset of 192 bottle images with pixel-by pixel-polygon annotation for the automatic segmentation task. The proposed transfer learning scheme makes use of a Mask R-CNN model pre-trained on the Microsoft COCO dataset. We present a comprehensive scheme for fine-tuning the base pre-trained Mask-RCNN model on our custom dataset. Our final fine-tuned model has achieved 59.4 \\textit{mean average precision} (mAP), which corresponds to the MS COCO metric. The results indicate a promising application of deep learning for detecting waste bottles.", "paper_url": "http://arxiv.org/abs/2204.07437v1", "pdf_url": "http://arxiv.org/pdf/2204.07437v1", "repo_url": null}, "2204.07305": {"publish_time": "2022-04-15", "title": "Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference", "author": "Shell Xu Hu et.al.", "abstract": "Few-shot learning (FSL) is an important and topical problem in computer vision that has motivated extensive research into numerous methods spanning from sophisticated meta-learning methods to simple transfer learning baselines. We seek to push the limits of a simple-but-effective pipeline for more realistic and practical settings of few-shot image classification. To this end, we explore few-shot learning from the perspective of neural network architecture, as well as a three stage pipeline of network updates under different data supplies, where unsupervised external data is considered for pre-training, base categories are used to simulate few-shot tasks for meta-training, and the scarcely labelled data of an novel task is taken for fine-tuning. We investigate questions such as: (1) How pre-training on external data benefits FSL? (2) How state-of-the-art transformer architectures can be exploited? and (3) How fine-tuning mitigates domain shift? Ultimately, we show that a simple transformer-based pipeline yields surprisingly good performance on standard benchmarks such as Mini-ImageNet, CIFAR-FS, CDFSL and Meta-Dataset. Our code and demo are available at https://hushell.github.io/pmf.", "paper_url": "http://arxiv.org/abs/2204.07305v1", "pdf_url": "http://arxiv.org/pdf/2204.07305v1", "repo_url": null}, "2204.07246": {"publish_time": "2022-04-14", "title": "Robotic and Generative Adversarial Attacks in Offline Writer-independent Signature Verification", "author": "Jordan J. Bird et.al.", "abstract": "This study explores how robots and generative approaches can be used to mount successful false-acceptance adversarial attacks on signature verification systems. Initially, a convolutional neural network topology and data augmentation strategy are explored and tuned, producing an 87.12% accurate model for the verification of 2,640 human signatures. Two robots are then tasked with forging 50 signatures, where 25 are used for the verification attack, and the remaining 25 are used for tuning of the model to defend against them. Adversarial attacks on the system show that there exists an information security risk; the Line-us robotic arm can fool the system 24% of the time and the iDraw 2.0 robot 32% of the time. A conditional GAN finds similar success, with around 30% forged signatures misclassified as genuine. Following fine-tune transfer learning of robotic and generative data, adversarial attacks are reduced below the model threshold by both robots and the GAN. It is observed that tuning the model reduces the risk of attack by robots to 8% and 12%, and that conditional generative adversarial attacks can be reduced to 4% when 25 images are presented and 5% when 1000 images are presented.", "paper_url": "http://arxiv.org/abs/2204.07246v1", "pdf_url": "http://arxiv.org/pdf/2204.07246v1", "repo_url": null}, "2204.08324": {"publish_time": "2022-04-18", "title": "Hierarchical Optimal Transport for Comparing Histopathology Datasets", "author": "Anna Yeaton et.al.", "abstract": "Scarcity of labeled histopathology data limits the applicability of deep learning methods to under-profiled cancer types and labels. Transfer learning allows researchers to overcome the limitations of small datasets by pre-training machine learning models on larger datasets similar to the small target dataset. However, similarity between datasets is often determined heuristically. In this paper, we propose a principled notion of distance between histopathology datasets based on a hierarchical generalization of optimal transport distances. Our method does not require any training, is agnostic to model type, and preserves much of the hierarchical structure in histopathology datasets imposed by tiling. We apply our method to H&E stained slides from The Cancer Genome Atlas from six different cancer types. We show that our method outperforms a baseline distance in a cancer-type prediction task. Our results also show that our optimal transport distance predicts difficulty of transferability in a tumor vs.normal prediction setting.", "paper_url": "http://arxiv.org/abs/2204.08324v2", "pdf_url": "http://arxiv.org/pdf/2204.08324v2", "repo_url": null}, "2204.08311": {"publish_time": "2022-04-18", "title": "Application of Transfer Learning and Ensemble Learning in Image-level Classification for Breast Histopathology", "author": "Yuchao Zheng et.al.", "abstract": "Background: Breast cancer has the highest prevalence in women globally. The classification and diagnosis of breast cancer and its histopathological images have always been a hot spot of clinical concern. In Computer-Aided Diagnosis (CAD), traditional classification models mostly use a single network to extract features, which has significant limitations. On the other hand, many networks are trained and optimized on patient-level datasets, ignoring the application of lower-level data labels.   Method: This paper proposes a deep ensemble model based on image-level labels for the binary classification of benign and malignant lesions of breast histopathological images. First, the BreakHis dataset is randomly divided into a training, validation and test set. Then, data augmentation techniques are used to balance the number of benign and malignant samples. Thirdly, considering the performance of transfer learning and the complementarity between each network, VGG-16, Xception, Resnet-50, DenseNet-201 are selected as the base classifiers.   Result: In the ensemble network model with accuracy as the weight, the image-level binary classification achieves an accuracy of $98.90\\%$. In order to verify the capabilities of our method, the latest Transformer and Multilayer Perception (MLP) models have been experimentally compared on the same dataset. Our model wins with a $5\\%-20\\%$ advantage, emphasizing the ensemble model's far-reaching significance in classification tasks.   Conclusion: This research focuses on improving the model's classification performance with an ensemble algorithm. Transfer learning plays an essential role in small datasets, improving training speed and accuracy. Our model has outperformed many existing approaches in accuracy, providing a method for the field of auxiliary medical diagnosis.", "paper_url": "http://arxiv.org/abs/2204.08311v1", "pdf_url": "http://arxiv.org/pdf/2204.08311v1", "repo_url": null}, "2204.08102": {"publish_time": "2022-04-17", "title": "kpfriends at SemEval-2022 Task 2: NEAMER -- Named Entity Augmented Multi-word Expression Recognizer", "author": "Min Sik Oh et.al.", "abstract": "We present NEAMER -- Named Entity Augmented Multi-word Expression Recognizer. This system is inspired by non-compositionality characteristics shared between Named Entity and Idiomatic Expressions. We utilize transfer learning and locality features to enhance idiom classification task. This system is our submission for SemEval Task 2: Multilingual Idiomaticity Detection and Sentence Embedding Subtask A OneShot shared task. We achieve SOTA with F1 0.9395 during post-evaluation phase. We also observe improvement in training stability. Lastly, we experiment with non-compositionality knowledge transfer, cross-lingual fine-tuning and locality features, which we also introduce in this paper.", "paper_url": "http://arxiv.org/abs/2204.08102v1", "pdf_url": "http://arxiv.org/pdf/2204.08102v1", "repo_url": null}, "2204.07942": {"publish_time": "2022-04-17", "title": "Wound Severity Classification using Deep Neural Network", "author": "D. M. Anisuzzaman et.al.", "abstract": "The classification of wound severity is a critical step in wound diagnosis. An effective classifier can help wound professionals categorize wound conditions more quickly and affordably, allowing them to choose the best treatment option. This study used wound photos to construct a deep neural network-based wound severity classifier that classified them into one of three classes: green, yellow, or red. The green class denotes wounds still in the early stages of healing and are most likely to recover with adequate care. Wounds in the yellow category require more attention and treatment than those in the green category. Finally, the red class denotes the most severe wounds that require prompt attention and treatment. A dataset containing different types of wound images is designed with the help of wound specialists. Nine deep learning models are used with applying the concept of transfer learning. Several stacked models are also developed by concatenating these transfer learning models. The maximum accuracy achieved on multi-class classification is 68.49%. In addition, we achieved 78.79%, 81.40%, and 77.57% accuracies on green vs. yellow, green vs. red, and yellow vs. red classifications for binary classifications.", "paper_url": "http://arxiv.org/abs/2204.07942v1", "pdf_url": "http://arxiv.org/pdf/2204.07942v1", "repo_url": null}, "2204.07848": {"publish_time": "2022-04-16", "title": "STRATA: Word Boundaries & Phoneme Recognition From Continuous Urdu Speech using Transfer Learning, Attention, & Data Augmentation", "author": "Saad Naeem et.al.", "abstract": "Phoneme recognition is a largely unsolved problem in NLP, especially for low-resource languages like Urdu. The systems that try to extract the phonemes from audio speech require hand-labeled phonetic transcriptions. This requires expert linguists to annotate speech data with its relevant phonetic representation which is both an expensive and a tedious task. In this paper, we propose STRATA, a framework for supervised phoneme recognition that overcomes the data scarcity issue for low resource languages using a seq2seq neural architecture integrated with transfer learning, attention mechanism, and data augmentation. STRATA employs transfer learning to reduce the network loss in half. It uses attention mechanism for word boundaries and frame alignment detection which further reduces the network loss by 4% and is able to identify the word boundaries with 92.2% accuracy. STRATA uses various data augmentation techniques to further reduce the loss by 1.5% and is more robust towards new signals both in terms of generalization and accuracy. STRATA is able to achieve a Phoneme Error Rate of 16.5% and improves upon the state of the art by 1.1% for TIMIT dataset (English) and 11.5% for CSaLT dataset (Urdu).", "paper_url": "http://arxiv.org/abs/2204.07848v1", "pdf_url": "http://arxiv.org/pdf/2204.07848v1", "repo_url": null}, "2204.08478": {"publish_time": "2022-04-18", "title": "Enhancing Non-mass Breast Ultrasound Cancer Classification With Knowledge Transfer", "author": "Yangrun Hu et.al.", "abstract": "Much progress has been made in the deep neural network (DNN) based diagnosis of mass lesions breast ultrasound (BUS) images. However, the non-mass lesion is less investigated because of the limited data. Based on the insight that mass data is sufficient and shares the same knowledge structure with non-mass data of identifying the malignancy of a lesion based on the ultrasound image, we propose a novel transfer learning framework to enhance the generalizability of the DNN model for non-mass BUS with the help of mass BUS. Specifically, we train a shared DNN with combined non-mass and mass data. With the prior of different marginal distributions in input and output space, we employ two domain alignment strategies in the proposed transfer learning framework with the insight of capturing domain-specific distribution to address the issue of domain shift. Moreover, we propose a cross-domain semantic-preserve data generation module called CrossMix to recover the missing distribution between non-mass and mass data that is not presented in training data. Experimental results on an in-house dataset demonstrate that the DNN model trained with combined data by our framework achieves a 10% improvement in AUC on the malignancy prediction task of non-mass BUS compared to training directly on non-mass data.", "paper_url": "http://arxiv.org/abs/2204.08478v1", "pdf_url": "http://arxiv.org/pdf/2204.08478v1", "repo_url": null}, "2204.09368": {"publish_time": "2022-04-20", "title": "BugListener: Identifying and Synthesizing Bug Reports from Collaborative Live Chats", "author": "Lin Shi et.al.", "abstract": "In community-based software development, developers frequently rely on live-chatting to discuss emergent bugs/errors they encounter in daily development tasks. However, it remains a challenging task to accurately record such knowledge due to the noisy nature of interleaved dialogs in live chat data. In this paper, we first formulate the task of identifying and synthesizing bug reports from community live chats, and propose a novel approach, named BugListener, to address the challenges. Specifically, BugListener automates three sub-tasks: 1) Disentangle the dialogs from massive chat logs by using a Feed-Forward neural network; 2) Identify the bug-report dialogs from separated dialogs by modeling the original dialog to the graph-structured dialog and leveraging the graph neural network to learn the contextual information; 3) Synthesize the bug reports by utilizing the TextCNN model and Transfer Learning network to classify the sentences into three groups: observed behaviors (OB), expected behaviors (EB), and steps to reproduce the bug (SR). BugListener is evaluated on six open source projects. The results show that: for bug report identification, BugListener achieves the average F1 of 74.21%, improving the best baseline by 10.37%; and for bug report synthesis task, BugListener could classify the OB, EB, and SR sentences with the F1 of 67.37%, 87.14%, and 65.03%, improving the best baselines by 7.21%, 7.38%, 5.30%, respectively. A human evaluation also confirms the effectiveness of BugListener in generating relevant and accurate bug reports. These demonstrate the significant potential of applying BugListener in community-based software development, for promoting bug discovery and quality improvement.", "paper_url": "http://arxiv.org/abs/2204.09368v1", "pdf_url": "http://arxiv.org/pdf/2204.09368v1", "repo_url": "https://github.com/buglistener/buglistener2022"}, "2204.09323": {"publish_time": "2022-04-20", "title": "Self-supervised Learning for Sonar Image Classification", "author": "Alan Preciado-Grijalva et.al.", "abstract": "Self-supervised learning has proved to be a powerful approach to learn image representations without the need of large labeled datasets. For underwater robotics, it is of great interest to design computer vision algorithms to improve perception capabilities such as sonar image classification. Due to the confidential nature of sonar imaging and the difficulty to interpret sonar images, it is challenging to create public large labeled sonar datasets to train supervised learning algorithms. In this work, we investigate the potential of three self-supervised learning methods (RotNet, Denoising Autoencoders, and Jigsaw) to learn high-quality sonar image representation without the need of human labels. We present pre-training and transfer learning results on real-life sonar image datasets. Our results indicate that self-supervised pre-training yields classification performance comparable to supervised pre-training in a few-shot transfer learning setup across all three methods. Code and self-supervised pre-trained models are be available at https://github.com/agrija9/ssl-sonar-images", "paper_url": "http://arxiv.org/abs/2204.09323v1", "pdf_url": "http://arxiv.org/pdf/2204.09323v1", "repo_url": "https://github.com/agrija9/ssl-sonar-images"}, "2204.09222": {"publish_time": "2022-04-20", "title": "K-LITE: Learning Transferable Visual Models with External Knowledge", "author": "Sheng Shen et.al.", "abstract": "Recent state-of-the-art computer vision systems are trained from natural language supervision, ranging from simple object category names to descriptive captions. This free form of supervision ensures high generality and usability of the learned visual models, based on extensive heuristics on data collection to cover as many visual concepts as possible. Alternatively, learning with external knowledge about images is a promising way which leverages a much more structured source of supervision. In this paper, we propose K-LITE (Knowledge-augmented Language-Image Training and Evaluation), a simple strategy to leverage external knowledge to build transferable visual systems: In training, it enriches entities in natural language with WordNet and Wiktionary knowledge, leading to an efficient and scalable approach to learning image representations that can understand both visual concepts and their knowledge; In evaluation, the natural language is also augmented with external knowledge and then used to reference learned visual concepts (or describe new ones) to enable zero-shot and few-shot transfer of the pre-trained models. We study the performance of K-LITE on two important computer vision problems, image classification and object detection, benchmarking on 20 and 13 different existing datasets, respectively. The proposed knowledge-augmented models show significant improvement in transfer learning performance over existing methods.", "paper_url": "http://arxiv.org/abs/2204.09222v1", "pdf_url": "http://arxiv.org/pdf/2204.09222v1", "repo_url": null}, "2204.09924": {"publish_time": "2022-04-21", "title": "Progressive Training of A Two-Stage Framework for Video Restoration", "author": "Meisong Zheng et.al.", "abstract": "As a widely studied task, video restoration aims to enhance the quality of the videos with multiple potential degradations, such as noises, blurs and compression artifacts. Among video restorations, compressed video quality enhancement and video super-resolution are two of the main tacks with significant values in practical scenarios. Recently, recurrent neural networks and transformers attract increasing research interests in this field, due to their impressive capability in sequence-to-sequence modeling. However, the training of these models is not only costly but also relatively hard to converge, with gradient exploding and vanishing problems. To cope with these problems, we proposed a two-stage framework including a multi-frame recurrent network and a single-frame transformer. Besides, multiple training strategies, such as transfer learning and progressive training, are developed to shorten the training time and improve the model performance. Benefiting from the above technical contributions, our solution wins two champions and a runner-up in the NTIRE 2022 super-resolution and quality enhancement of compressed video challenges.", "paper_url": "http://arxiv.org/abs/2204.09924v1", "pdf_url": "http://arxiv.org/pdf/2204.09924v1", "repo_url": null}, "2204.09810": {"publish_time": "2022-04-20", "title": "Deep transfer learning for partial differential equations under conditional shift with DeepONet", "author": "Somdatta Goswami et.al.", "abstract": "Traditional machine learning algorithms are designed to learn in isolation, i.e. address single tasks. The core idea of transfer learning (TL) is that knowledge gained in learning to perform one task (source) can be leveraged to improve learning performance in a related, but different, task (target). TL leverages and transfers previously acquired knowledge to address the expense of data acquisition and labeling, potential computational power limitations, and the dataset distribution mismatches. Although significant progress has been made in the fields of image processing, speech recognition, and natural language processing (for classification and regression) for TL, little work has been done in the field of scientific machine learning for functional regression and uncertainty quantification in partial differential equations. In this work, we propose a novel TL framework for task-specific learning under conditional shift with a deep operator network (DeepONet). Inspired by the conditional embedding operator theory, we measure the statistical distance between the source domain and the target feature domain by embedding conditional distributions onto a reproducing kernel Hilbert space. Task-specific operator learning is accomplished by fine-tuning task-specific layers of the target DeepONet using a hybrid loss function that allows for the matching of individual target samples while also preserving the global properties of the conditional distribution of target data. We demonstrate the advantages of our approach for various TL scenarios involving nonlinear PDEs under conditional shift. Our results include geometry domain adaptation and show that the proposed TL framework enables fast and efficient multi-task operator learning, despite significant differences between the source and target domains.", "paper_url": "http://arxiv.org/abs/2204.09810v1", "pdf_url": "http://arxiv.org/pdf/2204.09810v1", "repo_url": null}, "2204.10841": {"publish_time": "2022-04-22", "title": "Detecting early signs of depression in the conversational domain: The role of transfer learning in low-resource scenarios", "author": "Petr Lorenc et.al.", "abstract": "The high prevalence of depression in society has given rise to the need for new digital tools to assist in its early detection. To this end, existing research has mainly focused on detecting depression in the domain of social media, where there is a sufficient amount of data. However, with the rise of conversational agents like Siri or Alexa, the conversational domain is becoming more critical. Unfortunately, there is a lack of data in the conversational domain. We perform a study focusing on domain adaptation from social media to the conversational domain. Our approach mainly exploits the linguistic information preserved in the vector representation of text. We describe transfer learning techniques to classify users who suffer from early signs of depression with high recall. We achieve state-of-the-art results on a commonly used conversational dataset, and we highlight how the method can easily be used in conversational agents. We publicly release all source code.", "paper_url": "http://arxiv.org/abs/2204.10841v1", "pdf_url": "http://arxiv.org/pdf/2204.10841v1", "repo_url": "https://github.com/petrlorenc/mental-health"}, "2204.11667": {"publish_time": "2022-04-25", "title": "Multi-Head Distillation for Continual Unsupervised Domain Adaptation in Semantic Segmentation", "author": "Antoine Saporta et.al.", "abstract": "Unsupervised Domain Adaptation (UDA) is a transfer learning task which aims at training on an unlabeled target domain by leveraging a labeled source domain. Beyond the traditional scope of UDA with a single source domain and a single target domain, real-world perception systems face a variety of scenarios to handle, from varying lighting conditions to many cities around the world. In this context, UDAs with several domains increase the challenges with the addition of distribution shifts within the different target domains. This work focuses on a novel framework for learning UDA, continuous UDA, in which models operate on multiple target domains discovered sequentially, without access to previous target domains. We propose MuHDi, for Multi-Head Distillation, a method that solves the catastrophic forgetting problem, inherent in continual learning tasks. MuHDi performs distillation at multiple levels from the previous model as well as an auxiliary target-specialist segmentation head. We report both extensive ablation and experiments on challenging multi-target UDA semantic segmentation benchmarks to validate the proposed learning scheme and architecture.", "paper_url": "http://arxiv.org/abs/2204.11667v1", "pdf_url": "http://arxiv.org/pdf/2204.11667v1", "repo_url": null}, "2204.11420": {"publish_time": "2022-04-25", "title": "Audio-Visual Scene Classification Using A Transfer Learning Based Joint Optimization Strategy", "author": "Chengxin Chen et.al.", "abstract": "Recently, audio-visual scene classification (AVSC) has attracted increasing attention from multidisciplinary communities. Previous studies tended to adopt a pipeline training strategy, which uses well-trained visual and acoustic encoders to extract high-level representations (embeddings) first, then utilizes them to train the audio-visual classifier. In this way, the extracted embeddings are well suited for uni-modal classifiers, but not necessarily suited for multi-modal ones. In this paper, we propose a joint training framework, using the acoustic features and raw images directly as inputs for the AVSC task. Specifically, we retrieve the bottom layers of pre-trained image models as visual encoder, and jointly optimize the scene classifier and 1D-CNN based acoustic encoder during training. We evaluate the approach on the development dataset of TAU Urban Audio-Visual Scenes 2021. The experimental results show that our proposed approach achieves significant improvement over the conventional pipeline training strategy. Moreover, our best single system outperforms previous state-of-the-art methods, yielding a log loss of 0.1517 and accuracy of 94.59% on the official test fold.", "paper_url": "http://arxiv.org/abs/2204.11420v1", "pdf_url": "http://arxiv.org/pdf/2204.11420v1", "repo_url": null}, "2204.11218": {"publish_time": "2022-04-24", "title": "Learning to Win Lottery Tickets in BERT Transfer via Task-agnostic Mask Training", "author": "Yuanxin Liu et.al.", "abstract": "Recent studies on the lottery ticket hypothesis (LTH) show that pre-trained language models (PLMs) like BERT contain matching subnetworks that have similar transfer learning performance as the original PLM. These subnetworks are found using magnitude-based pruning. In this paper, we find that the BERT subnetworks have even more potential than these studies have shown. Firstly, we discover that the success of magnitude pruning can be attributed to the preserved pre-training performance, which correlates with the downstream transferability. Inspired by this, we propose to directly optimize the subnetwork structure towards the pre-training objectives, which can better preserve the pre-training performance. Specifically, we train binary masks over model weights on the pre-training tasks, with the aim of preserving the universal transferability of the subnetwork, which is agnostic to any specific downstream tasks. We then fine-tune the subnetworks on the GLUE benchmark and the SQuAD dataset. The results show that, compared with magnitude pruning, mask training can effectively find BERT subnetworks with improved overall performance on downstream tasks. Moreover, our method is also more efficient in searching subnetworks and more advantageous when fine-tuning within a certain range of data scarcity. Our code is available at https://github.com/llyx97/TAMT.", "paper_url": "http://arxiv.org/abs/2204.11218v1", "pdf_url": "http://arxiv.org/pdf/2204.11218v1", "repo_url": "https://github.com/llyx97/TAMT"}, "2204.11138": {"publish_time": "2022-04-23", "title": "Use of Multifidelity Training Data and Transfer Learning for Efficient Construction of Subsurface Flow Surrogate Models", "author": "Su Jiang et.al.", "abstract": "Data assimilation presents computational challenges because many high-fidelity models must be simulated. Various deep-learning-based surrogate modeling techniques have been developed to reduce the simulation costs associated with these applications. However, to construct data-driven surrogate models, several thousand high-fidelity simulation runs may be required to provide training samples, and these computations can make training prohibitively expensive. To address this issue, in this work we present a framework where most of the training simulations are performed on coarsened geomodels. These models are constructed using a flow-based upscaling method. The framework entails the use of a transfer-learning procedure, incorporated within an existing recurrent residual U-Net architecture, in which network training is accomplished in three steps. In the first step. where the bulk of the training is performed, only low-fidelity simulation results are used. The second and third steps, in which the output layer is trained and the overall network is fine-tuned, require a relatively small number of high-fidelity simulations. Here we use 2500 low-fidelity runs and 200 high-fidelity runs, which leads to about a 90% reduction in training simulation costs. The method is applied for two-phase subsurface flow in 3D channelized systems, with flow driven by wells. The surrogate model trained with multifidelity data is shown to be nearly as accurate as a reference surrogate trained with only high-fidelity data in predicting dynamic pressure and saturation fields in new geomodels. Importantly, the network provides results that are significantly more accurate than the low-fidelity simulations used for most of the training. The multifidelity surrogate is also applied for history matching using an ensemble-based procedure, where accuracy relative to reference results is again demonstrated.", "paper_url": "http://arxiv.org/abs/2204.11138v1", "pdf_url": "http://arxiv.org/pdf/2204.11138v1", "repo_url": null}, "2204.11075": {"publish_time": "2022-04-23", "title": "Smart App Attack: Hacking Deep Learning Models in Android Apps", "author": "Yujin Huang et.al.", "abstract": "On-device deep learning is rapidly gaining popularity in mobile applications. Compared to offloading deep learning from smartphones to the cloud, on-device deep learning enables offline model inference while preserving user privacy. However, such mechanisms inevitably store models on users' smartphones and may invite adversarial attacks as they are accessible to attackers. Due to the characteristic of the on-device model, most existing adversarial attacks cannot be directly applied for on-device models. In this paper, we introduce a grey-box adversarial attack framework to hack on-device models by crafting highly similar binary classification models based on identified transfer learning approaches and pre-trained models from TensorFlow Hub. We evaluate the attack effectiveness and generality in terms of four different settings including pre-trained models, datasets, transfer learning approaches and adversarial attack algorithms. The results demonstrate that the proposed attacks remain effective regardless of different settings, and significantly outperform state-of-the-art baselines. We further conduct an empirical study on real-world deep learning mobile apps collected from Google Play. Among 53 apps adopting transfer learning, we find that 71.7\\% of them can be successfully attacked, which includes popular ones in medicine, automation, and finance categories with critical usage scenarios. The results call for the awareness and actions of deep learning mobile app developers to secure the on-device models. The code of this work is available at https://github.com/Jinxhy/SmartAppAttack", "paper_url": "http://arxiv.org/abs/2204.11075v1", "pdf_url": "http://arxiv.org/pdf/2204.11075v1", "repo_url": "https://github.com/jinxhy/smartappattack"}, "2204.12466": {"publish_time": "2022-04-26", "title": "Meta-free representation learning for few-shot learning via stochastic weight averaging", "author": "Kuilin Chen et.al.", "abstract": "Recent studies on few-shot classification using transfer learning pose challenges to the effectiveness and efficiency of episodic meta-learning algorithms. Transfer learning approaches are a natural alternative, but they are restricted to few-shot classification. Moreover, little attention has been on the development of probabilistic models with well-calibrated uncertainty from few-shot samples, except for some Bayesian episodic learning algorithms. To tackle the aforementioned issues, we propose a new transfer learning method to obtain accurate and reliable models for few-shot regression and classification. The resulting method does not require episodic meta-learning and is called meta-free representation learning (MFRL). MFRL first finds low-rank representation generalizing well on meta-test tasks. Given the learned representation, probabilistic linear models are fine-tuned with few-shot samples to obtain models with well-calibrated uncertainty. The proposed method not only achieves the highest accuracy on a wide range of few-shot learning benchmark datasets but also correctly quantifies the prediction uncertainty. In addition, weight averaging and temperature scaling are effective in improving the accuracy and reliability of few-shot learning in existing meta-learning algorithms with a wide range of learning paradigms and model architectures.", "paper_url": "http://arxiv.org/abs/2204.12466v1", "pdf_url": "http://arxiv.org/pdf/2204.12466v1", "repo_url": null}, "2204.12044": {"publish_time": "2022-04-26", "title": "ISTRBoost: Importance Sampling Transfer Regression using Boosting", "author": "Shrey Gupta et.al.", "abstract": "Current Instance Transfer Learning (ITL) methodologies use domain adaptation and sub-space transformation to achieve successful transfer learning. However, these methodologies, in their processes, sometimes overfit on the target dataset or suffer from negative transfer if the test dataset has a high variance. Boosting methodologies have been shown to reduce the risk of overfitting by iteratively re-weighing instances with high-residual. However, this balance is usually achieved with parameter optimization, as well as reducing the skewness in weights produced due to the size of the source dataset. While the former can be achieved, the latter is more challenging and can lead to negative transfer. We introduce a simpler and more robust fix to this problem by building upon the popular boosting ITL regression methodology, two-stage TrAdaBoost.R2. Our methodology,~\\us{}, is a boosting and random-forest based ensemble methodology that utilizes importance sampling to reduce the skewness due to the source dataset. We show that~\\us{}~performs better than competitive transfer learning methodologies $63\\%$ of the time. It also displays consistency in its performance over diverse datasets with varying complexities, as opposed to the sporadic results observed for other transfer learning methodologies.", "paper_url": "http://arxiv.org/abs/2204.12044v1", "pdf_url": "http://arxiv.org/pdf/2204.12044v1", "repo_url": null}, "2204.11860": {"publish_time": "2022-04-25", "title": "Multi-objective Pointer Network for Combinatorial Optimization", "author": "Le-yang Gao et.al.", "abstract": "Multi-objective combinatorial optimization problems (MOCOPs), one type of complex optimization problems, widely exist in various real applications. Although meta-heuristics have been successfully applied to address MOCOPs, the calculation time is often much longer. Recently, a number of deep reinforcement learning (DRL) methods have been proposed to generate approximate optimal solutions to the combinatorial optimization problems. However, the existing studies on DRL have seldom focused on MOCOPs. This study proposes a single-model deep reinforcement learning framework, called multi-objective Pointer Network (MOPN), where the input structure of PN is effectively improved so that the single PN is capable of solving MOCOPs. In addition, two training strategies, based on representative model and transfer learning, respectively, are proposed to further enhance the performance of MOPN in different application scenarios. Moreover, compared to classical meta-heuristics, MOPN only consumes much less time on forward propagation to obtain the Pareto front. Meanwhile, MOPN is insensitive to problem scale, meaning that a trained MOPN is able to address MOCOPs with different scales. To verify the performance of MOPN, extensive experiments are conducted on three multi-objective traveling salesman problems, in comparison with one state-of-the-art model DRL-MOA and three classical multi-objective meta-heuristics. Experimental results demonstrate that the proposed model outperforms all the comparative methods with only 20\\% to 40\\% training time of DRL-MOA.", "paper_url": "http://arxiv.org/abs/2204.11860v1", "pdf_url": "http://arxiv.org/pdf/2204.11860v1", "repo_url": "https://github.com/gaoly/mopn"}, "2204.12833": {"publish_time": "2022-04-27", "title": "Transfer Learning with Pre-trained Conditional Generative Models", "author": "Shin'ya Yamaguchi et.al.", "abstract": "Transfer learning is crucial in training deep neural networks on new target tasks. Current transfer learning methods generally assume at least one of (i) source and target task label spaces must overlap, (ii) source datasets are available, and (iii) target network architectures are consistent with source ones. However, these all assumptions are difficult to hold in practical settings because the target task rarely has the same labels as the source task, the source dataset access is restricted due to licensing and storage costs, and the target architecture is often specialized to each task. To transfer source knowledge without these assumptions, we propose a transfer learning method that uses deep generative models and is composed of the following two stages: pseudo pre-training (PP) and pseudo semi-supervised learning (P-SSL). PP trains a target architecture with a synthesized dataset by using conditional source generative models. P-SSL applies SSL algorithms to labeled target data and unlabeled pseudo samples, which are generated by cascading the source classifier and generative models to condition them with target samples. Our experimental results indicate that our method can outperform baselines of scratch training and knowledge distillation.", "paper_url": "http://arxiv.org/abs/2204.12833v1", "pdf_url": "http://arxiv.org/pdf/2204.12833v1", "repo_url": null}, "2204.12753": {"publish_time": "2022-04-27", "title": "A Comprehensive Understanding of Code-mixed Language Semantics using Hierarchical Transformer", "author": "Ayan Sengupta et.al.", "abstract": "Being a popular mode of text-based communication in multilingual communities, code-mixing in online social media has became an important subject to study. Learning the semantics and morphology of code-mixed language remains a key challenge, due to scarcity of data and unavailability of robust and language-invariant representation learning technique. Any morphologically-rich language can benefit from character, subword, and word-level embeddings, aiding in learning meaningful correlations. In this paper, we explore a hierarchical transformer-based architecture (HIT) to learn the semantics of code-mixed languages. HIT consists of multi-headed self-attention and outer product attention components to simultaneously comprehend the semantic and syntactic structures of code-mixed texts. We evaluate the proposed method across 6 Indian languages (Bengali, Gujarati, Hindi, Tamil, Telugu and Malayalam) and Spanish for 9 NLP tasks on 17 datasets. The HIT model outperforms state-of-the-art code-mixed representation learning and multilingual language models in all tasks. We further demonstrate the generalizability of the HIT architecture using masked language modeling-based pre-training, zero-shot learning, and transfer learning approaches. Our empirical results show that the pre-training objectives significantly improve the performance on downstream tasks.", "paper_url": "http://arxiv.org/abs/2204.12753v1", "pdf_url": "http://arxiv.org/pdf/2204.12753v1", "repo_url": "https://github.com/lcs2-iiitd/code-mixed-classification"}, "2204.12637": {"publish_time": "2022-04-27", "title": "Meta-Learning Based Early Fault Detection for Rolling Bearings via Few-Shot Anomaly Detection", "author": "Wenbin Song et.al.", "abstract": "Early fault detection (EFD) of rolling bearings can recognize slight deviation of the health states and contribute to the stability of mechanical systems. In practice, very limited target bearing data are available to conduct EFD, which makes it hard to adapt to the EFD task of new bearings. To address this problem, many transfer learning based EFD methods utilize historical data to learn transferable domain knowledge and conduct early fault detection on new target bearings. However, most existing methods only consider the distribution drift across different working conditions but ignore the difference between bearings under the same working condition, which is called Unit-to-Unit Variability (UtUV). The setting of EFD with limited target data considering UtUV can be formulated as a Few-shot Anomaly Detection task. Therefore, this paper proposes a novel EFD method based on meta-learning considering UtUV. The proposed method can learn a generic metric based on Relation Network (RN) to measure the similarity between normal data and the new arrival target bearing data. Besides, the proposed method utilizes a health state embedding strategy to decrease false alarms. The performance of proposed method is tested on two bearing datasets. The results show that the proposed method can detect incipient faults earlier than the baselines with lower false alarms.", "paper_url": "http://arxiv.org/abs/2204.12637v1", "pdf_url": "http://arxiv.org/pdf/2204.12637v1", "repo_url": null}, "2204.13545": {"publish_time": "2022-04-28", "title": "Predicting single-cell perturbation responses for unseen drugs", "author": "Leon Hetzel et.al.", "abstract": "Single-cell transcriptomics enabled the study of cellular heterogeneity in response to perturbations at the resolution of individual cells. However, scaling high-throughput screens (HTSs) to measure cellular responses for many drugs remains a challenge due to technical limitations and, more importantly, the cost of such multiplexed experiments. Thus, transferring information from routinely performed bulk RNA-seq HTS is required to enrich single-cell data meaningfully. We introduce a new encoder-decoder architecture to study the perturbational effects of unseen drugs. We combine the model with a transfer learning scheme and demonstrate how training on existing bulk RNA-seq HTS datasets can improve generalisation performance. Better generalisation reduces the need for extensive and costly screens at single-cell resolution. We envision that our proposed method will facilitate more efficient experiment designs through its ability to generate in-silico hypotheses, ultimately accelerating targeted drug discovery.", "paper_url": "http://arxiv.org/abs/2204.13545v1", "pdf_url": "http://arxiv.org/pdf/2204.13545v1", "repo_url": "https://github.com/theislab/chemCPA"}, "2204.13293": {"publish_time": "2022-04-28", "title": "Model Selection, Adaptation, and Combination for Deep Transfer Learning through Neural Networks in Renewable Energies", "author": "Jens Schreiber et.al.", "abstract": "There is recent interest in using model hubs, a collection of pre-trained models, in computer vision tasks. To utilize the model hub, we first select a source model and then adapt the model for the target to compensate for differences. While there is yet limited research on a model selection and adaption for computer vision tasks, this holds even more for the field of renewable power. At the same time, it is a crucial challenge to provide forecasts for the increasing demand for power forecasts based on weather features from a numerical weather prediction. We close these gaps by conducting the first thorough experiment for model selection and adaptation for transfer learning in renewable power forecast, adopting recent results from the field of computer vision on six datasets. We adopt models based on data from different seasons and limit the amount of training data. As an extension of the current state of the art, we utilize a Bayesian linear regression for forecasting the response based on features extracted from a neural network. This approach outperforms the baseline with only seven days of training data. We further show how combining multiple models through ensembles can significantly improve the model selection and adaptation approach. In fact, with more than 30 days of training data, both proposed model combination techniques achieve similar results to those models trained with a full year of training data.", "paper_url": "http://arxiv.org/abs/2204.13293v1", "pdf_url": "http://arxiv.org/pdf/2204.13293v1", "repo_url": null}, "2204.13280": {"publish_time": "2022-04-28", "title": "Resource-efficient domain adaptive pre-training for medical images", "author": "Yasar Mehmood et.al.", "abstract": "The deep learning-based analysis of medical images suffers from data scarcity because of high annotation costs and privacy concerns. Researchers in this domain have used transfer learning to avoid overfitting when using complex architectures. However, the domain differences between pre-training and downstream data hamper the performance of the downstream task. Some recent studies have successfully used domain-adaptive pre-training (DAPT) to address this issue. In DAPT, models are initialized with the generic dataset pre-trained weights, and further pre-training is performed using a moderately sized in-domain dataset (medical images). Although this technique achieved good results for the downstream tasks in terms of accuracy and robustness, it is computationally expensive even when the datasets for DAPT are moderately sized. These compute-intensive techniques and models impact the environment negatively and create an uneven playing field for researchers with limited resources. This study proposed computationally efficient DAPT without compromising the downstream accuracy and robustness. This study proposes three techniques for this purpose, where the first (partial DAPT) performs DAPT on a subset of layers. The second one adopts a hybrid strategy (hybrid DAPT) by performing partial DAPT for a few epochs and then full DAPT for the remaining epochs. The third technique performs DAPT on simplified variants of the base architecture. The results showed that compared to the standard DAPT (full DAPT), the hybrid DAPT technique achieved better performance on the development and external datasets. In contrast, simplified architectures (after DAPT) achieved the best robustness while achieving modest performance on the development dataset .", "paper_url": "http://arxiv.org/abs/2204.13280v1", "pdf_url": "http://arxiv.org/pdf/2204.13280v1", "repo_url": null}, "2204.13232": {"publish_time": "2022-04-28", "title": "Adversarial Fine-tune with Dynamically Regulated Adversary", "author": "Pengyue Hou et.al.", "abstract": "Adversarial training is an effective method to boost model robustness to malicious, adversarial attacks. However, such improvement in model robustness often leads to a significant sacrifice of standard performance on clean images. In many real-world applications such as health diagnosis and autonomous surgical robotics, the standard performance is more valued over model robustness against such extremely malicious attacks. This leads to the question: To what extent we can boost model robustness without sacrificing standard performance? This work tackles this problem and proposes a simple yet effective transfer learning-based adversarial training strategy that disentangles the negative effects of adversarial samples on model's standard performance. In addition, we introduce a training-friendly adversarial attack algorithm, which facilitates the boost of adversarial robustness without introducing significant training complexity. Extensive experimentation indicates that the proposed method outperforms previous adversarial training algorithms towards the target: to improve model robustness while preserving model's standard performance on clean data.", "paper_url": "http://arxiv.org/abs/2204.13232v1", "pdf_url": "http://arxiv.org/pdf/2204.13232v1", "repo_url": null}, "2204.14255": {"publish_time": "2022-04-29", "title": "Human-in-the-loop online multi-agent approach to increase trustworthiness in ML models through trust scores and data augmentation", "author": "Gusseppe Bravo-Rocca et.al.", "abstract": "Increasing a ML model accuracy is not enough, we must also increase its trustworthiness. This is an important step for building resilient AI systems for safety-critical applications such as automotive, finance, and healthcare. For that purpose, we propose a multi-agent system that combines both machine and human agents. In this system, a checker agent calculates a trust score of each instance (which penalizes overconfidence and overcautiousness in predictions) using an agreement-based method and ranks it; then an improver agent filters the anomalous instances based on a human rule-based procedure (which is considered safe), gets the human labels, applies geometric data augmentation, and retrains with the augmented data using transfer learning. We evaluate the system on corrupted versions of the MNIST and FashionMNIST datasets. We get an improvement in accuracy and trust score with just few additional labels compared to a baseline approach.", "paper_url": "http://arxiv.org/abs/2204.14255v2", "pdf_url": "http://arxiv.org/pdf/2204.14255v2", "repo_url": null}, "2204.14079": {"publish_time": "2022-04-29", "title": "Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN", "author": "Dongyeun Lee et.al.", "abstract": "Transfer learning of StyleGAN has recently shown great potential to solve diverse tasks, especially in domain translation. Previous methods utilized a source model by swapping or freezing weights during transfer learning, however, they have limitations on visual quality and controlling source features. In other words, they require additional models that are computationally demanding and have restricted control steps that prevent a smooth transition. In this paper, we propose a new approach to overcome these limitations. Instead of swapping or freezing, we introduce a simple feature matching loss to improve generation quality. In addition, to control the degree of source features, we train a target model with the proposed strategy, FixNoise, to preserve the source features only in a disentangled subspace of a target feature space. Owing to the disentangled feature space, our method can smoothly control the degree of the source features in a single model. Extensive experiments demonstrate that the proposed method can generate more consistent and realistic images than previous works.", "paper_url": "http://arxiv.org/abs/2204.14079v2", "pdf_url": "http://arxiv.org/pdf/2204.14079v2", "repo_url": null}, "2204.13912": {"publish_time": "2022-04-29", "title": "Quantitative Prediction of Fracture Toughness $(K_{{\\rm I}c})$ of Polymer by Fractography Using Deep Neural Networks", "author": "Yoh-ichi Mototake et.al.", "abstract": "Fracture surfaces provide various types of information about fracture. The fracture toughness $K_{{\\rm I}c}$, which represents the resistance to fracture, can be estimated using the three-dimensional (3D) information of a fracture surface, i.e., its roughness. However, this is time-consuming and expensive to obtain the 3D information of a fracture surface; thus, it is desirable to estimate $K_{{\\rm I}c}$ from a two-dimensional (2D) image, which can be easily obtained. In recent years, methods of estimating a 3D structure from its 2D image using deep learning have been rapidly developed. In this study, we propose a framework for fractography that directly estimates $K_{{\\rm I}c}$ from a 2D fracture surface image using deep neural networks (DNNs). Typically, image recognition using a DNN requires a tremendous amount of image data, which is difficult to acquire for fractography owing to the high experimental cost. To compensate for the limited data, in this study, we used the transfer learning (TL) method, and constructed high-performance prediction models even with a small dataset by transferring machine learning models trained using other large datasets. We found that the regression model obtained using our proposed framework can predict $K_{{\\rm I}c}$ in the range of approximately 1-5 [MPa$\\sqrt{m}$] with a standard deviation of the estimation error of approximately $\\pm$0.37 [MPa$\\sqrt{m}$]. The present results demonstrate that the DNN trained with TL opens a new route for quantitative fractography by which parameters of fracture process can be estimated from a fracture surface even with a small dataset. The proposed framework also enables the building of regression models in a few hours. Therefore, our framework enables us to screen a large number of image datasets available in the field of materials science and find candidates that are worth expensive machine learning analysis.", "paper_url": "http://arxiv.org/abs/2204.13912v1", "pdf_url": "http://arxiv.org/pdf/2204.13912v1", "repo_url": null}, "2204.13908": {"publish_time": "2022-04-29", "title": "Task Embedding Temporal Convolution Networks for Transfer Learning Problems in Renewable Power Time-Series Forecast", "author": "Jens Schreiber et.al.", "abstract": "Task embeddings in multi-layer perceptrons for multi-task learning and inductive transfer learning in renewable power forecasts have recently been introduced. In many cases, this approach improves the forecast error and reduces the required training data. However, it does not take the seasonal influences in power forecasts within a day into account, i.e., the diurnal cycle. Therefore, we extended this idea to temporal convolutional networks to consider those seasonalities. We propose transforming the embedding space, which contains the latent similarities between tasks, through convolution and providing these results to the network's residual block. The proposed architecture significantly improves up to 25 percent for multi-task learning for power forecasts on the EuropeWindFarm and GermanSolarFarm dataset compared to the multi-layer perceptron approach. Based on the same data, we achieve a ten percent improvement for the wind datasets and more than 20 percent in most cases for the solar dataset for inductive transfer learning without catastrophic forgetting. Finally, we are the first proposing zero-shot learning for renewable power forecasts to provide predictions even if no training data is available.", "paper_url": "http://arxiv.org/abs/2204.13908v1", "pdf_url": "http://arxiv.org/pdf/2204.13908v1", "repo_url": null}, "2204.13869": {"publish_time": "2022-04-29", "title": "Por Qu\u00e9 N\u00e3o Utiliser Alla Spr\u00e5k? Mixed Training with Gradient Optimization in Few-Shot Cross-Lingual Transfer", "author": "Haoran Xu et.al.", "abstract": "The current state-of-the-art for few-shot cross-lingual transfer learning first trains on abundant labeled data in the source language and then fine-tunes with a few examples on the target language, termed target-adapting. Though this has been demonstrated to work on a variety of tasks, in this paper we show some deficiencies of this approach and propose a one-step mixed training method that trains on both source and target data with \\textit{stochastic gradient surgery}, a novel gradient-level optimization. Unlike the previous studies that focus on one language at a time when target-adapting, we use one model to handle all target languages simultaneously to avoid excessively language-specific models. Moreover, we discuss the unreality of utilizing large target development sets for model selection in previous literature. We further show that our method is both development-free for target languages, and is also able to escape from overfitting issues. We conduct a large-scale experiment on 4 diverse NLP tasks across up to 48 languages. Our proposed method achieves state-of-the-art performance on all tasks and outperforms target-adapting by a large margin, especially for languages that are linguistically distant from the source language, e.g., 7.36% F1 absolute gain on average for the NER task, up to 17.60% on Punjabi.", "paper_url": "http://arxiv.org/abs/2204.13869v1", "pdf_url": "http://arxiv.org/pdf/2204.13869v1", "repo_url": null}, "2205.00506": {"publish_time": "2022-05-01", "title": "Preserve Pre-trained Knowledge: Transfer Learning With Self-Distillation For Action Recognition", "author": "Yang Zhou et.al.", "abstract": "Video-based action recognition is one of the most popular topics in computer vision. With recent advances of selfsupervised video representation learning approaches, action recognition usually follows a two-stage training framework, i.e., self-supervised pre-training on large-scale unlabeled sets and transfer learning on a downstream labeled set. However, catastrophic forgetting of the pre-trained knowledge becomes the main issue in the downstream transfer learning of action recognition, resulting in a sub-optimal solution. In this paper, to alleviate the above issue, we propose a novel transfer learning approach that combines self-distillation in fine-tuning to preserve knowledge from the pre-trained model learned from the large-scale dataset. Specifically, we fix the encoder from the last epoch as the teacher model to guide the training of the encoder from the current epoch in the transfer learning. With such a simple yet effective learning strategy, we outperform state-of-the-art methods on widely used UCF101 and HMDB51 datasets in action recognition task.", "paper_url": "http://arxiv.org/abs/2205.00506v1", "pdf_url": "http://arxiv.org/pdf/2205.00506v1", "repo_url": null}, "2205.00387": {"publish_time": "2022-05-01", "title": "Crude Oil-related Events Extraction and Processing: A Transfer Learning Approach", "author": "Meisin Lee et.al.", "abstract": "One of the challenges in event extraction via traditional supervised learning paradigm is the need for a sizeable annotated dataset to achieve satisfactory model performance. It is even more challenging when it comes to event extraction in the finance and economics domain, a domain with considerably fewer resources. This paper presents a complete framework for extracting and processing crude oil-related events found in CrudeOilNews corpus, addressing the issue of annotation scarcity and class imbalance by leveraging on the effectiveness of transfer learning. Apart from event extraction, we place special emphasis on event properties (Polarity, Modality, and Intensity) classification to determine the factual certainty of each event. We build baseline models first by supervised learning and then exploit Transfer Learning methods to boost event extraction model performance despite the limited amount of annotated data and severe class imbalance. This is done via methods within the transfer learning framework such as Domain Adaptive Pre-training, Multi-task Learning and Sequential Transfer Learning. Based on experiment results, we are able to improve all event extraction sub-task models both in F1 and MCC1-score as compared to baseline models trained via the standard supervised learning. Accurate and holistic event extraction from crude oil news is very useful for downstream tasks such as understanding event chains and learning event-event relations, which can be used for other downstream tasks such as commodity price prediction, summarisation, etc. to support a wide range of business decision making.", "paper_url": "http://arxiv.org/abs/2205.00387v1", "pdf_url": "http://arxiv.org/pdf/2205.00387v1", "repo_url": null}, "2205.00271": {"publish_time": "2022-04-30", "title": "Deep Learning-Enabled Semantic Communication Systems with Task-Unaware Transmitter and Dynamic Data", "author": "Hongwei Zhang et.al.", "abstract": "Existing deep learning-enabled semantic communication systems often rely on shared background knowledge between the transmitter and receiver that includes empirical data and their associated semantic information. In practice, the semantic information is defined by the pragmatic task of the receiver and cannot be known to the transmitter. The actual observable data at the transmitter can also have non-identical distribution with the empirical data in the shared background knowledge library. To address these practical issues, this paper proposes a new neural network-based semantic communication system for image transmission, where the task is unaware at the transmitter and the data environment is dynamic. The system consists of two main parts, namely the semantic extraction (SE) network and the data adaptation (DA) network. The SE network learns how to extract the semantic information using a receiver-leading training process. By using domain adaptation technique from transfer learning, the DA network learns how to convert the data observed into a similar form of the empirical data that the SE network can process without re-training. Numerical experiments show that the proposed method can be adaptive to observable datasets while keeping high performance in terms of both data recovery and task execution. The codes are available on https://github.com/SJTU-mxtao/Semantic-Communication-Systems.", "paper_url": "http://arxiv.org/abs/2205.00271v1", "pdf_url": "http://arxiv.org/pdf/2205.00271v1", "repo_url": "https://github.com/sjtu-mxtao/semantic-communication-systems"}, "2205.01404": {"publish_time": "2022-05-03", "title": "Neural Language Taskonomy: Which NLP Tasks are the most Predictive of fMRI Brain Activity?", "author": "Subba Reddy Oota et.al.", "abstract": "Several popular Transformer based language models have been found to be successful for text-driven brain encoding. However, existing literature leverages only pretrained text Transformer models and has not explored the efficacy of task-specific learned Transformer representations. In this work, we explore transfer learning from representations learned for ten popular natural language processing tasks (two syntactic and eight semantic) for predicting brain responses from two diverse datasets: Pereira (subjects reading sentences from paragraphs) and Narratives (subjects listening to the spoken stories). Encoding models based on task features are used to predict activity in different regions across the whole brain. Features from coreference resolution, NER, and shallow syntax parsing explain greater variance for the reading activity. On the other hand, for the listening activity, tasks such as paraphrase generation, summarization, and natural language inference show better encoding performance. Experiments across all 10 task representations provide the following cognitive insights: (i) language left hemisphere has higher predictive brain activity versus language right hemisphere, (ii) posterior medial cortex, temporo-parieto-occipital junction, dorsal frontal lobe have higher correlation versus early auditory and auditory association cortex, (iii) syntactic and semantic tasks display a good predictive performance across brain regions for reading and listening stimuli resp.", "paper_url": "http://arxiv.org/abs/2205.01404v1", "pdf_url": "http://arxiv.org/pdf/2205.01404v1", "repo_url": null}, "2205.01381": {"publish_time": "2022-05-03", "title": "Kompetencer: Fine-grained Skill Classification in Danish Job Postings via Distant Supervision and Transfer Learning", "author": "Mike Zhang et.al.", "abstract": "Skill Classification (SC) is the task of classifying job competences from job postings. This work is the first in SC applied to Danish job vacancy data. We release the first Danish job posting dataset: Kompetencer (en: competences), annotated for nested spans of competences. To improve upon coarse-grained annotations, we make use of The European Skills, Competences, Qualifications and Occupations (ESCO; le Vrang et al., 2014) taxonomy API to obtain fine-grained labels via distant supervision. We study two setups: The zero-shot and few-shot classification setting. We fine-tune English-based models and RemBERT (Chung et al., 2020) and compare them to in-language Danish models. Our results show RemBERT significantly outperforms all other models in both the zero-shot and the few-shot setting.", "paper_url": "http://arxiv.org/abs/2205.01381v1", "pdf_url": "http://arxiv.org/pdf/2205.01381v1", "repo_url": "https://github.com/jjzha/kompetencer"}, "2205.01223": {"publish_time": "2022-05-02", "title": "FINETUNA: Fine-tuning Accelerated Molecular Simulations", "author": "Joseph Musielewicz et.al.", "abstract": "Machine learning approaches have the potential to approximate Density Functional Theory (DFT) for atomistic simulations in a computationally efficient manner, which could dramatically increase the impact of computational simulations on real-world problems. However, they are limited by their accuracy and the cost of generating labeled data. Here, we present an online active learning framework for accelerating the simulation of atomic systems efficiently and accurately by incorporating prior physical information learned by large-scale pre-trained graph neural network models from the Open Catalyst Project. Accelerating these simulations enables useful data to be generated more cheaply, allowing better models to be trained and more atomistic systems to be screened. We also present a method of comparing local optimization techniques on the basis of both their speed and accuracy. Experiments on 30 benchmark adsorbate-catalyst systems show that our method of transfer learning to incorporate prior information from pre-trained models accelerates simulations by reducing the number of DFT calculations by 91%, while meeting an accuracy threshold of 0.02 eV 93% of the time. Finally, we demonstrate a technique for leveraging the interactive functionality built in to VASP to efficiently compute single point calculations within our online active learning framework without the significant startup costs. This allows VASP to work in tandem with our framework while requiring 75% fewer self-consistent cycles than conventional single point calculations. The online active learning implementation, and examples using the VASP interactive code, are available in the open source FINETUNA package on Github.", "paper_url": "http://arxiv.org/abs/2205.01223v1", "pdf_url": "http://arxiv.org/pdf/2205.01223v1", "repo_url": null}, "2205.02152": {"publish_time": "2022-05-04", "title": "Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models", "author": "Constantine Maganaris et.al.", "abstract": "Recent studies indicate that detecting radiographic patterns on CT scans can yield high sensitivity and specificity for COVID-19 localization. In this paper, we investigate the appropriateness of deep learning models transferability, for semantic segmentation of pneumonia-infected areas in CT images. Transfer learning allows for the fast initialization/ reutilization of detection models, given that large volumes of training are not available. Our work explores the efficacy of using pre-trained U-Net architectures, on a specific CT data set, for identifying Covid-19 side-effects over images from different datasets. Experimental results indicate improvement in the segmentation accuracy of identifying COVID-19 infected regions.", "paper_url": "http://arxiv.org/abs/2205.02152v1", "pdf_url": "http://arxiv.org/pdf/2205.02152v1", "repo_url": null}, "2205.01987": {"publish_time": "2022-05-04", "title": "ON-TRAC Consortium Systems for the IWSLT 2022 Dialect and Low-resource Speech Translation Tasks", "author": "Marcely Zanon Boito et.al.", "abstract": "This paper describes the ON-TRAC Consortium translation systems developed for two challenge tracks featured in the Evaluation Campaign of IWSLT 2022: low-resource and dialect speech translation. For the Tunisian Arabic-English dataset (low-resource and dialect tracks), we build an end-to-end model as our joint primary submission, and compare it against cascaded models that leverage a large fine-tuned wav2vec 2.0 model for ASR. Our results show that in our settings pipeline approaches are still very competitive, and that with the use of transfer learning, they can outperform end-to-end models for speech translation (ST). For the Tamasheq-French dataset (low-resource track) our primary submission leverages intermediate representations from a wav2vec 2.0 model trained on 234 hours of Tamasheq audio, while our contrastive model uses a French phonetic transcription of the Tamasheq audio as input in a Conformer speech translation architecture jointly trained on automatic speech recognition, ST and machine translation losses. Our results highlight that self-supervised models trained on smaller sets of target data are more effective to low-resource end-to-end ST fine-tuning, compared to large off-the-shelf models. Results also illustrate that even approximate phonetic transcriptions can improve ST scores.", "paper_url": "http://arxiv.org/abs/2205.01987v1", "pdf_url": "http://arxiv.org/pdf/2205.01987v1", "repo_url": null}, "2205.03339": {"publish_time": "2022-05-06", "title": "Transferring Chemical and Energetic Knowledge Between Molecular Systems with Machine Learning", "author": "Sajjad Heydari et.al.", "abstract": "Predicting structural and energetic properties of a molecular system is one of the fundamental tasks in molecular simulations, and it has use cases in chemistry, biology, and medicine. In the past decade, the advent of machine learning algorithms has impacted on molecular simulations for various tasks, including property prediction of atomistic systems. In this paper, we propose a novel methodology for transferring knowledge obtained from simple molecular systems to a more complex one, possessing a significantly larger number of atoms and degrees of freedom. In particular, we focus on the classification of high and low free-energy states. Our approach relies on utilizing (i) a novel hypergraph representation of molecules, encoding all relevant information for characterizing the potential energy of a conformation, and (ii) novel message passing and pooling layers for processing and making predictions on such hypergraph-structured data. Despite the complexity of the problem, our results show a remarkable AUC of 0.92 for transfer learning from tri-alanine to the deca-alanine system. Moreover, we show that the very same transfer learning approach can be used to group, in an unsupervised way, various secondary structures of deca-alanine in clusters having similar free-energy values. Our study represents a proof of concept that reliable transfer learning models for molecular systems can be designed paving the way to unexplored routes in prediction of structural and energetic properties of biologically relevant systems.", "paper_url": "http://arxiv.org/abs/2205.03339v1", "pdf_url": "http://arxiv.org/pdf/2205.03339v1", "repo_url": null}, "2205.03289": {"publish_time": "2022-05-06", "title": "Learning to Cooperate with Completely Unknown Teammates", "author": "Alexandre Neves et.al.", "abstract": "A key goal of ad hoc teamwork is to develop a learning agent that cooperates with unknown teams, without resorting to any pre-coordination protocol. Despite a vast number of ad hoc teamwork algorithms in the literature, most of them cannot address the problem of learning to cooperate with a completely unknown team, unless it learns from scratch. This article presents a novel approach that uses transfer learning alongside the state-of-the-art PLASTIC-Policy to adapt to completely unknown teammates quickly. We test our solution within the Half Field Offense simulator with five different teammates. The teammates were designed independently by developers from different countries and at different times. Our empirical evaluation shows that it is advantageous for an ad hoc agent to leverage its past knowledge when adapting to a new team instead of learning how to cooperate with it from scratch.", "paper_url": "http://arxiv.org/abs/2205.03289v1", "pdf_url": "http://arxiv.org/pdf/2205.03289v1", "repo_url": null}, "2205.02973": {"publish_time": "2022-05-06", "title": "Large Scale Transfer Learning for Differentially Private Image Classification", "author": "Harsh Mehta et.al.", "abstract": "Differential Privacy (DP) provides a formal framework for training machine learning models with individual example level privacy. Training models with DP protects the model against leakage of sensitive data in a potentially adversarial setting. In the field of deep learning, Differentially Private Stochastic Gradient Descent (DP-SGD) has emerged as a popular private training algorithm. Private training using DP-SGD protects against leakage by injecting noise into individual example gradients, such that the trained model weights become nearly independent of the use any particular training example. While this result is quite appealing, the computational cost of training large-scale models with DP-SGD is substantially higher than non-private training. This is further exacerbated by the fact that increasing the number of parameters leads to larger degradation in utility with DP. In this work, we zoom in on the ImageNet dataset and demonstrate that similar to the non-private case, pre-training over-parameterized models on a large public dataset can lead to substantial gains when the model is finetuned privately. Moreover, by systematically comparing private and non-private models across a range of huge batch sizes, we find that similar to non-private setting, choice of optimizer can further improve performance substantially with DP. By switching from DP-SGD to DP-LAMB we saw improvement of up to 20$\\%$ points (absolute). Finally, we show that finetuning just the last layer for a \\emph{single step} in the full batch setting leads to both SOTA results of 81.7 $\\%$ under a wide privacy budget range of $\\epsilon \\in [4, 10]$ and $\\delta$ = $10^{-6}$ while minimizing the computational overhead substantially.", "paper_url": "http://arxiv.org/abs/2205.02973v1", "pdf_url": "http://arxiv.org/pdf/2205.02973v1", "repo_url": null}, "2205.02841": {"publish_time": "2022-05-05", "title": "Understanding Transfer Learning for Chest Radiograph Clinical Report Generation with Modified Transformer Architectures", "author": "Edward Vendrow et.al.", "abstract": "The image captioning task is increasingly prevalent in artificial intelligence applications for medicine. One important application is clinical report generation from chest radiographs. The clinical writing of unstructured reports is time consuming and error-prone. An automated system would improve standardization, error reduction, time consumption, and medical accessibility. In this paper we demonstrate the importance of domain specific pre-training and propose a modified transformer architecture for the medical image captioning task. To accomplish this, we train a series of modified transformers to generate clinical reports from chest radiograph image input. These modified transformers include: a meshed-memory augmented transformer architecture with visual extractor using ImageNet pre-trained weights, a meshed-memory augmented transformer architecture with visual extractor using CheXpert pre-trained weights, and a meshed-memory augmented transformer whose encoder is passed the concatenated embeddings using both ImageNet pre-trained weights and CheXpert pre-trained weights. We use BLEU(1-4), ROUGE-L, CIDEr, and the clinical CheXbert F1 scores to validate our models and demonstrate competitive scores with state of the art models. We provide evidence that ImageNet pre-training is ill-suited for the medical image captioning task, especially for less frequent conditions (eg: enlarged cardiomediastinum, lung lesion, pneumothorax). Furthermore, we demonstrate that the double feature model improves performance for specific medical conditions (edema, consolidation, pneumothorax, support devices) and overall CheXbert F1 score, and should be further developed in future work. Such a double feature model, including both ImageNet pre-training as well as domain specific pre-training, could be used in a wide range of image captioning models in medicine.", "paper_url": "http://arxiv.org/abs/2205.02841v1", "pdf_url": "http://arxiv.org/pdf/2205.02841v1", "repo_url": null}, "2205.04344": {"publish_time": "2022-05-09", "title": "Transfer Learning Based Efficient Traffic Prediction with Limited Training Data", "author": "Sajal Saha et.al.", "abstract": "Efficient prediction of internet traffic is an essential part of Self Organizing Network (SON) for ensuring proactive management. There are many existing solutions for internet traffic prediction with higher accuracy using deep learning. But designing individual predictive models for each service provider in the network is challenging due to data heterogeneity, scarcity, and abnormality. Moreover, the performance of the deep sequence model in network traffic prediction with limited training data has not been studied extensively in the current works. In this paper, we investigated and evaluated the performance of the deep transfer learning technique in traffic prediction with inadequate historical data leveraging the knowledge of our pre-trained model. First, we used a comparatively larger real-world traffic dataset for source domain prediction based on five different deep sequence models: Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), LSTM Encoder-Decoder (LSTM_En_De), LSTM_En_De with Attention layer (LSTM_En_De_Atn), and Gated Recurrent Unit (GRU). Then, two best-performing models, LSTM_En_De and LSTM_En_De_Atn, from the source domain with an accuracy of 96.06% and 96.05% are considered for the target domain prediction. Finally, four smaller traffic datasets collected for four particular sources and destination pairs are used in the target domain to compare the performance of the standard learning and transfer learning in terms of accuracy and execution time. According to our experimental result, transfer learning helps to reduce the execution time for most cases, while the model's accuracy is improved in transfer learning with a larger training session.", "paper_url": "http://arxiv.org/abs/2205.04344v1", "pdf_url": "http://arxiv.org/pdf/2205.04344v1", "repo_url": null}, "2205.04234": {"publish_time": "2022-05-09", "title": "An Effective Scheme for Maize Disease Recognition based on Deep Networks", "author": "Saeedeh Osouli et.al.", "abstract": "In the last decades, the area under cultivation of maize products has increased because of its essential role in the food cycle for humans, livestock, and poultry. Moreover, the diseases of plants impact food safety and can significantly reduce both the quality and quantity of agricultural products. There are many challenges to accurate and timely diagnosis of the disease. This research presents a novel scheme based on a deep neural network to overcome the mentioned challenges. Due to the limited number of data, the transfer learning technique is employed with the help of two well-known architectures. In this way, a new effective model is adopted by a combination of pre-trained MobileNetV2 and Inception Networks due to their effective performance on object detection problems. The convolution layers of MoblieNetV2 and Inception modules are parallelly arranged as earlier layers to extract crucial features. In addition, the imbalance problem of classes has been solved by an augmentation strategy. The proposed scheme has a superior performance compared to other state-of-the-art models published in recent years. The accuracy of the model reaches 97%, approximately. In summary, experimental results prove the method's validity and significant performance in diagnosing disease in plant leaves.", "paper_url": "http://arxiv.org/abs/2205.04234v1", "pdf_url": "http://arxiv.org/pdf/2205.04234v1", "repo_url": null}, "2205.04067": {"publish_time": "2022-05-09", "title": "Sub-Word Alignment Is Still Useful: A Vest-Pocket Method for Enhancing Low-Resource Machine Translation", "author": "Minhan Xu et.al.", "abstract": "We leverage embedding duplication between aligned sub-words to extend the Parent-Child transfer learning method, so as to improve low-resource machine translation. We conduct experiments on benchmark datasets of My-En, Id-En and Tr-En translation scenarios. The test results show that our method produces substantial improvements, achieving the BLEU scores of 22.5, 28.0 and 18.1 respectively. In addition, the method is computationally efficient which reduces the consumption of training time by 63.8%, reaching the duration of 1.6 hours when training on a Tesla 16GB P100 GPU. All the models and source codes in the experiments will be made publicly available to support reproducible research.", "paper_url": "http://arxiv.org/abs/2205.04067v1", "pdf_url": "http://arxiv.org/pdf/2205.04067v1", "repo_url": null}, "2205.04040": {"publish_time": "2022-05-09", "title": "ProQA: Structural Prompt-based Pre-training for Unified Question Answering", "author": "Wanjun Zhong et.al.", "abstract": "Question Answering (QA) is a longstanding challenge in natural language processing. Existing QA works mostly focus on specific question types, knowledge domains, or reasoning skills. The specialty in QA research hinders systems from modeling commonalities between tasks and generalization for wider applications. To address this issue, we present ProQA, a unified QA paradigm that solves various tasks through a single model. ProQA takes a unified structural prompt as the bridge and improves the QA-centric ability by structural prompt-based pre-training. Through a structurally designed prompt-based input schema, ProQA concurrently models the knowledge generalization for all QA tasks while keeping the knowledge customization for every specific QA task. Furthermore, ProQA is pre-trained with structural prompt-formatted large-scale synthesized corpus, which empowers the model with the commonly-required QA ability. Experimental results on 11 QA benchmarks demonstrate that ProQA consistently boosts performance on both full data fine-tuning, few-shot learning, and zero-shot testing scenarios. Furthermore, ProQA exhibits strong ability in both continual learning and transfer learning by taking the advantages of the structural prompt.", "paper_url": "http://arxiv.org/abs/2205.04040v1", "pdf_url": "http://arxiv.org/pdf/2205.04040v1", "repo_url": null}, "2205.04029": {"publish_time": "2022-05-09", "title": "Muskits: an End-to-End Music Processing Toolkit for Singing Voice Synthesis", "author": "Jiatong Shi et.al.", "abstract": "This paper introduces a new open-source platform named Muskits for end-to-end music processing, which mainly focuses on end-to-end singing voice synthesis (E2E-SVS). Muskits supports state-of-the-art SVS models, including RNN SVS, transformer SVS, and XiaoiceSing. The design of Muskits follows the style of widely-used speech processing toolkits, ESPnet and Kaldi, for data prepossessing, training, and recipe pipelines. To the best of our knowledge, this toolkit is the first platform that allows a fair and highly-reproducible comparison between several published works in SVS. In addition, we also demonstrate several advanced usages based on the toolkit functionalities, including multilingual training and transfer learning. This paper describes the major framework of Muskits, its functionalities, and experimental results in single-singer, multi-singer, multilingual, and transfer learning scenarios. The toolkit is publicly available at https://github.com/SJTMusicTeam/Muskits.", "paper_url": "http://arxiv.org/abs/2205.04029v1", "pdf_url": "http://arxiv.org/pdf/2205.04029v1", "repo_url": null}, "2205.04841": {"publish_time": "2022-05-10", "title": "Object Detection in Indian Food Platters using Transfer Learning with YOLOv4", "author": "Deepanshu Pandey et.al.", "abstract": "Object detection is a well-known problem in computer vision. Despite this, its usage and pervasiveness in the traditional Indian food dishes has been limited. Particularly, recognizing Indian food dishes present in a single photo is challenging due to three reasons: 1. Lack of annotated Indian food datasets 2. Non-distinct boundaries between the dishes 3. High intra-class variation. We solve these issues by providing a comprehensively labelled Indian food dataset- IndianFood10, which contains 10 food classes that appear frequently in a staple Indian meal and using transfer learning with YOLOv4 object detector model. Our model is able to achieve an overall mAP score of 91.8% and f1-score of 0.90 for our 10 class dataset. We also provide an extension of our 10 class dataset- IndianFood20, which contains 10 more traditional Indian food classes.", "paper_url": "http://arxiv.org/abs/2205.04841v1", "pdf_url": "http://arxiv.org/pdf/2205.04841v1", "repo_url": null}, "2205.04617": {"publish_time": "2022-05-10", "title": "CoDo: Contrastive Learning with Downstream Background Invariance for Detection", "author": "Bing Zhao et.al.", "abstract": "The prior self-supervised learning researches mainly select image-level instance discrimination as pretext task. It achieves a fantastic classification performance that is comparable to supervised learning methods. However, with degraded transfer performance on downstream tasks such as object detection. To bridge the performance gap, we propose a novel object-level self-supervised learning method, called Contrastive learning with Downstream background invariance (CoDo). The pretext task is converted to focus on instance location modeling for various backgrounds, especially for downstream datasets. The ability of background invariance is considered vital for object detection. Firstly, a data augmentation strategy is proposed to paste the instances onto background images, and then jitter the bounding box to involve background information. Secondly, we implement architecture alignment between our pretraining network and the mainstream detection pipelines. Thirdly, hierarchical and multi views contrastive learning is designed to improve performance of visual representation learning. Experiments on MSCOCO demonstrate that the proposed CoDo with common backbones, ResNet50-FPN, yields strong transfer learning results for object detection.", "paper_url": "http://arxiv.org/abs/2205.04617v1", "pdf_url": "http://arxiv.org/pdf/2205.04617v1", "repo_url": null}, "2205.04601": {"publish_time": "2022-05-09", "title": "Long-term stability and generalization of observationally-constrained stochastic data-driven models for geophysical turbulence", "author": "Ashesh Chattopadhyay et.al.", "abstract": "Recent years have seen a surge in interest in building deep learning-based fully data-driven models for weather prediction. Such deep learning models if trained on observations can mitigate certain biases in current state-of-the-art weather models, some of which stem from inaccurate representation of subgrid-scale processes. However, these data-driven models, being over-parameterized, require a lot of training data which may not be available from reanalysis (observational data) products. Moreover, an accurate, noise-free, initial condition to start forecasting with a data-driven weather model is not available in realistic scenarios. Finally, deterministic data-driven forecasting models suffer from issues with long-term stability and unphysical climate drift, which makes these data-driven models unsuitable for computing climate statistics. Given these challenges, previous studies have tried to pre-train deep learning-based weather forecasting models on a large amount of imperfect long-term climate model simulations and then re-train them on available observational data. In this paper, we propose a convolutional variational autoencoder-based stochastic data-driven model that is pre-trained on an imperfect climate model simulation from a 2-layer quasi-geostrophic flow and re-trained, using transfer learning, on a small number of noisy observations from a perfect simulation. This re-trained model then performs stochastic forecasting with a noisy initial condition sampled from the perfect simulation. We show that our ensemble-based stochastic data-driven model outperforms a baseline deterministic encoder-decoder-based convolutional model in terms of short-term skills while remaining stable for long-term climate simulations yielding accurate climatology.", "paper_url": "http://arxiv.org/abs/2205.04601v1", "pdf_url": "http://arxiv.org/pdf/2205.04601v1", "repo_url": null}, "2205.05480": {"publish_time": "2022-05-11", "title": "Automatic Tuberculosis and COVID-19 cough classification using deep learning", "author": "Madhurananda Pahar et.al.", "abstract": "We present a deep learning based automatic cough classifier which can discriminate tuberculosis (TB) coughs from COVID-19 coughs and healthy coughs. Both TB and COVID-19 are respiratory disease, have cough as a predominant symptom and claim thousands of lives each year. The cough audio recordings were collected at both indoor and outdoor settings and also uploaded using smartphones from subjects around the globe, thus contain various levels of noise. This cough data include 1.68 hours of TB coughs, 18.54 minutes of COVID-19 coughs and 1.69 hours of healthy coughs from 47 TB patients, 229 COVID-19 patients and 1498 healthy patients and were used to train and evaluate a CNN, LSTM and Resnet50. These three deep architectures were also pre-trained on 2.14 hours of sneeze, 2.91 hours of speech and 2.79 hours of noise for improved performance. The class-imbalance in our dataset was addressed by using SMOTE data balancing technique and using performance metrics such as F1-score and AUC. Our study shows that the highest F1-scores of 0.9259 and 0.8631 have been achieved from a pre-trained Resnet50 for two-class (TB vs COVID-19) and three-class (TB vs COVID-19 vs healthy) cough classification tasks, respectively. The application of deep transfer learning has improved the classifiers' performance and makes them more robust as they generalise better over the cross-validation folds. Their performances exceed the TB triage test requirements set by the world health organisation (WHO). The features producing the best performance contain higher order of MFCCs suggesting that the differences between TB and COVID-19 coughs are not perceivable by the human ear. This type of cough audio classification is non-contact, cost-effective and can easily be deployed on a smartphone, thus it can be an excellent tool for both TB and COVID-19 screening.", "paper_url": "http://arxiv.org/abs/2205.05480v1", "pdf_url": "http://arxiv.org/pdf/2205.05480v1", "repo_url": null}, "2205.05390": {"publish_time": "2022-05-11", "title": "AutoKE: An automatic knowledge embedding framework for scientific machine learning", "author": "Mengge Du et.al.", "abstract": "Imposing physical constraints on neural networks as a method of knowledge embedding has achieved great progress in solving physical problems described by governing equations. However, for many engineering problems, governing equations often have complex forms, including complex partial derivatives or stochastic physical fields, which results in significant inconveniences from the perspective of implementation. In this paper, a scientific machine learning framework, called AutoKE, is proposed, and a reservoir flow problem is taken as an instance to demonstrate that this framework can effectively automate the process of embedding physical knowledge. In AutoKE, an emulator comprised of deep neural networks (DNNs) is built for predicting the physical variables of interest. An arbitrarily complex equation can be parsed and automatically converted into a computational graph through the equation parser module, and the fitness of the emulator to the governing equation is evaluated via automatic differentiation. Furthermore, the fixed weights in the loss function are substituted with adaptive weights by incorporating the Lagrangian dual method. Neural architecture search (NAS) is also introduced into the AutoKE to select an optimal network architecture of the emulator according to the specific problem. Finally, we apply transfer learning to enhance the scalability of the emulator. In experiments, the framework is verified by a series of physical problems in which it can automatically embed physical knowledge into an emulator without heavy hand-coding. The results demonstrate that the emulator can not only make accurate predictions, but also be applied to similar problems with high efficiency via transfer learning.", "paper_url": "http://arxiv.org/abs/2205.05390v1", "pdf_url": "http://arxiv.org/pdf/2205.05390v1", "repo_url": "https://github.com/menggedu/autoke"}, "2205.05282": {"publish_time": "2022-05-11", "title": "ReFine: Re-randomization before Fine-tuning for Cross-domain Few-shot Learning", "author": "Jaehoon Oh et.al.", "abstract": "Cross-domain few-shot learning (CD-FSL), where there are few target samples under extreme differences between source and target domains, has recently attracted huge attention. For CD-FSL, recent studies generally have developed transfer learning based approaches that pre-train a neural network on popular labeled source domain datasets and then transfer it to target domain data. Although the labeled datasets may provide suitable initial parameters for the target data, the domain difference between the source and target might hinder the fine-tuning on the target domain. This paper proposes a simple yet powerful method that re-randomizes the parameters fitted on the source domain before adapting to the target data. The re-randomization resets source-specific parameters of the source pre-trained model and thus facilitates fine-tuning on the target domain, improving few-shot performance.", "paper_url": "http://arxiv.org/abs/2205.05282v1", "pdf_url": "http://arxiv.org/pdf/2205.05282v1", "repo_url": null}, "2205.06025": {"publish_time": "2022-05-12", "title": "DTW at Qur'an QA 2022: Utilising Transfer Learning with Transformers for Question Answering in a Low-resource Domain", "author": "Damith Premasiri et.al.", "abstract": "The task of machine reading comprehension (MRC) is a useful benchmark to evaluate the natural language understanding of machines. It has gained popularity in the natural language processing (NLP) field mainly due to the large number of datasets released for many languages. However, the research in MRC has been understudied in several domains, including religious texts. The goal of the Qur'an QA 2022 shared task is to fill this gap by producing state-of-the-art question answering and reading comprehension research on Qur'an. This paper describes the DTW entry to the Quran QA 2022 shared task. Our methodology uses transfer learning to take advantage of available Arabic MRC data. We further improve the results using various ensemble learning strategies. Our approach provided a partial Reciprocal Rank (pRR) score of 0.49 on the test set, proving its strong performance on the task.", "paper_url": "http://arxiv.org/abs/2205.06025v1", "pdf_url": "http://arxiv.org/pdf/2205.06025v1", "repo_url": "https://github.com/damithdr/questionanswering"}, "2205.05967": {"publish_time": "2022-05-12", "title": "Target Aware Network Architecture Search and Compression for Efficient Knowledge Transfer", "author": "S. H. Shabbeer Basha et.al.", "abstract": "Transfer Learning enables Convolutional Neural Networks (CNN) to acquire knowledge from a source domain and transfer it to a target domain, where collecting large-scale annotated examples is both time-consuming and expensive. Conventionally, while transferring the knowledge learned from one task to another task, the deeper layers of a pre-trained CNN are finetuned over the target dataset. However, these layers that are originally designed for the source task are over-parameterized for the target task. Thus, finetuning these layers over the target dataset reduces the generalization ability of the CNN due to high network complexity. To tackle this problem, we propose a two-stage framework called TASCNet which enables efficient knowledge transfer. In the first stage, the configuration of the deeper layers is learned automatically and finetuned over the target dataset. Later, in the second stage, the redundant filters are pruned from the fine-tuned CNN to decrease the network's complexity for the target task while preserving the performance. This two-stage mechanism finds a compact version of the pre-trained CNN with optimal structure (number of filters in a convolutional layer, number of neurons in a dense layer, and so on) from the hypothesis space. The efficacy of the proposed method is evaluated using VGG-16, ResNet-50, and DenseNet-121 on CalTech-101, CalTech-256, and Stanford Dogs datasets. The proposed TASCNet reduces the computational complexity of pre-trained CNNs over the target task by reducing both trainable parameters and FLOPs which enables resource-efficient knowledge transfer.", "paper_url": "http://arxiv.org/abs/2205.05967v1", "pdf_url": "http://arxiv.org/pdf/2205.05967v1", "repo_url": null}, "2205.05940": {"publish_time": "2022-05-12", "title": "SimCPSR: Simple Contrastive Learning for Paper Submission Recommendation System", "author": "Duc H. Le et.al.", "abstract": "The recommendation system plays a vital role in many areas, especially academic fields, to support researchers in submitting and increasing the acceptance of their work through the conference or journal selection process. This study proposes a transformer-based model using transfer learning as an efficient approach for the paper submission recommendation system. By combining essential information (such as the title, the abstract, and the list of keywords) with the aims and scopes of journals, the model can recommend the Top K journals that maximize the acceptance of the paper. Our model had developed through two states: (i) Fine-tuning the pre-trained language model (LM) with a simple contrastive learning framework. We utilized a simple supervised contrastive objective to fine-tune all parameters, encouraging the LM to learn the document representation effectively. (ii) The fine-tuned LM was then trained on different combinations of the features for the downstream task. This study suggests a more advanced method for enhancing the efficiency of the paper submission recommendation system compared to previous approaches when we respectively achieve 0.5173, 0.8097, 0.8862, 0.9496 for Top 1, 3, 5, and 10 accuracies on the test set for combining the title, abstract, and keywords as input features. Incorporating the journals' aims and scopes, our model shows an exciting result by getting 0.5194, 0.8112, 0.8866, and 0.9496 respective to Top 1, 3, 5, and 10.", "paper_url": "http://arxiv.org/abs/2205.05940v1", "pdf_url": "http://arxiv.org/pdf/2205.05940v1", "repo_url": "https://github.com/hduc-le/simcpsr"}, "2205.06761": {"publish_time": "2022-05-13", "title": "Exploring the structure-property relations of thin-walled, 2D extruded lattices using neural networks", "author": "Junyan He et.al.", "abstract": "This paper investigates the structure-property relations of thin-walled lattices under dynamic longitudinal compression, characterized by their cross-sections and heights. These relations elucidate the interactions of different geometric features of a design on mechanical response, including energy absorption. We proposed a combinatorial, key-based design system to generate different lattice designs and used the finite element method to simulate their response with the Johnson-Cook material model. Using an autoencoder, we encoded the cross-sectional images of the lattices into latent design feature vectors, which were supplied to the neural network model to generate predictions. The trained models can accurately predict lattice energy absorption curves in the key-based design system and can be extended to new designs outside of the system via transfer learning.", "paper_url": "http://arxiv.org/abs/2205.06761v1", "pdf_url": "http://arxiv.org/pdf/2205.06761v1", "repo_url": null}, "2205.06743": {"publish_time": "2022-05-13", "title": "A Comprehensive Survey of Few-shot Learning: Evolution, Applications, Challenges, and Opportunities", "author": "Yisheng Song et.al.", "abstract": "Few-shot learning (FSL) has emerged as an effective learning method and shows great potential. Despite the recent creative works in tackling FSL tasks, learning valid information rapidly from just a few or even zero samples still remains a serious challenge. In this context, we extensively investigated 200+ latest papers on FSL published in the past three years, aiming to present a timely and comprehensive overview of the most recent advances in FSL along with impartial comparisons of the strengths and weaknesses of the existing works. For the sake of avoiding conceptual confusion, we first elaborate and compare a set of similar concepts including few-shot learning, transfer learning, and meta-learning. Furthermore, we propose a novel taxonomy to classify the existing work according to the level of abstraction of knowledge in accordance with the challenges of FSL. To enrich this survey, in each subsection we provide in-depth analysis and insightful discussion about recent advances on these topics. Moreover, taking computer vision as an example, we highlight the important application of FSL, covering various research hotspots. Finally, we conclude the survey with unique insights into the technology evolution trends together with potential future research opportunities in the hope of providing guidance to follow-up research.", "paper_url": "http://arxiv.org/abs/2205.06743v1", "pdf_url": "http://arxiv.org/pdf/2205.06743v1", "repo_url": null}, "2205.06324": {"publish_time": "2022-05-12", "title": "Graph Neural Network Modeling of Grain-scale Anisotropic Elastic Behavior using Simulated and Measured Microscale Data", "author": "Darren C. Pagan et.al.", "abstract": "Here we assess the applicability of graph neural networks (GNNs) for predicting the grain-scale elastic response of polycrystalline metallic alloys. Using GNN surrogate models, grain-averaged stresses during uniaxial elastic tension in Low Solvus High Refractory (LSHR) Ni Superalloy and Ti 7wt%Al (Ti-7Al), as example face centered cubic and hexagonal closed packed alloys, are predicted. A transfer learning approach is taken in which GNN surrogate models are trained using crystal elasticity finite element method simulations and then the trained surrogate models are used to predict the mechanical response of microstructures measured using high-energy X-ray diffraction microscopy. The performance of using various microstructural and micromechanical descriptors for input nodal features to the GNNs is explored. The effects of elastic anisotropy on GNN model performance and outlooks for extension of the framework are discussed.", "paper_url": "http://arxiv.org/abs/2205.06324v1", "pdf_url": "http://arxiv.org/pdf/2205.06324v1", "repo_url": null}, "2205.07731": {"publish_time": "2022-05-16", "title": "Transfer learning based physics-informed neural networks for solving inverse problems in tunneling", "author": "Chen Xu et.al.", "abstract": "Recently, a class of machine learning methods called physics-informed neural networks (PINNs) has been proposed and gained great prevalence in solving various scientific computing problems. This approach enables the solution of partial differential equations (PDEs) via embedding physical laws into the loss function of neural networks. Many inverse problems can also be tackled by simply combining the observational data from real life scenarios with existing PINN algorithms. In this paper, we present a multi-task learning method to improve the training stability of PINNs for linear elastic problems, and the homoscedastic uncertainty is introduced as a basis for weighting losses. Furthermore, we demonstrate an application of PINNs to a practical inverse problem in tunnel engineering: prediction of external loading distributions of tunnel rings based on a limited number of displacement monitoring points. To this end, we first determine a simplified tunneling scenario at the offline stage. By setting unknown boundary conditions as learnable parameters, PINNs can predict the external loads applied on the tunnel lining with the support of enough measurement data. When it comes to the online stage in real tunnel projects, the Kriging method is adopted to reconstruct the whole displacement field based on very limited measurements. Then transfer learning is employed to fine-tune the pre-trained model from offline stage. Our results show that, although the reconstructed displacement field generated from gappy measurements is accompanied by errors, satisfactory results can still be obtained from the PINN model due to the dual regularization of physics laws and prior knowledge, which exhibits better robustness compared to traditional analysis methods. The convergence of training is also accelerated, thus making it possible for PINNs to be applied in actual tunnel projects.", "paper_url": "http://arxiv.org/abs/2205.07731v1", "pdf_url": "http://arxiv.org/pdf/2205.07731v1", "repo_url": null}, "2205.07477": {"publish_time": "2022-05-16", "title": "Manifold Characteristics That Predict Downstream Task Performance", "author": "Ruan van der Merwe et.al.", "abstract": "Pretraining methods are typically compared by evaluating the accuracy of linear classifiers, transfer learning performance, or visually inspecting the representation manifold's (RM) lower-dimensional projections. We show that the differences between methods can be understood more clearly by investigating the RM directly, which allows for a more detailed comparison. To this end, we propose a framework and new metric to measure and compare different RMs. We also investigate and report on the RM characteristics for various pretraining methods. These characteristics are measured by applying sequentially larger local alterations to the input data, using white noise injections and Projected Gradient Descent (PGD) adversarial attacks, and then tracking each datapoint. We calculate the total distance moved for each datapoint and the relative change in distance between successive alterations. We show that self-supervised methods learn an RM where alterations lead to large but constant size changes, indicating a smoother RM than fully supervised methods. We then combine these measurements into one metric, the Representation Manifold Quality Metric (RMQM), where larger values indicate larger and less variable step sizes, and show that RMQM correlates positively with performance on downstream tasks.", "paper_url": "http://arxiv.org/abs/2205.07477v1", "pdf_url": "http://arxiv.org/pdf/2205.07477v1", "repo_url": "https://github.com/bytefuse/representation-manifold-quality-metric"}, "2205.07203": {"publish_time": "2022-05-15", "title": "Fused Deep Neural Network based Transfer Learning in Occluded Face Classification and Person re-Identification", "author": "Mohamed Mohana et.al.", "abstract": "Recent period of pandemic has brought person identification even with occluded face image a great importance with increased number of mask usage. This paper aims to recognize the occlusion of one of four types in face images. Various transfer learning methods were tested, and the results show that MobileNet V2 with Gated Recurrent Unit(GRU) performs better than any other Transfer Learning methods, with a perfect accuracy of 99% in classification of images as with or without occlusion and if with occlusion, then the type of occlusion. In parallel, identifying the Region of interest from the device captured image is done. This extracted Region of interest is utilised in face identification. Such a face identification process is done using the ResNet model with its Caffe implementation. To reduce the execution time, after the face occlusion type was recognized the person was searched to confirm their face image in the registered database. The face label of the person obtained from both simultaneous processes was verified for their matching score. If the matching score was above 90, the recognized label of the person was logged into a file with their name, type of mask, date, and time of recognition. MobileNetV2 is a lightweight framework which can also be used in embedded or IoT devices to perform real time detection and identification in suspicious areas of investigations using CCTV footages. When MobileNetV2 was combined with GRU, a reliable accuracy was obtained. The data provided in the paper belong to two categories, being either collected from Google Images for occlusion classification, face recognition, and facial landmarks, or collected in fieldwork. The motive behind this research is to identify and log person details which could serve surveillance activities in society-based e-governance.", "paper_url": "http://arxiv.org/abs/2205.07203v1", "pdf_url": "http://arxiv.org/pdf/2205.07203v1", "repo_url": null}, "2205.07124": {"publish_time": "2022-05-14", "title": "Classification of Astronomical Bodies by Efficient Layer Fine-Tuning of Deep Neural Networks", "author": "Sabeesh Ethiraj et.al.", "abstract": "The SDSS-IV dataset contains information about various astronomical bodies such as Galaxies, Stars, and Quasars captured by observatories. Inspired by our work on deep multimodal learning, which utilized transfer learning to classify the SDSS-IV dataset, we further extended our research in the fine tuning of these architectures to study the effect in the classification scenario. Architectures such as Resnet-50, DenseNet-121 VGG-16, Xception, EfficientNetB2, MobileNetV2 and NasnetMobile have been built using layer wise fine tuning at different levels. Our findings suggest that freezing all layers with Imagenet weights and adding a final trainable layer may not be the optimal solution. Further, baseline models and models that have higher number of trainable layers performed similarly in certain architectures. Model need to be fine tuned at different levels and a specific training ratio is required for a model to be termed ideal. Different architectures had different responses to the change in the number of trainable layers w.r.t accuracies. While models such as DenseNet-121, Xception, EfficientNetB2 achieved peak accuracies that were relatively consistent with near perfect training curves, models such as Resnet-50,VGG-16, MobileNetV2 and NasnetMobile had lower, delayed peak accuracies with poorly fitting training curves. It was also found that though mobile neural networks have lesser parameters and model size, they may not always be ideal for deployment on a low computational device as they had consistently lower validation accuracies. Customized evaluation metrics such as Tuning Parameter Ratio and Tuning Layer Ratio are used for model evaluation.", "paper_url": "http://arxiv.org/abs/2205.07124v1", "pdf_url": "http://arxiv.org/pdf/2205.07124v1", "repo_url": null}, "2205.07121": {"publish_time": "2022-05-14", "title": "Revisiting Facial Key Point Detection: An Efficient Approach Using Deep Neural Networks", "author": "Prathima Dileep et.al.", "abstract": "Facial landmark detection is a widely researched field of deep learning as this has a wide range of applications in many fields. These key points are distinguishing characteristic points on the face, such as the eyes center, the eye's inner and outer corners, the mouth center, and the nose tip from which human emotions and intent can be explained. The focus of our work has been evaluating transfer learning models such as MobileNetV2 and NasNetMobile, including custom CNN architectures. The objective of the research has been to develop efficient deep learning models in terms of model size, parameters, and inference time and to study the effect of augmentation imputation and fine-tuning on these models. It was found that while augmentation techniques produced lower RMSE scores than imputation techniques, they did not affect the inference time. MobileNetV2 architecture produced the lowest RMSE and inference time. Moreover, our results indicate that manually optimized CNN architectures performed similarly to Auto Keras tuned architecture. However, manually optimized architectures yielded better inference time and training curves.", "paper_url": "http://arxiv.org/abs/2205.07121v1", "pdf_url": "http://arxiv.org/pdf/2205.07121v1", "repo_url": "https://github.com/bharathbolla/FKPD"}, "2205.08340": {"publish_time": "2022-05-17", "title": "A unified framework for dataset shift diagnostics", "author": "Felipe Maia Polo et.al.", "abstract": "Most machine learning (ML) methods assume that the data used in the training phase comes from the distribution of the target population. However, in practice one often faces dataset shift, which, if not properly taken into account, may decrease the predictive performance of the ML models. In general, if the practitioner knows which type of shift is taking place - e.g., covariate shift or label shift - they may apply transfer learning methods to obtain better predictions. Unfortunately, current methods for detecting shift are only designed to detect specific types of shift or cannot formally test their presence. We introduce a general framework that gives insights on how to improve prediction methods by detecting the presence of different types of shift and quantifying how strong they are. Our approach can be used for any data type (tabular/image/text) and both for classification and regression tasks. Moreover, it uses formal hypotheses tests that controls false alarms. We illustrate how our framework is useful in practice using both artificial and real datasets. Our package for dataset shift detection can be found in https://github.com/felipemaiapolo/detectshift.", "paper_url": "http://arxiv.org/abs/2205.08340v1", "pdf_url": "http://arxiv.org/pdf/2205.08340v1", "repo_url": null}, "2205.08124": {"publish_time": "2022-05-17", "title": "When to Use Multi-Task Learning vs Intermediate Fine-Tuning for Pre-Trained Encoder Transfer Learning", "author": "Orion Weller et.al.", "abstract": "Transfer learning (TL) in natural language processing (NLP) has seen a surge of interest in recent years, as pre-trained models have shown an impressive ability to transfer to novel tasks. Three main strategies have emerged for making use of multiple supervised datasets during fine-tuning: training on an intermediate task before training on the target task (STILTs), using multi-task learning (MTL) to train jointly on a supplementary task and the target task (pairwise MTL), or simply using MTL to train jointly on all available datasets (MTL-ALL). In this work, we compare all three TL methods in a comprehensive analysis on the GLUE dataset suite. We find that there is a simple heuristic for when to use one of these techniques over the other: pairwise MTL is better than STILTs when the target task has fewer instances than the supporting task and vice versa. We show that this holds true in more than 92% of applicable cases on the GLUE dataset and validate this hypothesis with experiments varying dataset size. The simplicity and effectiveness of this heuristic is surprising and warrants additional exploration by the TL community. Furthermore, we find that MTL-ALL is worse than the pairwise methods in almost every case. We hope this study will aid others as they choose between TL methods for NLP tasks.", "paper_url": "http://arxiv.org/abs/2205.08124v1", "pdf_url": "http://arxiv.org/pdf/2205.08124v1", "repo_url": null}, "2205.09048": {"publish_time": "2022-05-18", "title": "Global Contrast Masked Autoencoders Are Powerful Pathological Representation Learners", "author": "Hao Quan et.al.", "abstract": "Based on digital whole slide scanning technique, artificial intelligence algorithms represented by deep learning have achieved remarkable results in the field of computational pathology. Compared with other medical images such as Computed Tomography (CT) or Magnetic Resonance Imaging (MRI), pathological images are more difficult to annotate, thus there is an extreme lack of data sets that can be used for supervised learning. In this study, a self-supervised learning (SSL) model, Global Contrast Masked Autoencoders (GCMAE), is proposed, which has the ability to represent both global and local domain-specific features of whole slide image (WSI), as well as excellent cross-data transfer ability. The Camelyon16 and NCTCRC datasets are used to evaluate the performance of our model. When dealing with transfer learning tasks with different data sets, the experimental results show that GCMAE has better linear classification accuracy than MAE, which can reach 81.10% and 89.22% respectively. Our method outperforms the previous state-of-the-art algorithm and even surpass supervised learning (improved by 3.86% on NCTCRC data sets). The source code of this paper is publicly available at https://github.com/StarUniversus/gcmae", "paper_url": "http://arxiv.org/abs/2205.09048v1", "pdf_url": "http://arxiv.org/pdf/2205.09048v1", "repo_url": "https://github.com/staruniversus/gcmae"}, "2205.08808": {"publish_time": "2022-05-18", "title": "Evaluation of Transfer Learning for Polish with a Text-to-Text Model", "author": "Aleksandra Chrabrowa et.al.", "abstract": "We introduce a new benchmark for assessing the quality of text-to-text models for Polish. The benchmark consists of diverse tasks and datasets: KLEJ benchmark adapted for text-to-text, en-pl translation, summarization, and question answering. In particular, since summarization and question answering lack benchmark datasets for the Polish language, we describe their construction and make them publicly available. Additionally, we present plT5 - a general-purpose text-to-text model for Polish that can be fine-tuned on various Natural Language Processing (NLP) tasks with a single training objective. Unsupervised denoising pre-training is performed efficiently by initializing the model weights with a multi-lingual T5 (mT5) counterpart. We evaluate the performance of plT5, mT5, Polish BART (plBART), and Polish GPT-2 (papuGaPT2). The plT5 scores top on all of these tasks except summarization, where plBART is best. In general (except for summarization), the larger the model, the better the results. The encoder-decoder architectures prove to be better than the decoder-only equivalent.", "paper_url": "http://arxiv.org/abs/2205.08808v1", "pdf_url": "http://arxiv.org/pdf/2205.08808v1", "repo_url": null}, "2205.08755": {"publish_time": "2022-05-18", "title": "Persian Natural Language Inference: A Meta-learning approach", "author": "Heydar Soudani et.al.", "abstract": "Incorporating information from other languages can improve the results of tasks in low-resource languages. A powerful method of building functional natural language processing systems for low-resource languages is to combine multilingual pre-trained representations with cross-lingual transfer learning. In general, however, shared representations are learned separately, either across tasks or across languages. This paper proposes a meta-learning approach for inferring natural language in Persian. Alternately, meta-learning uses different task information (such as QA in Persian) or other language information (such as natural language inference in English). Also, we investigate the role of task augmentation strategy for forming additional high-quality tasks. We evaluate the proposed method using four languages and an auxiliary task. Compared to the baseline approach, the proposed model consistently outperforms it, improving accuracy by roughly six percent. We also examine the effect of finding appropriate initial parameters using zero-shot evaluation and CCA similarity.", "paper_url": "http://arxiv.org/abs/2205.08755v1", "pdf_url": "http://arxiv.org/pdf/2205.08755v1", "repo_url": "https://github.com/hassanmojab/metanli"}, "2205.08621": {"publish_time": "2022-05-17", "title": "Geographical Distance Is The New Hyperparameter: A Case Study Of Finding The Optimal Pre-trained Language For English-isiZulu Machine Translation", "author": "Muhammad Umair Nasir et.al.", "abstract": "Stemming from the limited availability of datasets and textual resources for low-resource languages such as isiZulu, there is a significant need to be able to harness knowledge from pre-trained models to improve low resource machine translation. Moreover, a lack of techniques to handle the complexities of morphologically rich languages has compounded the unequal development of translation models, with many widely spoken African languages being left behind. This study explores the potential benefits of transfer learning in an English-isiZulu translation framework. The results indicate the value of transfer learning from closely related languages to enhance the performance of low-resource translation models, thus providing a key strategy for low-resource translation going forward. We gathered results from 8 different language corpora, including one multi-lingual corpus, and saw that isiXhosa-isiZulu outperformed all languages, with a BLEU score of 8.56 on the test set which was better from the multi-lingual corpora pre-trained model by 2.73. We also derived a new coefficient, Nasir's Geographical Distance Coefficient (NGDC) which provides an easy selection of languages for the pre-trained models. NGDC also indicated that isiXhosa should be selected as the language for the pre-trained model.", "paper_url": "http://arxiv.org/abs/2205.08621v1", "pdf_url": "http://arxiv.org/pdf/2205.08621v1", "repo_url": "https://github.com/umair-nasir14/ngdc"}, "2205.08590": {"publish_time": "2022-05-17", "title": "Quantum Transfer Learning for Wi-Fi Sensing", "author": "Toshiaki Koike-Akino et.al.", "abstract": "Beyond data communications, commercial-off-the-shelf Wi-Fi devices can be used to monitor human activities, track device locomotion, and sense the ambient environment. In particular, spatial beam attributes that are inherently available in the 60-GHz IEEE 802.11ad/ay standards have shown to be effective in terms of overhead and channel measurement granularity for these indoor sensing tasks. In this paper, we investigate transfer learning to mitigate domain shift in human monitoring tasks when Wi-Fi settings and environments change over time. As a proof-of-concept study, we consider quantum neural networks (QNN) as well as classical deep neural networks (DNN) for the future quantum-ready society. The effectiveness of both DNN and QNN is validated by an in-house experiment for human pose recognition, achieving greater than 90% accuracy with a limited data size.", "paper_url": "http://arxiv.org/abs/2205.08590v1", "pdf_url": "http://arxiv.org/pdf/2205.08590v1", "repo_url": null}, "2205.09723": {"publish_time": "2022-05-19", "title": "Robust and Efficient Medical Imaging with Self-Supervision", "author": "Shekoofeh Azizi et.al.", "abstract": "Recent progress in Medical Artificial Intelligence (AI) has delivered systems that can reach clinical expert level performance. However, such systems tend to demonstrate sub-optimal \"out-of-distribution\" performance when evaluated in clinical settings different from the training environment. A common mitigation strategy is to develop separate systems for each clinical setting using site-specific data [1]. However, this quickly becomes impractical as medical data is time-consuming to acquire and expensive to annotate [2]. Thus, the problem of \"data-efficient generalization\" presents an ongoing difficulty for Medical AI development. Although progress in representation learning shows promise, their benefits have not been rigorously studied, specifically for out-of-distribution settings. To meet these challenges, we present REMEDIS, a unified representation learning strategy to improve robustness and data-efficiency of medical imaging AI. REMEDIS uses a generic combination of large-scale supervised transfer learning with self-supervised learning and requires little task-specific customization. We study a diverse range of medical imaging tasks and simulate three realistic application scenarios using retrospective data. REMEDIS exhibits significantly improved in-distribution performance with up to 11.5% relative improvement in diagnostic accuracy over a strong supervised baseline. More importantly, our strategy leads to strong data-efficient generalization of medical imaging AI, matching strong supervised baselines using between 1% to 33% of retraining data across tasks. These results suggest that REMEDIS can significantly accelerate the life-cycle of medical imaging AI development thereby presenting an important step forward for medical imaging AI to deliver broad impact.", "paper_url": "http://arxiv.org/abs/2205.09723v1", "pdf_url": "http://arxiv.org/pdf/2205.09723v1", "repo_url": "https://github.com/google-research/big_transfer"}, "2205.09328": {"publish_time": "2022-05-19", "title": "TransTab: Learning Transferable Tabular Transformers Across Tables", "author": "Zifeng Wang et.al.", "abstract": "Tabular data (or tables) are the most widely used data format in machine learning (ML). However, ML models often assume the table structure keeps fixed in training and testing. Before ML modeling, heavy data cleaning is required to merge disparate tables with different columns. This preprocessing often incurs significant data waste (e.g., removing unmatched columns and samples). How to learn ML models from multiple tables with partially overlapping columns? How to incrementally update ML models as more columns become available over time? Can we leverage model pretraining on multiple distinct tables? How to train an ML model which can predict on an unseen table?   To answer all those questions, we propose to relax fixed table structures by introducing a Transferable Tabular Transformer (TransTab) for tables. The goal of TransTab is to convert each sample (a row in the table) to a generalizable embedding vector, and then apply stacked transformers for feature encoding. One methodology insight is combining column description and table cells as the raw input to a gated transformer model. The other insight is to introduce supervised and self-supervised pretraining to improve model performance. We compare TransTab with multiple baseline methods on diverse benchmark datasets and five oncology clinical trial datasets. Overall, TransTab ranks 1.00, 1.00, 1.78 out of 12 methods in supervised learning, feature incremental learning, and transfer learning scenarios, respectively; and the proposed pretraining leads to 2.3\\% AUC lift on average over the supervised learning.}", "paper_url": "http://arxiv.org/abs/2205.09328v1", "pdf_url": "http://arxiv.org/pdf/2205.09328v1", "repo_url": "https://github.com/ryanwangzf/transtab"}, "2205.09281": {"publish_time": "2022-05-19", "title": "Causal Inference from Small High-dimensional Datasets", "author": "Raquel Aoki et.al.", "abstract": "Many methods have been proposed to estimate treatment effects with observational data. Often, the choice of the method considers the application's characteristics, such as type of treatment and outcome, confounding effect, and the complexity of the data. These methods implicitly assume that the sample size is large enough to train such models, especially the neural network-based estimators. What if this is not the case? In this work, we propose Causal-Batle, a methodology to estimate treatment effects in small high-dimensional datasets in the presence of another high-dimensional dataset in the same feature space. We adopt an approach that brings transfer learning techniques into causal inference. Our experiments show that such an approach helps to bring stability to neural network-based methods and improve the treatment effect estimates in small high-dimensional datasets.", "paper_url": "http://arxiv.org/abs/2205.09281v1", "pdf_url": "http://arxiv.org/pdf/2205.09281v1", "repo_url": null}, "2205.09513": {"publish_time": "2022-05-18", "title": "Federated Learning: Applications, Challenges and Future Scopes", "author": "Subrato Bharati et.al.", "abstract": "Federated learning (FL) is a system in which a central aggregator coordinates the efforts of multiple clients to solve machine learning problems. This setting allows training data to be dispersed in order to protect privacy. The purpose of this paper is to provide an overview of FL systems with a focus on healthcare. FL is evaluated here based on its frameworks, architectures, and applications. It is shown here that FL solves the preceding issues with a shared global deep learning (DL) model via a central aggregator server. This paper examines recent developments and provides a comprehensive list of unresolved issues, inspired by the rapid growth of FL research. In the context of FL, several privacy methods are described, including secure multiparty computation, homomorphic encryption, differential privacy, and stochastic gradient descent. Furthermore, a review of various FL classes, such as horizontal and vertical FL and federated transfer learning, is provided. FL has applications in wireless communication, service recommendation, intelligent medical diagnosis systems, and healthcare, all of which are discussed in this paper. We also present a thorough review of existing FL challenges, such as privacy protection, communication cost, system heterogeneity, and unreliable model upload, followed by future research directions.", "paper_url": "http://arxiv.org/abs/2205.09513v1", "pdf_url": "http://arxiv.org/pdf/2205.09513v1", "repo_url": null}, "2205.10279": {"publish_time": "2022-05-20", "title": "Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors", "author": "Ravid Shwartz-Ziv et.al.", "abstract": "Deep learning is increasingly moving towards a transfer learning paradigm whereby large foundation models are fine-tuned on downstream tasks, starting from an initialization learned on the source task. But an initialization contains relatively little information about the source task. Instead, we show that we can learn highly informative posteriors from the source task, through supervised or self-supervised approaches, which then serve as the basis for priors that modify the whole loss surface on the downstream task. This simple modular approach enables significant performance gains and more data-efficient learning on a variety of downstream classification and segmentation tasks, serving as a drop-in replacement for standard pre-training strategies. These highly informative priors also can be saved for future use, similar to pre-trained weights, and stand in contrast to the zero-mean isotropic uninformative priors that are typically used in Bayesian deep learning.", "paper_url": "http://arxiv.org/abs/2205.10279v1", "pdf_url": "http://arxiv.org/pdf/2205.10279v1", "repo_url": "https://github.com/hsouri/bayesiantransferlearning"}, "2205.09904": {"publish_time": "2022-05-20", "title": "Deep transfer learning for image classification: a survey", "author": "Jo Plested et.al.", "abstract": "Deep neural networks such as convolutional neural networks (CNNs) and transformers have achieved many successes in image classification in recent years. It has been consistently demonstrated that best practice for image classification is when large deep models can be trained on abundant labelled data. However there are many real world scenarios where the requirement for large amounts of training data to get the best performance cannot be met. In these scenarios transfer learning can help improve performance. To date there have been no surveys that comprehensively review deep transfer learning as it relates to image classification overall. However, several recent general surveys of deep transfer learning and ones that relate to particular specialised target image classification tasks have been published. We believe it is important for the future progress in the field that all current knowledge is collated and the overarching patterns analysed and discussed. In this survey we formally define deep transfer learning and the problem it attempts to solve in relation to image classification. We survey the current state of the field and identify where recent progress has been made. We show where the gaps in current knowledge are and make suggestions for how to progress the field to fill in these knowledge gaps. We present a new taxonomy of the applications of transfer learning for image classification. This taxonomy makes it easier to see overarching patterns of where transfer learning has been effective and, where it has failed to fulfill its potential. This also allows us to suggest where the problems lie and how it could be used more effectively. We show that under this new taxonomy, many of the applications where transfer learning has been shown to be ineffective or even hinder performance are to be expected when taking into account the source and target datasets and the techniques used.", "paper_url": "http://arxiv.org/abs/2205.09904v1", "pdf_url": "http://arxiv.org/pdf/2205.09904v1", "repo_url": null}, "2205.09850": {"publish_time": "2022-05-19", "title": "Human Gender Prediction Based on Deep Transfer Learning from Panoramic Radiograph Images", "author": "I. Atas et.al.", "abstract": "Panoramic Dental Radiography (PDR) image processing is one of the most extensively used manual methods for gender determination in forensic medicine. Manual approaches require a wide range of mandibular parameter measurements in metric units. Besides being time-consuming, these methods also necessitate the employment of experienced professionals. In this context, deep learning models are widely utilized in the auto-analysis of radiological images nowadays, owing to their high processing speed, accuracy, and stability. In our study, a data set consisting of 24,000 dental panoramic images was prepared for binary classification, and the transfer learning method was used to accelerate the training and increase the performance of our proposed DenseNet121 deep learning model. With the transfer learning method, instead of starting the learning process from scratch, the existing patterns learned beforehand were used. Extensive comparisons were made using deep transfer learning (DTL) models VGG16, ResNet50, and EfficientNetB6 to assess the classification performance of the proposed model in PDR images. According to the findings of the comparative analysis, the proposed model outperformed the other approaches by achieving a success rate of 97.25% in gender classification.", "paper_url": "http://arxiv.org/abs/2205.09850v1", "pdf_url": "http://arxiv.org/pdf/2205.09850v1", "repo_url": null}, "2205.11277": {"publish_time": "2022-05-23", "title": "When does Parameter-Efficient Transfer Learning Work for Machine Translation?", "author": "Ahmet \u00dcst\u00fcn et.al.", "abstract": "Parameter-efficient fine-tuning methods (PEFTs) offer the promise of adapting large pre-trained models while only tuning a small number of parameters. They have been shown to be competitive with full model fine-tuning for many downstream tasks. However, prior work indicates that PEFTs may not work as well for machine translation (MT), and there is no comprehensive study showing when PEFTs work for MT. We conduct a comprehensive empirical study of PEFTs for MT, considering (1) various parameter budgets, (2) a diverse set of language-pairs, and (3) different pre-trained models. We find that 'adapters', in which small feed-forward networks are added after every layer, are indeed on par with full model fine-tuning when the parameter budget corresponds to 10% of total model parameters. Nevertheless, as the number of tuned parameters decreases, the performance of PEFTs decreases. The magnitude of this decrease depends on the language pair, with PEFTs particularly struggling for distantly related language-pairs. We find that using PEFTs with a larger pre-trained model outperforms full fine-tuning with a smaller model, and for smaller training data sizes, PEFTs outperform full fine-tuning for the same pre-trained model.", "paper_url": "http://arxiv.org/abs/2205.11277v1", "pdf_url": "http://arxiv.org/pdf/2205.11277v1", "repo_url": null}, "2205.11152": {"publish_time": "2022-05-23", "title": "Cross-lingual Lifelong Learning", "author": "Meryem M'hamdi et.al.", "abstract": "The longstanding goal of multi-lingual learning has been to develop a universal cross-lingual model that can withstand the changes in multi-lingual data distributions. However, most existing models assume full access to the target languages in advance, whereas in realistic scenarios this is not often the case, as new languages can be incorporated later on. In this paper, we present the Cross-lingual Lifelong Learning (CLL) challenge, where a model is continually fine-tuned to adapt to emerging data from different languages. We provide insights into what makes multilingual sequential learning particularly challenging. To surmount such challenges, we benchmark a representative set of cross-lingual continual learning algorithms and analyze their knowledge preservation, accumulation, and generalization capabilities compared to baselines on carefully curated datastreams. The implications of this analysis include a recipe for how to measure and balance between different cross-lingual continual learning desiderata, which goes beyond conventional transfer learning.", "paper_url": "http://arxiv.org/abs/2205.11152v1", "pdf_url": "http://arxiv.org/pdf/2205.11152v1", "repo_url": null}, "2205.11108": {"publish_time": "2022-05-23", "title": "Paddy Doctor: A Visual Image Dataset for Paddy Disease Classification", "author": "Petchiammal A et.al.", "abstract": "One of the critical biotic stress factors paddy farmers face is diseases caused by bacteria, fungi, and other organisms. These diseases affect plants' health severely and lead to significant crop loss. Most of these diseases can be identified by regularly observing the leaves and stems under expert supervision. In a country with vast agricultural regions and limited crop protection experts, manual identification of paddy diseases is challenging. Thus, to add a solution to this problem, it is necessary to automate the disease identification process and provide easily accessible decision support tools to enable effective crop protection measures. However, the lack of availability of public datasets with detailed disease information limits the practical implementation of accurate disease detection systems. This paper presents Paddy Doctor, a visual image dataset for identifying paddy diseases. Our dataset contains 13,876 annotated paddy leaf images across ten classes (nine diseases and normal leaf). We benchmarked the Paddy Doctor using a Convolutional Neural Network (CNN) and two transfer learning approaches, VGG16 and MobileNet. The experimental results show that MobileNet achieves the highest classification accuracy of 93.83\\%. We release our dataset and reproducible code in the open source for community use.", "paper_url": "http://arxiv.org/abs/2205.11108v1", "pdf_url": "http://arxiv.org/pdf/2205.11108v1", "repo_url": null}, "2205.10972": {"publish_time": "2022-05-23", "title": "Global Extreme Heat Forecasting Using Neural Weather Models", "author": "Ignacio Lopez-Gomez et.al.", "abstract": "Heat waves are projected to increase in frequency and severity with global warming. Improved warning systems would help reduce the associated loss of lives, wildfires, power disruptions, and reduction in crop yields. In this work, we explore the potential for deep learning systems trained on historical data to forecast extreme heat on short, medium and subseasonal timescales. To this purpose, we train a set of neural weather models (NWMs) with convolutional architectures to forecast surface temperature anomalies globally, 1 to 28 days ahead, at $\\sim200~\\mathrm{km}$ resolution and on the cubed sphere. The NWMs are trained using the ERA5 reanalysis product and a set of candidate loss functions, including the mean squared error and exponential losses targeting extremes. We find that training models to minimize custom losses tailored to emphasize extremes leads to significant skill improvements in the heat wave prediction task, compared to NWMs trained on the mean squared error loss. This improvement is accomplished with almost no skill reduction in the general temperature prediction task, and it can be efficiently realized through transfer learning, by re-training NWMs with the custom losses for a few epochs. In addition, we find that the use of a symmetric exponential loss reduces the smoothing of NWM forecasts with lead time. Our best NWM is able to outperform persistence in a regressive sense for all lead times and temperature anomaly thresholds considered, and shows positive regressive skill compared to the ECMWF subseasonal-to-seasonal control forecast within the first two forecast days and after two weeks.", "paper_url": "http://arxiv.org/abs/2205.10972v1", "pdf_url": "http://arxiv.org/pdf/2205.10972v1", "repo_url": null}, "2205.10964": {"publish_time": "2022-05-22", "title": "The Geometry of Multilingual Language Model Representations", "author": "Tyler A. Chang et.al.", "abstract": "We assess how multilingual language models maintain a shared multilingual representation space while still encoding language-sensitive information in each language. Using XLM-R as a case study, we show that languages occupy similar linear subspaces after mean-centering, evaluated based on causal effects on language modeling performance and direct comparisons between subspaces for 88 languages. The subspace means differ along language-sensitive axes that are relatively stable throughout middle layers, and these axes encode information such as token vocabularies. Shifting representations by language means is sufficient to induce token predictions in different languages. However, we also identify stable language-neutral axes that encode information such as token positions and part-of-speech. We visualize representations projected onto language-sensitive and language-neutral axes, identifying language family and part-of-speech clusters, along with spirals, toruses, and curves representing token position information. These results demonstrate that multilingual language models encode information along orthogonal language-sensitive and language-neutral axes, allowing the models to extract a variety of features for downstream tasks and cross-lingual transfer learning.", "paper_url": "http://arxiv.org/abs/2205.10964v1", "pdf_url": "http://arxiv.org/pdf/2205.10964v1", "repo_url": null}, "2205.12253": {"publish_time": "2022-05-24", "title": "Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing", "author": "Linlu Qiu et.al.", "abstract": "Despite their strong performance on many tasks, pre-trained language models have been shown to struggle on out-of-distribution compositional generalization. Meanwhile, recent work has shown considerable improvements on many NLP tasks from model scaling. Can scaling up model size also improve compositional generalization in semantic parsing? We evaluate encoder-decoder models up to 11B parameters and decoder-only models up to 540B parameters, and compare model scaling curves for three different methods for transfer learning: fine-tuning all parameters, prompt tuning, and in-context learning. We observe that fine-tuning generally has flat or negative scaling curves on out-of-distribution compositional generalization in semantic parsing evaluations. In-context learning has positive scaling curves, but is generally outperformed by much smaller fine-tuned models. Prompt-tuning can outperform fine-tuning, suggesting further potential improvements from scaling as it exhibits a more positive scaling curve. Additionally, we identify several error trends that vary with model scale. For example, larger models are generally better at modeling the syntax of the output space, but are also more prone to certain types of overfitting. Overall, our study highlights limitations of current techniques for effectively leveraging model scale for compositional generalization, while our analysis also suggests promising directions for future work.", "paper_url": "http://arxiv.org/abs/2205.12253v1", "pdf_url": "http://arxiv.org/pdf/2205.12253v1", "repo_url": null}, "2205.12148": {"publish_time": "2022-05-24", "title": "Hyper-X: A Unified Hypernetwork for Multi-Task Multilingual Transfer", "author": "Ahmet \u00dcst\u00fcn et.al.", "abstract": "Massively multilingual models are promising for transfer learning across tasks and languages. However, existing methods are unable to fully leverage training data when it is available in different task-language combinations. To exploit such heterogeneous supervision we propose Hyper-X, a unified hypernetwork that generates weights for parameter-efficient adapter modules conditioned on both tasks and language embeddings. By learning to combine task and language-specific knowledge our model enables zero-shot transfer for unseen languages and task-language combinations. Our experiments on a diverse set of languages demonstrate that Hyper-X achieves the best gain when a mixture of multiple resources is available while performing on par with strong baselines in the standard scenario. Finally, Hyper-X consistently produces strong results in few-shot scenarios for new languages and tasks showing the effectiveness of our approach beyond zero-shot transfer.", "paper_url": "http://arxiv.org/abs/2205.12148v1", "pdf_url": "http://arxiv.org/pdf/2205.12148v1", "repo_url": null}, "2205.12052": {"publish_time": "2022-05-24", "title": "On statistic alignment for domain adaptation in structural health monitoring", "author": "Jack Poole et.al.", "abstract": "The practical application of structural health monitoring (SHM) is often limited by the availability of labelled data. Transfer learning - specifically in the form of domain adaptation (DA) - gives rise to the possibility of leveraging information from a population of physical or numerical structures, by inferring a mapping that aligns the feature spaces. Typical DA methods rely on nonparametric distance metrics, which require sufficient data to perform density estimation. In addition, these methods can be prone to performance degradation under class imbalance. To address these issues, statistic alignment (SA) is discussed, with a demonstration of how these methods can be made robust to class imbalance, including a special case of class imbalance called a partial DA scenario. SA is demonstrated to facilitate damage localisation with no target labels in a numerical case study, outperforming other state-of-the-art DA methods. It is then shown to be capable of aligning the feature spaces of a real heterogeneous population, the Z24 and KW51 bridges, with only 220 samples used from the KW51 bridge. Finally, in scenarios where more complex mappings are required for knowledge transfer, SA is shown to be a vital pre-processing tool, increasing the performance of established DA methods.", "paper_url": "http://arxiv.org/abs/2205.12052v1", "pdf_url": "http://arxiv.org/pdf/2205.12052v1", "repo_url": "https://github.com/Jack-Poole/Statistic-Alignment"}, "2205.11935": {"publish_time": "2022-05-24", "title": "CryptoTL: Private, efficient and secure transfer learning", "author": "Roman Walch et.al.", "abstract": "Big data has been a pervasive catchphrase in recent years, but dealing with data scarcity has become a crucial question for many real-world deep learning (DL) applications. A popular methodology to efficiently enable the training of DL models to perform tasks in scenarios where only a small dataset is available is transfer learning (TL). TL allows knowledge transfer from a general domain to a specific target one; however, such a knowledge transfer may put privacy at risk when it comes to sensitive or private data. With CryptoTL we introduce a solution to this problem, and show for the first time a cryptographic privacy-preserving TL approach based on homomorphic encryption that is efficient and feasible for real-world use cases. We demonstrate this by focusing on classification tasks with small datasets and show the applicability of our approach for sentiment analysis. Additionally we highlight how our approach can be combined with differential privacy to further increase the security guarantees. Our extensive benchmarks show that using CryptoTL leads to high accuracy while still having practical fine-tuning and classification runtimes despite using homomorphic encryption. Concretely, one forward-pass through the encrypted layers of our setup takes roughly 1s on a notebook CPU.", "paper_url": "http://arxiv.org/abs/2205.11935v1", "pdf_url": "http://arxiv.org/pdf/2205.11935v1", "repo_url": null}, "2205.11690": {"publish_time": "2022-05-24", "title": "Workflow Discovery from Dialogues in the Low Data Regime", "author": "Amine El Hattami et.al.", "abstract": "Text-based dialogues are now widely used to solve real-world problems. In cases where solution strategies are already known, they can sometimes be codified into workflows and used to guide humans or artificial agents through the task of helping clients. We are interested in the situation where a formal workflow may not yet exist, but we wish to discover the steps of actions that have been taken to resolve problems. We examine a novel transformer-based approach for this situation and we present experiments where we summarize dialogues in the Action-Based Conversations Dataset (ABCD) with workflows. Since the ABCD dialogues were generated using known workflows to guide agents we can evaluate our ability to extract such workflows using ground truth sequences of action steps, organized as workflows. We propose and evaluate an approach that conditions models on the set of allowable action steps and we show that using this strategy we can improve workflow discovery (WD) performance. Our conditioning approach also improves zero-shot and few-shot WD performance when transferring learned models to entirely new domains (i.e. the MultiWOZ setting). Further, a modified variant of our architecture achieves state-of-the-art performance on the related but different problems of Action State Tracking (AST) and Cascading Dialogue Success (CDS) on the ABCD.", "paper_url": "http://arxiv.org/abs/2205.11690v1", "pdf_url": "http://arxiv.org/pdf/2205.11690v1", "repo_url": null}, "2205.12900": {"publish_time": "2022-05-25", "title": "Differentially Private Data Generation Needs Better Features", "author": "Fredrik Harder et.al.", "abstract": "Training even moderately-sized generative models with differentially-private stochastic gradient descent (DP-SGD) is difficult: the required level of noise for reasonable levels of privacy is simply too large. We advocate instead building off a good, relevant representation on public data, then using private data only for \"transfer learning.\" In particular, we minimize the maximum mean discrepancy (MMD) between private target data and the generated distribution, using a kernel based on perceptual features from a public dataset. With the MMD, we can simply privatize the data-dependent term once and for all, rather than introducing noise at each step of optimization as in DP-SGD. Our algorithm allows us to generate CIFAR10-level images faithfully with $\\varepsilon \\approx 2$, far surpassing the current state of the art, which only models MNIST and FashionMNIST at $\\varepsilon \\approx 10$. Our work introduces simple yet powerful foundations for reducing the gap between private and non-private deep generative models.", "paper_url": "http://arxiv.org/abs/2205.12900v1", "pdf_url": "http://arxiv.org/pdf/2205.12900v1", "repo_url": null}, "2205.12647": {"publish_time": "2022-05-25", "title": "Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation", "author": "Tu Vu et.al.", "abstract": "In this paper, we explore the challenging problem of performing a generative task (i.e., summarization) in a target language when labeled data is only available in English. We assume a strict setting with no access to parallel data or machine translation. Prior work has shown, and we confirm, that standard transfer learning techniques struggle in this setting, as a generative multilingual model fine-tuned purely on English catastrophically forgets how to generate non-English. Given the recent rise of parameter-efficient adaptation techniques (e.g., prompt tuning), we conduct the first investigation into how well these methods can overcome catastrophic forgetting to enable zero-shot cross-lingual generation. We find that parameter-efficient adaptation provides gains over standard fine-tuning when transferring between less-related languages, e.g., from English to Thai. However, a significant gap still remains between these methods and fully-supervised baselines. To improve cross-lingual transfer further, we explore three approaches: (1) mixing in unlabeled multilingual data, (2) pre-training prompts on target language data, and (3) explicitly factoring prompts into recombinable language and task components. Our methods can provide further quality gains, suggesting that robust zero-shot cross-lingual generation is within reach.", "paper_url": "http://arxiv.org/abs/2205.12647v1", "pdf_url": "http://arxiv.org/pdf/2205.12647v1", "repo_url": null}, "2205.12453": {"publish_time": "2022-05-25", "title": "Know Where You're Going: Meta-Learning for Parameter-Efficient Fine-tuning", "author": "Mozhdeh Gheini et.al.", "abstract": "A recent family of techniques, dubbed as lightweight fine-tuning methods, facilitates parameter-efficient transfer learning by updating only a small set of additional parameters while keeping the parameters of the pretrained language model frozen. While proven to be an effective method, there are no existing studies on if and how such knowledge of the downstream fine-tuning approach should affect the pretraining stage. In this work, we show that taking the ultimate choice of fine-tuning method into consideration boosts the performance of parameter-efficient fine-tuning. By relying on optimization-based meta-learning using MAML with certain modifications for our distinct purpose, we prime the pretrained model specifically for parameter-efficient fine-tuning, resulting in gains of up to 1.7 points on cross-lingual NER fine-tuning. Our ablation settings and analyses further reveal that the tweaks we introduce in MAML are crucial for the attained gains.", "paper_url": "http://arxiv.org/abs/2205.12453v1", "pdf_url": "http://arxiv.org/pdf/2205.12453v1", "repo_url": null}, "2205.12411": {"publish_time": "2022-05-24", "title": "Linear Connectivity Reveals Generalization Strategies", "author": "Jeevesh Juneja et.al.", "abstract": "It is widely accepted in the mode connectivity literature that when two neural networks are trained similarly on the same data, they are connected by a path through parameter space over which test set accuracy is maintained. Under some circumstances, including transfer learning from pretrained models, these paths are presumed to be linear. In contrast to existing results, we find that among text classifiers (trained on MNLI, QQP, and CoLA), some pairs of finetuned models have large barriers of increasing loss on the linear paths between them. On each task, we find distinct clusters of models which are linearly connected on the test loss surface, but are disconnected from models outside the cluster -- models that occupy separate basins on the surface. By measuring performance on specially-crafted diagnostic datasets, we find that these clusters correspond to different generalization strategies: one cluster behaves like a bag of words model under domain shift, while another cluster uses syntactic heuristics. Our work demonstrates how the geometry of the loss surface can guide models towards different heuristic functions.", "paper_url": "http://arxiv.org/abs/2205.12411v1", "pdf_url": "http://arxiv.org/pdf/2205.12411v1", "repo_url": "https://github.com/anonwhymoos/connectivity"}, "2205.12342": {"publish_time": "2022-05-24", "title": "Face2Text revisited: Improved data set and baseline results", "author": "Marc Tanti et.al.", "abstract": "Current image description generation models do not transfer well to the task of describing human faces. To encourage the development of more human-focused descriptions, we developed a new data set of facial descriptions based on the CelebA image data set. We describe the properties of this data set, and present results from a face description generator trained on it, which explores the feasibility of using transfer learning from VGGFace/ResNet CNNs. Comparisons are drawn through both automated metrics and human evaluation by 76 English-speaking participants. The descriptions generated by the VGGFace-LSTM + Attention model are closest to the ground truth according to human evaluation whilst the ResNet-LSTM + Attention model obtained the highest CIDEr and CIDEr-D results (1.252 and 0.686 respectively). Together, the new data set and these experimental results provide data and baselines for future work in this area.", "paper_url": "http://arxiv.org/abs/2205.12342v1", "pdf_url": "http://arxiv.org/pdf/2205.12342v1", "repo_url": null}, "2205.13519": {"publish_time": "2022-05-26", "title": "Transfer learning driven design optimization for inertial confinement fusion", "author": "K. D. Humbird et.al.", "abstract": "Transfer learning is a promising approach to creating predictive models that incorporate simulation and experimental data into a common framework. In this technique, a neural network is first trained on a large database of simulations, then partially retrained on sparse sets of experimental data to adjust predictions to be more consistent with reality. Previously, this technique has been used to create predictive models of Omega and NIF inertial confinement fusion (ICF) experiments that are more accurate than simulations alone. In this work, we conduct a transfer learning driven hypothetical ICF campaign in which the goal is to maximize experimental neutron yield via Bayesian optimization. The transfer learning model achieves yields within 5% of the maximum achievable yield in a modest-sized design space in fewer than 20 experiments. Furthermore, we demonstrate that this method is more efficient at optimizing designs than traditional model calibration techniques commonly employed in ICF design. Such an approach to ICF design could enable robust optimization of experimental performance under uncertainty.", "paper_url": "http://arxiv.org/abs/2205.13519v1", "pdf_url": "http://arxiv.org/pdf/2205.13519v1", "repo_url": null}, "2205.13150": {"publish_time": "2022-05-26", "title": "Semantically Supervised Appearance Decomposition for Virtual Staging from a Single Panorama", "author": "Tiancheng Zhi et.al.", "abstract": "We describe a novel approach to decompose a single panorama of an empty indoor environment into four appearance components: specular, direct sunlight, diffuse and diffuse ambient without direct sunlight. Our system is weakly supervised by automatically generated semantic maps (with floor, wall, ceiling, lamp, window and door labels) that have shown success on perspective views and are trained for panoramas using transfer learning without any further annotations. A GAN-based approach supervised by coarse information obtained from the semantic map extracts specular reflection and direct sunlight regions on the floor and walls. These lighting effects are removed via a similar GAN-based approach and a semantic-aware inpainting step. The appearance decomposition enables multiple applications including sun direction estimation, virtual furniture insertion, floor material replacement, and sun direction change, providing an effective tool for virtual home staging. We demonstrate the effectiveness of our approach on a large and recently released dataset of panoramas of empty homes.", "paper_url": "http://arxiv.org/abs/2205.13150v1", "pdf_url": "http://arxiv.org/pdf/2205.13150v1", "repo_url": "https://github.com/tiancheng-zhi/pano_decomp"}, "2205.13961": {"publish_time": "2022-05-27", "title": "Punctuation Restoration in Spanish Customer Support Transcripts using Transfer Learning", "author": "Xiliang Zhu et.al.", "abstract": "Automatic Speech Recognition (ASR) systems typically produce unpunctuated transcripts that have poor readability. In addition, building a punctuation restoration system is challenging for low-resource languages, especially for domain-specific applications. In this paper, we propose a Spanish punctuation restoration system designed for a real-time customer support transcription service. To address the data sparsity of Spanish transcripts in the customer support domain, we introduce two transfer-learning-based strategies: 1) domain adaptation using out-of-domain Spanish text data; 2) cross-lingual transfer learning leveraging in-domain English transcript data. Our experiment results show that these strategies improve the accuracy of the Spanish punctuation restoration system.", "paper_url": "http://arxiv.org/abs/2205.13961v1", "pdf_url": "http://arxiv.org/pdf/2205.13961v1", "repo_url": null}, "2205.13774": {"publish_time": "2022-05-27", "title": "Classification of COVID-19 Patients with their Severity Level from Chest CT Scans using Transfer Learning", "author": "Mansi Gupta et.al.", "abstract": "Background and Objective: During pandemics, the use of artificial intelligence (AI) approaches combined with biomedical science play a significant role in reducing the burden on the healthcare systems and physicians. The rapid increment in cases of COVID-19 has led to an increase in demand for hospital beds and other medical equipment. However, since medical facilities are limited, it is recommended to diagnose patients as per the severity of the infection. Keeping this in mind, we share our research in detecting COVID-19 as well as assessing its severity using chest-CT scans and Deep Learning pre-trained models. Dataset: We have collected a total of 1966 CT Scan images for three different class labels, namely, Non-COVID, Severe COVID, and Non-Severe COVID, out of which 714 CT images belong to the Non-COVID category, 713 CT images are for Non-Severe COVID category and 539 CT images are of Severe COVID category. Methods: All of the images are initially pre-processed using the Contrast Limited Histogram Equalization (CLAHE) approach. The pre-processed images are then fed into the VGG-16 network for extracting features. Finally, the retrieved characteristics are categorized and the accuracy is evaluated using a support vector machine (SVM) with 10-fold cross-validation (CV). Result and Conclusion: In our study, we have combined well-known strategies for pre-processing, feature extraction, and classification which brings us to a remarkable success rate of disease and its severity recognition with an accuracy of 96.05% (97.7% for Non-Severe COVID-19 images and 93% for Severe COVID-19 images). Our model can therefore help radiologists detect COVID-19 and the extent of its severity.", "paper_url": "http://arxiv.org/abs/2205.13774v1", "pdf_url": "http://arxiv.org/pdf/2205.13774v1", "repo_url": null}, "2205.13769": {"publish_time": "2022-05-27", "title": "Semantic-aware Dense Representation Learning for Remote Sensing Image Change Detection", "author": "Hao Chen et.al.", "abstract": "Training deep learning-based change detection (CD) model heavily depends on labeled data. Contemporary transfer learning-based methods to alleviate the CD label insufficiency mainly upon ImageNet pre-training. A recent trend is using remote sensing (RS) data to obtain in-domain representations via supervised or self-supervised learning (SSL). Here, different from traditional supervised pre-training that learns the mapping from image to label, we leverage semantic supervision in a contrastive manner. There are typically multiple objects of interest (e.g., buildings) distributed in varying locations in RS images. We propose dense semantic-aware pre-training for RS image CD via sampling multiple class-balanced points. Instead of manipulating image-level representations that lack spatial information, we constrain pixel-level cross-view consistency and cross-semantic discrimination to learn spatially-sensitive features, thus benefiting downstream dense CD. Apart from learning illumination invariant features, we fulfill consistent foreground features insensitive to irrelevant background changes via a synthetic view using background swapping. We additionally achieve discriminative representations to distinguish foreground land-covers and others. We collect large-scale image-mask pairs freely available in the RS community for pre-training. Extensive experiments on three CD datasets verify the effectiveness of our method. Ours significantly outperforms ImageNet, in-domain supervision, and several SSL methods. Empirical results indicate ours well alleviates data insufficiency in CD. Notably, we achieve competitive results using only 20% training data than baseline (random) using 100% data. Both quantitative and qualitative results demonstrate the generalization ability of our pre-trained model to downstream images even remaining domain gaps with the pre-training data. Our Code will make public.", "paper_url": "http://arxiv.org/abs/2205.13769v1", "pdf_url": "http://arxiv.org/pdf/2205.13769v1", "repo_url": null}, "2205.13607": {"publish_time": "2022-05-26", "title": "Self-supervised Pretraining and Transfer Learning Enable Flu and COVID-19 Predictions in Small Mobile Sensing Datasets", "author": "Mike A. Merrill et.al.", "abstract": "Detailed mobile sensing data from phones, watches, and fitness trackers offer an unparalleled opportunity to quantify and act upon previously unmeasurable behavioral changes in order to improve individual health and accelerate responses to emerging diseases. Unlike in natural language processing and computer vision, deep representation learning has yet to broadly impact this domain, in which the vast majority of research and clinical applications still rely on manually defined features and boosted tree models or even forgo predictive modeling altogether due to insufficient accuracy. This is due to unique challenges in the behavioral health domain, including very small datasets (~10^1 participants), which frequently contain missing data, consist of long time series with critical long-range dependencies (length>10^4), and extreme class imbalances (>10^3:1).", "paper_url": "http://arxiv.org/abs/2205.13607v1", "pdf_url": "http://arxiv.org/pdf/2205.13607v1", "repo_url": null}, "2205.14949": {"publish_time": "2022-05-30", "title": "HiViT: Hierarchical Vision Transformer Meets Masked Image Modeling", "author": "Xiaosong Zhang et.al.", "abstract": "Recently, masked image modeling (MIM) has offered a new methodology of self-supervised pre-training of vision transformers. A key idea of efficient implementation is to discard the masked image patches (or tokens) throughout the target network (encoder), which requires the encoder to be a plain vision transformer (e.g., ViT), albeit hierarchical vision transformers (e.g., Swin Transformer) have potentially better properties in formulating vision inputs. In this paper, we offer a new design of hierarchical vision transformers named HiViT (short for Hierarchical ViT) that enjoys both high efficiency and good performance in MIM. The key is to remove the unnecessary \"local inter-unit operations\", deriving structurally simple hierarchical vision transformers in which mask-units can be serialized like plain vision transformers. For this purpose, we start with Swin Transformer and (i) set the masking unit size to be the token size in the main stage of Swin Transformer, (ii) switch off inter-unit self-attentions before the main stage, and (iii) eliminate all operations after the main stage. Empirical studies demonstrate the advantageous performance of HiViT in terms of fully-supervised, self-supervised, and transfer learning. In particular, in running MAE on ImageNet-1K, HiViT-B reports a +0.6% accuracy gain over ViT-B and a 1.9$\\times$ speed-up over Swin-B, and the performance gain generalizes to downstream tasks of detection and segmentation. Code will be made publicly available.", "paper_url": "http://arxiv.org/abs/2205.14949v1", "pdf_url": "http://arxiv.org/pdf/2205.14949v1", "repo_url": null}, "2205.14856": {"publish_time": "2022-05-30", "title": "Underwater Acoustic Communication Channel Modeling using Reservoir Computing", "author": "Oluwaseyi Onasami et.al.", "abstract": "Underwater acoustic (UWA) communications have been widely used but greatly impaired due to the complicated nature of the underwater environment. In order to improve UWA communications, modeling and understanding the UWA channel is indispensable. However, there exist many challenges due to the high uncertainties of the underwater environment and the lack of real-world measurement data. In this work, the capability of reservoir computing and deep learning has been explored for modeling the UWA communication channel accurately using real underwater data collected from a water tank with disturbance and from Lake Tahoe. We leverage the capability of reservoir computing for modeling dynamical systems and provided a data-driven approach to modeling the UWA channel using Echo State Network (ESN). In addition, the potential application of transfer learning to reservoir computing has been examined. Experimental results show that ESN is able to model chaotic UWA channels with better performance compared to popular deep learning models in terms of mean absolute percentage error (MAPE), specifically, ESN has outperformed deep neural network by 2% and as much as 40% in benign and chaotic UWA respectively.", "paper_url": "http://arxiv.org/abs/2205.14856v1", "pdf_url": "http://arxiv.org/pdf/2205.14856v1", "repo_url": null}, "2205.14553": {"publish_time": "2022-05-29", "title": "A Model of One-Shot Generalization", "author": "Thomas Laurent et.al.", "abstract": "We provide a theoretical framework to study a phenomenon that we call one-shot generalization. This phenomenon refers to the ability of an algorithm to perform transfer learning within a single task, meaning that it correctly classifies a test point that has a single exemplar in the training set. We propose a simple data model and use it to study this phenomenon in two ways. First, we prove a non-asymptotic base-line -- kernel methods based on nearest-neighbor classification cannot perform one-shot generalization, independently of the choice of the kernel and the size of the training set. Second, we empirically show that the most direct neural network architecture for our data model performs one-shot generalization almost perfectly. This stark differential leads us to believe that the one-shot generalization mechanism is partially responsible for the empirical success of neural networks.", "paper_url": "http://arxiv.org/abs/2205.14553v1", "pdf_url": "http://arxiv.org/pdf/2205.14553v1", "repo_url": null}, "2205.14520": {"publish_time": "2022-05-28", "title": "Transfer Learning as a Method to Reproduce High-Fidelity NLTE Opacities in Simulations", "author": "Michael D. Vander Wal et.al.", "abstract": "Simulations of high-energy density physics often need non-local thermodynamic equilibrium (NLTE) opacity data. This data, however, is expensive to produce at relatively low-fidelity. It is even more so at high-fidelity such that the opacity calculations can contribute ninety-five percent of the total computation time. This proportion can even reach large proportions. Neural networks can be used to replace the standard calculations of low-fidelity data, and the neural networks can be trained to reproduce artificial, high-fidelity opacity spectra. In this work, it is demonstrated that a novel neural network architecture trained to reproduce high-fidelity krypton spectra through transfer learning can be used in simulations. Further, it is demonstrated that this can be done while achieving a relative percent error of the peak radiative temperature of the hohlraum of approximately 1\\% to 4\\% while achieving a 19.4x speed up.", "paper_url": "http://arxiv.org/abs/2205.14520v1", "pdf_url": "http://arxiv.org/pdf/2205.14520v1", "repo_url": null}, "2205.14442": {"publish_time": "2022-05-28", "title": "Looks Like Magic: Transfer Learning in GANs to Generate New Card Illustrations", "author": "Matheus K. Venturelli et.al.", "abstract": "In this paper, we propose MAGICSTYLEGAN and MAGICSTYLEGAN-ADA - both incarnations of the state-of-the-art models StyleGan2 and StyleGan2 ADA - to experiment with their capacity of transfer learning into a rather different domain: creating new illustrations for the vast universe of the game \"Magic: The Gathering\" cards. This is a challenging task especially due to the variety of elements present in these illustrations, such as humans, creatures, artifacts, and landscapes - not to mention the plethora of art styles of the images made by various artists throughout the years. To solve the task at hand, we introduced a novel dataset, named MTG, with thousands of illustration from diverse card types and rich in metadata. The resulting set is a dataset composed by a myriad of both realistic and fantasy-like illustrations. Although, to investigate effects of diversity we also introduced subsets that contain specific types of concepts, such as forests, islands, faces, and humans. We show that simpler models, such as DCGANs, are not able to learn to generate proper illustrations in any setting. On the other side, we train instances of MAGICSTYLEGAN using all proposed subsets, being able to generate high quality illustrations. We perform experiments to understand how well pre-trained features from StyleGan2 can be transferred towards the target domain. We show that in well trained models we can find particular instances of noise vector that realistically represent real images from the dataset. Moreover, we provide both quantitative and qualitative studies to support our claims, and that demonstrate that MAGICSTYLEGAN is the state-of-the-art approach for generating Magic illustrations. Finally, this paper highlights some emerging properties regarding transfer learning in GANs, which is still a somehow under-explored field in generative learning research.", "paper_url": "http://arxiv.org/abs/2205.14442v1", "pdf_url": "http://arxiv.org/pdf/2205.14442v1", "repo_url": null}, "2205.15523": {"publish_time": "2022-05-31", "title": "Variational Transfer Learning using Cross-Domain Latent Modulation", "author": "Jinyong Hou et.al.", "abstract": "To successfully apply trained neural network models to new domains, powerful transfer learning solutions are essential. We propose to introduce a novel cross-domain latent modulation mechanism to a variational autoencoder framework so as to achieve effective transfer learning. Our key idea is to procure deep representations from one data domain and use it to influence the reparameterization of the latent variable of another domain. Specifically, deep representations of the source and target domains are first extracted by a unified inference model and aligned by employing gradient reversal. The learned deep representations are then cross-modulated to the latent encoding of the alternative domain, where consistency constraints are also applied. In the empirical validation that includes a number of transfer learning benchmark tasks for unsupervised domain adaptation and image-to-image translation, our model demonstrates competitive performance, which is also supported by evidence obtained from visualization.", "paper_url": "http://arxiv.org/abs/2205.15523v1", "pdf_url": "http://arxiv.org/pdf/2205.15523v1", "repo_url": null}, "2206.00432": {"publish_time": "2022-06-01", "title": "Evaluating Gaussian Grasp Maps for Generative Grasping Models", "author": "William Prew et.al.", "abstract": "Generalising robotic grasping to previously unseen objects is a key task in general robotic manipulation. The current method for training many antipodal generative grasping models rely on a binary ground truth grasp map generated from the centre thirds of correctly labelled grasp rectangles. However, these binary maps do not accurately reflect the positions in which a robotic arm can correctly grasp a given object. We propose a continuous Gaussian representation of annotated grasps to generate ground truth training data which achieves a higher success rate on a simulated robotic grasping benchmark. Three modern generative grasping networks are trained with either binary or Gaussian grasp maps, along with recent advancements from the robotic grasping literature, such as discretisation of grasp angles into bins and an attentional loss function. Despite negligible difference according to the standard rectangle metric, Gaussian maps better reproduce the training data and therefore improve success rates when tested on the same simulated robot arm by avoiding collisions with the object: achieving 87.94\\% accuracy. Furthermore, the best performing model is shown to operate with a high success rate when transferred to a real robotic arm, at high inference speeds, without the need for transfer learning. The system is then shown to be capable of performing grasps on an antagonistic physical object dataset benchmark.", "paper_url": "http://arxiv.org/abs/2206.00432v1", "pdf_url": "http://arxiv.org/pdf/2206.00432v1", "repo_url": null}, "2206.00395": {"publish_time": "2022-06-01", "title": "Optimization with access to auxiliary information", "author": "El Mahdi Chayti et.al.", "abstract": "We investigate the fundamental optimization question of minimizing a target function $f(x)$ whose gradients are expensive to compute or have limited availability, given access to some auxiliary side function $h(x)$ whose gradients are cheap or more available. This formulation captures many settings of practical relevance such as i) re-using batches in SGD, ii) transfer learning, iii) federated learning, iv) training with compressed models/dropout, etc. We propose two generic new algorithms which are applicable in all these settings and prove using only an assumption on the Hessian similarity between the target and side information that we can benefit from this framework.", "paper_url": "http://arxiv.org/abs/2206.00395v1", "pdf_url": "http://arxiv.org/pdf/2206.00395v1", "repo_url": "https://github.com/elmahdichayti/optauxinf"}, "2206.00388": {"publish_time": "2022-06-01", "title": "Transfer without Forgetting", "author": "Matteo Boschini et.al.", "abstract": "This work investigates the entanglement between Continual Learning (CL) and Transfer Learning (TL). In particular, we shed light on the widespread application of network pretraining, highlighting that it is itself subject to catastrophic forgetting. Unfortunately, this issue leads to the under-exploitation of knowledge transfer during later tasks. On this ground, we propose Transfer without Forgetting (TwF), a hybrid Continual Transfer Learning approach building upon a fixed pretrained sibling network, which continuously propagates the knowledge inherent in the source domain through a layer-wise loss term. Our experiments indicate that TwF steadily outperforms other CL methods across a variety of settings, averaging a 4.81% gain in Class-Incremental accuracy over a variety of datasets and different buffer sizes.", "paper_url": "http://arxiv.org/abs/2206.00388v1", "pdf_url": "http://arxiv.org/pdf/2206.00388v1", "repo_url": "https://github.com/mbosc/twf"}, "2206.00338": {"publish_time": "2022-06-01", "title": "CellCentroidFormer: Combining Self-attention and Convolution for Cell Detection", "author": "Royden Wagner et.al.", "abstract": "Cell detection in microscopy images is important to study how cells move and interact with their environment. Most recent deep learning-based methods for cell detection use convolutional neural networks (CNNs). However, inspired by the success in other computer vision applications, vision transformers (ViTs) are also used for this purpose. We propose a novel hybrid CNN-ViT model for cell detection in microscopy images to exploit the advantages of both types of deep learning models. We employ an efficient CNN, that was pre-trained on the ImageNet dataset, to extract image features and utilize transfer learning to reduce the amount of required training data. Extracted image features are further processed by a combination of convolutional and transformer layers, so that the convolutional layers can focus on local information and the transformer layers on global information. Our centroid-based cell detection method represents cells as ellipses and is end-to-end trainable. Furthermore, we show that our proposed model can outperform a fully convolutional baseline model on four different 2D microscopy datasets. Code is available at: https://github.com/roydenwa/cell-centroid-former", "paper_url": "http://arxiv.org/abs/2206.00338v1", "pdf_url": "http://arxiv.org/pdf/2206.00338v1", "repo_url": "https://github.com/roydenwa/cell-centroid-former"}, "2206.00305": {"publish_time": "2022-06-01", "title": "Supervised Denoising of Diffusion-Weighted Magnetic Resonance Images Using a Convolutional Neural Network and Transfer Learning", "author": "Jakub Jurek et.al.", "abstract": "In this paper, we propose a method for denoising diffusion-weighted images (DWI) of the brain using a convolutional neural network trained on realistic, synthetic MR data. We compare our results to averaging of repeated scans, a widespread method used in clinics to improve signal-to-noise ratio of MR images. To obtain training data for transfer learning, we model, in a data-driven fashion, the effects of echo-planar imaging (EPI): Nyquist ghosting and ramp sampling. We introduce these effects to the digital phantom of brain anatomy (BrainWeb). Instead of simulating pseudo-random noise with a defined probability distribution, we perform noise scans with a brain-DWI-designed protocol to obtain realistic noise maps. We combine them with the simulated, noise-free EPI images. We also measure the Point Spread Function in a DW image of an AJR-approved geometrical phantom and inter-scan movement in a brain scan of a healthy volunteer. Their influence on image denoising and averaging of repeated images is investigated at different signal-to-noise ratio levels. Denoising performance is evaluated quantitatively using the simulated EPI images and qualitatively in real EPI DWI of the brain. We show that the application of our method allows for a significant reduction in scan time by lowering the number of repeated scans. Visual comparisons made in the acquired brain images indicate that the denoised single-repetition images are less noisy than multi-repetition averaged images. We also analyse the convolutional neural network denoiser and point out the challenges accompanying this denoising method.", "paper_url": "http://arxiv.org/abs/2206.00305v1", "pdf_url": "http://arxiv.org/pdf/2206.00305v1", "repo_url": null}, "2206.01087": {"publish_time": "2022-06-02", "title": "Enriching a Fashion Knowledge Graph from Product Textual Descriptions", "author": "Jo\u00e3o Barroca et.al.", "abstract": "Knowledge Graphs offer a very useful and powerful structure for representing information, consequently, they have been adopted as the backbone for many applications in e-commerce scenarios. In this paper, we describe an application of existing techniques for enriching thelarge-scale Fashion Knowledge Graph (FKG) that we build at Farfetch. In particular, we apply techniques for named entity recognition (NER) and entity linking (EL) in order to extract and link rich metadata from product textual descriptions to entities in the FKG. Having a complete and enriched FKG as an e-commerce backbone can have a highly valuable impact on downstream applications such as search and recommendations. However, enriching a Knowledge Graph in the fashion domain has its own challenges. Data representation is different from a more generic KG, like Wikidata and Yago, as entities (e.g. product attributes) are too specific to the domain, and long textual descriptions are not readily available. Data itself is also scarce, as labelling datasets to train supervised models is a very laborious task. Even more, fashion products display a high variability and require an intricate ontology of attributes to link to. We use a transfer learning based approach to train an NER module on a small amount of manually labeled data, followed by an EL module that links the previously identified named entities to the appropriate entities within the FKG. Experiments using a pre-trained model show that it is possible to achieve 89.75% accuracy in NER even with a small manually labeled dataset. Moreover, the EL module, despite relying on simple rule-based or ML models (due to lack of training data), is able to link relevant attributes to products, thus automatically enriching the FKG.", "paper_url": "http://arxiv.org/abs/2206.01087v1", "pdf_url": "http://arxiv.org/pdf/2206.01087v1", "repo_url": null}, "2206.00962": {"publish_time": "2022-06-02", "title": "Transfer Language Selection for Zero-Shot Cross-Lingual Abusive Language Detection", "author": "Juuso Eronen et.al.", "abstract": "We study the selection of transfer languages for automatic abusive language detection. Instead of preparing a dataset for every language, we demonstrate the effectiveness of cross-lingual transfer learning for zero-shot abusive language detection. This way we can use existing data from higher-resource languages to build better detection systems for low-resource languages. Our datasets are from seven different languages from three language families. We measure the distance between the languages using several language similarity measures, especially by quantifying the World Atlas of Language Structures. We show that there is a correlation between linguistic similarity and classifier performance. This discovery allows us to choose an optimal transfer language for zero shot abusive language detection.", "paper_url": "http://arxiv.org/abs/2206.00962v1", "pdf_url": "http://arxiv.org/pdf/2206.00962v1", "repo_url": null}, "2206.01618": {"publish_time": "2022-06-03", "title": "A transformer-based synthetic-inflow generator for spatially-developing turbulent boundary layers", "author": "Mustafa Z. Yousif et.al.", "abstract": "This study proposes a newly-developed deep-learning-based method to generate turbulent inflow conditions for spatially-developing turbulent boundary layer (TBL) simulations. A combination of a transformer and a multiscale-enhanced super-resolution generative adversarial network is utilized to predict velocity fields of a spatially-developing TBL at various planes normal to the streamwise direction. Datasets of direct numerical simulation (DNS) of flat plate flow spanning a momentum thickness-based Reynolds number, Re_theta = 661.5 - 1502.0, are used to train and test the model. The model shows a remarkable ability to predict the instantaneous velocity fields with detailed fluctuations and reproduce the turbulence statistics as well as spatial and temporal spectra with commendable accuracy as compared with the DNS results. The proposed model also exhibits a reasonable accuracy for predicting velocity fields at Reynolds numbers that are not used in the training process. With the aid of transfer learning, the computational cost of the proposed model is considered to be effectively low. The results demonstrate, for the first time that transformer-based models can be efficient in predicting the dynamics of turbulent flows. It also shows that combining these models with generative adversarial networks-based models can be useful in tackling various turbulence-related problems, including the development of efficient synthetic-turbulent inflow generators.", "paper_url": "http://arxiv.org/abs/2206.01618v1", "pdf_url": "http://arxiv.org/pdf/2206.01618v1", "repo_url": null}, "2206.01408": {"publish_time": "2022-06-03", "title": "MetaLR: Layer-wise Learning Rate based on Meta-Learning for Adaptively Fine-tuning Medical Pre-trained Models", "author": "Yixiong Chen et.al.", "abstract": "When applying transfer learning for medical image analysis, downstream tasks often have significant gaps with the pre-training tasks. Previous methods mainly focus on improving the transferabilities of the pre-trained models to bridge the gaps. In fact, model fine-tuning can also play a very important role in tackling this problem. A conventional fine-tuning method is updating all deep neural networks (DNNs) layers by a single learning rate (LR), which ignores the unique transferabilities of different layers. In this work, we explore the behaviors of different layers in the fine-tuning stage. More precisely, we first hypothesize that lower-level layers are more domain-specific while higher-level layers are more task-specific, which is verified by a simple bi-directional fine-tuning scheme. It is harder for the pre-trained specific layers to transfer to new tasks than general layers. On this basis, to make different layers better co-adapt to the downstream tasks according to their transferabilities, a meta-learning-based LR learner, namely MetaLR, is proposed to assign LRs for each layer automatically. Extensive experiments on various medical applications (i.e., POCUS, BUSI, Chest X-ray, and LiTS) well confirm our hypothesis and show the superior performance of the proposed methods to previous state-of-the-art fine-tuning methods.", "paper_url": "http://arxiv.org/abs/2206.01408v1", "pdf_url": "http://arxiv.org/pdf/2206.01408v1", "repo_url": null}, "2206.01369": {"publish_time": "2022-06-03", "title": "Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation", "author": "Chenyu You et.al.", "abstract": "Many medical datasets have recently been created for medical image segmentation tasks, and it is natural to question whether we can use them to sequentially train a single model that (1) performs better on all these datasets, and (2) generalizes well and transfers better to the unknown target site domain. Prior works have achieved this goal by jointly training one model on multi-site datasets, which achieve competitive performance on average but such methods rely on the assumption about the availability of all training data, thus limiting its effectiveness in practical deployment. In this paper, we propose a novel multi-site segmentation framework called incremental-transfer learning (ITL), which learns a model from multi-site datasets in an end-to-end sequential fashion. Specifically, \"incremental\" refers to training sequentially constructed datasets, and \"transfer\" is achieved by leveraging useful information from the linear combination of embedding features on each dataset. In addition, we introduce our ITL framework, where we train the network including a site-agnostic encoder with pre-trained weights and at most two segmentation decoder heads. We also design a novel site-level incremental loss in order to generalize well on the target domain. Second, we show for the first time that leveraging our ITL training scheme is able to alleviate challenging catastrophic forgetting problems in incremental learning. We conduct experiments using five challenging benchmark datasets to validate the effectiveness of our incremental-transfer learning approach. Our approach makes minimal assumptions on computation resources and domain-specific expertise, and hence constitutes a strong starting point in multi-site medical image segmentation.", "paper_url": "http://arxiv.org/abs/2206.01369v1", "pdf_url": "http://arxiv.org/pdf/2206.01369v1", "repo_url": null}, "2206.01323": {"publish_time": "2022-06-02", "title": "SPD domain-specific batch normalization to crack interpretable unsupervised domain adaptation in EEG", "author": "Reinmar J Kobler et.al.", "abstract": "Electroencephalography (EEG) provides access to neuronal dynamics non-invasively with millisecond resolution, rendering it a viable method in neuroscience and healthcare. However, its utility is limited as current EEG technology does not generalize well across domains (i.e., sessions and subjects) without expensive supervised re-calibration. Contemporary methods cast this transfer learning (TL) problem as a multi-source/-target unsupervised domain adaptation (UDA) problem and address it with deep learning or shallow, Riemannian geometry aware alignment methods. Both directions have, so far, failed to consistently close the performance gap to state-of-the-art domain-specific methods based on tangent space mapping (TSM) on the symmetric positive definite (SPD) manifold. Here, we propose a theory-based machine learning framework that enables, for the first time, learning domain-invariant TSM models in an end-to-end fashion. To achieve this, we propose a new building block for geometric deep learning, which we denote SPD domain-specific momentum batch normalization (SPDDSMBN). A SPDDSMBN layer can transform domain-specific SPD inputs into domain-invariant SPD outputs, and can be readily applied to multi-source/-target and online UDA scenarios. In extensive experiments with 6 diverse EEG brain-computer interface (BCI) datasets, we obtain state-of-the-art performance in inter-session and -subject TL with a simple, intrinsically interpretable network architecture, which we denote TSMNet.", "paper_url": "http://arxiv.org/abs/2206.01323v1", "pdf_url": "http://arxiv.org/pdf/2206.01323v1", "repo_url": null}, "2206.01319": {"publish_time": "2022-06-02", "title": "Learning Unbiased Transferability for Domain Adaptation by Uncertainty Modeling", "author": "Jian Hu et.al.", "abstract": "Domain adaptation (DA) aims to transfer knowledge learned from a labeled source domain to an unlabeled or a less labeled but related target domain. Ideally, the source and target distributions should be aligned to each other equally to achieve unbiased knowledge transfer. However, due to the significant imbalance between the amount of annotated data in the source and target domains, usually only the target distribution is aligned to the source domain, leading to adapting unnecessary source specific knowledge to the target domain, i.e., biased domain adaptation. To resolve this problem, in this work, we delve into the transferability estimation problem in domain adaptation and propose a non-intrusive Unbiased Transferability Estimation Plug-in (UTEP) by modeling the uncertainty of a discriminator in adversarial-based DA methods to optimize unbiased transfer. We theoretically analyze the effectiveness of the proposed approach to unbiased transferability learning in DA. Furthermore, to alleviate the impact of imbalanced annotated data, we utilize the estimated uncertainty for pseudo label selection of unlabeled samples in the target domain, which helps achieve better marginal and conditional distribution alignments between domains. Extensive experimental results on a high variety of DA benchmark datasets show that the proposed approach can be readily incorporated into various adversarial-based DA methods, achieving state-of-the-art performance.", "paper_url": "http://arxiv.org/abs/2206.01319v1", "pdf_url": "http://arxiv.org/pdf/2206.01319v1", "repo_url": null}, "2206.02663": {"publish_time": "2022-06-06", "title": "TransBO: Hyperparameter Optimization via Two-Phase Transfer Learning", "author": "Yang Li et.al.", "abstract": "With the extensive applications of machine learning models, automatic hyperparameter optimization (HPO) has become increasingly important. Motivated by the tuning behaviors of human experts, it is intuitive to leverage auxiliary knowledge from past HPO tasks to accelerate the current HPO task. In this paper, we propose TransBO, a novel two-phase transfer learning framework for HPO, which can deal with the complementary nature among source tasks and dynamics during knowledge aggregation issues simultaneously. This framework extracts and aggregates source and target knowledge jointly and adaptively, where the weights can be learned in a principled manner. The extensive experiments, including static and dynamic transfer learning settings and neural architecture search, demonstrate the superiority of TransBO over the state-of-the-arts.", "paper_url": "http://arxiv.org/abs/2206.02663v1", "pdf_url": "http://arxiv.org/pdf/2206.02663v1", "repo_url": null}, "2206.02659": {"publish_time": "2022-06-06", "title": "Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees", "author": "Haotian Ju et.al.", "abstract": "We consider transfer learning approaches that fine-tune a pretrained deep neural network on a target task. We investigate generalization properties of fine-tuning to understand the problem of overfitting, which often happens in practice. Previous works have shown that constraining the distance from the initialization of fine-tuning improves generalization. Using a PAC-Bayesian analysis, we observe that besides distance from initialization, Hessians affect generalization through the noise stability of deep neural networks against noise injections. Motivated by the observation, we develop Hessian distance-based generalization bounds for a wide range of fine-tuning methods. Next, we investigate the robustness of fine-tuning with noisy labels. We design an algorithm that incorporates consistent losses and distance-based regularization for fine-tuning. Additionally, we prove a generalization error bound of our algorithm under class conditional independent noise in the training dataset labels. We perform a detailed empirical study of our algorithm on various noisy environments and architectures. For example, on six image classification tasks whose training labels are generated with programmatic labeling, we show a 3.26% accuracy improvement over prior methods. Meanwhile, the Hessian distance measure of the fine-tuned network using our algorithm decreases by six times more than existing approaches.", "paper_url": "http://arxiv.org/abs/2206.02659v1", "pdf_url": "http://arxiv.org/pdf/2206.02659v1", "repo_url": null}, "2206.02625": {"publish_time": "2022-06-06", "title": "Study of transfer learning from 2D supercritical airfoils to 3D transonic swept wings", "author": "Runze Li et.al.", "abstract": "Machine learning has been widely utilized in fluid mechanics studies and aerodynamic optimizations. However, most applications, especially flow field modeling and inverse design, involve two-dimensional flows and geometries. The dimensionality of three-dimensional problems is so high that it is too difficult and expensive to prepare sufficient samples. Therefore, transfer learning has become a promising approach to reuse well-trained two-dimensional models and greatly reduce the need for samples for three-dimensional problems. This paper proposes to reuse the baseline models trained on supercritical airfoils to predict finite-span swept supercritical wings, where the simple swept theory is embedded to improve the prediction accuracy. Two baseline models for transfer learning are investigated: one is commonly referred to as the forward problem of predicting the pressure coefficient distribution based on the geometry, and the other is the inverse problem that predicts the geometry based on the pressure coefficient distribution. Two transfer learning strategies are compared for both baseline models. The transferred models are then tested on the prediction of complete wings. The results show that transfer learning requires only approximately 500 wing samples to achieve good prediction accuracy on different wing planforms and different free stream conditions. Compared to the two baseline models, the transferred models reduce the prediction error by 60% and 80%, respectively.", "paper_url": "http://arxiv.org/abs/2206.02625v1", "pdf_url": "http://arxiv.org/pdf/2206.02625v1", "repo_url": null}, "2206.02622": {"publish_time": "2022-06-06", "title": "Hardware-accelerated Mars Sample Localization via deep transfer learning from photorealistic simulations", "author": "Ra\u00fal Castilla-Arquillo et.al.", "abstract": "The goal of the Mars Sample Return campaign is to collect soil samples from the surface of Mars and return them to Earth for further study. The samples will be acquired and stored in metal tubes by the Perseverance rover and deposited on the Martian surface. As part of this campaign, it is expected the Sample Fetch Rover will be in charge of localizing and gathering up to 35 sample tubes over 150 Martian sols. Autonomous capabilities are critical for the success of the overall campaign and for the Sample Fetch Rover in particular. This work proposes a novel approach for the autonomous detection and pose estimation of the sample tubes. For the detection stage, a Deep Neural Network and transfer learning from a synthetic dataset are proposed. The dataset is created from photorealistic 3D simulations of Martian scenarios. Additionally, Computer Vision techniques are used to estimate the detected sample tubes poses. Finally, laboratory tests of the Sample Localization procedure are performed using the ExoMars Testing Rover on a Mars-like testbed. These tests validate the proposed approach in different hardware architectures, providing promising results related to the sample detection and pose estimation.", "paper_url": "http://arxiv.org/abs/2206.02622v1", "pdf_url": "http://arxiv.org/pdf/2206.02622v1", "repo_url": "https://github.com/spaceuma/marssamplelocalization"}, "2206.02511": {"publish_time": "2022-06-06", "title": "Transfer Learning based Search Space Design for Hyperparameter Tuning", "author": "Yang Li et.al.", "abstract": "The tuning of hyperparameters becomes increasingly important as machine learning (ML) models have been extensively applied in data mining applications. Among various approaches, Bayesian optimization (BO) is a successful methodology to tune hyper-parameters automatically. While traditional methods optimize each tuning task in isolation, there has been recent interest in speeding up BO by transferring knowledge across previous tasks. In this work, we introduce an automatic method to design the BO search space with the aid of tuning history from past tasks. This simple yet effective approach can be used to endow many existing BO methods with transfer learning capabilities. In addition, it enjoys the three advantages: universality, generality, and safeness. The extensive experiments show that our approach considerably boosts BO by designing a promising and compact search space instead of using the entire space, and outperforms the state-of-the-arts on a wide range of benchmarks, including machine learning and deep learning tuning tasks, and neural architecture search.", "paper_url": "http://arxiv.org/abs/2206.02511v1", "pdf_url": "http://arxiv.org/pdf/2206.02511v1", "repo_url": null}, "2206.03467": {"publish_time": "2022-06-07", "title": "Discrete State-Action Abstraction via the Successor Representation", "author": "Amnon Attali et.al.", "abstract": "When reinforcement learning is applied with sparse rewards, agents must spend a prohibitively long time exploring the unknown environment without any learning signal. Abstraction is one approach that provides the agent with an intrinsic reward for transitioning in a latent space. Prior work focuses on dense continuous latent spaces, or requires the user to manually provide the representation. Our approach is the first for automatically learning a discrete abstraction of the underlying environment. Moreover, our method works on arbitrary input spaces, using an end-to-end trainable regularized successor representation model. For transitions between abstract states, we train a set of temporally extended actions in the form of options, i.e., an action abstraction. Our proposed algorithm, Discrete State-Action Abstraction (DSAA), iteratively swaps between training these options and using them to efficiently explore more of the environment to improve the state abstraction. As a result, our model is not only useful for transfer learning but also in the online learning setting. We empirically show that our agent is able to explore the environment and solve provided tasks more efficiently than baseline reinforcement learning algorithms. Our code is publicly available at \\url{https://github.com/amnonattali/dsaa}.", "paper_url": "http://arxiv.org/abs/2206.03467v1", "pdf_url": "http://arxiv.org/pdf/2206.03467v1", "repo_url": "https://github.com/amnonattali/dsaa"}, "2206.03198": {"publish_time": "2022-06-07", "title": "Explaining the physics of transfer learning a data-driven subgrid-scale closure to a different turbulent flow", "author": "Adam Subel et.al.", "abstract": "Transfer learning (TL) is becoming a powerful tool in scientific applications of neural networks (NNs), such as weather/climate prediction and turbulence modeling. TL enables out-of-distribution generalization (e.g., extrapolation in parameters) and effective blending of disparate training sets (e.g., simulations and observations). In TL, selected layers of a NN, already trained for a base system, are re-trained using a small dataset from a target system. For effective TL, we need to know 1) what are the best layers to re-train? and 2) what physics are learned during TL? Here, we present novel analyses and a new framework to address (1)-(2) for a broad range of multi-scale, nonlinear systems. Our approach combines spectral analyses of the systems' data with spectral analyses of convolutional NN's activations and kernels, explaining the inner-workings of TL in terms of the system's nonlinear physics. Using subgrid-scale modeling of several setups of 2D turbulence as test cases, we show that the learned kernels are combinations of low-, band-, and high-pass filters, and that TL learns new filters whose nature is consistent with the spectral differences of base and target systems. We also find the shallowest layers are the best to re-train in these cases, which is against the common wisdom guiding TL in machine learning literature. Our framework identifies the best layer(s) to re-train beforehand, based on physics and NN theory. Together, these analyses explain the physics learned in TL and provide a framework to guide TL for wide-ranging applications in science and engineering, such as climate change modeling.", "paper_url": "http://arxiv.org/abs/2206.03198v1", "pdf_url": "http://arxiv.org/pdf/2206.03198v1", "repo_url": null}, "2206.03726": {"publish_time": "2022-06-08", "title": "Hub-Pathway: Transfer Learning from A Hub of Pre-trained Models", "author": "Yang Shu et.al.", "abstract": "Transfer learning aims to leverage knowledge from pre-trained models to benefit the target task. Prior transfer learning work mainly transfers from a single model. However, with the emergence of deep models pre-trained from different resources, model hubs consisting of diverse models with various architectures, pre-trained datasets and learning paradigms are available. Directly applying single-model transfer learning methods to each model wastes the abundant knowledge of the model hub and suffers from high computational cost. In this paper, we propose a Hub-Pathway framework to enable knowledge transfer from a model hub. The framework generates data-dependent pathway weights, based on which we assign the pathway routes at the input level to decide which pre-trained models are activated and passed through, and then set the pathway aggregation at the output level to aggregate the knowledge from different models to make predictions. The proposed framework can be trained end-to-end with the target task-specific loss, where it learns to explore better pathway configurations and exploit the knowledge in pre-trained models for each target datum. We utilize a noisy pathway generator and design an exploration loss to further explore different pathways throughout the model hub. To fully exploit the knowledge in pre-trained models, each model is further trained by specific data that activate it, which ensures its performance and enhances knowledge transfer. Experiment results on computer vision and reinforcement learning tasks demonstrate that the proposed Hub-Pathway framework achieves the state-of-the-art performance for model hub transfer learning.", "paper_url": "http://arxiv.org/abs/2206.03726v1", "pdf_url": "http://arxiv.org/pdf/2206.03726v1", "repo_url": null}, "2206.03715": {"publish_time": "2022-06-08", "title": "Modularized Transfer Learning with Multiple Knowledge Graphs for Zero-shot Commonsense Reasoning", "author": "Yu Jin Kim et.al.", "abstract": "Commonsense reasoning systems should be able to generalize to diverse reasoning cases. However, most state-of-the-art approaches depend on expensive data annotations and overfit to a specific benchmark without learning how to perform general semantic reasoning. To overcome these drawbacks, zero-shot QA systems have shown promise as a robust learning scheme by transforming a commonsense knowledge graph (KG) into synthetic QA-form samples for model training. Considering the increasing type of different commonsense KGs, this paper aims to extend the zero-shot transfer learning scenario into multiple-source settings, where different KGs can be utilized synergetically. Towards this goal, we propose to mitigate the loss of knowledge from the interference among the different knowledge sources, by developing a modular variant of the knowledge aggregation as a new zero-shot commonsense reasoning framework. Results on five commonsense reasoning benchmarks demonstrate the efficacy of our framework, improving the performance with multiple KGs.", "paper_url": "http://arxiv.org/abs/2206.03715v1", "pdf_url": "http://arxiv.org/pdf/2206.03715v1", "repo_url": null}, "2206.03950": {"publish_time": "2022-06-07", "title": "Transfer learning to decode brain states reflecting the relationship between cognitive tasks", "author": "Youzhi Qu et.al.", "abstract": "Transfer learning improves the performance of the target task by leveraging the data of a specific source task: the closer the relationship between the source and the target tasks, the greater the performance improvement by transfer learning. In neuroscience, the relationship between cognitive tasks is usually represented by similarity of activated brain regions or neural representation. However, no study has linked transfer learning and neuroscience to reveal the relationship between cognitive tasks. In this study, we propose a transfer learning framework to reflect the relationship between cognitive tasks, and compare the task relations reflected by transfer learning and by the overlaps of brain regions (e.g., neurosynth). Our results of transfer learning create cognitive taskonomy to reflect the relationship between cognitive tasks which is well in line with the task relations derived from neurosynth. Transfer learning performs better in task decoding with fMRI data if the source and target cognitive tasks activate similar brain regions. Our study uncovers the relationship of multiple cognitive tasks and provides guidance for source task selection in transfer learning for neural decoding based on small-sample data.", "paper_url": "http://arxiv.org/abs/2206.03950v1", "pdf_url": "http://arxiv.org/pdf/2206.03950v1", "repo_url": null}, "2206.04325": {"publish_time": "2022-06-09", "title": "CFA: Coupled-hypersphere-based Feature Adaptation for Target-Oriented Anomaly Localization", "author": "Sungwook Lee et.al.", "abstract": "For a long time, anomaly localization has been widely used in industries. Previous studies focused on approximating the distribution of normal features without adaptation to a target dataset. However, since anomaly localization should precisely discriminate normal and abnormal features, the absence of adaptation may make the normality of abnormal features overestimated. Thus, we propose Coupled-hypersphere-based Feature Adaptation (CFA) which accomplishes sophisticated anomaly localization using features adapted to the target dataset. CFA consists of (1) a learnable patch descriptor that learns and embeds target-oriented features and (2) scalable memory bank independent of the size of the target dataset. And, CFA adopts transfer learning to increase the normal feature density so that abnormal features can be clearly distinguished by applying patch descriptor and memory bank to a pre-trained CNN. The proposed method outperforms the previous methods quantitatively and qualitatively. For example, it provides an AUROC score of 99.5% in anomaly detection and 98.5% in anomaly localization of MVTec AD benchmark. In addition, this paper points out the negative effects of biased features of pre-trained CNNs and emphasizes the importance of the adaptation to the target dataset. The code is publicly available at https://github.com/sungwool/CFA_for_anomaly_localization.", "paper_url": "http://arxiv.org/abs/2206.04325v1", "pdf_url": "http://arxiv.org/pdf/2206.04325v1", "repo_url": "https://github.com/sungwool/cfa_for_anomaly_localization"}, "2206.04277": {"publish_time": "2022-06-09", "title": "On Transfer Learning in Functional Linear Regression", "author": "Haotian Lin et.al.", "abstract": "This work studies the problem of transfer learning under the functional linear model framework, which aims to improve the fit of the target model by leveraging the knowledge from related source models. We measure the relatedness between target and source models using Reproducing Kernel Hilbert Spaces, allowing the type of knowledge being transferred to be interpreted by the structure of the spaces. Two algorithms are proposed: one transfers knowledge when the index of transferable sources is known, while the other one utilizes aggregation to achieve knowledge transfer without prior information about the sources. Furthermore, we establish the optimal convergence rates for excess risk, making the statistical gain via transfer learning mathematically provable. The effectiveness of the proposed algorithms is demonstrated on synthetic data as well as real financial data.", "paper_url": "http://arxiv.org/abs/2206.04277v1", "pdf_url": "http://arxiv.org/pdf/2206.04277v1", "repo_url": null}, "2206.04877": {"publish_time": "2022-06-10", "title": "Efficient Per-Shot Convex Hull Prediction By Recurrent Learning", "author": "Somdyuti Paul et.al.", "abstract": "Adaptive video streaming relies on the construction of efficient bitrate ladders to deliver the best possible visual quality to viewers under bandwidth constraints. The traditional method of content dependent bitrate ladder selection requires a video shot to be pre-encoded with multiple encoding parameters to find the optimal operating points given by the convex hull of the resulting rate-quality curves. However, this pre-encoding step is equivalent to an exhaustive search process over the space of possible encoding parameters, which causes significant overhead in terms of both computation and time expenditure. To reduce this overhead, we propose a deep learning based method of content aware convex hull prediction. We employ a recurrent convolutional network (RCN) to implicitly analyze the spatiotemporal complexity of video shots in order to predict their convex hulls. A two-step transfer learning scheme is adopted to train our proposed RCN-Hull model, which ensures sufficient content diversity to analyze scene complexity, while also making it possible capture the scene statistics of pristine source videos. Our experimental results reveal that our proposed model yields better approximations of the optimal convex hulls, and offers competitive time savings as compared to existing approaches. On average, the pre-encoding time was reduced by 58.0% by our method, while the average Bjontegaard delta bitrate (BD-rate) of the predicted convex hulls against ground truth was 0.08%, while the mean absolute deviation of the BD-rate distribution was 0.44%", "paper_url": "http://arxiv.org/abs/2206.04877v1", "pdf_url": "http://arxiv.org/pdf/2206.04877v1", "repo_url": null}, "2206.04762": {"publish_time": "2022-06-09", "title": "Data-Efficient Double-Win Lottery Tickets from Robust Pre-training", "author": "Tianlong Chen et.al.", "abstract": "Pre-training serves as a broadly adopted starting point for transfer learning on various downstream tasks. Recent investigations of lottery tickets hypothesis (LTH) demonstrate such enormous pre-trained models can be replaced by extremely sparse subnetworks (a.k.a. matching subnetworks) without sacrificing transferability. However, practical security-crucial applications usually pose more challenging requirements beyond standard transfer, which also demand these subnetworks to overcome adversarial vulnerability. In this paper, we formulate a more rigorous concept, Double-Win Lottery Tickets, in which a located subnetwork from a pre-trained model can be independently transferred on diverse downstream tasks, to reach BOTH the same standard and robust generalization, under BOTH standard and adversarial training regimes, as the full pre-trained model can do. We comprehensively examine various pre-training mechanisms and find that robust pre-training tends to craft sparser double-win lottery tickets with superior performance over the standard counterparts. For example, on downstream CIFAR-10/100 datasets, we identify double-win matching subnetworks with the standard, fast adversarial, and adversarial pre-training from ImageNet, at 89.26%/73.79%, 89.26%/79.03%, and 91.41%/83.22% sparsity, respectively. Furthermore, we observe the obtained double-win lottery tickets can be more data-efficient to transfer, under practical data-limited (e.g., 1% and 10%) downstream schemes. Our results show that the benefits from robust pre-training are amplified by the lottery ticket scheme, as well as the data-limited transfer setting. Codes are available at https://github.com/VITA-Group/Double-Win-LTH.", "paper_url": "http://arxiv.org/abs/2206.04762v1", "pdf_url": "http://arxiv.org/pdf/2206.04762v1", "repo_url": "https://github.com/vita-group/double-win-lth"}, "2206.06355": {"publish_time": "2022-06-13", "title": "Anomaly Detection and Inter-Sensor Transfer Learning on Smart Manufacturing Datasets", "author": "Mustafa Abdallah et.al.", "abstract": "Smart manufacturing systems are being deployed at a growing rate because of their ability to interpret a wide variety of sensed information and act on the knowledge gleaned from system observations. In many cases, the principal goal of the smart manufacturing system is to rapidly detect (or anticipate) failures to reduce operational cost and eliminate downtime. This often boils down to detecting anomalies within the sensor date acquired from the system. The smart manufacturing application domain poses certain salient technical challenges. In particular, there are often multiple types of sensors with varying capabilities and costs. The sensor data characteristics change with the operating point of the environment or machines, such as, the RPM of the motor. The anomaly detection process therefore has to be calibrated near an operating point. In this paper, we analyze four datasets from sensors deployed from manufacturing testbeds. We evaluate the performance of several traditional and ML-based forecasting models for predicting the time series of sensor data. Then, considering the sparse data from one kind of sensor, we perform transfer learning from a high data rate sensor to perform defect type classification. Taken together, we show that predictive failure classification can be achieved, thus paving the way for predictive maintenance.", "paper_url": "http://arxiv.org/abs/2206.06355v1", "pdf_url": "http://arxiv.org/pdf/2206.06355v1", "repo_url": null}, "2206.06190": {"publish_time": "2022-06-13", "title": "TransRec: Learning Transferable Recommendation from Mixture-of-Modality Feedback", "author": "Jie Wang et.al.", "abstract": "Learning big models and then transfer has become the de facto practice in computer vision (CV) and natural language processing (NLP). However, such unified paradigm is uncommon for recommender systems (RS). A critical issue that hampers this is that standard recommendation models are built on unshareable identity data, where both users and their interacted items are represented by unique IDs. In this paper, we study a novel scenario where user's interaction feedback involves mixture-of-modality (MoM) items. We present TransRec, a straightforward modification done on the popular ID-based RS framework. TransRec directly learns from MoM feedback in an end-to-end manner, and thus enables effective transfer learning under various scenarios without relying on overlapped users or items. We empirically study the transferring ability of TransRec across four different real-world recommendation settings. Besides, we study its effects by scaling the size of source and target data. Our results suggest that learning recommenders from MoM feedback provides a promising way to realize universal recommender systems. Our code and datasets will be made available.", "paper_url": "http://arxiv.org/abs/2206.06190v1", "pdf_url": "http://arxiv.org/pdf/2206.06190v1", "repo_url": null}, "2206.06067": {"publish_time": "2022-06-13", "title": "Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge Distillation", "author": "Zengyu Qiu et.al.", "abstract": "Knowledge distillation (KD) has shown very promising capabilities in transferring learning representations from large models (teachers) to small models (students). However, as the capacity gap between students and teachers becomes larger, existing KD methods fail to achieve better results. Our work shows that the 'prior knowledge' is vital to KD, especially when applying large teachers. Particularly, we propose the dynamic prior knowledge (DPK), which integrates part of the teacher's features as the prior knowledge before the feature distillation. This means that our method also takes the teacher's feature as `input', not just `target'. Besides, we dynamically adjust the ratio of the prior knowledge during the training phase according to the feature gap, thus guiding the student in an appropriate difficulty. To evaluate the proposed method, we conduct extensive experiments on two image classification benchmarks (i.e. CIFAR100 and ImageNet) and an object detection benchmark (i.e. MS COCO). The results demonstrate the superiority of our method in performance under varying settings. More importantly, our DPK makes the performance of the student model is positively correlated with that of the teacher model, which means that we can further boost the accuracy of students by applying larger teachers. Our codes will be publicly available for the reproducibility.", "paper_url": "http://arxiv.org/abs/2206.06067v1", "pdf_url": "http://arxiv.org/pdf/2206.06067v1", "repo_url": null}, "2206.05853": {"publish_time": "2022-06-12", "title": "Modeling Generalized Specialist Approach To Train Quality Resilient Snapshot Ensemble", "author": "Ghalib Ahmed Tahir et.al.", "abstract": "Convolutional neural networks (CNNs) apply well with food image recognition due to the ability to learn discriminative visual features. Nevertheless, recognizing distorted images is challenging for existing CNNs. Hence, the study modelled a generalized specialist approach to train a quality resilient ensemble. The approach aids the models in the ensemble framework retain general skills of recognizing clean images and shallow skills of classifying noisy images with one deep expertise area on a particular distortion. Subsequently, a novel data augmentation random quality mixup (RQMixUp) is combined with snapshot ensembling to train G-Specialist. During each training cycle of G-Specialist, a model is fine-tuned on the synthetic images generated by RQMixup, intermixing clean and distorted images of a particular distortion at a randomly chosen level. Resultantly, each snapshot in the ensemble gained expertise on several distortion levels, with shallow skills on other quality distortions. Next, the filter outputs from diverse experts were fused for higher accuracy. The learning process has no additional cost due to a single training process to train experts, compatible with a wide range of supervised CNNs for transfer learning. Finally, the experimental analysis on three real-world food and a Malaysian food database showed significant improvement for distorted images with competitive classification performance on pristine food images.", "paper_url": "http://arxiv.org/abs/2206.05853v1", "pdf_url": "http://arxiv.org/pdf/2206.05853v1", "repo_url": "https://github.com/ghalib2021/-g-specialist"}, "2206.05703": {"publish_time": "2022-06-12", "title": "PAC-Net: A Model Pruning Approach to Inductive Transfer Learning", "author": "Sanghoon Myung et.al.", "abstract": "Inductive transfer learning aims to learn from a small amount of training data for the target task by utilizing a pre-trained model from the source task. Most strategies that involve large-scale deep learning models adopt initialization with the pre-trained model and fine-tuning for the target task. However, when using over-parameterized models, we can often prune the model without sacrificing the accuracy of the source task. This motivates us to adopt model pruning for transfer learning with deep learning models. In this paper, we propose PAC-Net, a simple yet effective approach for transfer learning based on pruning. PAC-Net consists of three steps: Prune, Allocate, and Calibrate (PAC). The main idea behind these steps is to identify essential weights for the source task, fine-tune on the source task by updating the essential weights, and then calibrate on the target task by updating the remaining redundant weights. Under the various and extensive set of inductive transfer learning experiments, we show that our method achieves state-of-the-art performance by a large margin.", "paper_url": "http://arxiv.org/abs/2206.05703v1", "pdf_url": "http://arxiv.org/pdf/2206.05703v1", "repo_url": null}, "2206.06862": {"publish_time": "2022-06-14", "title": "Evaluating histopathology transfer learning with ChampKit", "author": "Jakub R. Kaczmarzyk et.al.", "abstract": "Histopathology remains the gold standard for diagnosis of various cancers. Recent advances in computer vision, specifically deep learning, have facilitated the analysis of histopathology images for various tasks, including immune cell detection and microsatellite instability classification. The state-of-the-art for each task often employs base architectures that have been pretrained for image classification on ImageNet. The standard approach to develop classifiers in histopathology tends to focus narrowly on optimizing models for a single task, not considering the aspects of modeling innovations that improve generalization across tasks. Here we present ChampKit (Comprehensive Histopathology Assessment of Model Predictions toolKit): an extensible, fully reproducible benchmarking toolkit that consists of a broad collection of patch-level image classification tasks across different cancers. ChampKit enables a way to systematically document the performance impact of proposed improvements in models and methodology. ChampKit source code and data are freely accessible at https://github.com/kaczmarj/champkit .", "paper_url": "http://arxiv.org/abs/2206.06862v1", "pdf_url": "http://arxiv.org/pdf/2206.06862v1", "repo_url": "https://github.com/kaczmarj/champkit"}, "2206.06817": {"publish_time": "2022-06-14", "title": "Physics-Informed Transfer Learning Strategy to Accelerate Unsteady Fluid Flow Simulations", "author": "Joongoo Jeon et.al.", "abstract": "Since the derivation of the Navier Stokes equations, it has become possible to numerically solve real world viscous flow problems (computational fluid dynamics (CFD)). However, despite the rapid advancements in the performance of central processing units (CPUs), the computational cost of simulating transient flows with extremely small time/grid scale physics is still unrealistic. In recent years, machine learning (ML) technology has received significant attention across industries, and this big wave has propagated various interests in the fluid dynamics community. Recent ML CFD studies have revealed that completely suppressing the increase in error with the increase in interval between the training and prediction times in data driven methods is unrealistic. The development of a practical CFD acceleration methodology that applies ML is a remaining issue. Therefore, the objectives of this study were developing a realistic ML strategy based on a physics-informed transfer learning and validating the accuracy and acceleration performance of this strategy using an unsteady CFD dataset. This strategy can determine the timing of transfer learning while monitoring the residuals of the governing equations in a cross coupling computation framework. Consequently, our hypothesis that continuous fluid flow time series prediction is feasible was validated, as the intermediate CFD simulations periodically not only reduce the increased residuals but also update the network parameters. Notably, the cross coupling strategy with a grid based network model does not compromise the simulation accuracy for computational acceleration. The simulation was accelerated by 1.8 times in the laminar counterflow CFD dataset condition including the parameter updating time. Open source CFD software OpenFOAM and open-source ML software TensorFlow were used in this feasibility study.", "paper_url": "http://arxiv.org/abs/2206.06817v1", "pdf_url": "http://arxiv.org/pdf/2206.06817v1", "repo_url": null}, "2206.06663": {"publish_time": "2022-06-14", "title": "Quantitative Imaging Principles Improves Medical Image Learning", "author": "Lambert T. Leong et.al.", "abstract": "Fundamental differences between natural and medical images have recently favored the use of self-supervised learning (SSL) over ImageNet transfer learning for medical image applications. Differences between image types are primarily due to the imaging modality and medical images utilize a wide range of physics based techniques while natural images are captured using only visible light. While many have demonstrated that SSL on medical images has resulted in better downstream task performance, our work suggests that more performance can be gained. The scientific principles which are used to acquire medical images are not often considered when constructing learning problems. For this reason, we propose incorporating quantitative imaging principles during generative SSL to improve image quality and quantitative biological accuracy. We show that this training schema results in better starting states for downstream supervised training on limited data. Our model also generates images that validate on clinical quantitative analysis software.", "paper_url": "http://arxiv.org/abs/2206.06663v1", "pdf_url": "http://arxiv.org/pdf/2206.06663v1", "repo_url": "https://github.com/lambertleong/dxa-vae"}, "2206.06629": {"publish_time": "2022-06-14", "title": "Semantic-Discriminative Mixup for Generalizable Sensor-based Cross-domain Activity Recognition", "author": "Wang Lu et.al.", "abstract": "It is expensive and time-consuming to collect sufficient labeled data to build human activity recognition (HAR) models. Training on existing data often makes the model biased towards the distribution of the training data, thus the model might perform terribly on test data with different distributions. Although existing efforts on transfer learning and domain adaptation try to solve the above problem, they still need access to unlabeled data on the target domain, which may not be possible in real scenarios. Few works pay attention to training a model that can generalize well to unseen target domains for HAR. In this paper, we propose a novel method called Semantic-Discriminative Mixup (SDMix) for generalizable cross-domain HAR. Firstly, we introduce semantic-aware Mixup that considers the activity semantic ranges to overcome the semantic inconsistency brought by domain differences. Secondly, we introduce the large margin loss to enhance the discrimination of Mixup to prevent misclassification brought by noisy virtual labels. Comprehensive generalization experiments on five public datasets demonstrate that our SDMix substantially outperforms the state-of-the-art approaches with 6% average accuracy improvement on cross-person, cross-dataset, and cross-position HAR.", "paper_url": "http://arxiv.org/abs/2206.06629v1", "pdf_url": "http://arxiv.org/pdf/2206.06629v1", "repo_url": null}, "2206.06522": {"publish_time": "2022-06-13", "title": "LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning", "author": "Yi-Lin Sung et.al.", "abstract": "Fine-tuning large pre-trained models on downstream tasks has been adopted in a variety of domains recently. However, it is costly to update the entire parameter set of large pre-trained models. Although recently proposed parameter-efficient transfer learning (PETL) techniques allow updating a small subset of parameters (e.g. only using 2% of parameters) inside a pre-trained backbone network for a new task, they only reduce the training memory requirement by up to 30%. This is because the gradient computation for the trainable parameters still requires backpropagation through the large pre-trained backbone model. To address this, we propose Ladder Side-Tuning (LST), a new PETL technique that reduces training memory requirements by more substantial amounts. Unlike existing parameter-efficient methods that insert additional parameters inside backbone networks, we train a ladder side network, a small and separate network that takes intermediate activations as input via shortcut connections (ladders) from backbone networks and makes predictions. LST has significantly lower memory requirements than previous methods, because it does not require backpropagation through the backbone network, but instead only through the side network and ladder connections. We evaluate our method with various models (T5, CLIP-T5) on both NLP (GLUE) and vision-language (VQA, GQA, NLVR2, MSCOCO) tasks. LST saves 69% of the memory costs to fine-tune the whole network, while other methods only save 26% of that in similar parameter usages (hence, 2.7x more memory savings). Moreover, LST achieves higher accuracy than Adapter and LoRA in a low-memory regime. To further show the advantage of this better memory efficiency, we also apply LST to larger T5 models (T5-large, T5-3B), attaining better GLUE performance than full fine-tuning and other PETL methods. The exact same trend also holds in our experiments on VL tasks.", "paper_url": "http://arxiv.org/abs/2206.06522v1", "pdf_url": "http://arxiv.org/pdf/2206.06522v1", "repo_url": "https://github.com/ylsung/ladder-side-tuning"}, "2206.07388": {"publish_time": "2022-06-15", "title": "Subsurface Depths Structure Maps Reconstruction with Generative Adversarial Networks", "author": "Dmitry Ivlev et.al.", "abstract": "This paper described a method for reconstruction of detailed-resolution depth structure maps, usually obtained after the 3D seismic surveys, using the data from 2D seismic depth maps. The method uses two algorithms based on the generative-adversarial neural network architecture. The first algorithm StyleGAN2-ADA accumulates in the hidden space of the neural network the semantic images of mountainous terrain forms first, and then with help of transfer learning, in the ideal case - the structure geometry of stratigraphic horizons. The second algorithm, the Pixel2Style2Pixel encoder, using the semantic level of generalization of the first algorithm, learns to reconstruct the original high-resolution images from their degraded copies (super-resolution technology). There was demonstrated a methodological approach to transferring knowledge on the structural forms of stratigraphic horizon boundaries from the well-studied areas to the underexplored ones. Using the multimodal synthesis of Pixel2Style2Pixel encoder, it is proposed to create a probabilistic depth space, where each point of the project area is represented by the density of probabilistic depth distribution of equally probable reconstructed geological forms of structural images. Assessment of the reconstruction quality was carried out for two blocks. Using this method, credible detailed depth reconstructions comparable with the quality of 3D seismic maps have been obtained from 2D seismic maps.", "paper_url": "http://arxiv.org/abs/2206.07388v1", "pdf_url": "http://arxiv.org/pdf/2206.07388v1", "repo_url": null}, "2206.08329": {"publish_time": "2022-06-16", "title": "Assessing the Value of Transfer Learning Metrics for RF Domain Adaptation", "author": "Lauren J. Wong et.al.", "abstract": "The use of transfer learning (TL) techniques has become common practice in fields such as computer vision (CV) and natural language processing (NLP). Leveraging prior knowledge gained from data with different distributions, TL offers higher performance and reduced training time, but has yet to be fully utilized in applications of machine learning (ML) and deep learning (DL) techniques to applications related to wireless communications, a field loosely termed radio frequency machine learning (RFML). This work begins this examination by evaluating the how radio frequency (RF) domain changes encourage or prevent the transfer of features learned by convolutional neural network (CNN)-based automatic modulation classifiers. Additionally, we examine existing transferability metrics, Log Expected Empirical Prediction (LEEP) and Logarithm of Maximum Evidence (LogME), as a means to both select source models for RF domain adaptation and predict post-transfer accuracy without further training.", "paper_url": "http://arxiv.org/abs/2206.08329v1", "pdf_url": "http://arxiv.org/pdf/2206.08329v1", "repo_url": null}, "2206.08277": {"publish_time": "2022-06-16", "title": "A machine-generated catalogue of Charon's craters and implications for the Kuiper belt", "author": "Mohamad Ali-Dib et.al.", "abstract": "In this paper we investigate Charon's craters size distribution using a deep learning model. This is motivated by the recent results of Singer et al. (2019) who, using manual cataloging, found a change in the size distribution slope of craters smaller than 12 km in diameter, translating into a paucity of small Kuiper Belt objects. These results were corroborated by Robbins and Singer (2021), but opposed by Morbidelli et al. (2021), necessitating an independent review. Our MaskRCNN-based ensemble of models was trained on Lunar, Mercurian, and Martian crater catalogues and both optical and digital elevation images. We use a robust image augmentation scheme to force the model to generalize and transfer-learn into icy objects. With no prior bias or exposure to Charon, our model find best fit slopes of q =-1.47+-0.33 for craters smaller than 10 km, and q =-2.91+-0.51 for craters larger than 15 km. These values indicate a clear change in slope around 15 km as suggested by Singer et al. (2019) and thus independently confirm their conclusions. Our slopes however are both slightly flatter than those found more recently by Robbins and Singer (2021). Our trained models and relevant codes are available online on github.com/malidib/ACID .", "paper_url": "http://arxiv.org/abs/2206.08277v1", "pdf_url": "http://arxiv.org/pdf/2206.08277v1", "repo_url": "https://github.com/malidib/acid"}, "2206.08272": {"publish_time": "2022-06-16", "title": "Longitudinal detection of new MS lesions using Deep Learning", "author": "Reda Abdellah Kamraoui et.al.", "abstract": "The detection of new multiple sclerosis (MS) lesions is an important marker of the evolution of the disease. The applicability of learning-based methods could automate this task efficiently. However, the lack of annotated longitudinal data with new-appearing lesions is a limiting factor for the training of robust and generalizing models. In this work, we describe a deep-learning-based pipeline addressing the challenging task of detecting and segmenting new MS lesions. First, we propose to use transfer-learning from a model trained on a segmentation task using single time-points. Therefore, we exploit knowledge from an easier task and for which more annotated datasets are available. Second, we propose a data synthesis strategy to generate realistic longitudinal time-points with new lesions using single time-point scans. In this way, we pretrain our detection model on large synthetic annotated datasets. Finally, we use a data-augmentation technique designed to simulate data diversity in MRI. By doing that, we increase the size of the available small annotated longitudinal datasets. Our ablation study showed that each contribution lead to an enhancement of the segmentation accuracy. Using the proposed pipeline, we obtained the best score for the segmentation and the detection of new MS lesions in the MSSEG2 MICCAI challenge.", "paper_url": "http://arxiv.org/abs/2206.08272v1", "pdf_url": "http://arxiv.org/pdf/2206.08272v1", "repo_url": null}, "2206.08101": {"publish_time": "2022-06-16", "title": "Is Continual Learning Truly Learning Representations Continually?", "author": "Sungmin Cha et.al.", "abstract": "Continual learning (CL) aims to learn from sequentially arriving tasks without forgetting previous tasks. Whereas CL algorithms have tried to achieve higher average test accuracy across all the tasks learned so far, learning continuously useful representations is critical for successful generalization and downstream transfer. To measure representational quality, we re-train only the output layers using a small balanced dataset for all the tasks, evaluating the average accuracy without any biased predictions toward the current task. We also test on several downstream tasks, measuring transfer learning accuracy of the learned representations. By testing our new formalism on ImageNet-100 and ImageNet-1000, we find that using more exemplar memory is the only option to make a meaningful difference in learned representations, and most of the regularization- or distillation-based CL algorithms that use the exemplar memory fail to learn continuously useful representations in class-incremental learning. Surprisingly, unsupervised (or self-supervised) CL with sufficient memory size can achieve comparable performance to the supervised counterparts. Considering non-trivial labeling costs, we claim that finding more efficient unsupervised CL algorithms that minimally use exemplary memory would be the next promising direction for CL research.", "paper_url": "http://arxiv.org/abs/2206.08101v1", "pdf_url": "http://arxiv.org/pdf/2206.08101v1", "repo_url": null}, "2206.07756": {"publish_time": "2022-06-15", "title": "Hybrid full-field thermal characterization of additive manufacturing processes using physics-informed neural networks with data", "author": "Shuheng Liao et.al.", "abstract": "Understanding the thermal behavior of additive manufacturing (AM) processes is crucial for enhancing the quality control and enabling customized process design. Most purely physics-based computational models suffer from intensive computational costs, thus not suitable for online control and iterative design application. Data-driven models taking advantage of the latest developed computational tools can serve as a more efficient surrogate, but they are usually trained over a large amount of simulation data and often fail to effectively use small but high-quality experimental data. In this work, we developed a hybrid physics-based data-driven thermal modeling approach of AM processes using physics-informed neural networks. Specifically, partially observed temperature data measured from an infrared camera is combined with the physics laws to predict full-field temperature history and to discover unknown material and process parameters. In the numerical and experimental examples, the effectiveness of adding auxiliary training data and using the technique of transfer learning on training efficiency and prediction accuracy, as well as the ability to identify unknown parameters with partially observed data, are demonstrated. The results show that the hybrid thermal model can effectively identify unknown parameters and capture the full-field temperature accurately, and thus it has the potential to be used in iterative process design and real-time process control of AM.", "paper_url": "http://arxiv.org/abs/2206.07756v1", "pdf_url": "http://arxiv.org/pdf/2206.07756v1", "repo_url": "https://github.com/shuhengliao/physics_informed_am"}, "2206.08883": {"publish_time": "2022-06-17", "title": "CtrlFormer: Learning Transferable State Representation for Visual Control via Transformer", "author": "Yao Mu et.al.", "abstract": "Transformer has achieved great successes in learning vision and language representation, which is general across various downstream tasks. In visual control, learning transferable state representation that can transfer between different control tasks is important to reduce the training sample size. However, porting Transformer to sample-efficient visual control remains a challenging and unsolved problem. To this end, we propose a novel Control Transformer (CtrlFormer), possessing many appealing benefits that prior arts do not have. Firstly, CtrlFormer jointly learns self-attention mechanisms between visual tokens and policy tokens among different control tasks, where multitask representation can be learned and transferred without catastrophic forgetting. Secondly, we carefully design a contrastive reinforcement learning paradigm to train CtrlFormer, enabling it to achieve high sample efficiency, which is important in control problems. For example, in the DMControl benchmark, unlike recent advanced methods that failed by producing a zero score in the \"Cartpole\" task after transfer learning with 100k samples, CtrlFormer can achieve a state-of-the-art score with only 100k samples while maintaining the performance of previous tasks. The code and models are released in our project homepage.", "paper_url": "http://arxiv.org/abs/2206.08883v1", "pdf_url": "http://arxiv.org/pdf/2206.08883v1", "repo_url": null}, "2206.08671": {"publish_time": "2022-06-17", "title": "FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and Federated Image Classification", "author": "Aliaksandra Shysheya et.al.", "abstract": "Modern deep learning systems are increasingly deployed in situations such as personalization and federated learning where it is necessary to support i) learning on small amounts of data, and ii) communication efficient distributed training protocols. In this work we develop FiLM Transfer (FiT) which fulfills these requirements in the image classification setting. FiT uses an automatically configured Naive Bayes classifier on top of a fixed backbone that has been pretrained on large image datasets. Parameter efficient FiLM layers are used to modulate the backbone, shaping the representation for the downstream task. The network is trained via an episodic fine-tuning protocol. The approach is parameter efficient which is key for enabling few-shot learning, inexpensive model updates for personalization, and communication efficient federated learning. We experiment with FiT on a wide range of downstream datasets and show that it achieves better classification accuracy than the state-of-the-art Big Transfer (BiT) algorithm at low-shot and on the challenging VTAB-1k benchmark, with fewer than 1% of the updateable parameters. Finally, we demonstrate the parameter efficiency of FiT in distributed low-shot applications including model personalization and federated learning where model update size is an important performance metric.", "paper_url": "http://arxiv.org/abs/2206.08671v1", "pdf_url": "http://arxiv.org/pdf/2206.08671v1", "repo_url": "https://github.com/cambridge-mlg/fit"}, "2206.08574": {"publish_time": "2022-06-17", "title": "Using Transfer Learning for Code-Related Tasks", "author": "Antonio Mastropaolo et.al.", "abstract": "Deep learning (DL) techniques have been used to support several code-related tasks such as code summarization and bug-fixing. In particular, pre-trained transformer models are on the rise, also thanks to the excellent results they achieved in Natural Language Processing (NLP) tasks. The basic idea behind these models is to first pre-train them on a generic dataset using a self-supervised task (e.g, filling masked words in sentences). Then, these models are fine-tuned to support specific tasks of interest (e.g, language translation). A single model can be fine-tuned to support multiple tasks, possibly exploiting the benefits of transfer learning. This means that knowledge acquired to solve a specific task (e.g, language translation) can be useful to boost performance on another task (e.g, sentiment classification). While the benefits of transfer learning have been widely studied in NLP, limited empirical evidence is available when it comes to code-related tasks. In this paper, we assess the performance of the Text-To-Text Transfer Transformer (T5) model in supporting four different code-related tasks: (i) automatic bug-fixing, (ii) injection of code mutants, (iii) generation of assert statements, and (iv) code summarization. We pay particular attention in studying the role played by pre-training and multi-task fine-tuning on the model's performance. We show that (i) the T5 can achieve better performance as compared to state-of-the-art baselines; and (ii) while pre-training helps the model, not all tasks benefit from a multi-task fine-tuning.", "paper_url": "http://arxiv.org/abs/2206.08574v1", "pdf_url": "http://arxiv.org/pdf/2206.08574v1", "repo_url": "https://github.com/antonio-mastropaolo/transferlearning4code"}, "2206.08557": {"publish_time": "2022-06-17", "title": "COVID-19 Detection using Transfer Learning with Convolutional Neural Network", "author": "Pramit Dutta et.al.", "abstract": "The Novel Coronavirus disease 2019 (COVID-19) is a fatal infectious disease, first recognized in December 2019 in Wuhan, Hubei, China, and has gone on an epidemic situation. Under these circumstances, it became more important to detect COVID-19 in infected people. Nowadays, the testing kits are gradually lessening in number compared to the number of infected population. Under recent prevailing conditions, the diagnosis of lung disease by analyzing chest CT (Computed Tomography) images has become an important tool for both diagnosis and prophecy of COVID-19 patients. In this study, a Transfer learning strategy (CNN) for detecting COVID-19 infection from CT images has been proposed. In the proposed model, a multilayer Convolutional neural network (CNN) with Transfer learning model Inception V3 has been designed. Similar to CNN, it uses convolution and pooling to extract features, but this transfer learning model contains weights of dataset Imagenet. Thus it can detect features very effectively which gives it an upper hand for achieving better accuracy.", "paper_url": "http://arxiv.org/abs/2206.08557v1", "pdf_url": "http://arxiv.org/pdf/2206.08557v1", "repo_url": null}, "2206.08543": {"publish_time": "2022-06-17", "title": "Multi-Classification of Brain Tumor Images Using Transfer Learning Based Deep Neural Network", "author": "Pramit Dutta et.al.", "abstract": "In recent advancement towards computer based diagnostics system, the classification of brain tumor images is a challenging task. This paper mainly focuses on elevating the classification accuracy of brain tumor images with transfer learning based deep neural network. The classification approach is started with the image augmentation operation including rotation, zoom, hori-zontal flip, width shift, height shift, and shear to increase the diversity in image datasets. Then the general features of the input brain tumor images are extracted based on a pre-trained transfer learning method comprised of Inception-v3. Fi-nally, the deep neural network with 4 customized layers is employed for classi-fying the brain tumors in most frequent brain tumor types as meningioma, glioma, and pituitary. The proposed model acquires an effective performance with an overall accuracy of 96.25% which is much improved than some existing multi-classification methods. Whereas, the fine-tuning of hyper-parameters and inclusion of customized DNN with the Inception-v3 model results in an im-provement of the classification accuracy.", "paper_url": "http://arxiv.org/abs/2206.08543v1", "pdf_url": "http://arxiv.org/pdf/2206.08543v1", "repo_url": null}, "2206.10375": {"publish_time": "2022-06-21", "title": "MEStereo-Du2CNN: A Novel Dual Channel CNN for Learning Robust Depth Estimates from Multi-exposure Stereo Images for HDR 3D Applications", "author": "Rohit Choudhary et.al.", "abstract": "Display technologies have evolved over the years. It is critical to develop practical HDR capturing, processing, and display solutions to bring 3D technologies to the next level. Depth estimation of multi-exposure stereo image sequences is an essential task in the development of cost-effective 3D HDR video content. In this paper, we develop a novel deep architecture for multi-exposure stereo depth estimation. The proposed architecture has two novel components. First, the stereo matching technique used in traditional stereo depth estimation is revamped. For the stereo depth estimation component of our architecture, a mono-to-stereo transfer learning approach is deployed. The proposed formulation circumvents the cost volume construction requirement, which is replaced by a ResNet based dual-encoder single-decoder CNN with different weights for feature fusion. EfficientNet based blocks are used to learn the disparity. Secondly, we combine disparity maps obtained from the stereo images at different exposure levels using a robust disparity feature fusion approach. The disparity maps obtained at different exposures are merged using weight maps calculated for different quality measures. The final predicted disparity map obtained is more robust and retains best features that preserve the depth discontinuities. The proposed CNN offers flexibility to train using standard dynamic range stereo data or with multi-exposure low dynamic range stereo sequences. In terms of performance, the proposed model surpasses state-of-the-art monocular and stereo depth estimation methods, both quantitatively and qualitatively, on challenging Scene flow and differently exposed Middlebury stereo datasets. The architecture performs exceedingly well on complex natural scenes, demonstrating its usefulness for diverse 3D HDR applications.", "paper_url": "http://arxiv.org/abs/2206.10375v1", "pdf_url": "http://arxiv.org/pdf/2206.10375v1", "repo_url": null}, "2206.10348": {"publish_time": "2022-06-21", "title": "Supervised learning of random quantum circuits via scalable neural networks", "author": "S. Cantori et.al.", "abstract": "Predicting the output of quantum circuits is a hard computational task that plays a pivotal role in the development of universal quantum computers. Here we investigate the supervised learning of output expectation values of random quantum circuits. Deep convolutional neural networks (CNNs) are trained to predict single-qubit and two-qubit expectation values using databases of classically simulated circuits. These circuits are represented via an appropriately designed one-hot encoding of the constituent gates. The prediction accuracy for previously unseen circuits is analyzed, also making comparisons with small-scale quantum computers available from the free IBM Quantum program. The CNNs often outperform the quantum devices, depending on the circuit depth, on the network depth, and on the training set size. Notably, our CNNs are designed to be scalable. This allows us exploiting transfer learning and performing extrapolations to circuits larger than those included in the training set. These CNNs also demonstrate remarkable resilience against noise, namely, they remain accurate even when trained on (simulated) expectation values averaged over very few measurements.", "paper_url": "http://arxiv.org/abs/2206.10348v1", "pdf_url": "http://arxiv.org/pdf/2206.10348v1", "repo_url": "https://github.com/simonecantori/supervised-learning-of-quantum-circuits"}, "2206.10343": {"publish_time": "2022-06-21", "title": "Building an Endangered Language Resource in the Classroom: Universal Dependencies for Kakataibo", "author": "Roberto Zariquiey et.al.", "abstract": "In this paper, we launch a new Universal Dependencies treebank for an endangered language from Amazonia: Kakataibo, a Panoan language spoken in Peru. We first discuss the collaborative methodology implemented, which proved effective to create a treebank in the context of a Computational Linguistic course for undergraduates. Then, we describe the general details of the treebank and the language-specific considerations implemented for the proposed annotation. We finally conduct some experiments on part-of-speech tagging and syntactic dependency parsing. We focus on monolingual and transfer learning settings, where we study the impact of a Shipibo-Konibo treebank, another Panoan language resource.", "paper_url": "http://arxiv.org/abs/2206.10343v1", "pdf_url": "http://arxiv.org/pdf/2206.10343v1", "repo_url": "https://github.com/tarotis/building-an-endangered-language-resource-in-the-classroom"}, "2206.09872": {"publish_time": "2022-06-20", "title": "A Neural Network Based Method with Transfer Learning for Genetic Data Analysis", "author": "Jinghang Lin et.al.", "abstract": "Transfer learning has emerged as a powerful technique in many application problems, such as computer vision and natural language processing. However, this technique is largely ignored in application to genetic data analysis. In this paper, we combine transfer learning technique with a neural network based method(expectile neural networks). With transfer learning, instead of starting the learning process from scratch, we start from one task that have been learned when solving a different task. We leverage previous learnings and avoid starting from scratch to improve the model performance by passing information gained in different but related task. To demonstrate the performance, we run two real data sets. By using transfer learning algorithm, the performance of expectile neural networks is improved compared to expectile neural network without using transfer learning technique.", "paper_url": "http://arxiv.org/abs/2206.09872v1", "pdf_url": "http://arxiv.org/pdf/2206.09872v1", "repo_url": null}, "2206.09807": {"publish_time": "2022-06-20", "title": "Deep representation of EEG data from Spatio-Spectral Feature Images", "author": "Nikesh Bajaj et.al.", "abstract": "Unlike conventional data such as natural images, audio and speech, raw multi-channel Electroencephalogram (EEG) data are difficult to interpret. Modern deep neural networks have shown promising results in EEG studies, however finding robust invariant representations of EEG data across subjects remains a challenge, due to differences in brain folding structures. Thus, invariant representations of EEG data would be desirable to improve our understanding of the brain activity and to use them effectively during transfer learning. In this paper, we propose an approach to learn deep representations of EEG data by exploiting spatial relationships between recording electrodes and encoding them in a Spatio-Spectral Feature Images. We use multi-channel EEG signals from the PhyAAt dataset for auditory tasks and train a Convolutional Neural Network (CNN) on 25 subjects individually. Afterwards, we generate the input patterns that activate deep neurons across all the subjects. The generated pattern can be seen as a map of the brain activity in different spatial regions. Our analysis reveals the existence of specific brain regions related to different tasks. Low-level features focusing on larger regions and high-level features focusing on a smaller and very specific cluster of regions are also identified. Interestingly, similar patterns are found across different subjects although the activities appear in different regions. Our analysis also reveals common brain regions across subjects, which can be used as generalized representations. Our proposed approach allows us to find more interpretable representations of EEG data, which can further be used for effective transfer learning.", "paper_url": "http://arxiv.org/abs/2206.09807v1", "pdf_url": "http://arxiv.org/pdf/2206.09807v1", "repo_url": null}, "2206.10914": {"publish_time": "2022-06-22", "title": "Template-based Approach to Zero-shot Intent Recognition", "author": "Dmitry Lamanov et.al.", "abstract": "The recent advances in transfer learning techniques and pre-training of large contextualized encoders foster innovation in real-life applications, including dialog assistants. Practical needs of intent recognition require effective data usage and the ability to constantly update supported intents, adopting new ones, and abandoning outdated ones. In particular, the generalized zero-shot paradigm, in which the model is trained on the seen intents and tested on both seen and unseen intents, is taking on new importance. In this paper, we explore the generalized zero-shot setup for intent recognition. Following best practices for zero-shot text classification, we treat the task with a sentence pair modeling approach. We outperform previous state-of-the-art f1-measure by up to 16\\% for unseen intents, using intent labels and user utterances and without accessing external sources (such as knowledge bases). Further enhancement includes lexicalization of intent labels, which improves performance by up to 7\\%. By using task transferring from other sentence pair tasks, such as Natural Language Inference, we gain additional improvements.", "paper_url": "http://arxiv.org/abs/2206.10914v1", "pdf_url": "http://arxiv.org/pdf/2206.10914v1", "repo_url": null}, "2206.10797": {"publish_time": "2022-06-22", "title": "Imitation Learning for Generalizable Self-driving Policy with Sim-to-real Transfer", "author": "Zolt\u00e1n L\u0151rincz et.al.", "abstract": "Imitation Learning uses the demonstrations of an expert to uncover the optimal policy and it is suitable for real-world robotics tasks as well. In this case, however, the training of the agent is carried out in a simulation environment due to safety, economic and time constraints. Later, the agent is applied in the real-life domain using sim-to-real methods. In this paper, we apply Imitation Learning methods that solve a robotics task in a simulated environment and use transfer learning to apply these solutions in the real-world environment. Our task is set in the Duckietown environment, where the robotic agent has to follow the right lane based on the input images of a single forward-facing camera. We present three Imitation Learning and two sim-to-real methods capable of achieving this task. A detailed comparison is provided on these techniques to highlight their advantages and disadvantages.", "paper_url": "http://arxiv.org/abs/2206.10797v1", "pdf_url": "http://arxiv.org/pdf/2206.10797v1", "repo_url": "https://github.com/lzoltan35/duckietown_imitation_learning"}, "2206.11627": {"publish_time": "2022-06-23", "title": "Learning Newtonian mechanics with an intrinsically integrated educational game", "author": "Anne van der Linden et.al.", "abstract": "Research on cognitive effects of educational games in general shows promising results. However, large variations in learning outcomes between individual educational games exists. Research on the design process and different design elements of educational games has led to some interesting directions, but some design aspects remain unclear. We examined how an educational game designed on the basis of intrinsic integration theory, based on a strong alignment between game and learning goals, supports the learning of Newtonian mechanics. This study applied a mixed methods approach. An pre and posttest design was used to examine possible learning and transfer effects fostered by playing the educational game, Newtons Race. To examine how players played the game, log data of each player was digitally recorded during gameplay. Our findings demonstrated a significant positive learning effect of Newtons Race. This finding can be explained with acquired log data. Log data show that players gameplay mostly matched expected learning during the game, with physically correct game settings occurring more and more as gameplay progressed. The ability to transfer learned knowledge onto other situations was shown to be limited to situations closely resembling the game environment. Similar designed intrinsically integrated games on different (physics) subjects could also foster learning in a relative short time. In order to foster transfer to other situations we propose embedding the game within other instructional activities.", "paper_url": "http://arxiv.org/abs/2206.11627v1", "pdf_url": "http://arxiv.org/pdf/2206.11627v1", "repo_url": null}, "2206.11326": {"publish_time": "2022-06-22", "title": "Optimistic Linear Support and Successor Features as a Basis for Optimal Policy Transfer", "author": "Lucas N. Alegre et.al.", "abstract": "In many real-world applications, reinforcement learning (RL) agents might have to solve multiple tasks, each one typically modeled via a reward function. If reward functions are expressed linearly, and the agent has previously learned a set of policies for different tasks, successor features (SFs) can be exploited to combine such policies and identify reasonable solutions for new problems. However, the identified solutions are not guaranteed to be optimal. We introduce a novel algorithm that addresses this limitation. It allows RL agents to combine existing policies and directly identify optimal policies for arbitrary new problems, without requiring any further interactions with the environment. We first show (under mild assumptions) that the transfer learning problem tackled by SFs is equivalent to the problem of learning to optimize multiple objectives in RL. We then introduce an SF-based extension of the Optimistic Linear Support algorithm to learn a set of policies whose SFs form a convex coverage set. We prove that policies in this set can be combined via generalized policy improvement to construct optimal behaviors for any new linearly-expressible tasks, without requiring any additional training samples. We empirically show that our method outperforms state-of-the-art competing algorithms both in discrete and continuous domains under value function approximation.", "paper_url": "http://arxiv.org/abs/2206.11326v1", "pdf_url": "http://arxiv.org/pdf/2206.11326v1", "repo_url": "https://github.com/lucasalegre/sfols"}, "2206.12300": {"publish_time": "2022-06-24", "title": "Automatic extraction of coronary arteries using deep learning in invasive coronary angiograms", "author": "Yinghui Meng et.al.", "abstract": "Accurate extraction of coronary arteries from invasive coronary angiography (ICA) is important in clinical decision-making for the diagnosis and risk stratification of coronary artery disease (CAD). In this study, we develop a method using deep learning to automatically extract the coronary artery lumen. Methods. A deep learning model U-Net 3+, which incorporates the full-scale skip connections and deep supervisions, was proposed for automatic extraction of coronary arteries from ICAs. Transfer learning and a hybrid loss function were employed in this novel coronary artery extraction framework. Results. A data set containing 616 ICAs obtained from 210 patients was used. In the technical evaluation, the U-Net 3+ achieved a Dice score of 0.8942 and a sensitivity of 0.8735, which is higher than U-Net ++ (Dice score: 0.8814, the sensitivity of 0.8331) and U-net (Dice score: 0.8799, the sensitivity of 0.8305). Conclusion. Our study demonstrates that the U-Net 3+ is superior to other segmentation frameworks for the automatic extraction of the coronary arteries from ICAs. This result suggests great promise for clinical use.", "paper_url": "http://arxiv.org/abs/2206.12300v1", "pdf_url": "http://arxiv.org/pdf/2206.12300v1", "repo_url": null}, "2206.13472": {"publish_time": "2022-06-27", "title": "On the sample complexity of entropic optimal transport", "author": "Philippe Rigollet et.al.", "abstract": "We study the sample complexity of entropic optimal transport in high dimensions using computationally efficient plug-in estimators. We significantly advance the state of the art by establishing dimension-free, parametric rates for estimating various quantities of interest, including the entropic regression function which is a natural analog to the optimal transport map. As an application, we propose a practical model for transfer learning based on entropic optimal transport and establish parametric rates of convergence for nonparametric regression and classification.", "paper_url": "http://arxiv.org/abs/2206.13472v1", "pdf_url": "http://arxiv.org/pdf/2206.13472v1", "repo_url": null}, "2206.13399": {"publish_time": "2022-06-27", "title": "Transfer Learning via Test-Time Neural Networks Aggregation", "author": "Bruno Casella et.al.", "abstract": "It has been demonstrated that deep neural networks outperform traditional machine learning. However, deep networks lack generalisability, that is, they will not perform as good as in a new (testing) set drawn from a different distribution due to the domain shift. In order to tackle this known issue, several transfer learning approaches have been proposed, where the knowledge of a trained model is transferred into another to improve performance with different data. However, most of these approaches require additional training steps, or they suffer from catastrophic forgetting that occurs when a trained model has overwritten previously learnt knowledge. We address both problems with a novel transfer learning approach that uses network aggregation. We train dataset-specific networks together with an aggregation network in a unified framework. The loss function includes two main components: a task-specific loss (such as cross-entropy) and an aggregation loss. The proposed aggregation loss allows our model to learn how trained deep network parameters can be aggregated with an aggregation operator. We demonstrate that the proposed approach learns model aggregation at test time without any further training step, reducing the burden of transfer learning to a simple arithmetical operation. The proposed approach achieves comparable performance w.r.t. the baseline. Besides, if the aggregation operator has an inverse, we will show that our model also inherently allows for selective forgetting, i.e., the aggregated model can forget one of the datasets it was trained on, retaining information on the others.", "paper_url": "http://arxiv.org/abs/2206.13399v1", "pdf_url": "http://arxiv.org/pdf/2206.13399v1", "repo_url": null}, "2206.13378": {"publish_time": "2022-06-27", "title": "Guillotine Regularization: Improving Deep Networks Generalization by Removing their Head", "author": "Florian Bordes et.al.", "abstract": "One unexpected technique that emerged in recent years consists in training a Deep Network (DN) with a Self-Supervised Learning (SSL) method, and using this network on downstream tasks but with its last few layers entirely removed. This usually skimmed-over trick is actually critical for SSL methods to display competitive performances. For example, on ImageNet classification, more than 30 points of percentage can be gained that way. This is a little vexing, as one would hope that the network layer at which invariance is explicitly enforced by the SSL criterion during training (the last layer) should be the one to use for best generalization performance downstream. But it seems not to be, and this study sheds some light on why. This trick, which we name Guillotine Regularization (GR), is in fact a generically applicable form of regularization that has also been used to improve generalization performance in transfer learning scenarios. In this work, through theory and experiments, we formalize GR and identify the underlying reasons behind its success in SSL methods. Our study shows that the use of this trick is essential to SSL performance for two main reasons: (i) improper data-augmentations to define the positive pairs used during training, and/or (ii) suboptimal selection of the hyper-parameters of the SSL loss.", "paper_url": "http://arxiv.org/abs/2206.13378v1", "pdf_url": "http://arxiv.org/pdf/2206.13378v1", "repo_url": null}, "2206.13365": {"publish_time": "2022-06-27", "title": "Interpretable Acoustic Representation Learning on Breathing and Speech Signals for COVID-19 Detection", "author": "Debottam Dutta et.al.", "abstract": "In this paper, we describe an approach for representation learning of audio signals for the task of COVID-19 detection. The raw audio samples are processed with a bank of 1-D convolutional filters that are parameterized as cosine modulated Gaussian functions. The choice of these kernels allows the interpretation of the filterbanks as smooth band-pass filters. The filtered outputs are pooled, log-compressed and used in a self-attention based relevance weighting mechanism. The relevance weighting emphasizes the key regions of the time-frequency decomposition that are important for the downstream task. The subsequent layers of the model consist of a recurrent architecture and the models are trained for a COVID-19 detection task. In our experiments on the Coswara data set, we show that the proposed model achieves significant performance improvements over the baseline system as well as other representation learning approaches. Further, the approach proposed is shown to be uniformly applicable for speech and breathing signals and for transfer learning from a larger data set.", "paper_url": "http://arxiv.org/abs/2206.13365v1", "pdf_url": "http://arxiv.org/pdf/2206.13365v1", "repo_url": null}, "2206.13317": {"publish_time": "2022-06-27", "title": "Automatic identification of segmentation errors for radiotherapy using geometric learning", "author": "Edward G. A. Henderson et.al.", "abstract": "Automatic segmentation of organs-at-risk (OARs) in CT scans using convolutional neural networks (CNNs) is being introduced into the radiotherapy workflow. However, these segmentations still require manual editing and approval by clinicians prior to clinical use, which can be time consuming. The aim of this work was to develop a tool to automatically identify errors in 3D OAR segmentations without a ground truth. Our tool uses a novel architecture combining a CNN and graph neural network (GNN) to leverage the segmentation's appearance and shape. The proposed model is trained using self-supervised learning using a synthetically-generated dataset of segmentations of the parotid and with realistic contouring errors. The effectiveness of our model is assessed with ablation tests, evaluating the efficacy of different portions of the architecture as well as the use of transfer learning from an unsupervised pretext task. Our best performing model predicted errors on the parotid gland with a precision of 85.0% & 89.7% for internal and external errors respectively, and recall of 66.5% & 68.6%. This offline QA tool could be used in the clinical pathway, potentially decreasing the time clinicians spend correcting contours by detecting regions which require their attention. All our code is publicly available at https://github.com/rrr-uom-projects/contour_auto_QATool.", "paper_url": "http://arxiv.org/abs/2206.13317v1", "pdf_url": "http://arxiv.org/pdf/2206.13317v1", "repo_url": "https://github.com/rrr-uom-projects/contour_auto_qatool"}, "2206.13964": {"publish_time": "2022-06-28", "title": "Learning Gait Representation from Massive Unlabelled Walking Videos: A Benchmark", "author": "Chao Fan et.al.", "abstract": "Gait depicts individuals' unique and distinguishing walking patterns and has become one of the most promising biometric features for human identification. As a fine-grained recognition task, gait recognition is easily affected by many factors and usually requires a large amount of completely annotated data that is costly and insatiable. This paper proposes a large-scale self-supervised benchmark for gait recognition with contrastive learning, aiming to learn the general gait representation from massive unlabelled walking videos for practical applications via offering informative walking priors and diverse real-world variations. Specifically, we collect a large-scale unlabelled gait dataset GaitLU-1M consisting of 1.02M walking sequences and propose a conceptually simple yet empirically powerful baseline model GaitSSB. Experimentally, we evaluate the pre-trained model on four widely-used gait benchmarks, CASIA-B, OU-MVLP, GREW and Gait3D with or without transfer learning. The unsupervised results are comparable to or even better than the early model-based and GEI-based methods. After transfer learning, our method outperforms existing methods by a large margin in most cases. Theoretically, we discuss the critical issues for gait-specific contrastive framework and present some insights for further study. As far as we know, GaitLU-1M is the first large-scale unlabelled gait dataset, and GaitSSB is the first method that achieves remarkable unsupervised results on the aforementioned benchmarks. The source code of GaitSSB will be integrated into OpenGait which is available at https://github.com/ShiqiYu/OpenGait.", "paper_url": "http://arxiv.org/abs/2206.13964v1", "pdf_url": "http://arxiv.org/pdf/2206.13964v1", "repo_url": "https://github.com/shiqiyu/opengait"}, "2206.13696": {"publish_time": "2022-06-28", "title": "Photometric redshift estimates using Bayesian neural networks in the CSST survey", "author": "Xingchen Zhou et.al.", "abstract": "Galaxy photometric redshift (photo-$z$) is crucial in cosmological studies, such as weak gravitational lensing and galaxy angular clustering measurements. In this work, we try to extract photo-$z$ information and construct its probabilistic distribution function (PDF) using the Bayesian neural networks (BNN) from both galaxy flux and image data expected to be obtained by the China Space Station Telescope (CSST). The mock galaxy images are generated from the Advanced Camera for Surveys of Hubble Space Telescope (HST-ACS) and COSMOS catalog, in which the CSST instrumental effects are carefully considered. And the galaxy flux data are measured from galaxy images using aperture photometry. We construct Bayesian multilayer perceptron (B-MLP) and Bayesian convolutional neural network (B-CNN) to predict photo-$z$ along with the PDFs from fluxes and images, respectively. We combine the B-MLP and B-CNN together, and construct a hybrid network and employ the transfer learning techniques to investigate the improvement of including both flux and image data. We find that the accuracy and outlier fraction of photo-$z$ can achieve $\\sigma_{NMAD}$ = 0.022 and $\\eta$ = 2.83% for the B-MLP using the flux data only, and $\\sigma_{NMAD}$ = 0.025 and $\\eta$ = 2.32% for the B-CNN using the image data only. The Bayesian hybrid transfer network can improve the result to $\\sigma_{NMAD}$ = 0.021 and $\\eta$ = 1.62%, and can provide the most confident predictions with the lowest average uncertainty.", "paper_url": "http://arxiv.org/abs/2206.13696v1", "pdf_url": "http://arxiv.org/pdf/2206.13696v1", "repo_url": null}, "2206.13577": {"publish_time": "2022-06-27", "title": "A View Independent Classification Framework for Yoga Postures", "author": "Mustafa Chasmai et.al.", "abstract": "Yoga is a globally acclaimed and widely recommended practice for a healthy living. Maintaining correct posture while performing a Yogasana is of utmost importance. In this work, we employ transfer learning from Human Pose Estimation models for extracting 136 key-points spread all over the body to train a Random Forest classifier which is used for estimation of the Yogasanas. The results are evaluated on an in-house collected extensive yoga video database of 51 subjects recorded from 4 different camera angles. We propose a 3 step scheme for evaluating the generalizability of a Yoga classifier by testing it on 1) unseen frames, 2) unseen subjects, and 3) unseen camera angles. We argue that for most of the applications, validation accuracies on unseen subjects and unseen camera angles would be most important. We empirically analyze over three public datasets, the advantage of transfer learning and the possibilities of target leakage. We further demonstrate that the classification accuracies critically depend on the cross validation method employed and can often be misleading. To promote further research, we have made key-points dataset and code publicly available.", "paper_url": "http://arxiv.org/abs/2206.13577v1", "pdf_url": "http://arxiv.org/pdf/2206.13577v1", "repo_url": null}, "2206.13559": {"publish_time": "2022-06-27", "title": "Parameter-Efficient Image-to-Video Transfer Learning", "author": "Junting Pan et.al.", "abstract": "Capitalizing on large pre-trained models for various downstream tasks of interest have recently emerged with promising performance. Due to the ever-growing model size, the standard full fine-tuning based task adaptation strategy becomes prohibitively costly in terms of model training and storage. This has led to a new research direction in parameter-efficient transfer learning. However, existing attempts typically focus on downstream tasks from the same modality (e.g., image understanding) of the pre-trained model. This creates a limit because in some specific modalities, (e.g., video understanding) such a strong pre-trained model with sufficient knowledge is less or not available. In this work, we investigate such a novel cross-modality transfer learning setting, namely parameter-efficient image-to-video transfer learning. To solve this problem, we propose a new Spatio-Temporal Adapter (ST-Adapter) for parameter-efficient fine-tuning per video task. With a built-in spatio-temporal reasoning capability in a compact design, ST-Adapter enables a pre-trained image model without temporal knowledge to reason about dynamic video content at a small (~8%) per-task parameter cost, requiring approximately 20 times fewer updated parameters compared to previous work. Extensive experiments on video action recognition tasks show that our ST-Adapter can match or even outperform the strong full fine-tuning strategy and state-of-the-art video models, whilst enjoying the advantage of parameter efficiency.", "paper_url": "http://arxiv.org/abs/2206.13559v1", "pdf_url": "http://arxiv.org/pdf/2206.13559v1", "repo_url": null}, "2206.14504": {"publish_time": "2022-06-29", "title": "GERNERMED++: Transfer Learning in German Medical NLP", "author": "Johann Frei et.al.", "abstract": "We present a statistical model for German medical natural language processing trained for named entity recognition (NER) as an open, publicly available model. The work serves as a refined successor to our first GERNERMED model which is substantially outperformed by our work. We demonstrate the effectiveness of combining multiple techniques in order to achieve strong results in entity recognition performance by the means of transfer-learning on pretrained deep language models (LM), word-alignment and neural machine translation. Due to the sparse situation on open, public medical entity recognition models for German texts, this work offers benefits to the German research community on medical NLP as a baseline model. Since our model is based on public English data, its weights are provided without legal restrictions on usage and distribution. The sample code and the statistical model is available at: https://github.com/frankkramer-lab/GERNERMED-pp", "paper_url": "http://arxiv.org/abs/2206.14504v1", "pdf_url": "http://arxiv.org/pdf/2206.14504v1", "repo_url": "https://github.com/frankkramer-lab/gernermed-pp"}, "2206.14200": {"publish_time": "2022-06-28", "title": "ECG Heartbeat classification using deep transfer learning with Convolutional Neural Network and STFT technique", "author": "Minh Cao et.al.", "abstract": "Electrocardiogram (ECG) is a simple non-invasive measure to identify heart-related issues such as irregular heartbeats known as arrhythmias. While artificial intelligence and machine learning is being utilized in a wide range of healthcare related applications and datasets, many arrhythmia classifiers using deep learning methods have been proposed in recent years. However, sizes of the available datasets from which to build and assess machine learning models is often very small and the lack of well-annotated public ECG datasets is evident. In this paper, we propose a deep transfer learning framework that is aimed to perform classification on a small size training dataset. The proposed method is to fine-tune a general-purpose image classifier ResNet-18 with MIT-BIH arrhythmia dataset in accordance with the AAMI EC57 standard. This paper further investigates many existing deep learning models that have failed to avoid data leakage against AAMI recommendations. We compare how different data split methods impact the model performance. This comparison study implies that future work in arrhythmia classification should follow the AAMI EC57 standard when using any including MIT-BIH arrhythmia dataset.", "paper_url": "http://arxiv.org/abs/2206.14200v1", "pdf_url": "http://arxiv.org/pdf/2206.14200v1", "repo_url": null}, "2206.15472": {"publish_time": "2022-06-30", "title": "On-Device Training Under 256KB Memory", "author": "Ji Lin et.al.", "abstract": "On-device training enables the model to adapt to new data collected from the sensors by fine-tuning a pre-trained model. However, the training memory consumption is prohibitive for IoT devices that have tiny memory resources. We propose an algorithm-system co-design framework to make on-device training possible with only 256KB of memory. On-device training faces two unique challenges: (1) the quantized graphs of neural networks are hard to optimize due to mixed bit-precision and the lack of normalization; (2) the limited hardware resource (memory and computation) does not allow full backward computation. To cope with the optimization difficulty, we propose Quantization-Aware Scaling to calibrate the gradient scales and stabilize quantized training. To reduce the memory footprint, we propose Sparse Update to skip the gradient computation of less important layers and sub-tensors. The algorithm innovation is implemented by a lightweight training system, Tiny Training Engine, which prunes the backward computation graph to support sparse updates and offloads the runtime auto-differentiation to compile time. Our framework is the first practical solution for on-device transfer learning of visual recognition on tiny IoT devices (e.g., a microcontroller with only 256KB SRAM), using less than 1/100 of the memory of existing frameworks while matching the accuracy of cloud training+edge deployment for the tinyML application VWW. Our study enables IoT devices to not only perform inference but also continuously adapt to new data for on-device lifelong learning.", "paper_url": "http://arxiv.org/abs/2206.15472v1", "pdf_url": "http://arxiv.org/pdf/2206.15472v1", "repo_url": null}, "2206.15369": {"publish_time": "2022-06-30", "title": "Improving the Generalization of Supervised Models", "author": "Mert Bulent Sariyildiz et.al.", "abstract": "We consider the problem of training a deep neural network on a given classification task, e.g., ImageNet-1K (IN1K), so that it excels at that task as well as at other (future) transfer tasks. These two seemingly contradictory properties impose a trade-off between improving the model's generalization while maintaining its performance on the original task. Models trained with self-supervised learning (SSL) tend to generalize better than their supervised counterparts for transfer learning; yet, they still lag behind supervised models on IN1K. In this paper, we propose a supervised learning setup that leverages the best of both worlds. We enrich the common supervised training framework using two key components of recent SSL models: multi-scale crops for data augmentation and the use of an expendable projector head. We replace the last layer of class weights with class prototypes computed on the fly using a memory bank. We show that these three improvements lead to a more favorable trade-off between the IN1K training task and 13 transfer tasks. Over all the explored configurations, we single out two models: t-ReX that achieves a new state of the art for transfer learning and outperforms top methods such as DINO and PAWS on IN1K, and t-ReX* that matches the highly optimized RSB-A1 model on IN1K while performing better on transfer tasks. Project page and pretrained models: https://europe.naverlabs.com/t-rex", "paper_url": "http://arxiv.org/abs/2206.15369v1", "pdf_url": "http://arxiv.org/pdf/2206.15369v1", "repo_url": null}, "2206.15306": {"publish_time": "2022-06-30", "title": "Transfer Learning with Deep Tabular Models", "author": "Roman Levin et.al.", "abstract": "Recent work on deep learning for tabular data demonstrates the strong performance of deep tabular models, often bridging the gap between gradient boosted decision trees and neural networks. Accuracy aside, a major advantage of neural models is that they learn reusable features and are easily fine-tuned in new domains. This property is often exploited in computer vision and natural language applications, where transfer learning is indispensable when task-specific training data is scarce. In this work, we demonstrate that upstream data gives tabular neural networks a decisive advantage over widely used GBDT models. We propose a realistic medical diagnosis benchmark for tabular transfer learning, and we present a how-to guide for using upstream data to boost performance with a variety of tabular neural network architectures. Finally, we propose a pseudo-feature method for cases where the upstream and downstream feature sets differ, a tabular-specific problem widespread in real-world applications. Our code is available at https://github.com/LevinRoman/tabular-transfer-learning .", "paper_url": "http://arxiv.org/abs/2206.15306v1", "pdf_url": "http://arxiv.org/pdf/2206.15306v1", "repo_url": "https://github.com/levinroman/tabular-transfer-learning"}, "2206.15163": {"publish_time": "2022-06-30", "title": "Efficient Entity Candidate Generation for Low-Resource Languages", "author": "Alberto Garc\u00eda-Dur\u00e1n et.al.", "abstract": "Candidate generation is a crucial module in entity linking. It also plays a key role in multiple NLP tasks that have been proven to beneficially leverage knowledge bases. Nevertheless, it has often been overlooked in the monolingual English entity linking literature, as naive approaches obtain very good performance. Unfortunately, the existing approaches for English cannot be successfully transferred to poorly resourced languages. This paper constitutes an in-depth analysis of the candidate generation problem in the context of cross-lingual entity linking with a focus on low-resource languages. Among other contributions, we point out limitations in the evaluation conducted in previous works. We introduce a characterization of queries into types based on their difficulty, which improves the interpretability of the performance of different methods. We also propose a light-weight and simple solution based on the construction of indexes whose design is motivated by more complex transfer learning based neural approaches. A thorough empirical analysis on 9 real-world datasets under 2 evaluation settings shows that our simple solution outperforms the state-of-the-art approach in terms of both quality and efficiency for almost all datasets and query types.", "paper_url": "http://arxiv.org/abs/2206.15163v1", "pdf_url": "http://arxiv.org/pdf/2206.15163v1", "repo_url": "https://github.com/epfl-dlab/pti-candgen"}, "2206.15144": {"publish_time": "2022-06-30", "title": "Neural Networks can Learn Representations with Gradient Descent", "author": "Alex Damian et.al.", "abstract": "Significant theoretical work has established that in specific regimes, neural networks trained by gradient descent behave like kernel methods. However, in practice, it is known that neural networks strongly outperform their associated kernels. In this work, we explain this gap by demonstrating that there is a large class of functions which cannot be efficiently learned by kernel methods but can be easily learned with gradient descent on a two layer neural network outside the kernel regime by learning representations that are relevant to the target task. We also demonstrate that these representations allow for efficient transfer learning, which is impossible in the kernel regime.   Specifically, we consider the problem of learning polynomials which depend on only a few relevant directions, i.e. of the form $f^\\star(x) = g(Ux)$ where $U: \\R^d \\to \\R^r$ with $d \\gg r$. When the degree of $f^\\star$ is $p$, it is known that $n \\asymp d^p$ samples are necessary to learn $f^\\star$ in the kernel regime. Our primary result is that gradient descent learns a representation of the data which depends only on the directions relevant to $f^\\star$. This results in an improved sample complexity of $n\\asymp d^2 r + dr^p$. Furthermore, in a transfer learning setup where the data distributions in the source and target domain share the same representation $U$ but have different polynomial heads we show that a popular heuristic for transfer learning has a target sample complexity independent of $d$.", "paper_url": "http://arxiv.org/abs/2206.15144v1", "pdf_url": "http://arxiv.org/pdf/2206.15144v1", "repo_url": null}, "2207.00259": {"publish_time": "2022-07-01", "title": "Covid-19 detection using transfer learning approach from computed temography images", "author": "Kenan Mornai et.al.", "abstract": "Our main goal in this study is to propose a transfer learning based method for COVID-19 detection from Computed Tomography (CT) images. The transfer learning model used for the task is a pretrained Xception model. Both model architecture and pre-trained weights on ImageNet were used. The resulting modified model was trained with 128 batch size and 224x224, 3 channeled input images, converted from original 512x512, grayscale images. The dataset used is a the COV19-CT-DB. Labels in the dataset include COVID-19 cases and Non-COVID-19 cases for COVID-1919 detection. Firstly, a accuracy and loss on the validation partition of the dataset as well as precision recall and macro F1 score were used to measure the performance of the proposed method. The resulting Macro F1 score on the validation set exceeded the baseline model.", "paper_url": "http://arxiv.org/abs/2207.00259v1", "pdf_url": "http://arxiv.org/pdf/2207.00259v1", "repo_url": null}, "2207.01584": {"publish_time": "2022-07-04", "title": "Classification of Alzheimer's Disease Using the Convolutional Neural Network (CNN) with Transfer Learning and Weighted Loss", "author": "Muhammad Wildan Oktavian et.al.", "abstract": "Alzheimer's disease is a progressive neurodegenerative disorder that gradually deprives the patient of cognitive function and can end in death. With the advancement of technology today, it is possible to detect Alzheimer's disease through Magnetic Resonance Imaging (MRI) scans. So that MRI is the technique most often used for the diagnosis and analysis of the progress of Alzheimer's disease. With this technology, image recognition in the early diagnosis of Alzheimer's disease can be achieved automatically using machine learning. Although machine learning has many advantages, currently the use of deep learning is more widely applied because it has stronger learning capabilities and is more suitable for solving image recognition problems. However, there are still several challenges that must be faced to implement deep learning, such as the need for large datasets, requiring large computing resources, and requiring careful parameter setting to prevent overfitting or underfitting. In responding to the challenge of classifying Alzheimer's disease using deep learning, this study propose the Convolutional Neural Network (CNN) method with the Residual Network 18 Layer (ResNet-18) architecture. To overcome the need for a large and balanced dataset, transfer learning from ImageNet is used and weighting the loss function values so that each class has the same weight. And also in this study conducted an experiment by changing the network activation function to a mish activation function to increase accuracy. From the results of the tests that have been carried out, the accuracy of the model is 88.3 % using transfer learning, weighted loss and the mish activation function. This accuracy value increases from the baseline model which only gets an accuracy of 69.1 %.", "paper_url": "http://arxiv.org/abs/2207.01584v1", "pdf_url": "http://arxiv.org/pdf/2207.01584v1", "repo_url": null}, "2207.01419": {"publish_time": "2022-07-04", "title": "A Robust Ensemble Model for Patasitic Egg Detection and Classification", "author": "Yuqi Wang et.al.", "abstract": "Intestinal parasitic infections, as a leading causes of morbidity worldwide, still lacks time-saving, high-sensitivity and user-friendly examination method. The development of deep learning technique reveals its broad application potential in biological image. In this paper, we apply several object detectors such as YOLOv5 and variant cascadeRCNNs to automatically discriminate parasitic eggs in microscope images. Through specially-designed optimization including raw data augmentation, model ensemble, transfer learning and test time augmentation, our model achieves excellent performance on challenge dataset. In addition, our model trained with added noise gains a high robustness against polluted input, which further broaden its applicability in practice.", "paper_url": "http://arxiv.org/abs/2207.01419v1", "pdf_url": "http://arxiv.org/pdf/2207.01419v1", "repo_url": null}, "2207.01301": {"publish_time": "2022-07-04", "title": "NodeTrans: A Graph Transfer Learning Approach for Traffic Prediction", "author": "Xueyan Yin et.al.", "abstract": "Recently, deep learning methods have made great progress in traffic prediction, but their performance depends on a large amount of historical data. In reality, we may face the data scarcity issue. In this case, deep learning models fail to obtain satisfactory performance. Transfer learning is a promising approach to solve the data scarcity issue. However, existing transfer learning approaches in traffic prediction are mainly based on regular grid data, which is not suitable for the inherent graph data in the traffic network. Moreover, existing graph-based models can only capture shared traffic patterns in the road network, and how to learn node-specific patterns is also a challenge. In this paper, we propose a novel transfer learning approach to solve the traffic prediction with few data, which can transfer the knowledge learned from a data-rich source domain to a data-scarce target domain. First, a spatial-temporal graph neural network is proposed, which can capture the node-specific spatial-temporal traffic patterns of different road networks. Then, to improve the robustness of transfer, we design a pattern-based transfer strategy, where we leverage a clustering-based mechanism to distill common spatial-temporal patterns in the source domain, and use these knowledge to further improve the prediction performance of the target domain. Experiments on real-world datasets verify the effectiveness of our approach.", "paper_url": "http://arxiv.org/abs/2207.01301v1", "pdf_url": "http://arxiv.org/pdf/2207.01301v1", "repo_url": null}, "2207.01084": {"publish_time": "2022-07-03", "title": "Enhancing Automated Software Traceability by Transfer Learning from Open-World Data", "author": "Jinfeng Lin et.al.", "abstract": "Software requirements traceability is a critical component of the software engineering process, enabling activities such as requirements validation, compliance verification, and safety assurance. However, the cost and effort of manually creating a complete set of trace links across natural language artifacts such as requirements, design, and test-cases can be prohibitively expensive. Researchers have therefore proposed automated link-generation solutions primarily based on information-retrieval (IR) techniques; however, these solutions have failed to deliver the accuracy needed for full adoption in industrial projects. Improvements can be achieved using deep-learning traceability models; however, their efficacy is impeded by the limited size and availability of project-level artifacts and links to serve as training data. In this paper, we address this problem by proposing and evaluating several deep-learning approaches for text-to-text traceability. Our method, named NLTrace, explores three transfer learning strategies that use datasets mined from open world platforms. Through pretraining Language Models (LMs) and leveraging adjacent tracing tasks, we demonstrate that NLTrace can significantly improve the performance of LM based trace models when training links are available. In such scenarios NLTrace outperforms the best performing classical IR method with an 188% improvement in F2 score and 94.01% in Mean Average Precision (MAP). It also outperforms the general LM based trace model by 7% and 23% for F2 and MAP respectively. In addition, NLTrace can adapt to low-resource tracing scenarios where other LM models can not. The knowledge learned from adjacent tasks enables NLTrace to outperform VSM models by 28% F2 on generation challenges when presented with a small number of training examples.", "paper_url": "http://arxiv.org/abs/2207.01084v1", "pdf_url": "http://arxiv.org/pdf/2207.01084v1", "repo_url": null}, "2207.01071": {"publish_time": "2022-07-03", "title": "You Only Need One Detector: Unified Object Detector for Different Modalities based on Vision Transformers", "author": "Xiaoke Shen et.al.", "abstract": "Most systems use different models for different modalities, such as one model for processing RGB images and one for depth images. Meanwhile, some recent works discovered that an identical model for one modality can be used for another modality with the help of cross modality transfer learning. In this article, we further find out that by using a vision transformer together with cross/inter modality transfer learning, a unified detector can achieve better performances when using different modalities as inputs. The unified model is useful as we don't need to maintain separate models or weights for robotics, hence, it is more efficient. One application scenario of our unified system for robotics can be: without any model architecture and model weights updating, robotics can switch smoothly on using RGB camera or both RGB and Depth Sensor during the day time and Depth sensor during the night time .   Experiments on SUN RGB-D dataset show: Our unified model is not only efficient, but also has a similar or better performance in terms of mAP50 based on SUNRGBD16 category: compare with the RGB only one, ours is slightly worse (52.3 $\\to$ 51.9). compare with the point cloud only one, we have similar performance (52.7 $\\to$ 52.8); When using the novel inter modality mixing method proposed in this work, our model can achieve a significantly better performance with 3.1 (52.7 $\\to$ 55.8) absolute improvement comparing with the previous best result. Code (including training/inference logs and model checkpoints) is available: \\url{https://github.com/liketheflower/YONOD.git}", "paper_url": "http://arxiv.org/abs/2207.01071v1", "pdf_url": "http://arxiv.org/pdf/2207.01071v1", "repo_url": "https://github.com/liketheflower/yonod"}, "2207.02066": {"publish_time": "2022-07-05", "title": "Test-time Adaptation for Real Image Denoising via Meta-transfer Learning", "author": "Agus Gunawan et.al.", "abstract": "In recent years, a ton of research has been conducted on real image denoising tasks. However, the efforts are more focused on improving real image denoising through creating a better network architecture. We explore a different direction where we propose to improve real image denoising performance through a better learning strategy that can enable test-time adaptation on the multi-task network. The learning strategy is two stages where the first stage pre-train the network using meta-auxiliary learning to get better meta-initialization. Meanwhile, we use meta-learning for fine-tuning (meta-transfer learning) the network as the second stage of our training to enable test-time adaptation on real noisy images. To exploit a better learning strategy, we also propose a network architecture with self-supervised masked reconstruction loss. Experiments on a real noisy dataset show the contribution of the proposed method and show that the proposed method can outperform other SOTA methods.", "paper_url": "http://arxiv.org/abs/2207.02066v1", "pdf_url": "http://arxiv.org/pdf/2207.02066v1", "repo_url": null}, "2207.01784": {"publish_time": "2022-07-05", "title": "A Unified Meta-Learning Framework for Dynamic Transfer Learning", "author": "Jun Wu et.al.", "abstract": "Transfer learning refers to the transfer of knowledge or information from a relevant source task to a target task. However, most existing works assume both tasks are sampled from a stationary task distribution, thereby leading to the sub-optimal performance for dynamic tasks drawn from a non-stationary task distribution in real scenarios. To bridge this gap, in this paper, we study a more realistic and challenging transfer learning setting with dynamic tasks, i.e., source and target tasks are continuously evolving over time. We theoretically show that the expected error on the dynamic target task can be tightly bounded in terms of source knowledge and consecutive distribution discrepancy across tasks. This result motivates us to propose a generic meta-learning framework L2E for modeling the knowledge transferability on dynamic tasks. It is centered around a task-guided meta-learning problem with a group of meta-pairs of tasks, based on which we are able to learn the prior model initialization for fast adaptation on the newest target task. L2E enjoys the following properties: (1) effective knowledge transferability across dynamic tasks; (2) fast adaptation to the new target task; (3) mitigation of catastrophic forgetting on historical target tasks; and (4) flexibility in incorporating any existing static transfer learning algorithms. Extensive experiments on various image data sets demonstrate the effectiveness of the proposed L2E framework.", "paper_url": "http://arxiv.org/abs/2207.01784v1", "pdf_url": "http://arxiv.org/pdf/2207.01784v1", "repo_url": "https://github.com/jwu4sml/l2e"}, "2207.01772": {"publish_time": "2022-07-05", "title": "Vision-and-Language Pretraining", "author": "Thong Nguyen et.al.", "abstract": "With the burgeoning amount of data of image-text pairs and diversity of Vision-and-Language (V&L) tasks, scholars have introduced an abundance of deep learning models in this research domain. Furthermore, in recent years, transfer learning has also shown tremendous success in Computer Vision for tasks such as Image Classification, Object Detection, etc., and in Natural Language Processing for Question Answering, Machine Translation, etc. Inheriting the spirit of Transfer Learning, research works in V&L have devised multiple pretraining techniques on large-scale datasets in order to enhance the performance of downstream tasks. The aim of this article is to provide a comprehensive revision of contemporary V&L pretraining models. In particular, we categorize and delineate pretraining approaches, along with the summary of state-of-the-art vision-and-language pre-trained models. Moreover, a list of training datasets and downstream tasks is supplied to further polish the perspective on V&L pretraining. Lastly, we decided to take a further step to discuss numerous directions for future research.", "paper_url": "http://arxiv.org/abs/2207.01772v1", "pdf_url": "http://arxiv.org/pdf/2207.01772v1", "repo_url": null}, "2207.02842": {"publish_time": "2022-07-06", "title": "When does Bias Transfer in Transfer Learning?", "author": "Hadi Salman et.al.", "abstract": "Using transfer learning to adapt a pre-trained \"source model\" to a downstream \"target task\" can dramatically increase performance with seemingly no downside. In this work, we demonstrate that there can exist a downside after all: bias transfer, or the tendency for biases of the source model to persist even after adapting the model to the target class. Through a combination of synthetic and natural experiments, we show that bias transfer both (a) arises in realistic settings (such as when pre-training on ImageNet or other standard datasets) and (b) can occur even when the target dataset is explicitly de-biased. As transfer-learned models are increasingly deployed in the real world, our work highlights the importance of understanding the limitations of pre-trained source models. Code is available at https://github.com/MadryLab/bias-transfer", "paper_url": "http://arxiv.org/abs/2207.02842v1", "pdf_url": "http://arxiv.org/pdf/2207.02842v1", "repo_url": null}, "2207.02724": {"publish_time": "2022-07-06", "title": "Pre-training Transformers for Molecular Property Prediction Using Reaction Prediction", "author": "Johan Broberg et.al.", "abstract": "Molecular property prediction is essential in chemistry, especially for drug discovery applications. However, available molecular property data is often limited, encouraging the transfer of information from related data. Transfer learning has had a tremendous impact in fields like Computer Vision and Natural Language Processing signaling for its potential in molecular property prediction. We present a pre-training procedure for molecular representation learning using reaction data and use it to pre-train a SMILES Transformer. We fine-tune and evaluate the pre-trained model on 12 molecular property prediction tasks from MoleculeNet within physical chemistry, biophysics, and physiology and show a statistically significant positive effect on 5 of the 12 tasks compared to a non-pre-trained baseline model.", "paper_url": "http://arxiv.org/abs/2207.02724v1", "pdf_url": "http://arxiv.org/pdf/2207.02724v1", "repo_url": null}, "2207.02515": {"publish_time": "2022-07-06", "title": "Lightweight Encoder-Decoder Architecture for Foot Ulcer Segmentation", "author": "Shahzad Ali et.al.", "abstract": "Continuous monitoring of foot ulcer healing is needed to ensure the efficacy of a given treatment and to avoid any possibility of deterioration. Foot ulcer segmentation is an essential step in wound diagnosis. We developed a model that is similar in spirit to the well-established encoder-decoder and residual convolution neural networks. Our model includes a residual connection along with a channel and spatial attention integrated within each convolution block. A simple patch-based approach for model training, test time augmentations, and majority voting on the obtained predictions resulted in superior performance. Our model did not leverage any readily available backbone architecture, pre-training on a similar external dataset, or any of the transfer learning techniques. The total number of network parameters being around 5 million made it a significantly lightweight model as compared with the available state-of-the-art models used for the foot ulcer segmentation task. Our experiments presented results at the patch-level and image-level. Applied on publicly available Foot Ulcer Segmentation (FUSeg) Challenge dataset from MICCAI 2021, our model achieved state-of-the-art image-level performance of 88.22% in terms of Dice similarity score and ranked second in the official challenge leaderboard. We also showed an extremely simple solution that could be compared against the more advanced architectures.", "paper_url": "http://arxiv.org/abs/2207.02515v1", "pdf_url": "http://arxiv.org/pdf/2207.02515v1", "repo_url": null}, "2207.02445": {"publish_time": "2022-07-06", "title": "Distillation to Enhance the Portability of Risk Models Across Institutions with Large Patient Claims Database", "author": "Steve Nyemba et.al.", "abstract": "Artificial intelligence, and particularly machine learning (ML), is increasingly developed and deployed to support healthcare in a variety of settings. However, clinical decision support (CDS) technologies based on ML need to be portable if they are to be adopted on a broad scale. In this respect, models developed at one institution should be reusable at another. Yet there are numerous examples of portability failure, particularly due to naive application of ML models. Portability failure can lead to suboptimal care and medical errors, which ultimately could prevent the adoption of ML-based CDS in practice. One specific healthcare challenge that could benefit from enhanced portability is the prediction of 30-day readmission risk. Research to date has shown that deep learning models can be effective at modeling such risk. In this work, we investigate the practicality of model portability through a cross-site evaluation of readmission prediction models. To do so, we apply a recurrent neural network, augmented with self-attention and blended with expert features, to build readmission prediction models for two independent large scale claims datasets. We further present a novel transfer learning technique that adapts the well-known method of born-again network (BAN) training. Our experiments show that direct application of ML models trained at one institution and tested at another institution perform worse than models trained and tested at the same institution. We further show that the transfer learning approach based on the BAN produces models that are better than those trained on just a single institution's data. Notably, this improvement is consistent across both sites and occurs after a single retraining, which illustrates the potential for a cheap and general model transfer mechanism of readmission risk prediction.", "paper_url": "http://arxiv.org/abs/2207.02445v1", "pdf_url": "http://arxiv.org/pdf/2207.02445v1", "repo_url": null}, "2207.02337": {"publish_time": "2022-07-05", "title": "Federated and Transfer Learning: A Survey on Adversaries and Defense Mechanisms", "author": "Ehsan Hallaji et.al.", "abstract": "The advent of federated learning has facilitated large-scale data exchange amongst machine learning models while maintaining privacy. Despite its brief history, federated learning is rapidly evolving to make wider use more practical. One of the most significant advancements in this domain is the incorporation of transfer learning into federated learning, which overcomes fundamental constraints of primary federated learning, particularly in terms of security. This chapter performs a comprehensive survey on the intersection of federated and transfer learning from a security point of view. The main goal of this study is to uncover potential vulnerabilities and defense mechanisms that might compromise the privacy and performance of systems that use federated and transfer learning.", "paper_url": "http://arxiv.org/abs/2207.02337v1", "pdf_url": "http://arxiv.org/pdf/2207.02337v1", "repo_url": null}, "2207.03139": {"publish_time": "2022-07-07", "title": "Application of Transfer Learning to Neutrino Interaction Classification", "author": "Andrew Chappell et.al.", "abstract": "Training deep neural networks using simulations typically requires very large numbers of simulated events. This can be a large computational burden and a limitation in the performance of the deep learning algorithm when insufficient numbers of events can be produced. We investigate the use of transfer learning, where a set of simulated images are used to fine tune a model trained on generic image recognition tasks, to the specific use case of neutrino interaction classification in a liquid argon time projection chamber. A ResNet18, pre-trained on photographic images, was fine-tuned using simulated neutrino images and when trained with one hundred thousand training events reached an F1 score of $0.896 \\pm 0.002$ compared to $0.836 \\pm 0.004$ from a randomly-initialised network trained with the same training sample.", "paper_url": "http://arxiv.org/abs/2207.03139v1", "pdf_url": "http://arxiv.org/pdf/2207.03139v1", "repo_url": null}, "2207.03112": {"publish_time": "2022-07-07", "title": "Design of Human Machine Interface through vision-based low-cost Hand Gesture Recognition system based on deep CNN with transfer-learning approach", "author": "Abir Sen et.al.", "abstract": "In this work, a real-time hand gesture recognition system-based human-computer interface (HCI) is presented. The system consists of six stages: (1) hand detection, (2) gesture segmentation, (3) use of six pre-trained CNN models by using the transfer-learning method, (4) building an interactive human-machine interface, (5) development of a gesture-controlled virtual mouse, (6) use of Kalman filter to estimate the hand position, based on that the smoothness of the motion of pointer is improved. Six pre-trained convolutional neural network (CNN) models (VGG16, VGG19, ResNet50, ResNet101, Inception-V1, and MobileNet-V1) have been used to classify hand gesture images. Three multi-class datasets (two publicly and one custom) have been used to evaluate the model performances. Considering the models' performances, it has been observed that Inception-V1 has significantly shown a better classification performance compared to the other five pre-trained models in terms of accuracy, precision, recall, and F-score values. The gesture recognition system is expanded and used to control multimedia applications (like VLC player, audio player, file management, playing 2D Super-Mario-Bros game, etc.) with different customized gesture commands in real-time scenarios. The average speed of this system has reached 35 fps (frame per seconds), which meets the requirements for the real-time scenario.", "paper_url": "http://arxiv.org/abs/2207.03112v1", "pdf_url": "http://arxiv.org/pdf/2207.03112v1", "repo_url": null}, "2207.03046": {"publish_time": "2022-07-07", "title": "Self-Supervised RF Signal Representation Learning for NextG Signal Classification with Deep Learning", "author": "Kemal Davaslioglu et.al.", "abstract": "Deep learning (DL) finds rich applications in the wireless domain to improve spectrum awareness. Typically, the DL models are either randomly initialized following a statistical distribution or pretrained on tasks from other data domains such as computer vision (in the form of transfer learning) without accounting for the unique characteristics of wireless signals. Self-supervised learning enables the learning of useful representations from Radio Frequency (RF) signals themselves even when only limited training data samples with labels are available. We present the first self-supervised RF signal representation learning model and apply it to the automatic modulation recognition (AMR) task by specifically formulating a set of transformations to capture the wireless signal characteristics. We show that the sample efficiency (the number of labeled samples required to achieve a certain accuracy performance) of AMR can be significantly increased (almost an order of magnitude) by learning signal representations with self-supervised learning. This translates to substantial time and cost savings. Furthermore, self-supervised learning increases the model accuracy compared to the state-of-the-art DL methods and maintains high accuracy even when a small set of training data samples is used.", "paper_url": "http://arxiv.org/abs/2207.03046v1", "pdf_url": "http://arxiv.org/pdf/2207.03046v1", "repo_url": null}, "2207.03331": {"publish_time": "2022-07-06", "title": "Low-resource Low-footprint Wake-word Detection using Knowledge Distillation", "author": "Arindam Ghosh et.al.", "abstract": "As virtual assistants have become more diverse and specialized, so has the demand for application or brand-specific wake words. However, the wake-word-specific datasets typically used to train wake-word detectors are costly to create. In this paper, we explore two techniques to leverage acoustic modeling data for large-vocabulary speech recognition to improve a purpose-built wake-word detector: transfer learning and knowledge distillation. We also explore how these techniques interact with time-synchronous training targets to improve detection latency. Experiments are presented on the open-source \"Hey Snips\" dataset and a more challenging in-house far-field dataset. Using phone-synchronous targets and knowledge distillation from a large acoustic model, we are able to improve accuracy across dataset sizes for both datasets while reducing latency.", "paper_url": "http://arxiv.org/abs/2207.03331v1", "pdf_url": "http://arxiv.org/pdf/2207.03331v1", "repo_url": null}}}, "Graph Neural Network": {"Graph Neural Network": {"2202.12619": {"publish_time": "2022-02-25", "title": "Fluid Simulation System Based on Graph Neural Network", "author": "Qiang Liu et.al.", "abstract": "Traditional computational fluid dynamics calculates the physical information of the flow field by solving partial differential equations, which takes a long time to calculate and consumes a lot of computational resources. We build a fluid simulation simulator based on the graph neural network architecture. The simulator has fast computing speed and low consumption of computing resources. We regard the computational domain as a structural graph, and the computational nodes in the structural graph determine neighbor nodes through adaptive sampling. Building deep learning architectures with attention graph neural networks. The fluid simulation simulator is trained according to the simulation results of the flow field around the cylinder with different Reynolds numbers. The trained fluid simulation simulator not only has a very high accuracy for the prediction of the flow field in the training set, but also can extrapolate the flow field outside the training set. Compared to traditional CFD solvers, the fluid simulation simulator achieves a speedup of 2-3 orders of magnitude. The fluid simulation simulator provides new ideas for the rapid optimization and design of fluid mechanics models and the real-time control of intelligent fluid mechanisms.", "paper_url": "http://arxiv.org/abs/2202.12619v1", "pdf_url": "http://arxiv.org/pdf/2202.12619v1", "repo_url": null}, "2202.12586": {"publish_time": "2022-02-25", "title": "Spatio-Temporal Latent Graph Structure Learning for Traffic Forecasting", "author": "Jiabin Tang et.al.", "abstract": "Accurate traffic forecasting, the foundation of intelligent transportation systems (ITS), has never been more significant than nowadays due to the prosperity of the smart cities and urban computing. Recently, Graph Neural Network truly outperforms the traditional methods. Nevertheless, the most conventional GNN based model works well while given a pre-defined graph structure. And the existing methods of defining the graph structures focus purely on spatial dependencies and ignored the temporal correlation. Besides, the semantics of the static pre-defined graph adjacency applied during the whole training progress is always incomplete, thus overlooking the latent topologies that may fine-tune the model. To tackle these challenges, we proposed a new traffic forecasting framework--Spatio-Temporal Latent Graph Structure Learning networks (ST-LGSL). More specifically, the model employed a graph generator based on Multilayer perceptron and K-Nearest Neighbor, which learns the latent graph topological information from the entire data considering both spatial and temporal dynamics. Furthermore, with the initialization of MLP-kNN based on ground-truth adjacency matrix and similarity metric in kNN, ST-LGSL aggregates the topologies focusing on geography and node similarity. Additionally, the generated graphs act as the input of spatio-temporal prediction module combined with the Diffusion Graph Convolutions and Gated Temporal Convolutions Networks. Experimental results on two benchmarking datasets in real world demonstrate that ST-LGSL outperforms various types of state-of-art baselines.", "paper_url": "http://arxiv.org/abs/2202.12586v1", "pdf_url": "http://arxiv.org/pdf/2202.12586v1", "repo_url": null}, "2202.12508": {"publish_time": "2022-02-25", "title": "Addressing Over-Smoothing in Graph Neural Networks via Deep Supervision", "author": "Pantelis Elinas et.al.", "abstract": "Learning useful node and graph representations with graph neural networks (GNNs) is a challenging task. It is known that deep GNNs suffer from over-smoothing where, as the number of layers increases, node representations become nearly indistinguishable and model performance on the downstream task degrades significantly. To address this problem, we propose deeply-supervised GNNs (DSGNNs), i.e., GNNs enhanced with deep supervision where representations learned at all layers are used for training. We show empirically that DSGNNs are resilient to over-smoothing and can outperform competitive benchmarks on node and graph property prediction problems.", "paper_url": "http://arxiv.org/abs/2202.12508v1", "pdf_url": "http://arxiv.org/pdf/2202.12508v1", "repo_url": null}, "2202.12481": {"publish_time": "2022-02-25", "title": "Multi-View Graph Representation for Programming Language Processing: An Investigation into Algorithm Detection", "author": "Ting Long et.al.", "abstract": "Program representation, which aims at converting program source code into vectors with automatically extracted features, is a fundamental problem in programming language processing (PLP). Recent work tries to represent programs with neural networks based on source code structures. However, such methods often focus on the syntax and consider only one single perspective of programs, limiting the representation power of models. This paper proposes a multi-view graph (MVG) program representation method. MVG pays more attention to code semantics and simultaneously includes both data flow and control flow as multiple views. These views are then combined and processed by a graph neural network (GNN) to obtain a comprehensive program representation that covers various aspects. We thoroughly evaluate our proposed MVG approach in the context of algorithm detection, an important and challenging subfield of PLP. Specifically, we use a public dataset POJ-104 and also construct a new challenging dataset ALG-109 to test our method. In experiments, MVG outperforms previous methods significantly, demonstrating our model's strong capability of representing source code.", "paper_url": "http://arxiv.org/abs/2202.12481v1", "pdf_url": "http://arxiv.org/pdf/2202.12481v1", "repo_url": null}, "2202.12478": {"publish_time": "2022-02-25", "title": "GAME-ON: Graph Attention Network based Multimodal Fusion for Fake News Detection", "author": "Mudit Dhawan et.al.", "abstract": "Social media in present times has a significant and growing influence. Fake news being spread on these platforms have a disruptive and damaging impact on our lives. Furthermore, as multimedia content improves the visibility of posts more than text data, it has been observed that often multimedia is being used for creating fake content. A plethora of previous multimodal-based work has tried to address the problem of modeling heterogeneous modalities in identifying fake content. However, these works have the following limitations: (1) inefficient encoding of inter-modal relations by utilizing a simple concatenation operator on the modalities at a later stage in a model, which might result in information loss; (2) training very deep neural networks with a disproportionate number of parameters on small but complex real-life multimodal datasets result in higher chances of overfitting. To address these limitations, we propose GAME-ON, a Graph Neural Network based end-to-end trainable framework that allows granular interactions within and across different modalities to learn more robust data representations for multimodal fake news detection. We use two publicly available fake news datasets, Twitter and Weibo, for evaluations. Our model outperforms on Twitter by an average of 11% and keeps competitive performance on Weibo, within a 2.6% margin, while using 65% fewer parameters than the best comparable state-of-the-art baseline.", "paper_url": "http://arxiv.org/abs/2202.12478v1", "pdf_url": "http://arxiv.org/pdf/2202.12478v1", "repo_url": null}, "2202.13956": {"publish_time": "2022-02-28", "title": "RouteNet-Erlang: A Graph Neural Network for Network Performance Evaluation", "author": "Miquel Ferriol-Galm\u00e9s et.al.", "abstract": "Network modeling is a fundamental tool in network research, design, and operation. Arguably the most popular method for modeling is Queuing Theory (QT). Its main limitation is that it imposes strong assumptions on the packet arrival process, which typically do not hold in real networks. In the field of Deep Learning, Graph Neural Networks (GNN) have emerged as a new technique to build data-driven models that can learn complex and non-linear behavior. In this paper, we present \\emph{RouteNet-Erlang}, a pioneering GNN architecture designed to model computer networks. RouteNet-Erlang supports complex traffic models, multi-queue scheduling policies, routing policies and can provide accurate estimates in networks not seen in the training phase. We benchmark RouteNet-Erlang against a state-of-the-art QT model, and our results show that it outperforms QT in all the network scenarios.", "paper_url": "http://arxiv.org/abs/2202.13956v1", "pdf_url": "http://arxiv.org/pdf/2202.13956v1", "repo_url": null}, "2202.13947": {"publish_time": "2022-02-28", "title": "Data-Augmentation for Graph Neural Network Learning of the Relaxed Energies of Unrelaxed Structures", "author": "Jason B. Gibson et.al.", "abstract": "Computational materials discovery has continually grown in utility over the past decade due to advances in computing power and crystal structure prediction algorithms (CSPA). However, the computational cost of the \\textit{ab initio} calculations required by CSPA limits its utility to small unit cells, reducing the compositional and structural space the algorithms can explore. Past studies have bypassed many unneeded \\textit{ab initio} calculations by utilizing machine learning methods to predict formation energy and determine the stability of a material. Specifically, graph neural networks display high fidelity in predicting formation energy. Traditionally graph neural networks are trained on large data sets of relaxed structures. Unfortunately, the geometries of unrelaxed candidate structures produced by CSPA often deviate from the relaxed state, which leads to poor predictions hindering the model's ability to filter energetically unfavorable prior to \\textit{ab initio} evaluation. This work shows that the prediction error on relaxed structures reduces as training progresses, while the prediction error on unrelaxed structures increases, suggesting an inverse correlation between relaxed and unrelaxed structure prediction accuracy. To remedy this behavior, we propose a simple, physically motivated, computationally cheap perturbation technique that augments training data to improve predictions on unrelaxed structures dramatically. On our test set consisting of 623 Nb-Sr-H hydride structures, we found that training a crystal graph convolutional neural networks, utilizing our augmentation method, reduced the MAE of formation energy prediction by 66\\% compared to training with only relaxed structures. We then show how this error reduction can accelerates CSPA by improving the model's ability to filter out energetically unfavorable structures accurately.", "paper_url": "http://arxiv.org/abs/2202.13947v1", "pdf_url": "http://arxiv.org/pdf/2202.13947v1", "repo_url": null}, "2202.13852": {"publish_time": "2022-02-28", "title": "Hyperbolic Graph Neural Networks: A Review of Methods and Applications", "author": "Menglin Yang et.al.", "abstract": "Graph neural networks generalize conventional neural networks to graph-structured data and have received widespread attention due to their impressive representation ability. In spite of the remarkable achievements, the performance of Euclidean models in graph-related learning is still bounded and limited by the representation ability of Euclidean geometry, especially for datasets with highly non-Euclidean latent anatomy. Recently, hyperbolic space has gained increasing popularity in processing graph data with tree-like structure and power-law distribution, owing to its exponential growth property. In this survey, we comprehensively revisit the technical details of the current hyperbolic graph neural networks, unifying them into a general framework and summarizing the variants of each component. More importantly, we present various HGNN-related applications. Last, we also identify several challenges, which potentially serve as guidelines for further flourishing the achievements of graph learning in hyperbolic spaces.", "paper_url": "http://arxiv.org/abs/2202.13852v1", "pdf_url": "http://arxiv.org/pdf/2202.13852v1", "repo_url": "https://github.com/marlin-codes/HGNNs"}, "2202.13800": {"publish_time": "2022-02-28", "title": "Differential equation and probability inspired graph neural networks for latent variable learning", "author": "Zhuangwei Shi et.al.", "abstract": "Probabilistic theory and differential equation are powerful tools for the interpretability and guidance of the design of machine learning models, especially for illuminating the mathematical motivation of learning latent variable from observation. State estimation and subspace learning are two classical problems in latent variable learning. State estimation solves optimal value for latent variable (i.e. state) from noised observation. Subspace learning maps high-dimensional features on low-dimensional subspace to capture efficient representation. Graphs are widely applied for modeling latent variable learning problems, and graph neural networks implement deep learning architectures on graphs. Inspired by probabilistic theory and differential equations, this paper proposes graph neural networks to solve state estimation and subspace learning problems. This paper conducts theoretical studies, and adopts empirical studies on several tasks, including text classification, protein classification, stock prediction and state estimation for robotics. Experiments illustrate that the proposed graph neural networks are superior to the current methods. Source code of this paper is available at https://github.com/zshicode/Latent-variable-GNN.", "paper_url": "http://arxiv.org/abs/2202.13800v1", "pdf_url": "http://arxiv.org/pdf/2202.13800v1", "repo_url": "https://github.com/zshicode/latent-variable-gnn"}, "2202.13686": {"publish_time": "2022-02-28", "title": "Points-of-Interest Relationship Inference with Spatial-enriched Graph Neural Networks", "author": "Yile Chen et.al.", "abstract": "As a fundamental component in location-based services, inferring the relationship between points-of-interests (POIs) is very critical for service providers to offer good user experience to business owners and customers. Most of the existing methods for relationship inference are not targeted at POI, thus failing to capture unique spatial characteristics that have huge effects on POI relationships. In this work we propose PRIM to tackle POI relationship inference for multiple relation types. PRIM features four novel components, including a weighted relational graph neural network, category taxonomy integration, a self-attentive spatial context extractor, and a distance-specific scoring function. Extensive experiments on two real-world datasets show that PRIM achieves the best results compared to state-of-the-art baselines and it is robust against data sparsity and is applicable to unseen cases in practice.", "paper_url": "http://arxiv.org/abs/2202.13686v1", "pdf_url": "http://arxiv.org/pdf/2202.13686v1", "repo_url": null}, "2203.00638": {"publish_time": "2022-03-01", "title": "PaSca: a Graph Neural Architecture Search System under the Scalable Paradigm", "author": "Wentao Zhang et.al.", "abstract": "Graph neural networks (GNNs) have achieved state-of-the-art performance in various graph-based tasks. However, as mainstream GNNs are designed based on the neural message passing mechanism, they do not scale well to data size and message passing steps. Although there has been an emerging interest in the design of scalable GNNs, current researches focus on specific GNN design, rather than the general design space, limiting the discovery of potential scalable GNN models. This paper proposes PasCa, a new paradigm and system that offers a principled approach to systemically construct and explore the design space for scalable GNNs, rather than studying individual designs. Through deconstructing the message passing mechanism, PasCa presents a novel Scalable Graph Neural Architecture Paradigm (SGAP), together with a general architecture design space consisting of 150k different designs. Following the paradigm, we implement an auto-search engine that can automatically search well-performing and scalable GNN architectures to balance the trade-off between multiple criteria (e.g., accuracy and efficiency) via multi-objective optimization. Empirical studies on ten benchmark datasets demonstrate that the representative instances (i.e., PasCa-V1, V2, and V3) discovered by our system achieve consistent performance among competitive baselines. Concretely, PasCa-V3 outperforms the state-of-the-art GNN method JK-Net by 0.4\\% in terms of predictive accuracy on our large industry dataset while achieving up to $28.3\\times$ training speedups.", "paper_url": "http://arxiv.org/abs/2203.00638v1", "pdf_url": "http://arxiv.org/pdf/2203.00638v1", "repo_url": null}, "2203.00611": {"publish_time": "2022-03-01", "title": "Learning Intermediate Representations using Graph Neural Networks for NUMA and Prefetchers Optimization", "author": "Ali TehraniJamsaz et.al.", "abstract": "There is a large space of NUMA and hardware prefetcher configurations that can significantly impact the performance of an application. Previous studies have demonstrated how a model can automatically select configurations based on the dynamic properties of the code to achieve speedups. This paper demonstrates how the static Intermediate Representation (IR) of the code can guide NUMA/prefetcher optimizations without the prohibitive cost of performance profiling. We propose a method to create a comprehensive dataset that includes a diverse set of intermediate representations along with optimum configurations. We then apply a graph neural network model in order to validate this dataset. We show that our static intermediate representation based model achieves 80% of the performance gains provided by expensive dynamic performance profiling based strategies. We further develop a hybrid model that uses both static and dynamic information. Our hybrid model achieves the same gains as the dynamic models but at a reduced cost by only profiling 30% of the programs.", "paper_url": "http://arxiv.org/abs/2203.00611v1", "pdf_url": "http://arxiv.org/pdf/2203.00611v1", "repo_url": null}, "2203.00387": {"publish_time": "2022-03-01", "title": "Motion-aware Dynamic Graph Neural Network for Video Compressive Sensing", "author": "Ruiying Lu et.al.", "abstract": "Video snapshot compressive imaging (SCI) utilizes a 2D detector to capture sequential video frames and compresses them into a single measurement. Various reconstruction methods have been developed to recover the high-speed video frames from the snapshot measurement. However, most existing reconstruction methods are incapable of capturing long-range spatial and temporal dependencies, which are critical for video processing. In this paper, we propose a flexible and robust approach based on graph neural network (GNN) to efficiently model non-local interactions between pixels in space as well as time regardless of the distance. Specifically, we develop a motion-aware dynamic GNN for better video representation, i.e., represent each pixel as the aggregation of relative nodes under the guidance of frame-by-frame motions, which consists of motion-aware dynamic sampling, cross-scale node sampling and graph aggregation. Extensive results on both simulation and real data demonstrate both the effectiveness and efficiency of the proposed approach, and the visualization clearly illustrates the intrinsic dynamic sampling operations of our proposed model for boosting the video SCI reconstruction results. The code and models will be released to the public.", "paper_url": "http://arxiv.org/abs/2203.00387v1", "pdf_url": "http://arxiv.org/pdf/2203.00387v1", "repo_url": null}, "2203.00330": {"publish_time": "2022-03-01", "title": "Machine Learning for Particle Flow Reconstruction at CMS", "author": "Joosep Pata et.al.", "abstract": "We provide details on the implementation of a machine-learning based particle flow algorithm for CMS. The standard particle flow algorithm reconstructs stable particles based on calorimeter clusters and tracks to provide a global event reconstruction that exploits the combined information of multiple detector subsystems, leading to strong improvements for quantities such as jets and missing transverse energy. We have studied a possible evolution of particle flow towards heterogeneous computing platforms such as GPUs using a graph neural network. The machine-learned PF model reconstructs particle candidates based on the full list of tracks and calorimeter clusters in the event. For validation, we determine the physics performance directly in the CMS software framework when the proposed algorithm is interfaced with the offline reconstruction of jets and missing transverse energy. We also report the computational performance of the algorithm, which scales approximately linearly in runtime and memory usage with the input size.", "paper_url": "http://arxiv.org/abs/2203.00330v1", "pdf_url": "http://arxiv.org/pdf/2203.00330v1", "repo_url": null}, "2203.00199": {"publish_time": "2022-03-01", "title": "Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks", "author": "Haorui Wang et.al.", "abstract": "Graph neural networks (GNN) have shown great advantages in many graph-based learning tasks but often fail to predict accurately for a task-based on sets of nodes such as link/motif prediction and so on. Many works have recently proposed to address this problem by using random node features or node distance features. However, they suffer from either slow convergence, inaccurate prediction, or high complexity. In this work, we revisit GNNs that allow using positional features of nodes given by positional encoding (PE) techniques such as Laplacian Eigenmap, Deepwalk, etc. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable. Here, we study these issues in a principled way and propose a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. PEG uses separate channels to update the original node features and positional features. PEG imposes permutation equivariance w.r.t. the original node features and rotation equivariance w.r.t. the positional features simultaneously. Extensive link prediction experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability.", "paper_url": "http://arxiv.org/abs/2203.00199v1", "pdf_url": "http://arxiv.org/pdf/2203.00199v1", "repo_url": "https://github.com/graph-com/peg"}, "2203.01189": {"publish_time": "2022-03-02", "title": "GNN-based end-to-end reconstruction in the CMS Phase 2 High-Granularity Calorimeter", "author": "Saptaparna Bhattacharya et.al.", "abstract": "We present the current stage of research progress towards a one-pass, completely Machine Learning (ML) based imaging calorimeter reconstruction. The model used is based on Graph Neural Networks (GNNs) and directly analyzes the hits in each HGCAL endcap. The ML algorithm is trained to predict clusters of hits originating from the same incident particle by labeling the hits with the same cluster index. We impose simple criteria to assess whether the hits associated as a cluster by the prediction are matched to those hits resulting from any particular individual incident particles. The algorithm is studied by simulating two tau leptons in each of the two HGCAL endcaps, where each tau may decay according to its measured standard model branching probabilities. The simulation includes the material interaction of the tau decay products which may create additional particles incident upon the calorimeter. Using this varied multiparticle environment we can investigate the application of this reconstruction technique and begin to characterize energy containment and performance.", "paper_url": "http://arxiv.org/abs/2203.01189v1", "pdf_url": "http://arxiv.org/pdf/2203.01189v1", "repo_url": null}, "2203.01187": {"publish_time": "2022-03-02", "title": "Visual Feature Encoding for GNNs on Road Networks", "author": "Oliver Stromann et.al.", "abstract": "In this work, we present a novel approach to learning an encoding of visual features into graph neural networks with the application on road network data. We propose an architecture that combines state-of-the-art vision backbone networks with graph neural networks. More specifically, we perform a road type classification task on an Open Street Map road network through encoding of satellite imagery using various ResNet architectures. Our architecture further enables fine-tuning and a transfer-learning approach is evaluated by pretraining on the NWPU-RESISC45 image classification dataset for remote sensing and comparing them to purely ImageNet-pretrained ResNet models as visual feature encoders. The results show not only that the visual feature encoders are superior to low-level visual features, but also that the fine-tuning of the visual feature encoder to a general remote sensing dataset such as NWPU-RESISC45 can further improve the performance of a GNN on a machine learning task like road type classification.", "paper_url": "http://arxiv.org/abs/2203.01187v1", "pdf_url": "http://arxiv.org/pdf/2203.01187v1", "repo_url": null}, "2203.01112": {"publish_time": "2022-03-02", "title": "Hyperparameter optimization of data-driven AI models on HPC systems", "author": "Eric Wulff et.al.", "abstract": "In the European Center of Excellence in Exascale computing \"Research on AI- and Simulation-Based Engineering at Exascale\" (CoE RAISE), researchers develop novel, scalable AI technologies towards Exascale. This work exercises High Performance Computing resources to perform large-scale hyperparameter optimization using distributed training on multiple compute nodes. This is part of RAISE's work on data-driven use cases which leverages AI- and HPC cross-methods developed within the project. In response to the demand for parallelizable and resource efficient hyperparameter optimization methods, advanced hyperparameter search algorithms are benchmarked and compared. The evaluated algorithms, including Random Search, Hyperband and ASHA, are tested and compared in terms of both accuracy and accuracy per compute resources spent. As an example use case, a graph neural network model known as MLPF, developed for the task of Machine-Learned Particle-Flow reconstruction in High Energy Physics, acts as the base model for optimization. Results show that hyperparameter optimization significantly increased the performance of MLPF and that this would not have been possible without access to large-scale High Performance Computing resources. It is also shown that, in the case of MLPF, the ASHA algorithm in combination with Bayesian optimization gives the largest performance increase per compute resources spent out of the investigated algorithms.", "paper_url": "http://arxiv.org/abs/2203.01112v1", "pdf_url": "http://arxiv.org/pdf/2203.01112v1", "repo_url": null}, "2203.01093": {"publish_time": "2022-03-02", "title": "Information Gain Propagation: a new way to Graph Active Learning with Soft Labels", "author": "Wentao Zhang et.al.", "abstract": "Graph Neural Networks (GNNs) have achieved great success in various tasks, but their performance highly relies on a large number of labeled nodes, which typically requires considerable human effort. GNN-based Active Learning (AL) methods are proposed to improve the labeling efficiency by selecting the most valuable nodes to label. Existing methods assume an oracle can correctly categorize all the selected nodes and thus just focus on the node selection. However, such an exact labeling task is costly, especially when the categorization is out of the domain of individual expert (oracle). The paper goes further, presenting a soft-label approach to AL on GNNs. Our key innovations are: i) relaxed queries where a domain expert (oracle) only judges the correctness of the predicted labels (a binary question) rather than identifying the exact class (a multi-class question), and ii) new criteria of maximizing information gain propagation for active learner with relaxed queries and soft labels. Empirical studies on public datasets demonstrate that our method significantly outperforms the state-of-the-art GNN-based AL methods in terms of both accuracy and labeling cost.", "paper_url": "http://arxiv.org/abs/2203.01093v1", "pdf_url": "http://arxiv.org/pdf/2203.01093v1", "repo_url": "https://github.com/zwt233/igp"}, "2203.00949": {"publish_time": "2022-03-02", "title": "GAP: Differentially Private Graph Neural Networks with Aggregation Perturbation", "author": "Sina Sajadmanesh et.al.", "abstract": "Graph Neural Networks (GNNs) are powerful models designed for graph data that learn node representation by recursively aggregating information from each node's local neighborhood. However, despite their state-of-the-art performance in predictive graph-based applications, recent studies have shown that GNNs can raise significant privacy concerns when graph data contain sensitive information. As a result, in this paper, we study the problem of learning GNNs with Differential Privacy (DP). We propose GAP, a novel differentially private GNN that safeguards the privacy of nodes and edges using aggregation perturbation, i.e., adding calibrated stochastic noise to the output of the GNN's aggregation function, which statistically obfuscates the presence of a single edge (edge-level privacy) or a single node and all its adjacent edges (node-level privacy). To circumvent the accumulation of privacy cost at every forward pass of the model, we tailor the GNN architecture to the specifics of private learning. In particular, we first precompute private aggregations by recursively applying neighborhood aggregation and perturbing the output of each aggregation step. Then, we privately train a deep neural network on the resulting perturbed aggregations for any node-wise classification task. A major advantage of GAP over previous approaches is that we guarantee edge-level and node-level DP not only for training, but also at inference time with no additional costs beyond the training's privacy budget. We theoretically analyze the formal privacy guarantees of GAP using R\\'enyi DP. Empirical experiments conducted over three real-world graph datasets demonstrate that GAP achieves a favorable privacy-accuracy trade-off and significantly outperforms existing approaches.", "paper_url": "http://arxiv.org/abs/2203.00949v1", "pdf_url": "http://arxiv.org/pdf/2203.00949v1", "repo_url": null}, "2203.01884": {"publish_time": "2022-03-03", "title": "Graph Neural Networks for Multimodal Single-Cell Data Integration", "author": "Hongzhi Wen et.al.", "abstract": "Recent advances in multimodal single-cell technologies have enabled simultaneous acquisitions of multiple omics data from the same cell, providing deeper insights into cellular states and dynamics. However, it is challenging to learn the joint representations from the multimodal data, model the relationship between modalities, and, more importantly, incorporate the vast amount of single-modality datasets into the downstream analyses. To address these challenges and correspondingly facilitate multimodal single-cell data analyses, three key tasks have been introduced: $\\textit{modality prediction}$, $\\textit{modality matching}$ and $\\textit{joint embedding}$. In this work, we present a general Graph Neural Network framework $\\textit{scMoGNN}$ to tackle these three tasks and show that $\\textit{scMoGNN}$ demonstrates superior results in all three tasks compared with the state-of-the-art and conventional approaches. Our method is an official winner in the overall ranking of $\\textit{modality prediction}$ from $\\href{https://openproblems.bio/neurips_2021/}{\\textit{NeurIPS 2021 Competition}}$.", "paper_url": "http://arxiv.org/abs/2203.01884v1", "pdf_url": "http://arxiv.org/pdf/2203.01884v1", "repo_url": "https://github.com/openproblems-bio/neurips2021_multimodal_topmethods"}, "2203.01874": {"publish_time": "2022-03-03", "title": "Thermodynamics-informed graph neural networks", "author": "Quercus Hern\u00e1ndez et.al.", "abstract": "In this paper we present a deep learning method to predict the time evolution of dissipative dynamical systems. We propose using both geometric and thermodynamic inductive biases to improve accuracy and generalization of the resulting integration scheme. The first is achieved with Graph Neural Networks, which induces a non-Euclidean geometrical prior and permutation invariant node and edge update functions. The second bias is forced by learning the GENERIC structure of the problem, an extension of the Hamiltonian formalism, to model more general non-conservative dynamics. Several examples are provided in both Eulerian and Lagrangian description in the context of fluid and solid mechanics respectively.", "paper_url": "http://arxiv.org/abs/2203.01874v1", "pdf_url": "http://arxiv.org/pdf/2203.01874v1", "repo_url": null}, "2203.01821": {"publish_time": "2022-03-03", "title": "Socially Aware Robot Crowd Navigation with Interaction Graphs and Human Trajectory Prediction", "author": "Shuijing Liu et.al.", "abstract": "We study the problem of safe and socially aware robot navigation in dense and interactive human crowds. Previous works use simplified methods to model the personal spaces of pedestrians and ignore the social compliance of the robot behaviors. In this paper, we provide a more accurate representation of personal zones of walking pedestrians with their future trajectories. The predicted personal zones are incorporated into a reinforcement learning framework to prevent the robot from intruding into the personal zones. To learn socially aware navigation policies, we propose a novel recurrent graph neural network with attention mechanisms to capture the interactions among agents through space and time. We demonstrate that our method enables the robot to achieve good navigation performance and non-invasiveness in challenging crowd navigation scenarios. We successfully transfer the policy learned in the simulator to a real-world TurtleBot 2i.", "paper_url": "http://arxiv.org/abs/2203.01821v1", "pdf_url": "http://arxiv.org/pdf/2203.01821v1", "repo_url": null}, "2203.01646": {"publish_time": "2022-03-03", "title": "On an application of graph neural networks in population based SHM", "author": "G. Tsialiamanis et.al.", "abstract": "Attempts have been made recently in the field of population-based structural health monitoring (PBSHM), to transfer knowledge between SHM models of different structures. The attempts have been focussed on homogeneous and heterogeneous populations. A more general approach to transferring knowledge between structures, is by considering all plausible structures as points on a multidimensional base manifold and building a fibre bundle. The idea is quite powerful, since, a mapping between points in the base manifold and their fibres, the potential states of any arbitrary structure, can be learnt. A smaller scale problem, but still useful, is that of learning a specific point of every fibre, i.e. that corresponding to the undamaged state of structures within a population. Under the framework of PBSHM, a data-driven approach to the aforementioned problem is developed. Structures are converted into graphs and inference is attempted within a population, using a graph neural network (GNN) algorithm. The algorithm solves a major problem existing in such applications. Structures comprise different sizes and are defined as abstract objects, thus attempting to perform inference within a heterogeneous population is not trivial. The proposed approach is tested in a simulated population of trusses. The goal of the application is to predict the first natural frequency of trusses of different sizes, across different environmental temperatures and having different bar member types. After training the GNN using part of the total population, it was tested on trusses that were not included in the training dataset. Results show that the accuracy of the regression is satisfactory even in structures with higher number of nodes and members than those used to train it.", "paper_url": "http://arxiv.org/abs/2203.01646v1", "pdf_url": "http://arxiv.org/pdf/2203.01646v1", "repo_url": null}, "2203.01597": {"publish_time": "2022-03-03", "title": "Neural Graph Matching for Pre-training Graph Neural Networks", "author": "Yupeng Hou et.al.", "abstract": "Recently, graph neural networks (GNNs) have been shown powerful capacity at modeling structural data. However, when adapted to downstream tasks, it usually requires abundant task-specific labeled data, which can be extremely scarce in practice. A promising solution to data scarcity is to pre-train a transferable and expressive GNN model on large amounts of unlabeled graphs or coarse-grained labeled graphs. Then the pre-trained GNN is fine-tuned on downstream datasets with task-specific fine-grained labels. In this paper, we present a novel Graph Matching based GNN Pre-Training framework, called GMPT. Focusing on a pair of graphs, we propose to learn structural correspondences between them via neural graph matching, consisting of both intra-graph message passing and inter-graph message passing. In this way, we can learn adaptive representations for a given graph when paired with different graphs, and both node- and graph-level characteristics are naturally considered in a single pre-training task. The proposed method can be applied to fully self-supervised pre-training and coarse-grained supervised pre-training. We further propose an approximate contrastive training strategy to significantly reduce time/memory consumption. Extensive experiments on multi-domain, out-of-distribution benchmarks have demonstrated the effectiveness of our approach. The code is available at: https://github.com/RUCAIBox/GMPT.", "paper_url": "http://arxiv.org/abs/2203.01597v1", "pdf_url": "http://arxiv.org/pdf/2203.01597v1", "repo_url": "https://github.com/rucaibox/gmpt"}, "2203.02177": {"publish_time": "2022-03-04", "title": "GCNet: Graph Completion Network for Incomplete Multimodal Learning in Conversation", "author": "Zheng Lian et.al.", "abstract": "Conversations have become a critical data format on social media platforms. Understanding conversation from emotion, content, and other aspects also attracts increasing attention from researchers due to its widespread application in human-computer interaction. In real-world environments, we often encounter the problem of incomplete modalities, which has become a core issue of conversation understanding. To address this problem, researchers propose various methods. However, existing approaches are mainly designed for individual utterances or medical images rather than conversational data, which cannot exploit temporal and speaker information in conversations. To this end, we propose a novel framework for incomplete multimodal learning in conversations, called \"Graph Complete Network (GCNet)\", filling the gap of existing works. Our GCNet contains two well-designed graph neural network-based modules, \"Speaker GNN\" and \"Temporal GNN\", to capture temporal and speaker information in conversations. To make full use of complete and incomplete data in feature learning, we jointly optimize classification and reconstruction in an end-to-end manner. To verify the effectiveness of our method, we conduct experiments on three benchmark conversational datasets. Experimental results demonstrate that our GCNet is superior to existing state-of-the-art approaches in incomplete multimodal learning.", "paper_url": "http://arxiv.org/abs/2203.02177v1", "pdf_url": "http://arxiv.org/pdf/2203.02177v1", "repo_url": null}, "2203.02150": {"publish_time": "2022-03-04", "title": "Time-aware Graph Neural Networks for Entity Alignment between Temporal Knowledge Graphs", "author": "Chengjin_Xu et.al.", "abstract": "Entity alignment aims to identify equivalent entity pairs between different knowledge graphs (KGs). Recently, the availability of temporal KGs (TKGs) that contain time information created the need for reasoning over time in such TKGs. Existing embedding-based entity alignment approaches disregard time information that commonly exists in many large-scale KGs, leaving much room for improvement. In this paper, we focus on the task of aligning entity pairs between TKGs and propose a novel Time-aware Entity Alignment approach based on Graph Neural Networks (TEA-GNN). We embed entities, relations and timestamps of different KGs into a vector space and use GNNs to learn entity representations. To incorporate both relation and time information into the GNN structure of our model, we use a time-aware attention mechanism which assigns different weights to different nodes with orthogonal transformation matrices computed from embeddings of the relevant relations and timestamps in a neighborhood. Experimental results on multiple real-world TKG datasets show that our method significantly outperforms the state-of-the-art methods due to the inclusion of time information.", "paper_url": "http://arxiv.org/abs/2203.02150v1", "pdf_url": "http://arxiv.org/pdf/2203.02150v1", "repo_url": "https://github.com/soledad921/tea-gnn"}, "2203.02018": {"publish_time": "2022-03-03", "title": "Zero-shot Domain Adaptation of Heterogeneous Graphs via Knowledge Transfer Networks", "author": "Minji Yoon et.al.", "abstract": "How can we make predictions for nodes in a heterogeneous graph when an entire type of node (e.g. user) has no labels (perhaps due to privacy issues) at all? Although heterogeneous graph neural networks (HGNNs) have shown superior performance as powerful representation learning techniques, there is no direct way to learn using labels rooted at different node types. Domain adaptation (DA) targets this setting, however, existing DA can not be applied directly to HGNNs. In heterogeneous graphs, the source and target domains have different modalities, thus HGNNs provide different feature extractors to them, while most of DA assumes source and target domains share a common feature extractor. In this work, we address the issue of zero-shot domain adaptation in HGNNs. We first theoretically induce a relationship between source and target domain features extracted from HGNNs, then propose a novel domain adaptation method, Knowledge Transfer Networks for HGNNs (HGNN-KTN). HGNN-KTN learns the relationship between source and target features, then maps the target distributions into the source domain. HGNN-KTN outperforms state-of-the-art baselines, showing up to 73.3% higher in MRR on 18 different domain adaptation tasks running on real-world benchmark graphs.", "paper_url": "http://arxiv.org/abs/2203.02018v1", "pdf_url": "http://arxiv.org/pdf/2203.02018v1", "repo_url": null}, "2203.03610": {"publish_time": "2022-03-07", "title": "ZippyPoint: Fast Interest Point Detection, Description, and Matching through Mixed Precision Discretization", "author": "Simon Maurer et.al.", "abstract": "The design of more complex and powerful neural network models has significantly advanced the state-of-the-art in local feature detection and description. These advances can be attributed to deeper networks, improved training methodologies through self-supervision, or the introduction of new building blocks, such as graph neural networks for feature matching. However, in the pursuit of increased performance, efficient architectures that generate lightweight descriptors have received surprisingly little attention. In this paper, we investigate the adaptations neural networks for detection and description require in order to enable their use in embedded platforms. To that end, we investigate and adapt network quantization techniques for use in real-time applications. In addition, we revisit common practices in descriptor quantization and propose the use of a binary descriptor normalization layer, enabling the generation of distinctive length-invariant binary descriptors. ZippyPoint, our efficient network, runs at 47.2 fps on the Apple M1 CPU. This is up to 5x faster than other learned detection and description models, making it the only real-time learned network. ZippyPoint consistently outperforms all other binary detection and descriptor methods in visual localization and homography estimation tasks. Code and trained models will be released upon publication.", "paper_url": "http://arxiv.org/abs/2203.03610v1", "pdf_url": "http://arxiv.org/pdf/2203.03610v1", "repo_url": null}, "2203.03457": {"publish_time": "2022-03-07", "title": "Graph Neural Networks for Image Classification and Reinforcement Learning using Graph representations", "author": "Naman Goyal et.al.", "abstract": "In this paper, we will evaluate the performance of graph neural networks in two distinct domains: computer vision and reinforcement learning. In the computer vision section, we seek to learn whether a novel non-redundant representation for images as graphs can improve performance over trivial pixel to node mapping on a graph-level prediction graph, specifically image classification. For the reinforcement learning section, we seek to learn if explicitly modeling solving a Rubik's cube as a graph problem can improve performance over a standard model-free technique with no inductive bias.", "paper_url": "http://arxiv.org/abs/2203.03457v1", "pdf_url": "http://arxiv.org/pdf/2203.03457v1", "repo_url": null}, "2203.03195": {"publish_time": "2022-03-07", "title": "Unpaired Image Captioning by Image-level Weakly-Supervised Visual Concept Recognition", "author": "Peipei Zhu et.al.", "abstract": "The goal of unpaired image captioning (UIC) is to describe images without using image-caption pairs in the training phase. Although challenging, we except the task can be accomplished by leveraging a training set of images aligned with visual concepts. Most existing studies use off-the-shelf algorithms to obtain the visual concepts because the Bounding Box (BBox) labels or relationship-triplet labels used for the training are expensive to acquire. In order to resolve the problem in expensive annotations, we propose a novel approach to achieve cost-effective UIC. Specifically, we adopt image-level labels for the optimization of the UIC model in a weakly-supervised manner. For each image, we assume that only the image-level labels are available without specific locations and numbers. The image-level labels are utilized to train a weakly-supervised object recognition model to extract object information (e.g., instance) in an image, and the extracted instances are adopted to infer the relationships among different objects based on an enhanced graph neural network (GNN). The proposed approach achieves comparable or even better performance compared with previous methods without the expensive cost of annotations. Furthermore, we design an unrecognized object (UnO) loss combined with a visual concept reward to improve the alignment of the inferred object and relationship information with the images. It can effectively alleviate the issue encountered by existing UIC models about generating sentences with nonexistent objects. To the best of our knowledge, this is the first attempt to solve the problem of Weakly-Supervised visual concept recognition for UIC (WS-UIC) based only on image-level labels. Extensive experiments have been carried out to demonstrate that the proposed WS-UIC model achieves inspiring results on the COCO dataset while significantly reducing the cost of labeling.", "paper_url": "http://arxiv.org/abs/2203.03195v1", "pdf_url": "http://arxiv.org/pdf/2203.03195v1", "repo_url": null}, "2203.03153": {"publish_time": "2022-03-07", "title": "Scalable Verification of GNN-based Job Schedulers", "author": "Haoze Wu et.al.", "abstract": "Recently, Graph Neural Networks (GNNs) have been applied for scheduling jobs over clusters achieving better performance than hand-crafted heuristics. Despite their impressive performance, concerns remain over their trustworthiness when deployed in a real-world environment due to their black-box nature. To address these limitations, we consider formal verification of their expected properties such as strategy proofness and locality in this work. We address several domain-specific challenges such as deeper networks and richer specifications not encountered by existing verifiers for image and NLP classifiers. We develop GNN-Verify, the first general framework for verifying both single-step and multi-step properties of these schedulers based on carefully designed algorithms that combine abstractions, refinements, solvers, and proof transfer. Our experimental results on challenging benchmarks show that our approach can provide precise and scalable formal guarantees on the trustworthiness of state-of-the-art GNN-based scheduler.", "paper_url": "http://arxiv.org/abs/2203.03153v1", "pdf_url": "http://arxiv.org/pdf/2203.03153v1", "repo_url": null}, "2203.03145": {"publish_time": "2022-03-07", "title": "End-to-end video instance segmentation via spatial-temporal graph neural networks", "author": "Tao Wang et.al.", "abstract": "Video instance segmentation is a challenging task that extends image instance segmentation to the video domain. Existing methods either rely only on single-frame information for the detection and segmentation subproblems or handle tracking as a separate post-processing step, which limit their capability to fully leverage and share useful spatial-temporal information for all the subproblems. In this paper, we propose a novel graph-neural-network (GNN) based method to handle the aforementioned limitation. Specifically, graph nodes representing instance features are used for detection and segmentation while graph edges representing instance relations are used for tracking. Both inter and intra-frame information is effectively propagated and shared via graph updates and all the subproblems (i.e. detection, segmentation and tracking) are jointly optimized in an unified framework. The performance of our method shows great improvement on the YoutubeVIS validation dataset compared to existing methods and achieves 35.2% AP with a ResNet-50 backbone, operating at 22 FPS. Code is available at http://github.com/lucaswithai/visgraph.git .", "paper_url": "http://arxiv.org/abs/2203.03145v1", "pdf_url": "http://arxiv.org/pdf/2203.03145v1", "repo_url": "https://github.com/lucaswithai/visgraph"}, "2203.03991": {"publish_time": "2022-03-08", "title": "Sparsification and Filtering for Spatial-temporal GNN in Multivariate Time-series", "author": "Yuanrong Wang et.al.", "abstract": "We propose an end-to-end architecture for multivariate time-series prediction that integrates a spatial-temporal graph neural network with a matrix filtering module. This module generates filtered (inverse) correlation graphs from multivariate time series before inputting them into a GNN. In contrast with existing sparsification methods adopted in graph neural network, our model explicitly leverage time-series filtering to overcome the low signal-to-noise ratio typical of complex systems data. We present a set of experiments, where we predict future sales from a synthetic time-series sales dataset. The proposed spatial-temporal graph neural network displays superior performances with respect to baseline approaches, with no graphical information, and with fully connected, disconnected graphs and unfiltered graphs.", "paper_url": "http://arxiv.org/abs/2203.03991v1", "pdf_url": "http://arxiv.org/pdf/2203.03991v1", "repo_url": null}, "2203.03965": {"publish_time": "2022-03-08", "title": "Few-Shot Traffic Prediction with Graph Networks using Locale as Relational Inductive Biases", "author": "Mingxi Li et.al.", "abstract": "Accurate short-term traffic prediction plays a pivotal role in various smart mobility operation and management systems. Currently, most of the state-of-the-art prediction models are based on graph neural networks (GNNs), and the required training samples are proportional to the size of the traffic network. In many cities, the available amount of traffic data is substantially below the minimum requirement due to the data collection expense. It is still an open question to develop traffic prediction models with a small size of training data on large-scale networks. We notice that the traffic states of a node for the near future only depend on the traffic states of its localized neighborhoods, which can be represented using the graph relational inductive biases. In view of this, this paper develops a graph network (GN)-based deep learning model LocaleGn that depicts the traffic dynamics using localized data aggregating and updating functions, as well as the node-wise recurrent neural networks. LocaleGn is a light-weighted model designed for training on few samples without over-fitting, and hence it can solve the problem of few-shot traffic prediction. The proposed model is examined on predicting both traffic speed and flow with six datasets, and the experimental results demonstrate that LocaleGn outperforms existing state-of-the-art baseline models. It is also demonstrated that the learned knowledge from LocaleGn can be transferred across cities. The research outcomes can help to develop light-weighted traffic prediction systems, especially for cities lacking in historically archived traffic data.", "paper_url": "http://arxiv.org/abs/2203.03965v1", "pdf_url": "http://arxiv.org/pdf/2203.03965v1", "repo_url": "https://github.com/mingxilii/localegn"}, "2203.03906": {"publish_time": "2022-03-08", "title": "Graph Reinforcement Learning for Predictive Power Allocation to Mobile Users", "author": "Jianyu Zhao et.al.", "abstract": "Allocating resources with future channels can save resource to ensure quality-of-service of video streaming. In this paper, we optimize predictive power allocation to minimize the energy consumed at distributed units (DUs) by using deep deterministic policy gradient (DDPG) to find optimal policy and predict average channel gains. To improve training efficiency, we resort to graph DDPG for exploiting two kinds of relational priors: (a) permutation equivariant (PE) and permutation invariant (PI) properties of policy function and action-value function, (b) topology relation among users and DUs. To design graph DDPG framework more systematically in harnessing the priors, we first demonstrate how to transform matrix-based DDPG into graph-based DDPG. Then, we respectively design the actor and critic networks to satisfy the permutation properties when graph neural networks are used in embedding and end to-end manners. To avoid destroying the PE/PI properties of the actor and critic networks, we conceive a batch normalization method. Finally, we show the impact of leveraging each prior. Simulation results show that the learned predictive policy performs close to the optimal solution with perfect future information, and the graph DDPG algorithms converge much faster than existing DDPG algorithms.", "paper_url": "http://arxiv.org/abs/2203.03906v1", "pdf_url": "http://arxiv.org/pdf/2203.03906v1", "repo_url": null}, "2203.03806": {"publish_time": "2022-03-08", "title": "Panoramic Human Activity Recognition", "author": "Ruize Han et.al.", "abstract": "To obtain a more comprehensive activity understanding for a crowded scene, in this paper, we propose a new problem of panoramic human activity recognition (PAR), which aims to simultaneous achieve the individual action, social group activity, and global activity recognition. This is a challenging yet practical problem in real-world applications. For this problem, we develop a novel hierarchical graph neural network to progressively represent and model the multi-granularity human activities and mutual social relations for a crowd of people. We further build a benchmark to evaluate the proposed method and other existing related methods. Experimental results verify the rationality of the proposed PAR problem, the effectiveness of our method and the usefulness of the benchmark. We will release the source code and benchmark to the public for promoting the study on this problem.", "paper_url": "http://arxiv.org/abs/2203.03806v1", "pdf_url": "http://arxiv.org/pdf/2203.03806v1", "repo_url": null}, "2203.04910": {"publish_time": "2022-03-09", "title": "BaM: A Case for Enabling Fine-grain High Throughput GPU-Orchestrated Access to Storage", "author": "Zaid Qureshi et.al.", "abstract": "Accelerators like Graphics Processing Units (GPUs) have been increasingly deployed in modern data centers because of their compute capabilities and memory bandwidth. These accelerators have traditionally relied on the \"application host code\" and the OS running on the CPU to orchestrate their access to the data storage devices. CPU orchestration of storage data accesses works well for classic GPU applications, like dense neural network training, where data access patterns are predefined, regular, dense, and independent of the data values, enabling the CPU to partition the storage data into coarse-grain chunks and coordinate the storage device accesses and data transfers to the accelerators. Unfortunately, such a CPU-centric strategy causes excessive CPU-GPU synchronization overhead and/or I/O traffic amplification, diminishing the effective storage bandwidth for emerging applications with fine-grain data-dependent access patterns like graph and data analytics, recommender systems, and graph neural networks. In this work, we make a case for enabling GPUs to orchestrate high-throughput, fine-grain accesses into NVMe Solid State Drives (SSDs) in a new system architecture called BaM. BaM mitigates the I/O traffic amplification by enabling the GPU threads to read or write small amounts of data on-demand, as determined by the compute. We show that (1) the BaM infrastructure software running on GPUs can identify and communicate the fine-grain accesses at a sufficiently high rate to fully utilize the underlying storage devices, (2) even with consumer-grade SSDs, a BaM system can support application performance that is competitive against a much more expensive DRAM-only solution, and (3) the reduction in I/O amplification can yield significant performance benefit.", "paper_url": "http://arxiv.org/abs/2203.04910v1", "pdf_url": "http://arxiv.org/pdf/2203.04910v1", "repo_url": null}, "2203.04746": {"publish_time": "2022-03-09", "title": "SkinningNet: Two-Stream Graph Convolutional Neural Network for Skinning Prediction of Synthetic Characters", "author": "Albert Mosella-Montoro et.al.", "abstract": "This work presents SkinningNet, an end-to-end Two-Stream Graph Neural Network architecture that computes skinning weights from an input mesh and its associated skeleton, without making any assumptions on shape class and structure of the provided mesh. Whereas previous methods pre-compute handcrafted features that relate the mesh and the skeleton or assume a fixed topology of the skeleton, the proposed method extracts this information in an end-to-end learnable fashion by jointly learning the best relationship between mesh vertices and skeleton joints. The proposed method exploits the benefits of the novel Multi-Aggregator Graph Convolution that combines the results of different aggregators during the summarizing step of the Message-Passing scheme, helping the operation to generalize for unseen topologies. Experimental results demonstrate the effectiveness of the contributions of our novel architecture, with SkinningNet outperforming current state-of-the-art alternatives.", "paper_url": "http://arxiv.org/abs/2203.04746v1", "pdf_url": "http://arxiv.org/pdf/2203.04746v1", "repo_url": null}, "2203.05380": {"publish_time": "2022-03-10", "title": "Spatial Commonsense Graph for Object Localisation in Partial Scenes", "author": "Francesco Giuliari et.al.", "abstract": "We solve object localisation in partial scenes, a new problem of estimating the unknown position of an object (e.g. where is the bag?) given a partial 3D scan of a scene. The proposed solution is based on a novel scene graph model, the Spatial Commonsense Graph (SCG), where objects are the nodes and edges define pairwise distances between them, enriched by concept nodes and relationships from a commonsense knowledge base. This allows SCG to better generalise its spatial inference over unknown 3D scenes. The SCG is used to estimate the unknown position of the target object in two steps: first, we feed the SCG into a novel Proximity Prediction Network, a graph neural network that uses attention to perform distance prediction between the node representing the target object and the nodes representing the observed objects in the SCG; second, we propose a Localisation Module based on circular intersection to estimate the object position using all the predicted pairwise distances in order to be independent of any reference system. We create a new dataset of partially reconstructed scenes to benchmark our method and baselines for object localisation in partial scenes, where our proposed method achieves the best localisation performance.", "paper_url": "http://arxiv.org/abs/2203.05380v1", "pdf_url": "http://arxiv.org/pdf/2203.05380v1", "repo_url": "https://github.com/fgiuliari/spatialcommonsensegraph-dataset"}, "2203.05181": {"publish_time": "2022-03-10", "title": "LineVD: Statement-level Vulnerability Detection using Graph Neural Networks", "author": "David Hin et.al.", "abstract": "Current machine-learning based software vulnerability detection methods are primarily conducted at the function-level. However, a key limitation of these methods is that they do not indicate the specific lines of code contributing to vulnerabilities. This limits the ability of developers to efficiently inspect and interpret the predictions from a learnt model, which is crucial for integrating machine-learning based tools into the software development workflow. Graph-based models have shown promising performance in function-level vulnerability detection, but their capability for statement-level vulnerability detection has not been extensively explored. While interpreting function-level predictions through explainable AI is one promising direction, we herein consider the statement-level software vulnerability detection task from a fully supervised learning perspective. We propose a novel deep learning framework, LineVD, which formulates statement-level vulnerability detection as a node classification task. LineVD leverages control and data dependencies between statements using graph neural networks, and a transformer-based model to encode the raw source code tokens. In particular, by addressing the conflicting outputs between function-level and statement-level information, LineVD significantly improve the prediction performance without vulnerability status for function code. We have conducted extensive experiments against a large-scale collection of real-world C/C++ vulnerabilities obtained from multiple real-world projects, and demonstrate an increase of 105\\% in F1-score over the current state-of-the-art.", "paper_url": "http://arxiv.org/abs/2203.05181v1", "pdf_url": "http://arxiv.org/pdf/2203.05181v1", "repo_url": null}, "2203.05144": {"publish_time": "2022-03-10", "title": "Earthquake Location and Magnitude Estimation with Graph Neural Networks", "author": "Ian W. McBrearty et.al.", "abstract": "We solve the traditional problems of earthquake location and magnitude estimation through a supervised learning approach, where we train a Graph Neural Network to predict estimates directly from input pick data, and each input allows a distinct seismic network with variable number of stations and positions. We train the model using synthetic simulations from assumed travel-time and amplitude-distance attenuation models. The architecture uses one graph to represent the station set, and another to represent the model space. The input includes theoretical predictions of data, given model parameters, and the adjacency matrices of the graphs defined link spatially local elements. As we show, graph convolutions on this combined representation are highly effective at inference, data fusion, and outlier suppression. We compare our results with traditional methods and observe favorable performance.", "paper_url": "http://arxiv.org/abs/2203.05144v1", "pdf_url": "http://arxiv.org/pdf/2203.05144v1", "repo_url": null}, "2203.05095": {"publish_time": "2022-03-10", "title": "Model-Architecture Co-Design for High Performance Temporal GNN Inference on FPGA", "author": "Hongkuan Zhou et.al.", "abstract": "Temporal Graph Neural Networks (TGNNs) are powerful models to capture temporal, structural, and contextual information on temporal graphs. The generated temporal node embeddings outperform other methods in many downstream tasks. Real-world applications require high performance inference on real-time streaming dynamic graphs. However, these models usually rely on complex attention mechanisms to capture relationships between temporal neighbors. In addition, maintaining vertex memory suffers from intrinsic temporal data dependency that hinders task-level parallelism, making it inefficient on general-purpose processors. In this work, we present a novel model-architecture co-design for inference in memory-based TGNNs on FPGAs. The key modeling optimizations we propose include a light-weight method to compute attention scores and a related temporal neighbor pruning strategy to further reduce computation and memory accesses. These are holistically coupled with key hardware optimizations that leverage FPGA hardware. We replace the temporal sampler with an on-chip FIFO based hardware sampler and the time encoder with a look-up-table. We train our simplified models using knowledge distillation to ensure similar accuracy vis-\\'a-vis the original model. Taking advantage of the model optimizations, we propose a principled hardware architecture using batching, pipelining, and prefetching techniques to further improve the performance. We also propose a hardware mechanism to ensure the chronological vertex updating without sacrificing the computation parallelism. We evaluate the performance of the proposed hardware accelerator on three real-world datasets.", "paper_url": "http://arxiv.org/abs/2203.05095v1", "pdf_url": "http://arxiv.org/pdf/2203.05095v1", "repo_url": "https://github.com/zjjzby/tgnn-fpga-ipdps2022"}, "2203.05046": {"publish_time": "2022-03-09", "title": "Adaptive Trajectory Prediction via Transferable GNN", "author": "Yi Xu et.al.", "abstract": "Pedestrian trajectory prediction is an essential component in a wide range of AI applications such as autonomous driving and robotics. Existing methods usually assume the training and testing motions follow the same pattern while ignoring the potential distribution differences (e.g., shopping mall and street). This issue results in inevitable performance decrease. To address this issue, we propose a novel Transferable Graph Neural Network (T-GNN) framework, which jointly conducts trajectory prediction as well as domain alignment in a unified framework. Specifically, a domain invariant GNN is proposed to explore the structural motion knowledge where the domain specific knowledge is reduced. Moreover, an attention-based adaptive knowledge learning module is further proposed to explore fine-grained individual-level feature representation for knowledge transfer. By this way, disparities across different trajectory domains will be better alleviated. More challenging while practical trajectory prediction experiments are designed, and the experimental results verify the superior performance of our proposed model. To the best of our knowledge, our work is the pioneer which fills the gap in benchmarks and techniques for practical pedestrian trajectory prediction across different domains.", "paper_url": "http://arxiv.org/abs/2203.05046v1", "pdf_url": "http://arxiv.org/pdf/2203.05046v1", "repo_url": null}, "2203.05985": {"publish_time": "2022-03-11", "title": "Graph Neural Networks for Relational Inductive Bias in Vision-based Deep Reinforcement Learning of Robot Control", "author": "Marco Oliva et.al.", "abstract": "State-of-the-art reinforcement learning algorithms predominantly learn a policy from either a numerical state vector or images. Both approaches generally do not take structural knowledge of the task into account, which is especially prevalent in robotic applications and can benefit learning if exploited. This work introduces a neural network architecture that combines relational inductive bias and visual feedback to learn an efficient position control policy for robotic manipulation. We derive a graph representation that models the physical structure of the manipulator and combines the robot's internal state with a low-dimensional description of the visual scene generated by an image encoding network. On this basis, a graph neural network trained with reinforcement learning predicts joint velocities to control the robot. We further introduce an asymmetric approach of training the image encoder separately from the policy using supervised learning. Experimental results demonstrate that, for a 2-DoF planar robot in a geometrically simplistic 2D environment, a learned representation of the visual scene can replace access to the explicit coordinates of the reaching target without compromising on the quality and sample efficiency of the policy. We further show the ability of the model to improve sample efficiency for a 6-DoF robot arm in a visually realistic 3D environment.", "paper_url": "http://arxiv.org/abs/2203.05985v1", "pdf_url": "http://arxiv.org/pdf/2203.05985v1", "repo_url": null}, "2203.05919": {"publish_time": "2022-03-11", "title": "Graph Summarization with Graph Neural Networks", "author": "Maximilian Blasi et.al.", "abstract": "The goal of graph summarization is to represent large graphs in a structured and compact way. A graph summary based on equivalence classes preserves pre-defined features of a graph's vertex within a $k$-hop neighborhood such as the vertex labels and edge labels. Based on these neighborhood characteristics, the vertex is assigned to an equivalence class. The calculation of the assigned equivalence class must be a permutation invariant operation on the pre-defined features. This is achieved by sorting on the feature values, e. g., the edge labels, which is computationally expensive, and subsequently hashing the result. Graph Neural Networks (GNN) fulfill the permutation invariance requirement. We formulate the problem of graph summarization as a subgraph classification task on the root vertex of the $k$-hop neighborhood. We adapt different GNN architectures, both based on the popular message-passing protocol and alternative approaches, to perform the structural graph summarization task. We compare different GNNs with a standard multi-layer perceptron (MLP) and Bloom filter as non-neural method. For our experiments, we consider four popular graph summary models on a large web graph. This resembles challenging multi-class vertex classification tasks with the numbers of classes ranging from $576$ to multiple hundreds of thousands. Our results show that the performance of GNNs are close to each other. In three out of four experiments, the non-message-passing GraphMLP model outperforms the other GNNs. The performance of the standard MLP is extraordinary good, especially in the presence of many classes. Finally, the Bloom filter outperforms all neural architectures by a large margin, except for the dataset with the fewest number of $576$ classes.", "paper_url": "http://arxiv.org/abs/2203.05919v1", "pdf_url": "http://arxiv.org/pdf/2203.05919v1", "repo_url": null}, "2203.07353": {"publish_time": "2022-03-14", "title": "Improving Di-Higgs Sensitivity at Future Colliders in Hadronic Final States with Machine Learning", "author": "Daniel Diaz et.al.", "abstract": "One of the central goals of the physics program at the future colliders is to elucidate the origin of electroweak symmetry breaking, including precision measurements of the Higgs sector. This includes a detailed study of Higgs boson (H) pair production, which can reveal the H self-coupling. Since the discovery of the Higgs boson, a large campaign of measurements of the properties of the Higgs boson has begun and many new ideas have emerged during the completion of this program. One such idea is the use of highly boosted and merged hadronic decays of the Higgs boson ($\\mathrm{H}\\to\\mathrm{b}\\overline{\\mathrm{b}}$, $\\mathrm{H}\\to\\mathrm{W}\\mathrm{W}\\to\\mathrm{q}\\overline{\\mathrm{q}}\\mathrm{q}\\overline{\\mathrm{q}}$) with machine learning methods to improve the signal-to-background discrimination. In this white paper, we champion the use of these modes to boost the sensitivity of future collider physics programs to Higgs boson pair production, the Higgs self-coupling, and Higgs-vector boson couplings. We demonstrate the potential improvement possible thanks to use of graph neural networks.", "paper_url": "http://arxiv.org/abs/2203.07353v1", "pdf_url": "http://arxiv.org/pdf/2203.07353v1", "repo_url": null}, "2203.06944": {"publish_time": "2022-03-14", "title": "Towards Neural Sparse Linear Solvers", "author": "Luca Grementieri et.al.", "abstract": "Large sparse symmetric linear systems appear in several branches of science and engineering thanks to the widespread use of the finite element method (FEM). The fastest sparse linear solvers available implement hybrid iterative methods. These methods are based on heuristic algorithms to permute rows and columns or find a preconditioner matrix. In addition, they are inherently sequential, making them unable to leverage the GPU processing power entirely. We propose neural sparse linear solvers, a deep learning framework to learn approximate solvers for sparse symmetric linear systems. Our method relies on representing a sparse symmetric linear system as an undirected weighted graph. Such graph representation is inherently permutation-equivariant and scale-invariant, and it can become the input to a graph neural network trained to regress the solution. We test neural sparse linear solvers on static linear analysis problems from structural engineering. Our method is less accurate than classic algorithms, but it is hardware-independent, fast on GPUs, and applicable to generic sparse symmetric systems without any additional hypothesis. Although many limitations remain, this study shows a general approach to tackle problems involving sparse symmetric matrices using graph neural networks.", "paper_url": "http://arxiv.org/abs/2203.06944v1", "pdf_url": "http://arxiv.org/pdf/2203.06944v1", "repo_url": null}, "2203.06852": {"publish_time": "2022-03-14", "title": "Continual Learning for Multivariate Time Series Tasks with Variable Input Dimensions", "author": "Vibhor Gupta et.al.", "abstract": "We consider a sequence of related multivariate time series learning tasks, such as predicting failures for different instances of a machine from time series of multi-sensor data, or activity recognition tasks over different individuals from multiple wearable sensors. We focus on two under-explored practical challenges arising in such settings: (i) Each task may have a different subset of sensors, i.e., providing different partial observations of the underlying 'system'. This restriction can be due to different manufacturers in the former case, and people wearing more or less measurement devices in the latter (ii) We are not allowed to store or re-access data from a task once it has been observed at the task level. This may be due to privacy considerations in the case of people, or legal restrictions placed by machine owners. Nevertheless, we would like to (a) improve performance on subsequent tasks using experience from completed tasks as well as (b) continue to perform better on past tasks, e.g., update the model and improve predictions on even the first machine after learning from subsequently observed ones. We note that existing continual learning methods do not take into account variability in input dimensions arising due to different subsets of sensors being available across tasks, and struggle to adapt to such variable input dimensions (VID) tasks. In this work, we address this shortcoming of existing methods. To this end, we learn task-specific generative models and classifiers, and use these to augment data for target tasks. Since the input dimensions across tasks vary, we propose a novel conditioning module based on graph neural networks to aid a standard recurrent neural network. We evaluate the efficacy of the proposed approach on three publicly available datasets corresponding to two activity recognition tasks (classification) and one prognostics task (regression).", "paper_url": "http://arxiv.org/abs/2203.06852v1", "pdf_url": "http://arxiv.org/pdf/2203.06852v1", "repo_url": null}, "2203.06778": {"publish_time": "2022-03-13", "title": "Pruned Graph Neural Network for Short Story Ordering", "author": "Melika Golestani et.al.", "abstract": "Text coherence is a fundamental problem in natural language generation and understanding. Organizing sentences into an order that maximizes coherence is known as sentence ordering. This paper is proposing a new approach based on the graph neural network approach to encode a set of sentences and learn orderings of short stories. We propose a new method for constructing sentence-entity graphs of short stories to create the edges between sentences and reduce noise in our graph by replacing the pronouns with their referring entities. We improve the sentence ordering by introducing an aggregation method based on majority voting of state-of-the-art methods and our proposed one. Our approach employs a BERT-based model to learn semantic representations of the sentences. The results demonstrate that the proposed method significantly outperforms existing baselines on a corpus of short stories with a new state-of-the-art performance in terms of Perfect Match Ratio (PMR) and Kendall's Tau (Tau) metrics. More precisely, our method increases PMR and Tau criteria by more than 5% and 4.3%, respectively. These outcomes highlight the benefit of forming the edges between sentences based on their cosine similarity. We also observe that replacing pronouns with their referring entities effectively encodes sentences in sentence-entity graphs.", "paper_url": "http://arxiv.org/abs/2203.06778v1", "pdf_url": "http://arxiv.org/pdf/2203.06778v1", "repo_url": null}, "2203.06442": {"publish_time": "2022-03-12", "title": "Equivariant Graph Mechanics Networks with Constraints", "author": "Wenbing Huang et.al.", "abstract": "Learning to reason about relations and dynamics over multiple interacting objects is a challenging topic in machine learning. The challenges mainly stem from that the interacting systems are exponentially-compositional, symmetrical, and commonly geometrically-constrained. Current methods, particularly the ones based on equivariant Graph Neural Networks (GNNs), have targeted on the first two challenges but remain immature for constrained systems. In this paper, we propose Graph Mechanics Network (GMN) which is combinatorially efficient, equivariant and constraint-aware. The core of GMN is that it represents, by generalized coordinates, the forward kinematics information (positions and velocities) of a structural object. In this manner, the geometrical constraints are implicitly and naturally encoded in the forward kinematics. Moreover, to allow equivariant message passing in GMN, we have developed a general form of orthogonality-equivariant functions, given that the dynamics of constrained systems are more complicated than the unconstrained counterparts. Theoretically, the proposed equivariant formulation is proved to be universally expressive under certain conditions. Extensive experiments support the advantages of GMN compared to the state-of-the-art GNNs in terms of prediction accuracy, constraint satisfaction and data efficiency on the simulated systems consisting of particles, sticks and hinges, as well as two real-world datasets for molecular dynamics prediction and human motion capture.", "paper_url": "http://arxiv.org/abs/2203.06442v1", "pdf_url": "http://arxiv.org/pdf/2203.06442v1", "repo_url": "https://github.com/hanjq17/gmn"}, "2203.07977": {"publish_time": "2022-03-15", "title": "OcclusionFusion: Occlusion-aware Motion Estimation for Real-time Dynamic 3D Reconstruction", "author": "Wenbin Lin et.al.", "abstract": "RGBD-based real-time dynamic 3D reconstruction suffers from inaccurate inter-frame motion estimation as errors may accumulate with online tracking. This problem is even more severe for single-view-based systems due to strong occlusions. Based on these observations, we propose OcclusionFusion, a novel method to calculate occlusion-aware 3D motion to guide the reconstruction. In our technique, the motion of visible regions is first estimated and combined with temporal information to infer the motion of the occluded regions through an LSTM-involved graph neural network. Furthermore, our method computes the confidence of the estimated motion by modeling the network output with a probabilistic model, which alleviates untrustworthy motions and enables robust tracking. Experimental results on public datasets and our own recorded data show that our technique outperforms existing single-view-based real-time methods by a large margin. With the reduction of the motion errors, the proposed technique can handle long and challenging motion sequences. Please check out the project page for sequence results: https://wenbin-lin.github.io/OcclusionFusion.", "paper_url": "http://arxiv.org/abs/2203.07977v1", "pdf_url": "http://arxiv.org/pdf/2203.07977v1", "repo_url": null}, "2203.07969": {"publish_time": "2022-03-15", "title": "PDNS-Net: A Large Heterogeneous Graph Benchmark Dataset of Network Resolutions for Graph Learning", "author": "Udesh Kumarasinghe et.al.", "abstract": "In order to advance the state of the art in graph learning algorithms, it is necessary to construct large real-world datasets. While there are many benchmark datasets for homogeneous graphs, only a few of them are available for heterogeneous graphs. Furthermore, the latter graphs are small in size rendering them insufficient to understand how graph learning algorithms perform in terms of classification metrics and computational resource utilization. We introduce, PDNS-Net, the largest public heterogeneous graph dataset containing 447K nodes and 897K edges for the malicious domain classification task. Compared to the popular heterogeneous datasets IMDB and DBLP, PDNS-Net is 38 and 17 times bigger respectively. We provide a detailed analysis of PDNS-Net including the data collection methodology, heterogeneous graph construction, descriptive statistics and preliminary graph classification performance. The dataset is publicly available at https://github.com/qcri/PDNS-Net. Our preliminary evaluation of both popular homogeneous and heterogeneous graph neural networks on PDNS-Net reveals that further research is required to improve the performance of these models on large heterogeneous graphs.", "paper_url": "http://arxiv.org/abs/2203.07969v1", "pdf_url": "http://arxiv.org/pdf/2203.07969v1", "repo_url": "https://github.com/qcri/pdns-net"}, "2203.07961": {"publish_time": "2022-03-15", "title": "Amortised inference of fractional Brownian motion with linear computational complexity", "author": "Fran\u00e7ois Laurent et.al.", "abstract": "We introduce a simulation-based, amortised Bayesian inference scheme to infer the parameters of random walks. Our approach learns the posterior distribution of the walks' parameters with a likelihood-free method. In the first step a graph neural network is trained on simulated data to learn optimized low-dimensional summary statistics of the random walk. In the second step an invertible neural network generates the posterior distribution of the parameters from the learnt summary statistics using variational inference. We apply our method to infer the parameters of the fractional Brownian motion model from single trajectories. The computational complexity of the amortized inference procedure scales linearly with trajectory length, and its precision scales similarly to the Cram{\\'e}r-Rao bound over a wide range of lengths. The approach is robust to positional noise, and generalizes well to trajectories longer than those seen during training. Finally, we adapt this scheme to show that a finite decorrelation time in the environment can furthermore be inferred from individual trajectories.", "paper_url": "http://arxiv.org/abs/2203.07961v1", "pdf_url": "http://arxiv.org/pdf/2203.07961v1", "repo_url": null}, "2203.07831": {"publish_time": "2022-03-15", "title": "Graph Neural Network Sensitivity Under Probabilistic Error Model", "author": "Xinjue Wang et.al.", "abstract": "Graph convolutional networks (GCNs) can successfully learn the graph signal representation by graph convolution. The graph convolution depends on the graph filter, which contains the topological dependency of data and propagates data features. However, the estimation errors in the propagation matrix (e.g., the adjacency matrix) can have a significant impact on graph filters and GCNs. In this paper, we study the effect of a probabilistic graph error model on the performance of the GCNs. We prove that the adjacency matrix under the error model is bounded by a function of graph size and error probability. We further analytically specify the upper bound of a normalized adjacency matrix with self-loop added. Finally, we illustrate the error bounds by running experiments on a synthetic dataset and study the sensitivity of a simple GCN under this probabilistic error model on accuracy.", "paper_url": "http://arxiv.org/abs/2203.07831v1", "pdf_url": "http://arxiv.org/pdf/2203.07831v1", "repo_url": null}, "2203.07691": {"publish_time": "2022-03-15", "title": "Supervised Contrastive Learning with Structure Inference for Graph Classification", "author": "Hao Jia et.al.", "abstract": "Advanced graph neural networks have shown great potentials in graph classification tasks recently. Different from node classification where node embeddings aggregated from local neighbors can be directly used to learn node labels, graph classification requires a hierarchical accumulation of different levels of topological information to generate discriminative graph embeddings. Still, how to fully explore graph structures and formulate an effective graph classification pipeline remains rudimentary. In this paper, we propose a novel graph neural network based on supervised contrastive learning with structure inference for graph classification. First, we propose a data-driven graph augmentation strategy that can discover additional connections to enhance the existing edge set. Concretely, we resort to a structure inference stage based on diffusion cascades to recover possible connections with high node similarities. Second, to improve the contrastive power of graph neural networks, we propose to use a supervised contrastive loss for graph classification. With the integration of label information, the one-vs-many contrastive learning can be extended to a many-vs-many setting, so that the graph-level embeddings with higher topological similarities will be pulled closer. The supervised contrastive loss and structure inference can be naturally incorporated within the hierarchical graph neural networks where the topological patterns can be fully explored to produce discriminative graph embeddings. Experiment results show the effectiveness of the proposed method compared with recent state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2203.07691v1", "pdf_url": "http://arxiv.org/pdf/2203.07691v1", "repo_url": null}, "2203.08654": {"publish_time": "2022-03-16", "title": "Graph Neural Networks for Multiparallel Word Alignment", "author": "Ayyoob Imani et.al.", "abstract": "After a period of decrease, interest in word alignments is increasing again for their usefulness in domains such as typological research, cross-lingual annotation projection, and machine translation. Generally, alignment algorithms only use bitext and do not make use of the fact that many parallel corpora are multiparallel. Here, we compute high-quality word alignments between multiple language pairs by considering all language pairs together. First, we create a multiparallel word alignment graph, joining all bilingual word alignment pairs in one graph. Next, we use graph neural networks (GNNs) to exploit the graph structure. Our GNN approach (i) utilizes information about the meaning, position, and language of the input words, (ii) incorporates information from multiple parallel sentences, (iii) adds and removes edges from the initial alignments, and (iv) yields a prediction model that can generalize beyond the training sentences. We show that community detection provides valuable information for multiparallel word alignment. Our method outperforms previous work on three word-alignment datasets and on a downstream task.", "paper_url": "http://arxiv.org/abs/2203.08654v1", "pdf_url": "http://arxiv.org/pdf/2203.08654v1", "repo_url": null}, "2203.08500": {"publish_time": "2022-03-16", "title": "HeterMPC: A Heterogeneous Graph Neural Network for Response Generation in Multi-Party Conversations", "author": "Jia-Chen Gu et.al.", "abstract": "Recently, various response generation models for two-party conversations have achieved impressive improvements, but less effort has been paid to multi-party conversations (MPCs) which are more practical and complicated. Compared with a two-party conversation where a dialogue context is a sequence of utterances, building a response generation model for MPCs is more challenging, since there exist complicated context structures and the generated responses heavily rely on both interlocutors (i.e., speaker and addressee) and history utterances. To address these challenges, we present HeterMPC, a heterogeneous graph-based neural network for response generation in MPCs which models the semantics of utterances and interlocutors simultaneously with two types of nodes in a graph. Besides, we also design six types of meta relations with node-edge-type-dependent parameters to characterize the heterogeneous interactions within the graph. Through multi-hop updating, HeterMPC can adequately utilize the structural knowledge of conversations for response generation. Experimental results on the Ubuntu Internet Relay Chat (IRC) channel benchmark show that HeterMPC outperforms various baseline models for response generation in MPCs.", "paper_url": "http://arxiv.org/abs/2203.08500v1", "pdf_url": "http://arxiv.org/pdf/2203.08500v1", "repo_url": "https://github.com/lxchtan/hetermpc"}, "2203.09360": {"publish_time": "2022-03-17", "title": "Behavior-aware Account De-anonymization on Ethereum Interaction Graph", "author": "Jiajun Zhou et.al.", "abstract": "Blockchain technology has the characteristics of decentralization, traceability and tamper-proof, which creates a reliable decentralized trust mechanism, further accelerating the development of blockchain finance. However, the anonymization of blockchain hinders market regulation, resulting in increasing illegal activities such as money laundering, gambling and phishing fraud on blockchain financial platforms. Thus financial security has become a top priority in the blockchain ecosystem, calling for effective market regulation. In this paper, we consider identifying Ethereum accounts from a graph classification perspective, and propose an end-to-end graph neural network framework named Ethident, to characterize the behavior patterns of accounts and further achieve account de-anonymization. Specifically, we first construct an Account Interaction Graph (AIG) using raw Ethereum data. Then we design a hierarchical graph attention encoder named HGATE as the backbone of our framework, which can effectively characterize the node-level account features and subgraph-level behavior patterns. For alleviating account label sparsity, we further introduce contrastive self-supervision mechanism as regularization to jointly train our framework. Comprehensive experiments on Ethereum datasets demonstrate that our framework achieves superior performance in account identification, yielding 1.13% - 4.93% relative improvement over previous state-of-the-art. Furthermore, detailed analyses illustrate the effectiveness of Ethident in identifying and understanding the behavior of known participants in Ethereum (e.g. exchanges, miners, etc.), as well as that of the lawbreakers (e.g. phishing scammers, hackers, etc.), which may aid in risk assessment and market regulation.", "paper_url": "http://arxiv.org/abs/2203.09360v2", "pdf_url": "http://arxiv.org/pdf/2203.09360v2", "repo_url": null}, "2203.09258": {"publish_time": "2022-03-17", "title": "Explainability in Graph Neural Networks: An Experimental Survey", "author": "Peibo Li et.al.", "abstract": "Graph neural networks (GNNs) have been extensively developed for graph representation learning in various application domains. However, similar to all other neural networks models, GNNs suffer from the black-box problem as people cannot understand the mechanism underlying them. To solve this problem, several GNN explainability methods have been proposed to explain the decisions made by GNNs. In this survey, we give an overview of the state-of-the-art GNN explainability methods and how they are evaluated. Furthermore, we propose a new evaluation metric and conduct thorough experiments to compare GNN explainability methods on real world datasets. We also suggest future directions for GNN explainability.", "paper_url": "http://arxiv.org/abs/2203.09258v1", "pdf_url": "http://arxiv.org/pdf/2203.09258v1", "repo_url": null}, "2203.09205": {"publish_time": "2022-03-17", "title": "SoK: Differential Privacy on Graph-Structured Data", "author": "Tamara T. Mueller et.al.", "abstract": "In this work, we study the applications of differential privacy (DP) in the context of graph-structured data. We discuss the formulations of DP applicable to the publication of graphs and their associated statistics as well as machine learning on graph-based data, including graph neural networks (GNNs). The formulation of DP in the context of graph-structured data is difficult, as individual data points are interconnected (often non-linearly or sparsely). This connectivity complicates the computation of individual privacy loss in differentially private learning. The problem is exacerbated by an absence of a single, well-established formulation of DP in graph settings. This issue extends to the domain of GNNs, rendering private machine learning on graph-structured data a challenging task. A lack of prior systematisation work motivated us to study graph-based learning from a privacy perspective. In this work, we systematise different formulations of DP on graphs, discuss challenges and promising applications, including the GNN domain. We compare and separate works into graph analysis tasks and graph learning tasks with GNNs. Finally, we conclude our work with a discussion of open questions and potential directions for further research in this area.", "paper_url": "http://arxiv.org/abs/2203.09205v1", "pdf_url": "http://arxiv.org/pdf/2203.09205v1", "repo_url": null}, "2203.09141": {"publish_time": "2022-03-17", "title": "Graph Representation Learning with Individualization and Refinement", "author": "Mohammed Haroon Dupty et.al.", "abstract": "Graph Neural Networks (GNNs) have emerged as prominent models for representation learning on graph structured data. GNNs follow an approach of message passing analogous to 1-dimensional Weisfeiler Lehman (1-WL) test for graph isomorphism and consequently are limited by the distinguishing power of 1-WL. More expressive higher-order GNNs which operate on k-tuples of nodes need increased computational resources in order to process higher-order tensors. Instead of the WL approach, in this work, we follow the classical approach of Individualization and Refinement (IR), a technique followed by most practical isomorphism solvers. Individualization refers to artificially distinguishing a node in the graph and refinement is the propagation of this information to other nodes through message passing. We learn to adaptively select nodes to individualize and to aggregate the resulting graphs after refinement to help handle the complexity. Our technique lets us learn richer node embeddings while keeping the computational complexity manageable. Theoretically, we show that our procedure is more expressive than the 1-WL test. Experiments show that our method outperforms prominent 1-WL GNN models as well as competitive higher-order baselines on several benchmark synthetic and real datasets. Furthermore, our method opens new doors for exploring the paradigm of learning on graph structures with individualization and refinement.", "paper_url": "http://arxiv.org/abs/2203.09141v1", "pdf_url": "http://arxiv.org/pdf/2203.09141v1", "repo_url": null}, "2203.08852": {"publish_time": "2022-03-16", "title": "Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks", "author": "Marten Lienen et.al.", "abstract": "We propose a new method for spatio-temporal forecasting on arbitrarily distributed points. Assuming that the observed system follows an unknown partial differential equation, we derive a continuous-time model for the dynamics of the data via the finite element method. The resulting graph neural network estimates the instantaneous effects of the unknown dynamics on each cell in a meshing of the spatial domain. Our model can incorporate prior knowledge via assumptions on the form of the unknown PDE, which induce a structural bias towards learning specific processes. Through this mechanism, we derive a transport variant of our model from the convection equation and show that it improves the transfer performance to higher-resolution meshes on sea surface temperature and gas flow forecasting against baseline models representing a selection of spatio-temporal forecasting methods. A qualitative analysis shows that our model disentangles the data dynamics into their constituent parts, which makes it uniquely interpretable.", "paper_url": "http://arxiv.org/abs/2203.08852v1", "pdf_url": "http://arxiv.org/pdf/2203.08852v1", "repo_url": "https://github.com/martenlienen/finite-element-networks"}, "2203.09736": {"publish_time": "2022-03-18", "title": "Series Photo Selection via Multi-view Graph Learning", "author": "Jin Huang et.al.", "abstract": "Series photo selection (SPS) is an important branch of the image aesthetics quality assessment, which focuses on finding the best one from a series of nearly identical photos. While a great progress has been observed, most of the existing SPS approaches concentrate solely on extracting features from the original image, neglecting that multiple views, e.g, saturation level, color histogram and depth of field of the image, will be of benefit to successfully reflecting the subtle aesthetic changes. Taken multi-view into consideration, we leverage a graph neural network to construct the relationships between multi-view features. Besides, multiple views are aggregated with an adaptive-weight self-attention module to verify the significance of each view. Finally, a siamese network is proposed to select the best one from a series of nearly identical photos. Experimental results demonstrate that our model accomplish the highest success rates compared with competitive methods.", "paper_url": "http://arxiv.org/abs/2203.09736v1", "pdf_url": "http://arxiv.org/pdf/2203.09736v1", "repo_url": null}, "2203.09697": {"publish_time": "2022-03-18", "title": "Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations", "author": "Anuroop Sriram et.al.", "abstract": "Recent progress in Graph Neural Networks (GNNs) for modeling atomic simulations has the potential to revolutionize catalyst discovery, which is a key step in making progress towards the energy breakthroughs needed to combat climate change. However, the GNNs that have proven most effective for this task are memory intensive as they model higher-order interactions in the graphs such as those between triplets or quadruplets of atoms, making it challenging to scale these models. In this paper, we introduce Graph Parallelism, a method to distribute input graphs across multiple GPUs, enabling us to train very large GNNs with hundreds of millions or billions of parameters. We empirically evaluate our method by scaling up the number of parameters of the recently proposed DimeNet++ and GemNet models by over an order of magnitude. On the large-scale Open Catalyst 2020 (OC20) dataset, these graph-parallelized models lead to relative improvements of 1) 15% on the force MAE metric for the S2EF task and 2) 21% on the AFbT metric for the IS2RS task, establishing new state-of-the-art results.", "paper_url": "http://arxiv.org/abs/2203.09697v1", "pdf_url": "http://arxiv.org/pdf/2203.09697v1", "repo_url": null}, "2203.10977": {"publish_time": "2022-03-21", "title": "Improving anatomical plausibility in medical image segmentation via hybrid graph neural networks: applications to chest x-ray analysis", "author": "Nicol\u00e1s Gaggion et.al.", "abstract": "Anatomical segmentation is a fundamental task in medical image computing, generally tackled with fully convolutional neural networks which produce dense segmentation masks. These models are often trained with loss functions such as cross-entropy or Dice, which assume pixels to be independent of each other, thus ignoring topological errors and anatomical inconsistencies. We address this limitation by moving from pixel-level to graph representations, which allow to naturally incorporate anatomical constraints by construction. To this end, we introduce HybridGNet, an encoder-decoder neural architecture that leverages standard convolutions for image feature encoding and graph convolutional neural networks (GCNNs) to decode plausible representations of anatomical structures. We also propose a novel image-to-graph skip connection layer which allows localized features to flow from standard convolutional blocks to GCNN blocks, and show that it improves segmentation accuracy. The proposed architecture is extensively evaluated in a variety of domain shift and image occlusion scenarios, and audited considering different types of demographic domain shift. Our comprehensive experimental setup compares HybridGNet with other landmark and pixel-based models for anatomical segmentation in chest x-ray images, and shows that it produces anatomically plausible results in challenging scenarios where other models tend to fail.", "paper_url": "http://arxiv.org/abs/2203.10977v1", "pdf_url": "http://arxiv.org/pdf/2203.10977v1", "repo_url": "https://github.com/ngaggion/HybridGNet"}, "2203.10926": {"publish_time": "2022-03-21", "title": "3D Multi-Object Tracking Using Graph Neural Networks with Cross-Edge Modality Attention", "author": "Martin Buchner et.al.", "abstract": "Online 3D multi-object tracking (MOT) has witnessed significant research interest in recent years, largely driven by demand from the autonomous systems community. However, 3D offline MOT is relatively less explored. Labeling 3D trajectory scene data at a large scale while not relying on high-cost human experts is still an open research question. In this work, we propose Batch3DMOT that follows the tracking-by-detection paradigm and represents real-world scenes as directed, acyclic, and category-disjoint tracking graphs that are attributed using various modalities such as camera, LiDAR, and radar. We present a multi-modal graph neural network that uses a cross-edge attention mechanism mitigating modality intermittence, which translates into sparsity in the graph domain. Additionally, we present attention-weighted convolutions over frame-wise k-NN neighborhoods as suitable means to allow information exchange across disconnected graph components. We evaluate our approach using various sensor modalities and model configurations on the challenging nuScenes and KITTI datasets. Extensive experiments demonstrate that our proposed approach yields an overall improvement of 2.8% in the AMOTA score on nuScenes thereby setting a new benchmark for 3D tracking methods and successfully enhances false positive filtering.", "paper_url": "http://arxiv.org/abs/2203.10926v1", "pdf_url": "http://arxiv.org/pdf/2203.10926v1", "repo_url": null}, "2203.10800": {"publish_time": "2022-03-21", "title": "Graph Neural Networks for Wireless Communications: From Theory to Practice", "author": "Yifei Shen et.al.", "abstract": "Deep learning-based approaches have been developed to solve challenging problems in wireless communications, leading to promising results. Early attempts adopted neural network architectures inherited from applications such as computer vision. They often require huge amounts of training samples (i.e., poor generalization), and yield poor performance in large-scale networks (i.e., poor scalability). To resolve these issues, graph neural networks (GNNs) have been recently adopted, as they can effectively exploit the domain knowledge, i.e., the graph topology in wireless communication problems. GNN-based methods can achieve near-optimal performance in large-scale networks and generalize well under different system settings, but the theoretical underpinnings and design guidelines remain elusive, which may hinder their practical implementations. This paper endeavors to fill both the theoretical and practical gaps. For theoretical guarantees, we prove that GNNs achieve near-optimal performance in wireless networks with much fewer training samples than traditional neural architectures. Specifically, to solve an optimization problem on an $n$-node graph (where the nodes may represent users, base stations, or antennas), GNNs' generalization error and required number of training samples are $\\mathcal{O}(n)$ and $\\mathcal{O}(n^2)$ times lower than the unstructured multi-layer perceptrons. For design guidelines, we propose a unified framework that is applicable to general design problems in wireless networks, which includes graph modeling, neural architecture design, and theory-guided performance enhancement. Extensive simulations, which cover a variety of important problems and network settings, verify our theory and effectiveness of the proposed design framework.", "paper_url": "http://arxiv.org/abs/2203.10800v1", "pdf_url": "http://arxiv.org/pdf/2203.10800v1", "repo_url": "https://github.com/yshenaw/gnn4com"}, "2203.10620": {"publish_time": "2022-03-20", "title": "Differentiable Reasoning over Long Stories -- Assessing Systematic Generalisation in Neural Models", "author": "Wanshui Li et.al.", "abstract": "Contemporary neural networks have achieved a series of developments and successes in many aspects; however, when exposed to data outside the training distribution, they may fail to predict correct answers. In this work, we were concerned about this generalisation issue and thus analysed a broad set of models systematically and robustly over long stories. Related experiments were conducted based on the CLUTRR, which is a diagnostic benchmark suite that can analyse generalisation of natural language understanding (NLU) systems by training over small story graphs and testing on larger ones. In order to handle the multi-relational story graph, we consider two classes of neural models: \"E-GNN\", the graph-based models that can process graph-structured data and consider the edge attributes simultaneously; and \"L-Graph\", the sequence-based models which can process linearized version of the graphs. We performed an extensive empirical evaluation, and we found that the modified recurrent neural network yield surprisingly accurate results across every systematic generalisation tasks which outperform the modified graph neural network, while the latter produced more robust models.", "paper_url": "http://arxiv.org/abs/2203.10620v1", "pdf_url": "http://arxiv.org/pdf/2203.10620v1", "repo_url": null}, "2203.10565": {"publish_time": "2022-03-20", "title": "LEReg: Empower Graph Neural Networks with Local Energy Regularization", "author": "Xiaojun Ma et.al.", "abstract": "Researches on analyzing graphs with Graph Neural Networks (GNNs) have been receiving more and more attention because of the great expressive power of graphs. GNNs map the adjacency matrix and node features to node representations by message passing through edges on each convolution layer. However, the message passed through GNNs is not always beneficial for all parts in a graph. Specifically, as the data distribution is different over the graph, the receptive field (the farthest nodes that a node can obtain information from) needed to gather information is also different. Existing GNNs treat all parts of the graph uniformly, which makes it difficult to adaptively pass the most informative message for each unique part. To solve this problem, we propose two regularization terms that consider message passing locally: (1) Intra-Energy Reg and (2) Inter-Energy Reg. Through experiments and theoretical discussion, we first show that the speed of smoothing of different parts varies enormously and the topology of each part affects the way of smoothing. With Intra-Energy Reg, we strengthen the message passing within each part, which is beneficial for getting more useful information. With Inter-Energy Reg, we improve the ability of GNNs to distinguish different nodes. With the proposed two regularization terms, GNNs are able to filter the most useful information adaptively, learn more robustly and gain higher expressiveness. Moreover, the proposed LEReg can be easily applied to other GNN models with plug-and-play characteristics. Extensive experiments on several benchmarks verify that GNNs with LEReg outperform or match the state-of-the-art methods. The effectiveness and efficiency are also empirically visualized with elaborate experiments.", "paper_url": "http://arxiv.org/abs/2203.10565v1", "pdf_url": "http://arxiv.org/pdf/2203.10565v1", "repo_url": null}, "2203.11492": {"publish_time": "2022-03-22", "title": "Exploring High-Order Structure for Robust Graph Structure Learning", "author": "Guangqian Yang et.al.", "abstract": "Recent studies show that Graph Neural Networks (GNNs) are vulnerable to adversarial attack, i.e., an imperceptible structure perturbation can fool GNNs to make wrong predictions. Some researches explore specific properties of clean graphs such as the feature smoothness to defense the attack, but the analysis of it has not been well-studied. In this paper, we analyze the adversarial attack on graphs from the perspective of feature smoothness which further contributes to an efficient new adversarial defensive algorithm for GNNs. We discover that the effect of the high-order graph structure is a smoother filter for processing graph structures. Intuitively, the high-order graph structure denotes the path number between nodes, where larger number indicates closer connection, so it naturally contributes to defense the adversarial perturbation. Further, we propose a novel algorithm that incorporates the high-order structural information into the graph structure learning. We perform experiments on three popular benchmark datasets, Cora, Citeseer and Polblogs. Extensive experiments demonstrate the effectiveness of our method for defending against graph adversarial attacks.", "paper_url": "http://arxiv.org/abs/2203.11492v1", "pdf_url": "http://arxiv.org/pdf/2203.11492v1", "repo_url": null}, "2203.12522": {"publish_time": "2022-03-23", "title": "Semi-Supervised Graph Learning Meets Dimensionality Reduction", "author": "Alex Morehead et.al.", "abstract": "Semi-supervised learning (SSL) has recently received increased attention from machine learning researchers. By enabling effective propagation of known labels in graph-based deep learning (GDL) algorithms, SSL is poised to become an increasingly used technique in GDL in the coming years. However, there are currently few explorations in the graph-based SSL literature on exploiting classical dimensionality reduction techniques for improved label propagation. In this work, we investigate the use of dimensionality reduction techniques such as PCA, t-SNE, and UMAP to see their effect on the performance of graph neural networks (GNNs) designed for semi-supervised propagation of node labels. Our study makes use of benchmark semi-supervised GDL datasets such as the Cora and Citeseer datasets to allow meaningful comparisons of the representations learned by each algorithm when paired with a dimensionality reduction technique. Our comprehensive benchmarks and clustering visualizations quantitatively and qualitatively demonstrate that, under certain conditions, employing a priori and a posteriori dimensionality reduction to GNN inputs and outputs, respectively, can simultaneously improve the effectiveness of semi-supervised node label propagation and node clustering. Our source code is freely available on GitHub.", "paper_url": "http://arxiv.org/abs/2203.12522v1", "pdf_url": "http://arxiv.org/pdf/2203.12522v1", "repo_url": "https://github.com/amorehead/SSL-With-DR-And-GNNs"}, "2203.12363": {"publish_time": "2022-03-23", "title": "Ethereum Fraud Detection with Heterogeneous Graph Neural Networks", "author": "Hiroki Kanezashi et.al.", "abstract": "While transactions with cryptocurrencies such as Ethereum are becoming more prevalent, fraud and other criminal transactions are not uncommon. Graph analysis algorithms and machine learning techniques detect suspicious transactions that lead to phishing in large transaction networks. Many graph neural network (GNN) models have been proposed to apply deep learning techniques to graph structures. Although there is research on phishing detection using GNN models in the Ethereum transaction network, models that address the scale of the number of vertices and edges and the imbalance of labels have not yet been studied. In this paper, we compared the model performance of GNN models on the actual Ethereum transaction network dataset and phishing reported label data to exhaustively compare and verify which GNN models and hyperparameters produce the best accuracy. Specifically, we evaluated the model performance of representative homogeneous GNN models which consider single-type nodes and edges and heterogeneous GNN models which support different types of nodes and edges. We showed that heterogeneous models had better model performance than homogeneous models. In particular, the RGCN model achieved the best performance in the overall metrics.", "paper_url": "http://arxiv.org/abs/2203.12363v1", "pdf_url": "http://arxiv.org/pdf/2203.12363v1", "repo_url": null}, "2203.12848": {"publish_time": "2022-03-24", "title": "Keypoints Tracking via Transformer Networks", "author": "Oleksii Nasypanyi et.al.", "abstract": "In this thesis, we propose a pioneering work on sparse keypoints tracking across images using transformer networks. While deep learning-based keypoints matching have been widely investigated using graph neural networks - and more recently transformer networks, they remain relatively too slow to operate in real-time and are particularly sensitive to the poor repeatability of the keypoints detectors. In order to address these shortcomings, we propose to study the particular case of real-time and robust keypoints tracking. Specifically, we propose a novel architecture which ensures a fast and robust estimation of the keypoints tracking between successive images of a video sequence. Our method takes advantage of a recent breakthrough in computer vision, namely, visual transformer networks. Our method consists of two successive stages, a coarse matching followed by a fine localization of the keypoints' correspondences prediction. Through various experiments, we demonstrate that our approach achieves competitive results and demonstrates high robustness against adverse conditions, such as illumination change, occlusion and viewpoint differences.", "paper_url": "http://arxiv.org/abs/2203.12848v1", "pdf_url": "http://arxiv.org/pdf/2203.12848v1", "repo_url": "https://github.com/lexanagibator228/keypoints-tracking-via-transformer-networks"}, "2203.12831": {"publish_time": "2022-03-24", "title": "LHNN: Lattice Hypergraph Neural Network for VLSI Congestion Prediction", "author": "Bowen Wang et.al.", "abstract": "Precise congestion prediction from a placement solution plays a crucial role in circuit placement. This work proposes the lattice hypergraph (LH-graph), a novel graph formulation for circuits, which preserves netlist data during the whole learning process, and enables the congestion information propagated geometrically and topologically. Based on the formulation, we further developed a heterogeneous graph neural network architecture LHNN, jointing the routing demand regression to support the congestion spot classification. LHNN constantly achieves more than 35% improvements compared with U-nets and Pix2Pix on the F1 score. We expect our work shall highlight essential procedures using machine learning for congestion prediction.", "paper_url": "http://arxiv.org/abs/2203.12831v1", "pdf_url": "http://arxiv.org/pdf/2203.12831v1", "repo_url": null}, "2203.12852": {"publish_time": "2022-03-23", "title": "Graph Neural Networks in Particle Physics: Implementations, Innovations, and Challenges", "author": "Savannah Thais et.al.", "abstract": "Many physical systems can be best understood as sets of discrete data with associated relationships. Where previously these sets of data have been formulated as series or image data to match the available machine learning architectures, with the advent of graph neural networks (GNNs), these systems can be learned natively as graphs. This allows a wide variety of high- and low-level physical features to be attached to measurements and, by the same token, a wide variety of HEP tasks to be accomplished by the same GNN architectures. GNNs have found powerful use-cases in reconstruction, tagging, generation and end-to-end analysis. With the wide-spread adoption of GNNs in industry, the HEP community is well-placed to benefit from rapid improvements in GNN latency and memory usage. However, industry use-cases are not perfectly aligned with HEP and much work needs to be done to best match unique GNN capabilities to unique HEP obstacles. We present here a range of these capabilities, predictions of which are currently being well-adopted in HEP communities, and which are still immature. We hope to capture the landscape of graph techniques in machine learning as well as point out the most significant gaps that are inhibiting potentially large leaps in research.", "paper_url": "http://arxiv.org/abs/2203.12852v1", "pdf_url": "http://arxiv.org/pdf/2203.12852v1", "repo_url": null}, "2203.13783": {"publish_time": "2022-03-25", "title": "Ensemble Spectral Prediction (ESP) Model for Metabolite Annotation", "author": "Xinmeng Li et.al.", "abstract": "A key challenge in metabolomics is annotating measured spectra from a biological sample with chemical identities. Currently, only a small fraction of measurements can be assigned identities. Two complementary computational approaches have emerged to address the annotation problem: mapping candidate molecules to spectra, and mapping query spectra to molecular candidates. In essence, the candidate molecule with the spectrum that best explains the query spectrum is recommended as the target molecule. Despite candidate ranking being fundamental in both approaches, no prior works utilized rank learning tasks in determining the target molecule. We propose a novel machine learning model, Ensemble Spectral Prediction (ESP), for metabolite annotation. ESP takes advantage of prior neural network-based annotation models that utilize multilayer perceptron (MLP) networks and Graph Neural Networks (GNNs). Based on the ranking results of the MLP and GNN-based models, ESP learns a weighting for the outputs of MLP and GNN spectral predictors to generate a spectral prediction for a query molecule. Importantly, training data is stratified by molecular formula to provide candidate sets during model training. Further, baseline MLP and GNN models are enhanced by considering peak dependencies through multi-head attention mechanism and multi-tasking on spectral topic distributions. ESP improves average rank by 41% and 30% over the MLP and GNN baselines, respectively, demonstrating remarkable performance gain over state-of-the-art neural network approaches. We show that annotation performance, for ESP and other models, is a strong function of the number of molecules in the candidate set and their similarity to the target molecule.", "paper_url": "http://arxiv.org/abs/2203.13783v1", "pdf_url": "http://arxiv.org/pdf/2203.13783v1", "repo_url": null}, "2203.13424": {"publish_time": "2022-03-25", "title": "Dealing with Sparse Rewards Using Graph Neural Networks", "author": "Matvey Gerasyov et.al.", "abstract": "Deep reinforcement learning in partially observable environments is a difficult task in itself, and can be further complicated by a sparse reward signal. Most tasks involving navigation in three-dimensional environments provide the agent with extremely limited information. Typically, the agent receives a visual observation input from the environment and is rewarded once at the end of the episode. A good reward function could substantially improve the convergence of reinforcement learning algorithms for such tasks. The classic approach to increase the density of the reward signal is to augment it with supplementary rewards. This technique is called the reward shaping. In this study, we propose two modifications of one of the recent reward shaping methods based on graph convolutional networks: the first involving advanced aggregation functions, and the second utilizing the attention mechanism. We empirically validate the effectiveness of our solutions for the task of navigation in a 3D environment with sparse rewards. For the solution featuring attention mechanism, we are also able to show that the learned attention is concentrated on edges corresponding to important transitions in 3D environment.", "paper_url": "http://arxiv.org/abs/2203.13424v1", "pdf_url": "http://arxiv.org/pdf/2203.13424v1", "repo_url": null}, "2203.14921": {"publish_time": "2022-03-28", "title": "Learning What You Need from What You Did: Product Taxonomy Expansion with User Behaviors Supervision", "author": "Sijie Cheng et.al.", "abstract": "Taxonomies have been widely used in various domains to underpin numerous applications. Specially, product taxonomies serve an essential role in the e-commerce domain for the recommendation, browsing, and query understanding. However, taxonomies need to constantly capture the newly emerged terms or concepts in e-commerce platforms to keep up-to-date, which is expensive and labor-intensive if it relies on manual maintenance and updates. Therefore, we target the taxonomy expansion task to attach new concepts to existing taxonomies automatically. In this paper, we present a self-supervised and user behavior-oriented product taxonomy expansion framework to append new concepts into existing taxonomies. Our framework extracts hyponymy relations that conform to users' intentions and cognition. Specifically, i) to fully exploit user behavioral information, we extract candidate hyponymy relations that match user interests from query-click concepts; ii) to enhance the semantic information of new concepts and better detect hyponymy relations, we model concepts and relations through both user-generated content and structural information in existing taxonomies and user click logs, by leveraging Pre-trained Language Models and Graph Neural Network combined with Contrastive Learning; iii) to reduce the cost of dataset construction and overcome data skews, we construct a high-quality and balanced training dataset from existing taxonomy with no supervision. Extensive experiments on real-world product taxonomies in Meituan Platform, a leading Chinese vertical e-commerce platform to order take-out with more than 70 million daily active users, demonstrate the superiority of our proposed framework over state-of-the-art methods. Notably, our method enlarges the size of real-world product taxonomies from 39,263 to 94,698 relations with 88% precision.", "paper_url": "http://arxiv.org/abs/2203.14921v1", "pdf_url": "http://arxiv.org/pdf/2203.14921v1", "repo_url": "https://github.com/adacheng/product_taxonomy_expansion"}, "2203.14883": {"publish_time": "2022-03-28", "title": "TGL: A General Framework for Temporal GNN Training on Billion-Scale Graphs", "author": "Hongkuan Zhou et.al.", "abstract": "Many real world graphs contain time domain information. Temporal Graph Neural Networks capture temporal information as well as structural and contextual information in the generated dynamic node embeddings. Researchers have shown that these embeddings achieve state-of-the-art performance in many different tasks. In this work, we propose TGL, a unified framework for large-scale offline Temporal Graph Neural Network training where users can compose various Temporal Graph Neural Networks with simple configuration files. TGL comprises five main components, a temporal sampler, a mailbox, a node memory module, a memory updater, and a message passing engine. We design a Temporal-CSR data structure and a parallel sampler to efficiently sample temporal neighbors to formtraining mini-batches. We propose a novel random chunk scheduling technique that mitigates the problem of obsolete node memory when training with a large batch size. To address the limitations of current TGNNs only being evaluated on small-scale datasets, we introduce two large-scale real-world datasets with 0.2 and 1.3 billion temporal edges. We evaluate the performance of TGL on four small-scale datasets with a single GPU and the two large datasets with multiple GPUs for both link prediction and node classification tasks. We compare TGL with the open-sourced code of five methods and show that TGL achieves similar or better accuracy with an average of 13x speedup. Our temporal parallel sampler achieves an average of 173x speedup on a multi-core CPU compared with the baselines. On a 4-GPU machine, TGL can train one epoch of more than one billion temporal edges within 1-10 hours. To the best of our knowledge, this is the first work that proposes a general framework for large-scale Temporal Graph Neural Networks training on multiple GPUs.", "paper_url": "http://arxiv.org/abs/2203.14883v1", "pdf_url": "http://arxiv.org/pdf/2203.14883v1", "repo_url": null}, "2203.14846": {"publish_time": "2022-03-28", "title": "Discovering dynamic laws from observations with Graph Neural Networks: the case of self-propelled, interacting colloids", "author": "Miguel Ruiz-Garcia et.al.", "abstract": "Active matter spans a wide range of time and length scales, from groups of cells and synthetic self-propelled particles to schools of fish or even human crowds. The theoretical framework describing these systems has shown tremendous success at finding universal phenomenology. However, further progress is often burdened by the difficulty of determining the forces that control the dynamics of the individual elements within each system. Accessing this local information is key to understanding the physics dominating the system and to create the models that can explain the observed collective phenomena. In this work, we present a machine learning model, a graph neural network, that uses the collective movement of the system to learn the active and two-body forces controlling the individual dynamics of the particles. We verify our approach using numerical simulations of active brownian particles, considering different interaction potentials and levels of activity. Finally, we apply our model to experiments of electrophoretic Janus particles, extracting the active and two-body forces that control the dynamics of the colloids. Due to this, we can uncover the physics dominating the behavior of the system. We extract an active force that depends on the electric field and also area fraction. We also discover a dependence of the two-body interaction with the electric field that leads us to propose that the dominant force between these colloids is a screened electrostatic interaction with a constant length scale. We expect that this methodology can open a new avenue for the study and modeling of experimental systems of active particles.", "paper_url": "http://arxiv.org/abs/2203.14846v1", "pdf_url": "http://arxiv.org/pdf/2203.14846v1", "repo_url": null}, "2203.14487": {"publish_time": "2022-03-28", "title": "Enhancing Neural Mathematical Reasoning by Abductive Combination with Symbolic Library", "author": "Yangyang Hu et.al.", "abstract": "Mathematical reasoning recently has been shown as a hard challenge for neural systems. Abilities including expression translation, logical reasoning, and mathematics knowledge acquiring appear to be essential to overcome the challenge. This paper demonstrates that some abilities can be achieved through abductive combination with discrete systems that have been programmed with human knowledge. On a mathematical reasoning dataset, we adopt the recently proposed abductive learning framework, and propose the ABL-Sym algorithm that combines the Transformer neural models with a symbolic mathematics library. ABL-Sym shows 9.73% accuracy improvement on the interpolation tasks and 47.22% accuracy improvement on the extrapolation tasks, over the state-of-the-art approaches. Online demonstration: http://math.polixir.ai", "paper_url": "http://arxiv.org/abs/2203.14487v1", "pdf_url": "http://arxiv.org/pdf/2203.14487v1", "repo_url": null}, "2203.14486": {"publish_time": "2022-03-28", "title": "Equivariant Point Cloud Analysis via Learning Orientations for Message Passing", "author": "Shitong Luo et.al.", "abstract": "Equivariance has been a long-standing concern in various fields ranging from computer vision to physical modeling. Most previous methods struggle with generality, simplicity, and expressiveness -- some are designed ad hoc for specific data types, some are too complex to be accessible, and some sacrifice flexible transformations. In this work, we propose a novel and simple framework to achieve equivariance for point cloud analysis based on the message passing (graph neural network) scheme. We find the equivariant property could be obtained by introducing an orientation for each point to decouple the relative position for each point from the global pose of the entire point cloud. Therefore, we extend current message passing networks with a module that learns orientations for each point. Before aggregating information from the neighbors of a point, the networks transforms the neighbors' coordinates based on the point's learned orientations. We provide formal proofs to show the equivariance of the proposed framework. Empirically, we demonstrate that our proposed method is competitive on both point cloud analysis and physical modeling tasks. Code is available at https://github.com/luost26/Equivariant-OrientedMP .", "paper_url": "http://arxiv.org/abs/2203.14486v1", "pdf_url": "http://arxiv.org/pdf/2203.14486v1", "repo_url": "https://github.com/luost26/equivariant-orientedmp"}, "2203.15789": {"publish_time": "2022-03-29", "title": "Revisiting Neighborhood-based Link Prediction for Collaborative Filtering", "author": "Hao-Ming Fu et.al.", "abstract": "Collaborative filtering (CF) is one of the most successful and fundamental techniques in recommendation systems. In recent years, Graph Neural Network (GNN)-based CF models, such as NGCF [31], LightGCN [10] and GTN [9] have achieved tremendous success and significantly advanced the state-of-the-art. While there is a rich literature of such works using advanced models for learning user and item representations separately, item recommendation is essentially a link prediction problem between users and items. Furthermore, while there have been early works employing link prediction for collaborative filtering [5, 6], this trend has largely given way to works focused on aggregating information from user and item nodes, rather than modeling links directly. In this paper, we propose a new linkage (connectivity) score for bipartite graphs, generalizing multiple standard link prediction methods. We combine this new score with an iterative degree update process in the user-item interaction bipartite graph to exploit local graph structures without any node modeling. The result is a simple, non-deep learning model with only six learnable parameters. Despite its simplicity, we demonstrate our approach significantly outperforms existing state-of-the-art GNN-based CF approaches on four widely used benchmarks. In particular, on Amazon-Book, we demonstrate an over 60% improvement for both Recall and NDCG. We hope our work would invite the community to revisit the link prediction aspect of collaborative filtering, where significant performance gains could be achieved through aligning link prediction with item recommendations.", "paper_url": "http://arxiv.org/abs/2203.15789v1", "pdf_url": "http://arxiv.org/pdf/2203.15789v1", "repo_url": null}, "2203.15544": {"publish_time": "2022-03-29", "title": "Graph Neural Networks are Dynamic Programmers", "author": "Andrew Dudzik et.al.", "abstract": "Recent advances in neural algorithmic reasoning with graph neural networks (GNNs) are propped up by the notion of algorithmic alignment. Broadly, a neural network will be better at learning to execute a reasoning task (in terms of sample complexity) if its individual components align well with the target algorithm. Specifically, GNNs are claimed to align with dynamic programming (DP), a general problem-solving strategy which expresses many polynomial-time algorithms. However, has this alignment truly been demonstrated and theoretically quantified? Here we show, using methods from category theory and abstract algebra, that there exists an intricate connection between GNNs and DP, going well beyond the initial observations over individual algorithms such as Bellman-Ford. Exposing this connection, we easily verify several prior findings in the literature, and hope it will serve as a foundation for building stronger algorithmically aligned GNNs.", "paper_url": "http://arxiv.org/abs/2203.15544v1", "pdf_url": "http://arxiv.org/pdf/2203.15544v1", "repo_url": null}, "2203.15470": {"publish_time": "2022-03-29", "title": "Graph similarity learning for change-point detection in dynamic networks", "author": "Deborah Sulem et.al.", "abstract": "Dynamic networks are ubiquitous for modelling sequential graph-structured data, e.g., brain connectome, population flows and messages exchanges. In this work, we consider dynamic networks that are temporal sequences of graph snapshots, and aim at detecting abrupt changes in their structure. This task is often termed network change-point detection and has numerous applications, such as fraud detection or physical motion monitoring. Leveraging a graph neural network model, we design a method to perform online network change-point detection that can adapt to the specific network domain and localise changes with no delay. The main novelty of our method is to use a siamese graph neural network architecture for learning a data-driven graph similarity function, which allows to effectively compare the current graph and its recent history. Importantly, our method does not require prior knowledge on the network generative distribution and is agnostic to the type of change-points; moreover, it can be applied to a large variety of networks, that include for instance edge weights and node attributes. We show on synthetic and real data that our method enjoys a number of benefits: it is able to learn an adequate graph similarity function for performing online network change-point detection in diverse types of change-point settings, and requires a shorter data history to detect changes than most existing state-of-the-art baselines.", "paper_url": "http://arxiv.org/abs/2203.15470v1", "pdf_url": "http://arxiv.org/pdf/2203.15470v1", "repo_url": null}, "2203.15209": {"publish_time": "2022-03-29", "title": "OrphicX: A Causality-Inspired Latent Variable Model for Interpreting Graph Neural Networks", "author": "Wanyu Lin et.al.", "abstract": "This paper proposes a new eXplanation framework, called OrphicX, for generating causal explanations for any graph neural networks (GNNs) based on learned latent causal factors. Specifically, we construct a distinct generative model and design an objective function that encourages the generative model to produce causal, compact, and faithful explanations. This is achieved by isolating the causal factors in the latent space of graphs by maximizing the information flow measurements. We theoretically analyze the cause-effect relationships in the proposed causal graph, identify node attributes as confounders between graphs and GNN predictions, and circumvent such confounder effect by leveraging the backdoor adjustment formula. Our framework is compatible with any GNNs, and it does not require access to the process by which the target GNN produces its predictions. In addition, it does not rely on the linear-independence assumption of the explained features, nor require prior knowledge on the graph learning tasks. We show a proof-of-concept of OrphicX on canonical classification problems on graph data. In particular, we analyze the explanatory subgraphs obtained from explanations for molecular graphs (i.e., Mutag) and quantitatively evaluate the explanation performance with frequently occurring subgraph patterns. Empirically, we show that OrphicX can effectively identify the causal semantics for generating causal explanations, significantly outperforming its alternatives.", "paper_url": "http://arxiv.org/abs/2203.15209v1", "pdf_url": "http://arxiv.org/pdf/2203.15209v1", "repo_url": "https://github.com/wanyugroup/cvpr2022-orphicx"}, "2203.15182": {"publish_time": "2022-03-29", "title": "Long-term Visual Map Sparsification with Heterogeneous GNN", "author": "Ming-Fang Chang et.al.", "abstract": "We address the problem of map sparsification for long-term visual localization. For map sparsification, a commonly employed assumption is that the pre-build map and the later captured localization query are consistent. However, this assumption can be easily violated in the dynamic world. Additionally, the map size grows as new data accumulate through time, causing large data overhead in the long term. In this paper, we aim to overcome the environmental changes and reduce the map size at the same time by selecting points that are valuable to future localization. Inspired by the recent progress in Graph Neural Network(GNN), we propose the first work that models SfM maps as heterogeneous graphs and predicts 3D point importance scores with a GNN, which enables us to directly exploit the rich information in the SfM map graph. Two novel supervisions are proposed: 1) a data-fitting term for selecting valuable points to future localization based on training queries; 2) a K-Cover term for selecting sparse points with full map coverage. The experiments show that our method selected map points on stable and widely visible structures and outperformed baselines in localization performance.", "paper_url": "http://arxiv.org/abs/2203.15182v1", "pdf_url": "http://arxiv.org/pdf/2203.15182v1", "repo_url": null}, "2203.16319": {"publish_time": "2022-03-30", "title": "Multi-Robot Active Mapping via Neural Bipartite Graph Matching", "author": "Kai Ye et.al.", "abstract": "We study the problem of multi-robot active mapping, which aims for complete scene map construction in minimum time steps. The key to this problem lies in the goal position estimation to enable more efficient robot movements. Previous approaches either choose the frontier as the goal position via a myopic solution that hinders the time efficiency, or maximize the long-term value via reinforcement learning to directly regress the goal position, but does not guarantee the complete map construction. In this paper, we propose a novel algorithm, namely NeuralCoMapping, which takes advantage of both approaches. We reduce the problem to bipartite graph matching, which establishes the node correspondences between two graphs, denoting robots and frontiers. We introduce a multiplex graph neural network (mGNN) that learns the neural distance to fill the affinity matrix for more effective graph matching. We optimize the mGNN with a differentiable linear assignment layer by maximizing the long-term values that favor time efficiency and map completeness via reinforcement learning. We compare our algorithm with several state-of-the-art multi-robot active mapping approaches and adapted reinforcement-learning baselines. Experimental results demonstrate the superior performance and exceptional generalization ability of our algorithm on various indoor scenes and unseen number of robots, when only trained with 9 indoor scenes.", "paper_url": "http://arxiv.org/abs/2203.16319v1", "pdf_url": "http://arxiv.org/pdf/2203.16319v1", "repo_url": null}, "2203.16280": {"publish_time": "2022-03-30", "title": "CMMD: Cross-Metric Multi-Dimensional Root Cause Analysis", "author": "Shifu Yan et.al.", "abstract": "In large-scale online services, crucial metrics, a.k.a., key performance indicators (KPIs), are monitored periodically to check their running statuses. Generally, KPIs are aggregated along multiple dimensions and derived by complex calculations among fundamental metrics from the raw data. Once abnormal KPI values are observed, root cause analysis (RCA) can be applied to identify the reasons for anomalies, so that we can troubleshoot quickly. Recently, several automatic RCA techniques were proposed to localize the related dimensions (or a combination of dimensions) to explain the anomalies. However, their analyses are limited to the data on the abnormal metric and ignore the data of other metrics which may be also related to the anomalies, leading to imprecise or even incorrect root causes. To this end, we propose a cross-metric multi-dimensional root cause analysis method, named CMMD, which consists of two key components: 1) relationship modeling, which utilizes graph neural network (GNN) to model the unknown complex calculation among metrics and aggregation function among dimensions from historical data; 2) root cause localization, which adopts the genetic algorithm to efficiently and effectively dive into the raw data and localize the abnormal dimension(s) once the KPI anomalies are detected. Experiments on synthetic datasets, public datasets and online production environment demonstrate the superiority of our proposed CMMD method compared with baselines. Currently, CMMD is running as an online service in Microsoft Azure.", "paper_url": "http://arxiv.org/abs/2203.16280v1", "pdf_url": "http://arxiv.org/pdf/2203.16280v1", "repo_url": null}, "2203.16162": {"publish_time": "2022-03-30", "title": "AdaGrid: Adaptive Grid Search for Link Prediction Training Objective", "author": "Tim Po\u0161tuvan et.al.", "abstract": "One of the most important factors that contribute to the success of a machine learning model is a good training objective. Training objective crucially influences the model's performance and generalization capabilities. This paper specifically focuses on graph neural network training objective for link prediction, which has not been explored in the existing literature. Here, the training objective includes, among others, a negative sampling strategy, and various hyperparameters, such as edge message ratio which controls how training edges are used. Commonly, these hyperparameters are fine-tuned by complete grid search, which is very time-consuming and model-dependent. To mitigate these limitations, we propose Adaptive Grid Search (AdaGrid), which dynamically adjusts the edge message ratio during training. It is model agnostic and highly scalable with a fully customizable computational budget. Through extensive experiments, we show that AdaGrid can boost the performance of the models up to $1.9\\%$ while being nine times more time-efficient than a complete search. Overall, AdaGrid represents an effective automated algorithm for designing machine learning training objectives.", "paper_url": "http://arxiv.org/abs/2203.16162v1", "pdf_url": "http://arxiv.org/pdf/2203.16162v1", "repo_url": null}, "2203.15936": {"publish_time": "2022-03-29", "title": "A Simple Yet Effective Pretraining Strategy for Graph Few-shot Learning", "author": "Zhen Tan et.al.", "abstract": "Recently, increasing attention has been devoted to the graph few-shot learning problem, where the target novel classes only contain a few labeled nodes. Among many existing endeavors, episodic meta-learning has become the most prevailing paradigm, and its episodic emulation of the test environment is believed to equip the graph neural network models with adaptability to novel node classes. However, in the image domain, recent results have shown that feature reuse is more likely to be the key of meta-learning to few-shot extrapolation. Based on such observation, in this work, we propose a simple transductive fine-tuning based framework as a new paradigm for graph few-shot learning. In the proposed paradigm, a graph encoder backbone is pretrained with base classes, and a simple linear classifier is fine-tuned by the few labeled samples and is tasked to classify the unlabeled ones. For pretraining, we propose a supervised contrastive learning framework with data augmentation strategies specific for few-shot node classification to improve the extrapolation of a GNN encoder. Finally, extensive experiments conducted on three benchmark datasets demonstrate the superior advantage of our framework over the state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2203.15936v1", "pdf_url": "http://arxiv.org/pdf/2203.15936v1", "repo_url": null}, "2203.15935": {"publish_time": "2022-03-29", "title": "Graph Neural Networks in IoT: A Survey", "author": "Guimin Dong et.al.", "abstract": "The Internet of Things (IoT) boom has revolutionized almost every corner of people's daily lives: healthcare, home, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technologies, IoT devices including smart wearables, cameras, smartwatches, and autonomous vehicles can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph Neural Networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-the-art results in numerous IoT learning tasks. In this survey, we present a comprehensive review of recent advances in the application of GNNs to the IoT field, including a deep dive analysis of GNN design in various IoT sensing environments, an overarching list of public data and source code from the collected publications, and future research directions. To keep track of newly published works, we collect representative papers and their open-source implementations and create a Github repository at https://github.com/GuiminDong/GNN4IoT.", "paper_url": "http://arxiv.org/abs/2203.15935v1", "pdf_url": "http://arxiv.org/pdf/2203.15935v1", "repo_url": "https://github.com/guimindong/gnn4iot"}, "2203.17149": {"publish_time": "2022-03-31", "title": "AEGNN: Asynchronous Event-based Graph Neural Networks", "author": "Simon Schaefer et.al.", "abstract": "The best performing learning algorithms devised for event cameras work by first converting events into dense representations that are then processed using standard CNNs. However, these steps discard both the sparsity and high temporal resolution of events, leading to high computational burden and latency. For this reason, recent works have adopted Graph Neural Networks (GNNs), which process events as \"static\" spatio-temporal graphs, which are inherently \"sparse\". We take this trend one step further by introducing Asynchronous, Event-based Graph Neural Networks (AEGNNs), a novel event-processing paradigm that generalizes standard GNNs to process events as \"evolving\" spatio-temporal graphs. AEGNNs follow efficient update rules that restrict recomputation of network activations only to the nodes affected by each new event, thereby significantly reducing both computation and latency for event-by-event processing. AEGNNs are easily trained on synchronous inputs and can be converted to efficient, \"asynchronous\" networks at test time. We thoroughly validate our method on object classification and detection tasks, where we show an up to a 200-fold reduction in computational complexity (FLOPs), with similar or even better performance than state-of-the-art asynchronous methods. This reduction in computation directly translates to an 8-fold reduction in computational latency when compared to standard GNNs, which opens the door to low-latency event-based processing.", "paper_url": "http://arxiv.org/abs/2203.17149v1", "pdf_url": "http://arxiv.org/pdf/2203.17149v1", "repo_url": null}, "2203.16995": {"publish_time": "2022-03-31", "title": "Message Passing Neural Networks for Hypergraphs", "author": "Sajjad Heydari et.al.", "abstract": "Hypergraph representations are both more efficient and better suited to describe data characterized by relations between two or more objects. In this work, we present the first graph neural network based on message passing capable of processing hypergraph-structured data. We show that the proposed model defines a design space for neural network models for hypergraphs, thus generalizing existing models for hypergraphs. We report experiments on a benchmark dataset for node classification, highlighting the effectiveness of the proposed model with respect to other state-of-the-art methods for graphs and hypergraphs. We also discuss the benefits of using hypergraph representations and, at the same time, highlight the limitation of using equivalent graph representations when the underlying problem has relations among more than two objects.", "paper_url": "http://arxiv.org/abs/2203.16995v1", "pdf_url": "http://arxiv.org/pdf/2203.16995v1", "repo_url": null}, "2203.16628": {"publish_time": "2022-03-30", "title": "Physics-constrained Unsupervised Learning of Partial Differential Equations using Meshes", "author": "Mike Y. Michelis et.al.", "abstract": "Enhancing neural networks with knowledge of physical equations has become an efficient way of solving various physics problems, from fluid flow to electromagnetism. Graph neural networks show promise in accurately representing irregularly meshed objects and learning their dynamics, but have so far required supervision through large datasets. In this work, we represent meshes naturally as graphs, process these using Graph Networks, and formulate our physics-based loss to provide an unsupervised learning framework for partial differential equations (PDE). We quantitatively compare our results to a classical numerical PDE solver, and show that our computationally efficient approach can be used as an interactive PDE solver that is adjusting boundary conditions in real-time and remains sufficiently close to the baseline solution. Our inherently differentiable framework will enable the application of PDE solvers in interactive settings, such as model-based control of soft-body deformations, or in gradient-based optimization methods that require a fully differentiable pipeline.", "paper_url": "http://arxiv.org/abs/2203.16628v1", "pdf_url": "http://arxiv.org/pdf/2203.16628v1", "repo_url": null}, "2204.00255": {"publish_time": "2022-04-01", "title": "NC-DRE: Leveraging Non-entity Clue Information for Document-level Relation Extraction", "author": "Liang Zhang et.al.", "abstract": "Document-level relation extraction (RE), which requires reasoning on multiple entities in different sentences to identify complex inter-sentence relations, is more challenging than sentence-level RE. To extract the complex inter-sentence relations, previous studies usually employ graph neural networks (GNN) to perform inference upon heterogeneous document-graphs. Despite their great successes, these graph-based methods, which normally only consider the words within the mentions in the process of building graphs and reasoning, tend to ignore the non-entity clue words that are not in the mentions but provide important clue information for relation reasoning. To alleviate this problem, we treat graph-based document-level RE models as an encoder-decoder framework, which typically uses a pre-trained language model as the encoder and a GNN model as the decoder, and propose a novel graph-based model NC-DRE that introduces decoder-to-encoder attention mechanism to leverage Non-entity Clue information for Document-level Relation Extraction.", "paper_url": "http://arxiv.org/abs/2204.00255v1", "pdf_url": "http://arxiv.org/pdf/2204.00255v1", "repo_url": null}, "2204.00203": {"publish_time": "2022-04-01", "title": "Graph Enhanced Contrastive Learning for Radiology Findings Summarization", "author": "Jinpeng Hu et.al.", "abstract": "The impression section of a radiology report summarizes the most prominent observation from the findings section and is the most important section for radiologists to communicate to physicians. Summarizing findings is time-consuming and can be prone to error for inexperienced radiologists, and thus automatic impression generation has attracted substantial attention. With the encoder-decoder framework, most previous studies explore incorporating extra knowledge (e.g., static pre-defined clinical ontologies or extra background information). Yet, they encode such knowledge by a separate encoder to treat it as an extra input to their models, which is limited in leveraging their relations with the original findings. To address the limitation, we propose a unified framework for exploiting both extra knowledge and the original findings in an integrated way so that the critical information (i.e., key words and their relations) can be extracted in an appropriate way to facilitate impression generation. In detail, for each input findings, it is encoded by a text encoder, and a graph is constructed through its entities and dependency tree. Then, a graph encoder (e.g., graph neural networks (GNNs)) is adopted to model relation information in the constructed graph. Finally, to emphasize the key words in the findings, contrastive learning is introduced to map positive samples (constructed by masking non-key words) closer and push apart negative ones (constructed by masking key words). The experimental results on OpenI and MIMIC-CXR confirm the effectiveness of our proposed method.", "paper_url": "http://arxiv.org/abs/2204.00203v1", "pdf_url": "http://arxiv.org/pdf/2204.00203v1", "repo_url": "https://github.com/jinpeng01/aig_cl"}, "2204.01681": {"publish_time": "2022-04-04", "title": "End-to-end multi-particle reconstruction in high occupancy imaging calorimeters with graph neural networks", "author": "Shah Rukh Qasim et.al.", "abstract": "We present an end-to-end reconstruction algorithm to build particle candidates from detector hits in next-generation granular calorimeters similar to that foreseen for the high-luminosity upgrade of the CMS detector. The algorithm exploits a distance-weighted graph neural network, trained with object condensation, a graph segmentation technique. Through a single-shot approach, the reconstruction task is paired with energy regression. We describe the reconstruction performance in terms of efficiency as well as in terms of energy resolution. In addition, we show the jet reconstruction performance of our method and discuss its inference computational cost. This work is the first-ever example of single-shot calorimetric reconstruction of ${\\cal O}(1000)$ particles in high-luminosity conditions with 200 pileup to our knowledge.", "paper_url": "http://arxiv.org/abs/2204.01681v1", "pdf_url": "http://arxiv.org/pdf/2204.01681v1", "repo_url": null}, "2204.01618": {"publish_time": "2022-04-04", "title": "Deep-Ensemble-Based Uncertainty Quantification in Spatiotemporal Graph Neural Networks for Traffic Forecasting", "author": "Tanwi Mallick et.al.", "abstract": "Deep-learning-based data-driven forecasting methods have produced impressive results for traffic forecasting. A major limitation of these methods, however, is that they provide forecasts without estimates of uncertainty, which are critical for real-time deployments. We focus on a diffusion convolutional recurrent neural network (DCRNN), a state-of-the-art method for short-term traffic forecasting. We develop a scalable deep ensemble approach to quantify uncertainties for DCRNN. Our approach uses a scalable Bayesian optimization method to perform hyperparameter optimization, selects a set of high-performing configurations, fits a generative model to capture the joint distributions of the hyperparameter configurations, and trains an ensemble of models by sampling a new set of hyperparameter configurations from the generative model. We demonstrate the efficacy of the proposed methods by comparing them with other uncertainty estimation techniques. We show that our generic and scalable approach outperforms the current state-of-the-art Bayesian and a number of other commonly used frequentist techniques.", "paper_url": "http://arxiv.org/abs/2204.01618v1", "pdf_url": "http://arxiv.org/pdf/2204.01618v1", "repo_url": null}, "2204.01376": {"publish_time": "2022-04-04", "title": "Synthetic Graph Generation to Benchmark Graph Learning", "author": "Anton Tsitsulin et.al.", "abstract": "Graph learning algorithms have attained state-of-the-art performance on many graph analysis tasks such as node classification, link prediction, and clustering. It has, however, become hard to track the field's burgeoning progress. One reason is due to the very small number of datasets used in practice to benchmark the performance of graph learning algorithms. This shockingly small sample size (~10) allows for only limited scientific insight into the problem.   In this work, we aim to address this deficiency. We propose to generate synthetic graphs, and study the behaviour of graph learning algorithms in a controlled scenario. We develop a fully-featured synthetic graph generator that allows deep inspection of different models. We argue that synthetic graph generations allows for thorough investigation of algorithms and provides more insights than overfitting on three citation datasets. In the case study, we show how our framework provides insight into unsupervised and supervised graph neural network models.", "paper_url": "http://arxiv.org/abs/2204.01376v1", "pdf_url": "http://arxiv.org/pdf/2204.01376v1", "repo_url": null}, "2204.01349": {"publish_time": "2022-04-04", "title": "MGRR-Net: Multi-level Graph Relational Reasoning Network for Facial Action Units Detection", "author": "Xuri Ge et.al.", "abstract": "The Facial Action Coding System (FACS) encodes the action units (AUs) in facial images, which has attracted extensive research attention due to its wide use in facial expression analysis. Many methods that perform well on automatic facial action unit (AU) detection primarily focus on modeling various types of AU relations between corresponding local muscle areas, or simply mining global attention-aware facial features, however, neglect the dynamic interactions among local-global features. We argue that encoding AU features just from one perspective may not capture the rich contextual information between regional and global face features, as well as the detailed variability across AUs, because of the diversity in expression and individual characteristics. In this paper, we propose a novel Multi-level Graph Relational Reasoning Network (termed MGRR-Net) for facial AU detection. Each layer of MGRR-Net performs a multi-level (i.e., region-level, pixel-wise and channel-wise level) feature learning. While the region-level feature learning from local face patches features via graph neural network can encode the correlation across different AUs, the pixel-wise and channel-wise feature learning via graph attention network can enhance the discrimination ability of AU features from global face features. The fused features from the three levels lead to improved AU discriminative ability. Extensive experiments on DISFA and BP4D AU datasets show that the proposed approach achieves superior performance than the state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2204.01349v1", "pdf_url": "http://arxiv.org/pdf/2204.01349v1", "repo_url": null}, "2204.01089": {"publish_time": "2022-04-03", "title": "Virtual Relational Knowledge Graphs for Recommendation", "author": "Lingyun Lu et.al.", "abstract": "Incorporating knowledge graph as side information has become a new trend in recommendation systems. Recent studies regard items as entities of a knowledge graph and leverage graph neural networks to assist item encoding, yet by considering each relation type individually. However, relation types are often too many and sometimes one relation type involves too few entities. We argue that it is not efficient nor effective to use every relation type for item encoding. In this paper, we propose a VRKG4Rec model (Virtual Relational Knowledge Graphs for Recommendation), which explicitly distinguish the influence of different relations for item representation learning. We first construct virtual relational graphs (VRKGs) by an unsupervised learning scheme. We also design a local weighted smoothing (LWS) mechanism for encoding nodes, which iteratively updates a node embedding only depending on the embedding of its own and its neighbors, but involve no additional training parameters. We also employ the LWS mechanism on a user-item bipartite graph for user representation learning, which utilizes encodings of items with relational knowledge to help training representations of users. Experiment results on two public datasets validate that our VRKG4Rec model outperforms the state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2204.01089v1", "pdf_url": "http://arxiv.org/pdf/2204.01089v1", "repo_url": null}, "2204.02338": {"publish_time": "2022-04-05", "title": "MGDCF: Distance Learning via Markov Graph Diffusion for Neural Collaborative Filtering", "author": "Jun Hu et.al.", "abstract": "Collaborative filtering (CF) is widely used by personalized recommendation systems, which aims to predict the preference of users with historical user-item interactions. In recent years, Graph Neural Networks (GNNs) have been utilized to build CF models and have shown promising performance. Recent state-of-the-art GNN-based CF approaches simply attribute their performance improvement to the high-order neighbor aggregation ability of GNNs. However, we observe that some powerful deep GNNs such as JKNet and DropEdge, can effectively exploit high-order neighbor information on other graph tasks but perform poorly on CF tasks, which conflicts with the explanation of these GNN-based CF research. Different from these research, we investigate the GNN-based CF from the perspective of Markov processes for distance learning with a unified framework named Markov Graph Diffusion Collaborative Filtering (MGDCF). We design a Markov Graph Diffusion Network (MGDN) as MGDCF's GNN encoder, which learns vertex representations by trading off two types of distances via a Markov process. We show the theoretical equivalence between MGDN's output and the optimal solution of a distance loss function, which can boost the optimization of CF models. MGDN can generalize state-of-the-art models such as LightGCN and APPNP, which are heterogeneous GNNs. In addition, MGDN can be extended to homogeneous GNNs with our sparsification technique. For optimizing MGDCF, we propose the InfoBPR loss function, which extends the widely used BPR loss to exploit multiple negative samples for better performance. We conduct experiments to perform detailed analysis on MGDCF. The source code is publicly available at https://github.com/hujunxianligong/MGDCF.", "paper_url": "http://arxiv.org/abs/2204.02338v1", "pdf_url": "http://arxiv.org/pdf/2204.02338v1", "repo_url": "https://github.com/hujunxianligong/MGDCF"}, "2204.02119": {"publish_time": "2022-04-05", "title": "Transition Information Enhanced Disentangled Graph Neural Networks for Session-based Recommendation", "author": "Ansong Li et.al.", "abstract": "Session-based recommendation is a practical recommendation task that predicts the next item based on an anonymous behavior sequence, and its performance relies heavily on the transition information between items in the sequence. The SOTA methods in SBR employ GNN to model neighboring item transitions from global (i.e, other sessions) and local (i.e, current session) contexts. However, most existing methods treat neighbors from different sessions equally without considering that the neighbor items from different sessions may share similar features with the target item on different aspects and may have different contributions. In other words, they have not explored finer-granularity transition information between items in the global context, leading to sub-optimal performance. In this paper, we fill this gap by proposing a novel Transition Information Enhanced Disentangled Graph Neural Network (TIE-DGNN) model to capture finer-granular transition information between items and try to interpret the reason of the transition by modeling the various factors of the item. Specifically, we propose a position-aware global graph, which utilizes the relative position information to model the neighboring item transition. Then, we slice item embeddings into blocks, each of which represents a factor, and use disentangling module to separately learn the factor embeddings over the global graph. For local context, we train item embeddings by using attention mechanisms to capture transition information from the current session. To this end, our model considers two levels of transition information. Especially in global text, we not only consider finer-granularity transition information between items but also take user intents at factor-level into account to interpret the key reason for the transition. Extensive experiments on three datasets demonstrate the superiority of our method over the SOTA methods.", "paper_url": "http://arxiv.org/abs/2204.02119v1", "pdf_url": "http://arxiv.org/pdf/2204.02119v1", "repo_url": "https://github.com/AnsongLi/TIE-DGNN"}, "2204.02002": {"publish_time": "2022-04-05", "title": "Micro-Behavior Encoding for Session-based Recommendation", "author": "Jiahao Yuan et.al.", "abstract": "Session-based Recommendation (SR) aims to predict the next item for recommendation based on previously recorded sessions of user interaction. The majority of existing approaches to SR focus on modeling the transition patterns of items. In such models, the so-called micro-behaviors describing how the user locates an item and carries out various activities on it (e.g., click, add-to-cart, and read-comments), are simply ignored. A few recent studies have tried to incorporate the sequential patterns of micro-behaviors into SR models. However, those sequential models still cannot effectively capture all the inherent interdependencies between micro-behavior operations. In this work, we aim to investigate the effects of the micro-behavior information in SR systematically. Specifically, we identify two different patterns of micro-behaviors: \"sequential patterns\" and \"dyadic relational patterns\". To build a unified model of user micro-behaviors, we first devise a multigraph to aggregate the sequential patterns from different items via a graph neural network, and then utilize an extended self-attention network to exploit the pair-wise relational patterns of micro-behaviors. Extensive experiments on three public real-world datasets show the superiority of the proposed approach over the state-of-theart baselines and confirm the usefulness of these two different micro-behavior patterns for SR.", "paper_url": "http://arxiv.org/abs/2204.02002v1", "pdf_url": "http://arxiv.org/pdf/2204.02002v1", "repo_url": null}, "2204.02944": {"publish_time": "2022-04-06", "title": "\"The Pedestrian next to the Lamppost\" Adaptive Object Graphs for Better Instantaneous Mapping", "author": "Avishkar Saha et.al.", "abstract": "Estimating a semantically segmented bird's-eye-view (BEV) map from a single image has become a popular technique for autonomous control and navigation. However, they show an increase in localization error with distance from the camera. While such an increase in error is entirely expected - localization is harder at distance - much of the drop in performance can be attributed to the cues used by current texture-based models, in particular, they make heavy use of object-ground intersections (such as shadows), which become increasingly sparse and uncertain for distant objects. In this work, we address these shortcomings in BEV-mapping by learning the spatial relationship between objects in a scene. We propose a graph neural network which predicts BEV objects from a monocular image by spatially reasoning about an object within the context of other objects. Our approach sets a new state-of-the-art in BEV estimation from monocular images across three large-scale datasets, including a 50% relative improvement for objects on nuScenes.", "paper_url": "http://arxiv.org/abs/2204.02944v1", "pdf_url": "http://arxiv.org/pdf/2204.02944v1", "repo_url": null}, "2204.02782": {"publish_time": "2022-04-06", "title": "How Do Graph Networks Generalize to Large and Diverse Molecular Systems?", "author": "Johannes Gasteiger et.al.", "abstract": "The predominant method of demonstrating progress of atomic graph neural networks are benchmarks on small and limited datasets. The implicit hypothesis behind this approach is that progress on these narrow datasets generalize to the large diversity of chemistry. This generalizability would be very helpful for research, but currently remains untested. In this work we test this assumption by identifying four aspects of complexity in which many datasets are lacking: 1. Chemical diversity (number of different elements), 2. system size (number of atoms per sample), 3. dataset size (number of data samples), and 4. domain shift (similarity of the training and test set). We introduce multiple subsets of the large Open Catalyst 2020 (OC20) dataset to independently investigate each of these aspects. We then perform 21 ablation studies and sensitivity analyses on 9 datasets testing both previously proposed and new model enhancements. We find that some improvements are consistent between datasets, but many are not and some even have opposite effects. Based on this analysis, we identify a smaller dataset that correlates well with the full OC20 dataset, and propose the GemNet-OC model, which outperforms the previous state-of-the-art on OC20 by 16%, while reducing training time by a factor of 10. Overall, our findings challenge the common belief that graph neural networks work equally well independent of dataset size and diversity, and suggest that caution must be exercised when making generalizations based on narrow datasets.", "paper_url": "http://arxiv.org/abs/2204.02782v1", "pdf_url": "http://arxiv.org/pdf/2204.02782v1", "repo_url": null}, "2204.02625": {"publish_time": "2022-04-06", "title": "Bridging the Gap of AutoGraph between Academia and Industry: Analysing AutoGraph Challenge at KDD Cup 2020", "author": "Zhen Xu et.al.", "abstract": "Graph structured data is ubiquitous in daily life and scientific areas and has attracted increasing attention. Graph Neural Networks (GNNs) have been proved to be effective in modeling graph structured data and many variants of GNN architectures have been proposed. However, much human effort is often needed to tune the architecture depending on different datasets. Researchers naturally adopt Automated Machine Learning on Graph Learning, aiming to reduce the human effort and achieve generally top-performing GNNs, but their methods focus more on the architecture search. To understand GNN practitioners' automated solutions, we organized AutoGraph Challenge at KDD Cup 2020, emphasizing on automated graph neural networks for node classification. We received top solutions especially from industrial tech companies like Meituan, Alibaba and Twitter, which are already open sourced on Github. After detailed comparisons with solutions from academia, we quantify the gaps between academia and industry on modeling scope, effectiveness and efficiency, and show that (1) academia AutoML for Graph solutions focus on GNN architecture search while industrial solutions, especially the winning ones in the KDD Cup, tend to obtain an overall solution (2) by neural architecture search only, academia solutions achieve on average 97.3% accuracy of industrial solutions (3) academia solutions are cheap to obtain with several GPU hours while industrial solutions take a few months' labors. Academic solutions also contain much fewer parameters.", "paper_url": "http://arxiv.org/abs/2204.02625v1", "pdf_url": "http://arxiv.org/pdf/2204.02625v1", "repo_url": null}, "2204.03225": {"publish_time": "2022-04-07", "title": "Explicit Feature Interaction-aware Graph Neural Networks", "author": "Minkyu Kim et.al.", "abstract": "Graph neural networks are powerful methods to handle graph-structured data. However, existing graph neural networks only learn higher-order feature interactions implicitly. Thus, they cannot capture information that occurred in low-order feature interactions. To overcome this problem, we propose Explicit Feature Interaction-aware Graph Neural Network (EFI-GNN), which explicitly learns arbitrary-order feature interactions. EFI-GNN can jointly learn with any other graph neural network. We demonstrate that the joint learning method always enhances performance on the various node classification tasks. Furthermore, since EFI-GNN is inherently a linear model, we can interpret the prediction result of EFI-GNN. With the computation rule, we can obtain an any-order feature's effect on the decision. By that, we visualize the effects of the first-order and second-order features as a form of a heatmap.", "paper_url": "http://arxiv.org/abs/2204.03225v1", "pdf_url": "http://arxiv.org/pdf/2204.03225v1", "repo_url": null}, "2204.03117": {"publish_time": "2022-04-06", "title": "BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based Sentiment Analysis", "author": "Shuo Liang et.al.", "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task that aims to align aspects and corresponding sentiments for aspect-specific sentiment polarity inference. It is challenging because a sentence may contain multiple aspects or complicated (e.g., conditional, coordinating, or adversative) relations. Recently, exploiting dependency syntax information with graph neural networks has been the most popular trend. Despite its success, methods that heavily rely on the dependency tree pose challenges in accurately modeling the alignment of the aspects and their words indicative of sentiment, since the dependency tree may provide noisy signals of unrelated associations (e.g., the \"conj\" relation between \"great\" and \"dreadful\" in Figure 2). In this paper, to alleviate this problem, we propose a Bi-Syntax aware Graph Attention Network (BiSyn-GAT+). Specifically, BiSyn-GAT+ fully exploits the syntax information (e.g., phrase segmentation and hierarchical structure) of the constituent tree of a sentence to model the sentiment-aware context of every single aspect (called intra-context) and the sentiment relations across aspects (called inter-context) for learning. Experiments on four benchmark datasets demonstrate that BiSyn-GAT+ outperforms the state-of-the-art methods consistently.", "paper_url": "http://arxiv.org/abs/2204.03117v1", "pdf_url": "http://arxiv.org/pdf/2204.03117v1", "repo_url": null}, "2204.03080": {"publish_time": "2022-04-06", "title": "Graph Neural Networks Designed for Different Graph Types: A Survey", "author": "Josephine M. Thomas et.al.", "abstract": "Graphs are ubiquitous in nature and can therefore serve as models for many practical but also theoretical problems. Based on this, the young research field of Graph Neural Networks (GNNs) has emerged. Despite the youth of the field and the speed in which new models are developed, many good surveys have been published in the last years. Nevertheless, an overview on which graph types can be modeled by GNNs is missing. In this survey, we give a detailed overview of already existing GNNs and, unlike previous surveys, categorize them according to their ability to handle different graph types. We consider GNNs operating on static as well as on dynamic graphs of different structural constitutions, with or without node or edge attributes. Moreover in the dynamic case, we separate the models in discrete-time and continuous-time dynamic graphs based on their architecture. According to our findings, there are still graph types, that are not covered by existing GNN models. Specifically, models concerning heterogeneity in attributes are missing and the deletion of nodes and edges is only covered rarely.", "paper_url": "http://arxiv.org/abs/2204.03080v1", "pdf_url": "http://arxiv.org/pdf/2204.03080v1", "repo_url": null}, "2204.04046": {"publish_time": "2022-04-08", "title": "KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media", "author": "Wenqian Zhang et.al.", "abstract": "Political perspective detection has become an increasingly important task that can help combat echo chambers and political polarization. Previous approaches generally focus on leveraging textual content to identify stances, while they fail to reason with background knowledge or leverage the rich semantic and syntactic textual labels in news articles. In light of these limitations, we propose KCD, a political perspective detection approach to enable multi-hop knowledge reasoning and incorporate textual cues as paragraph-level labels. Specifically, we firstly generate random walks on external knowledge graphs and infuse them with news text representations. We then construct a heterogeneous information network to jointly model news content as well as semantic, syntactic and entity cues in news articles. Finally, we adopt relational graph neural networks for graph-level representation learning and conduct political perspective detection. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods on two benchmark datasets. We further examine the effect of knowledge walks and textual cues and how they contribute to our approach's data efficiency.", "paper_url": "http://arxiv.org/abs/2204.04046v1", "pdf_url": "http://arxiv.org/pdf/2204.04046v1", "repo_url": null}, "2204.03954": {"publish_time": "2022-04-08", "title": "Bag-of-Words vs. Sequence vs. Graph vs. Hierarchy for Single- and Multi-Label Text Classification", "author": "Andor Diera et.al.", "abstract": "Graph neural networks have triggered a resurgence of graph-based text classification methods, defining today's state of the art. We show that a simple multi-layer perceptron (MLP) using a Bag of Words (BoW) outperforms the recent graph-based models TextGCN and HeteGCN in an inductive text classification setting and is comparable with HyperGAT in single-label classification. We also run our own experiments on multi-label classification, where the simple MLP outperforms the recent sequential-based gMLP and aMLP models. Moreover, we fine-tune a sequence-based BERT and a lightweight DistilBERT model, which both outperform all models on both single-label and multi-label settings in most datasets. These results question the importance of synthetic graphs used in modern text classifiers. In terms of parameters, DistilBERT is still twice as large as our BoW-based wide MLP, while graph-based models like TextGCN require setting up an $\\mathcal{O}(N^2)$ graph, where $N$ is the vocabulary plus corpus size.", "paper_url": "http://arxiv.org/abs/2204.03954v1", "pdf_url": "http://arxiv.org/pdf/2204.03954v1", "repo_url": null}, "2204.05258": {"publish_time": "2022-04-11", "title": "Multi-view graph structure learning using subspace merging on Grassmann manifold", "author": "Razieh Ghiasi et.al.", "abstract": "Many successful learning algorithms have been recently developed to represent graph-structured data. For example, Graph Neural Networks (GNNs) have achieved considerable successes in various tasks such as node classification, graph classification, and link prediction. However, these methods are highly dependent on the quality of the input graph structure. One used approach to alleviate this problem is to learn the graph structure instead of relying on a manually designed graph. In this paper, we introduce a new graph structure learning approach using multi-view learning, named MV-GSL (Multi-View Graph Structure Learning), in which we aggregate different graph structure learning methods using subspace merging on Grassmann manifold to improve the quality of the learned graph structures. Extensive experiments are performed to evaluate the effectiveness of the proposed method on two benchmark datasets, Cora and Citeseer. Our experiments show that the proposed method has promising performance compared to single and other combined graph structure learning methods.", "paper_url": "http://arxiv.org/abs/2204.05258v1", "pdf_url": "http://arxiv.org/pdf/2204.05258v1", "repo_url": null}, "2204.05141": {"publish_time": "2022-04-11", "title": "Learning Object-Centered Autotelic Behaviors with Graph Neural Networks", "author": "Ahmed Akakzia et.al.", "abstract": "Although humans live in an open-ended world and endlessly face new challenges, they do not have to learn from scratch each time they face the next one. Rather, they have access to a handful of previously learned skills, which they rapidly adapt to new situations. In artificial intelligence, autotelic agents, which are intrinsically motivated to represent and set their own goals, exhibit promising skill adaptation capabilities. However, these capabilities are highly constrained by their policy and goal space representations. In this paper, we propose to investigate the impact of these representations on the learning capabilities of autotelic agents. We study different implementations of autotelic agents using four types of Graph Neural Networks policy representations and two types of goal spaces, either geometric or predicate-based. We show that combining object-centered architectures that are expressive enough with semantic relational goals enables an efficient transfer between skills and promotes behavioral diversity. We also release our graph-based implementations to encourage further research in this direction.", "paper_url": "http://arxiv.org/abs/2204.05141v1", "pdf_url": "http://arxiv.org/pdf/2204.05141v1", "repo_url": "https://github.com/akakzia/rlgraph"}, "2204.04879": {"publish_time": "2022-04-11", "title": "How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision", "author": "Dongkwan Kim et.al.", "abstract": "Attention mechanism in graph neural networks is designed to assign larger weights to important neighbor nodes for better representation. However, what graph attention learns is not understood well, particularly when graphs are noisy. In this paper, we propose a self-supervised graph attention network (SuperGAT), an improved graph attention model for noisy graphs. Specifically, we exploit two attention forms compatible with a self-supervised task to predict edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. By encoding edges, SuperGAT learns more expressive attention in distinguishing mislinked neighbors. We find two graph characteristics influence the effectiveness of attention forms and self-supervision: homophily and average degree. Thus, our recipe provides guidance on which attention design to use when those two graph characteristics are known. Our experiment on 17 real-world datasets demonstrates that our recipe generalizes across 15 datasets of them, and our models designed by recipe show improved performance over baselines.", "paper_url": "http://arxiv.org/abs/2204.04879v1", "pdf_url": "http://arxiv.org/pdf/2204.04879v1", "repo_url": "https://github.com/dongkwan-kim/SuperGAT"}, "2204.04874": {"publish_time": "2022-04-11", "title": "Augmentation-Free Graph Contrastive Learning", "author": "Haonan Wang et.al.", "abstract": "Graph contrastive learning (GCL) is the most representative and prevalent self-supervised learning approach for graph-structured data. Despite its remarkable success, existing GCL methods highly rely on an augmentation scheme to learn the representations invariant across different augmentation views. In this work, we revisit such a convention in GCL through examining the effect of augmentation techniques on graph data via the lens of spectral theory. We found that graph augmentations preserve the low-frequency components and perturb the middle- and high-frequency components of the graph, which contributes to the success of GCL algorithms on homophilic graphs but hinders its application on heterophilic graphs, due to the high-frequency preference of heterophilic data. Motivated by this, we propose a novel, theoretically-principled, and augmentation-free GCL method, named AF-GCL, that (1) leverages the features aggregated by Graph Neural Network to construct the self-supervision signal instead of augmentations and therefore (2) is less sensitive to the graph homophily degree. Theoretically, We present the performance guarantee for AF-GCL as well as an analysis for understanding the efficacy of AF-GCL. Extensive experiments on 14 benchmark datasets with varying degrees of heterophily show that AF-GCL presents competitive or better performance on homophilic graphs and outperforms all existing state-of-the-art GCL methods on heterophilic graphs with significantly less computational overhead.", "paper_url": "http://arxiv.org/abs/2204.04874v1", "pdf_url": "http://arxiv.org/pdf/2204.04874v1", "repo_url": null}, "2204.04740": {"publish_time": "2022-04-10", "title": "Melting temperature prediction via first principles and deep learning", "author": "Qi-Jun Hong et.al.", "abstract": "Melting is a high temperature process that requires extensive sampling of configuration space, thus making melting temperature prediction computationally very expensive and challenging. Over the past few years, I have built two methods to address this challenge, one via direct density functional theory (DFT) molecular dynamics (MD) simulations and the other via deep learning graph neural networks. The DFT approach is based on statistical analysis of small-size solid-liquid coexistence MD simulations. It eliminates the risk of metastable superheated solid in the fast-heating method, while also significantly reducing the computer cost relative to the traditional large-scale coexistence method. Being both accurate and efficient (at the speed of several days per material), it is considered as one of the best methods for direct DFT melting temperature calculation. The deep learning method is based on graph neural networks that effectively handles permutation invariance in chemical formula, which drastically improves efficiency and reduces cost. At the speed of milliseconds per material, the model is extremely fast, while being moderately accurate, especially within the composition space expanded by the dataset. I have implemented both methods into automated computer code packages, making them publicly available and free to download. The DFT and deep learning methods are highly complementary to each other, and hence they can be potentially well integrated into a framework for melting temperature prediction. I demonstrated examples of applying the methods to materials design and discovery of high-melting-point materials.", "paper_url": "http://arxiv.org/abs/2204.04740v1", "pdf_url": "http://arxiv.org/pdf/2204.04740v1", "repo_url": null}, "2204.05518": {"publish_time": "2022-04-12", "title": "Trigger-GNN: A Trigger-Based Graph Neural Network for Nested Named Entity Recognition", "author": "Yuan Sui et.al.", "abstract": "Nested named entity recognition (NER) aims to identify the entity boundaries and recognize categories of the named entities in a complex hierarchical sentence. Some works have been done using character-level, word-level, or lexicon-level based models. However, such researches ignore the role of the complementary annotations. In this paper, we propose a trigger-based graph neural network (Trigger-GNN) to leverage the nested NER. It obtains the complementary annotation embeddings through entity trigger encoding and semantic matching, and tackle nested entity utilizing an efficient graph message passing architecture, aggregation-update mode. We posit that using entity triggers as external annotations can add in complementary supervision signals on the whole sentences. It helps the model to learn and generalize more efficiently and cost-effectively. Experiments show that the Trigger-GNN consistently outperforms the baselines on four public NER datasets, and it can effectively alleviate the nested NER.", "paper_url": "http://arxiv.org/abs/2204.05518v1", "pdf_url": "http://arxiv.org/pdf/2204.05518v1", "repo_url": null}, "2204.05493": {"publish_time": "2022-04-12", "title": "Physics-informed graph neural networks enhance scalability of variational nonequilibrium optimal control", "author": "Jiawei Yan et.al.", "abstract": "When a physical system is driven away from equilibrium, the statistical distribution of its dynamical trajectories informs many of its physical properties. Characterizing the nature of the distribution of dynamical observables, such as a current or entropy production rate, has become a central problem in nonequilibrium statistical mechanics. Asymptotically, for a broad class of observables, the distribution of a given observable satisfies a large deviation principle when the dynamics is Markovian, meaning that fluctuations can be characterized in the long-time limit by computing a scaled cumulant generating function. Calculating this function is not tractable analytically (nor often numerically) for complex, interacting systems, so the development of robust numerical techniques to carry out this computation is needed to probe the properties of nonequilibrium materials. Here, we describe an algorithm that recasts this task as an optimal control problem that can be solved variationally. We solve for optimal control forces using neural network ans\\\"atze that are tailored to the physical systems to which the forces are applied. We demonstrate that this approach leads to transferable and accurate solutions in two systems featuring large numbers of interacting particles.", "paper_url": "http://arxiv.org/abs/2204.05493v1", "pdf_url": "http://arxiv.org/pdf/2204.05493v1", "repo_url": null}, "2204.05351": {"publish_time": "2022-04-11", "title": "Graph Ordering Attention Networks", "author": "Michail Chatzianastasis et.al.", "abstract": "Graph Neural Networks (GNNs) have been successfully used in many problems involving graph-structured data, achieving state-of-the-art performance. GNNs typically employ a message-passing scheme, in which every node aggregates information from its neighbors using a permutation-invariant aggregation function. Standard well-examined choices such as the mean or sum aggregation functions have limited capabilities, as they are not able to capture interactions among neighbors. In this work, we formalize these interactions using an information-theoretic framework that notably includes synergistic information. Driven by this definition, we introduce the Graph Ordering Attention (GOAT) layer, a novel GNN component that captures interactions between nodes in a neighborhood. This is achieved by learning local node orderings via an attention mechanism and processing the ordered representations using a recurrent neural network aggregator. This design allows us to make use of a permutation-sensitive aggregator while maintaining the permutation-equivariance of the proposed GOAT layer. The GOAT model demonstrates its increased performance in modeling graph metrics that capture complex information, such as the betweenness centrality and the effective size of a node. In practical use-cases, its superior modeling capability is confirmed through its success in several real-world node classification benchmarks.", "paper_url": "http://arxiv.org/abs/2204.05351v1", "pdf_url": "http://arxiv.org/pdf/2204.05351v1", "repo_url": "https://github.com/michailchatzianastasis/goat"}, "2204.07077": {"publish_time": "2022-04-14", "title": "Galaxies and Halos on Graph Neural Networks: Deep Generative Modeling Scalar and Vector Quantities for Intrinsic Alignment", "author": "Yesukhei Jagvaral et.al.", "abstract": "In order to prepare for the upcoming wide-field cosmological surveys, large simulations of the Universe with realistic galaxy populations are required. In particular, the tendency of galaxies to naturally align towards overdensities, an effect called intrinsic alignments (IA), can be a major source of systematics in the weak lensing analysis. As the details of galaxy formation and evolution relevant to IA cannot be simulated in practice on such volumes, we propose as an alternative a Deep Generative Model. This model is trained on the IllustrisTNG-100 simulation and is capable of sampling the orientations of a population of galaxies so as to recover the correct alignments. In our approach, we model the cosmic web as a set of graphs, where the graphs are constructed for each halo, and galaxy orientations as a signal on those graphs. The generative model is implemented on a Generative Adversarial Network architecture and uses specifically designed Graph-Convolutional Networks sensitive to the relative 3D positions of the vertices. Given (sub)halo masses and tidal fields, the model is able to learn and predict scalar features such as galaxy and dark matter subhalo shapes; and more importantly, vector features such as the 3D orientation of the major axis of the ellipsoid and the complex 2D ellipticities. For correlations of 3D orientations the model is in good quantitative agreement with the measured values from the simulation, except for at very small and transition scales. For correlations of 2D ellipticities, the model is in good quantitative agreement with the measured values from the simulation on all scales. Additionally, the model is able to capture the dependence of IA on mass, morphological type and central/satellite type.", "paper_url": "http://arxiv.org/abs/2204.07077v1", "pdf_url": "http://arxiv.org/pdf/2204.07077v1", "repo_url": null}, "2204.07000": {"publish_time": "2022-04-14", "title": "Solving AC Power Flow with Graph Neural Networks under Realistic Constraints", "author": "Luis B\u00f6ttcher et.al.", "abstract": "In this paper we propose a graph neural network architecture solving the AC power flow problem under realistic constraints. While the energy transition is changing the energy industry to a digitalized and decentralized energy system, the challenges are increasingly shifting to the distribution grid level to integrate new loads and generation technologies. To ensure a save and resilient operation of distribution grids, AC power flow calculations are the means of choice to determine grid operating limits or analyze grid asset utilization in planning procedures. In our approach we demonstrate the development of a framework which makes use of graph neural networks to learn the physical constraints of the power flow. We present our model architecture on which we perform unsupervised training to learn a general solution of the AC power flow formulation that is independent of the specific topologies and supply tasks used for training. Finally, we demonstrate, validate and discuss our results on medium voltage benchmark grids.", "paper_url": "http://arxiv.org/abs/2204.07000v1", "pdf_url": "http://arxiv.org/pdf/2204.07000v1", "repo_url": null}, "2204.06963": {"publish_time": "2022-04-14", "title": "Finding MNEMON: Reviving Memories of Node Embeddings", "author": "Yun Shen et.al.", "abstract": "Previous security research efforts orbiting around graphs have been exclusively focusing on either (de-)anonymizing the graphs or understanding the security and privacy issues of graph neural networks. Little attention has been paid to understand the privacy risks of integrating the output from graph embedding models (e.g., node embeddings) with complex downstream machine learning pipelines. In this paper, we fill this gap and propose a novel model-agnostic graph recovery attack that exploits the implicit graph structural information preserved in the embeddings of graph nodes. We show that an adversary can recover edges with decent accuracy by only gaining access to the node embedding matrix of the original graph without interactions with the node embedding models. We demonstrate the effectiveness and applicability of our graph recovery attack through extensive experiments.", "paper_url": "http://arxiv.org/abs/2204.06963v1", "pdf_url": "http://arxiv.org/pdf/2204.06963v1", "repo_url": null}, "2204.06766": {"publish_time": "2022-04-14", "title": "Multimodal spatiotemporal graph neural networks for improved prediction of 30-day all-cause hospital readmission", "author": "Siyi Tang et.al.", "abstract": "Measures to predict 30-day readmission are considered an important quality factor for hospitals as accurate predictions can reduce the overall cost of care by identifying high risk patients before they are discharged. While recent deep learning-based studies have shown promising empirical results on readmission prediction, several limitations exist that may hinder widespread clinical utility, such as (a) only patients with certain conditions are considered, (b) existing approaches do not leverage data temporality, (c) individual admissions are assumed independent of each other, which is unrealistic, (d) prior studies are usually limited to single source of data and single center data. To address these limitations, we propose a multimodal, modality-agnostic spatiotemporal graph neural network (MM-STGNN) for prediction of 30-day all-cause hospital readmission that fuses multimodal in-patient longitudinal data. By training and evaluating our methods using longitudinal chest radiographs and electronic health records from two independent centers, we demonstrate that MM-STGNN achieves AUROC of 0.79 on both primary and external datasets. Furthermore, MM-STGNN significantly outperforms the current clinical reference standard, LACE+ score (AUROC=0.61), on the primary dataset. For subset populations of patients with heart and vascular disease, our model also outperforms baselines on predicting 30-day readmission (e.g., 3.7 point improvement in AUROC in patients with heart disease). Lastly, qualitative model interpretability analysis indicates that while patients' primary diagnoses were not explicitly used to train the model, node features crucial for model prediction directly reflect patients' primary diagnoses. Importantly, our MM-STGNN is agnostic to node feature modalities and could be utilized to integrate multimodal data for triaging patients in various downstream resource allocation tasks.", "paper_url": "http://arxiv.org/abs/2204.06766v1", "pdf_url": "http://arxiv.org/pdf/2204.06766v1", "repo_url": "https://github.com/tsy935/readmit-stgnn"}, "2204.07524": {"publish_time": "2022-04-15", "title": "Neural Structured Prediction for Inductive Node Classification", "author": "Meng Qu et.al.", "abstract": "This paper studies node classification in the inductive setting, i.e., aiming to learn a model on labeled training graphs and generalize it to infer node labels on unlabeled test graphs. This problem has been extensively studied with graph neural networks (GNNs) by learning effective node representations, as well as traditional structured prediction methods for modeling the structured output of node labels, e.g., conditional random fields (CRFs). In this paper, we present a new approach called the Structured Proxy Network (SPN), which combines the advantages of both worlds. SPN defines flexible potential functions of CRFs with GNNs. However, learning such a model is nontrivial as it involves optimizing a maximin game with high-cost inference. Inspired by the underlying connection between joint and marginal distributions defined by Markov networks, we propose to solve an approximate version of the optimization problem as a proxy, which yields a near-optimal solution, making learning more efficient. Extensive experiments on two settings show that our approach outperforms many competitive baselines.", "paper_url": "http://arxiv.org/abs/2204.07524v1", "pdf_url": "http://arxiv.org/pdf/2204.07524v1", "repo_url": "https://github.com/deepgraphlearning/spn"}, "2204.07360": {"publish_time": "2022-04-15", "title": "Spatio-Temporal-Frequency Graph Attention Convolutional Network for Aircraft Recognition Based on Heterogeneous Radar Network", "author": "Han Meng et.al.", "abstract": "This paper proposes a knowledge-and-data-driven graph neural network-based collaboration learning model for reliable aircraft recognition in a heterogeneous radar network. The aircraft recognizability analysis shows that: (1) the semantic feature of an aircraft is motion patterns driven by the kinetic characteristics, and (2) the grammatical features contained in the radar cross-section (RCS) signals present spatial-temporal-frequency (STF) diversity decided by both the electromagnetic radiation shape and motion pattern of the aircraft. Then a STF graph attention convolutional network (STFGACN) is developed to distill semantic features from the RCS signals received by the heterogeneous radar network. Extensive experiment results verify that the STFGACN outperforms the baseline methods in terms of detection accuracy, and ablation experiments are carried out to further show that the expansion of the information dimension can gain considerable benefits to perform robustly in the low signal-to-noise ratio region.", "paper_url": "http://arxiv.org/abs/2204.07360v1", "pdf_url": "http://arxiv.org/pdf/2204.07360v1", "repo_url": null}, "2204.07321": {"publish_time": "2022-04-15", "title": "Graph Pooling for Graph Neural Networks: Progress, Challenges, and Opportunities", "author": "Chuang Liu et.al.", "abstract": "Graph neural networks have emerged as a leading architecture for many graph-level tasks such as graph classification and graph generation with a notable improvement. Among these tasks, graph pooling is an essential component of graph neural network architectures for obtaining a holistic graph-level representation of the entire graph. Although a great variety of methods have been proposed in this promising and fast-developing research field, to the best of our knowledge, little effort has been made to systematically summarize these methods. To set the stage for the development of future works, in this paper, we attempt to fill this gap by providing a broad review of recent methods on graph pooling. Specifically, 1) we first propose a taxonomy of existing graph pooling methods and provide a mathematical summary for each category; 2) next, we provide an overview of the libraries related to graph pooling, including the commonly used datasets, model architectures for downstream tasks, and open-source implementations; 3) then, we further outline in brief the applications that incorporate the idea of graph pooling in a number of domains; 4) and finally, we discuss some critical challenges faced by the current studies and share our insights on potential directions for improving graph pooling in the future.", "paper_url": "http://arxiv.org/abs/2204.07321v1", "pdf_url": "http://arxiv.org/pdf/2204.07321v1", "repo_url": null}, "2204.08414": {"publish_time": "2022-04-18", "title": "STONet: A Neural-Operator-Driven Spatio-temporal Network", "author": "Haitao Lin et.al.", "abstract": "Graph-based spatio-temporal neural networks are effective to model the spatial dependency among discrete points sampled irregularly from unstructured grids, thanks to the great expressiveness of graph neural networks. However, these models are usually spatially-transductive -- only fitting the signals for discrete spatial nodes fed in models but unable to generalize to `unseen' spatial points with zero-shot. In comparison, for forecasting tasks on continuous space such as temperature prediction on the earth's surface, the \\textit{spatially-inductive} property allows the model to generalize to any point in the spatial domain, demonstrating models' ability to learn the underlying mechanisms or physics laws of the systems, rather than simply fit the signals. Besides, in temporal domains, \\textit{irregularly-sampled} time series, e.g. data with missing values, urge models to be temporally-continuous. Motivated by the two issues, we propose a spatio-temporal framework based on neural operators for PDEs, which learn the underlying mechanisms governing the dynamics of spatially-continuous physical quantities. Experiments show our model's improved performance on forecasting spatially-continuous physic quantities, and its superior generalization to unseen spatial points and ability to handle temporally-irregular data.", "paper_url": "http://arxiv.org/abs/2204.08414v1", "pdf_url": "http://arxiv.org/pdf/2204.08414v1", "repo_url": null}, "2204.08241": {"publish_time": "2022-04-18", "title": "GNN-encoder: Learning a Dual-encoder Architecture via Graph Neural Networks for Passage Retrieval", "author": "Jiduan Liu et.al.", "abstract": "Recently, retrieval models based on dense representations are dominant in passage retrieval tasks, due to their outstanding ability in terms of capturing semantics of input text compared to the traditional sparse vector space models. A common practice of dense retrieval models is to exploit a dual-encoder architecture to represent a query and a passage independently. Though efficient, such a structure loses interaction between the query-passage pair, resulting in inferior accuracy. To enhance the performance of dense retrieval models without loss of efficiency, we propose a GNN-encoder model in which query (passage) information is fused into passage (query) representations via graph neural networks that are constructed by queries and their top retrieved passages. By this means, we maintain a dual-encoder structure, and retain some interaction information between query-passage pairs in their representations, which enables us to achieve both efficiency and efficacy in passage retrieval. Evaluation results indicate that our method significantly outperforms the existing models on MSMARCO, Natural Questions and TriviaQA datasets, and achieves the new state-of-the-art on these datasets.", "paper_url": "http://arxiv.org/abs/2204.08241v1", "pdf_url": "http://arxiv.org/pdf/2204.08241v1", "repo_url": null}, "2204.08229": {"publish_time": "2022-04-18", "title": "Preference Enhanced Social Influence Modeling for Network-Aware Cascade Prediction", "author": "Likang Wu et.al.", "abstract": "Network-aware cascade size prediction aims to predict the final reposted number of user-generated information via modeling the propagation process in social networks. Estimating the user's reposting probability by social influence, namely state activation plays an important role in the information diffusion process. Therefore, Graph Neural Networks (GNN), which can simulate the information interaction between nodes, has been proved as an effective scheme to handle this prediction task. However, existing studies including GNN-based models usually neglect a vital factor of user's preference which influences the state activation deeply. To that end, we propose a novel framework to promote cascade size prediction by enhancing the user preference modeling according to three stages, i.e., preference topics generation, preference shift modeling, and social influence activation. Our end-to-end method makes the user activating process of information diffusion more adaptive and accurate. Extensive experiments on two large-scale real-world datasets have clearly demonstrated the effectiveness of our proposed model compared to state-of-the-art baselines.", "paper_url": "http://arxiv.org/abs/2204.08229v1", "pdf_url": "http://arxiv.org/pdf/2204.08229v1", "repo_url": null}, "2204.08194": {"publish_time": "2022-04-18", "title": "Phishing Fraud Detection on Ethereum using Graph Neural Network", "author": "Panpan Li et.al.", "abstract": "Blockchain has widespread applications in the financial field but has also attracted increasing cybercrimes. Recently, phishing fraud has emerged as a major threat to blockchain security, calling for the development of effective regulatory strategies. Nowadays network science has been widely used in modeling Ethereum transaction data, further introducing the network representation learning technology to analyze the transaction patterns. In this paper, we consider phishing detection as a graph classification task and propose an end-to-end Phishing Detection Graph Neural Network framework (PDGNN). Specifically, we first construct a lightweight Ethereum transaction network and extract transaction subgraphs of collected phishing accounts. Then we propose an end-to-end detection model based on Chebyshev-GCN to precisely distinguish between normal and phishing accounts. Extensive experiments on five Ethereum datasets demonstrate that our PDGNN significantly outperforms general phishing detection methods and scales well in large transaction networks.", "paper_url": "http://arxiv.org/abs/2204.08194v1", "pdf_url": "http://arxiv.org/pdf/2204.08194v1", "repo_url": null}, "2204.08150": {"publish_time": "2022-04-18", "title": "Characterizing and Understanding Distributed GNN Training on GPUs", "author": "Haiyang Lin et.al.", "abstract": "Graph neural network (GNN) has been demonstrated to be a powerful model in many domains for its effectiveness in learning over graphs. To scale GNN training for large graphs, a widely adopted approach is distributed training which accelerates training using multiple computing nodes. Maximizing the performance is essential, but the execution of distributed GNN training remains preliminarily understood. In this work, we provide an in-depth analysis of distributed GNN training on GPUs, revealing several significant observations and providing useful guidelines for both software optimization and hardware optimization.", "paper_url": "http://arxiv.org/abs/2204.08150v1", "pdf_url": "http://arxiv.org/pdf/2204.08150v1", "repo_url": null}, "2204.08870": {"publish_time": "2022-04-19", "title": "OpenGlue: Open Source Graph Neural Net Based Pipeline for Image Matching", "author": "Ostap Viniavskyi et.al.", "abstract": "We present OpenGlue: a free open-source framework for image matching, that uses a Graph Neural Network-based matcher inspired by SuperGlue \\cite{sarlin20superglue}. We show that including additional geometrical information, such as local feature scale, orientation, and affine geometry, when available (e.g. for SIFT features), significantly improves the performance of the OpenGlue matcher. We study the influence of the various attention mechanisms on accuracy and speed. We also present a simple architectural improvement by combining local descriptors with context-aware descriptors. The code and pretrained OpenGlue models for the different local features are publicly available.", "paper_url": "http://arxiv.org/abs/2204.08870v1", "pdf_url": "http://arxiv.org/pdf/2204.08870v1", "repo_url": "https://github.com/ucuapps/openglue"}, "2204.08807": {"publish_time": "2022-04-19", "title": "Multi-level Cross-view Contrastive Learning for Knowledge-aware Recommender System", "author": "Ding Zou et.al.", "abstract": "Knowledge graph (KG) plays an increasingly important role in recommender systems. Recently, graph neural networks (GNNs) based model has gradually become the theme of knowledge-aware recommendation (KGR). However, there is a natural deficiency for GNN-based KGR models, that is, the sparse supervised signal problem, which may make their actual performance drop to some extent. Inspired by the recent success of contrastive learning in mining supervised signals from data itself, in this paper, we focus on exploring the contrastive learning in KG-aware recommendation and propose a novel multi-level cross-view contrastive learning mechanism, named MCCLK. Different from traditional contrastive learning methods which generate two graph views by uniform data augmentation schemes such as corruption or dropping, we comprehensively consider three different graph views for KG-aware recommendation, including global-level structural view, local-level collaborative and semantic views. Specifically, we consider the user-item graph as a collaborative view, the item-entity graph as a semantic view, and the user-item-entity graph as a structural view. MCCLK hence performs contrastive learning across three views on both local and global levels, mining comprehensive graph feature and structure information in a self-supervised manner. Besides, in semantic view, a k-Nearest-Neighbor (kNN) item-item semantic graph construction module is proposed, to capture the important item-item semantic relation which is usually ignored by previous work. Extensive experiments conducted on three benchmark datasets show the superior performance of our proposed method over the state-of-the-arts. The implementations are available at: https://github.com/CCIIPLab/MCCLK.", "paper_url": "http://arxiv.org/abs/2204.08807v1", "pdf_url": "http://arxiv.org/pdf/2204.08807v1", "repo_url": "https://github.com/cciiplab/mcclk"}, "2204.08621": {"publish_time": "2022-04-19", "title": "Proximal Implicit ODE Solvers for Accelerating Learning Neural ODEs", "author": "Justin Baker et.al.", "abstract": "Learning neural ODEs often requires solving very stiff ODE systems, primarily using explicit adaptive step size ODE solvers. These solvers are computationally expensive, requiring the use of tiny step sizes for numerical stability and accuracy guarantees. This paper considers learning neural ODEs using implicit ODE solvers of different orders leveraging proximal operators. The proximal implicit solver consists of inner-outer iterations: the inner iterations approximate each implicit update step using a fast optimization algorithm, and the outer iterations solve the ODE system over time. The proximal implicit ODE solver guarantees superiority over explicit solvers in numerical stability and computational efficiency. We validate the advantages of proximal implicit solvers over existing popular neural ODE solvers on various challenging benchmark tasks, including learning continuous-depth graph neural networks and continuous normalizing flows.", "paper_url": "http://arxiv.org/abs/2204.08621v1", "pdf_url": "http://arxiv.org/pdf/2204.08621v1", "repo_url": null}, "2204.08570": {"publish_time": "2022-04-18", "title": "A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability", "author": "Enyan Dai et.al.", "abstract": "Graph Neural Networks (GNNs) have made rapid developments in the recent years. Due to their great ability in modeling graph-structured data, GNNs are vastly used in various applications, including high-stakes scenarios such as financial analysis, traffic predictions, and drug discovery. Despite their great potential in benefiting humans in the real world, recent study shows that GNNs can leak private information, are vulnerable to adversarial attacks, can inherit and magnify societal bias from training data and lack interpretability, which have risk of causing unintentional harm to the users and society. For example, existing works demonstrate that attackers can fool the GNNs to give the outcome they desire with unnoticeable perturbation on training graph. GNNs trained on social networks may embed the discrimination in their decision process, strengthening the undesirable societal bias. Consequently, trustworthy GNNs in various aspects are emerging to prevent the harm from GNN models and increase the users' trust in GNNs. In this paper, we give a comprehensive survey of GNNs in the computational aspects of privacy, robustness, fairness, and explainability. For each aspect, we give the taxonomy of the related methods and formulate the general frameworks for the multiple categories of trustworthy GNNs. We also discuss the future research directions of each aspect and connections between these aspects to help achieve trustworthiness.", "paper_url": "http://arxiv.org/abs/2204.08570v1", "pdf_url": "http://arxiv.org/pdf/2204.08570v1", "repo_url": null}, "2204.08557": {"publish_time": "2022-04-18", "title": "PIDGeuN: Graph Neural Network-Enabled Transient Dynamics Prediction of Networked Microgrids Through Full-Field Measurement", "author": "Yin Yu et.al.", "abstract": "A Physics-Informed Dynamic Graph Neural Network (PIDGeuN) is presented to accurately, efficiently and robustly predict the nonlinear transient dynamics of microgrids in the presence of disturbances. The graph-based architecture of PIDGeuN provides a natural representation of the microgrid topology. Using only the state information that is practically measurable, PIDGeuN employs a time delay embedding formulation to fully reproduce the system dynamics, avoiding the dependency of conventional methods on internal dynamic states such as controllers. Based on a judiciously designed message passing mechanism, the PIDGeuN incorporates two physics-informed techniques to improve its prediction performance, including a physics-data-infusion approach to determining the inter-dependencies between buses, and a loss term to respect the known physical law of the power system, i.e., the Kirchhoff's law, to ensure the feasibility of the model prediction. Extensive tests show that PIDGeuN can provide accurate and robust prediction of transient dynamics for nonlinear microgrids over a long-term time period. Therefore, the PIDGeuN offers a potent tool for the modeling of large scale networked microgrids (NMs), with potential applications to predictive or preventive control in real time applications for the stable and resilient operations of NMs.", "paper_url": "http://arxiv.org/abs/2204.08557v1", "pdf_url": "http://arxiv.org/pdf/2204.08557v1", "repo_url": null}, "2204.09486": {"publish_time": "2022-04-20", "title": "Graph neural networks and attention-based CNN-LSTM for protein classification", "author": "Zhuangwei Shi et.al.", "abstract": "This paper focuses on three critical problems on protein classification. Firstly, Carbohydrate-active enzyme (CAZyme) classification can help people to understand the properties of enzymes. However, one CAZyme may belong to several classes. This leads to Multi-label CAZyme classification. Secondly, to capture information from the secondary structure of protein, protein classification is modeled as graph classification problem. Thirdly, compound-protein interactions prediction employs graph learning for compound with sequential embedding for protein. This can be seen as classification task for compound-protein pairs. This paper proposes three models for protein classification. Firstly, this paper proposes a Multi-label CAZyme classification model using CNN-LSTM with Attention mechanism. Secondly, this paper proposes a variational graph autoencoder based subspace learning model for protein graph classification. Thirdly, this paper proposes graph isomorphism networks (GIN) and Attention-based CNN-LSTM for compound-protein interactions prediction, as well as comparing GIN with graph convolution networks (GCN) and graph attention networks (GAT) in this task. The proposed models are effective for protein classification. Source code and data are available at https://github.com/zshicode/GNN-AttCL-protein. Besides, this repository collects and collates the benchmark datasets with respect to above problems, including CAZyme classification, enzyme protein graph classification, compound-protein interactions prediction, drug-target affinities prediction and drug-drug interactions prediction. Hence, the usage for evaluation by benchmark datasets can be more conveniently.", "paper_url": "http://arxiv.org/abs/2204.09486v1", "pdf_url": "http://arxiv.org/pdf/2204.09486v1", "repo_url": "https://github.com/zshicode/gnn-attcl-protein"}, "2204.09455": {"publish_time": "2022-04-20", "title": "Simplicial Attention Networks", "author": "Christopher Wei Jin Goh et.al.", "abstract": "Graph representation learning methods have mostly been limited to the modelling of node-wise interactions. Recently, there has been an increased interest in understanding how higher-order structures can be utilised to further enhance the learning abilities of graph neural networks (GNNs) in combinatorial spaces. Simplicial Neural Networks (SNNs) naturally model these interactions by performing message passing on simplicial complexes, higher-dimensional generalisations of graphs. Nonetheless, the computations performed by most existent SNNs are strictly tied to the combinatorial structure of the complex. Leveraging the success of attention mechanisms in structured domains, we propose Simplicial Attention Networks (SAT), a new type of simplicial network that dynamically weighs the interactions between neighbouring simplicies and can readily adapt to novel structures. Additionally, we propose a signed attention mechanism that makes SAT orientation equivariant, a desirable property for models operating on (co)chain complexes. We demonstrate that SAT outperforms existent convolutional SNNs and GNNs in two image and trajectory classification tasks.", "paper_url": "http://arxiv.org/abs/2204.09455v1", "pdf_url": "http://arxiv.org/pdf/2204.09455v1", "repo_url": null}, "2204.09368": {"publish_time": "2022-04-20", "title": "BugListener: Identifying and Synthesizing Bug Reports from Collaborative Live Chats", "author": "Lin Shi et.al.", "abstract": "In community-based software development, developers frequently rely on live-chatting to discuss emergent bugs/errors they encounter in daily development tasks. However, it remains a challenging task to accurately record such knowledge due to the noisy nature of interleaved dialogs in live chat data. In this paper, we first formulate the task of identifying and synthesizing bug reports from community live chats, and propose a novel approach, named BugListener, to address the challenges. Specifically, BugListener automates three sub-tasks: 1) Disentangle the dialogs from massive chat logs by using a Feed-Forward neural network; 2) Identify the bug-report dialogs from separated dialogs by modeling the original dialog to the graph-structured dialog and leveraging the graph neural network to learn the contextual information; 3) Synthesize the bug reports by utilizing the TextCNN model and Transfer Learning network to classify the sentences into three groups: observed behaviors (OB), expected behaviors (EB), and steps to reproduce the bug (SR). BugListener is evaluated on six open source projects. The results show that: for bug report identification, BugListener achieves the average F1 of 74.21%, improving the best baseline by 10.37%; and for bug report synthesis task, BugListener could classify the OB, EB, and SR sentences with the F1 of 67.37%, 87.14%, and 65.03%, improving the best baselines by 7.21%, 7.38%, 5.30%, respectively. A human evaluation also confirms the effectiveness of BugListener in generating relevant and accurate bug reports. These demonstrate the significant potential of applying BugListener in community-based software development, for promoting bug discovery and quality improvement.", "paper_url": "http://arxiv.org/abs/2204.09368v1", "pdf_url": "http://arxiv.org/pdf/2204.09368v1", "repo_url": null}, "2204.09230": {"publish_time": "2022-04-20", "title": "Dark Spot Detection from SAR Images Based on Superpixel Deeper Graph Convolutional Network", "author": "Xiaojian Liu et.al.", "abstract": "Synthetic Aperture Radar (SAR) is the main instrument utilized for the detection of oil slicks on the ocean surface. In SAR images, some areas affected by ocean phenomena, such as rain cells, upwellings, and internal waves, or discharge from oil spills appear as dark spots on images. Dark spot detection is the first step in the detection of oil spills, which then become oil slick candidates. The accuracy of dark spot segmentation ultimately affects the accuracy of oil slick identification. Although some advanced deep learning methods that use pixels as processing units perform well in remote sensing image semantic segmentation, detecting some dark spots with weak boundaries from noisy SAR images remains a huge challenge. We propose a dark spot detection method based on superpixels deeper graph convolutional networks (SGDCN) in this paper, which takes the superpixels as the processing units and extracts features for each superpixel. The features calculated from superpixel regions are more robust than those from fixed pixel neighborhoods. To reduce the difficulty of learning tasks, we discard irrelevant features and obtain an optimal subset of features. After superpixel segmentation, the images are transformed into graphs with superpixels as nodes, which are fed into the deeper graph convolutional neural network for node classification. This graph neural network uses a differentiable aggregation function to aggregate the features of nodes and neighbors to form more advanced features. It is the first time using it for dark spot detection. To validate our method, we mark all dark spots on six SAR images covering the Baltic Sea and construct a dark spots detection dataset, which has been made publicly available (https://drive.google.com/drive/folders/12UavrntkDSPrItISQ8iGefXn2gIZHxJ6?usp=sharing). The experimental results demonstrate that our proposed SGDCN is robust and effective.", "paper_url": "http://arxiv.org/abs/2204.09230v1", "pdf_url": "http://arxiv.org/pdf/2204.09230v1", "repo_url": null}, "2204.09410": {"publish_time": "2022-04-19", "title": "Generating 3D Molecules for Target Protein Binding", "author": "Meng Liu et.al.", "abstract": "A fundamental problem in drug discovery is to design molecules that bind to specific proteins. To tackle this problem using machine learning methods, here we propose a novel and effective framework, known as GraphBP, to generate 3D molecules that bind to given proteins by placing atoms of specific types and locations to the given binding site one by one. In particular, at each step, we first employ a 3D graph neural network to obtain geometry-aware and chemically informative representations from the intermediate contextual information. Such context includes the given binding site and atoms placed in the previous steps. Second, to preserve the desirable equivariance property, we select a local reference atom according to the designed auxiliary classifiers and then construct a local spherical coordinate system. Finally, to place a new atom, we generate its atom type and relative location w.r.t. the constructed local coordinate system via a flow model. We also consider generating the variables of interest sequentially to capture the underlying dependencies among them. Experiments demonstrate that our GraphBP is effective to generate 3D molecules with binding ability to target protein binding sites. Our implementation is available at https://github.com/divelab/GraphBP.", "paper_url": "http://arxiv.org/abs/2204.09410v1", "pdf_url": "http://arxiv.org/pdf/2204.09410v1", "repo_url": "https://github.com/divelab/graphbp"}, "2204.10277": {"publish_time": "2022-04-21", "title": "Deep learning techniques for energy clustering in the CMS ECAL", "author": "Davide Valsecchi et.al.", "abstract": "The reconstruction of electrons and photons in CMS depends on topological clustering of the energy deposited by an incident particle in different crystals of the electromagnetic calorimeter (ECAL). These clusters are formed by aggregating neighbouring crystals according to the expected topology of an electromagnetic shower in the ECAL. The presence of upstream material (beampipe, tracker and support structures) causes electrons and photons to start showering before reaching the calorimeter. This effect, combined with the 3.8T CMS magnetic field, leads to energy being spread in several clusters around the primary one. It is essential to recover the energy contained in these satellite clusters in order to achieve the best possible energy resolution for physics analyses. Historically satellite clusters have been associated to the primary cluster using a purely topological algorithm which does not attempt to remove spurious energy deposits from additional pileup interactions (PU). The performance of this algorithm is expected to degrade during LHC Run 3 (2022+) because of the larger average PU levels and the increasing levels of noise due to the ageing of the ECAL detector. New methods are being investigated that exploit state-of-the-art deep learning architectures like Graph Neural Networks (GNN) and self-attention algorithms. These more sophisticated models improve the energy collection and are more resilient to PU and noise, helping to preserve the electron and photon energy resolution achieved during LHC Runs 1 and 2. This work will cover the challenges of training the models as well the opportunity that this new approach offers to unify the ECAL energy measurement with the particle identification steps used in the global CMS photon and electron reconstruction.", "paper_url": "http://arxiv.org/abs/2204.10277v1", "pdf_url": "http://arxiv.org/pdf/2204.10277v1", "repo_url": null}, "2204.10085": {"publish_time": "2022-04-21", "title": "Forgetting Prevention for Cross-regional Fraud Detection with Heterogeneous Trade Graph", "author": "Yujie Li et.al.", "abstract": "With the booming growth of e-commerce, detecting financial fraud has become an urgent task to avoid transaction risks. Despite the successful application of graph neural networks in fraud detection, the existing solutions are only suitable for a narrow scope due to the limitation of data collection. Especially when expanding a business into new territory, e.g., new cities or new countries, developing a totally new model will bring the cost issue and result in forgetting previous knowledge. Besides, most existing GNNs-based solutions concentrate on either homogeneous graphs or decomposing heterogeneous interactions into several homogeneous connections for convenience. To this end, this study proposes a novel solution based on heterogeneous trade graphs, namely HTG-CFD, to prevent knowledge forgetting of cross-regional fraud detection. In particular, the heterogeneous trade graph (HTG) is constructed from initial transaction records to explore the complex semantics among different types of entities and relationships. Extensive experiments demonstrate that the proposed HTG-CFD not only promotes the performance in cross-regional scenarios but also significantly contributes to the single-regional fraud detection. The code of the paper can be accessed at https://github.com/YujieLi42/HTG-CFD.", "paper_url": "http://arxiv.org/abs/2204.10085v1", "pdf_url": "http://arxiv.org/pdf/2204.10085v1", "repo_url": "https://github.com/yujieli42/htg-cfd"}, "2204.10072": {"publish_time": "2022-04-21", "title": "Detecting Topology Attacks against Graph Neural Networks", "author": "Senrong Xu et.al.", "abstract": "Graph neural networks (GNNs) have been widely used in many real applications, and recent studies have revealed their vulnerabilities against topology attacks. To address this issue, existing efforts have mainly been dedicated to improving the robustness of GNNs, while little attention has been paid to the detection of such attacks. In this work, we study the victim node detection problem under topology attacks against GNNs. Our approach is built upon the key observation rooted in the intrinsic message passing nature of GNNs. That is, the neighborhood of a victim node tends to have two competing group forces, pushing the node classification results towards the original label and the targeted label, respectively. Based on this observation, we propose to detect victim nodes by deliberately designing an effective measurement of the neighborhood variance for each node. Extensive experimental results on four real-world datasets and five existing topology attacks show the effectiveness and efficiency of the proposed detection approach.", "paper_url": "http://arxiv.org/abs/2204.10072v1", "pdf_url": "http://arxiv.org/pdf/2204.10072v1", "repo_url": null}, "2204.10037": {"publish_time": "2022-04-21", "title": "DropMessage: Unifying Random Dropping for Graph Neural Networks", "author": "Taoran Fang et.al.", "abstract": "Graph Neural Networks (GNNs) are powerful tools for graph representation learning. Despite their rapid development, GNNs also faces some challenges, such as over-fitting, over-smoothing, and non-robustness. Previous works indicate that these problems can be alleviated by random dropping methods, which integrate noises into models by randomly masking parts of the input. However, some open-ended problems of random dropping on GNNs remain to solve. First, it is challenging to find a universal method that are suitable for all cases considering the divergence of different datasets and models. Second, random noises introduced to GNNs cause the incomplete coverage of parameters and unstable training process. In this paper, we propose a novel random dropping method called DropMessage, which performs dropping operations directly on the message matrix and can be applied to any message-passing GNNs. Furthermore, we elaborate the superiority of DropMessage: it stabilizes the training process by reducing sample variance; it keeps information diversity from the perspective of information theory, which makes it a theoretical upper bound of other methods. Also, we unify existing random dropping methods into our framework and analyze their effects on GNNs. To evaluate our proposed method, we conduct experiments that aims for multiple tasks on five public datasets and two industrial datasets with various backbone models. The experimental results show that DropMessage has both advantages of effectiveness and generalization.", "paper_url": "http://arxiv.org/abs/2204.10037v1", "pdf_url": "http://arxiv.org/pdf/2204.10037v1", "repo_url": null}, "2204.10614": {"publish_time": "2022-04-22", "title": "Modelling graph dynamics in fraud detection with \"Attention\"", "author": "Susie Xi Rao et.al.", "abstract": "At online retail platforms, detecting fraudulent accounts and transactions is crucial to improve customer experience, minimize loss, and avoid unauthorized transactions. Despite the variety of different models for deep learning on graphs, few approaches have been proposed for dealing with graphs that are both heterogeneous and dynamic. In this paper, we propose DyHGN (Dynamic Heterogeneous Graph Neural Network) and its variants to capture both temporal and heterogeneous information. We first construct dynamic heterogeneous graphs from registration and transaction data from eBay. Then, we build models with diachronic entity embedding and heterogeneous graph transformer. We also use model explainability techniques to understand the behaviors of DyHGN-* models. Our findings reveal that modelling graph dynamics with heterogeneous inputs need to be conducted with \"attention\" depending on the data structure, distribution, and computation cost.", "paper_url": "http://arxiv.org/abs/2204.10614v1", "pdf_url": "http://arxiv.org/pdf/2204.10614v1", "repo_url": "https://github.com/ds3lab/dyhgn"}, "2204.10390": {"publish_time": "2022-04-21", "title": "SoftEdge: Regularizing Graph Classification with Random Soft Edges", "author": "Hongyu Guo et.al.", "abstract": "Graph data augmentation plays a vital role in regularizing Graph Neural Networks (GNNs), which leverage information exchange along edges in graphs, in the form of message passing, for learning. Due to their effectiveness, simple edge and node manipulations (e.g., addition and deletion) have been widely used in graph augmentation. In this paper, we identify a limitation in such a common augmentation technique. That is, simple edge and node manipulations can create graphs with an identical structure or indistinguishable structures to message passing GNNs but of conflict labels, leading to the sample collision issue and thus the degradation of model performance. To address this problem, we propose SoftEdge, which assigns random weights to a portion of the edges of a given graph to construct dynamic neighborhoods over the graph. We prove that SoftEdge creates collision-free augmented graphs. We also show that this simple method obtains superior accuracy to popular node and edge manipulation approaches and notable resilience to the accuracy degradation with the GNN depth.", "paper_url": "http://arxiv.org/abs/2204.10390v1", "pdf_url": "http://arxiv.org/pdf/2204.10390v1", "repo_url": null}, "2204.10348": {"publish_time": "2022-04-21", "title": "Simulate Time-integrated Coarse-grained Molecular Dynamics with Geometric Machine Learning", "author": "Xiang Fu et.al.", "abstract": "Molecular dynamics (MD) simulation is the workhorse of various scientific domains but is limited by high computational cost. Learning-based force fields have made major progress in accelerating ab-initio MD simulation but are still not fast enough for many real-world applications that require long-time MD simulation. In this paper, we adopt a different machine learning approach where we coarse-grain a physical system using graph clustering, and model the system evolution with a very large time-integration step using graph neural networks. A novel score-based GNN refinement module resolves the long-standing challenge of long-time simulation instability. Despite only trained with short MD trajectory data, our learned simulator can generalize to unseen novel systems and simulate for much longer than the training trajectories. Properties requiring 10-100 ns level long-time dynamics can be accurately recovered at several-orders-of-magnitude higher speed than classical force fields. We demonstrate the effectiveness of our method on two realistic complex systems: (1) single-chain coarse-grained polymers in implicit solvent; (2) multi-component Li-ion polymer electrolyte systems.", "paper_url": "http://arxiv.org/abs/2204.10348v1", "pdf_url": "http://arxiv.org/pdf/2204.10348v1", "repo_url": null}, "2204.11700": {"publish_time": "2022-04-25", "title": "ClusterGNN: Cluster-based Coarse-to-Fine Graph Neural Network for Efficient Feature Matching", "author": "Yan Shi et.al.", "abstract": "Graph Neural Networks (GNNs) with attention have been successfully applied for learning visual feature matching. However, current methods learn with complete graphs, resulting in a quadratic complexity in the number of features. Motivated by a prior observation that self- and cross- attention matrices converge to a sparse representation, we propose ClusterGNN, an attentional GNN architecture which operates on clusters for learning the feature matching task. Using a progressive clustering module we adaptively divide keypoints into different subgraphs to reduce redundant connectivity, and employ a coarse-to-fine paradigm for mitigating miss-classification within images. Our approach yields a 59.7% reduction in runtime and 58.4% reduction in memory consumption for dense detection, compared to current state-of-the-art GNN-based matching, while achieving a competitive performance on various computer vision tasks.", "paper_url": "http://arxiv.org/abs/2204.11700v1", "pdf_url": "http://arxiv.org/pdf/2204.11700v1", "repo_url": null}, "2204.11673": {"publish_time": "2022-04-25", "title": "Incorporating Explicit Knowledge in Pre-trained Language Models for Passage Re-ranking", "author": "Qian Dong et.al.", "abstract": "Passage re-ranking is to obtain a permutation over the candidate passage set from retrieval stage. Re-rankers have been boomed by Pre-trained Language Models (PLMs) due to their overwhelming advantages in natural language understanding. However, existing PLM based re-rankers may easily suffer from vocabulary mismatch and lack of domain specific knowledge. To alleviate these problems, explicit knowledge contained in knowledge graph is carefully introduced in our work. Specifically, we employ the existing knowledge graph which is incomplete and noisy, and first apply it in passage re-ranking task. To leverage a reliable knowledge, we propose a novel knowledge graph distillation method and obtain a knowledge meta graph as the bridge between query and passage. To align both kinds of embedding in the latent space, we employ PLM as text encoder and graph neural network over knowledge meta graph as knowledge encoder. Besides, a novel knowledge injector is designed for the dynamic interaction between text and knowledge encoder. Experimental results demonstrate the effectiveness of our method especially in queries requiring in-depth domain knowledge.", "paper_url": "http://arxiv.org/abs/2204.11673v1", "pdf_url": "http://arxiv.org/pdf/2204.11673v1", "repo_url": null}, "2204.11431": {"publish_time": "2022-04-25", "title": "Hardware Trojan Detection using Graph Neural Networks", "author": "Rozhin Yasaei et.al.", "abstract": "The globalization of the Integrated Circuit (IC) supply chain has moved most of the design, fabrication, and testing process from a single trusted entity to various untrusted third-party entities around the world. The risk of using untrusted third-Party Intellectual Property (3PIP) is the possibility for adversaries to insert malicious modifications known as Hardware Trojans (HTs). These HTs can compromise the integrity, deteriorate the performance, and deny the functionality of the intended design. Various HT detection methods have been proposed in the literature; however, many fall short due to their reliance on a golden reference circuit, a limited detection scope, the need for manual code review, or the inability to scale with large modern designs. We propose a novel golden reference-free HT detection method for both Register Transfer Level (RTL) and gate-level netlists by leveraging Graph Neural Networks (GNNs) to learn the behavior of the circuit through a Data Flow Graph (DFG) representation of the hardware design. We evaluate our model on a custom dataset by expanding the Trusthub HT benchmarks \\cite{trusthub1}. The results demonstrate that our approach detects unknown HTs with 97% recall (true positive rate) very fast in 21.1ms for RTL and 84% recall in 13.42s for Gate-Level Netlist.", "paper_url": "http://arxiv.org/abs/2204.11431v1", "pdf_url": "http://arxiv.org/pdf/2204.11431v1", "repo_url": null}, "2204.11350": {"publish_time": "2022-04-24", "title": "Collaborative Auto-Curricula Multi-Agent Reinforcement Learning with Graph Neural Network Communication Layer for Open-ended Wildfire-Management Resource Distribution", "author": "Philipp Dominic Siedler et.al.", "abstract": "Most real-world domains can be formulated as multi-agent (MA) systems. Intentionality sharing agents can solve more complex tasks by collaborating, possibly in less time. True cooperative actions are beneficial for egoistic and collective reasons. However, teaching individual agents to sacrifice egoistic benefits for a better collective performance seems challenging. We build on a recently proposed Multi-Agent Reinforcement Learning (MARL) mechanism with a Graph Neural Network (GNN) communication layer. Rarely chosen communication actions were marginally beneficial. Here we propose a MARL system in which agents can help collaborators perform better while risking low individual performance. We conduct our study in the context of resource distribution for wildfire management. Communicating environmental features and partially observable fire occurrence help the agent collective to pre-emptively distribute resources. Furthermore, we introduce a procedural training environment accommodating auto-curricula and open-endedness towards better generalizability. Our MA communication proposal outperforms a Greedy Heuristic Baseline and a Single-Agent (SA) setup. We further demonstrate how auto-curricula and openendedness improves generalizability of our MA proposal.", "paper_url": "http://arxiv.org/abs/2204.11350v1", "pdf_url": "http://arxiv.org/pdf/2204.11350v1", "repo_url": null}, "2204.11224": {"publish_time": "2022-04-24", "title": "Optimizing Task Placement and Online Scheduling for Distributed GNN Training Acceleration", "author": "Ziyue Luo et.al.", "abstract": "Training Graph Neural Networks (GNN) on large graphs is resource-intensive and time-consuming, mainly due to the large graph data that cannot be fit into the memory of a single machine, but have to be fetched from distributed graph storage and processed on the go. Unlike distributed deep neural network (DNN) training, the bottleneck in distributed GNN training lies largely in large graph data transmission for constructing mini-batches of training samples. Existing solutions often advocate data-computation colocation, and do not work well with limited resources where the colocation is infeasible. The potentials of strategical task placement and optimal scheduling of data transmission and task execution have not been well explored. This paper designs an efficient algorithm framework for task placement and execution scheduling of distributed GNN training, to better resource utilization, improve execution pipelining, and expediting training completion. Our framework consists of two modules: (i) an online scheduling algorithm that schedules the execution of training tasks, and the data transmission plan; and (ii) an exploratory task placement scheme that decides the placement of each training task. We conduct thorough theoretical analysis, testbed experiments and simulation studies, and observe up to 67% training speed-up with our algorithm as compared to representative baselines.", "paper_url": "http://arxiv.org/abs/2204.11224v1", "pdf_url": "http://arxiv.org/pdf/2204.11224v1", "repo_url": null}, "2204.12326": {"publish_time": "2022-04-26", "title": "Investigating Accuracy-Novelty Performance for Graph-based Collaborative Filtering", "author": "Minghao Zhao et.al.", "abstract": "Recent years have witnessed the great accuracy performance of graph-based Collaborative Filtering (CF) models for recommender systems. By taking the user-item interaction behavior as a graph, these graph-based CF models borrow the success of Graph Neural Networks (GNN), and iteratively perform neighborhood aggregation to propagate the collaborative signals. While conventional CF models are known for facing the challenges of the popularity bias that favors popular items, one may wonder \"Whether the existing graph-based CF models alleviate or exacerbate popularity bias of recommender systems?\" To answer this question, we first investigate the two-fold performances w.r.t. accuracy and novelty for existing graph-based CF methods. The empirical results show that symmetric neighborhood aggregation adopted by most existing graph-based CF models exacerbate the popularity bias and this phenomenon becomes more serious as the depth of graph propagation increases. Further, we theoretically analyze the cause of popularity bias for graph-based CF. Then, we propose a simple yet effective plugin, namely r-AdjNorm, to achieve an accuracy-novelty trade-off by controlling the normalization strength in the neighborhood aggregation process. Meanwhile, r-AdjNorm can be smoothly applied to the existing graph-based CF backbones without additional computation. Finally, experimental results on three benchmark datasets show that our proposed method can improve novelty without sacrificing accuracy under various graph-based CF backbones.", "paper_url": "http://arxiv.org/abs/2204.12326v2", "pdf_url": "http://arxiv.org/pdf/2204.12326v2", "repo_url": "https://github.com/fuxiailab/r-adjnorm"}, "2204.12270": {"publish_time": "2022-04-26", "title": "Graph Neural Networks for Microbial Genome Recovery", "author": "Andre Lamurias et.al.", "abstract": "Microbes have a profound impact on our health and environment, but our understanding of the diversity and function of microbial communities is severely limited. Through DNA sequencing of microbial communities (metagenomics), DNA fragments (reads) of the individual microbes can be obtained, which through assembly graphs can be combined into long contiguous DNA sequences (contigs). Given the complexity of microbial communities, single contig microbial genomes are rarely obtained. Instead, contigs are eventually clustered into bins, with each bin ideally making up a full genome. This process is referred to as metagenomic binning.   Current state-of-the-art techniques for metagenomic binning rely only on the local features for the individual contigs. These techniques therefore fail to exploit the similarities between contigs as encoded by the assembly graph, in which the contigs are organized. In this paper, we propose to use Graph Neural Networks (GNNs) to leverage the assembly graph when learning contig representations for metagenomic binning. Our method, VaeG-Bin, combines variational autoencoders for learning latent representations of the individual contigs, with GNNs for refining these representations by taking into account the neighborhood structure of the contigs in the assembly graph. We explore several types of GNNs and demonstrate that VaeG-Bin recovers more high-quality genomes than other state-of-the-art binners on both simulated and real-world datasets.", "paper_url": "http://arxiv.org/abs/2204.12270v1", "pdf_url": "http://arxiv.org/pdf/2204.12270v1", "repo_url": null}, "2204.12231": {"publish_time": "2022-04-26", "title": "IRC-safe Graph Autoencoder for an unsupervised anomaly detection", "author": "Oliver Atkinson et.al.", "abstract": "Anomaly detection through employing machine learning techniques has emerged as a novel powerful tool in the search for new physics beyond the Standard Model. Historically similar to the development of jet observables, theoretical consistency has not always assumed a central role in the fast development of algorithms and neural network architectures. In this work, we construct an infrared and collinear safe autoencoder based on graph neural networks by employing energy-weighted message passing. We demonstrate that whilst this approach has theoretically favourable properties, it also exhibits formidable sensitivity to non-QCD structures.", "paper_url": "http://arxiv.org/abs/2204.12231v1", "pdf_url": "http://arxiv.org/pdf/2204.12231v1", "repo_url": null}, "2204.11981": {"publish_time": "2022-04-25", "title": "End-to-end Mapping in Heterogeneous Systems Using Graph Representation Learning", "author": "Yao Xiao et.al.", "abstract": "To enable heterogeneous computing systems with autonomous programming and optimization capabilities, we propose a unified, end-to-end, programmable graph representation learning (PGL) framework that is capable of mining the complexity of high-level programs down to the universal intermediate representation, extracting the specific computational patterns and predicting which code segments would run best on a specific core in heterogeneous hardware platforms. The proposed framework extracts multi-fractal topological features from code graphs, utilizes graph autoencoders to learn how to partition the graph into computational kernels, and exploits graph neural networks (GNN) to predict the correct assignment to a processor type. In the evaluation, we validate the PGL framework and demonstrate a maximum speedup of 6.42x compared to the thread-based execution, and 2.02x compared to the state-of-the-art technique.", "paper_url": "http://arxiv.org/abs/2204.11981v1", "pdf_url": "http://arxiv.org/pdf/2204.11981v1", "repo_url": null}, "2204.13103": {"publish_time": "2022-04-27", "title": "FlowGNN: A Dataflow Architecture for Universal Graph Neural Network Inference via Multi-Queue Streaming", "author": "Rishov Sarkar et.al.", "abstract": "Graph neural networks (GNNs) have recently exploded in popularity thanks to their broad applicability to graph-related problems such as quantum chemistry, drug discovery, and high energy physics. However, meeting demand for novel GNN models and fast inference simultaneously is challenging because of the gap between developing efficient accelerators and the rapid creation of new GNN models. Prior art focuses on the acceleration of specific classes of GNNs, such as Graph Convolutional Network (GCN), but lacks the generality to support a wide range of existing or new GNN models. Meanwhile, most work rely on graph pre-processing to exploit data locality, making them unsuitable for real-time applications. To address these limitations, in this work, we propose a generic dataflow architecture for GNN acceleration, named FlowGNN, which can flexibly support the majority of message-passing GNNs. The contributions are three-fold. First, we propose a novel and scalable dataflow architecture, which flexibly supports a wide range of GNN models with message-passing mechanism. The architecture features a configurable dataflow optimized for simultaneous computation of node embedding, edge embedding, and message passing, which is generally applicable to all models. We also propose a rich library of model-specific components. Second, we deliver ultra-fast real-time GNN inference without any graph pre-processing, making it agnostic to dynamically changing graph structures. Third, we verify our architecture on the Xilinx Alveo U50 FPGA board and measure the on-board end-to-end performance. We achieve a speed-up of up to 51-254x against CPU (6226R) and 1.3-477x against GPU (A6000) (with batch sizes 1 through 1024); we also outperform the SOTA GNN accelerator I-GCN by 1.03x and 1.25x across two datasets. Our implementation code and on-board measurement are publicly available on GitHub.", "paper_url": "http://arxiv.org/abs/2204.13103v1", "pdf_url": "http://arxiv.org/pdf/2204.13103v1", "repo_url": "https://github.com/sharc-lab/flowgnn"}, "2204.12881": {"publish_time": "2022-04-27", "title": "LiftPool: Lifting-based Graph Pooling for Hierarchical Graph Representation Learning", "author": "Mingxing Xu et.al.", "abstract": "Graph pooling has been increasingly considered for graph neural networks (GNNs) to facilitate hierarchical graph representation learning. Existing graph pooling methods commonly consist of two stages, i.e., selecting the top-ranked nodes and removing the rest nodes to construct a coarsened graph representation. However, local structural information of the removed nodes would be inevitably dropped in these methods, due to the inherent coupling of nodes (location) and their features (signals). In this paper, we propose an enhanced three-stage method via lifting, named LiftPool, to improve hierarchical graph representation by maximally preserving the local structural information in graph pooling. LiftPool introduces an additional stage of graph lifting before graph coarsening to preserve the local information of the removed nodes and decouple the processes of node removing and feature reduction. Specifically, for each node to be removed, its local information is obtained by subtracting the global information aggregated from its neighboring preserved nodes. Subsequently, this local information is aligned and propagated to the preserved nodes to alleviate information loss in graph coarsening. Furthermore, we demonstrate that the proposed LiftPool is localized and permutation-invariant. The proposed graph lifting structure is general to be integrated with existing downsampling-based graph pooling methods. Evaluations on benchmark graph datasets show that LiftPool substantially outperforms the state-of-the-art graph pooling methods in the task of graph classification.", "paper_url": "http://arxiv.org/abs/2204.12881v1", "pdf_url": "http://arxiv.org/pdf/2204.12881v1", "repo_url": null}, "2204.12682": {"publish_time": "2022-04-27", "title": "A Practical Two-stage Ranking Framework for Cross-market Recommendation", "author": "Zeyuan Chen et.al.", "abstract": "Cross-market recommendation aims to recommend products to users in a resource-scarce target market by leveraging user behaviors from similar rich-resource markets, which is crucial for E-commerce companies but receives less research attention. In this paper, we present our detailed solution adopted in the cross-market recommendation contest, i.e., WSDM CUP 2022. To better utilize collaborative signals and similarities between target and source markets, we carefully consider multiple features as well as stacking learning models consisting of deep graph recommendation models (Graph Neural Network, DeepWalk, etc.) and traditional recommendation models (ItemCF, UserCF, Swing, etc.). Furthermore, We adopt tree-based ensembling methods, e.g., LightGBM, which show superior performance in prediction task to generate final results. We conduct comprehensive experiments on the XMRec dataset, verifying the effectiveness of our model. The proposed solution of our team WSDM_Coggle_ is selected as the second place submission.", "paper_url": "http://arxiv.org/abs/2204.12682v1", "pdf_url": "http://arxiv.org/pdf/2204.12682v1", "repo_url": null}, "2204.12656": {"publish_time": "2022-04-27", "title": "SCGC : Self-Supervised Contrastive Graph Clustering", "author": "Gayan K. Kulatilleke et.al.", "abstract": "Graph clustering discovers groups or communities within networks. Deep learning methods such as autoencoders (AE) extract effective clustering and downstream representations but cannot incorporate rich structural information. While Graph Neural Networks (GNN) have shown great success in encoding graph structure, typical GNNs based on convolution or attention variants suffer from over-smoothing, noise, heterophily, are computationally expensive and typically require the complete graph being present. Instead, we propose Self-Supervised Contrastive Graph Clustering (SCGC), which imposes graph-structure via contrastive loss signals to learn discriminative node representations and iteratively refined soft cluster labels. We also propose SCGC*, with a more effective, novel, Influence Augmented Contrastive (IAC) loss to fuse richer structural information, and half the original model parameters. SCGC(*) is faster with simple linear units, completely eliminate convolutions and attention of traditional GNNs, yet efficiently incorporates structure. It is impervious to layer depth and robust to over-smoothing, incorrect edges and heterophily. It is scalable by batching, a limitation in many prior GNN models, and trivially parallelizable. We obtain significant improvements over state-of-the-art on a wide range of benchmark graph datasets, including images, sensor data, text, and citation networks efficiently. Specifically, 20% on ARI and 18% on NMI for DBLP; overall 55% reduction in training time and overall, 81% reduction on inference time. Our code is available at : https://github.com/gayanku/SCGC", "paper_url": "http://arxiv.org/abs/2204.12656v1", "pdf_url": "http://arxiv.org/pdf/2204.12656v1", "repo_url": null}, "2204.13442": {"publish_time": "2022-04-28", "title": "TTAGN: Temporal Transaction Aggregation Graph Network for Ethereum Phishing Scams Detection", "author": "Sijia Li et.al.", "abstract": "In recent years, phishing scams have become the most serious type of crime involved in Ethereum, the second-largest blockchain platform. The existing phishing scams detection technology on Ethereum mostly uses traditional machine learning or network representation learning to mine the key information from the transaction network to identify phishing addresses. However, these methods adopt the last transaction record or even completely ignore these records, and only manual-designed features are taken for the node representation. In this paper, we propose a Temporal Transaction Aggregation Graph Network (TTAGN) to enhance phishing scams detection performance on Ethereum. Specifically, in the temporal edges representation module, we model the temporal relationship of historical transaction records between nodes to construct the edge representation of the Ethereum transaction network. Moreover, the edge representations around the node are aggregated to fuse topological interactive relationships into its representation, also named as trading features, in the edge2node module. We further combine trading features with common statistical and structural features obtained by graph neural networks to identify phishing addresses. Evaluated on real-world Ethereum phishing scams datasets, our TTAGN (92.8% AUC, and 81.6% F1score) outperforms the state-of-the-art methods, and the effectiveness of temporal edges representation and edge2node module is also demonstrated.", "paper_url": "http://arxiv.org/abs/2204.13442v1", "pdf_url": "http://arxiv.org/pdf/2204.13442v1", "repo_url": null}, "2204.13429": {"publish_time": "2022-04-28", "title": "DOTIN: Dropping Task-Irrelevant Nodes for GNNs", "author": "Shaofeng Zhang et.al.", "abstract": "Scalability is an important consideration for deep graph neural networks. Inspired by the conventional pooling layers in CNNs, many recent graph learning approaches have introduced the pooling strategy to reduce the size of graphs for learning, such that the scalability and efficiency can be improved. However, these pooling-based methods are mainly tailored to a single graph-level task and pay more attention to local information, limiting their performance in multi-task settings which often require task-specific global information. In this paper, departure from these pooling-based efforts, we design a new approach called DOTIN (\\underline{D}r\\underline{o}pping \\underline{T}ask-\\underline{I}rrelevant \\underline{N}odes) to reduce the size of graphs. Specifically, by introducing $K$ learnable virtual nodes to represent the graph embeddings targeted to $K$ different graph-level tasks, respectively, up to 90\\% raw nodes with low attentiveness with an attention model -- a transformer in this paper, can be adaptively dropped without notable performance decreasing. Achieving almost the same accuracy, our method speeds up GAT by about 50\\% on graph-level tasks including graph classification and graph edit distance (GED) with about 60\\% less memory, on D\\&D dataset. Code will be made publicly available in https://github.com/Sherrylone/DOTIN.", "paper_url": "http://arxiv.org/abs/2204.13429v1", "pdf_url": "http://arxiv.org/pdf/2204.13429v1", "repo_url": null}, "2204.13237": {"publish_time": "2022-04-28", "title": "Spatio-Temporal Graph Localization Networks for Image-based Navigation", "author": "Takahiro Niwa et.al.", "abstract": "Localization in topological maps is essential for image-based navigation using an RGB camera. Localization using only one camera can be challenging in medium-to-large-sized environments because similar-looking images are often observed repeatedly, especially in indoor environments. To overcome this issue, we propose a learning-based localization method that simultaneously utilizes the spatial consistency from topological maps and the temporal consistency from time-series images captured by the robot. Our method combines a convolutional neural network (CNN) to embed image features and a recurrent-type graph neural network to perform accurate localization. When training our model, it is difficult to obtain the ground truth pose of the robot when capturing images in real-world environments. Hence, we propose a sim2real transfer approach with semi-supervised learning that leverages simulator images with the ground truth pose in addition to real images. We evaluated our method quantitatively and qualitatively and compared it with several state-of-the-art baselines. The proposed method outperformed the baselines in environments where the map contained similar images. Moreover, we evaluated an image-based navigation system incorporating our localization method and confirmed that navigation accuracy significantly improved in the simulator and real environments when compared with the other baseline methods.", "paper_url": "http://arxiv.org/abs/2204.13237v1", "pdf_url": "http://arxiv.org/pdf/2204.13237v1", "repo_url": null}, "2204.13153": {"publish_time": "2022-04-27", "title": "SSR-GNNs: Stroke-based Sketch Representation with Graph Neural Networks", "author": "Sheng Cheng et.al.", "abstract": "This paper follows cognitive studies to investigate a graph representation for sketches, where the information of strokes, i.e., parts of a sketch, are encoded on vertices and information of inter-stroke on edges. The resultant graph representation facilitates the training of a Graph Neural Networks for classification tasks, and achieves accuracy and robustness comparable to the state-of-the-art against translation and rotation attacks, as well as stronger attacks on graph vertices and topologies, i.e., modifications and addition of strokes, all without resorting to adversarial training. Prior studies on sketches, e.g., graph transformers, encode control points of stroke on vertices, which are not invariant to spatial transformations. In contrary, we encode vertices and edges using pairwise distances among control points to achieve invariance. Compared with existing generative sketch model for one-shot classification, our method does not rely on run-time statistical inference. Lastly, the proposed representation enables generation of novel sketches that are structurally similar to while separable from the existing dataset.", "paper_url": "http://arxiv.org/abs/2204.13153v1", "pdf_url": "http://arxiv.org/pdf/2204.13153v1", "repo_url": null}, "2204.13972": {"publish_time": "2022-04-29", "title": "Size Generalization for Resource Allocation with Graph Neural Networks", "author": "Wu Jiajun et.al.", "abstract": "Size generalization is important for learning wireless policies, which are often with dynamic sizes, say caused by time-varying number of users. Recent works of learning to optimize resource allocation empirically demonstrate that graph neural networks (GNNs) can generalize to different problem scales. However, GNNs are not guaranteed to generalize across input sizes. In this paper, we strive to analyze the size generalization mechanism of GNNs when learning permutation equivariant (PE) policies. We find that the aggregation function and activation functions of a GNN play a key role on its size generalization ability. We take the GNN with mean aggregator, called mean-GNN, as an example to demonstrate a size generalization condition, and interpret why several GNNs in the literature of wireless communications can generalize well to problem scales. To illustrate how to design GNNs with size generalizability according to our finding, we consider power and bandwidth allocation, and suggest to select or pre-train activation function in the output layer of mean-GNN for learning the PE policies. Simulation results show that the proposed GNN can generalize well to the number of users, which validate our analysis for the size generalization condition of GNNs when learning the PE policies.", "paper_url": "http://arxiv.org/abs/2204.13972v1", "pdf_url": "http://arxiv.org/pdf/2204.13972v1", "repo_url": null}, "2204.13766": {"publish_time": "2022-04-28", "title": "Distributed Auto-Learning GNN for Multi-Cell Cluster-Free NOMA Communications", "author": "Xiaoxia Xu et.al.", "abstract": "A multi-cell cluster-free NOMA framework is proposed, where both intra-cell and inter-cell interference are jointly mitigated via flexible cluster-free successive interference cancellation (SIC) and coordinated beamforming design, respectively. The joint design problem is formulated to maximize the system sum rate while satisfying the SIC decoding requirements and users' data rate constraints. To address this highly complex and coupling non-convex mixed integer nonlinear programming (MINLP), a novel distributed auto-learning graph neural network (AutoGNN) architecture is proposed to alleviate the overwhelming information exchange burdens among base stations (BSs). The proposed AutoGNN can train the GNN model weights whilst automatically learning the optimal GNN architecture, namely the GNN network depth and message embedding sizes, to achieve communication-efficient distributed scheduling. Based on the proposed architecture, a bi-level AutoGNN learning algorithm is further developed to efficiently approximate the hypergradient in model training. It is theoretically proved that the proposed bi-level AutoGNN learning algorithm can converge to a stationary point. Numerical results reveal that: 1) the proposed cluster-free NOMA framework outperforms the conventional cluster-based NOMA framework in the multi-cell scenario; and 2) the proposed AutoGNN architecture significantly reduces the computation and communication overheads compared to the conventional convex optimization-based methods and the conventional GNN with a fixed architecture.", "paper_url": "http://arxiv.org/abs/2204.13766v1", "pdf_url": "http://arxiv.org/pdf/2204.13766v1", "repo_url": null}, "2204.13713": {"publish_time": "2022-04-28", "title": "Learning cosmology and clustering with cosmic graphs", "author": "Pablo Villanueva-Domingo et.al.", "abstract": "We train deep learning models on thousands of galaxy catalogues from the state-of-the-art hydrodynamic simulations of the CAMELS project to perform regression and inference. We employ Graph Neural Networks (GNNs), architectures designed to work with irregular and sparse data, like the distribution of galaxies in the Universe. We first show that GNNs can learn to compute the power spectrum of galaxy catalogues with a few percent accuracy. We then train GNNs to perform likelihood-free inference at the galaxy-field level. Our models are able to infer the value of $\\Omega_{\\rm m}$ with a $\\sim12\\%-13\\%$ accuracy just from the positions of $\\sim1000$ galaxies in a volume of $(25~h^{-1}{\\rm Mpc})^3$ at $z=0$ while accounting for astrophysical uncertainties as modelled in CAMELS. Incorporating information from galaxy properties, such as stellar mass, stellar metallicity, and stellar radius, increases the accuracy to $4\\%-8\\%$. Our models are built to be translational and rotational invariant, and they can extract information from any scale larger than the minimum distance between two galaxies. However, our models are not completely robust: testing on simulations run with a different subgrid physics than the ones used for training does not yield as accurate results.", "paper_url": "http://arxiv.org/abs/2204.13713v1", "pdf_url": "http://arxiv.org/pdf/2204.13713v1", "repo_url": "https://github.com/PabloVD/CosmoGraphNet"}, "2205.00968": {"publish_time": "2022-05-02", "title": "Detection Recovery in Online Multi-Object Tracking with Sparse Graph Tracker", "author": "Jeongseok Hyun et.al.", "abstract": "Joint object detection and online multi-object tracking (JDT) methods have been proposed recently to achieve one-shot tracking. Yet, existing works overlook the importance of detection itself and often result in missed detections when confronted by occlusions or motion blurs. The missed detections affect not only detection performance but also tracking performance due to inconsistent tracklets. Hence, we propose a new JDT model that recovers the missed detections while associating the detection candidates of consecutive frames by learning object-level spatio-temporal consistency through edge features in a Graph Neural Network (GNN). Our proposed model Sparse Graph Tracker (SGT) converts video data into a graph, where the nodes are top-$K$ scored detection candidates, and the edges are relations between the nodes at different times, such as position difference and visual similarity. Two nodes are connected if they are close in either a Euclidean or feature space, generating a sparsely connected graph. Without motion prediction or Re-Identification (ReID), the association is performed by predicting an edge score representing the probability that two connected nodes refer to the same object. Under the online setting, our SGT achieves state-of-the-art (SOTA) on the MOT17/20 Detection and MOT16/20 benchmarks in terms of AP and MOTA, respectively. Especially, SGT surpasses the previous SOTA on the crowded dataset MOT20 where partial occlusion cases are dominant, showing the effectiveness of detection recovery against partial occlusion. Code will be released at https://github.com/HYUNJS/SGT.", "paper_url": "http://arxiv.org/abs/2205.00968v1", "pdf_url": "http://arxiv.org/pdf/2205.00968v1", "repo_url": null}, "2205.00905": {"publish_time": "2022-05-02", "title": "FastGCL: Fast Self-Supervised Learning on Graphs via Contrastive Neighborhood Aggregation", "author": "Yuansheng Wang et.al.", "abstract": "Graph contrastive learning (GCL), as a popular approach to graph self-supervised learning, has recently achieved a non-negligible effect. To achieve superior performance, the majority of existing GCL methods elaborate on graph data augmentation to construct appropriate contrastive pairs. However, existing methods place more emphasis on the complex graph data augmentation which requires extra time overhead, and pay less attention to developing contrastive schemes specific to encoder characteristics. We argue that a better contrastive scheme should be tailored to the characteristics of graph neural networks (e.g., neighborhood aggregation) and propose a simple yet effective method named FastGCL. Specifically, by constructing weighted-aggregated and non-aggregated neighborhood information as positive and negative samples respectively, FastGCL identifies the potential semantic information of data without disturbing the graph topology and node attributes, resulting in faster training and convergence speeds. Extensive experiments have been conducted on node classification and graph classification tasks, showing that FastGCL has competitive classification performance and significant training speedup compared to existing state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2205.00905v1", "pdf_url": "http://arxiv.org/pdf/2205.00905v1", "repo_url": null}, "2205.00772": {"publish_time": "2022-05-02", "title": "Large Neighborhood Search based on Neural Construction Heuristics", "author": "Jonas K. Falkner et.al.", "abstract": "We propose a Large Neighborhood Search (LNS) approach utilizing a learned construction heuristic based on neural networks as repair operator to solve the vehicle routing problem with time windows (VRPTW). Our method uses graph neural networks to encode the problem and auto-regressively decodes a solution and is trained with reinforcement learning on the construction task without requiring any labels for supervision. The neural repair operator is combined with a local search routine, heuristic destruction operators and a selection procedure applied to a small population to arrive at a sophisticated solution approach. The key idea is to use the learned model to re-construct the partially destructed solution and to introduce randomness via the destruction heuristics (or the stochastic policy itself) to effectively explore a large neighborhood.", "paper_url": "http://arxiv.org/abs/2205.00772v1", "pdf_url": "http://arxiv.org/pdf/2205.00772v1", "repo_url": "https://github.com/jokofa/jampr_plus"}, "2205.00614": {"publish_time": "2022-05-02", "title": "Extracting Symbolic Models of Collective Behaviors with Graph Neural Networks and Macro-Micro Evolution", "author": "Stephen Powers et.al.", "abstract": "Collective behaviors are typically hard to model. The scale of the swarm, the large number of interactions, and the richness and complexity of the behaviors are factors that make it difficult to distill a collective behavior into simple symbolic expressions. In this paper, we propose a novel approach to symbolic regression designed to facilitate such modeling. Using raw and post-processed data as an input, our approach produces viable symbolic expressions that closely model the target behavior. Our approach is composed of two phases. In the first, a graph neural network (GNN) is trained to extract an approximation of the target behavior. In the second phase, the GNN is used to produce data for a nested evolutionary algorithm called macro-micro evolution (MME). The macro layer of this algorithm selects candidate symbolic expressions, while the micro layer tunes its parameters. Experimental evaluation shows that our approach outperforms competing solutions for symbolic regression, making it possible to extract compact expressions for complex swarm behaviors.", "paper_url": "http://arxiv.org/abs/2205.00614v1", "pdf_url": "http://arxiv.org/pdf/2205.00614v1", "repo_url": null}, "2205.00546": {"publish_time": "2022-05-01", "title": "Heterogeneous graph neural network for power allocation in multicarrier-division duplex cell-free massive MIMO systems", "author": "Bohan Li et.al.", "abstract": "In-band full duplex-based cell-free (IBFD-CF) systems suffer from severe interference problem including self-interference (SI) and cross-link interference (CLI), especially when cell-free (CF) systems are operated in a distributed way. To this end, we propose multicarrier-division duplex (MDD) as an enabler for full-duplex (FD)-style operation in distributed CF massive MIMO systems, where DL and UL transmissions take place simultaneously at the same frequency band but mutually orthogonal subcarrier sets. In order to maximize the spectral efficiency (SE) in the proposed systems, we present heterogeneous graph neural network specific for CF systems (CF-HGNN), which consists of an adaptive node embedding layer, meta-path based message passing, meta-path based attention and downstream power allocation learning. In particular, the adaptive node embedding layer can handle the varying number of access points (APs), mobile stations (MSs) and subcarriers, and the involved attention mechanism enables each AP/MS node in CF-HGNN to aggregate the information from interfering path and communication path with different priorities. Numerical results show that CF-HGNN is capable of using $10^4$ times less operation time to achieve the 99% performance of the SE of quadratic transform and successive convex approximation (QT-SCA). Additionally, CF-HGNN also significantly outperforms unfair greedy method in terms of SE performance. Furthermore, CF-HGNN exhibits good adaptivity to varying number of nodes and subcarriers, and also generalization ability to different sizes of CF network.", "paper_url": "http://arxiv.org/abs/2205.00546v1", "pdf_url": "http://arxiv.org/pdf/2205.00546v1", "repo_url": null}, "2205.01666": {"publish_time": "2022-05-03", "title": "DANBO: Disentangled Articulated Neural Body Representations via Graph Neural Networks", "author": "Shih-Yang Su et.al.", "abstract": "Deep learning greatly improved the realism of animatable human models by learning geometry and appearance from collections of 3D scans, template meshes, and multi-view imagery. High-resolution models enable photo-realistic avatars but at the cost of requiring studio settings not available to end users. Our goal is to create avatars directly from raw images without relying on expensive studio setups and surface tracking. While a few such approaches exist, those have limited generalization capabilities and are prone to learning spurious (chance) correlations between irrelevant body parts, resulting in implausible deformations and missing body parts on unseen poses. We introduce a three-stage method that induces two inductive biases to better disentangled pose-dependent deformation. First, we model correlations of body parts explicitly with a graph neural network. Second, to further reduce the effect of chance correlations, we introduce localized per-bone features that use a factorized volumetric representation and a new aggregation function. We demonstrate that our model produces realistic body shapes under challenging unseen poses and shows high-quality image synthesis. Our proposed representation strikes a better trade-off between model capacity, expressiveness, and robustness than competing methods. Project website: https://lemonatsu.github.io/danbo.", "paper_url": "http://arxiv.org/abs/2205.01666v1", "pdf_url": "http://arxiv.org/pdf/2205.01666v1", "repo_url": null}, "2205.01316": {"publish_time": "2022-05-03", "title": "HL-Net: Heterophily Learning Network for Scene Graph Generatio", "author": "Xin Lin et.al.", "abstract": "Scene graph generation (SGG) aims to detect objects and predict their pairwise relationships within an image. Current SGG methods typically utilize graph neural networks (GNNs) to acquire context information between objects/relationships. Despite their effectiveness, however, current SGG methods only assume scene graph homophily while ignoring heterophily. Accordingly, in this paper, we propose a novel Heterophily Learning Network (HL-Net) to comprehensively explore the homophily and heterophily between objects/relationships in scene graphs. More specifically, HL-Net comprises the following 1) an adaptive reweighting transformer module, which adaptively integrates the information from different layers to exploit both the heterophily and homophily in objects; 2) a relationship feature propagation module that efficiently explores the connections between relationships by considering heterophily in order to refine the relationship representation; 3) a heterophily-aware message-passing scheme to further distinguish the heterophily and homophily between objects/relationships, thereby facilitating improved message passing in graphs. We conducted extensive experiments on two public datasets: Visual Genome (VG) and Open Images (OI). The experimental results demonstrate the superiority of our proposed HL-Net over existing state-of-the-art approaches. In more detail, HL-Net outperforms the second-best competitors by 2.1$\\%$ on the VG dataset for scene graph classification and 1.2$\\%$ on the IO dataset for the final score. Code is available at https://github.com/siml3/HL-Net.", "paper_url": "http://arxiv.org/abs/2205.01316v1", "pdf_url": "http://arxiv.org/pdf/2205.01316v1", "repo_url": null}, "2205.01297": {"publish_time": "2022-05-03", "title": "RU-Net: Regularized Unrolling Network for Scene Graph Generation", "author": "Xin Lin et.al.", "abstract": "Scene graph generation (SGG) aims to detect objects and predict the relationships between each pair of objects. Existing SGG methods usually suffer from several issues, including 1) ambiguous object representations, as graph neural network-based message passing (GMP) modules are typically sensitive to spurious inter-node correlations, and 2) low diversity in relationship predictions due to severe class imbalance and a large number of missing annotations. To address both problems, in this paper, we propose a regularized unrolling network (RU-Net). We first study the relation between GMP and graph Laplacian denoising (GLD) from the perspective of the unrolling technique, determining that GMP can be formulated as a solver for GLD. Based on this observation, we propose an unrolled message passing module and introduce an $\\ell_p$-based graph regularization to suppress spurious connections between nodes. Second, we propose a group diversity enhancement module that promotes the prediction diversity of relationships via rank maximization. Systematic experiments demonstrate that RU-Net is effective under a variety of settings and metrics. Furthermore, RU-Net achieves new state-of-the-arts on three popular databases: VG, VRD, and OI. Code is available at https://github.com/siml3/RU-Net.", "paper_url": "http://arxiv.org/abs/2205.01297v1", "pdf_url": "http://arxiv.org/pdf/2205.01297v1", "repo_url": null}, "2205.01223": {"publish_time": "2022-05-02", "title": "FINETUNA: Fine-tuning Accelerated Molecular Simulations", "author": "Joseph Musielewicz et.al.", "abstract": "Machine learning approaches have the potential to approximate Density Functional Theory (DFT) for atomistic simulations in a computationally efficient manner, which could dramatically increase the impact of computational simulations on real-world problems. However, they are limited by their accuracy and the cost of generating labeled data. Here, we present an online active learning framework for accelerating the simulation of atomic systems efficiently and accurately by incorporating prior physical information learned by large-scale pre-trained graph neural network models from the Open Catalyst Project. Accelerating these simulations enables useful data to be generated more cheaply, allowing better models to be trained and more atomistic systems to be screened. We also present a method of comparing local optimization techniques on the basis of both their speed and accuracy. Experiments on 30 benchmark adsorbate-catalyst systems show that our method of transfer learning to incorporate prior information from pre-trained models accelerates simulations by reducing the number of DFT calculations by 91%, while meeting an accuracy threshold of 0.02 eV 93% of the time. Finally, we demonstrate a technique for leveraging the interactive functionality built in to VASP to efficiently compute single point calculations within our online active learning framework without the significant startup costs. This allows VASP to work in tandem with our framework while requiring 75% fewer self-consistent cycles than conventional single point calculations. The online active learning implementation, and examples using the VASP interactive code, are available in the open source FINETUNA package on Github.", "paper_url": "http://arxiv.org/abs/2205.01223v1", "pdf_url": "http://arxiv.org/pdf/2205.01223v1", "repo_url": null}, "2205.02041": {"publish_time": "2022-05-04", "title": "Who Will Support My Project? Interactive Search of Potential Crowdfunding Investors Through InSearch", "author": "Songheng Zhang et.al.", "abstract": "Crowdfunding provides project founders with a convenient way to reach online investors. However, it is challenging for founders to find the most potential investors and successfully raise money for their projects on crowdfunding platforms. A few machine learning based methods have been proposed to recommend investors' interest in a specific crowdfunding project, but they fail to provide project founders with explanations in detail for these recommendations, thereby leading to an erosion of trust in predicted investors. To help crowdfunding founders find truly interested investors, we conducted semi-structured interviews with four crowdfunding experts and presents inSearch, a visual analytic system. inSearch allows founders to search for investors interactively on crowdfunding platforms. It supports an effective overview of potential investors by leveraging a Graph Neural Network to model investor preferences. Besides, it enables interactive exploration and comparison of the temporal evolution of different investors' investment details.", "paper_url": "http://arxiv.org/abs/2205.02041v2", "pdf_url": "http://arxiv.org/pdf/2205.02041v2", "repo_url": null}, "2205.02003": {"publish_time": "2022-05-04", "title": "Multi-subgoal Robot Navigation in Crowds with History Information and Interactions", "author": "Xinyi Yu et.al.", "abstract": "Robot navigation in dynamic environments shared with humans is an important but challenging task, which suffers from performance deterioration as the crowd grows. In this paper, multi-subgoal robot navigation approach based on deep reinforcement learning is proposed, which can reason about more comprehensive relationships among all agents (robot and humans). Specifically, the next position point is planned for the robot by introducing history information and interactions in our work. Firstly, based on subgraph network, the history information of all agents is aggregated before encoding interactions through a graph neural network, so as to improve the ability of the robot to anticipate the future scenarios implicitly. Further consideration, in order to reduce the probability of unreliable next position points, the selection module is designed after policy network in the reinforcement learning framework. In addition, the next position point generated from the selection module satisfied the task requirements better than that obtained directly from the policy network. The experiments demonstrate that our approach outperforms state-of-the-art approaches in terms of both success rate and collision rate, especially in crowded human environments.", "paper_url": "http://arxiv.org/abs/2205.02003v1", "pdf_url": "http://arxiv.org/pdf/2205.02003v1", "repo_url": null}, "2205.01893": {"publish_time": "2022-05-04", "title": "Crystal Twins: Self-supervised Learning for Crystalline Material Property Prediction", "author": "Rishikesh Magar et.al.", "abstract": "Machine learning (ML) models have been widely successful in the prediction of material properties. However, large labeled datasets required for training accurate ML models are elusive and computationally expensive to generate. Recent advances in Self-Supervised Learning (SSL) frameworks capable of training ML models on unlabeled data have mitigated this problem and demonstrated superior performance in computer vision and natural language processing tasks. Drawing inspiration from the developments in SSL, we introduce Crystal Twins (CT): an SSL method for crystalline materials property prediction. Using a large unlabeled dataset, we pre-train a Graph Neural Network (GNN) by applying the redundancy reduction principle to the graph latent embeddings of augmented instances obtained from the same crystalline system. By sharing the pre-trained weights when fine-tuning the GNN for regression tasks, we significantly improve the performance for 7 challenging material property prediction benchmarks", "paper_url": "http://arxiv.org/abs/2205.01893v1", "pdf_url": "http://arxiv.org/pdf/2205.01893v1", "repo_url": null}, "2205.01841": {"publish_time": "2022-05-04", "title": "Great Truths are Always Simple: A Rather Simple Knowledge Encoder for Enhancing the Commonsense Reasoning Capacity of Pre-Trained Models", "author": "Jinhao Jiang et.al.", "abstract": "Commonsense reasoning in natural language is a desired ability of artificial intelligent systems. For solving complex commonsense reasoning tasks, a typical solution is to enhance pre-trained language models~(PTMs) with a knowledge-aware graph neural network~(GNN) encoder that models a commonsense knowledge graph~(CSKG). Despite the effectiveness, these approaches are built on heavy architectures, and can't clearly explain how external knowledge resources improve the reasoning capacity of PTMs. Considering this issue, we conduct a deep empirical analysis, and find that it is indeed relation features from CSKGs (but not node features) that mainly contribute to the performance improvement of PTMs. Based on this finding, we design a simple MLP-based knowledge encoder that utilizes statistical relation paths as features. Extensive experiments conducted on five benchmarks demonstrate the effectiveness of our approach, which also largely reduces the parameters for encoding CSKGs. Our codes and data are publicly available at https://github.com/RUCAIBox/SAFE.", "paper_url": "http://arxiv.org/abs/2205.01841v1", "pdf_url": "http://arxiv.org/pdf/2205.01841v1", "repo_url": "https://github.com/rucaibox/safe"}, "2205.02637": {"publish_time": "2022-05-05", "title": "Towards Fast Simulation of Environmental Fluid Mechanics with Multi-Scale Graph Neural Networks", "author": "Mario Lino et.al.", "abstract": "Numerical simulators are essential tools in the study of natural fluid-systems, but their performance often limits application in practice. Recent machine-learning approaches have demonstrated their ability to accelerate spatio-temporal predictions, although, with only moderate accuracy in comparison. Here we introduce MultiScaleGNN, a novel multi-scale graph neural network model for learning to infer unsteady continuum mechanics in problems encompassing a range of length scales and complex boundary geometries. We demonstrate this method on advection problems and incompressible fluid dynamics, both fundamental phenomena in oceanic and atmospheric processes. Our results show good extrapolation to new domain geometries and parameters for long-term temporal simulations. Simulations obtained with MultiScaleGNN are between two and four orders of magnitude faster than those on which it was trained.", "paper_url": "http://arxiv.org/abs/2205.02637v1", "pdf_url": "http://arxiv.org/pdf/2205.02637v1", "repo_url": null}, "2205.02468": {"publish_time": "2022-05-05", "title": "Alignahead: Online Cross-Layer Knowledge Extraction on Graph Neural Networks", "author": "Jiongyu Guo et.al.", "abstract": "Existing knowledge distillation methods on graph neural networks (GNNs) are almost offline, where the student model extracts knowledge from a powerful teacher model to improve its performance. However, a pre-trained teacher model is not always accessible due to training cost, privacy, etc. In this paper, we propose a novel online knowledge distillation framework to resolve this problem. Specifically, each student GNN model learns the extracted local structure from another simultaneously trained counterpart in an alternating training procedure. We further develop a cross-layer distillation strategy by aligning ahead one student layer with the layer in different depth of another student model, which theoretically makes the structure information spread over all layers. Experimental results on five datasets including PPI, Coauthor-CS/Physics and Amazon-Computer/Photo demonstrate that the student performance is consistently boosted in our collaborative training framework without the supervision of a pre-trained teacher model. In addition, we also find that our alignahead technique can accelerate the model convergence speed and its effectiveness can be generally improved by increasing the student numbers in training. Code is available: https://github.com/GuoJY-eatsTG/Alignahead", "paper_url": "http://arxiv.org/abs/2205.02468v1", "pdf_url": "http://arxiv.org/pdf/2205.02468v1", "repo_url": "https://github.com/guojy-eatstg/alignahead"}, "2205.02455": {"publish_time": "2022-05-05", "title": "COGMEN: COntextualized GNN based Multimodal Emotion recognitioN", "author": "Abhinav Joshi et.al.", "abstract": "Emotions are an inherent part of human interactions, and consequently, it is imperative to develop AI systems that understand and recognize human emotions. During a conversation involving various people, a person's emotions are influenced by the other speaker's utterances and their own emotional state over the utterances. In this paper, we propose COntextualized Graph Neural Network based Multimodal Emotion recognitioN (COGMEN) system that leverages local information (i.e., inter/intra dependency between speakers) and global information (context). The proposed model uses Graph Neural Network (GNN) based architecture to model the complex dependencies (local and global information) in a conversation. Our model gives state-of-the-art (SOTA) results on IEMOCAP and MOSEI datasets, and detailed ablation experiments show the importance of modeling information at both levels.", "paper_url": "http://arxiv.org/abs/2205.02455v1", "pdf_url": "http://arxiv.org/pdf/2205.02455v1", "repo_url": "https://github.com/exploration-lab/cogmen"}, "2205.02998": {"publish_time": "2022-05-06", "title": "Learning Optimal Propagation for Graph Neural Networks", "author": "Beidi Zhao et.al.", "abstract": "Graph Neural Networks (GNNs) have achieved tremendous success in a variety of real-world applications by relying on the fixed graph data as input. However, the initial input graph might not be optimal in terms of specific downstream tasks, because of information scarcity, noise, adversarial attacks, or discrepancies between the distribution in graph topology, features, and groundtruth labels. In this paper, we propose a bi-level optimization-based approach for learning the optimal graph structure via directly learning the Personalized PageRank propagation matrix as well as the downstream semi-supervised node classification simultaneously. We also explore a low-rank approximation model for further reducing the time complexity. Empirical evaluations show the superior efficacy and robustness of the proposed model over all baseline methods.", "paper_url": "http://arxiv.org/abs/2205.02998v1", "pdf_url": "http://arxiv.org/pdf/2205.02998v1", "repo_url": null}, "2205.02909": {"publish_time": "2022-05-05", "title": "RoboCraft: Learning to See, Simulate, and Shape Elasto-Plastic Objects with Graph Networks", "author": "Haochen Shi et.al.", "abstract": "Modeling and manipulating elasto-plastic objects are essential capabilities for robots to perform complex industrial and household interaction tasks (e.g., stuffing dumplings, rolling sushi, and making pottery). However, due to the high degree of freedom of elasto-plastic objects, significant challenges exist in virtually every aspect of the robotic manipulation pipeline, e.g., representing the states, modeling the dynamics, and synthesizing the control signals. We propose to tackle these challenges by employing a particle-based representation for elasto-plastic objects in a model-based planning framework. Our system, RoboCraft, only assumes access to raw RGBD visual observations. It transforms the sensing data into particles and learns a particle-based dynamics model using graph neural networks (GNNs) to capture the structure of the underlying system. The learned model can then be coupled with model-predictive control (MPC) algorithms to plan the robot's behavior. We show through experiments that with just 10 minutes of real-world robotic interaction data, our robot can learn a dynamics model that can be used to synthesize control signals to deform elasto-plastic objects into various target shapes, including shapes that the robot has never encountered before. We perform systematic evaluations in both simulation and the real world to demonstrate the robot's manipulation capabilities and ability to generalize to a more complex action space, different tool shapes, and a mixture of motion modes. We also conduct comparisons between RoboCraft and untrained human subjects controlling the gripper to manipulate deformable objects in both simulation and the real world. Our learned model-based planning framework is comparable to and sometimes better than human subjects on the tested tasks.", "paper_url": "http://arxiv.org/abs/2205.02909v1", "pdf_url": "http://arxiv.org/pdf/2205.02909v1", "repo_url": null}, "2205.04423": {"publish_time": "2022-05-09", "title": "Graph Neural Networks for Propositional Model Counting", "author": "Gaia Saveri et.al.", "abstract": "Graph Neural Networks (GNNs) have been recently leveraged to solve several logical reasoning tasks. Nevertheless, counting problems such as propositional model counting (#SAT) are still mostly approached with traditional solvers. Here we tackle this gap by presenting an architecture based on the GNN framework for belief propagation (BP) of Kuch et al., extended with self-attentive GNN and trained to approximately solve the #SAT problem. We ran a thorough experimental investigation, showing that our model, trained on a small set of random Boolean formulae, is able to scale effectively to much larger problem sizes, with comparable or better performances of state of the art approximate solvers. Moreover, we show that it can be efficiently fine-tuned to provide good generalization results on different formulae distributions, such as those coming from SAT-encoded combinatorial problems.", "paper_url": "http://arxiv.org/abs/2205.04423v1", "pdf_url": "http://arxiv.org/pdf/2205.04423v1", "repo_url": null}, "2205.04188": {"publish_time": "2022-05-09", "title": "Joint learning of object graph and relation graph for visual question answering", "author": "Hao Li et.al.", "abstract": "Modeling visual question answering(VQA) through scene graphs can significantly improve the reasoning accuracy and interpretability. However, existing models answer poorly for complex reasoning questions with attributes or relations, which causes false attribute selection or missing relation in Figure 1(a). It is because these models cannot balance all kinds of information in scene graphs, neglecting relation and attribute information. In this paper, we introduce a novel Dual Message-passing enhanced Graph Neural Network (DM-GNN), which can obtain a balanced representation by properly encoding multi-scale scene graph information. Specifically, we (i)transform the scene graph into two graphs with diversified focuses on objects and relations; Then we design a dual structure to encode them, which increases the weights from relations (ii)fuse the encoder output with attribute features, which increases the weights from attributes; (iii)propose a message-passing mechanism to enhance the information transfer between objects, relations and attributes. We conduct extensive experiments on datasets including GQA, VG, motif-VG and achieve new state of the art.", "paper_url": "http://arxiv.org/abs/2205.04188v1", "pdf_url": "http://arxiv.org/pdf/2205.04188v1", "repo_url": null}, "2205.03811": {"publish_time": "2022-05-08", "title": "Data-Free Adversarial Knowledge Distillation for Graph Neural Networks", "author": "Yuanxin Zhuang et.al.", "abstract": "Graph neural networks (GNNs) have been widely used in modeling graph structured data, owing to its impressive performance in a wide range of practical applications. Recently, knowledge distillation (KD) for GNNs has enabled remarkable progress in graph model compression and knowledge transfer. However, most of the existing KD methods require a large volume of real data, which are not readily available in practice, and may preclude their applicability in scenarios where the teacher model is trained on rare or hard to acquire datasets. To address this problem, we propose the first end-to-end framework for data-free adversarial knowledge distillation on graph structured data (DFAD-GNN). To be specific, our DFAD-GNN employs a generative adversarial network, which mainly consists of three components: a pre-trained teacher model and a student model are regarded as two discriminators, and a generator is utilized for deriving training graphs to distill knowledge from the teacher model into the student model. Extensive experiments on various benchmark models and six representative datasets demonstrate that our DFAD-GNN significantly surpasses state-of-the-art data-free baselines in the graph classification task.", "paper_url": "http://arxiv.org/abs/2205.03811v1", "pdf_url": "http://arxiv.org/pdf/2205.03811v1", "repo_url": null}, "2205.03786": {"publish_time": "2022-05-08", "title": "GRAPHCACHE: Message Passing as Caching for Sentence-Level Relation Extraction", "author": "Yiwei Wang et.al.", "abstract": "Entity types and textual context are essential properties for sentence-level relation extraction (RE). Existing work only encodes these properties within individual instances, which limits the performance of RE given the insufficient features in a single sentence. In contrast, we model these properties from the whole dataset and use the dataset-level information to enrich the semantics of every instance. We propose the GRAPHCACHE (Graph Neural Network as Caching) module, that propagates the features across sentences to learn better representations for RE. GRAPHCACHE aggregates the features from sentences in the whole dataset to learn global representations of properties, and use them to augment the local features within individual sentences. The global property features act as dataset-level prior knowledge for RE, and a complement to the sentence-level features. Inspired by the classical caching technique in computer systems, we develop GRAPHCACHE to update the property representations in an online manner. Overall, GRAPHCACHE yields significant effectiveness gains on RE and enables efficient message passing across all sentences in the dataset.", "paper_url": "http://arxiv.org/abs/2205.03786v1", "pdf_url": "http://arxiv.org/pdf/2205.03786v1", "repo_url": null}, "2205.03612": {"publish_time": "2022-05-07", "title": "BrainIB: Interpretable Brain Network-based Psychiatric Diagnosis with Graph Information Bottleneck", "author": "Kaizhong Zheng et.al.", "abstract": "Developing a new diagnostic models based on the underlying biological mechanisms rather than subjective symptoms for psychiatric disorders is an emerging consensus. Recently, machine learning-based classifiers using functional connectivity (FC) for psychiatric disorders and healthy controls are developed to identify brain markers. However, existing machine learningbased diagnostic models are prone to over-fitting (due to insufficient training samples) and perform poorly in new test environment. Furthermore, it is difficult to obtain explainable and reliable brain biomarkers elucidating the underlying diagnostic decisions. These issues hinder their possible clinical applications. In this work, we propose BrainIB, a new graph neural network (GNN) framework to analyze functional magnetic resonance images (fMRI), by leveraging the famed Information Bottleneck (IB) principle. BrainIB is able to identify the most informative regions in the brain (i.e., subgraph) and generalizes well to unseen data. We evaluate the performance of BrainIB against 6 popular brain network classification methods on two multi-site, largescale datasets and observe that our BrainIB always achieves the highest diagnosis accuracy. It also discovers the subgraph biomarkers which are consistent to clinical and neuroimaging findings.", "paper_url": "http://arxiv.org/abs/2205.03612v1", "pdf_url": "http://arxiv.org/pdf/2205.03612v1", "repo_url": null}, "2205.04739": {"publish_time": "2022-05-10", "title": "Flow Completion Network: Inferring the Fluid Dynamics from Incomplete Flow Information using Graph Neural Networks", "author": "Xiaodong He et.al.", "abstract": "This paper introduces a novel neural network -- the flow completion network (FCN) -- to infer the fluid dynamics, including the flow field and the force acting on the body, from the incomplete data based on Graph Convolution Attention Network. The FCN is composed of several graph convolution layers and spatial attention layers. It is designed to infer the velocity field and the vortex force contribution of the flow field when combined with the vortex force map (VFM) method. Compared with other neural networks adopted in fluid dynamics, the FCN is capable of dealing with both structured data and unstructured data. The performance of the proposed FCN is assessed by the computational fluid dynamics (CFD) data on the flow field around a circular cylinder. The force coefficients predicted by our model are validated against those obtained directly from CFD. Moreover, it is shown that our model effectively utilizes the existing flow field information and the gradient information simultaneously, giving a better performance than the traditional CNN-based and DNN-based models.", "paper_url": "http://arxiv.org/abs/2205.04739v1", "pdf_url": "http://arxiv.org/pdf/2205.04739v1", "repo_url": null}, "2205.04711": {"publish_time": "2022-05-10", "title": "SmartSAGE: Training Large-scale Graph Neural Networks using In-Storage Processing Architectures", "author": "Yunjae Lee et.al.", "abstract": "Graph neural networks (GNNs) can extract features by learning both the representation of each objects (i.e., graph nodes) and the relationship across different objects (i.e., the edges that connect nodes), achieving state-of-the-art performance in various graph-based tasks. Despite its strengths, utilizing these algorithms in a production environment faces several challenges as the number of graph nodes and edges amount to several billions to hundreds of billions scale, requiring substantial storage space for training. Unfortunately, state-of-the-art ML frameworks employ an in-memory processing model which significantly hampers the productivity of ML practitioners as it mandates the overall working set to fit within DRAM capacity. In this work, we first conduct a detailed characterization on a state-of-the-art, large-scale GNN training algorithm, GraphSAGE. Based on the characterization, we then explore the feasibility of utilizing capacity-optimized NVM SSDs for storing memory-hungry GNN data, which enables large-scale GNN training beyond the limits of main memory size. Given the large performance gap between DRAM and SSD, however, blindly utilizing SSDs as a direct substitute for DRAM leads to significant performance loss. We therefore develop SmartSAGE, our software/hardware co-design based on an in-storage processing (ISP) architecture. Our work demonstrates that an ISP based large-scale GNN training system can achieve both high capacity storage and high performance, opening up opportunities for ML practitioners to train large GNN datasets without being hampered by the physical limitations of main memory size.", "paper_url": "http://arxiv.org/abs/2205.04711v1", "pdf_url": "http://arxiv.org/pdf/2205.04711v1", "repo_url": null}, "2205.04692": {"publish_time": "2022-05-10", "title": "Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting", "author": "Mingyang Chen et.al.", "abstract": "We study the knowledge extrapolation problem to embed new components (i.e., entities and relations) that come with emerging knowledge graphs (KGs) in the federated setting. In this problem, a model trained on an existing KG needs to embed an emerging KG with unseen entities and relations. To solve this problem, we introduce the meta-learning setting, where a set of tasks are sampled on the existing KG to mimic the link prediction task on the emerging KG. Based on sampled tasks, we meta-train a graph neural network framework that can construct features for unseen components based on structural information and output embeddings for them. Experimental results show that our proposed method can effectively embed unseen components and outperforms models that consider inductive settings for KGs and baselines that directly use conventional KG embedding methods.", "paper_url": "http://arxiv.org/abs/2205.04692v1", "pdf_url": "http://arxiv.org/pdf/2205.04692v1", "repo_url": "https://github.com/zjukg/maker"}, "2205.05475": {"publish_time": "2022-05-11", "title": "Efficient prediction of density functional theory Hamiltonian with graph neural network", "author": "Mao Su et.al.", "abstract": "Despite the past decades have witnessed many successes of machine learning methods in predicting physical properties, the prediction of Hamiltonian and thus electronic properties is still out of satisfactions. Here based on the graph neural network architecture, we present an extendible neural network model to learn the Hamiltonian from ab initio data with only local structures as inputs. The local coordinates, encoded using the convolutional neural network and designed to reserve the Hermitian symmetry, is used to map hopping parameters onto local structures. We demonstrate the performance of our model using SiGe random alloys as an example. We show that, our neural network model, although trained using small-size systems, can predict Hamiltonian as well as electronic properties such as band structures and densities of states (DOS) for large-size systems within the ab initio accuracy, justifying its extendibility. In combination with the high efficiency of our model, i.e., it takes only seconds to get the Hamiltonian of a 1728-atom system, our work provides a general framework to efficiently and accurately predict the electronic properties, which provides new insights into computational physics and will accelerate the research for large-scale materials.", "paper_url": "http://arxiv.org/abs/2205.05475v1", "pdf_url": "http://arxiv.org/pdf/2205.05475v1", "repo_url": null}, "2205.05348": {"publish_time": "2022-05-11", "title": "NDGGNET-A Node Independent Gate based Graph Neural Networks", "author": "Ye Tang et.al.", "abstract": "Graph Neural Networks (GNNs) is an architecture for structural data, and has been adopted in a mass of tasks and achieved fabulous results, such as link prediction, node classification, graph classification and so on. Generally, for a certain node in a given graph, a traditional GNN layer can be regarded as an aggregation from one-hop neighbors, thus a set of stacked layers are able to fetch and update node status within multi-hops. For nodes with sparse connectivity, it is difficult to obtain enough information through a single GNN layer as not only there are only few nodes directly connected to them but also can not propagate the high-order neighbor information. However, as the number of layer increases, the GNN model is prone to over-smooth for nodes with the dense connectivity, which resulting in the decrease of accuracy. To tackle this issue, in this thesis, we define a novel framework that allows the normal GNN model to accommodate more layers. Specifically, a node-degree based gate is employed to adjust weight of layers dynamically, that try to enhance the information aggregation ability and reduce the probability of over-smoothing. Experimental results show that our proposed model can effectively increase the model depth and perform well on several datasets.", "paper_url": "http://arxiv.org/abs/2205.05348v1", "pdf_url": "http://arxiv.org/pdf/2205.05348v1", "repo_url": null}, "2205.05250": {"publish_time": "2022-05-11", "title": "Spatial-temporal associations representation and application for process monitoring using graph convolution neural network", "author": "Hao Ren et.al.", "abstract": "Industrial process data reflects the dynamic changes of operation conditions, which mainly refer to the irregular changes in the dynamic associations between different variables in different time. And this related associations knowledge for process monitoring is often implicit in these dynamic monitoring data which always have richer operation condition information and have not been paid enough attention in current research. To this end, a new process monitoring method based on spatial-based graph convolution neural network (SGCN) is proposed to describe the characteristics of the dynamic associations which can be used to represent the operation status over time. Spatia-temporal graphs are firstly defined, which can be used to represent the characteristics of node attributes (dynamic edge features) dynamically changing with time. Then, the associations between monitoring variables at a certain time can be considered as the node attributes to define a snapshot of the static graph network at the certain time. Finally, the snapshot containing graph structure and node attributes is used as model inputs which are processed to implement graph classification by spatial-based convolution graph neural network with aggregate and readout steps. The feasibility and applicability of this proposed method are demonstrated by our experimental results of benchmark and practical case application.", "paper_url": "http://arxiv.org/abs/2205.05250v1", "pdf_url": "http://arxiv.org/pdf/2205.05250v1", "repo_url": null}, "2205.06002": {"publish_time": "2022-05-12", "title": "Learning Generalized Policies Without Supervision Using GNNs", "author": "Simon St\u00e5hlberg et.al.", "abstract": "We consider the problem of learning generalized policies for classical planning domains using graph neural networks from small instances represented in lifted STRIPS. The problem has been considered before but the proposed neural architectures are complex and the results are often mixed. In this work, we use a simple and general GNN architecture and aim at obtaining crisp experimental results and a deeper understanding: either the policy greedy in the learned value function achieves close to 100% generalization over instances larger than those used in training, or the failure must be understood, and possibly fixed, logically. For this, we exploit the relation established between the expressive power of GNNs and the $C_{2}$ fragment of first-order logic (namely, FOL with 2 variables and counting quantifiers). We find for example that domains with general policies that require more expressive features can be solved with GNNs once the states are extended with suitable \"derived atoms\" encoding role compositions and transitive closures that do not fit into $C_{2}$. The work follows the GNN approach for learning optimal general policies in a supervised fashion (Stahlberg, Bonet, Geffner, 2022); but the learned policies are no longer required to be optimal (which expands the scope, as many planning domains do not have general optimal policies) and are learned without supervision. Interestingly, value-based reinforcement learning methods that aim to produce optimal policies, do not always yield policies that generalize, as the goals of optimality and generality are in conflict in domains where optimal planning is NP-hard.", "paper_url": "http://arxiv.org/abs/2205.06002v1", "pdf_url": "http://arxiv.org/pdf/2205.06002v1", "repo_url": null}, "2205.05964": {"publish_time": "2022-05-12", "title": "GPN: A Joint Structural Learning Framework for Graph Neural Networks", "author": "Qianggang Ding et.al.", "abstract": "Graph neural networks (GNNs) have been applied into a variety of graph tasks. Most existing work of GNNs is based on the assumption that the given graph data is optimal, while it is inevitable that there exists missing or incomplete edges in the graph data for training, leading to degraded performance. In this paper, we propose Generative Predictive Network (GPN), a GNN-based joint learning framework that simultaneously learns the graph structure and the downstream task. Specifically, we develop a bilevel optimization framework for this joint learning task, in which the upper optimization (generator) and the lower optimization (predictor) are both instantiated with GNNs. To the best of our knowledge, our method is the first GNN-based bilevel optimization framework for resolving this task. Through extensive experiments, our method outperforms a wide range of baselines using benchmark datasets.", "paper_url": "http://arxiv.org/abs/2205.05964v1", "pdf_url": "http://arxiv.org/pdf/2205.05964v1", "repo_url": null}, "2205.05861": {"publish_time": "2022-05-12", "title": "S3E-GNN: Sparse Spatial Scene Embedding with Graph Neural Networks for Camera Relocalization", "author": "Ran Cheng et.al.", "abstract": "Camera relocalization is the key component of simultaneous localization and mapping (SLAM) systems. This paper proposes a learning-based approach, named Sparse Spatial Scene Embedding with Graph Neural Networks (S3E-GNN), as an end-to-end framework for efficient and robust camera relocalization. S3E-GNN consists of two modules. In the encoding module, a trained S3E network encodes RGB images into embedding codes to implicitly represent spatial and semantic embedding code. With embedding codes and the associated poses obtained from a SLAM system, each image is represented as a graph node in a pose graph. In the GNN query module, the pose graph is transformed to form a embedding-aggregated reference graph for camera relocalization. We collect various scene datasets in the challenging environments to perform experiments. Our results demonstrate that S3E-GNN method outperforms the traditional Bag-of-words (BoW) for camera relocalization due to learning-based embedding and GNN powered scene matching mechanism.", "paper_url": "http://arxiv.org/abs/2205.05861v1", "pdf_url": "http://arxiv.org/pdf/2205.05861v1", "repo_url": null}, "2205.06667": {"publish_time": "2022-05-13", "title": "Search for nonresonant pair production of highly energetic Higgs bosons decaying to bottom quarks", "author": "CMS Collaboration et.al.", "abstract": "A search for nonresonant Higgs boson (H) pair production via gluon and vector boson (V) fusion is performed in the four-bottom-quark final state, using proton-proton collision data at 13 TeV corresponding to 138 fb$^{-1}$ collected by the CMS experiment at the LHC. The analysis targets Lorentz-boosted H pairs identified using a graph neural network. It constrains the strengths relative to the standard model of the H self-coupling and the quartic VVHH couplings, $\\kappa_{2V}$, excluding $\\kappa_{2V}$ = 0 for the first time, with a significance of 6.3 standard deviations when other H couplings are fixed to their standard model values.", "paper_url": "http://arxiv.org/abs/2205.06667v1", "pdf_url": "http://arxiv.org/pdf/2205.06667v1", "repo_url": null}, "2205.06562": {"publish_time": "2022-05-13", "title": "A Graph-based probabilistic geometric deep learning framework with online physics-based corrections to predict the criticality of defects in porous materials", "author": "Vasilis Krokos et.al.", "abstract": "Stress prediction in porous materials and structures is challenging due to the high computational cost associated with direct numerical simulations. Convolutional Neural Network (CNN) based architectures have recently been proposed as surrogates to approximate and extrapolate the solution of such multiscale simulations. These methodologies are usually limited to 2D problems due to the high computational cost of 3D voxel based CNNs. We propose a novel geometric learning approach based on a Graph Neural Network (GNN) that efficiently deals with three-dimensional problems by performing convolutions over 2D surfaces only. Following our previous developments using pixel-based CNN, we train the GNN to automatically add local fine-scale stress corrections to an inexpensively computed coarse stress prediction in the porous structure of interest. Our method is Bayesian and generates densities of stress fields, from which credible intervals may be extracted. As a second scientific contribution, we propose to improve the extrapolation ability of our network by deploying a strategy of online physics-based corrections. Specifically, we condition the posterior predictions of our probabilistic predictions to satisfy partial equilibrium at the microscale, at the inference stage. This is done using an Ensemble Kalman algorithm, to ensure tractability of the Bayesian conditioning operation. We show that this innovative methodology allows us to alleviate the effect of undesirable biases observed in the outputs of the uncorrected GNN, and improves the accuracy of the predictions in general.", "paper_url": "http://arxiv.org/abs/2205.06562v1", "pdf_url": "http://arxiv.org/pdf/2205.06562v1", "repo_url": null}, "2205.06456": {"publish_time": "2022-05-13", "title": "Simple and Effective Relation-based Embedding Propagation for Knowledge Representation Learning", "author": "Huijuan Wang et.al.", "abstract": "Relational graph neural networks have garnered particular attention to encode graph context in knowledge graphs (KGs). Although they achieved competitive performance on small KGs, how to efficiently and effectively utilize graph context for large KGs remains an open problem. To this end, we propose the Relation-based Embedding Propagation (REP) method. It is a post-processing technique to adapt pre-trained KG embeddings with graph context. As relations in KGs are directional, we model the incoming head context and the outgoing tail context separately. Accordingly, we design relational context functions with no external parameters. Besides, we use averaging to aggregate context information, making REP more computation-efficient. We theoretically prove that such designs can avoid information distortion during propagation. Extensive experiments also demonstrate that REP has significant scalability while improving or maintaining prediction quality. Notably, it averagely brings about 10% relative improvement to triplet-based embedding methods on OGBL-WikiKG2 and takes 5%-83% time to achieve comparable results as the state-of-the-art GC-OTE.", "paper_url": "http://arxiv.org/abs/2205.06456v1", "pdf_url": "http://arxiv.org/pdf/2205.06456v1", "repo_url": null}, "2205.06396": {"publish_time": "2022-05-12", "title": "Learning Based User Scheduling in Reconfigurable Intelligent Surface Assisted Multiuser Downlink", "author": "Zhongze Zhang et.al.", "abstract": "Reconfigurable intelligent surface (RIS) is capable of intelligently manipulating the phases of the incident electromagnetic wave to improve the wireless propagation environment between the base-station (BS) and the users. This paper addresses the joint user scheduling, RIS configuration, and BS beamforming problem in an RIS-assisted downlink network with limited pilot overhead. We show that graph neural networks (GNN) with permutation invariant and equivariant properties can be used to appropriately schedule users and to design RIS configurations to achieve high overall throughput while accounting for fairness among the users. As compared to the conventional methodology of first estimating the channels then optimizing the user schedule, RIS configuration and the beamformers, this paper shows that an optimized user schedule can be obtained directly from a very short set of pilots using a GNN, then the RIS configuration can be optimized using a second GNN, and finally the BS beamformers can be designed based on the overall effective channel. Numerical results show that the proposed approach can utilize the received pilots more efficiently than the conventional channel estimation based approach, and can generalize to systems with an arbitrary number of users.", "paper_url": "http://arxiv.org/abs/2205.06396v1", "pdf_url": "http://arxiv.org/pdf/2205.06396v1", "repo_url": null}, "2205.06324": {"publish_time": "2022-05-12", "title": "Graph Neural Network Modeling of Grain-scale Anisotropic Elastic Behavior using Simulated and Measured Microscale Data", "author": "Darren C. Pagan et.al.", "abstract": "Here we assess the applicability of graph neural networks (GNNs) for predicting the grain-scale elastic response of polycrystalline metallic alloys. Using GNN surrogate models, grain-averaged stresses during uniaxial elastic tension in Low Solvus High Refractory (LSHR) Ni Superalloy and Ti 7wt%Al (Ti-7Al), as example face centered cubic and hexagonal closed packed alloys, are predicted. A transfer learning approach is taken in which GNN surrogate models are trained using crystal elasticity finite element method simulations and then the trained surrogate models are used to predict the mechanical response of microstructures measured using high-energy X-ray diffraction microscopy. The performance of using various microstructural and micromechanical descriptors for input nodal features to the GNNs is explored. The effects of elastic anisotropy on GNN model performance and outlooks for extension of the framework are discussed.", "paper_url": "http://arxiv.org/abs/2205.06324v1", "pdf_url": "http://arxiv.org/pdf/2205.06324v1", "repo_url": null}, "2205.07826": {"publish_time": "2022-05-16", "title": "GraphHD: Efficient graph classification using hyperdimensional computing", "author": "Igor Nunes et.al.", "abstract": "Hyperdimensional Computing (HDC) developed by Kanerva is a computational model for machine learning inspired by neuroscience. HDC exploits characteristics of biological neural systems such as high-dimensionality, randomness and a holographic representation of information to achieve a good balance between accuracy, efficiency and robustness. HDC models have already been proven to be useful in different learning applications, especially in resource-limited settings such as the increasingly popular Internet of Things (IoT). One class of learning tasks that is missing from the current body of work on HDC is graph classification. Graphs are among the most important forms of information representation, yet, to this day, HDC algorithms have not been applied to the graph learning problem in a general sense. Moreover, graph learning in IoT and sensor networks, with limited compute capabilities, introduce challenges to the overall design methodology. In this paper, we present GraphHD$-$a baseline approach for graph classification with HDC. We evaluate GraphHD on real-world graph classification problems. Our results show that when compared to the state-of-the-art Graph Neural Networks (GNNs) the proposed model achieves comparable accuracy, while training and inference times are on average 14.6$\\times$ and 2.0$\\times$ faster, respectively.", "paper_url": "http://arxiv.org/abs/2205.07826v1", "pdf_url": "http://arxiv.org/pdf/2205.07826v1", "repo_url": null}, "2205.07424": {"publish_time": "2022-05-16", "title": "Trustworthy Graph Neural Networks: Aspects, Methods and Trends", "author": "He Zhang et.al.", "abstract": "Graph neural networks (GNNs) have emerged as a series of competent graph learning methods for diverse real-world scenarios, ranging from daily applications like recommendation systems and question answering to cutting-edge technologies such as drug discovery in life sciences and n-body simulation in astrophysics. However, task performance is not the only requirement for GNNs. Performance-oriented GNNs have exhibited potential adverse effects like vulnerability to adversarial attacks, unexplainable discrimination against disadvantaged groups, or excessive resource consumption in edge computing environments. To avoid these unintentional harms, it is necessary to build competent GNNs characterised by trustworthiness. To this end, we propose a comprehensive roadmap to build trustworthy GNNs from the view of the various computing technologies involved. In this survey, we introduce basic concepts and comprehensively summarise existing efforts for trustworthy GNNs from six aspects, including robustness, explainability, privacy, fairness, accountability, and environmental well-being. Additionally, we highlight the intricate cross-aspect relations between the above six aspects of trustworthy GNNs. Finally, we present a thorough overview of trending directions for facilitating the research and industrialisation of trustworthy GNNs.", "paper_url": "http://arxiv.org/abs/2205.07424v1", "pdf_url": "http://arxiv.org/pdf/2205.07424v1", "repo_url": null}, "2205.07308": {"publish_time": "2022-05-15", "title": "Finding Global Homophily in Graph Neural Networks When Meeting Heterophily", "author": "Xiang Li et.al.", "abstract": "We investigate graph neural networks on graphs with heterophily. Some existing methods amplify a node's neighborhood with multi-hop neighbors to include more nodes with homophily. However, it is a significant challenge to set personalized neighborhood sizes for different nodes. Further, for other homophilous nodes excluded in the neighborhood, they are ignored for information aggregation. To address these problems, we propose two models GloGNN and GloGNN++, which generate a node's embedding by aggregating information from global nodes in the graph. In each layer, both models learn a coefficient matrix to capture the correlations between nodes, based on which neighborhood aggregation is performed. The coefficient matrix allows signed values and is derived from an optimization problem that has a closed-form solution. We further accelerate neighborhood aggregation and derive a linear time complexity. We theoretically explain the models' effectiveness by proving that both the coefficient matrix and the generated node embedding matrix have the desired grouping effect. We conduct extensive experiments to compare our models against 11 other competitors on 15 benchmark datasets in a wide range of domains, scales and graph heterophilies. Experimental results show that our methods achieve superior performance and are also very efficient.", "paper_url": "http://arxiv.org/abs/2205.07308v1", "pdf_url": "http://arxiv.org/pdf/2205.07308v1", "repo_url": null}, "2205.07266": {"publish_time": "2022-05-15", "title": "Discovering the Representation Bottleneck of Graph Neural Networks from Multi-order Interactions", "author": "Fang Wu et.al.", "abstract": "Most graph neural networks (GNNs) rely on the message passing paradigm to propagate node features and build interactions. Recent works point out that different graph learning tasks require different ranges of interactions between nodes. To investigate its underlying mechanism, we explore the capacity of GNNs to capture pairwise interactions between nodes under contexts with different complexities, especially for their graph-level and node-level applications in scientific domains like biochemistry and physics. When formulating pairwise interactions, we study two common graph construction methods in scientific domains, i.e., \\emph{K-nearest neighbor} (KNN) graphs and \\emph{fully-connected} (FC) graphs. Furthermore, we demonstrate that the inductive bias introduced by KNN-graphs and FC-graphs hinders GNNs to learn the most informative order of interactions. {Such a phenomenon is broadly shared by several GNNs for different graph learning tasks and forbids GNNs to achieve the global minimum loss, so we name it a \\emph{representation bottleneck}.} To overcome that, we propose a novel graph rewiring approach based on the pairwise interaction strengths to dynamically adjust the reception fields of each node. Extensive experiments in molecular property prediction and dynamic system forecast prove the superiority of our method over state-of-the-art GNN baselines. More importantly, this paper provides a reasonable explanation of why subgraphs play an important role in the determination of graph properties.", "paper_url": "http://arxiv.org/abs/2205.07266v1", "pdf_url": "http://arxiv.org/pdf/2205.07266v1", "repo_url": null}, "2205.07249": {"publish_time": "2022-05-15", "title": "Pocket2Mol: Efficient Molecular Sampling Based on 3D Protein Pockets", "author": "Xingang Peng et.al.", "abstract": "Deep generative models have achieved tremendous success in designing novel drug molecules in recent years. A new thread of works have shown the great potential in advancing the specificity and success rate of in silico drug design by considering the structure of protein pockets. This setting posts fundamental computational challenges in sampling new chemical compounds that could satisfy multiple geometrical constraints imposed by pockets. Previous sampling algorithms either sample in the graph space or only consider the 3D coordinates of atoms while ignoring other detailed chemical structures such as bond types and functional groups. To address the challenge, we develop Pocket2Mol, an E(3)-equivariant generative network composed of two modules: 1) a new graph neural network capturing both spatial and bonding relationships between atoms of the binding pockets and 2) a new efficient algorithm which samples new drug candidates conditioned on the pocket representations from a tractable distribution without relying on MCMC. Experimental results demonstrate that molecules sampled from Pocket2Mol achieve significantly better binding affinity and other drug properties such as druglikeness and synthetic accessibility.", "paper_url": "http://arxiv.org/abs/2205.07249v1", "pdf_url": "http://arxiv.org/pdf/2205.07249v1", "repo_url": null}, "2205.08366": {"publish_time": "2022-05-17", "title": "A Deep-learning Model for Fast Prediction of Vacancy Formation in Diverse Materials", "author": "Kamal Choudhary et.al.", "abstract": "The presence of point defects such as vacancies plays an important role in material design. Here, we demonstrate that a graph neural network (GNN) model trained only on perfect materials can also be used to predict vacancy formation energies ($E_{vac}$) of defect structures without the need for additional training data. Such GNN-based predictions are considerably faster than density functional theory (DFT) calculations with reasonable accuracy and show the potential that GNNs are able to capture a functional form for energy predictions. To test this strategy, we developed a DFT dataset of 508 $E_{vac}$ consisting of 3D elemental solids, alloys, oxides, nitrides, and 2D monolayer materials. We analyzed and discussed the applicability of such direct and fast predictions. We applied the model to predict 192494 $E_{vac}$ for 55723 materials in the JARVIS-DFT database.", "paper_url": "http://arxiv.org/abs/2205.08366v1", "pdf_url": "http://arxiv.org/pdf/2205.08366v1", "repo_url": null}, "2205.08166": {"publish_time": "2022-05-17", "title": "CellTypeGraph: A New Geometric Computer Vision Benchmark", "author": "Lorenzo Cerrone et.al.", "abstract": "Classifying all cells in an organ is a relevant and difficult problem from plant developmental biology. We here abstract the problem into a new benchmark for node classification in a geo-referenced graph. Solving it requires learning the spatial layout of the organ including symmetries. To allow the convenient testing of new geometrical learning methods, the benchmark of Arabidopsis thaliana ovules is made available as a PyTorch data loader, along with a large number of precomputed features. Finally, we benchmark eight recent graph neural network architectures, finding that DeeperGCN currently works best on this problem.", "paper_url": "http://arxiv.org/abs/2205.08166v1", "pdf_url": "http://arxiv.org/pdf/2205.08166v1", "repo_url": "https://github.com/hci-unihd/celltype-graph-benchmark"}, "2205.08332": {"publish_time": "2022-05-16", "title": "Scalable algorithms for physics-informed neural and graph networks", "author": "Khemraj Shukla et.al.", "abstract": "Physics-informed machine learning (PIML) has emerged as a promising new approach for simulating complex physical and biological systems that are governed by complex multiscale processes for which some data are also available. In some instances, the objective is to discover part of the hidden physics from the available data, and PIML has been shown to be particularly effective for such problems for which conventional methods may fail. Unlike commercial machine learning where training of deep neural networks requires big data, in PIML big data are not available. Instead, we can train such networks from additional information obtained by employing the physical laws and evaluating them at random points in the space-time domain. Such physics-informed machine learning integrates multimodality and multifidelity data with mathematical models, and implements them using neural networks or graph networks. Here, we review some of the prevailing trends in embedding physics into machine learning, using physics-informed neural networks (PINNs) based primarily on feed-forward neural networks and automatic differentiation. For more complex systems or systems of systems and unstructured data, graph neural networks (GNNs) present some distinct advantages, and here we review how physics-informed learning can be accomplished with GNNs based on graph exterior calculus to construct differential operators; we refer to these architectures as physics-informed graph networks (PIGNs). We present representative examples for both forward and inverse problems and discuss what advances are needed to scale up PINNs, PIGNs and more broadly GNNs for large-scale engineering problems.", "paper_url": "http://arxiv.org/abs/2205.08332v1", "pdf_url": "http://arxiv.org/pdf/2205.08332v1", "repo_url": null}, "2205.08625": {"publish_time": "2022-05-17", "title": "Generic and Trend-aware Curriculum Learning for Relation Extraction in Graph Neural Networks", "author": "Nidhi Vakil et.al.", "abstract": "We present a generic and trend-aware curriculum learning approach for graph neural networks. It extends existing approaches by incorporating sample-level loss trends to better discriminate easier from harder samples and schedule them for training. The model effectively integrates textual and structural information for relation extraction in text graphs. Experimental results show that the model provides robust estimations of sample difficulty and shows sizable improvement over the state-of-the-art approaches across several datasets.", "paper_url": "http://arxiv.org/abs/2205.08625v1", "pdf_url": "http://arxiv.org/pdf/2205.08625v1", "repo_url": null}, "2205.08619": {"publish_time": "2022-05-17", "title": "A graph representation of molecular ensembles for polymer property prediction", "author": "Matteo Aldeghi et.al.", "abstract": "Synthetic polymers are versatile and widely used materials. Similar to small organic molecules, a large chemical space of such materials is hypothetically accessible. Computational property prediction and virtual screening can accelerate polymer design by prioritizing candidates expected to have favorable properties. However, in contrast to organic molecules, polymers are often not well-defined single structures but an ensemble of similar molecules, which poses unique challenges to traditional chemical representations and machine learning approaches. Here, we introduce a graph representation of molecular ensembles and an associated graph neural network architecture that is tailored to polymer property prediction. We demonstrate that this approach captures critical features of polymeric materials, like chain architecture, monomer stoichiometry, and degree of polymerization, and achieves superior accuracy to off-the-shelf cheminformatics methodologies. While doing so, we built a dataset of simulated electron affinity and ionization potential values for >40k polymers with varying monomer composition, stoichiometry, and chain architecture, which may be used in the development of other tailored machine learning approaches. The dataset and machine learning models presented in this work pave the path toward new classes of algorithms for polymer informatics and, more broadly, introduce a framework for the modeling of molecular ensembles.", "paper_url": "http://arxiv.org/abs/2205.08619v1", "pdf_url": "http://arxiv.org/pdf/2205.08619v1", "repo_url": "https://github.com/coleygroup/polymer-chemprop-data"}, "2205.09702": {"publish_time": "2022-05-19", "title": "Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis", "author": "Maciej Besta et.al.", "abstract": "Graph neural networks (GNNs) are among the most powerful tools in deep learning. They routinely solve complex problems on unstructured networks, such as node classification, graph classification, or link prediction, with high accuracy. However, both inference and training of GNNs are complex, and they uniquely combine the features of irregular graph processing with dense and regular computations. This complexity makes it very challenging to execute GNNs efficiently on modern massively parallel architectures. To alleviate this, we first design a taxonomy of parallelism in GNNs, considering data and model parallelism, and different forms of pipelining. Then, we use this taxonomy to investigate the amount of parallelism in numerous GNN models, GNN-driven machine learning tasks, software frameworks, or hardware accelerators. We use the work-depth model, and we also assess communication volume and synchronization. We specifically focus on the sparsity/density of the associated tensors, in order to understand how to effectively apply techniques such as vectorization. We also formally analyze GNN pipelining, and we generalize the established Message-Passing class of GNN models to cover arbitrary pipeline depths, facilitating future optimizations. Finally, we investigate different forms of asynchronicity, navigating the path for future asynchronous parallel GNN pipelines. The outcomes of our analysis are synthesized in a set of insights that help to maximize GNN performance, and a comprehensive list of challenges and opportunities for further research into efficient GNN computations. Our work will help to advance the design of future GNNs.", "paper_url": "http://arxiv.org/abs/2205.09702v1", "pdf_url": "http://arxiv.org/pdf/2205.09702v1", "repo_url": null}, "2205.09575": {"publish_time": "2022-05-19", "title": "Learning Graph Structure from Convolutional Mixtures", "author": "Max Wasserman et.al.", "abstract": "Machine learning frameworks such as graph neural networks typically rely on a given, fixed graph to exploit relational inductive biases and thus effectively learn from network data. However, when said graphs are (partially) unobserved, noisy, or dynamic, the problem of inferring graph structure from data becomes relevant. In this paper, we postulate a graph convolutional relationship between the observed and latent graphs, and formulate the graph learning task as a network inverse (deconvolution) problem. In lieu of eigendecomposition-based spectral methods or iterative optimization solutions, we unroll and truncate proximal gradient iterations to arrive at a parameterized neural network architecture that we call a Graph Deconvolution Network (GDN). GDNs can learn a distribution of graphs in a supervised fashion, perform link prediction or edge-weight regression tasks by adapting the loss function, and they are inherently inductive. We corroborate GDN's superior graph recovery performance and its generalization to larger graphs using synthetic data in supervised settings. Furthermore, we demonstrate the robustness and representation power of GDNs on real world neuroimaging and social network datasets.", "paper_url": "http://arxiv.org/abs/2205.09575v1", "pdf_url": "http://arxiv.org/pdf/2205.09575v1", "repo_url": null}, "2205.09489": {"publish_time": "2022-05-19", "title": "Spatial Autoregressive Coding for Graph Neural Recommendation", "author": "Jiayi Zheng et.al.", "abstract": "Graph embedding methods including traditional shallow models and deep Graph Neural Networks (GNNs) have led to promising applications in recommendation. Nevertheless, shallow models especially random-walk-based algorithms fail to adequately exploit neighbor proximity in sampled subgraphs or sequences due to their optimization paradigm. GNN-based algorithms suffer from the insufficient utilization of high-order information and easily cause over-smoothing problems when stacking too much layers, which may deteriorate the recommendations of low-degree (long-tail) items, limiting the expressiveness and scalability. In this paper, we propose a novel framework SAC, namely Spatial Autoregressive Coding, to solve the above problems in a unified way. To adequately leverage neighbor proximity and high-order information, we design a novel spatial autoregressive paradigm. Specifically, we first randomly mask multi-hop neighbors and embed the target node by integrating all other surrounding neighbors with an explicit multi-hop attention. Then we reinforce the model to learn a neighbor-predictive coding for the target node by contrasting the coding and the masked neighbors' embedding, equipped with a new hard negative sampling strategy. To learn the minimal sufficient representation for the target-to-neighbor prediction task and remove the redundancy of neighbors, we devise Neighbor Information Bottleneck by maximizing the mutual information between target predictive coding and the masked neighbors' embedding, and simultaneously constraining those between the coding and surrounding neighbors' embedding. Experimental results on both public recommendation datasets and a real scenario web-scale dataset Douyin-Friend-Recommendation demonstrate the superiority of SAC compared with state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2205.09489v1", "pdf_url": "http://arxiv.org/pdf/2205.09489v1", "repo_url": null}, "2205.09389": {"publish_time": "2022-05-19", "title": "Simplifying Node Classification on Heterophilous Graphs with Compatible Label Propagation", "author": "Zhiqiang Zhong et.al.", "abstract": "Graph Neural Networks (GNNs) have been predominant for graph learning tasks; however, recent studies showed that a well-known graph algorithm, Label Propagation (LP), combined with a shallow neural network can achieve comparable performance to GNNs in semi-supervised node classification on graphs with high homophily. In this paper, we show that this approach falls short on graphs with low homophily, where nodes often connect to the nodes of the opposite classes. To overcome this, we carefully design a combination of a base predictor with LP algorithm that enjoys a closed-form solution as well as convergence guarantees. Our algorithm first learns the class compatibility matrix and then aggregates label predictions using LP algorithm weighted by class compatibilities. On a wide variety of benchmarks, we show that our approach achieves the leading performance on graphs with various levels of homophily. Meanwhile, it has orders of magnitude fewer parameters and requires less execution time. Empirical evaluations demonstrate that simple adaptations of LP can be competitive in semi-supervised node classification in both homophily and heterophily regimes.", "paper_url": "http://arxiv.org/abs/2205.09389v1", "pdf_url": "http://arxiv.org/pdf/2205.09389v1", "repo_url": null}, "2205.09363": {"publish_time": "2022-05-19", "title": "Plane Geometry Diagram Parsing", "author": "Ming-Liang Zhang et.al.", "abstract": "Geometry diagram parsing plays a key role in geometry problem solving, wherein the primitive extraction and relation parsing remain challenging due to the complex layout and between-primitive relationship. In this paper, we propose a powerful diagram parser based on deep learning and graph reasoning. Specifically, a modified instance segmentation method is proposed to extract geometric primitives, and the graph neural network (GNN) is leveraged to realize relation parsing and primitive classification incorporating geometric features and prior knowledge. All the modules are integrated into an end-to-end model called PGDPNet to perform all the sub-tasks simultaneously. In addition, we build a new large-scale geometry diagram dataset named PGDP5K with primitive level annotations. Experiments on PGDP5K and an existing dataset IMP-Geometry3K show that our model outperforms state-of-the-art methods in four sub-tasks remarkably. Our code, dataset and appendix material are available at https://github.com/mingliangzhang2018/PGDP.", "paper_url": "http://arxiv.org/abs/2205.09363v1", "pdf_url": "http://arxiv.org/pdf/2205.09363v1", "repo_url": "https://github.com/mingliangzhang2018/PGDP"}, "2205.10282": {"publish_time": "2022-05-20", "title": "Heterformer: A Transformer Architecture for Node Representation Learning on Heterogeneous Text-Rich Networks", "author": "Bowen Jin et.al.", "abstract": "We study node representation learning on heterogeneous text-rich networks, where nodes and edges are multi-typed and some types of nodes are associated with text information. Although recent studies on graph neural networks (GNNs) and pretrained language models (PLMs) have demonstrated their power in encoding network and text signals, respectively, less focus has been given to delicately coupling these two types of models on heterogeneous text-rich networks. Specifically, existing GNNs rarely model text in each node in a contextualized way; existing PLMs can hardly be applied to characterize graph structures due to their sequence architecture. In this paper, we propose Heterformer, a Heterogeneous GNN-nested transformer that blends GNNs and PLMs into a unified model. Different from previous \"cascaded architectures\" that directly add GNN layers upon a PLM, our Heterformer alternately stacks two modules - a graph-attention-based neighbor aggregation module and a transformer-based text and neighbor joint encoding module - to facilitate thorough mutual enhancement between network and text signals. Meanwhile, Heterformer is capable of characterizing network heterogeneity and nodes without text information. Comprehensive experiments on three large-scale datasets from different domains demonstrate the superiority of Heterformer over state-of-the-art baselines in link prediction, transductive/inductive node classification, node clustering, and semantics-based retrieval.", "paper_url": "http://arxiv.org/abs/2205.10282v1", "pdf_url": "http://arxiv.org/pdf/2205.10282v1", "repo_url": null}, "2205.10070": {"publish_time": "2022-05-20", "title": "On the Prediction Instability of Graph Neural Networks", "author": "Max Klabunde et.al.", "abstract": "Instability of trained models, i.e., the dependence of individual node predictions on random factors, can affect reproducibility, reliability, and trust in machine learning systems. In this paper, we systematically assess the prediction instability of node classification with state-of-the-art Graph Neural Networks (GNNs). With our experiments, we establish that multiple instantiations of popular GNN models trained on the same data with the same model hyperparameters result in almost identical aggregated performance but display substantial disagreement in the predictions for individual nodes. We find that up to one third of the incorrectly classified nodes differ across algorithm runs. We identify correlations between hyperparameters, node properties, and the size of the training set with the stability of predictions. In general, maximizing model performance implicitly also reduces model instability.", "paper_url": "http://arxiv.org/abs/2205.10070v1", "pdf_url": "http://arxiv.org/pdf/2205.10070v1", "repo_url": "https://github.com/mklabunde/on-the-prediction-instability-of-graph-neural-networks"}, "2205.09977": {"publish_time": "2022-05-20", "title": "FairNorm: Fair and Fast Graph Neural Network Training", "author": "O. Deniz Kose et.al.", "abstract": "Graph neural networks (GNNs) have been demonstrated to achieve state-of-the-art for a number of graph-based learning tasks, which leads to a rise in their employment in various domains. However, it has been shown that GNNs may inherit and even amplify bias within training data, which leads to unfair results towards certain sensitive groups. Meanwhile, training of GNNs introduces additional challenges, such as slow convergence and possible instability. Faced with these limitations, this work proposes FairNorm, a unified normalization framework that reduces the bias in GNN-based learning while also providing provably faster convergence. Specifically, FairNorm employs fairness-aware normalization operators over different sensitive groups with learnable parameters to reduce the bias in GNNs. The design of FairNorm is built upon analyses that illuminate the sources of bias in graph-based learning. Experiments on node classification over real-world networks demonstrate the efficiency of the proposed scheme in improving fairness in terms of statistical parity and equal opportunity compared to fairness-aware baselines. In addition, it is empirically shown that the proposed framework leads to faster convergence compared to the naive baseline where no normalization is employed.", "paper_url": "http://arxiv.org/abs/2205.09977v1", "pdf_url": "http://arxiv.org/pdf/2205.09977v1", "repo_url": null}, "2205.09968": {"publish_time": "2022-05-20", "title": "A General Framework for quantifying Aleatoric and Epistemic uncertainty in Graph Neural Networks", "author": "Sai Munikoti et.al.", "abstract": "Graph Neural Networks (GNN) provide a powerful framework that elegantly integrates Graph theory with Machine learning for modeling and analysis of networked data. We consider the problem of quantifying the uncertainty in predictions of GNN stemming from modeling errors and measurement uncertainty. We consider aleatoric uncertainty in the form of probabilistic links and noise in feature vector of nodes, while epistemic uncertainty is incorporated via a probability distribution over the model parameters. We propose a unified approach to treat both sources of uncertainty in a Bayesian framework, where Assumed Density Filtering is used to quantify aleatoric uncertainty and Monte Carlo dropout captures uncertainty in model parameters. Finally, the two sources of uncertainty are aggregated to estimate the total uncertainty in predictions of a GNN. Results in the real-world datasets demonstrate that the Bayesian model performs at par with a frequentist model and provides additional information about predictions uncertainty that are sensitive to uncertainties in the data and model.", "paper_url": "http://arxiv.org/abs/2205.09968v1", "pdf_url": "http://arxiv.org/pdf/2205.09968v1", "repo_url": null}, "2205.09948": {"publish_time": "2022-05-20", "title": "GDSRec: Graph-Based Decentralized Collaborative Filtering for Social Recommendation", "author": "Jiajia Chen et.al.", "abstract": "Generating recommendations based on user-item interactions and user-user social relations is a common use case in web-based systems. These connections can be naturally represented as graph-structured data and thus utilizing graph neural networks (GNNs) for social recommendation has become a promising research direction. However, existing graph-based methods fails to consider the bias offsets of users (items). For example, a low rating from a fastidious user may not imply a negative attitude toward this item because the user tends to assign low ratings in common cases. Such statistics should be considered into the graph modeling procedure. While some past work considers the biases, we argue that these proposed methods only treat them as scalars and can not capture the complete bias information hidden in data. Besides, social connections between users should also be differentiable so that users with similar item preference would have more influence on each other. To this end, we propose Graph-Based Decentralized Collaborative Filtering for Social Recommendation (GDSRec). GDSRec treats the biases as vectors and fuses them into the process of learning user and item representations. The statistical bias offsets are captured by decentralized neighborhood aggregation while the social connection strength is defined according to the preference similarity and then incorporated into the model design. We conduct extensive experiments on two benchmark datasets to verify the effectiveness of the proposed model. Experimental results show that the proposed GDSRec achieves superior performance compared with state-of-the-art related baselines. Our implementations are available in \\url{https://github.com/MEICRS/GDSRec}.", "paper_url": "http://arxiv.org/abs/2205.09948v1", "pdf_url": "http://arxiv.org/pdf/2205.09948v1", "repo_url": "https://github.com/meicrs/gdsrec"}, "2205.11343": {"publish_time": "2022-05-23", "title": "Heterogeneous Graph Neural Network for Session-Based Recommendation with User-Session Constraint", "author": "Minjae Park et.al.", "abstract": "The recommendation system provides users with an appropriate limit of recent online large amounts of information. Session-based recommendation, a sub-area of recommender systems, attempts to recommend items by interpreting sessions that consist of sequences of items. Recently, research to include user information in these sessions is progress. However, it is difficult to generate high-quality user information that includes session information generated by user. In this paper, we consider various relationships in graph created by sessions through HAN. Constraints also force user information to take into account information from the session. It seeks to increase performance through additional optimization in the training process. The proposed model outperformed other methods on various real-world data sets.", "paper_url": "http://arxiv.org/abs/2205.11343v1", "pdf_url": "http://arxiv.org/pdf/2205.11343v1", "repo_url": null}, "2205.11322": {"publish_time": "2022-05-23", "title": "Learning heterophilious edge to drop: A general framework for boosting graph neural networks", "author": "Jincheng Huang et.al.", "abstract": "Graph Neural Networks (GNNs) aim at integrating node contents with graph structure to learn nodes/graph representations. Nevertheless, it is found that most of existing GNNs do not work well on data with high heterophily level that accounts for a large proportion of edges between different class labels. Recently, many efforts to tackle this problem focus on optimizing the way of feature learning. From another angle, this work aims at mitigating the negative impacts of heterophily by optimizing graph structure for the first time. Specifically, on assumption that graph smoothing along heterophilious edges can hurt prediction performance, we propose a structure learning method called LHE to identify heterophilious edges to drop. A big advantage of this solution is that it can boost GNNs without careful modification of feature learning strategy. Extensive experiments demonstrate the remarkable performance improvement of GNNs with \\emph{LHE} on multiple datasets across full spectrum of homophily level.", "paper_url": "http://arxiv.org/abs/2205.11322v1", "pdf_url": "http://arxiv.org/pdf/2205.11322v1", "repo_url": null}, "2205.11172": {"publish_time": "2022-05-23", "title": "How Powerful are Spectral Graph Neural Networks", "author": "Xiyuan Wang et.al.", "abstract": "Spectral Graph Neural Network is a kind of Graph Neural Network (GNN) based on graph signal filters, and some models able to learn arbitrary spectral filters have emerged recently. However, few works analyze the expressive power of spectral GNNs. This paper studies spectral GNNs' expressive power theoretically. We first prove that even spectral GNNs without nonlinearity can produce arbitrary graph signals and give two conditions for reaching universality. They are: 1) no multiple eigenvalues of graph Laplacian, and 2) no missing frequency components in node features. We also establish a connection between the expressive power of spectral GNNs and Graph Isomorphism (GI) testing which is often used to characterize spatial GNNs' expressive power. Moreover, we study the difference in empirical performance among different spectral GNNs with the same expressive power from an optimization perspective, and motivate the use of an orthogonal basis whose weight function corresponds to the graph signal density in the spectrum. Inspired by the analysis, we propose JacobiConv, which uses Jacobi polynomial basis due to their orthogonality and flexibility to adapt to a wide range of weight functions. JacobiConv deserts nonlinearity while outperforming all baselines on both synthetic and real-world datasets.", "paper_url": "http://arxiv.org/abs/2205.11172v1", "pdf_url": "http://arxiv.org/pdf/2205.11172v1", "repo_url": null}, "2205.11139": {"publish_time": "2022-05-23", "title": "GraphAD: A Graph Neural Network for Entity-Wise Multivariate Time-Series Anomaly Detection", "author": "Xu Chen et.al.", "abstract": "In recent years, the emergence and development of third-party platforms have greatly facilitated the growth of the Online to Offline (O2O) business. However, the large amount of transaction data raises new challenges for retailers, especially anomaly detection in operating conditions. Thus, platforms begin to develop intelligent business assistants with embedded anomaly detection methods to reduce the management burden on retailers. Traditional time-series anomaly detection methods capture underlying patterns from the perspectives of time and attributes, ignoring the difference between retailers in this scenario. Besides, similar transaction patterns extracted by the platforms can also provide guidance to individual retailers and enrich their available information without privacy issues. In this paper, we pose an entity-wise multivariate time-series anomaly detection problem that considers the time-series of each unique entity. To address this challenge, we propose GraphAD, a novel multivariate time-series anomaly detection model based on the graph neural network. GraphAD decomposes the Key Performance Indicator (KPI) into stable and volatility components and extracts their patterns in terms of attributes, entities and temporal perspectives via graph neural networks. We also construct a real-world entity-wise multivariate time-series dataset from the business data of Ele.me. The experimental results on this dataset show that GraphAD significantly outperforms existing anomaly detection methods.", "paper_url": "http://arxiv.org/abs/2205.11139v1", "pdf_url": "http://arxiv.org/pdf/2205.11139v1", "repo_url": null}, "2205.10652": {"publish_time": "2022-05-21", "title": "Are Graph Neural Networks Really Helpful for Knowledge Graph Completion?", "author": "Juanhui Li et.al.", "abstract": "Knowledge graphs (KGs) facilitate a wide variety of applications due to their ability to store relational knowledge applicable to many areas. Despite great efforts invested in creation and maintenance, even the largest KGs are far from complete. Hence, KG completion (KGC) has become one of the most crucial tasks for KG research. Recently, considerable literature in this space has centered around the use of Graph Neural Networks (GNNs) to learn powerful embeddings which leverage topological structures in the KGs. Specifically, dedicated efforts have been made to extend GNNs, which are commonly designed for simple homogeneous and uni-relational graphs, to the KG context which has diverse and multi-relational connections between entities, by designing more complex aggregation schemes over neighboring nodes (crucial to GNN performance) to appropriately leverage multi-relational information. The success of these methods is naturally attributed to the use of GNNs over simpler multi-layer perceptron (MLP) models, owing to their additional aggregation functionality. In this work, we find that surprisingly, simple MLP models are able to achieve comparable performance to GNNs, suggesting that aggregation may not be as crucial as previously believed. With further exploration, we show careful scoring function and loss function design has a much stronger influence on KGC model performance, and aggregation is not practically required. This suggests a conflation of scoring function design, loss function design, and aggregation in prior work, with promising insights regarding the scalability of state-of-the-art KGC methods today, as well as careful attention to more suitable aggregation designs for KGC tasks tomorrow.", "paper_url": "http://arxiv.org/abs/2205.10652v1", "pdf_url": "http://arxiv.org/pdf/2205.10652v1", "repo_url": null}, "2205.12245": {"publish_time": "2022-05-24", "title": "Asynchronous Neural Networks for Learning in Graphs", "author": "Lukas Faber et.al.", "abstract": "This paper studies asynchronous message passing (AMP), a new paradigm for applying neural network based learning to graphs. Existing graph neural networks use the synchronous distributed computing model and aggregate their neighbors in each round, which causes problems such as oversmoothing and limits their expressiveness. On the other hand, AMP is based on the asynchronous model, where nodes react to messages of their neighbors individually. We prove that (i) AMP can simulate synchronous GNNs and that (ii) AMP can theoretically distinguish any pair of graphs. We experimentally validate AMP's expressiveness. Further, we show that AMP might be better suited to propagate messages over large distances in graphs and performs well on several graph classification benchmarks.", "paper_url": "http://arxiv.org/abs/2205.12245v1", "pdf_url": "http://arxiv.org/pdf/2205.12245v1", "repo_url": null}, "2205.12179": {"publish_time": "2022-05-24", "title": "Evidential Temporal-aware Graph-based Social Event Detection via Dempster-Shafer Theory", "author": "Jiaqian Ren et.al.", "abstract": "The rising popularity of online social network services has attracted lots of research on mining social media data, especially on mining social events. Social event detection, due to its wide applications, has now become a trivial task. State-of-the-art approaches exploiting Graph Neural Networks (GNNs) usually follow a two-step strategy: 1) constructing text graphs based on various views (\\textit{co-user}, \\textit{co-entities} and \\textit{co-hashtags}); and 2) learning a unified text representation by a specific GNN model. Generally, the results heavily rely on the quality of the constructed graphs and the specific message passing scheme. However, existing methods have deficiencies in both aspects: 1) They fail to recognize the noisy information induced by unreliable views. 2) Temporal information which works as a vital indicator of events is neglected in most works. To this end, we propose ETGNN, a novel Evidential Temporal-aware Graph Neural Network. Specifically, we construct view-specific graphs whose nodes are the texts and edges are determined by several types of shared elements respectively. To incorporate temporal information into the message passing scheme, we introduce a novel temporal-aware aggregator which assigns weights to neighbours according to an adaptive time exponential decay formula. Considering the view-specific uncertainty, the representations of all views are converted into mass functions through evidential deep learning (EDL) neural networks, and further combined via Dempster-Shafer theory (DST) to make the final detection. Experimental results on three real-world datasets demonstrate the effectiveness of ETGNN in accuracy, reliability and robustness in social event detection.", "paper_url": "http://arxiv.org/abs/2205.12179v1", "pdf_url": "http://arxiv.org/pdf/2205.12179v1", "repo_url": null}, "2205.12156": {"publish_time": "2022-05-24", "title": "Not too little, not too much: a theoretical analysis of graph (over)smoothing", "author": "Nicolas Keriven et.al.", "abstract": "We analyze graph smoothing with \\emph{mean aggregation}, where each node successively receives the average of the features of its neighbors. Indeed, it has quickly been observed that Graph Neural Networks (GNNs), which generally follow some variant of Message-Passing (MP) with repeated aggregation, may be subject to the \\emph{oversmoothing} phenomenon: by performing too many rounds of MP, the node features tend to converge to a non-informative limit. In the case of mean aggregation, for connected graphs, the node features become constant across the whole graph. At the other end of the spectrum, it is intuitively obvious that \\emph{some} MP rounds are necessary, but existing analyses do not exhibit both phenomena at once: beneficial ``finite'' smoothing and oversmoothing in the limit. In this paper, we consider simplified linear GNNs, and rigorously analyze two examples for which a finite number of mean aggregation steps provably improves the learning performance, before oversmoothing kicks in. We consider a latent space random graph model, where node features are partial observations of the latent variables and the graph contains pairwise relationships between them. We show that graph smoothing restores some of the lost information, up to a certain point, by two phenomenon: graph smoothing shrinks non-principal directions in the data faster than principal ones, which is useful for regression, and shrinks nodes within communities faster than they collapse together, which improves classification.", "paper_url": "http://arxiv.org/abs/2205.12156v1", "pdf_url": "http://arxiv.org/pdf/2205.12156v1", "repo_url": "https://github.com/nkeriven/graphsmoothing"}, "2205.12076": {"publish_time": "2022-05-24", "title": "Ensemble Multi-Relational Graph Neural Networks", "author": "Yuling Wang et.al.", "abstract": "It is well established that graph neural networks (GNNs) can be interpreted and designed from the perspective of optimization objective. With this clear optimization objective, the deduced GNNs architecture has sound theoretical foundation, which is able to flexibly remedy the weakness of GNNs. However, this optimization objective is only proved for GNNs with single-relational graph. Can we infer a new type of GNNs for multi-relational graphs by extending this optimization objective, so as to simultaneously solve the issues in previous multi-relational GNNs, e.g., over-parameterization? In this paper, we propose a novel ensemble multi-relational GNNs by designing an ensemble multi-relational (EMR) optimization objective. This EMR optimization objective is able to derive an iterative updating rule, which can be formalized as an ensemble message passing (EnMP) layer with multi-relations. We further analyze the nice properties of EnMP layer, e.g., the relationship with multi-relational personalized PageRank. Finally, a new multi-relational GNNs which well alleviate the over-smoothing and over-parameterization issues are proposed. Extensive experiments conducted on four benchmark datasets well demonstrate the effectiveness of the proposed model.", "paper_url": "http://arxiv.org/abs/2205.12076v1", "pdf_url": "http://arxiv.org/pdf/2205.12076v1", "repo_url": null}, "2205.11912": {"publish_time": "2022-05-24", "title": "Physics-Embedded Neural Networks: $\\boldsymbol{\\mathrm{E}(n)}$-Equivariant Graph Neural PDE Solvers", "author": "Masanobu Horie et.al.", "abstract": "Graph neural network (GNN) is a promising approach to learning and predicting physical phenomena described in boundary value problems, such as partial differential equations (PDEs) with boundary conditions. However, existing models inadequately treat boundary conditions essential for the reliable prediction of such problems. In addition, because of the locally connected nature of GNNs, it is difficult to accurately predict the state after a long time, where interaction between vertices tends to be global. We present our approach termed physics-embedded neural networks that considers boundary conditions and predicts the state after a long time using an implicit method. It is built based on an $\\mathrm{E}(n)$-equivariant GNN, resulting in high generalization performance on various shapes. We demonstrate that our model learns flow phenomena in complex shapes and outperforms a well-optimized classical solver and a state-of-the-art machine learning model in speed-accuracy trade-off. Therefore, our model can be a useful standard for realizing reliable, fast, and accurate GNN-based PDE solvers.", "paper_url": "http://arxiv.org/abs/2205.11912v1", "pdf_url": "http://arxiv.org/pdf/2205.11912v1", "repo_url": null}, "2205.12888": {"publish_time": "2022-05-25", "title": "Robust Reinforcement Learning on Graphs for Logistics optimization", "author": "Zangir Iklassov et.al.", "abstract": "Logistics optimization nowadays is becoming one of the hottest areas in the AI community. In the past year, significant advancements in the domain were achieved by representing the problem in a form of graph. Another promising area of research was to apply reinforcement learning algorithms to the above task. In our work, we made advantage of using both approaches and apply reinforcement learning on a graph. To do that, we have analyzed the most recent results in both fields and selected SOTA algorithms both from graph neural networks and reinforcement learning. Then, we combined selected models on the problem of AMOD systems optimization for the transportation network of New York city. Our team compared three algorithms - GAT, Pro-CNN and PTDNet - to bring to the fore the important nodes on a graph representation. Finally, we achieved SOTA results on AMOD systems optimization problem employing PTDNet with GNN and training them in reinforcement fashion.   Keywords: Graph Neural Network (GNN), Logistics optimization, Reinforcement Learning", "paper_url": "http://arxiv.org/abs/2205.12888v1", "pdf_url": "http://arxiv.org/pdf/2205.12888v1", "repo_url": null}, "2205.12784": {"publish_time": "2022-05-25", "title": "TrustGNN: Graph Neural Network based Trust Evaluation via Learnable Propagative and Composable Nature", "author": "Cuiying Huo et.al.", "abstract": "Trust evaluation is critical for many applications such as cyber security, social communication and recommender systems. Users and trust relationships among them can be seen as a graph. Graph neural networks (GNNs) show their powerful ability for analyzing graph-structural data. Very recently, existing work attempted to introduce the attributes and asymmetry of edges into GNNs for trust evaluation, while failed to capture some essential properties (e.g., the propagative and composable nature) of trust graphs. In this work, we propose a new GNN based trust evaluation method named TrustGNN, which integrates smartly the propagative and composable nature of trust graphs into a GNN framework for better trust evaluation. Specifically, TrustGNN designs specific propagative patterns for different propagative processes of trust, and distinguishes the contribution of different propagative processes to create new trust. Thus, TrustGNN can learn comprehensive node embeddings and predict trust relationships based on these embeddings. Experiments on some widely-used real-world datasets indicate that TrustGNN significantly outperforms the state-of-the-art methods. We further perform analytical experiments to demonstrate the effectiveness of the key designs in TrustGNN.", "paper_url": "http://arxiv.org/abs/2205.12784v1", "pdf_url": "http://arxiv.org/pdf/2205.12784v1", "repo_url": null}, "2205.12711": {"publish_time": "2022-05-25", "title": "Service Discovery in Social Internet of Things using Graph Neural Networks", "author": "Aymen Hamrouni et.al.", "abstract": "Internet-of-Things (IoT) networks intelligently connect thousands of physical entities to provide various services for the community. It is witnessing an exponential expansion, which is complicating the process of discovering IoT devices existing in the network and requesting corresponding services from them. As the highly dynamic nature of the IoT environment hinders the use of traditional solutions of service discovery, we aim, in this paper, to address this issue by proposing a scalable resource allocation neural model adequate for heterogeneous large-scale IoT networks. We devise a Graph Neural Network (GNN) approach that utilizes the social relationships formed between the devices in the IoT network to reduce the search space of any entity lookup and acquire a service from another device in the network. This proposed resource allocation approach surpasses standardization issues and embeds the structure and characteristics of the social IoT graph, by the means of GNNs, for eventual clustering analysis process. Simulation results applied on a real-world dataset illustrate the performance of this solution and its significant efficiency to operate on large-scale IoT networks.", "paper_url": "http://arxiv.org/abs/2205.12711v1", "pdf_url": "http://arxiv.org/pdf/2205.12711v1", "repo_url": null}, "2205.12583": {"publish_time": "2022-05-25", "title": "MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose", "author": "Chenyan Wu et.al.", "abstract": "Reconstructing multi-human body mesh from a single monocular image is an important but challenging computer vision problem. In addition to the individual body mesh models, we need to estimate relative 3D positions among subjects to generate a coherent representation. In this work, through a single graph neural network, named MUG (Multi-hUman Graph network), we construct coherent multi-human meshes using only multi-human 2D pose as input. Compared with existing methods, which adopt a detection-style pipeline (i.e., extracting image features and then locating human instances and recovering body meshes from that) and suffer from the significant domain gap between lab-collected training datasets and in-the-wild testing datasets, our method benefits from the 2D pose which has a relatively consistent geometric property across datasets. Our method works like the following: First, to model the multi-human environment, it processes multi-human 2D poses and builds a novel heterogeneous graph, where nodes from different people and within one person are connected to capture inter-human interactions and draw the body geometry (i.e., skeleton and mesh structure). Second, it employs a dual-branch graph neural network structure -- one for predicting inter-human depth relation and the other one for predicting root-joint-relative mesh coordinates. Finally, the entire multi-human 3D meshes are constructed by combining the output from both branches. Extensive experiments demonstrate that MUG outperforms previous multi-human mesh estimation methods on standard 3D human benchmarks -- Panoptic, MuPoTS-3D and 3DPW.", "paper_url": "http://arxiv.org/abs/2205.12583v1", "pdf_url": "http://arxiv.org/pdf/2205.12583v1", "repo_url": null}, "2205.12465": {"publish_time": "2022-05-25", "title": "FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain Network Generation", "author": "Xuan Kan et.al.", "abstract": "Functional magnetic resonance imaging (fMRI) is one of the most common imaging modalities to investigate brain functions. Recent studies in neuroscience stress the great potential of functional brain networks constructed from fMRI data for clinical predictions. Traditional functional brain networks, however, are noisy and unaware of downstream prediction tasks, while also incompatible with the deep graph neural network (GNN) models. In order to fully unleash the power of GNNs in network-based fMRI analysis, we develop FBNETGEN, a task-aware and interpretable fMRI analysis framework via deep brain network generation. In particular, we formulate (1) prominent region of interest (ROI) features extraction, (2) brain networks generation, and (3) clinical predictions with GNNs, in an end-to-end trainable model under the guidance of particular prediction tasks. Along with the process, the key novel component is the graph generator which learns to transform raw time-series features into task-oriented brain networks. Our learnable graphs also provide unique interpretations by highlighting prediction-related brain regions. Comprehensive experiments on two datasets, i.e., the recently released and currently largest publicly available fMRI dataset Adolescent Brain Cognitive Development (ABCD), and the widely-used fMRI dataset PNC, prove the superior effectiveness and interpretability of FBNETGEN. The implementation is available at https://github.com/Wayfear/FBNETGEN.}", "paper_url": "http://arxiv.org/abs/2205.12465v1", "pdf_url": "http://arxiv.org/pdf/2205.12465v1", "repo_url": "https://github.com/wayfear/fbnetgen"}, "2205.13492": {"publish_time": "2022-05-26", "title": "Sparse Graph Learning for Spatiotemporal Time Series", "author": "Andrea Cini et.al.", "abstract": "Outstanding achievements of graph neural networks for spatiotemporal time series prediction show that relational constraints introduce a positive inductive bias into neural forecasting architectures. Often, however, the relational information characterizing the underlying data generating process is unavailable; the practitioner is then left with the problem of inferring from data which relational graph to use in the subsequent processing stages. We propose novel, principled -- yet practical -- probabilistic methods that learn the relational dependencies by modeling distributions over graphs while maximizing, at the same time, end-to-end the forecasting accuracy. Our novel graph learning approach, based on consolidated variance reduction techniques for Monte Carlo score-based gradient estimation, is theoretically grounded and effective. We show that tailoring the gradient estimators to the graph learning problem allows us also for achieving state-of-the-art forecasting performance while controlling, at the same time, both the sparsity of the learned graph and the computational burden. We empirically assess the effectiveness of the proposed method on synthetic and real-world benchmarks, showing that the proposed solution can be used as a stand-alone graph identification procedure as well as a learned component of an end-to-end forecasting architecture.", "paper_url": "http://arxiv.org/abs/2205.13492v1", "pdf_url": "http://arxiv.org/pdf/2205.13492v1", "repo_url": null}, "2205.13479": {"publish_time": "2022-05-26", "title": "Learning to Reconstruct Missing Data from Spatiotemporal Graphs with Sparse Observations", "author": "Ivan Marisca et.al.", "abstract": "Modeling multivariate time series as temporal signals over a (possibly dynamic) graph is an effective representational framework that allows for developing models for time series analysis. In fact, discrete sequences of graphs can be processed by autoregressive graph neural networks to recursively learn representations at each discrete point in time and space. Spatiotemporal graphs are often highly sparse, with time series characterized by multiple, concurrent, and even long sequences of missing data, e.g., due to the unreliable underlying sensor network. In this context, autoregressive models can be brittle and exhibit unstable learning dynamics. The objective of this paper is, then, to tackle the problem of learning effective models to reconstruct, i.e., impute, missing data points by conditioning the reconstruction only on the available observations. In particular, we propose a novel class of attention-based architectures that, given a set of highly sparse discrete observations, learn a representation for points in time and space by exploiting a spatiotemporal diffusion architecture aligned with the imputation task. Representations are trained end-to-end to reconstruct observations w.r.t. the corresponding sensor and its neighboring nodes. Compared to the state of the art, our model handles sparse data without propagating prediction errors or requiring a bidirectional model to encode forward and backward time dependencies. Empirical results on representative benchmarks show the effectiveness of the proposed method.", "paper_url": "http://arxiv.org/abs/2205.13479v1", "pdf_url": "http://arxiv.org/pdf/2205.13479v1", "repo_url": null}, "2205.13328": {"publish_time": "2022-05-26", "title": "How Powerful are K-hop Message Passing Graph Neural Networks", "author": "Jiarui Feng et.al.", "abstract": "The most popular design paradigm for Graph Neural Networks (GNNs) is 1-hop message passing -- aggregating features from 1-hop neighbors repeatedly. However, the expressive power of 1-hop message passing is bounded by the Weisfeiler-Lehman (1-WL) test. Recently, researchers extended 1-hop message passing to K-hop message passing by aggregating information from K-hop neighbors of nodes simultaneously. However, there is no work on analyzing the expressive power of K-hop message passing. In this work, we theoretically characterize the expressive power of K-hop message passing. Specifically, we first formally differentiate two kinds of kernels of K-hop message passing which are often misused in previous works. We then characterize the expressive power of K-hop message passing by showing that it is more powerful than 1-hop message passing. Despite the higher expressive power, we show that K-hop message passing still cannot distinguish some simple regular graphs. To further enhance its expressive power, we introduce a KP-GNN framework, which improves K-hop message passing by leveraging the peripheral subgraph information in each hop. We prove that KP-GNN can distinguish almost all regular graphs including some distance regular graphs which could not be distinguished by previous distance encoding methods. Experimental results verify the expressive power and effectiveness of KP-GNN. KP-GNN achieves competitive results across all benchmark datasets.", "paper_url": "http://arxiv.org/abs/2205.13328v1", "pdf_url": "http://arxiv.org/pdf/2205.13328v1", "repo_url": null}, "2205.13234": {"publish_time": "2022-05-26", "title": "DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees", "author": "Peter M\u00fcller et.al.", "abstract": "We propose the fully explainable Decision Tree Graph Neural Network (DT+GNN) architecture. In contrast to existing black-box GNNs and post-hoc explanation methods, the reasoning of DT+GNN can be inspected at every step. To achieve this, we first construct a differentiable GNN layer, which uses a categorical state space for nodes and messages. This allows us to convert the trained MLPs in the GNN into decision trees. These trees are pruned using our newly proposed method to ensure they are small and easy to interpret. We can also use the decision trees to compute traditional explanations. We demonstrate on both real-world datasets and synthetic GNN explainability benchmarks that this architecture works as well as traditional GNNs. Furthermore, we leverage the explainability of DT+GNNs to find interesting insights into many of these datasets, with some surprising results. We also provide an interactive web tool to inspect DT+GNN's decision making.", "paper_url": "http://arxiv.org/abs/2205.13234v1", "pdf_url": "http://arxiv.org/pdf/2205.13234v1", "repo_url": null}, "2205.13084": {"publish_time": "2022-05-25", "title": "BRIGHT -- Graph Neural Networks in Real-Time Fraud Detection", "author": "Mingxuan Lu et.al.", "abstract": "Detecting fraudulent transactions is an essential component to control risk in e-commerce marketplaces. Apart from rule-based and machine learning filters that are already deployed in production, we want to enable efficient real-time inference with graph neural networks (GNNs), which is useful to catch multihop risk propagation in a transaction graph. However, two challenges arise in the implementation of GNNs in production. First, future information in a dynamic graph should not be considered in message passing to predict the past. Second, the latency of graph query and GNN model inference is usually up to hundreds of milliseconds, which is costly for some critical online services. To tackle these challenges, we propose a Batch and Real-time Inception GrapH Topology (BRIGHT) framework to conduct an end-to-end GNN learning that allows efficient online real-time inference. BRIGHT framework consists of a graph transformation module (Two-Stage Directed Graph) and a corresponding GNN architecture (Lambda Neural Network). The Two-Stage Directed Graph guarantees that the information passed through neighbors is only from the historical payment transactions. It consists of two subgraphs representing historical relationships and real-time links, respectively. The Lambda Neural Network decouples inference into two stages: batch inference of entity embeddings and real-time inference of transaction prediction. Our experiments show that BRIGHT outperforms the baseline models by >2\\% in average w.r.t.~precision. Furthermore, BRIGHT is computationally efficient for real-time fraud detection. Regarding end-to-end performance (including neighbor query and inference), BRIGHT can reduce the P99 latency by >75\\%. For the inference stage, our speedup is on average 7.8$\\times$ compared to the traditional GNN.", "paper_url": "http://arxiv.org/abs/2205.13084v1", "pdf_url": "http://arxiv.org/pdf/2205.13084v1", "repo_url": null}, "2205.14109": {"publish_time": "2022-05-27", "title": "Bayesian Robust Graph Contrastive Learning", "author": "Yancheng Wang et.al.", "abstract": "Graph Neural Networks (GNNs) have been widely used to learn node representations and with outstanding performance on various tasks such as node classification. However, noise, which inevitably exists in real-world graph data, would considerably degrade the performance of GNNs as the noise is easily propagated via the graph structure. In this work, we propose a novel and robust method, Bayesian Robust Graph Contrastive Learning (BRGCL), which trains a GNN encoder to learn robust node representations. The BRGCL encoder is a completely unsupervised encoder. Two steps are iteratively executed at each epoch of training the BRGCL encoder: (1) estimating confident nodes and computing robust cluster prototypes of node representations through a novel Bayesian nonparametric method; (2) prototypical contrastive learning between the node representations and the robust cluster prototypes. Experiments on public and large-scale benchmarks demonstrate the superior performance of BRGCL and the robustness of the learned node representations. The code of BRGCL is available at \\url{https://github.com/BRGCL-code/BRGCL-code}.", "paper_url": "http://arxiv.org/abs/2205.14109v1", "pdf_url": "http://arxiv.org/pdf/2205.14109v1", "repo_url": "https://github.com/brgcl-code/brgcl-code"}, "2205.14105": {"publish_time": "2022-05-27", "title": "Learning to Solve Combinatorial Graph Partitioning Problems via Efficient Exploration", "author": "Thomas D. Barrett et.al.", "abstract": "From logistics to the natural sciences, combinatorial optimisation on graphs underpins numerous real-world applications. Reinforcement learning (RL) has shown particular promise in this setting as it can adapt to specific problem structures and does not require pre-solved instances for these, often NP-hard, problems. However, state-of-the-art (SOTA) approaches typically suffer from severe scalability issues, primarily due to their reliance on expensive graph neural networks (GNNs) at each decision step. We introduce ECORD; a novel RL algorithm that alleviates this expense by restricting the GNN to a single pre-processing step, before entering a fast-acting exploratory phase directed by a recurrent unit. Experimentally, ECORD achieves a new SOTA for RL algorithms on the Maximum Cut problem, whilst also providing orders of magnitude improvement in speed and scalability. Compared to the nearest competitor, ECORD reduces the optimality gap by up to 73% on 500 vertex graphs with a decreased wall-clock time. Moreover, ECORD retains strong performance when generalising to larger graphs with up to 10000 vertices.", "paper_url": "http://arxiv.org/abs/2205.14105v1", "pdf_url": "http://arxiv.org/pdf/2205.14105v1", "repo_url": "https://github.com/tomdbar/ecord"}, "2205.14092": {"publish_time": "2022-05-27", "title": "Capturing Graphs with Hypo-Elliptic Diffusions", "author": "Csaba Toth et.al.", "abstract": "Convolutional layers within graph neural networks operate by aggregating information about local neighbourhood structures; one common way to encode such substructures is through random walks. The distribution of these random walks evolves according to a diffusion equation defined using the graph Laplacian. We extend this approach by leveraging classic mathematical results about hypo-elliptic diffusions. This results in a novel tensor-valued graph operator, which we call the hypo-elliptic graph Laplacian. We provide theoretical guarantees and efficient low-rank approximation algorithms. In particular, this gives a structured approach to capture long-range dependencies on graphs that is robust to pooling. Besides the attractive theoretical properties, our experiments show that this method competes with graph transformers on datasets requiring long-range reasoning but scales only linearly in the number of edges as opposed to quadratically in nodes.", "paper_url": "http://arxiv.org/abs/2205.14092v1", "pdf_url": "http://arxiv.org/pdf/2205.14092v1", "repo_url": "https://github.com/tgcsaba/graph2tens"}, "2205.13988": {"publish_time": "2022-05-27", "title": "Deep Ensembles for Graphs with Higher-order Dependencies", "author": "Steven J. Krieg et.al.", "abstract": "Graph neural networks (GNNs) continue to achieve state-of-the-art performance on many graph learning tasks, but rely on the assumption that a given graph is a sufficient approximation of the true neighborhood structure. In the presence of higher-order sequential dependencies, we show that the tendency of traditional graph representations to underfit each node's neighborhood causes existing GNNs to generalize poorly. To address this, we propose a novel Deep Graph Ensemble (DGE), which captures neighborhood variance by training an ensemble of GNNs on different neighborhood subspaces of the same node within a higher-order network structure. We show that DGE consistently outperforms existing GNNs on semisupervised and supervised tasks on four real-world data sets with known higher-order dependencies, even under a similar parameter budget. We demonstrate that learning diverse and accurate base classifiers is central to DGE's success, and discuss the implications of these findings for future work on GNNs.", "paper_url": "http://arxiv.org/abs/2205.13988v1", "pdf_url": "http://arxiv.org/pdf/2205.13988v1", "repo_url": null}, "2205.13954": {"publish_time": "2022-05-27", "title": "Geometer: Graph Few-Shot Class-Incremental Learning via Prototype Representation", "author": "Bin Lu et.al.", "abstract": "With the tremendous expansion of graphs data, node classification shows its great importance in many real-world applications. Existing graph neural network based methods mainly focus on classifying unlabeled nodes within fixed classes with abundant labeling. However, in many practical scenarios, graph evolves with emergence of new nodes and edges. Novel classes appear incrementally along with few labeling due to its newly emergence or lack of exploration. In this paper, we focus on this challenging but practical graph few-shot class-incremental learning (GFSCIL) problem and propose a novel method called Geometer. Instead of replacing and retraining the fully connected neural network classifer, Geometer predicts the label of a node by finding the nearest class prototype. Prototype is a vector representing a class in the metric space. With the pop-up of novel classes, Geometer learns and adjusts the attention-based prototypes by observing the geometric proximity, uniformity and separability. Teacher-student knowledge distillation and biased sampling are further introduced to mitigate catastrophic forgetting and unbalanced labeling problem respectively. Experimental results on four public datasets demonstrate that Geometer achieves a substantial improvement of 9.46% to 27.60% over state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2205.13954v1", "pdf_url": "http://arxiv.org/pdf/2205.13954v1", "repo_url": null}, "2205.15217": {"publish_time": "2022-05-30", "title": "GraphWalks: Efficient Shape Agnostic Geodesic Shortest Path Estimation", "author": "Rolandos Alexandros Potamias et.al.", "abstract": "Geodesic paths and distances are among the most popular intrinsic properties of 3D surfaces. Traditionally, geodesic paths on discrete polygon surfaces were computed using shortest path algorithms, such as Dijkstra. However, such algorithms have two major limitations. They are non-differentiable which limits their direct usage in learnable pipelines and they are considerably time demanding. To address such limitations and alleviate the computational burden, we propose a learnable network to approximate geodesic paths. The proposed method is comprised by three major components: a graph neural network that encodes node positions in a high dimensional space, a path embedding that describes previously visited nodes and a point classifier that selects the next point in the path. The proposed method provides efficient approximations of the shortest paths and geodesic distances estimations. Given that all of the components of our method are fully differentiable, it can be directly plugged into any learnable pipeline as well as customized under any differentiable constraint. We extensively evaluate the proposed method with several qualitative and quantitative experiments.", "paper_url": "http://arxiv.org/abs/2205.15217v1", "pdf_url": "http://arxiv.org/pdf/2205.15217v1", "repo_url": null}, "2205.15117": {"publish_time": "2022-05-30", "title": "OOD Link Prediction Generalization Capabilities of Message-Passing GNNs in Larger Test Graphs", "author": "Yangze Zhou et.al.", "abstract": "This work provides the first theoretical study on the ability of graph Message Passing Neural Networks (gMPNNs) -- such as Graph Neural Networks (GNNs) -- to perform inductive out-of-distribution (OOD) link prediction tasks, where deployment (test) graph sizes are larger than training graphs. We first prove non-asymptotic bounds showing that link predictors based on permutation-equivariant (structural) node embeddings obtained by gMPNNs can converge to a random guess as test graphs get larger. We then propose a theoretically-sound gMPNN that outputs structural pairwise (2-node) embeddings and prove non-asymptotic bounds showing that, as test graphs grow, these embeddings converge to embeddings of a continuous function that retains its ability to predict links OOD. Empirical results on random graphs show agreement with our theoretical results.", "paper_url": "http://arxiv.org/abs/2205.15117v1", "pdf_url": "http://arxiv.org/pdf/2205.15117v1", "repo_url": null}, "2205.15083": {"publish_time": "2022-05-30", "title": "CGMN: A Contrastive Graph Matching Network for Self-Supervised Graph Similarity Learning", "author": "Di Jin et.al.", "abstract": "Graph similarity learning refers to calculating the similarity score between two graphs, which is required in many realistic applications, such as visual tracking, graph classification, and collaborative filtering. As most of the existing graph neural networks yield effective graph representations of a single graph, little effort has been made for jointly learning two graph representations and calculating their similarity score. In addition, existing unsupervised graph similarity learning methods are mainly clustering-based, which ignores the valuable information embodied in graph pairs. To this end, we propose a contrastive graph matching network (CGMN) for self-supervised graph similarity learning in order to calculate the similarity between any two input graph objects. Specifically, we generate two augmented views for each graph in a pair respectively. Then, we employ two strategies, namely cross-view interaction and cross-graph interaction, for effective node representation learning. The former is resorted to strengthen the consistency of node representations in two views. The latter is utilized to identify node differences between different graphs. Finally, we transform node representations into graph-level representations via pooling operations for graph similarity computation. We have evaluated CGMN on eight real-world datasets, and the experiment results show that the proposed new approach is superior to the state-of-the-art methods in graph similarity learning downstream tasks.", "paper_url": "http://arxiv.org/abs/2205.15083v1", "pdf_url": "http://arxiv.org/pdf/2205.15083v1", "repo_url": null}, "2205.14931": {"publish_time": "2022-05-30", "title": "A multimedia recommendation model based on collaborative graph", "author": "Breda Lim et.al.", "abstract": "As one of the main solutions to the information overload problem, recommender systems are widely used in daily life. In the recent emerging micro-video recommendation scenario, micro-videos contain rich multimedia information, involving text, image, video and other multimodal data, and these rich multimodal information conceals users' deep interest in the items. Most of the current recommendation algorithms based on multimodal data use multimodal information to expand the information on the item side, but ignore the different preferences of users for different modal information, and lack the fine-grained mining of the internal connection of multimodal information. To investigate the problems in the micro-video recommendr system mentioned above, we design a hybrid recommendation model based on multimodal information, introduces multimodal information and user-side auxiliary information in the network structure, fully explores the deep interest of users, measures the importance of each dimension of user and item feature representation in the scoring prediction task, makes the application of graph neural network in the recommendation system is improved by using an attention mechanism to fuse the multi-layer state output information, allowing the shallow structural features provided by the intermediate layer to better participate in the prediction task. The recommendation accuracy is improved compared with the traditional recommendation algorithm on different data sets, and the feasibility and effectiveness of our model is verified.", "paper_url": "http://arxiv.org/abs/2205.14931v1", "pdf_url": "http://arxiv.org/pdf/2205.14931v1", "repo_url": null}, "2205.14831": {"publish_time": "2022-05-30", "title": "Temporal Multiresolution Graph Neural Networks For Epidemic Prediction", "author": "Truong Son Hy et.al.", "abstract": "In this paper, we introduce Temporal Multiresolution Graph Neural Networks (TMGNN), the first architecture that both learns to construct the multiscale and multiresolution graph structures and incorporates the time-series signals to capture the temporal changes of the dynamic graphs. We have applied our proposed model to the task of predicting future spreading of epidemic and pandemic based on the historical time-series data collected from the actual COVID-19 pandemic and chickenpox epidemic in several European countries, and have obtained competitive results in comparison to other previous state-of-the-art temporal architectures and graph learning algorithms. We have shown that capturing the multiscale and multiresolution structures of graphs is important to extract either local or global information that play a critical role in understanding the dynamic of a global pandemic such as COVID-19 which started from a local city and spread to the whole world. Our work brings a promising research direction in forecasting and mitigating future epidemics and pandemics.", "paper_url": "http://arxiv.org/abs/2205.14831v1", "pdf_url": "http://arxiv.org/pdf/2205.14831v1", "repo_url": null}, "2205.15924": {"publish_time": "2022-05-31", "title": "Continuous Temporal Graph Networks for Event-Based Graph Data", "author": "Jin Guo et.al.", "abstract": "There has been an increasing interest in modeling continuous-time dynamics of temporal graph data. Previous methods encode time-evolving relational information into a low-dimensional representation by specifying discrete layers of neural networks, while real-world dynamic graphs often vary continuously over time. Hence, we propose Continuous Temporal Graph Networks (CTGNs) to capture the continuous dynamics of temporal graph data. We use both the link starting timestamps and link duration as evolving information to model the continuous dynamics of nodes. The key idea is to use neural ordinary differential equations (ODE) to characterize the continuous dynamics of node representations over dynamic graphs. We parameterize ordinary differential equations using a novel graph neural network. The existing dynamic graph networks can be considered as a specific discretization of CTGNs. Experiment results on both transductive and inductive tasks demonstrate the effectiveness of our proposed approach over competitive baselines.", "paper_url": "http://arxiv.org/abs/2205.15924v1", "pdf_url": "http://arxiv.org/pdf/2205.15924v1", "repo_url": null}, "2205.15856": {"publish_time": "2022-05-31", "title": "coVariance Neural Networks", "author": "Saurabh Sihag et.al.", "abstract": "Graph neural networks (GNN) are an effective framework that exploit inter-relationships within graph-structured data for learning. Principal component analysis (PCA) involves the projection of data on the eigenspace of the covariance matrix and draws similarities with the graph convolutional filters in GNNs. Motivated by this observation, we propose a GNN architecture, called coVariance neural network (VNN), that operates on sample covariance matrices as graphs. We theoretically establish the stability of VNNs to perturbations in the covariance matrix, thus, implying an advantage over standard PCA-based data analysis approaches that are prone to instability due to principal components associated with close eigenvalues. Our experiments on real-world datasets validate our theoretical results and show that VNN performance is indeed more stable than PCA-based statistical approaches. Moreover, our experiments on multi-resolution datasets also demonstrate that VNNs are amenable to transferability of performance over covariance matrices of different dimensions; a feature that is infeasible for PCA-based approaches.", "paper_url": "http://arxiv.org/abs/2205.15856v1", "pdf_url": "http://arxiv.org/pdf/2205.15856v1", "repo_url": "https://github.com/pennbindlab/vnn"}, "2205.15765": {"publish_time": "2022-05-31", "title": "Strategic Classification with Graph Neural Networks", "author": "Itay Eilat et.al.", "abstract": "Strategic classification studies learning in settings where users can modify their features to obtain favorable predictions. Most current works focus on simple classifiers that trigger independent user responses. Here we examine the implications of learning with more elaborate models that break the independence assumption. Motivated by the idea that applications of strategic classification are often social in nature, we focus on \\emph{graph neural networks}, which make use of social relations between users to improve predictions. Using a graph for learning introduces inter-user dependencies in prediction; our key point is that strategic users can exploit these to promote their goals. As we show through analysis and simulation, this can work either against the system -- or for it. Based on this, we propose a differentiable framework for strategically-robust learning of graph-based classifiers. Experiments on several real networked datasets demonstrate the utility of our approach.", "paper_url": "http://arxiv.org/abs/2205.15765v1", "pdf_url": "http://arxiv.org/pdf/2205.15765v1", "repo_url": "https://github.com/strategicgnns/code"}, "2205.15733": {"publish_time": "2022-05-31", "title": "Template based Graph Neural Network with Optimal Transport Distances", "author": "C\u00e9dric Vincent-Cuaz et.al.", "abstract": "Current Graph Neural Networks (GNN) architectures generally rely on two important components: node features embedding through message passing, and aggregation with a specialized form of pooling. The structural (or topological) information is implicitly taken into account in these two steps. We propose in this work a novel point of view, which places distances to some learnable graph templates at the core of the graph representation. This distance embedding is constructed thanks to an optimal transport distance: the Fused Gromov-Wasserstein (FGW) distance, which encodes simultaneously feature and structure dissimilarities by solving a soft graph-matching problem. We postulate that the vector of FGW distances to a set of template graphs has a strong discriminative power, which is then fed to a non-linear classifier for final predictions. Distance embedding can be seen as a new layer, and can leverage on existing message passing techniques to promote sensible feature representations. Interestingly enough, in our work the optimal set of template graphs is also learnt in an end-to-end fashion by differentiating through this layer. After describing the corresponding learning procedure, we empirically validate our claim on several synthetic and real life graph classification datasets, where our method is competitive or surpasses kernel and GNN state-of-the-art approaches. We complete our experiments by an ablation study and a sensitivity analysis to parameters.", "paper_url": "http://arxiv.org/abs/2205.15733v1", "pdf_url": "http://arxiv.org/pdf/2205.15733v1", "repo_url": null}, "2205.15678": {"publish_time": "2022-05-31", "title": "Automatic Relation-aware Graph Network Proliferation", "author": "Shaofei Cai et.al.", "abstract": "Graph neural architecture search has sparked much attention as Graph Neural Networks (GNNs) have shown powerful reasoning capability in many relational tasks. However, the currently used graph search space overemphasizes learning node features and neglects mining hierarchical relational information. Moreover, due to diverse mechanisms in the message passing, the graph search space is much larger than that of CNNs. This hinders the straightforward application of classical search strategies for exploring complicated graph search space. We propose Automatic Relation-aware Graph Network Proliferation (ARGNP) for efficiently searching GNNs with a relation-guided message passing mechanism. Specifically, we first devise a novel dual relation-aware graph search space that comprises both node and relation learning operations. These operations can extract hierarchical node/relational information and provide anisotropic guidance for message passing on a graph. Second, analogous to cell proliferation, we design a network proliferation search paradigm to progressively determine the GNN architectures by iteratively performing network division and differentiation. The experiments on six datasets for four graph learning tasks demonstrate that GNNs produced by our method are superior to the current state-of-the-art hand-crafted and search-based GNNs. Codes are available at https://github.com/phython96/ARGNP.", "paper_url": "http://arxiv.org/abs/2205.15678v1", "pdf_url": "http://arxiv.org/pdf/2205.15678v1", "repo_url": "https://github.com/phython96/ARGNP"}, "2206.00637": {"publish_time": "2022-06-01", "title": "Graph Neural Networks with Precomputed Node Features", "author": "Beni Egressy et.al.", "abstract": "Most Graph Neural Networks (GNNs) cannot distinguish some graphs or indeed some pairs of nodes within a graph. This makes it impossible to solve certain classification tasks. However, adding additional node features to these models can resolve this problem. We introduce several such augmentations, including (i) positional node embeddings, (ii) canonical node IDs, and (iii) random features. These extensions are motivated by theoretical results and corroborated by extensive testing on synthetic subgraph detection tasks. We find that positional embeddings significantly outperform other extensions in these tasks. Moreover, positional embeddings have better sample efficiency, perform well on different graph distributions and even outperform learning with ground truth node positions. Finally, we show that the different augmentations perform competitively on established GNN benchmarks, and advise on when to use them.", "paper_url": "http://arxiv.org/abs/2206.00637v1", "pdf_url": "http://arxiv.org/pdf/2206.00637v1", "repo_url": null}, "2206.00619": {"publish_time": "2022-06-01", "title": "Graph Machine Learning for Design of High-Octane Fuels", "author": "Jan G. Rittig et.al.", "abstract": "Fuels with high-knock resistance enable modern spark-ignition engines to achieve high efficiency and thus low CO2 emissions. Identification of molecules with desired autoignition properties indicated by a high research octane number and a high octane sensitivity is therefore of great practical relevance and can be supported by computer-aided molecular design (CAMD). Recent developments in the field of graph machine learning (graph-ML) provide novel, promising tools for CAMD. We propose a modular graph-ML CAMD framework that integrates generative graph-ML models with graph neural networks and optimization, enabling the design of molecules with desired ignition properties in a continuous molecular space. In particular, we explore the potential of Bayesian optimization and genetic algorithms in combination with generative graph-ML models. The graph-ML CAMD framework successfully identifies well-established high-octane components. It also suggests new candidates, one of which we experimentally investigate and use to illustrate the need for further auto-ignition training data.", "paper_url": "http://arxiv.org/abs/2206.00619v1", "pdf_url": "http://arxiv.org/pdf/2206.00619v1", "repo_url": null}, "2206.00362": {"publish_time": "2022-06-01", "title": "Augmenting Message Passing by Retrieving Similar Graphs", "author": "Dingmin Wang et.al.", "abstract": "Graph Neural Networks (GNNs) are effective tools for graph representation learning. Most GNNs rely on a recursive neighborhood aggregation scheme, named message passing. In this paper, motivated by the success of retrieval-based models, we propose a non-parametric scheme called GraphRetrieval, in which similar training graphs associated with their ground-truth labels are retrieved to be jointly utilized with the input graph representation to complete various graph-based predictive tasks. In particular, we take a well-trained model with its parameters fixed and then we add an adapter based on self-attention with only a few trainable parameters per task to explicitly learn the interaction between an input graph and its retrieved similar graphs. Our experiments on 12 different datasets involving different tasks (classification and regression) show that GraphRetrieval is able to achieve substantial improvements on all twelve datasets compared to three strong GNN baseline models. Our work demonstrates that GraphRetrieval is a promising augmentation for message passing.", "paper_url": "http://arxiv.org/abs/2206.00362v1", "pdf_url": "http://arxiv.org/pdf/2206.00362v1", "repo_url": null}, "2206.00355": {"publish_time": "2022-06-01", "title": "Regularized by Physics: Graph Neural Network Parametrized Potentials for the Description of Intermolecular Interactions", "author": "Moritz Th\u00fcrlemann et.al.", "abstract": "Simulations with an explicit description of intermolecular forces using electronic structure methods are still not feasible for many systems of interest. As a result, empirical methods such as force fields (FF) have become an established tool for the simulation of large and complex molecular systems. However, the parametrization of FF is time consuming and has traditionally been based largely on experimental data, which is scarce for many functional groups. Recent years have therefore seen increasing efforts to automatize FF parametrization and a move towards FF fitted against quantum-mechanical reference data. Here, we propose an alternative strategy to parametrize intermolecular interactions, which makes use of machine learning and gradient-descent based optimization while retaining a functional form founded in physics. This strategy can be viewed as generalization of existing FF parametrization methods. In the proposed approach, graph neural networks are used in conjunction with automatic differentiation to parametrize physically motivated models to potential-energy surfaces, enabling full automatization and broad applicability in chemical space. As a result, highly accurate FF models are obtained which retain the computational efficiency, interpretability and robustness of classical FF. To showcase the potential of the proposed method, both a fixed-charge model and a polarizable model are parametrized for intermolecular interactions and applied to a wide range of systems including dimer dissociation curves and condensed-phase systems.", "paper_url": "http://arxiv.org/abs/2206.00355v1", "pdf_url": "http://arxiv.org/pdf/2206.00355v1", "repo_url": null}, "2206.00265": {"publish_time": "2022-06-01", "title": "InducT-GCN: Inductive Graph Convolutional Networks for Text Classification", "author": "Kunze Wang et.al.", "abstract": "Text classification aims to assign labels to textual units by making use of global information. Recent studies have applied graph neural network (GNN) to capture the global word co-occurrence in a corpus. Existing approaches require that all the nodes (training and test) in a graph are present during training, which are transductive and do not naturally generalise to unseen nodes. To make those models inductive, they use extra resources, like pretrained word embedding. However, high-quality resource is not always available and hard to train. Under the extreme settings with no extra resource and limited amount of training set, can we still learn an inductive graph-based text classification model? In this paper, we introduce a novel inductive graph-based text classification framework, InducT-GCN (InducTive Graph Convolutional Networks for Text classification). Compared to transductive models that require test documents in training, we construct a graph based on the statistics of training documents only and represent document vectors with a weighted sum of word vectors. We then conduct one-directional GCN propagation during testing. Across five text classification benchmarks, our InducT-GCN outperformed state-of-the-art methods that are either transductive in nature or pre-trained additional resources. We also conducted scalability testing by gradually increasing the data size and revealed that our InducT-GCN can reduce the time and space complexity. The code is available on: https://github.com/usydnlp/InductTGCN.", "paper_url": "http://arxiv.org/abs/2206.00265v1", "pdf_url": "http://arxiv.org/pdf/2206.00265v1", "repo_url": null}, "2206.01003": {"publish_time": "2022-06-02", "title": "Shortest Path Networks for Graph Property Prediction", "author": "Ralph Abboud et.al.", "abstract": "Most graph neural network models rely on a particular message passing paradigm, where the idea is to iteratively propagate node representations of a graph to each node in the direct neighborhood. While very prominent, this paradigm leads to information propagation bottlenecks, as information is repeatedly compressed at intermediary node representations, which causes loss of information, making it practically impossible to gather meaningful signals from distant nodes. To address this issue, we propose shortest path message passing neural networks, where the node representations of a graph are propagated to each node in the shortest path neighborhoods. In this setting, nodes can directly communicate between each other even if they are not neighbors, breaking the information bottleneck and hence leading to more adequately learned representations. Theoretically, our framework generalizes message passing neural networks, resulting in provably more expressive models. Empirically, we verify the capacity of a basic model of this framework on dedicated synthetic experiments, and on real-world graph classification and regression benchmarks, obtaining several state-of-the-art results.", "paper_url": "http://arxiv.org/abs/2206.01003v1", "pdf_url": "http://arxiv.org/pdf/2206.01003v1", "repo_url": null}, "2206.00711": {"publish_time": "2022-06-01", "title": "Learning to Solve PDE-constrained Inverse Problems with Graph Networks", "author": "Qingqing Zhao et.al.", "abstract": "Learned graph neural networks (GNNs) have recently been established as fast and accurate alternatives for principled solvers in simulating the dynamics of physical systems. In many application domains across science and engineering, however, we are not only interested in a forward simulation but also in solving inverse problems with constraints defined by a partial differential equation (PDE). Here we explore GNNs to solve such PDE-constrained inverse problems. Given a sparse set of measurements, we are interested in recovering the initial condition or parameters of the PDE. We demonstrate that GNNs combined with autodecoder-style priors are well-suited for these tasks, achieving more accurate estimates of initial conditions or physical parameters than other learned approaches when applied to the wave equation or Navier-Stokes equations. We also demonstrate computational speedups of up to 90x using GNNs compared to principled solvers. Project page: https://cyanzhao42.github.io/LearnInverseProblem", "paper_url": "http://arxiv.org/abs/2206.00711v1", "pdf_url": "http://arxiv.org/pdf/2206.00711v1", "repo_url": null}, "2206.01570": {"publish_time": "2022-06-03", "title": "On Calibration of Graph Neural Networks for Node Classification", "author": "Tong Liu et.al.", "abstract": "Graphs can model real-world, complex systems by representing entities and their interactions in terms of nodes and edges. To better exploit the graph structure, graph neural networks have been developed, which learn entity and edge embeddings for tasks such as node classification and link prediction. These models achieve good performance with respect to accuracy, but the confidence scores associated with the predictions might not be calibrated. That means that the scores might not reflect the ground-truth probabilities of the predicted events, which would be especially important for safety-critical applications. Even though graph neural networks are used for a wide range of tasks, the calibration thereof has not been sufficiently explored yet. We investigate the calibration of graph neural networks for node classification, study the effect of existing post-processing calibration methods, and analyze the influence of model capacity, graph density, and a new loss function on calibration. Further, we propose a topology-aware calibration method that takes the neighboring nodes into account and yields improved calibration compared to baseline methods.", "paper_url": "http://arxiv.org/abs/2206.01570v1", "pdf_url": "http://arxiv.org/pdf/2206.01570v1", "repo_url": null}, "2206.01506": {"publish_time": "2022-06-03", "title": "Can Hybrid Geometric Scattering Networks Help Solve the Maximal Clique Problem?", "author": "Yimeng Min et.al.", "abstract": "We propose a geometric scattering-based graph neural network (GNN) for approximating solutions of the NP-hard maximal clique (MC) problem. We construct a loss function with two terms, one which encourages the network to find a large set of nodes and the other which acts as a surrogate for the constraint that the nodes form a clique. We then use this loss to train a novel GNN architecture that outputs a vector representing the probability for each node to be part of the MC and apply a rule-based decoder to make our final prediction. The incorporation of the scattering transform alleviates the so-called oversmoothing problem that is often encountered in GNNs and would degrade the performance of our proposed setup. Our empirical results demonstrate that our method outperforms representative GNN baselines in terms of solution accuracy and inference speed as well as conventional solvers like GUROBI with limited time budgets.", "paper_url": "http://arxiv.org/abs/2206.01506v1", "pdf_url": "http://arxiv.org/pdf/2206.01506v1", "repo_url": "https://github.com/yimengmin/geometricscatteringmaximalclique"}, "2206.01379": {"publish_time": "2022-06-03", "title": "Instant Graph Neural Networks for Dynamic Graphs", "author": "Yanping Zheng et.al.", "abstract": "Graph Neural Networks (GNNs) have been widely used for modeling graph-structured data. With the development of numerous GNN variants, recent years have witnessed groundbreaking results in improving the scalability of GNNs to work on static graphs with millions of nodes. However, how to instantly represent continuous changes of large-scale dynamic graphs with GNNs is still an open problem. Existing dynamic GNNs focus on modeling the periodic evolution of graphs, often on a snapshot basis. Such methods suffer from two drawbacks: first, there is a substantial delay for the changes in the graph to be reflected in the graph representations, resulting in losses on the model's accuracy; second, repeatedly calculating the representation matrix on the entire graph in each snapshot is predominantly time-consuming and severely limits the scalability. In this paper, we propose Instant Graph Neural Network (InstantGNN), an incremental computation approach for the graph representation matrix of dynamic graphs. Set to work with dynamic graphs with the edge-arrival model, our method avoids time-consuming, repetitive computations and allows instant updates on the representation and instant predictions. Graphs with dynamic structures and dynamic attributes are both supported. The upper bounds of time complexity of those updates are also provided. Furthermore, our method provides an adaptive training strategy, which guides the model to retrain at moments when it can make the greatest performance gains. We conduct extensive experiments on several real-world and synthetic datasets. Empirical results demonstrate that our model achieves state-of-the-art accuracy while having orders-of-magnitude higher efficiency than existing methods.", "paper_url": "http://arxiv.org/abs/2206.01379v1", "pdf_url": "http://arxiv.org/pdf/2206.01379v1", "repo_url": null}, "2206.02771": {"publish_time": "2022-06-06", "title": "Neuro CROSS exchange: Learning to CROSS exchange to solve realistic vehicle routing problems", "author": "Minjun Kim et.al.", "abstract": "CROSS exchange (CE), a meta-heuristic that solves various vehicle routing problems (VRPs), improves the solutions of VRPs by swapping the sub-tours of the vehicles. Inspired by CE, we propose Neuro CE (NCE), a fundamental operator of learned meta-heuristic, to solve various VRPs while overcoming the limitations of CE (i.e., the expensive $\\mathcal{O}(n^4)$ search cost). NCE employs a graph neural network to predict the cost-decrements (i.e., results of CE searches) and utilizes the predicted cost-decrements as guidance for search to decrease the search cost to $\\mathcal{O}(n^2)$. As the learning objective of NCE is to predict the cost-decrement, the training can be simply done in a supervised fashion, whose training samples can be prepared effortlessly. Despite the simplicity of NCE, numerical results show that the NCE trained with flexible multi-depot VRP (FMDVRP) outperforms the meta-heuristic baselines. More importantly, it significantly outperforms the neural baselines when solving distinctive special cases of FMDVRP (e.g., MDVRP, mTSP, CVRP) without additional training.", "paper_url": "http://arxiv.org/abs/2206.02771v1", "pdf_url": "http://arxiv.org/pdf/2206.02771v1", "repo_url": null}, "2206.02731": {"publish_time": "2022-06-06", "title": "Robust and Fast Data-Driven Power System State Estimator Using Graph Neural Networks", "author": "Ognjen Kundacina et.al.", "abstract": "The power system state estimation (SE) algorithm estimates the complex bus voltages based on the available set of measurements. Because phasor measurement units (PMUs) are becoming more widely employed in transmission power systems, a fast SE solver capable of exploiting PMUs' high sample rates is required. To accomplish this, we present a method for training a model based on graph neural networks (GNNs) to learn estimates from PMU voltage and current measurements, which, once it is trained, has a linear computational complexity with respect to the number of nodes in the power system. We propose an original GNN implementation over the power system's factor graph to simplify the incorporation of various types and numbers of measurements both on power system buses and branches. Furthermore, we augment the factor graph to improve the robustness of GNN predictions. Training and test examples were generated by randomly sampling sets of power system measurements and annotated with the exact solutions of linear SE with PMUs. The numerical results demonstrate that the GNN model provides an accurate approximation of the SE solutions. Additionally, errors caused by PMU malfunctions or the communication failures that make the SE problem unobservable have a local effect and do not deteriorate the results in the rest of the power system.", "paper_url": "http://arxiv.org/abs/2206.02731v1", "pdf_url": "http://arxiv.org/pdf/2206.02731v1", "repo_url": null}, "2206.02671": {"publish_time": "2022-06-06", "title": "Canonical Cortical Graph Neural Networks and its Application for Speech Enhancement in Future Audio-Visual Hearing Aids", "author": "Leandro A. Passos et.al.", "abstract": "Despite the recent success of machine learning algorithms, most of these models still face several drawbacks when considering more complex tasks requiring interaction between different sources, such as multimodal input data and logical time sequence. On the other hand, the biological brain is highly sharpened in this sense, empowered to automatically manage and integrate such a stream of information through millions of years of evolution. In this context, this paper finds inspiration from recent discoveries on cortical circuits in the brain to propose a more biologically plausible self-supervised machine learning approach that combines multimodal information using intra-layer modulations together with canonical correlation analysis (CCA), as well as a memory mechanism to keep track of temporal data, the so-called Canonical Cortical Graph Neural networks. The approach outperformed recent state-of-the-art results considering both better clean audio reconstruction and energy efficiency, described by a reduced and smother neuron firing rate distribution, suggesting the model as a suitable approach for speech enhancement in future audio-visual hearing aid devices.", "paper_url": "http://arxiv.org/abs/2206.02671v1", "pdf_url": "http://arxiv.org/pdf/2206.02671v1", "repo_url": null}, "2206.02404": {"publish_time": "2022-06-06", "title": "A Simple yet Effective Method for Graph Classification", "author": "Junran Wu et.al.", "abstract": "In deep neural networks, better results can often be obtained by increasing the complexity of previously developed basic models. However, it is unclear whether there is a way to boost performance by decreasing the complexity of such models. Intuitively, given a problem, a simpler data structure comes with a simpler algorithm. Here, we investigate the feasibility of improving graph classification performance while simplifying the learning process. Inspired by structural entropy on graphs, we transform the data sample from graphs to coding trees, which is a simpler but essential structure for graph data. Furthermore, we propose a novel message passing scheme, termed hierarchical reporting, in which features are transferred from leaf nodes to root nodes by following the hierarchical structure of coding trees. We then present a tree kernel and a convolutional network to implement our scheme for graph classification. With the designed message passing scheme, the tree kernel and convolutional network have a lower runtime complexity of $O(n)$ than Weisfeiler-Lehman subtree kernel and other graph neural networks of at least $O(hm)$. We empirically validate our methods with several graph classification benchmarks and demonstrate that they achieve better performance and lower computational consumption than competing approaches.", "paper_url": "http://arxiv.org/abs/2206.02404v1", "pdf_url": "http://arxiv.org/pdf/2206.02404v1", "repo_url": null}, "2206.02386": {"publish_time": "2022-06-06", "title": "Restructuring Graph for Higher Homophily via Learnable Spectral Clustering", "author": "Shouheng Li et.al.", "abstract": "While a growing body of literature has been studying new Graph Neural Networks (GNNs) that work on both homophilic and heterophilic graphs, little work has been done on adapting classical GNNs to less-homophilic graphs. Although lacking the ability to work with less-homophilic graphs, classical GNNs still stand out in some properties such as efficiency, simplicity and explainability. We propose a novel graph restructuring method to maximize the benefit of prevalent GNNs with the homophilic assumption. Our contribution is threefold: a) learning the weight of pseudo-eigenvectors for an adaptive spectral clustering that aligns well with known node labels, b) proposing a new homophilic metric that measures how two nodes with the same label are likely to be connected, and c) reconstructing the adjacency matrix based on the result of adaptive spectral clustering to maximize the homophilic scores. The experimental results show that our graph restructuring method can significantly boost the performance of six classical GNNs by an average of 25% on less-homophilic graphs. The boosted performance is comparable to state-of-the-art methods.", "paper_url": "http://arxiv.org/abs/2206.02386v1", "pdf_url": "http://arxiv.org/pdf/2206.02386v1", "repo_url": null}, "2206.03469": {"publish_time": "2022-06-07", "title": "FDGNN: Fully Dynamic Graph Neural Network", "author": "Alice Moallemy-Oureh et.al.", "abstract": "Dynamic Graph Neural Networks recently became more and more important as graphs from many scientific fields, ranging from mathematics, biology, social sciences, and physics to computer science, are dynamic by nature. While temporal changes (dynamics) play an essential role in many real-world applications, most of the models in the literature on Graph Neural Networks (GNN) process static graphs. The few GNN models on dynamic graphs only consider exceptional cases of dynamics, e.g., node attribute-dynamic graphs or structure-dynamic graphs limited to additions or changes to the graph's edges, etc. Therefore, we present a novel Fully Dynamic Graph Neural Network (FDGNN) that can handle fully-dynamic graphs in continuous time. The proposed method provides a node and an edge embedding that includes their activity to address added and deleted nodes or edges, and possible attributes. Furthermore, the embeddings specify Temporal Point Processes for each event to encode the distributions of the structure- and attribute-related incoming graph events. In addition, our model can be updated efficiently by considering single events for local retraining.", "paper_url": "http://arxiv.org/abs/2206.03469v1", "pdf_url": "http://arxiv.org/pdf/2206.03469v1", "repo_url": null}, "2206.03426": {"publish_time": "2022-06-07", "title": "Improving Fairness in Graph Neural Networks via Mitigating Sensitive Attribute Leakage", "author": "Yu Wang et.al.", "abstract": "Graph Neural Networks (GNNs) have shown great power in learning node representations on graphs. However, they may inherit historical prejudices from training data, leading to discriminatory bias in predictions. Although some work has developed fair GNNs, most of them directly borrow fair representation learning techniques from non-graph domains without considering the potential problem of sensitive attribute leakage caused by feature propagation in GNNs. However, we empirically observe that feature propagation could vary the correlation of previously innocuous non-sensitive features to the sensitive ones. This can be viewed as a leakage of sensitive information which could further exacerbate discrimination in predictions. Thus, we design two feature masking strategies according to feature correlations to highlight the importance of considering feature propagation and correlation variation in alleviating discrimination. Motivated by our analysis, we propose Fair View Graph Neural Network (FairVGNN) to generate fair views of features by automatically identifying and masking sensitive-correlated features considering correlation variation after feature propagation. Given the learned fair views, we adaptively clamp weights of the encoder to avoid using sensitive-related features. Experiments on real-world datasets demonstrate that FairVGNN enjoys a better trade-off between model utility and fairness. Our code is publicly available at \\href{https://github.com/YuWVandy/FairVGNN}{\\textcolor{blue}{https://github.com/YuWVandy/FairVGNN}}.", "paper_url": "http://arxiv.org/abs/2206.03426v1", "pdf_url": "http://arxiv.org/pdf/2206.03426v1", "repo_url": "https://github.com/yuwvandy/fairvgnn"}, "2206.03164": {"publish_time": "2022-06-07", "title": "Utility of Equivariant Message Passing in Cortical Mesh Segmentation", "author": "D\u00e1niel Unyi et.al.", "abstract": "The automated segmentation of cortical areas has been a long-standing challenge in medical image analysis. The complex geometry of the cortex is commonly represented as a polygon mesh, whose segmentation can be addressed by graph-based learning methods. When cortical meshes are misaligned across subjects, current methods produce significantly worse segmentation results, limiting their ability to handle multi-domain data. In this paper, we investigate the utility of E(n)-equivariant graph neural networks (EGNNs), comparing their performance against plain graph neural networks (GNNs). Our evaluation shows that GNNs outperform EGNNs on aligned meshes, due to their ability to leverage the presence of a global coordinate system. On misaligned meshes, the performance of plain GNNs drop considerably, while E(n)-equivariant message passing maintains the same segmentation results. The best results can also be obtained by using plain GNNs on realigned data (co-registered meshes in a global coordinate system).", "paper_url": "http://arxiv.org/abs/2206.03164v1", "pdf_url": "http://arxiv.org/pdf/2206.03164v1", "repo_url": "https://github.com/daniel-unyi-42/equivariant-cortical-mesh-segmentation"}, "2206.02886": {"publish_time": "2022-06-06", "title": "Graph Rationalization with Environment-based Augmentations", "author": "Gang Liu et.al.", "abstract": "Rationale is defined as a subset of input features that best explains or supports the prediction by machine learning models. Rationale identification has improved the generalizability and interpretability of neural networks on vision and language data. In graph applications such as molecule and polymer property prediction, identifying representative subgraph structures named as graph rationales plays an essential role in the performance of graph neural networks. Existing graph pooling and/or distribution intervention methods suffer from lack of examples to learn to identify optimal graph rationales. In this work, we introduce a new augmentation operation called environment replacement that automatically creates virtual data examples to improve rationale identification. We propose an efficient framework that performs rationale-environment separation and representation learning on the real and augmented examples in latent spaces to avoid the high complexity of explicit graph decoding and encoding. Comparing against recent techniques, experiments on seven molecular and four polymer real datasets demonstrate the effectiveness and efficiency of the proposed augmentation-based graph rationalization framework.", "paper_url": "http://arxiv.org/abs/2206.02886v1", "pdf_url": "http://arxiv.org/pdf/2206.02886v1", "repo_url": "https://github.com/liugangcode/GREA"}, "2206.02855": {"publish_time": "2022-06-06", "title": "Efficient entity-based reinforcement learning", "author": "Vince Jankovics et.al.", "abstract": "Recent deep reinforcement learning (DRL) successes rely on end-to-end learning from fixed-size observational inputs (e.g. image, state-variables). However, many challenging and interesting problems in decision making involve observations or intermediary representations which are best described as a set of entities: either the image-based approach would miss small but important details in the observations (e.g. ojects on a radar, vehicles on satellite images, etc.), the number of sensed objects is not fixed (e.g. robotic manipulation), or the problem simply cannot be represented in a meaningful way as an image (e.g. power grid control, or logistics).   This type of structured representations is not directly compatible with current DRL architectures, however, there has been an increase in machine learning techniques directly targeting structured information, potentially addressing this issue.   We propose to combine recent advances in set representations with slot attention and graph neural networks to process structured data, broadening the range of applications of DRL algorithms. This approach allows to address entity-based problems in an efficient and scalable way. We show that it can improve training time and robustness significantly, and demonstrate their potential to handle structured as well as purely visual domains, on multiple environments from the Atari Learning Environment and Simple Playgrounds.", "paper_url": "http://arxiv.org/abs/2206.02855v1", "pdf_url": "http://arxiv.org/pdf/2206.02855v1", "repo_url": null}, "2206.03644": {"publish_time": "2022-06-08", "title": "Neural Bandit with Arm Group Graph", "author": "Yunzhe Qi et.al.", "abstract": "Contextual bandits aim to identify among a set of arms the optimal one with the highest reward based on their contextual information. Motivated by the fact that the arms usually exhibit group behaviors and the mutual impacts exist among groups, we introduce a new model, Arm Group Graph (AGG), where the nodes represent the groups of arms and the weighted edges formulate the correlations among groups. To leverage the rich information in AGG, we propose a bandit algorithm, AGG-UCB, where the neural networks are designed to estimate rewards, and we propose to utilize graph neural networks (GNN) to learn the representations of arm groups with correlations. To solve the exploitation-exploration dilemma in bandits, we derive a new upper confidence bound (UCB) built on neural networks (exploitation) for exploration. Furthermore, we prove that AGG-UCB can achieve a near-optimal regret bound with over-parameterized neural networks, and provide the convergence analysis of GNN with fully-connected layers which may be of independent interest. In the end, we conduct extensive experiments against state-of-the-art baselines on multiple public data sets, showing the effectiveness of the proposed algorithm.", "paper_url": "http://arxiv.org/abs/2206.03644v1", "pdf_url": "http://arxiv.org/pdf/2206.03644v1", "repo_url": null}, "2206.03638": {"publish_time": "2022-06-08", "title": "Alternately Optimized Graph Neural Networks", "author": "Haoyu Han et.al.", "abstract": "Graph Neural Networks (GNNs) have demonstrated powerful representation capability in numerous graph-based tasks. Specifically, the decoupled structures of GNNs such as APPNP become popular due to their simplicity and performance advantages. However, the end-to-end training of these GNNs makes them inefficient in computation and memory consumption. In order to deal with these limitations, in this work, we propose an alternating optimization framework for graph neural networks that does not require end-to-end training. Extensive experiments under different settings demonstrate that the performance of the proposed algorithm is comparable to existing state-of-the-art algorithms but has significantly better computation and memory efficiency. Additionally, we show that our framework can be taken advantage to enhance existing decoupled GNNs.", "paper_url": "http://arxiv.org/abs/2206.03638v1", "pdf_url": "http://arxiv.org/pdf/2206.03638v1", "repo_url": null}, "2206.03601": {"publish_time": "2022-06-07", "title": "Decoupled Self-supervised Learning for Non-Homophilous Graphs", "author": "Teng Xiao et.al.", "abstract": "In this paper, we study the problem of conducting self-supervised learning for node representation learning on non-homophilous graphs. Existing self-supervised learning methods typically assume the graph is homophilous where linked nodes often belong to the same class or have similar features. However, such assumptions of homophily do not always hold true in real-world graphs. We address this problem by developing a decoupled self-supervised learning (DSSL) framework for graph neural networks. DSSL imitates a generative process of nodes and links from latent variable modeling of the semantic structure, which decouples different underlying semantics between different neighborhoods into the self-supervised node learning process. Our DSSL framework is agnostic to the encoders and does not need prefabricated augmentations, thus is flexible to different graphs. To effectively optimize the framework with latent variables, we derive the evidence lower-bound of the self-supervised objective and develop a scalable training algorithm with variational inference. We provide a theoretical analysis to justify that DSSL enjoys better downstream performance. Extensive experiments on various types of graph benchmarks demonstrate that our proposed framework can significantly achieve better performance compared with competitive self-supervised learning baselines.", "paper_url": "http://arxiv.org/abs/2206.03601v1", "pdf_url": "http://arxiv.org/pdf/2206.03601v1", "repo_url": null}, "2206.04516": {"publish_time": "2022-06-09", "title": "Accurate Node Feature Estimation with Structured Variational Graph Autoencoder", "author": "Jaemin Yoo et.al.", "abstract": "Given a graph with partial observations of node features, how can we estimate the missing features accurately? Feature estimation is a crucial problem for analyzing real-world graphs whose features are commonly missing during the data collection process. Accurate estimation not only provides diverse information of nodes but also supports the inference of graph neural networks that require the full observation of node features. However, designing an effective approach for estimating high-dimensional features is challenging, since it requires an estimator to have large representation power, increasing the risk of overfitting. In this work, we propose SVGA (Structured Variational Graph Autoencoder), an accurate method for feature estimation. SVGA applies strong regularization to the distribution of latent variables by structured variational inference, which models the prior of variables as Gaussian Markov random field based on the graph structure. As a result, SVGA combines the advantages of probabilistic inference and graph neural networks, achieving state-of-the-art performance in real datasets.", "paper_url": "http://arxiv.org/abs/2206.04516v1", "pdf_url": "http://arxiv.org/pdf/2206.04516v1", "repo_url": "https://github.com/snudatalab/SVGA"}, "2206.04486": {"publish_time": "2022-06-09", "title": "Data-Efficient Brain Connectome Analysis via Multi-Task Meta-Learning", "author": "Yi Yang et.al.", "abstract": "Brain networks characterize complex connectivities among brain regions as graph structures, which provide a powerful means to study brain connectomes. In recent years, graph neural networks have emerged as a prevalent paradigm of learning with structured data. However, most brain network datasets are limited in sample sizes due to the relatively high cost of data acquisition, which hinders the deep learning models from sufficient training. Inspired by meta-learning that learns new concepts fast with limited training examples, this paper studies data-efficient training strategies for analyzing brain connectomes in a cross-dataset setting. Specifically, we propose to meta-train the model on datasets of large sample sizes and transfer the knowledge to small datasets. In addition, we also explore two brain-network-oriented designs, including atlas transformation and adaptive task reweighing. Compared to other pre-training strategies, our meta-learning-based approach achieves higher and stabler performance, which demonstrates the effectiveness of our proposed solutions. The framework is also able to derive new insights regarding the similarities among datasets and diseases in a data-driven fashion.", "paper_url": "http://arxiv.org/abs/2206.04486v1", "pdf_url": "http://arxiv.org/pdf/2206.04486v1", "repo_url": null}, "2206.04471": {"publish_time": "2022-06-09", "title": "Towards Understanding Graph Neural Networks: An Algorithm Unrolling Perspective", "author": "Zepeng Zhang et.al.", "abstract": "The graph neural network (GNN) has demonstrated its superior performance in various applications. The working mechanism behind it, however, remains mysterious. GNN models are designed to learn effective representations for graph-structured data, which intrinsically coincides with the principle of graph signal denoising (GSD). Algorithm unrolling, a \"learning to optimize\" technique, has gained increasing attention due to its prospects in building efficient and interpretable neural network architectures. In this paper, we introduce a class of unrolled networks built based on truncated optimization algorithms (e.g., gradient descent and proximal gradient descent) for GSD problems. They are shown to be tightly connected to many popular GNN models in that the forward propagations in these GNNs are in fact unrolled networks serving specific GSDs. Besides, the training process of a GNN model can be seen as solving a bilevel optimization problem with a GSD problem at the lower level. Such a connection brings a fresh view of GNNs, as we could try to understand their practical capabilities from their GSD counterparts, and it can also motivate designing new GNN models. Based on the algorithm unrolling perspective, an expressive model named UGDGNN, i.e., unrolled gradient descent GNN, is further proposed which inherits appealing theoretical properties. Extensive numerical simulations on seven benchmark datasets demonstrate that UGDGNN can achieve superior or competitive performance over the state-of-the-art models.", "paper_url": "http://arxiv.org/abs/2206.04471v1", "pdf_url": "http://arxiv.org/pdf/2206.04471v1", "repo_url": null}, "2206.04361": {"publish_time": "2022-06-09", "title": "Model Degradation Hinders Deep Graph Neural Networks", "author": "Wentao Zhang et.al.", "abstract": "Graph Neural Networks (GNNs) have achieved great success in various graph mining tasks.However, drastic performance degradation is always observed when a GNN is stacked with many layers. As a result, most GNNs only have shallow architectures, which limits their expressive power and exploitation of deep neighborhoods.Most recent studies attribute the performance degradation of deep GNNs to the \\textit{over-smoothing} issue. In this paper, we disentangle the conventional graph convolution operation into two independent operations: \\textit{Propagation} (\\textbf{P}) and \\textit{Transformation} (\\textbf{T}).Following this, the depth of a GNN can be split into the propagation depth ($D_p$) and the transformation depth ($D_t$). Through extensive experiments, we find that the major cause for the performance degradation of deep GNNs is the \\textit{model degradation} issue caused by large $D_t$ rather than the \\textit{over-smoothing} issue mainly caused by large $D_p$. Further, we present \\textit{Adaptive Initial Residual} (AIR), a plug-and-play module compatible with all kinds of GNN architectures, to alleviate the \\textit{model degradation} issue and the \\textit{over-smoothing} issue simultaneously. Experimental results on six real-world datasets demonstrate that GNNs equipped with AIR outperform most GNNs with shallow architectures owing to the benefits of both large $D_p$ and $D_t$, while the time costs associated with AIR can be ignored.", "paper_url": "http://arxiv.org/abs/2206.04361v1", "pdf_url": "http://arxiv.org/pdf/2206.04361v1", "repo_url": null}, "2206.04355": {"publish_time": "2022-06-09", "title": "Graph Attention Multi-Layer Perceptron", "author": "Wentao Zhang et.al.", "abstract": "Graph neural networks (GNNs) have achieved great success in many graph-based applications. However, the enormous size and high sparsity level of graphs hinder their applications under industrial scenarios. Although some scalable GNNs are proposed for large-scale graphs, they adopt a fixed $K$-hop neighborhood for each node, thus facing the over-smoothing issue when adopting large propagation depths for nodes within sparse regions. To tackle the above issue, we propose a new GNN architecture -- Graph Attention Multi-Layer Perceptron (GAMLP), which can capture the underlying correlations between different scales of graph knowledge. We have deployed GAMLP in Tencent with the Angel platform, and we further evaluate GAMLP on both real-world datasets and large-scale industrial datasets. Extensive experiments on these 14 graph datasets demonstrate that GAMLP achieves state-of-the-art performance while enjoying high scalability and efficiency. Specifically, it outperforms GAT by 1.3\\% regarding predictive accuracy on our large-scale Tencent Video dataset while achieving up to $50\\times$ training speedup. Besides, it ranks top-1 on both the leaderboards of the largest homogeneous and heterogeneous graph (i.e., ogbn-papers100M and ogbn-mag) of Open Graph Benchmark.", "paper_url": "http://arxiv.org/abs/2206.04355v1", "pdf_url": "http://arxiv.org/pdf/2206.04355v1", "repo_url": "https://github.com/pku-dair/gamlp"}, "2206.05070": {"publish_time": "2022-06-10", "title": "We Cannot Guarantee Safety: The Undecidability of Graph Neural Network Verification", "author": "Marco S\u00e4lzer et.al.", "abstract": "Graph Neural Networks (GNN) are commonly used for two tasks: (whole) graph classification and node classification. We formally introduce generically formulated decision problems for both tasks, corresponding to the following pattern: given a GNN, some specification of valid inputs, and some specification of valid outputs, decide whether there is a valid input satisfying the output specification. We then prove that graph classifier verification is undecidable in general, implying that there cannot be an algorithm surely guaranteeing the absence of misclassification of any kind. Additionally, we show that verification in the node classification case becomes decidable as soon as we restrict the degree of the considered graphs. Furthermore, we discuss possible changes to these results depending on the considered GNN model and specifications.", "paper_url": "http://arxiv.org/abs/2206.05070v1", "pdf_url": "http://arxiv.org/pdf/2206.05070v1", "repo_url": null}, "2206.05032": {"publish_time": "2022-06-10", "title": "Scalable Deep Gaussian Markov Random Fields for General Graphs", "author": "Joel Oskarsson et.al.", "abstract": "Machine learning methods on graphs have proven useful in many applications due to their ability to handle generally structured data. The framework of Gaussian Markov Random Fields (GMRFs) provides a principled way to define Gaussian models on graphs by utilizing their sparsity structure. We propose a flexible GMRF model for general graphs built on the multi-layer structure of Deep GMRFs, originally proposed for lattice graphs only. By designing a new type of layer we enable the model to scale to large graphs. The layer is constructed to allow for efficient training using variational inference and existing software frameworks for Graph Neural Networks. For a Gaussian likelihood, close to exact Bayesian inference is available for the latent field. This allows for making predictions with accompanying uncertainty estimates. The usefulness of the proposed model is verified by experiments on a number of synthetic and real world datasets, where it compares favorably to other both Bayesian and deep learning methods.", "paper_url": "http://arxiv.org/abs/2206.05032v1", "pdf_url": "http://arxiv.org/pdf/2206.05032v1", "repo_url": "https://github.com/joeloskarsson/graph-dgmrf"}, "2206.04910": {"publish_time": "2022-06-10", "title": "NAGphormer: Neighborhood Aggregation Graph Transformer for Node Classification in Large Graphs", "author": "Jinsong Chen et.al.", "abstract": "Graph Transformers have demonstrated superiority on various graph learning tasks in recent years. However, the complexity of existing Graph Transformers scales quadratically with the number of nodes, making it hard to scale to graphs with thousands of nodes. To this end, we propose a Neighborhood Aggregation Graph Transformer (NAGphormer) that is scalable to large graphs with millions of nodes. Before feeding the node features into the Transformer model, NAGphormer constructs tokens for each node by a neighborhood aggregation module called Hop2Token. For each node, Hop2Token aggregates neighborhood features from each hop into a representation, and thereby produces a sequence of token vectors. Subsequently, the resulting sequence of different hop information serves as input to the Transformer model. By considering each node as a sequence, NAGphormer could be trained in a mini-batch manner and thus could scale to large graphs. NAGphormer further develops an attention-based readout function so as to learn the importance of each hop adaptively. We conduct extensive experiments on various popular benchmarks, including six small datasets and three large datasets. The results demonstrate that NAGphormer consistently outperforms existing Graph Transformers and mainstream Graph Neural Networks.", "paper_url": "http://arxiv.org/abs/2206.04910v1", "pdf_url": "http://arxiv.org/pdf/2206.04910v1", "repo_url": null}, "2206.04855": {"publish_time": "2022-06-10", "title": "Beyond the Gates of Euclidean Space: Temporal-Discrimination-Fusions and Attention-based Graph Neural Network for Human Activity Recognition", "author": "Nafees Ahmad et.al.", "abstract": "Human activity recognition (HAR) through wearable devices has received much interest due to its numerous applications in fitness tracking, wellness screening, and supported living. As a result, we have seen a great deal of work in this field. Traditional deep learning (DL) has set a state of the art performance for HAR domain. However, it ignores the data's structure and the association between consecutive time stamps. To address this constraint, we offer an approach based on Graph Neural Networks (GNNs) for structuring the input representation and exploiting the relations among the samples. However, even when using a simple graph convolution network to eliminate this shortage, there are still several limiting factors, such as inter-class activities issues, skewed class distribution, and a lack of consideration for sensor data priority, all of which harm the HAR model's performance. To improve the current HAR model's performance, we investigate novel possibilities within the framework of graph structure to achieve highly discriminated and rich activity features. We propose a model for (1) time-series-graph module that converts raw data from HAR dataset into graphs; (2) Graph Convolutional Neural Networks (GCNs) to discover local dependencies and correlations between neighboring nodes; and (3) self-attention GNN encoder to identify sensors interactions and data priorities. To the best of our knowledge, this is the first work for HAR, which introduces a GNN-based approach that incorporates both the GCN and the attention mechanism. By employing a uniform evaluation method, our framework significantly improves the performance on hospital patient's activities dataset comparatively considered other state of the art baseline methods.", "paper_url": "http://arxiv.org/abs/2206.04855v1", "pdf_url": "http://arxiv.org/pdf/2206.04855v1", "repo_url": null}, "2206.04832": {"publish_time": "2022-06-10", "title": "Transformer-Graph Neural Network with Global-Local Attention for Multimodal Rumour Detection with Knowledge Distillation", "author": "Tsun-hin Cheung et.al.", "abstract": "Misinformation spreading becomes a critical issue in online conversation. Detecting rumours is an important research topic in social media analysis. Most existing methods, based on Convolutional Neural Networks (CNNs) and Graph Neural Networks (GNNs), do not make use of the relationship between the global and local information of a conversation for detection. In this paper, we propose a Transformer-Graph Neural Network (TGNN), to fuse the local information with the global representation, through an attention mechanism. Then, we extend the proposed TGNN for multimodal rumour detection, by considering the latent relationship between the multimodal feature and node feature to form a more comprehensive graph representation. To verify the effectiveness of our proposed method for multimodal rumour detection, we extend the existing PHEME-2016, PHEME-2018, and Weibo data sets, by collecting available and relevant images for training the proposal framework. To improve the performance of single-modal rumour detection, i.e., based on text input only, a teacher-student framework is employed to distil the knowledge from the multimodal model to the single-modal model. Experimental results show that our proposed TGNN can achieve state-of-the-art performance and generalization ability evaluated on the PHEME-2016, PHEME-2018, and Weibo data sets.", "paper_url": "http://arxiv.org/abs/2206.04832v1", "pdf_url": "http://arxiv.org/pdf/2206.04832v1", "repo_url": null}, "2206.06234": {"publish_time": "2022-06-13", "title": "Evaluating Graph Generative Models with Contrastively Learned Features", "author": "Hamed Shirzad et.al.", "abstract": "A wide range of models have been proposed for Graph Generative Models, necessitating effective methods to evaluate their quality. So far, most techniques use either traditional metrics based on subgraph counting, or the representations of randomly initialized Graph Neural Networks (GNNs). We propose using representations from contrastively trained GNNs, rather than random GNNs, and show this gives more reliable evaluation metrics. Neither traditional approaches nor GNN-based approaches dominate the other, however: we give examples of graphs that each approach is unable to distinguish. We demonstrate that Graph Substructure Networks (GSNs), which in a way combine both approaches, are better at distinguishing the distances between graph datasets.", "paper_url": "http://arxiv.org/abs/2206.06234v1", "pdf_url": "http://arxiv.org/pdf/2206.06234v1", "repo_url": "https://github.com/hamed1375/self-supervised-models-for-ggm-evaluation"}, "2206.05692": {"publish_time": "2022-06-12", "title": "tBDFS: Temporal Graph Neural Network Leveraging DFS", "author": "Uriel Singer et.al.", "abstract": "Temporal graph neural networks (temporal GNNs) have been widely researched, reaching state-of-the-art results on multiple prediction tasks. A common approach employed by most previous works is to apply a layer that aggregates information from the historical neighbors of a node. Taking a different research direction, in this work, we propose tBDFS -- a novel temporal GNN architecture. tBDFS applies a layer that efficiently aggregates information from temporal paths to a given (target) node in the graph. For each given node, the aggregation is applied in two stages: (1) A single representation is learned for each temporal path ending in that node, and (2) all path representations are aggregated into a final node representation. Overall, our goal is not to add new information to a node, but rather observe the same exact information in a new perspective. This allows our model to directly observe patterns that are path-oriented rather than neighborhood-oriented. This can be thought as a Depth-First Search (DFS) traversal over the temporal graph, compared to the popular Breath-First Search (BFS) traversal that is applied in previous works. We evaluate tBDFS over multiple link prediction tasks and show its favorable performance compared to state-of-the-art baselines. To the best of our knowledge, we are the first to apply a temporal-DFS neural network.", "paper_url": "http://arxiv.org/abs/2206.05692v1", "pdf_url": "http://arxiv.org/pdf/2206.05692v1", "repo_url": null}, "2206.05499": {"publish_time": "2022-06-11", "title": "Soft-mask: Adaptive Substructure Extractions for Graph Neural Networks", "author": "Mingqi Yang et.al.", "abstract": "For learning graph representations, not all detailed structures within a graph are relevant to the given graph tasks. Task-relevant structures can be $localized$ or $sparse$ which are only involved in subgraphs or characterized by the interactions of subgraphs (a hierarchical perspective). A graph neural network should be able to efficiently extract task-relevant structures and be invariant to irrelevant parts, which is challenging for general message passing GNNs. In this work, we propose to learn graph representations from a sequence of subgraphs of the original graph to better capture task-relevant substructures or hierarchical structures and skip $noisy$ parts. To this end, we design soft-mask GNN layer to extract desired subgraphs through the mask mechanism. The soft-mask is defined in a continuous space to maintain the differentiability and characterize the weights of different parts. Compared with existing subgraph or hierarchical representation learning methods and graph pooling operations, the soft-mask GNN layer is not limited by the fixed sample or drop ratio, and therefore is more flexible to extract subgraphs with arbitrary sizes. Extensive experiments on public graph benchmarks show that soft-mask mechanism brings performance improvements. And it also provides interpretability where visualizing the values of masks in each layer allows us to have an insight into the structures learned by the model.", "paper_url": "http://arxiv.org/abs/2206.05499v1", "pdf_url": "http://arxiv.org/pdf/2206.05499v1", "repo_url": null}, "2206.05437": {"publish_time": "2022-06-11", "title": "ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle Phase Transition", "author": "Yuelin Wang et.al.", "abstract": "Neural message passing is a basic feature extraction unit for graph-structured data that takes account of the impact of neighboring node features in network propagation from one layer to the next. We model such process by an interacting particle system with attractive and repulsive forces and the Allen-Cahn force arising in the modeling of phase transition. The system is a reaction-diffusion process which can separate particles to different clusters. This induces an Allen-Cahn message passing (ACMP) for graph neural networks where the numerical iteration for the solution constitutes the message passing propagation. The mechanism behind ACMP is phase transition of particles which enables the formation of multi-clusters and thus GNNs prediction for node classification. ACMP can propel the network depth to hundreds of layers with theoretically proven strictly positive lower bound of the Dirichlet energy. It thus provides a deep model of GNNs which circumvents the common GNN problem of oversmoothing. Experiments for various real node classification datasets, with possible high homophily difficulty, show the GNNs with ACMP can achieve state of the art performance with no decay of Dirichlet energy.", "paper_url": "http://arxiv.org/abs/2206.05437v1", "pdf_url": "http://arxiv.org/pdf/2206.05437v1", "repo_url": null}, "2206.05335": {"publish_time": "2022-06-10", "title": "Synthetic Over-sampling for Imbalanced Node Classification with Graph Neural Networks", "author": "Tianxiang Zhao et.al.", "abstract": "In recent years, graph neural networks (GNNs) have achieved state-of-the-art performance for node classification. However, most existing GNNs would suffer from the graph imbalance problem. In many real-world scenarios, node classes are imbalanced, with some majority classes making up most parts of the graph. The message propagation mechanism in GNNs would further amplify the dominance of those majority classes, resulting in sub-optimal classification performance. In this work, we seek to address this problem by generating pseudo instances of minority classes to balance the training data, extending previous over-sampling-based techniques. This task is non-trivial, as those techniques are designed with the assumption that instances are independent. Neglection of relation information would complicate this oversampling process. Furthermore, the node classification task typically takes the semi-supervised setting with only a few labeled nodes, providing insufficient supervision for the generation of minority instances. Generated new nodes of low quality would harm the trained classifier. In this work, we address these difficulties by synthesizing new nodes in a constructed embedding space, which encodes both node attributes and topology information. Furthermore, an edge generator is trained simultaneously to model the graph structure and provide relations for new samples. To further improve the data efficiency, we also explore synthesizing mixed ``in-between'' nodes to utilize nodes from the majority class in this over-sampling process. Experiments on real-world datasets validate the effectiveness of our proposed framework.", "paper_url": "http://arxiv.org/abs/2206.05335v1", "pdf_url": "http://arxiv.org/pdf/2206.05335v1", "repo_url": null}, "2206.06758": {"publish_time": "2022-06-14", "title": "Universally Expressive Communication in Multi-Agent Reinforcement Learning", "author": "Matthew Morris et.al.", "abstract": "Allowing agents to share information through communication is crucial for solving complex tasks in multi-agent reinforcement learning. In this work, we consider the question of whether a given communication protocol can express an arbitrary policy. By observing that many existing protocols can be viewed as instances of graph neural networks (GNNs), we demonstrate the equivalence of joint action selection to node labelling. With standard GNN approaches provably limited in their expressive capacity, we draw from existing GNN literature and consider augmenting agent observations with: (1) unique agent IDs and (2) random noise. We provide a theoretical analysis as to how these approaches yield universally expressive communication, and also prove them capable of targeting arbitrary sets of actions for identical agents. Empirically, these augmentations are found to improve performance on tasks where expressive communication is required, whilst, in general, the optimal communication protocol is found to be task-dependent.", "paper_url": "http://arxiv.org/abs/2206.06758v1", "pdf_url": "http://arxiv.org/pdf/2206.06758v1", "repo_url": null}, "2206.06757": {"publish_time": "2022-06-14", "title": "RoSGAS: Adaptive Social Bot Detection with Reinforced Self-Supervised GNN Architecture Search", "author": "Yingguang Yang et.al.", "abstract": "Social bots are referred to as the automated accounts on social networks that make attempts to behave like human. While Graph Neural Networks (GNNs) has been massively applied to the field of social bot detection, a huge amount of domain expertise and prior knowledge is heavily engaged in the state-of-the art approaches to design a dedicated neural network architecture for a specific classification task. Involving oversized nodes and network layers in the model design, however, usually causes the over-smoothing problem and the lack of embedding discrimination. In this paper, we propose RoSGAS, a novel Reinforced and Self-supervised GNN Architecture Search framework to adaptively pinpoint the most suitable multi-hop neighborhood and the number of layers in the GNN architecture. More specifically, we consider the social bot detection problem as a user-centric subgraph embedding and classification task. We exploit heterogeneous information network to present the user connectivity by leveraging account metadata, relationships, behavioral features and content features. RoSGAS uses a multi-agent deep reinforcement learning (RL) mechanism for navigating the search of optimal neighborhood and network layers to learn individually the subgraph embedding for each target user. A nearest neighbor mechanism is developed for accelerating the RL training process, and RoSGAS can learn more discriminative subgraph embedding with the aid of self-supervised learning. Experiments on 5 Twitter datasets show that RoSGAS outperforms the state-of-the-art approaches in terms of accuracy, training efficiency and stability, and has better generalization when handling unseen samples.", "paper_url": "http://arxiv.org/abs/2206.06757v1", "pdf_url": "http://arxiv.org/pdf/2206.06757v1", "repo_url": null}, "2206.06561": {"publish_time": "2022-06-14", "title": "FreeKD: Free-direction Knowledge Distillation for Graph Neural Networks", "author": "Kaituo Feng et.al.", "abstract": "Knowledge distillation (KD) has demonstrated its effectiveness to boost the performance of graph neural networks (GNNs), where its goal is to distill knowledge from a deeper teacher GNN into a shallower student GNN. However, it is actually difficult to train a satisfactory teacher GNN due to the well-known over-parametrized and over-smoothing issues, leading to invalid knowledge transfer in practical applications. In this paper, we propose the first Free-direction Knowledge Distillation framework via Reinforcement learning for GNNs, called FreeKD, which is no longer required to provide a deeper well-optimized teacher GNN. The core idea of our work is to collaboratively build two shallower GNNs in an effort to exchange knowledge between them via reinforcement learning in a hierarchical way. As we observe that one typical GNN model often has better and worse performances at different nodes during training, we devise a dynamic and free-direction knowledge transfer strategy that consists of two levels of actions: 1) node-level action determines the directions of knowledge transfer between the corresponding nodes of two networks; and then 2) structure-level action determines which of the local structures generated by the node-level actions to be propagated. In essence, our FreeKD is a general and principled framework which can be naturally compatible with GNNs of different architectures. Extensive experiments on five benchmark datasets demonstrate our FreeKD outperforms two base GNNs in a large margin, and shows its efficacy to various GNNs. More surprisingly, our FreeKD has comparable or even better performance than traditional KD algorithms that distill knowledge from a deeper and stronger teacher GNN.", "paper_url": "http://arxiv.org/abs/2206.06561v1", "pdf_url": "http://arxiv.org/pdf/2206.06561v1", "repo_url": null}, "2206.07680": {"publish_time": "2022-06-15", "title": "Learning Large-scale Subsurface Simulations with a Hybrid Graph Network Simulator", "author": "Tailin Wu et.al.", "abstract": "Subsurface simulations use computational models to predict the flow of fluids (e.g., oil, water, gas) through porous media. These simulations are pivotal in industrial applications such as petroleum production, where fast and accurate models are needed for high-stake decision making, for example, for well placement optimization and field development planning. Classical finite difference numerical simulators require massive computational resources to model large-scale real-world reservoirs. Alternatively, streamline simulators and data-driven surrogate models are computationally more efficient by relying on approximate physics models, however they are insufficient to model complex reservoir dynamics at scale. Here we introduce Hybrid Graph Network Simulator (HGNS), which is a data-driven surrogate model for learning reservoir simulations of 3D subsurface fluid flows. To model complex reservoir dynamics at both local and global scale, HGNS consists of a subsurface graph neural network (SGNN) to model the evolution of fluid flows, and a 3D-U-Net to model the evolution of pressure. HGNS is able to scale to grids with millions of cells per time step, two orders of magnitude higher than previous surrogate models, and can accurately predict the fluid flow for tens of time steps (years into the future). Using an industry-standard subsurface flow dataset (SPE-10) with 1.1 million cells, we demonstrate that HGNS is able to reduce the inference time up to 18 times compared to standard subsurface simulators, and that it outperforms other learning-based models by reducing long-term prediction errors by up to 21%.", "paper_url": "http://arxiv.org/abs/2206.07680v1", "pdf_url": "http://arxiv.org/pdf/2206.07680v1", "repo_url": null}, "2206.07665": {"publish_time": "2022-06-15", "title": "Region-enhanced Deep Graph Convolutional Networks for Rumor Detection", "author": "Ge Wang et.al.", "abstract": "Social media has been rapidly developing in the public sphere due to its ease of spreading new information, which leads to the circulation of rumors. However, detecting rumors from such a massive amount of information is becoming an increasingly arduous challenge. Previous work generally obtained valuable features from propagation information. It should be noted that most methods only target the propagation structure while ignoring the rumor transmission pattern. This limited focus severely restricts the collection of spread data. To solve this problem, the authors of the present study are motivated to explore the regionalized propagation patterns of rumors. Specifically, a novel region-enhanced deep graph convolutional network (RDGCN) that enhances the propagation features of rumors by learning regionalized propagation patterns and trains to learn the propagation patterns by unsupervised learning is proposed. In addition, a source-enhanced residual graph convolution layer (SRGCL) is designed to improve the graph neural network (GNN) oversmoothness and increase the depth limit of the rumor detection methods-based GNN. Experiments on Twitter15 and Twitter16 show that the proposed model performs better than the baseline approach on rumor detection and early rumor detection.", "paper_url": "http://arxiv.org/abs/2206.07665v1", "pdf_url": "http://arxiv.org/pdf/2206.07665v1", "repo_url": null}, "2206.07599": {"publish_time": "2022-06-15", "title": "How GNNs Facilitate CNNs in Mining Geometric Information from Large-Scale Medical Images", "author": "Yiqing Shen et.al.", "abstract": "Gigapixel medical images provide massive data, both morphological textures and spatial information, to be mined. Due to the large data scale in histology, deep learning methods play an increasingly significant role as feature extractors. Existing solutions heavily rely on convolutional neural networks (CNNs) for global pixel-level analysis, leaving the underlying local geometric structure such as the interaction between cells in the tumor microenvironment unexplored. The topological structure in medical images, as proven to be closely related to tumor evolution, can be well characterized by graphs. To obtain a more comprehensive representation for downstream oncology tasks, we propose a fusion framework for enhancing the global image-level representation captured by CNNs with the geometry of cell-level spatial information learned by graph neural networks (GNN). The fusion layer optimizes an integration between collaborative features of global images and cell graphs. Two fusion strategies have been developed: one with MLP which is simple but turns out efficient through fine-tuning, and the other with Transformer gains a champion in fusing multiple networks. We evaluate our fusion strategies on histology datasets curated from large patient cohorts of colorectal and gastric cancers for three biomarker prediction tasks. Both two models outperform plain CNNs or GNNs, reaching a consistent AUC improvement of more than 5% on various network backbones. The experimental results yield the necessity for combining image-level morphological features with cell spatial relations in medical image analysis. Codes are available at https://github.com/yiqings/HEGnnEnhanceCnn.", "paper_url": "http://arxiv.org/abs/2206.07599v1", "pdf_url": "http://arxiv.org/pdf/2206.07599v1", "repo_url": null}, "2206.07570": {"publish_time": "2022-06-15", "title": "Calibrating Agent-based Models to Microdata with Graph Neural Networks", "author": "Joel Dyer et.al.", "abstract": "Calibrating agent-based models (ABMs) to data is among the most fundamental requirements to ensure the model fulfils its desired purpose. In recent years, simulation-based inference methods have emerged as powerful tools for performing this task when the model likelihood function is intractable, as is often the case for ABMs. In some real-world use cases of ABMs, both the observed data and the ABM output consist of the agents' states and their interactions over time. In such cases, there is a tension between the desire to make full use of the rich information content of such granular data on the one hand, and the need to reduce the dimensionality of the data to prevent difficulties associated with high-dimensional learning tasks on the other. A possible resolution is to construct lower-dimensional time-series through the use of summary statistics describing the macrostate of the system at each time point. However, a poor choice of summary statistics can result in an unacceptable loss of information from the original dataset, dramatically reducing the quality of the resulting calibration. In this work, we instead propose to learn parameter posteriors associated with granular microdata directly using temporal graph neural networks. We will demonstrate that such an approach offers highly compelling inductive biases for Bayesian inference using the raw ABM microstates as output.", "paper_url": "http://arxiv.org/abs/2206.07570v1", "pdf_url": "http://arxiv.org/pdf/2206.07570v1", "repo_url": null}, "2206.07556": {"publish_time": "2022-06-15", "title": "KGEA: A Knowledge Graph Enhanced Article Quality Identification Dataset", "author": "Chunhui Ai et.al.", "abstract": "With so many articles of varying quality being produced at every moment, it is a very urgent task to screen this data for quality articles and commit them out to social media. It is worth noting that high quality articles have many characteristics, such as relevance, text quality, straightforward, multi-sided, background, novelty and sentiment. Thus, it would be inadequate to purely use the content of an article to identify its quality. Therefore, we plan to use the external knowledge interaction to refine the performance and propose a knowledge graph enhanced article quality identification dataset (KGEA) based on Baidu Encyclopedia. We quantified the articles through 7 dimensions and use co-occurrence of the entities between the articles and the Baidu encyclopedia to construct the knowledge graph for every article. We also compared some text classification baselines and found that external knowledge can guide the articles to a more competitive classification with the graph neural networks.", "paper_url": "http://arxiv.org/abs/2206.07556v1", "pdf_url": "http://arxiv.org/pdf/2206.07556v1", "repo_url": null}, "2206.08258": {"publish_time": "2022-06-16", "title": "ProGNNosis: A Data-driven Model to Predict GNN Computation Time Using Graph Metrics", "author": "Axel Wassington et.al.", "abstract": "Graph Neural Networks (GNN) show great promise in problems dealing with graph-structured data. One of the unique points of GNNs is their flexibility to adapt to multiple problems, which not only leads to wide applicability, but also poses important challenges when finding the best model or acceleration technique for a particular problem. An example of such challenges resides in the fact that the accuracy or effectiveness of a GNN model or acceleration technique generally depends on the structure of the underlying graph. In this paper, in an attempt to address the problem of graph-dependent acceleration, we propose ProGNNosis, a data-driven model that can predict the GNN training time of a given GNN model running over a graph of arbitrary characteristics by inspecting the input graph metrics. Such prediction is made based on a regression that was previously trained offline using a diverse synthetic graph dataset. In practice, our method allows making informed decisions on which design to use for a specific problem. In the paper, the methodology to build ProGNNosis is defined and applied for a specific use case, where it helps to decide which graph representation is better. Our results show that ProGNNosis helps achieve an average speedup of 1.22X over randomly selecting a graph representation in multiple widely used GNN models such as GCN, GIN, GAT, or GraphSAGE.", "paper_url": "http://arxiv.org/abs/2206.08258v1", "pdf_url": "http://arxiv.org/pdf/2206.08258v1", "repo_url": null}, "2206.08181": {"publish_time": "2022-06-16", "title": "ResNorm: Tackling Long-tailed Degree Distribution Issue in Graph Neural Networks via Normalization", "author": "Langzhang Liang et.al.", "abstract": "Graph Neural Networks (GNNs) have attracted much attention due to their ability in learning representations from graph-structured data. Despite the successful applications of GNNs in many domains, the optimization of GNNs is less well studied, and the performance on node classification heavily suffers from the long-tailed node degree distribution. This paper focuses on improving the performance of GNNs via normalization.   In detail, by studying the long-tailed distribution of node degrees in the graph, we propose a novel normalization method for GNNs, which is termed ResNorm (\\textbf{Res}haping the long-tailed distribution into a normal-like distribution via \\textbf{norm}alization). The $scale$ operation of ResNorm reshapes the node-wise standard deviation (NStd) distribution so as to improve the accuracy of tail nodes (\\textit{i}.\\textit{e}., low-degree nodes). We provide a theoretical interpretation and empirical evidence for understanding the mechanism of the above $scale$. In addition to the long-tailed distribution issue, over-smoothing is also a fundamental issue plaguing the community. To this end, we analyze the behavior of the standard shift and prove that the standard shift serves as a preconditioner on the weight matrix, increasing the risk of over-smoothing. With the over-smoothing issue in mind, we design a $shift$ operation for ResNorm that simulates the degree-specific parameter strategy in a low-cost manner. Extensive experiments have validated the effectiveness of ResNorm on several node classification benchmark datasets.", "paper_url": "http://arxiv.org/abs/2206.08181v1", "pdf_url": "http://arxiv.org/pdf/2206.08181v1", "repo_url": null}, "2206.08164": {"publish_time": "2022-06-16", "title": "Long Range Graph Benchmark", "author": "Vijay Prakash Dwivedi et.al.", "abstract": "Graph Neural Networks (GNNs) that are based on the message passing (MP) paradigm exchange information between 1-hop neighbors to build node representations at each layer. In principle, such networks are not able to capture long-range interactions (LRI) that may be desired or necessary for learning a given task on graphs. Recently, there has been an increasing interest in development of Transformer-based methods for graphs that can consider full node connectivity beyond the original sparse structure, thus enabling the modeling of LRI. However, MP-GNNs that simply rely on 1-hop message passing often fare better in several existing graph benchmarks when combined with positional feature representations, among other innovations, hence limiting the perceived utility and ranking of Transformer-like architectures. Here, we present the Long Range Graph Benchmark (LRGB) with 5 graph learning datasets: PascalVOC-SP, COCO-SP, PCQM-Contact, Peptides-func and Peptides-struct that arguably require LRI reasoning to achieve strong performance in a given task. We benchmark both baseline GNNs and Graph Transformer networks to verify that the models which capture long-range dependencies perform significantly better on these tasks. Therefore, these datasets are suitable for benchmarking and exploration of MP-GNNs and Graph Transformer architectures that are intended to capture LRI.", "paper_url": "http://arxiv.org/abs/2206.08164v1", "pdf_url": "http://arxiv.org/pdf/2206.08164v1", "repo_url": "https://github.com/vijaydwivedi75/lrgb"}, "2206.08088": {"publish_time": "2022-06-16", "title": "Reinforcement Learning-enhanced Shared-account Cross-domain Sequential Recommendation", "author": "Lei Guo et.al.", "abstract": "Shared-account Cross-domain Sequential Recommendation (SCSR) is an emerging yet challenging task that simultaneously considers the shared-account and cross-domain characteristics in the sequential recommendation. Existing works on SCSR are mainly based on Recurrent Neural Network (RNN) and Graph Neural Network (GNN) but they ignore the fact that although multiple users share a single account, it is mainly occupied by one user at a time. This observation motivates us to learn a more accurate user-specific account representation by attentively focusing on its recent behaviors. Furthermore, though existing works endow lower weights to irrelevant interactions, they may still dilute the domain information and impede the cross-domain recommendation. To address the above issues, we propose a reinforcement learning-based solution, namely RL-ISN, which consists of a basic cross-domain recommender and a reinforcement learning-based domain filter. Specifically, to model the account representation in the shared-account scenario, the basic recommender first clusters users' mixed behaviors as latent users, and then leverages an attention model over them to conduct user identification. To reduce the impact of irrelevant domain information, we formulate the domain filter as a hierarchical reinforcement learning task, where a high-level task is utilized to decide whether to revise the whole transferred sequence or not, and if it does, a low-level task is further performed to determine whether to remove each interaction within it or not. To evaluate the performance of our solution, we conduct extensive experiments on two real-world datasets, and the experimental results demonstrate the superiority of our RL-ISN method compared with the state-of-the-art recommendation methods.", "paper_url": "http://arxiv.org/abs/2206.08088v1", "pdf_url": "http://arxiv.org/pdf/2206.08088v1", "repo_url": null}, "2206.08050": {"publish_time": "2022-06-16", "title": "Time Interval-enhanced Graph Neural Network for Shared-account Cross-domain Sequential Recommendation", "author": "Lei Guo et.al.", "abstract": "Shared-account Cross-domain Sequential Recommendation (SCSR) task aims to recommend the next item via leveraging the mixed user behaviors in multiple domains. It is gaining immense research attention as more and more users tend to sign up on different platforms and share accounts with others to access domain-specific services. Existing works on SCSR mainly rely on mining sequential patterns via Recurrent Neural Network (RNN)-based models, which suffer from the following limitations: 1) RNN-based methods overwhelmingly target discovering sequential dependencies in single-user behaviors. They are not expressive enough to capture the relationships among multiple entities in SCSR. 2) All existing methods bridge two domains via knowledge transfer in the latent space, and ignore the explicit cross-domain graph structure. 3) None existing studies consider the time interval information among items, which is essential in the sequential recommendation for characterizing different items and learning discriminative representations for them. In this work, we propose a new graph-based solution, namely TiDA-GCN, to address the above challenges. Specifically, we first link users and items in each domain as a graph. Then, we devise a domain-aware graph convolution network to learn userspecific node representations. To fully account for users' domainspecific preferences on items, two effective attention mechanisms are further developed to selectively guide the message passing process. Moreover, to further enhance item- and account-level representation learning, we incorporate the time interval into the message passing, and design an account-aware self-attention module for learning items' interactive characteristics. Experiments demonstrate the superiority of our proposed method from various aspects.", "paper_url": "http://arxiv.org/abs/2206.08050v1", "pdf_url": "http://arxiv.org/pdf/2206.08050v1", "repo_url": null}, "2206.08917": {"publish_time": "2022-06-17", "title": "The Open Catalyst 2022 (OC22) Dataset and Challenges for Oxide Electrocatalysis", "author": "Richard Tran et.al.", "abstract": "Computational catalysis and machine learning communities have made considerable progress in developing machine learning models for catalyst discovery and design. Yet, a general machine learning potential that spans the chemical space of catalysis is still out of reach. A significant hurdle is obtaining access to training data across a wide range of materials. One important class of materials where data is lacking are oxides, which inhibits models from studying the Oxygen Evolution Reaction and oxide electrocatalysis more generally. To address this we developed the Open Catalyst 2022(OC22) dataset, consisting of 62,521 Density Functional Theory (DFT) relaxations (~9,884,504 single point calculations) across a range of oxide materials, coverages, and adsorbates (*H, *O, *N, *C, *OOH, *OH, *OH2, *O2, *CO). We define generalized tasks to predict the total system energy that are applicable across catalysis, develop baseline performance of several graph neural networks (SchNet, DimeNet++, ForceNet, SpinConv, PaiNN, GemNet-dT, GemNet-OC), and provide pre-defined dataset splits to establish clear benchmarks for future efforts. For all tasks, we study whether combining datasets leads to better results, even if they contain different materials or adsorbates. Specifically, we jointly train models on Open Catalyst 2020 (OC20) Dataset and OC22, or fine-tune pretrained OC20 models on OC22. In the most general task, GemNet-OC sees a ~32% improvement in energy predictions through fine-tuning and a ~9% improvement in force predictions via joint training. Surprisingly, joint training on both the OC20 and much smaller OC22 datasets also improves total energy predictions on OC20 by ~19%. The dataset and baseline models are open sourced, and a public leaderboard will follow to encourage continued community developments on the total energy tasks and data.", "paper_url": "http://arxiv.org/abs/2206.08917v1", "pdf_url": "http://arxiv.org/pdf/2206.08917v1", "repo_url": null}, "2206.08702": {"publish_time": "2022-06-17", "title": "Sheaf Neural Networks with Connection Laplacians", "author": "Federico Barbero et.al.", "abstract": "A Sheaf Neural Network (SNN) is a type of Graph Neural Network (GNN) that operates on a sheaf, an object that equips a graph with vector spaces over its nodes and edges and linear maps between these spaces. SNNs have been shown to have useful theoretical properties that help tackle issues arising from heterophily and over-smoothing. One complication intrinsic to these models is finding a good sheaf for the task to be solved. Previous works proposed two diametrically opposed approaches: manually constructing the sheaf based on domain knowledge and learning the sheaf end-to-end using gradient-based methods. However, domain knowledge is often insufficient, while learning a sheaf could lead to overfitting and significant computational overhead. In this work, we propose a novel way of computing sheaves drawing inspiration from Riemannian geometry: we leverage the manifold assumption to compute manifold-and-graph-aware orthogonal maps, which optimally align the tangent spaces of neighbouring data points. We show that this approach achieves promising results with less computational overhead when compared to previous SNN models. Overall, this work provides an interesting connection between algebraic topology and differential geometry, and we hope that it will spark future research in this direction.", "paper_url": "http://arxiv.org/abs/2206.08702v1", "pdf_url": "http://arxiv.org/pdf/2206.08702v1", "repo_url": null}, "2206.08621": {"publish_time": "2022-06-17", "title": "A Graph-Enhanced Click Model for Web Search", "author": "Jianghao Lin et.al.", "abstract": "To better exploit search logs and model users' behavior patterns, numerous click models are proposed to extract users' implicit interaction feedback. Most traditional click models are based on the probabilistic graphical model (PGM) framework, which requires manually designed dependencies and may oversimplify user behaviors. Recently, methods based on neural networks are proposed to improve the prediction accuracy of user behaviors by enhancing the expressive ability and allowing flexible dependencies. However, they still suffer from the data sparsity and cold-start problems. In this paper, we propose a novel graph-enhanced click model (GraphCM) for web search. Firstly, we regard each query or document as a vertex, and propose novel homogeneous graph construction methods for queries and documents respectively, to fully exploit both intra-session and inter-session information for the sparsity and cold-start problems. Secondly, following the examination hypothesis, we separately model the attractiveness estimator and examination predictor to output the attractiveness scores and examination probabilities, where graph neural networks and neighbor interaction techniques are applied to extract the auxiliary information encoded in the pre-constructed homogeneous graphs. Finally, we apply combination functions to integrate examination probabilities and attractiveness scores into click predictions. Extensive experiments conducted on three real-world session datasets show that GraphCM not only outperforms the state-of-art models, but also achieves superior performance in addressing the data sparsity and cold-start problems.", "paper_url": "http://arxiv.org/abs/2206.08621v1", "pdf_url": "http://arxiv.org/pdf/2206.08621v1", "repo_url": "https://github.com/chiangel/graphcm"}, "2206.08583": {"publish_time": "2022-06-17", "title": "NAFS: A Simple yet Tough-to-beat Baseline for Graph Representation Learning", "author": "Wentao Zhang et.al.", "abstract": "Recently, graph neural networks (GNNs) have shown prominent performance in graph representation learning by leveraging knowledge from both graph structure and node features. However, most of them have two major limitations. First, GNNs can learn higher-order structural information by stacking more layers but can not deal with large depth due to the over-smoothing issue. Second, it is not easy to apply these methods on large graphs due to the expensive computation cost and high memory usage. In this paper, we present node-adaptive feature smoothing (NAFS), a simple non-parametric method that constructs node representations without parameter learning. NAFS first extracts the features of each node with its neighbors of different hops by feature smoothing, and then adaptively combines the smoothed features. Besides, the constructed node representation can further be enhanced by the ensemble of smoothed features extracted via different smoothing strategies. We conduct experiments on four benchmark datasets on two different application scenarios: node clustering and link prediction. Remarkably, NAFS with feature ensemble outperforms the state-of-the-art GNNs on these tasks and mitigates the aforementioned two limitations of most learning-based GNN counterparts.", "paper_url": "http://arxiv.org/abs/2206.08583v1", "pdf_url": "http://arxiv.org/pdf/2206.08583v1", "repo_url": null}, "2206.08582": {"publish_time": "2022-06-17", "title": "DFG-NAS: Deep and Flexible Graph Neural Architecture Search", "author": "Wentao Zhang et.al.", "abstract": "Graph neural networks (GNNs) have been intensively applied to various graph-based applications. Despite their success, manually designing the well-behaved GNNs requires immense human expertise. And thus it is inefficient to discover the potentially optimal data-specific GNN architecture. This paper proposes DFG-NAS, a new neural architecture search (NAS) method that enables the automatic search of very deep and flexible GNN architectures. Unlike most existing methods that focus on micro-architectures, DFG-NAS highlights another level of design: the search for macro-architectures on how atomic propagation (\\textbf{\\texttt{P}}) and transformation (\\textbf{\\texttt{T}}) operations are integrated and organized into a GNN. To this end, DFG-NAS proposes a novel search space for \\textbf{\\texttt{P-T}} permutations and combinations based on message-passing dis-aggregation, defines four custom-designed macro-architecture mutations, and employs the evolutionary algorithm to conduct an efficient and effective search. Empirical studies on four node classification tasks demonstrate that DFG-NAS outperforms state-of-the-art manual designs and NAS methods of GNNs.", "paper_url": "http://arxiv.org/abs/2206.08582v1", "pdf_url": "http://arxiv.org/pdf/2206.08582v1", "repo_url": null}, "2206.10581": {"publish_time": "2022-06-21", "title": "Nimble GNN Embedding with Tensor-Train Decomposition", "author": "Chunxing Yin et.al.", "abstract": "This paper describes a new method for representing embedding tables of graph neural networks (GNNs) more compactly via tensor-train (TT) decomposition. We consider the scenario where (a) the graph data that lack node features, thereby requiring the learning of embeddings during training; and (b) we wish to exploit GPU platforms, where smaller tables are needed to reduce host-to-GPU communication even for large-memory GPUs. The use of TT enables a compact parameterization of the embedding, rendering it small enough to fit entirely on modern GPUs even for massive graphs. When combined with judicious schemes for initialization and hierarchical graph partitioning, this approach can reduce the size of node embedding vectors by 1,659 times to 81,362 times on large publicly available benchmark datasets, achieving comparable or better accuracy and significant speedups on multi-GPU systems. In some cases, our model without explicit node features on input can even match the accuracy of models that use node features.", "paper_url": "http://arxiv.org/abs/2206.10581v1", "pdf_url": "http://arxiv.org/pdf/2206.10581v1", "repo_url": null}, "2206.10206": {"publish_time": "2022-06-21", "title": "Personalized Subgraph Federated Learning", "author": "Jinheon Baek et.al.", "abstract": "In real-world scenarios, subgraphs of a larger global graph may be distributed across multiple devices or institutions, and only locally accessible due to privacy restrictions, although there may be links between them. Recently proposed subgraph Federated Learning (FL) methods deal with those missing links across private local subgraphs while distributively training Graph Neural Networks (GNNs) on them. However, they have overlooked the inevitable heterogeneity among subgraphs, caused by subgraphs comprising different parts of a global graph. For example, a subgraph may belong to one of the communities within the larger global graph. A naive subgraph FL in such a case will collapse incompatible knowledge from local GNN models trained on heterogeneous graph distributions. To overcome such a limitation, we introduce a new subgraph FL problem, personalized subgraph FL, which focuses on the joint improvement of the interrelated local GNN models rather than learning a single global GNN model, and propose a novel framework, FEDerated Personalized sUBgraph learning (FED-PUB), to tackle it. A crucial challenge in personalized subgraph FL is that the server does not know which subgraph each client has. FED-PUB thus utilizes functional embeddings of the local GNNs using random graphs as inputs to compute similarities between them, and use them to perform weighted averaging for server-side aggregation. Further, it learns a personalized sparse mask at each client to select and update only the subgraph-relevant subset of the aggregated parameters. We validate FED-PUB for its subgraph FL performance on six datasets, considering both non-overlapping and overlapping subgraphs, on which ours largely outperforms relevant baselines.", "paper_url": "http://arxiv.org/abs/2206.10206v1", "pdf_url": "http://arxiv.org/pdf/2206.10206v1", "repo_url": null}, "2206.10071": {"publish_time": "2022-06-21", "title": "Benchmarking Node Outlier Detection on Graphs", "author": "Kay Liu et.al.", "abstract": "Graph outlier detection is an emerging but crucial machine learning task with numerous applications. Despite the proliferation of algorithms developed in recent years, the lack of a standard and unified setting for performance evaluation limits their advancement and usage in real-world applications. To tap the gap, we present, (to our best knowledge) the first comprehensive unsupervised node outlier detection benchmark for graphs called UNOD, with the following highlights: (1) evaluating fourteen methods with backbone spanning from classical matrix factorization to the latest graph neural networks; (2) benchmarking the method performance with different types of injected outliers and organic outliers on real-world datasets; (3) comparing the efficiency and scalability of the algorithms by runtime and GPU memory usage on synthetic graphs at different scales. Based on the analyses of extensive experimental results, we discuss the pros and cons of current UNOD methods, and point out multiple crucial and promising future research directions.", "paper_url": "http://arxiv.org/abs/2206.10071v1", "pdf_url": "http://arxiv.org/pdf/2206.10071v1", "repo_url": "https://github.com/pygod-team/pygod"}, "2206.09677": {"publish_time": "2022-06-20", "title": "GraphFramEx: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks", "author": "Kenza Amara et.al.", "abstract": "As one of the most popular machine learning models today, graph neural networks (GNNs) have attracted intense interest recently, and so does their explainability. Users are increasingly interested in a better understanding of GNN models and their outcomes. Unfortunately, today's evaluation frameworks for GNN explainability often rely on synthetic datasets, leading to conclusions of limited scope due to a lack of complexity in the problem instances. As GNN models are deployed to more mission-critical applications, we are in dire need for a common evaluation protocol of explainability methods of GNNs. In this paper, we propose, to our best knowledge, the first systematic evaluation framework for GNN explainability, considering explainability on three different \"user needs:\" explanation focus, mask nature, and mask transformation. We propose a unique metric that combines the fidelity measures and classify explanations based on their quality of being sufficient or necessary. We scope ourselves to node classification tasks and compare the most representative techniques in the field of input-level explainability for GNNs. For the widely used synthetic benchmarks, surprisingly shallow techniques such as personalized PageRank have the best performance for a minimum computation time. But when the graph structure is more complex and nodes have meaningful features, gradient-based methods, in particular Saliency, are the best according to our evaluation criteria. However, none dominates the others on all evaluation dimensions and there is always a trade-off. We further apply our evaluation protocol in a case study on eBay graphs to reflect the production environment.", "paper_url": "http://arxiv.org/abs/2206.09677v1", "pdf_url": "http://arxiv.org/pdf/2206.09677v1", "repo_url": "https://github.com/k-amara/graphframex"}, "2206.09619": {"publish_time": "2022-06-20", "title": "Analyzing B\u00fcchi Automata with Graph Neural Networks", "author": "Christophe Stammet et.al.", "abstract": "B\\\"uchi Automata on infinite words present many interesting problems and are used frequently in program verification and model checking. A lot of these problems on B\\\"uchi automata are computationally hard, raising the question if a learning-based data-driven analysis might be more efficient than using traditional algorithms. Since B\\\"uchi automata can be represented by graphs, graph neural networks are a natural choice for such a learning-based analysis. In this paper, we demonstrate how graph neural networks can be used to reliably predict basic properties of B\\\"uchi automata when trained on automatically generated random automata datasets.", "paper_url": "http://arxiv.org/abs/2206.09619v1", "pdf_url": "http://arxiv.org/pdf/2206.09619v1", "repo_url": null}, "2206.11168": {"publish_time": "2022-06-22", "title": "Ordered Subgraph Aggregation Networks", "author": "Chendi Qian et.al.", "abstract": "Numerous subgraph-enhanced graph neural networks (GNNs) have emerged recently, provably boosting the expressive power of standard (message-passing) GNNs. However, there is a limited understanding of how these approaches relate to each other and to the Weisfeiler--Leman hierarchy. Moreover, current approaches either use all subgraphs of a given size, sample them uniformly at random, or use hand-crafted heuristics instead of learning to select subgraphs in a data-driven manner. Here, we offer a unified way to study such architectures by introducing a theoretical framework and extending the known expressivity results of subgraph-enhanced GNNs. Concretely, we show that increasing subgraph size always increases the expressive power and develop a better understanding of their limitations by relating them to the established $k\\text{-}\\mathsf{WL}$ hierarchy. In addition, we explore different approaches for learning to sample subgraphs using recent methods for backpropagating through complex discrete probability distributions. Empirically, we study the predictive performance of different subgraph-enhanced GNNs, showing that our data-driven architectures increase prediction accuracy on standard benchmark datasets compared to non-data-driven subgraph-enhanced graph neural networks while reducing computation time.", "paper_url": "http://arxiv.org/abs/2206.11168v1", "pdf_url": "http://arxiv.org/pdf/2206.11168v1", "repo_url": null}, "2206.11140": {"publish_time": "2022-06-22", "title": "Understanding and Extending Subgraph GNNs by Rethinking Their Symmetries", "author": "Fabrizio Frasca et.al.", "abstract": "Subgraph GNNs are a recent class of expressive Graph Neural Networks (GNNs) which model graphs as collections of subgraphs. So far, the design space of possible Subgraph GNN architectures as well as their basic theoretical properties are still largely unexplored. In this paper, we study the most prominent form of subgraph methods, which employs node-based subgraph selection policies such as ego-networks or node marking and deletion. We address two central questions: (1) What is the upper-bound of the expressive power of these methods? and (2) What is the family of equivariant message passing layers on these sets of subgraphs?. Our first step in answering these questions is a novel symmetry analysis which shows that modelling the symmetries of node-based subgraph collections requires a significantly smaller symmetry group than the one adopted in previous works. This analysis is then used to establish a link between Subgraph GNNs and Invariant Graph Networks (IGNs). We answer the questions above by first bounding the expressive power of subgraph methods by 3-WL, and then proposing a general family of message-passing layers for subgraph methods that generalises all previous node-based Subgraph GNNs. Finally, we design a novel Subgraph GNN dubbed SUN, which theoretically unifies previous architectures while providing better empirical performance on multiple benchmarks.", "paper_url": "http://arxiv.org/abs/2206.11140v1", "pdf_url": "http://arxiv.org/pdf/2206.11140v1", "repo_url": null}, "2206.11081": {"publish_time": "2022-06-22", "title": "Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph Neural Networks", "author": "Hongjoon Ahn et.al.", "abstract": "Heterogeneous graph neural networks (GNNs) achieve strong performance on node classification tasks in a semi-supervised learning setting. However, as in the simpler homogeneous GNN case, message-passing-based heterogeneous GNNs may struggle to balance between resisting the oversmoothing occuring in deep models and capturing long-range dependencies graph structured data. Moreover, the complexity of this trade-off is compounded in the heterogeneous graph case due to the disparate heterophily relationships between nodes of different types. To address these issues, we proposed a novel heterogeneous GNN architecture in which layers are derived from optimization steps that descend a novel relation-aware energy function. The corresponding minimizer is fully differentiable with respect to the energy function parameters, such that bilevel optimization can be applied to effectively learn a functional form whose minimum provides optimal node representations for subsequent classification tasks. In particular, this methodology allows us to model diverse heterophily relationships between different node types while avoiding oversmoothing effects. Experimental results on 8 heterogeneous graph benchmarks demonstrates that our proposed method can achieve competitive node classification accuracy.", "paper_url": "http://arxiv.org/abs/2206.11081v1", "pdf_url": "http://arxiv.org/pdf/2206.11081v1", "repo_url": null}, "2206.11023": {"publish_time": "2022-06-22", "title": "Heterogeneous Graph Neural Networks for Software Effort Estimation", "author": "Hung Phan et.al.", "abstract": "Software effort can be measured by story point [35]. Current approaches for automatically estimating story points focus on applying pre-trained embedding models and deep learning for text regression to solve this problem which required expensive embedding models. We propose HeteroSP, a tool for estimating story points from textual input of Agile software project issues. We select GPT2SP [12] and Deep-SE [8] as the baselines for comparison. First, from the analysis of the story point dataset [8], we conclude that software issues are actually a mixture of natural language sentences with quoted code snippets and have problems related to large-size vocabulary. Second, we provide a module to normalize the input text including words and code tokens of the software issues. Third, we design an algorithm to convert an input software issue to a graph with different types of nodes and edges. Fourth, we construct a heterogeneous graph neural networks model with the support of fastText [6] for constructing initial node embedding to learn and predict the story points of new issues. We did the comparison over three scenarios of estimation, including within project, cross-project within the repository, and cross-project cross repository with our baseline approaches. We achieve the average Mean Absolute Error (MAE) as 2.38, 2.61, and 2.63 for three scenarios. We outperform GPT2SP in 2/3 of the scenarios while outperforming Deep-SE in the most challenging scenario with significantly less amount of running time. We also compare our approaches with different homogeneous graph neural network models and the results show that the heterogeneous graph neural networks model outperforms the homogeneous models in story point estimation. For time performance, we achieve about 570 seconds as the time performance in both three processes: node embedding initialization, model construction, and story point estimation.", "paper_url": "http://arxiv.org/abs/2206.11023v1", "pdf_url": "http://arxiv.org/pdf/2206.11023v1", "repo_url": null}, "2206.11010": {"publish_time": "2022-06-22", "title": "Agent-based Graph Neural Networks", "author": "Karolis Martinkus et.al.", "abstract": "We present a novel graph neural network we call AgentNet, which is designed specifically for graph-level tasks. AgentNet is inspired by sublinear algorithms, featuring a computational complexity that is independent of the graph size. The architecture of AgentNet differs fundamentally from the architectures of known graph neural networks. In AgentNet, some trained \\textit{neural agents} intelligently walk the graph, and then collectively decide on the output. We provide an extensive theoretical analysis of AgentNet: We show that the agents can learn to systematically explore their neighborhood and that AgentNet can distinguish some structures that are even indistinguishable by 3-WL. Moreover, AgentNet is able to separate any two graphs which are sufficiently different in terms of subgraphs. We confirm these theoretical results with synthetic experiments on hard-to-distinguish graphs and real-world graph classification tasks. In both cases, we compare favorably not only to standard GNNs but also to computationally more expensive GNN extensions.", "paper_url": "http://arxiv.org/abs/2206.11010v1", "pdf_url": "http://arxiv.org/pdf/2206.11010v1", "repo_url": "https://github.com/karolismart/agentnet"}, "2206.11876": {"publish_time": "2022-06-23", "title": "A Topological characterisation of Weisfeiler-Leman equivalence classes", "author": "Jacob Bamberger et.al.", "abstract": "Graph Neural Networks (GNNs) are learning models aimed at processing graphs and signals on graphs. The most popular and successful GNNs are based on message passing schemes. Such schemes inherently have limited expressive power when it comes to distinguishing two non-isomorphic graphs. In this article, we rely on the theory of covering spaces to fully characterize the classes of graphs that GNNs cannot distinguish. We then generate arbitrarily many non-isomorphic graphs that cannot be distinguished by GNNs, leading to the GraphCovers dataset. We also show that the number of indistinguishable graphs in our dataset grows super-exponentially with the number of nodes. Finally, we test the GraphCovers dataset on several GNN architectures, showing that none of them can distinguish any two graphs it contains.", "paper_url": "http://arxiv.org/abs/2206.11876v1", "pdf_url": "http://arxiv.org/pdf/2206.11876v1", "repo_url": "https://github.com/jacobbamberger/graphcovers"}, "2206.11776": {"publish_time": "2022-06-23", "title": "Graph Neural Networks for Temperature-Dependent Activity Coefficient Prediction of Solutes in Ionic Liquids", "author": "Jan G. Rittig et.al.", "abstract": "Ionic liquids (ILs) are important solvents for sustainable processes and predicting activity coefficients (ACs) of solutes in ILs is needed. Recently, matrix completion methods (MCMs), transformers, and graph neural networks (GNNs) have shown high accuracy in predicting ACs of binary mixtures, superior to well-established models, e.g., COSMO-RS and UNIFAC. GNNs are particularly promising here as they learn a molecular graph-to-property relationship without pretraining, typically required for transformers, and are, unlike MCMs, applicable to molecules not included in training. For ILs, however, GNN applications are currently missing. Herein, we present a GNN to predict temperature-dependent infinite dilution ACs of solutes in ILs. We train the GNN on a database including more than 40,000 AC values and compare it to a state-of-the-art MCM. The GNN and MCM achieve similar high prediction performance, with the GNN additionally enabling high-quality predictions for ACs of solutions that contain ILs and solutes not considered during training.", "paper_url": "http://arxiv.org/abs/2206.11776v1", "pdf_url": "http://arxiv.org/pdf/2206.11776v1", "repo_url": null}, "2206.11477": {"publish_time": "2022-06-23", "title": "RetroGraph: Retrosynthetic Planning with Graph Search", "author": "Shufang Xie et.al.", "abstract": "Retrosynthetic planning, which aims to find a reaction pathway to synthesize a target molecule, plays an important role in chemistry and drug discovery. This task is usually modeled as a search problem. Recently, data-driven methods have attracted many research interests and shown promising results for retrosynthetic planning. We observe that the same intermediate molecules are visited many times in the searching process, and they are usually independently treated in previous tree-based methods (e.g., AND-OR tree search, Monte Carlo tree search). Such redundancies make the search process inefficient. We propose a graph-based search policy that eliminates the redundant explorations of any intermediate molecules. As searching over a graph is more complicated than over a tree, we further adopt a graph neural network to guide the search over graphs. Meanwhile, our method can search a batch of targets together in the graph and remove the inter-target duplication in the tree-based search methods. Experimental results on two datasets demonstrate the effectiveness of our method. Especially on the widely used USPTO benchmark, we improve the search success rate to 99.47%, advancing previous state-of-the-art performance for 2.6 points.", "paper_url": "http://arxiv.org/abs/2206.11477v1", "pdf_url": "http://arxiv.org/pdf/2206.11477v1", "repo_url": "https://github.com/binghong-ml/retro_star"}, "2206.12224": {"publish_time": "2022-06-24", "title": "MPClan: Protocol Suite for Privacy-Conscious Computations", "author": "Nishat Koti et.al.", "abstract": "The growing volumes of data being collected and its analysis to provide better services are creating worries about digital privacy. To address privacy concerns and give practical solutions, the literature has relied on secure multiparty computation. However, recent research has mostly focused on the small-party honest-majority setting of up to four parties, noting efficiency concerns. In this work, we extend the strategies to support a larger number of participants in an honest-majority setting with efficiency at the center stage.   Cast in the preprocessing paradigm, our semi-honest protocol improves the online complexity of the decade-old state-of-the-art protocol of Damg\\aa rd and Nielson (CRYPTO'07). In addition to having an improved online communication cost, we can shut down almost half of the parties in the online phase, thereby saving up to 50% in the system's operational costs. Our maliciously secure protocol also enjoys similar benefits and requires only half of the parties, except for one-time verification, towards the end.   To showcase the practicality of the designed protocols, we benchmark popular applications such as deep neural networks, graph neural networks, genome sequence matching, and biometric matching using prototype implementations. Our improved protocols aid in bringing up to 60-80% savings in monetary cost over prior work.", "paper_url": "http://arxiv.org/abs/2206.12224v1", "pdf_url": "http://arxiv.org/pdf/2206.12224v1", "repo_url": null}, "2206.12104": {"publish_time": "2022-06-24", "title": "On Structural Explanation of Bias in Graph Neural Networks", "author": "Yushun Dong et.al.", "abstract": "Graph Neural Networks (GNNs) have shown satisfying performance in various graph analytical problems. Hence, they have become the \\emph{de facto} solution in a variety of decision-making scenarios. However, GNNs could yield biased results against certain demographic subgroups. Some recent works have empirically shown that the biased structure of the input network is a significant source of bias for GNNs. Nevertheless, no studies have systematically scrutinized which part of the input network structure leads to biased predictions for any given node. The low transparency on how the structure of the input network influences the bias in GNN outcome largely limits the safe adoption of GNNs in various decision-critical scenarios. In this paper, we study a novel research problem of structural explanation of bias in GNNs. Specifically, we propose a novel post-hoc explanation framework to identify two edge sets that can maximally account for the exhibited bias and maximally contribute to the fairness level of the GNN prediction for any given node, respectively. Such explanations not only provide a comprehensive understanding of bias/fairness of GNN predictions but also have practical significance in building an effective yet fair GNN model. Extensive experiments on real-world datasets validate the effectiveness of the proposed framework towards delivering effective structural explanations for the bias of GNNs. Open-source code can be found at https://github.com/yushundong/REFEREE.", "paper_url": "http://arxiv.org/abs/2206.12104v1", "pdf_url": "http://arxiv.org/pdf/2206.12104v1", "repo_url": "https://github.com/yushundong/referee"}, "2206.12004": {"publish_time": "2022-06-23", "title": "Sampling Enclosing Subgraphs for Link Prediction", "author": "Paul Louis et.al.", "abstract": "Link prediction is a fundamental problem for graph-structured data (e.g., social networks, drug side-effect networks, etc.). Graph neural networks have offered robust solutions for this problem, specifically by learning the representation of the subgraph enclosing the target link (i.e., pair of nodes). However, these solutions do not scale well to large graphs as extraction and operation on enclosing subgraphs are computationally expensive, especially for large graphs. This paper presents a scalable link prediction solution, that we call ScaLed, which utilizes sparse enclosing subgraphs to make predictions. To extract sparse enclosing subgraphs, ScaLed takes multiple random walks from a target pair of nodes, then operates on the sampled enclosing subgraph induced by all visited nodes. By leveraging the smaller sampled enclosing subgraph, ScaLed can scale to larger graphs with much less overhead while maintaining high accuracy. ScaLed further provides the flexibility to control the trade-off between computation overhead and accuracy. Through comprehensive experiments, we have shown that ScaLed can produce comparable accuracy to those reported by the existing subgraph representation learning frameworks while being less computationally demanding.", "paper_url": "http://arxiv.org/abs/2206.12004v1", "pdf_url": "http://arxiv.org/pdf/2206.12004v1", "repo_url": null}, "2206.11990": {"publish_time": "2022-06-23", "title": "Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs", "author": "Yi-Lun Liao et.al.", "abstract": "3D-related inductive biases like translational invariance and rotational equivariance are indispensable to graph neural networks operating on 3D atomistic graphs such as molecules. Inspired by the success of Transformers in various domains, we study how to incorporate these inductive biases into Transformers. In this paper, we present Equiformer, a graph neural network leveraging the strength of Transformer architectures and incorporating $SE(3)/E(3)$-equivariant features based on irreducible representations (irreps). Irreps features encode equivariant information in channel dimensions without complicating graph structures. The simplicity enables us to directly incorporate them by replacing original operations with equivariant counterparts. Moreover, to better adapt Transformers to 3D graphs, we propose a novel equivariant graph attention, which considers both content and geometric information such as relative position contained in irreps features. To improve expressivity of the attention, we replace dot product attention with multi-layer perceptron attention and include non-linear message passing. We benchmark Equiformer on two quantum properties prediction datasets, QM9 and OC20. For QM9, among models trained with the same data partition, Equiformer achieves best results on 11 out of 12 regression tasks. For OC20, under the setting of training with IS2RE data and optionally IS2RS data, Equiformer improves upon state-of-the-art models. Code reproducing all main results will be available soon.", "paper_url": "http://arxiv.org/abs/2206.11990v1", "pdf_url": "http://arxiv.org/pdf/2206.11990v1", "repo_url": null}, "2206.11972": {"publish_time": "2022-06-23", "title": "Task-Adaptive Few-shot Node Classification", "author": "Song Wang et.al.", "abstract": "Node classification is of great importance among various graph mining tasks. In practice, real-world graphs generally follow the long-tail distribution, where a large number of classes only consist of limited labeled nodes. Although Graph Neural Networks (GNNs) have achieved significant improvements in node classification, their performance decreases substantially in such a few-shot scenario. The main reason can be attributed to the vast generalization gap between meta-training and meta-test due to the task variance caused by different node/class distributions in meta-tasks (i.e., node-level and class-level variance). Therefore, to effectively alleviate the impact of task variance, we propose a task-adaptive node classification framework under the few-shot learning setting. Specifically, we first accumulate meta-knowledge across classes with abundant labeled nodes. Then we transfer such knowledge to the classes with limited labeled nodes via our proposed task-adaptive modules. In particular, to accommodate the different node/class distributions among meta-tasks, we propose three essential modules to perform \\emph{node-level}, \\emph{class-level}, and \\emph{task-level} adaptations in each meta-task, respectively. In this way, our framework can conduct adaptations to different meta-tasks and thus advance the model generalization performance on meta-test tasks. Extensive experiments on four prevalent node classification datasets demonstrate the superiority of our framework over the state-of-the-art baselines. Our code is provided at https://github.com/SongW-SW/TENT.", "paper_url": "http://arxiv.org/abs/2206.11972v1", "pdf_url": "http://arxiv.org/pdf/2206.11972v1", "repo_url": "https://github.com/songw-sw/tent"}, "2206.13419": {"publish_time": "2022-06-27", "title": "DeStripe: A Self2Self Spatio-Spectral Graph Neural Network with Unfolded Hessian for Stripe Artifact Removal in Light-sheet Microscopy", "author": "Yu Liu et.al.", "abstract": "Light-sheet fluorescence microscopy (LSFM) is a cutting-edge volumetric imaging technique that allows for three-dimensional imaging of mesoscopic samples with decoupled illumination and detection paths. Although the selective excitation scheme of such a microscope provides intrinsic optical sectioning that minimizes out-of-focus fluorescence background and sample photodamage, it is prone to light absorption and scattering effects, which results in uneven illumination and striping artifacts in the images adversely. To tackle this issue, in this paper, we propose a blind stripe artifact removal algorithm in LSFM, called DeStripe, which combines a self-supervised spatio-spectral graph neural network with unfolded Hessian prior. Specifically, inspired by the desirable properties of Fourier transform in condensing striping information into isolated values in the frequency domain, DeStripe firstly localizes the potentially corrupted Fourier coefficients by exploiting the structural difference between unidirectional stripe artifacts and more isotropic foreground images. Affected Fourier coefficients can then be fed into a graph neural network for recovery, with a Hessian regularization unrolled to further ensure structures in the standard image space are well preserved. Since in realistic, stripe-free LSFM barely exists with a standard image acquisition protocol, DeStripe is equipped with a Self2Self denoising loss term, enabling artifact elimination without access to stripe-free ground truth images. Competitive experimental results demonstrate the efficacy of DeStripe in recovering corrupted biomarkers in LSFM with both synthetic and real stripe artifacts.", "paper_url": "http://arxiv.org/abs/2206.13419v1", "pdf_url": "http://arxiv.org/pdf/2206.13419v1", "repo_url": null}, "2206.13317": {"publish_time": "2022-06-27", "title": "Automatic identification of segmentation errors for radiotherapy using geometric learning", "author": "Edward G. A. Henderson et.al.", "abstract": "Automatic segmentation of organs-at-risk (OARs) in CT scans using convolutional neural networks (CNNs) is being introduced into the radiotherapy workflow. However, these segmentations still require manual editing and approval by clinicians prior to clinical use, which can be time consuming. The aim of this work was to develop a tool to automatically identify errors in 3D OAR segmentations without a ground truth. Our tool uses a novel architecture combining a CNN and graph neural network (GNN) to leverage the segmentation's appearance and shape. The proposed model is trained using self-supervised learning using a synthetically-generated dataset of segmentations of the parotid and with realistic contouring errors. The effectiveness of our model is assessed with ablation tests, evaluating the efficacy of different portions of the architecture as well as the use of transfer learning from an unsupervised pretext task. Our best performing model predicted errors on the parotid gland with a precision of 85.0% & 89.7% for internal and external errors respectively, and recall of 66.5% & 68.6%. This offline QA tool could be used in the clinical pathway, potentially decreasing the time clinicians spend correcting contours by detecting regions which require their attention. All our code is publicly available at https://github.com/rrr-uom-projects/contour_auto_QATool.", "paper_url": "http://arxiv.org/abs/2206.13317v1", "pdf_url": "http://arxiv.org/pdf/2206.13317v1", "repo_url": "https://github.com/rrr-uom-projects/contour_auto_qatool"}, "2206.13211": {"publish_time": "2022-06-27", "title": "Cracking nuts with a sledgehammer: when modern graph neural networks do worse than classical greedy algorithms", "author": "Maria Chiara Angelini et.al.", "abstract": "The recent work ``Combinatorial Optimization with Physics-Inspired Graph Neural Networks'' [Nat Mach Intell 4 (2022) 367] introduces a physics-inspired unsupervised Graph Neural Network (GNN) to solve combinatorial optimization problems on sparse graphs. To test the performances of these GNNs, the authors of the work show numerical results for two fundamental problems: maximum cut and maximum independent set (MIS). They conclude that \"the graph neural network optimizer performs on par or outperforms existing solvers, with the ability to scale beyond the state of the art to problems with millions of variables.\"   In this comment, we show that a simple greedy algorithm, running in almost linear time, can find solutions for the MIS problem of much better quality than the GNN. The greedy algorithm is faster by a factor of $10^4$ with respect to the GNN for problems with a million variables. We do not see any good reason for solving the MIS with these GNN, as well as for using a sledgehammer to crack nuts.   In general, many claims of superiority of neural networks in solving combinatorial problems are at risk of being not solid enough, since we lack standard benchmarks based on really hard problems. We propose one of such hard benchmarks, and we hope to see future neural network optimizers tested on these problems before any claim of superiority is made.", "paper_url": "http://arxiv.org/abs/2206.13211v1", "pdf_url": "http://arxiv.org/pdf/2206.13211v1", "repo_url": null}, "2206.13181": {"publish_time": "2022-06-27", "title": "Learning to Control Local Search for Combinatorial Optimization", "author": "Jonas K. Falkner et.al.", "abstract": "Combinatorial optimization problems are encountered in many practical contexts such as logistics and production, but exact solutions are particularly difficult to find and usually NP-hard for considerable problem sizes. To compute approximate solutions, a zoo of generic as well as problem-specific variants of local search is commonly used. However, which variant to apply to which particular problem is difficult to decide even for experts.   In this paper we identify three independent algorithmic aspects of such local search algorithms and formalize their sequential selection over an optimization process as Markov Decision Process (MDP). We design a deep graph neural network as policy model for this MDP, yielding a learned controller for local search called NeuroLS. Ample experimental evidence shows that NeuroLS is able to outperform both, well-known general purpose local search controllers from Operations Research as well as latest machine learning-based approaches.", "paper_url": "http://arxiv.org/abs/2206.13181v1", "pdf_url": "http://arxiv.org/pdf/2206.13181v1", "repo_url": "https://github.com/jokofa/neurols"}, "2206.13170": {"publish_time": "2022-06-27", "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "author": "Yifan Hou et.al.", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new GNN model, called CS-GNN, is then designed to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs.", "paper_url": "http://arxiv.org/abs/2206.13170v1", "pdf_url": "http://arxiv.org/pdf/2206.13170v1", "repo_url": "https://github.com/yifan-h/CS-GNN"}, "2206.14116": {"publish_time": "2022-06-28", "title": "SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous Driving", "author": "Prarthana Bhattacharyya et.al.", "abstract": "Self-supervised learning (SSL) is an emerging technique that has been successfully employed to train convolutional neural networks (CNNs) and graph neural networks (GNNs) for more transferable, generalizable, and robust representation learning. However its potential in motion forecasting for autonomous driving has rarely been explored. In this study, we report the first systematic exploration and assessment of incorporating self-supervision into motion forecasting. We first propose to investigate four novel self-supervised learning tasks for motion forecasting with theoretical rationale and quantitative and qualitative comparisons on the challenging large-scale Argoverse dataset. Secondly, we point out that our auxiliary SSL-based learning setup not only outperforms forecasting methods which use transformers, complicated fusion mechanisms and sophisticated online dense goal candidate optimization algorithms in terms of performance accuracy, but also has low inference time and architectural complexity. Lastly, we conduct several experiments to understand why SSL improves motion forecasting. Code is open-sourced at \\url{https://github.com/AutoVision-cloud/SSL-Lanes}.", "paper_url": "http://arxiv.org/abs/2206.14116v1", "pdf_url": "http://arxiv.org/pdf/2206.14116v1", "repo_url": null}, "2206.14092": {"publish_time": "2022-06-28", "title": "Learning the Solution Operator of Boundary Value Problems using Graph Neural Networks", "author": "Winfried L\u00f6tzsch et.al.", "abstract": "As an alternative to classical numerical solvers for partial differential equations (PDEs) subject to boundary value constraints, there has been a surge of interest in investigating neural networks that can solve such problems efficiently. In this work, we design a general solution operator for two different time-independent PDEs using graph neural networks (GNNs) and spectral graph convolutions. We train the networks on simulated data from a finite elements solver on a variety of shapes and inhomogeneities. In contrast to previous works, we focus on the ability of the trained operator to generalize to previously unseen scenarios. Specifically, we test generalization to meshes with different shapes and superposition of solutions for a different number of inhomogeneities. We find that training on a diverse dataset with lots of variation in the finite element meshes is a key ingredient for achieving good generalization results in all cases. With this, we believe that GNNs can be used to learn solution operators that generalize over a range of properties and produce solutions much faster than a generic solver. Our dataset, which we make publicly available, can be used and extended to verify the robustness of these models under varying conditions.", "paper_url": "http://arxiv.org/abs/2206.14092v1", "pdf_url": "http://arxiv.org/pdf/2206.14092v1", "repo_url": null}, "2206.14024": {"publish_time": "2022-06-28", "title": "Unraveling intricate processes of glassy dynamics from static structure by machine learning relative motion", "author": "Hayato Shiba et.al.", "abstract": "Glasses, a rigid state realized by rapidly quenching a liquid, are characterized by their random and featureless structure, which is markedly distinct from crystals. Identifying how the structural changeover in a glass-forming liquid proceeds in space and time is one of the major problems. Recent progress in machine-learning technologies provides us highly accurate prediction of such glassy dynamics by using the data-driven approach. In this article, we show that predictions of intricate dynamic processes are made possible by incorporating relative motion between particles as the target feature of learning in a graph neural network. Consequently, our model can achieve unprecedented precision in predicting glassy dynamics in the short time, implicating the underlying mechanism of glassy structural relaxation. Our model may open new paths to versatile applications in molecular simulations.", "paper_url": "http://arxiv.org/abs/2206.14024v1", "pdf_url": "http://arxiv.org/pdf/2206.14024v1", "repo_url": "https://github.com/h3-Open-BDEC/pyg_botan"}, "2206.13983": {"publish_time": "2022-06-28", "title": "BAGEL: A Benchmark for Assessing Graph Neural Network Explanations", "author": "Mandeep Rathee et.al.", "abstract": "The problem of interpreting the decisions of machine learning is a well-researched and important. We are interested in a specific type of machine learning model that deals with graph data called graph neural networks. Evaluating interpretability approaches for graph neural networks (GNN) specifically are known to be challenging due to the lack of a commonly accepted benchmark. Given a GNN model, several interpretability approaches exist to explain GNN models with diverse (sometimes conflicting) evaluation methodologies. In this paper, we propose a benchmark for evaluating the explainability approaches for GNNs called Bagel. In Bagel, we firstly propose four diverse GNN explanation evaluation regimes -- 1) faithfulness, 2) sparsity, 3) correctness. and 4) plausibility. We reconcile multiple evaluation metrics in the existing literature and cover diverse notions for a holistic evaluation. Our graph datasets range from citation networks, document graphs, to graphs from molecules and proteins. We conduct an extensive empirical study on four GNN models and nine post-hoc explanation approaches for node and graph classification tasks. We open both the benchmarks and reference implementations and make them available at https://github.com/Mandeep-Rathee/Bagel-benchmark.", "paper_url": "http://arxiv.org/abs/2206.13983v1", "pdf_url": "http://arxiv.org/pdf/2206.13983v1", "repo_url": null}, "2206.13953": {"publish_time": "2022-06-28", "title": "RAW-GNN: RAndom Walk Aggregation based Graph Neural Network", "author": "Di Jin et.al.", "abstract": "Graph-Convolution-based methods have been successfully applied to representation learning on homophily graphs where nodes with the same label or similar attributes tend to connect with one another. Due to the homophily assumption of Graph Convolutional Networks (GCNs) that these methods use, they are not suitable for heterophily graphs where nodes with different labels or dissimilar attributes tend to be adjacent. Several methods have attempted to address this heterophily problem, but they do not change the fundamental aggregation mechanism of GCNs because they rely on summation operators to aggregate information from neighboring nodes, which is implicitly subject to the homophily assumption. Here, we introduce a novel aggregation mechanism and develop a RAndom Walk Aggregation-based Graph Neural Network (called RAW-GNN) method. The proposed approach integrates the random walk strategy with graph neural networks. The new method utilizes breadth-first random walk search to capture homophily information and depth-first search to collect heterophily information. It replaces the conventional neighborhoods with path-based neighborhoods and introduces a new path-based aggregator based on Recurrent Neural Networks. These designs make RAW-GNN suitable for both homophily and heterophily graphs. Extensive experimental results showed that the new method achieved state-of-the-art performance on a variety of homophily and heterophily graphs.", "paper_url": "http://arxiv.org/abs/2206.13953v1", "pdf_url": "http://arxiv.org/pdf/2206.13953v1", "repo_url": null}, "2206.14741": {"publish_time": "2022-06-29", "title": "Modeling Teams Performance Using Deep Representational Learning on Graphs", "author": "Francesco Carli et.al.", "abstract": "The large majority of human activities require collaborations within and across formal or informal teams. Our understanding of how the collaborative efforts spent by teams relate to their performance is still a matter of debate. Teamwork results in a highly interconnected ecosystem of potentially overlapping components where tasks are performed in interaction with team members and across other teams. To tackle this problem, we propose a graph neural network model designed to predict a team's performance while identifying the drivers that determine such an outcome. In particular, the model is based on three architectural channels: topological, centrality, and contextual which capture different factors potentially shaping teams' success. We endow the model with two attention mechanisms to boost model performance and allow interpretability. A first mechanism allows pinpointing key members inside the team. A second mechanism allows us to quantify the contributions of the three driver effects in determining the outcome performance. We test model performance on a wide range of domains outperforming most of the classical and neural baselines considered. Moreover, we include synthetic datasets specifically designed to validate how the model disentangles the intended properties on which our model vastly outperforms baselines.", "paper_url": "http://arxiv.org/abs/2206.14741v1", "pdf_url": "http://arxiv.org/pdf/2206.14741v1", "repo_url": null}, "2206.14724": {"publish_time": "2022-06-29", "title": "Private Graph Extraction via Feature Explanations", "author": "Iyiola E. Olatunji et.al.", "abstract": "Privacy and interpretability are two of the important ingredients for achieving trustworthy machine learning. We study the interplay of these two aspects in graph machine learning through graph reconstruction attacks. The goal of the adversary here is to reconstruct the graph structure of the training data given access to model explanations. Based on the different kinds of auxiliary information available to the adversary, we propose several graph reconstruction attacks. We show that additional knowledge of post-hoc feature explanations substantially increases the success rate of these attacks. Further, we investigate in detail the differences between attack performance with respect to three different classes of explanation methods for graph neural networks: gradient-based, perturbation-based, and surrogate model-based methods. While gradient-based explanations reveal the most in terms of the graph structure, we find that these explanations do not always score high in utility. For the other two classes of explanations, privacy leakage increases with an increase in explanation utility. Finally, we propose a defense based on a randomized response mechanism for releasing the explanations which substantially reduces the attack success rate. Our anonymized code is available.", "paper_url": "http://arxiv.org/abs/2206.14724v1", "pdf_url": "http://arxiv.org/pdf/2206.14724v1", "repo_url": null}, "2206.14418": {"publish_time": "2022-06-29", "title": "Optimization-Induced Graph Implicit Nonlinear Diffusion", "author": "Qi Chen et.al.", "abstract": "Due to the over-smoothing issue, most existing graph neural networks can only capture limited dependencies with their inherently finite aggregation layers. To overcome this limitation, we propose a new kind of graph convolution, called Graph Implicit Nonlinear Diffusion (GIND), which implicitly has access to infinite hops of neighbors while adaptively aggregating features with nonlinear diffusion to prevent over-smoothing. Notably, we show that the learned representation can be formalized as the minimizer of an explicit convex optimization objective. With this property, we can theoretically characterize the equilibrium of our GIND from an optimization perspective. More interestingly, we can induce new structural variants by modifying the corresponding optimization objective. To be specific, we can embed prior properties to the equilibrium, as well as introducing skip connections to promote training stability. Extensive experiments show that GIND is good at capturing long-range dependencies, and performs well on both homophilic and heterophilic graphs with nonlinear diffusion. Moreover, we show that the optimization-induced variants of our models can boost the performance and improve training stability and efficiency as well. As a result, our GIND obtains significant improvements on both node-level and graph-level tasks.", "paper_url": "http://arxiv.org/abs/2206.14418v1", "pdf_url": "http://arxiv.org/pdf/2206.14418v1", "repo_url": "https://github.com/7qchen/gind"}, "2206.14337": {"publish_time": "2022-06-29", "title": "Deformable Graph Transformer", "author": "Jinyoung Park et.al.", "abstract": "Transformer-based models have been widely used and achieved state-of-the-art performance in various domains such as natural language processing and computer vision. Recent works show that Transformers can also be generalized to graph-structured data. However, the success is limited to small-scale graphs due to technical challenges such as the quadratic complexity in regards to the number of nodes and non-local aggregation that often leads to inferior generalization performance to conventional graph neural networks. In this paper, to address these issues, we propose Deformable Graph Transformer (DGT) that performs sparse attention with dynamically sampled key and value pairs. Specifically, our framework first constructs multiple node sequences with various criteria to consider both structural and semantic proximity. Then, the sparse attention is applied to the node sequences for learning node representations with a reduced computational cost. We also design simple and effective positional encodings to capture structural similarity and distance between nodes. Experiments demonstrate that our novel graph Transformer consistently outperforms existing Transformer-based models and shows competitive performance compared to state-of-the-art models on 8 graph benchmark datasets including large-scale graphs.", "paper_url": "http://arxiv.org/abs/2206.14337v1", "pdf_url": "http://arxiv.org/pdf/2206.14337v1", "repo_url": null}, "2206.14331": {"publish_time": "2022-06-29", "title": "Spherical Channels for Modeling Atomic Interactions", "author": "C. Lawrence Zitnick et.al.", "abstract": "Modeling the energy and forces of atomic systems is a fundamental problem in computational chemistry with the potential to help address many of the world's most pressing problems, including those related to energy scarcity and climate change. These calculations are traditionally performed using Density Functional Theory, which is computationally very expensive. Machine learning has the potential to dramatically improve the efficiency of these calculations from days or hours to seconds. We propose the Spherical Channel Network (SCN) to model atomic energies and forces. The SCN is a graph neural network where nodes represent atoms and edges their neighboring atoms. The atom embeddings are a set of spherical functions, called spherical channels, represented using spherical harmonics. We demonstrate, that by rotating the embeddings based on the 3D edge orientation, more information may be utilized while maintaining the rotational equivariance of the messages. While equivariance is a desirable property, we find that by relaxing this constraint in both message passing and aggregation, improved accuracy may be achieved. We demonstrate state-of-the-art results on the large-scale Open Catalyst 2020 dataset in both energy and force prediction for numerous tasks and metrics.", "paper_url": "http://arxiv.org/abs/2206.14331v1", "pdf_url": "http://arxiv.org/pdf/2206.14331v1", "repo_url": null}, "2206.14987": {"publish_time": "2022-06-30", "title": "Lookback for Learning to Branch", "author": "Prateek Gupta et.al.", "abstract": "The expressive and computationally inexpensive bipartite Graph Neural Networks (GNN) have been shown to be an important component of deep learning based Mixed-Integer Linear Program (MILP) solvers. Recent works have demonstrated the effectiveness of such GNNs in replacing the branching (variable selection) heuristic in branch-and-bound (B&B) solvers. These GNNs are trained, offline and on a collection of MILPs, to imitate a very good but computationally expensive branching heuristic, strong branching. Given that B&B results in a tree of sub-MILPs, we ask (a) whether there are strong dependencies exhibited by the target heuristic among the neighboring nodes of the B&B tree, and (b) if so, whether we can incorporate them in our training procedure. Specifically, we find that with the strong branching heuristic, a child node's best choice was often the parent's second-best choice. We call this the \"lookback\" phenomenon. Surprisingly, the typical branching GNN of Gasse et al. (2019) often misses this simple \"answer\". To imitate the target behavior more closely by incorporating the lookback phenomenon in GNNs, we propose two methods: (a) target smoothing for the standard cross-entropy loss function, and (b) adding a Parent-as-Target (PAT) Lookback regularizer term. Finally, we propose a model selection framework to incorporate harder-to-formulate objectives such as solving time in the final models. Through extensive experimentation on standard benchmark instances, we show that our proposal results in up to 22% decrease in the size of the B&B tree and up to 15% improvement in the solving times.", "paper_url": "http://arxiv.org/abs/2206.14987v1", "pdf_url": "http://arxiv.org/pdf/2206.14987v1", "repo_url": null}, "2207.00255": {"publish_time": "2022-07-01", "title": "Trajectory Forecasting on Temporal Graphs", "author": "G\u00f6rkay Aydemir et.al.", "abstract": "Predicting future locations of agents in the scene is an important problem in self-driving. In recent years, there has been a significant progress in representing the scene and the agents in it. The interactions of agents with the scene and with each other are typically modeled with a Graph Neural Network. However, the graph structure is mostly static and fails to represent the temporal changes in highly dynamic scenes. In this work, we propose a temporal graph representation to better capture the dynamics in traffic scenes. We complement our representation with two types of memory modules; one focusing on the agent of interest and the other on the entire scene. This allows us to learn temporally-aware representations that can achieve good results even with simple regression of multiple futures. When combined with goal-conditioned prediction, we show better results that can reach the state-of-the-art performance on the Argoverse benchmark.", "paper_url": "http://arxiv.org/abs/2207.00255v1", "pdf_url": "http://arxiv.org/pdf/2207.00255v1", "repo_url": null}, "2207.00107": {"publish_time": "2022-06-30", "title": "Modularity Optimization as a Training Criterion for Graph Neural Networks", "author": "Tsuyoshi Murata et.al.", "abstract": "Graph convolution is a recent scalable method for performing deep feature learning on attributed graphs by aggregating local node information over multiple layers. Such layers only consider attribute information of node neighbors in the forward model and do not incorporate knowledge of global network structure in the learning task. In particular, the modularity function provides a convenient source of information about the community structure of networks. In this work we investigate the effect on the quality of learned representations by the incorporation of community structure preservation objectives of networks in the graph convolutional model. We incorporate the objectives in two ways, through an explicit regularization term in the cost function in the output layer and as an additional loss term computed via an auxiliary layer. We report the effect of community structure preserving terms in the graph convolutional architectures. Experimental evaluation on two attributed bibilographic networks showed that the incorporation of the community-preserving objective improves semi-supervised node classification accuracy in the sparse label regime.", "paper_url": "http://arxiv.org/abs/2207.00107v1", "pdf_url": "http://arxiv.org/pdf/2207.00107v1", "repo_url": "https://github.com/naveed92/gcn_modularity"}, "2207.00012": {"publish_time": "2022-06-30", "title": "Reliable Representations Make A Stronger Defender: Unsupervised Structure Refinement for Robust GNN", "author": "Kuan Li et.al.", "abstract": "Benefiting from the message passing mechanism, Graph Neural Networks (GNNs) have been successful on flourish tasks over graph data. However, recent studies have shown that attackers can catastrophically degrade the performance of GNNs by maliciously modifying the graph structure. A straightforward solution to remedy this issue is to model the edge weights by learning a metric function between pairwise representations of two end nodes, which attempts to assign low weights to adversarial edges. The existing methods use either raw features or representations learned by supervised GNNs to model the edge weights. However, both strategies are faced with some immediate problems: raw features cannot represent various properties of nodes (e.g., structure information), and representations learned by supervised GNN may suffer from the poor performance of the classifier on the poisoned graph. We need representations that carry both feature information and as mush correct structure information as possible and are insensitive to structural perturbations. To this end, we propose an unsupervised pipeline, named STABLE, to optimize the graph structure. Finally, we input the well-refined graph into a downstream classifier. For this part, we design an advanced GCN that significantly enhances the robustness of vanilla GCN without increasing the time complexity. Extensive experiments on four real-world graph benchmarks demonstrate that STABLE outperforms the state-of-the-art methods and successfully defends against various attacks.", "paper_url": "http://arxiv.org/abs/2207.00012v1", "pdf_url": "http://arxiv.org/pdf/2207.00012v1", "repo_url": null}, "2207.01411": {"publish_time": "2022-07-04", "title": "The Neural-Prediction based Acceleration Algorithm of Column Generation for Graph-Based Set Covering Problems", "author": "Haofeng Yuan et.al.", "abstract": "Set covering problem is an important class of combinatorial optimization problems, which has been widely applied and studied in many fields. In this paper, we propose an improved column generation algorithm with neural prediction (CG-P) for solving graph-based set covering problems. We leverage a graph neural network based neural prediction model to predict the probability to be included in the final solution for each edge. Our CG-P algorithm constructs a reduced graph that only contains the edges with higher predicted probability, and this graph reduction process significantly speeds up the solution process. We evaluate the CG-P algorithm on railway crew scheduling problems and it outperforms the baseline column generation algorithm. We provide two solution modes for our CG-P algorithm. In the optimal mode, we can obtain a solution with an optimality guarantee while reducing the time cost to 63.12%. In the fast mode, we can obtain a sub-optimal solution with a 7.62% optimality gap in only 2.91% computation time.", "paper_url": "http://arxiv.org/abs/2207.01411v1", "pdf_url": "http://arxiv.org/pdf/2207.01411v1", "repo_url": null}, "2207.01301": {"publish_time": "2022-07-04", "title": "NodeTrans: A Graph Transfer Learning Approach for Traffic Prediction", "author": "Xueyan Yin et.al.", "abstract": "Recently, deep learning methods have made great progress in traffic prediction, but their performance depends on a large amount of historical data. In reality, we may face the data scarcity issue. In this case, deep learning models fail to obtain satisfactory performance. Transfer learning is a promising approach to solve the data scarcity issue. However, existing transfer learning approaches in traffic prediction are mainly based on regular grid data, which is not suitable for the inherent graph data in the traffic network. Moreover, existing graph-based models can only capture shared traffic patterns in the road network, and how to learn node-specific patterns is also a challenge. In this paper, we propose a novel transfer learning approach to solve the traffic prediction with few data, which can transfer the knowledge learned from a data-rich source domain to a data-scarce target domain. First, a spatial-temporal graph neural network is proposed, which can capture the node-specific spatial-temporal traffic patterns of different road networks. Then, to improve the robustness of transfer, we design a pattern-based transfer strategy, where we leverage a clustering-based mechanism to distill common spatial-temporal patterns in the source domain, and use these knowledge to further improve the prediction performance of the target domain. Experiments on real-world datasets verify the effectiveness of our approach.", "paper_url": "http://arxiv.org/abs/2207.01301v1", "pdf_url": "http://arxiv.org/pdf/2207.01301v1", "repo_url": null}, "2207.01105": {"publish_time": "2022-07-03", "title": "Scalable Polar Code Construction for Successive Cancellation List Decoding: A Graph Neural Network-Based Approach", "author": "Yun Liao et.al.", "abstract": "While constructing polar codes for successive-cancellation decoding can be implemented efficiently by sorting the bit-channels, finding optimal polar-code constructions for the successive-cancellation list (SCL) decoding in an efficient and scalable manner still awaits investigation. This paper proposes a graph neural network (GNN)-based reinforcement learning algorithm, named the iterative message-passing (IMP) algorithm, to solve the polar-code construction problem for SCL decoding. The algorithm operates only on the local structure of the graph induced by polar-code's generator matrix. The size of the IMP model is independent of the blocklength and the code rate, making it scalable to construct polar codes with long blocklengths. Moreover, a single trained IMP model can be directly applied to a wide range of target blocklengths, code rates, and channel conditions, and corresponding polar codes can be generated without separate training. Numerical experiments show that the IMP algorithm finds polar-code constructions that significantly outperform the classical constructions under cyclic-redundancy-check-aided SCL (CA-SCL) decoding. Compared to other learning-based construction methods tailored to SCL/CA-SCL decoding, the IMP algorithm constructs polar codes with comparable or lower frame error rates, while reducing the training complexity significantly by eliminating the need of separate training at each target blocklength, code rate, and channel condition.", "paper_url": "http://arxiv.org/abs/2207.01105v1", "pdf_url": "http://arxiv.org/pdf/2207.01105v1", "repo_url": null}, "2207.01079": {"publish_time": "2022-07-03", "title": "DiSCoMaT: Distantly Supervised Composition Extraction from Tables in Material Science Articles", "author": "Tanishq Gupta et.al.", "abstract": "A crucial component in the curation of KB for a scientific domain is information extraction from tables in the domain's published articles -- tables carry important information (often numeric), which must be adequately extracted for a comprehensive machine understanding of an article. Existing table extractors assume prior knowledge of table structure and format, which may not be known in scientific tables. We study a specific and challenging table extraction problem: extracting compositions of materials (e.g., glasses, alloys). We first observe that material science researchers organize similar compositions in a wide variety of table styles, necessitating an intelligent model for table understanding and composition extraction. Consequently, we define this novel task as a challenge for the ML community and create a training dataset comprising 4,408 distantly supervised tables, along with 1,475 manually annotated dev and test tables. We also present DiSCoMaT, a strong baseline geared towards this specific task, which combines multiple graph neural networks with several task-specific regular expressions, features, and constraints. We show that DiSCoMaT outperforms recent table processing architectures by significant margins.", "paper_url": "http://arxiv.org/abs/2207.01079v1", "pdf_url": "http://arxiv.org/pdf/2207.01079v1", "repo_url": null}, "2207.00940": {"publish_time": "2022-07-03", "title": "A Graph Isomorphism Network with Weighted Multiple Aggregators for Speech Emotion Recognition", "author": "Ying Hu et.al.", "abstract": "Speech emotion recognition (SER) is an essential part of human-computer interaction. In this paper, we propose an SER network based on a Graph Isomorphism Network with Weighted Multiple Aggregators (WMA-GIN), which can effectively handle the problem of information confusion when neighbour nodes' features are aggregated together in GIN structure. Moreover, a Full-Adjacent (FA) layer is adopted for alleviating the over-squashing problem, which is existed in all Graph Neural Network (GNN) structures, including GIN. Furthermore, a multi-phase attention mechanism and multi-loss training strategy are employed to avoid missing the useful emotional information in the stacked WMA-GIN layers. We evaluated the performance of our proposed WMA-GIN on the popular IEMOCAP dataset. The experimental results show that WMA-GIN outperforms other GNN-based methods and is comparable to some advanced non-graph-based methods by achieving 72.48% of weighted accuracy (WA) and 67.72% of unweighted accuracy (UA).", "paper_url": "http://arxiv.org/abs/2207.00940v1", "pdf_url": "http://arxiv.org/pdf/2207.00940v1", "repo_url": null}, "2207.01839": {"publish_time": "2022-07-05", "title": "What Do Graph Convolutional Neural Networks Learn?", "author": "Sannat Singh Bhasin et.al.", "abstract": "Graph neural networks (GNNs) have gained traction over the past few years for their superior performance in numerous machine learning tasks. Graph Convolutional Neural Networks (GCN) are a common variant of GNNs that are known to have high performance in semi-supervised node classification (SSNC), and work well under the assumption of homophily. Recent literature has highlighted that GCNs can achieve strong performance on heterophilous graphs under certain \"special conditions\". These arguments motivate us to understand why, and how, GCNs learn to perform SSNC. We find a positive correlation between similarity of latent node embeddings of nodes within a class and the performance of a GCN. Our investigation on underlying graph structures of a dataset finds that a GCN's SSNC performance is significantly influenced by the consistency and uniqueness in neighborhood structure of nodes within a class.", "paper_url": "http://arxiv.org/abs/2207.01839v1", "pdf_url": "http://arxiv.org/pdf/2207.01839v1", "repo_url": null}, "2207.02760": {"publish_time": "2022-07-06", "title": "Graph Trees with Attention", "author": "Maya Bechler-Speicher et.al.", "abstract": "When dealing with tabular data, models based on regression and decision trees are a popular choice due to the high accuracy they provide on such tasks and their ease of application as compared to other model classes. Yet, when it comes to graph-structure data, current tree learning algorithms do not provide tools to manage the structure of the data other than relying on feature engineering. In this work we address the above gap, and introduce Graph Trees with Attention (GTA), a new family of tree-based learning algorithms that are designed to operate on graphs. GTA leverages both the graph structure and the features at the vertices and employs an attention mechanism that allows decisions to concentrate on sub-structures of the graph. We analyze GTA models and show that they are strictly more expressive than plain decision trees. We also demonstrate the benefits of GTA empirically on multiple graph and node prediction benchmarks. In these experiments, GTA always outperformed other tree-based models and often outperformed other types of graph-learning algorithms such as Graph Neural Networks (GNNs) and Graph Kernels. Finally, we also provide an explainability mechanism for GTA, and demonstrate it can provide intuitive explanations.", "paper_url": "http://arxiv.org/abs/2207.02760v1", "pdf_url": "http://arxiv.org/pdf/2207.02760v1", "repo_url": null}, "2207.02547": {"publish_time": "2022-07-06", "title": "Simple and Efficient Heterogeneous Graph Neural Network", "author": "Xiaocheng Yang et.al.", "abstract": "Heterogeneous graph neural networks (HGNNs) deliver the powerful capability to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing HGNNs usually learn to embed information using hierarchy attention mechanism and repeated neighbor aggregation, suffering from unnecessary complexity and redundant computation. This paper proposes Simple and Efficient Heterogeneous Graph Neural Network (SeHGNN) which reduces this excess complexity through avoiding overused node-level attention within the same relation and pre-computing the neighbor aggregation in the pre-processing stage. Unlike previous work, SeHGNN utilizes a light-weight parameter-free neighbor aggregator to learn structural information for each metapath, and a transformer-based semantic aggregator to combine semantic information across metapaths for the final embedding of each node. As a result, SeHGNN offers the simple network structure, high prediction accuracy, and fast training speed. Extensive experiments on five real-world heterogeneous graphs demonstrate the superiority of SeHGNN over the state-of-the-arts on both the accuracy and training speed. Codes are available at https://github.com/ICT-GIMLab/SeHGNN.", "paper_url": "http://arxiv.org/abs/2207.02547v1", "pdf_url": "http://arxiv.org/pdf/2207.02547v1", "repo_url": "https://github.com/ict-gimlab/sehgnn"}, "2207.02505": {"publish_time": "2022-07-06", "title": "Pure Transformers are Powerful Graph Learners", "author": "Jinwoo Kim et.al.", "abstract": "We show that standard Transformers without graph-specific modifications can lead to promising results in graph learning both in theory and practice. Given a graph, we simply treat all nodes and edges as independent tokens, augment them with token embeddings, and feed them to a Transformer. With an appropriate choice of token embeddings, we prove that this approach is theoretically at least as expressive as an invariant graph network (2-IGN) composed of equivariant linear layers, which is already more expressive than all message-passing Graph Neural Networks (GNN). When trained on a large-scale graph dataset (PCQM4Mv2), our method coined Tokenized Graph Transformer (TokenGT) achieves significantly better results compared to GNN baselines and competitive results compared to Transformer variants with sophisticated graph-specific inductive bias. Our implementation is available at https://github.com/jw9730/tokengt.", "paper_url": "http://arxiv.org/abs/2207.02505v1", "pdf_url": "http://arxiv.org/pdf/2207.02505v1", "repo_url": "https://github.com/jw9730/tokengt"}, "2207.02368": {"publish_time": "2022-07-06", "title": "Text Enriched Sparse Hyperbolic Graph Convolutional Networks", "author": "Nurendra Choudhary et.al.", "abstract": "Heterogeneous networks, which connect informative nodes containing text with different edge types, are routinely used to store and process information in various real-world applications. Graph Neural Networks (GNNs) and their hyperbolic variants provide a promising approach to encode such networks in a low-dimensional latent space through neighborhood aggregation and hierarchical feature extraction, respectively. However, these approaches typically ignore metapath structures and the available semantic information. Furthermore, these approaches are sensitive to the noise present in the training data. To tackle these limitations, in this paper, we propose Text Enriched Sparse Hyperbolic Graph Convolution Network (TESH-GCN) to capture the graph's metapath structures using semantic signals and further improve prediction in large heterogeneous graphs. In TESH-GCN, we extract semantic node information, which successively acts as a connection signal to extract relevant nodes' local neighborhood and graph-level metapath features from the sparse adjacency tensor in a reformulated hyperbolic graph convolution layer. These extracted features in conjunction with semantic features from the language model (for robustness) are used for the final downstream task. Experiments on various heterogeneous graph datasets show that our model outperforms the current state-of-the-art approaches by a large margin on the task of link prediction. We also report a reduction in both the training time and model parameters compared to the existing hyperbolic approaches through a reformulated hyperbolic graph convolution. Furthermore, we illustrate the robustness of our model by experimenting with different levels of simulated noise in both the graph structure and text, and also, present a mechanism to explain TESH-GCN's prediction by analyzing the extracted metapaths.", "paper_url": "http://arxiv.org/abs/2207.02368v2", "pdf_url": "http://arxiv.org/pdf/2207.02368v2", "repo_url": null}, "2207.02242": {"publish_time": "2022-07-05", "title": "State-Augmented Learnable Algorithms for Resource Management in Wireless Networks", "author": "Navid NaderiAlizadeh et.al.", "abstract": "We consider resource management problems in multi-user wireless networks, which can be cast as optimizing a network-wide utility function, subject to constraints on the long-term average performance of users across the network. We propose a state-augmented algorithm for solving the aforementioned radio resource management (RRM) problems, where, alongside the instantaneous network state, the RRM policy takes as input the set of dual variables corresponding to the constraints, which evolve depending on how much the constraints are violated during execution. We theoretically show that the proposed state-augmented algorithm leads to feasible and near-optimal RRM decisions. Moreover, focusing on the problem of wireless power control using graph neural network (GNN) parameterizations, we demonstrate the superiority of the proposed RRM algorithm over baseline methods across a suite of numerical experiments.", "paper_url": "http://arxiv.org/abs/2207.02242v1", "pdf_url": "http://arxiv.org/pdf/2207.02242v1", "repo_url": "https://github.com/navid-naderi/stateaugmented_rrm_gnn"}, "2207.02957": {"publish_time": "2022-07-06", "title": "Context-aware Self-supervised Learning for Medical Images Using Graph Neural Network", "author": "Li Sun et.al.", "abstract": "Although self-supervised learning enables us to bootstrap the training by exploiting unlabeled data, the generic self-supervised methods for natural images do not sufficiently incorporate the context. For medical images, a desirable method should be sensitive enough to detect deviation from normal-appearing tissue of each anatomical region; here, anatomy is the context. We introduce a novel approach with two levels of self-supervised representation learning objectives: one on the regional anatomical level and another on the patient-level. We use graph neural networks to incorporate the relationship between different anatomical regions. The structure of the graph is informed by anatomical correspondences between each patient and an anatomical atlas. In addition, the graph representation has the advantage of handling any arbitrarily sized image in full resolution. Experiments on large-scale Computer Tomography (CT) datasets of lung images show that our approach compares favorably to baseline methods that do not account for the context. We use the learned embedding for staging lung tissue abnormalities related to COVID-19.", "paper_url": "http://arxiv.org/abs/2207.02957v1", "pdf_url": "http://arxiv.org/pdf/2207.02957v1", "repo_url": null}}}}